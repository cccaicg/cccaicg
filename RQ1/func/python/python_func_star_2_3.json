{"docstring": "\"\"\"Provide site_data variable with settings (currently only MEDIA_URL).\"\"\"\n", "func_signal": "def site_data(**kwargs):\n", "code": "content = 'window.site_data = {};'\ncontent += 'window.site_data.settings = %s;' % dumps({\n    'MEDIA_URL': settings.MEDIA_URL\n})\nreturn content", "path": "common\\appenginepatch\\mediautils\\generatemedia.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "\"\"\"Copy all media files directly\"\"\"\n", "func_signal": "def add_uncombined_app_media(env, app):\n", "code": "path = os.path.join(\n    os.path.dirname(__import__(app, {}, {}, ['']).__file__), 'media')\napp = app.rsplit('.', 1)[-1]\nfor root, dirs, files in os.walk(path):\n    for file in files:\n        if file.endswith(('.css', '.js')):\n            base = os.path.join(root, file)[len(path):].replace(os.sep,\n                '/').lstrip('/')\n            target = '%s/%s' % (app, base)\n            add_app_media(env, target, target)", "path": "common\\appenginepatch\\ragendja\\settings_post.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "\"\"\"\nValidate that the username is alphanumeric and is not already\nin use.\n\n\"\"\"\n", "func_signal": "def clean_username(self):\n", "code": "user = User.get_by_key_name(\"key_\"+self.cleaned_data['username'].lower())\nif user:\n    raise forms.ValidationError(_(u'This username is already taken. Please choose another.'))\nreturn self.cleaned_data['username']", "path": "registration\\forms.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "# Allow for using a RegisterVars instance as a context processor\n", "func_signal": "def __call__(self, item=None, name=None):\n", "code": "if isinstance(item, HttpRequest):\n    return self\nif name is None and isinstance(item, basestring):\n    # @register('as_name') # first param (item) contains the name\n    name, item = item, name\nelif name is None and isinstance(item, dict):\n    # register(somedict)  or  register(othermodule.register)\n    return self.update(item)\nif item is None and isinstance(name, basestring):\n    # @register(name='as_name')\n    return lambda func: self(func, name)\nself[name or item.__name__] = item\nreturn item", "path": "common\\appenginepatch\\ragendja\\registervars.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "# Ignore port if it's 80 or 443\n", "func_signal": "def process_request(self, request):\n", "code": "if ':' in request.get_host():\n    domain, port = request.get_host().split(':')\n    if int(port) not in (80, 443):\n        domain = request.get_host()\nelse:\n    domain = request.get_host().split(':')[0]\n\n# Try exact domain and fall back to with/without 'www.'\nsite = Site.all().filter('domain =', domain).get()\nif not site:\n    if domain.startswith('www.'):\n        fallback_domain = domain[4:]\n    else:\n        fallback_domain = 'www.' + domain\n    site = Site.all().filter('domain =', fallback_domain).get()\n\n# Add site if it doesn't exist\nif not site and getattr(settings, 'CREATE_SITES_AUTOMATICALLY', True):\n    site = db_create(Site, domain=domain, name=domain)\n    site.put()\n\n# Set SITE_ID for this thread/request\nif site:\n    SITE_ID.value = str(site.key())\nelse:\n    SITE_ID.value = _default_site_id", "path": "common\\appenginepatch\\ragendja\\sites\\dynamicsite.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "\"\"\"\nVerifiy that the values entered into the two password fields\nmatch. Note that an error here will end up in\n``non_field_errors()`` because it doesn't apply to a single\nfield.\n\n\"\"\"\n", "func_signal": "def clean(self):\n", "code": "if 'password1' in self.cleaned_data and 'password2' in self.cleaned_data:\n    if self.cleaned_data['password1'] != self.cleaned_data['password2']:\n        raise forms.ValidationError(_(u'You must type the same password each time'))\nreturn self.cleaned_data", "path": "registration\\forms.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "# Remove old generated files\n", "func_signal": "def cleanup_dir(dir, paths):\n", "code": "keep = []\ndir = os.path.abspath(dir)\nfor path in paths:\n    if not os.path.isabs(path):\n        path = os.path.join(dir, path)\n    path = os.path.abspath(path)\n    while path not in keep and path != dir:\n        keep.append(path)\n        path = os.path.dirname(path)\nfor root, dirs, files in os.walk(dir):\n    for name in dirs:\n        path = os.path.abspath(os.path.join(root, name))\n        if path not in keep:\n            shutil.rmtree(path)\n            dirs.remove(name)\n    for file in files:\n        path = os.path.abspath(os.path.join(root, file))\n        if path not in keep:\n            os.remove(path)", "path": "common\\appenginepatch\\mediautils\\generatemedia.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "\"\"\"\nDecorator that requires user.is_staff. Otherwise renders no_access.html.\n\"\"\"\n", "func_signal": "def staff_only(view):\n", "code": "@login_required\ndef wrapped(request, *args, **kwargs):\n    if request.user.is_active and request.user.is_staff:\n        return view(request, *args, **kwargs)\n    return render_to_response(request, 'no_access.html')\nreturn wrapped", "path": "common\\appenginepatch\\ragendja\\auth\\decorators.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "\"\"\"Returns all files that must be combined.\"\"\"\n", "func_signal": "def get_targets(combine_media=settings.COMBINE_MEDIA, **kwargs):\n", "code": "targets = []\nfor target in sorted(combine_media.keys()):\n    group = combine_media[target]\n    if '.site_data.js' in group:\n        index = list(group).index('.site_data.js')\n        group = group[:index] + (site_data,) + group[index+1:]\n    group = tuple(group)\n    if '%(LANGUAGE_CODE)s' in target:\n        # This file uses i18n, so generate a separate file per language.\n        # The language data is always added before all other files.\n        for LANGUAGE_CODE in LANGUAGES:\n            data = kwargs.copy()\n            data['LANGUAGE_CODE'] = LANGUAGE_CODE\n            filename = target % data\n            data['target'] = filename\n            group = (lang_data,) + group\n            targets.append((filename, data, group))\n    elif '%(LANGUAGE_DIR)s' in target:\n        # Generate CSS files for both text directions\n        for LANGUAGE_DIR in ('ltr', 'rtl'):\n            data = kwargs.copy()\n            data['LANGUAGE_DIR'] = LANGUAGE_DIR\n            filename = target % data\n            data['target'] = filename\n            targets.append((filename, data, group))\n    else:\n        data = kwargs.copy()\n        filename = target % data\n        data['target'] = filename\n        targets.append((filename, data, group))\nreturn targets", "path": "common\\appenginepatch\\mediautils\\generatemedia.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "#logging.warn(dir(request))\n#logging.warn(type(request.user))\n", "func_signal": "def createprofile(request):\n", "code": "logging.debug('entering createprofile')\ntemplatepage = 'createprofile.html'\nrc = {}\nrc.update(callmeutil.populatecreatepage(request.user))\npost = request.POST\n\nif request.user.get_profile():\n\t#logging.warn(\"We DO NOT want to create the new user: he looks like this: \"+ request.user.get_profile())\n\tlogging.warn(\"We DO NOT want to create the new user\")#: he looks like this: \"+ request.user.get_profile())\n\n#if phone number entered then we set up the new CUser\nif post.has_key('phone_number1') and post.has_key('phone_number2') and post.has_key('phone_number3'):\n\tphone_number = extractPhoneNumber(post)\n\tnow = datetime.now()\n\tsecret = int(random()*100000)\n\tuserProfile = CUser(phone_number=phone_number, date_last_used=now,\n\t\tverified=False, clients=1, secret=secret)\n\t\n\t#if there are test results then something is wrong, need to send that\n\t#otherwise profile looks good so far, we can send the sms\n\tif not userProfile.validate():\n\t\trc['val'] = 1\n\t\trc['response'] = \"error in input\"# userProfile.popitem()\n\t\tlogging.error('error in validation of phone number')\n\n\telse:\n\t\t#logging.warn(\"request.user type: \" + str(type(user)))\n\n\t\tuserProfile = CUser(user = request.user, phone_number=phone_number, date_last_used=now,\n\t\tverified=False, clients=1, secret=secret)\n\t\tuserProfile.save()\n\t\t#user.save()\n\t\t#request.user = user\n\t\tsendConfirmation(userProfile, phone_number)\n\t\trc['val'] = 0\n\t\trc['numbersent'] = True\n\t\trc['profile'] = userProfile\n\nelif post.has_key('code'):\n\t#see if it is the correct code\n\tcode = post.get('code', '')\n\tif str(request.user.get_profile().secret) == str(code):\n\t\tuser = request.user.get_profile()\n\t\tuser.verified = True\n\t\tuser.save()\n\t\ttemplatepage = 'create.html'\n\telse:\n\t\trc['numbersent'] = True\n\t\nreturn render_to_response(request, templatepage, rc)", "path": "callme\\views.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "\"\"\"\nAppends '?' or '&' to an url, so you can easily add extra GET parameters.\n\"\"\"\n", "func_signal": "def urlquerybase(url):\n", "code": "if url:\n    if '?' in url:\n        url += '&'\n    else:\n        url += '?'\nreturn url", "path": "common\\appenginepatch\\ragendja\\templatetags\\ragendjatags.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "\"\"\"Creates a class-wide instance property with a thread-specific value.\"\"\"\n", "func_signal": "def make_tls_property(default=None):\n", "code": "class TLSProperty(object):\n    def __init__(self):\n        self.local = local()\n\n    def __get__(self, instance, cls):\n        if not instance:\n            return self\n        return self.value\n\n    def __set__(self, instance, value):\n        self.value = value\n\n    def _get_value(self):\n        return getattr(self.local, 'value', default)\n    def _set_value(self, value):\n        self.local.value = value\n    value = property(_get_value, _set_value)\n\nreturn TLSProperty()", "path": "common\\appenginepatch\\ragendja\\pyutils.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "\"\"\"\nConverts objects to table-style list of rows with heading:\n\nExample:\nx.a = 1\nx.b = 2\nx.c = 3\ny.a = 11\ny.b = 12\ny.c = 13\nobject_list_to_table(('a', 'b', 'c'), [x, y])\nresults in the following (dict keys reordered for better readability):\n[\n    ('a', 'b', 'c'),\n    (1, 2, 3),\n    (11, 12, 13),\n]\n\"\"\"\n", "func_signal": "def object_list_to_table(headings, dict_list):\n", "code": "return [headings] + [tuple([getattr_by_path(row, heading, None)\n                            for heading in headings])\n                     for row in dict_list]", "path": "common\\appenginepatch\\ragendja\\pyutils.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "\"\"\"\nValidate that the supplied email address is unique for the\nsite.\n\n\"\"\"\n", "func_signal": "def clean_email(self):\n", "code": "email = self.cleaned_data['email'].lower()\nif User.all().filter('email =', email).count(1):\n    raise forms.ValidationError(_(u'This email address is already in use. Please supply a different email address.'))\nreturn email", "path": "registration\\forms.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "\"\"\"\nCompares two lists and returs True if they contain the same elements, but\ndoesn't require that they have the same order.\n\"\"\"\n", "func_signal": "def equal_lists(left, right):\n", "code": "right = list(right)\nif len(left) != len(right):\n    return False\nfor item in left:\n    if item in right:\n        del right[right.index(item)]\n    else:\n        return False\nreturn True", "path": "common\\appenginepatch\\ragendja\\pyutils.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "# These are needed for i18n\n", "func_signal": "def lang_data(LANGUAGE_CODE, **kwargs):\n", "code": "from django.http import HttpRequest\nfrom django.views.i18n import javascript_catalog\n\nLANGUAGE_BIDI = LANGUAGE_CODE.split('-')[0] in \\\n    settings.LANGUAGES_BIDI\n\nrequest = HttpRequest()\nrequest.GET['language'] = LANGUAGE_CODE\n\n# Add some JavaScript data\ncontent = 'var LANGUAGE_CODE = \"%s\";\\n' % LANGUAGE_CODE\ncontent += 'var LANGUAGE_BIDI = ' + \\\n    (LANGUAGE_BIDI and 'true' or 'false') + ';\\n'\ncontent += javascript_catalog(request,\n    packages=settings.INSTALLED_APPS).content\n\n# The hgettext() function just calls gettext() internally, but\n# it won't get indexed by makemessages.\ncontent += '\\nwindow.hgettext = function(text) { return gettext(text); };\\n'\n# Add a similar hngettext() function\ncontent += 'window.hngettext = function(singular, plural, count) { return ngettext(singular, plural, count); };\\n'\n\nreturn content", "path": "common\\appenginepatch\\mediautils\\generatemedia.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "\"\"\"Like getattr(), but can go down a hierarchy like 'attr.subattr'\"\"\"\n", "func_signal": "def getattr_by_path(obj, attr, *default):\n", "code": "value = obj\nfor part in attr.split('.'):\n    if not hasattr(value, part) and len(default):\n        return default[0]\n    value = getattr(value, part)\n    if callable(value):\n        value = value()\nreturn value", "path": "common\\appenginepatch\\ragendja\\pyutils.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "\"\"\"Returns paths of files that must be copied directly.\"\"\"\n# Some files types (MUST_COMBINE) never get copied.\n# They must always be combined.\n", "func_signal": "def get_copy_targets(media_dirs, **kwargs):\n", "code": "targets = {}\nfor app, media_dir in media_dirs.items():\n    for root, dirs, files in os.walk(media_dir):\n        for name in dirs:\n            if name.startswith('.'):\n                dirs.remove(name)\n        for file in files:\n            if file.startswith('.') or file.endswith(tuple(MUST_COMBINE)):\n                continue\n            path = os.path.abspath(os.path.join(root, file))\n            base = app + path[len(media_dir):]\n            targets[base.replace(os.sep, '/')] = path\nreturn targets", "path": "common\\appenginepatch\\mediautils\\generatemedia.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "\"\"\"\nCreate the new ``User`` and ``RegistrationProfile``, and\nreturns the ``User`` (by calling\n``RegistrationProfile.objects.create_inactive_user()``).\n\n\"\"\"\n", "func_signal": "def save(self, domain_override=\"\"):\n", "code": "new_user = RegistrationProfile.objects.create_inactive_user(username=self.cleaned_data['username'],\n                                                            password=self.cleaned_data['password1'],\n                                                            email=self.cleaned_data['email'],\n                                                            domain_override=domain_override,\n                                                            )\nreturn new_user", "path": "registration\\forms.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "\"\"\"\nCheck the supplied email address against a list of known free\nwebmail domains.\n\n\"\"\"\n", "func_signal": "def clean_email(self):\n", "code": "email_domain = self.cleaned_data['email'].split('@')[1]\nif email_domain in self.bad_domains:\n    raise forms.ValidationError(_(u'Registration using free email addresses is prohibited. Please supply a different email address.'))\nreturn self.cleaned_data['email']", "path": "registration\\forms.py", "repo_name": "rodericj/rodericj_com", "stars": 2, "license": "None", "language": "python", "size": 5856}
{"docstring": "\"\"\"\nCheck if an item is in the session data.\n\nArgs:\n    keyname: The keyname being searched.\n\"\"\"\n", "func_signal": "def __contains__(self, keyname):\n", "code": "try:\n    r = self.__getitem__(keyname)\nexcept KeyError:\n    return False\nreturn True", "path": "appengine_utilities\\sessions.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nDeletes all sessions and session data from the data store and memcache.\n\"\"\"\n", "func_signal": "def delete_all_sessions(self):\n", "code": "all_sessions_deleted = False\nall_data_deleted = False\n\nwhile not all_sessions_deleted:\n    query = _AppEngineUtilities_Session.all()\n    results = query.fetch(1000)\n    if len(results) is 0:\n        all_sessions_deleted = True\n    else:\n        for result in results:\n            result.delete()\n\nwhile not all_data_deleted:\n    query = _AppEngineUtilities_SessionData.all()\n    results = query.fetch(1000)\n    if len(results) is 0:\n        all_data_deleted = True\n    else:\n        for result in results:\n            result.delete()", "path": "appengine_utilities\\sessions.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nDelete the session and all session data for the sid passed.\n\"\"\"\n", "func_signal": "def _delete_session(self):\n", "code": "sessiondata = self._get()\n# delete from datastore\nif sessiondata is not None:\n    for sd in sessiondata:\n        sd.delete()\n# delete from memcache\nmemcache.delete('sid-'+str(self.session.key()))\n# delete the session now that all items that reference it are deleted.\nself.session.delete()\n# if the event class has been loaded, fire off the sessionDeleted event\nif 'AEU_Events' in __main__.__dict__:\n    __main__.AEU_Events.fire_event('sessionDelete')", "path": "appengine_utilities\\sessions.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "# start with dow as per cron if dow and day are set\n# then dow is used if it comes before day. If dow\n# is *, then ignore it.\n", "func_signal": "def _calc_day(self, next_run, cron):\n", "code": "if str(cron[\"dow\"]) != str(\"*\"):\n    # convert any integers to lists in order to easily compare values\n    m = next_run.month\n    while True:\n        if next_run.month is not m:\n            next_run = next_run.replace(hour=0, minute=0)\n            next_run = self._calc_month(next_run, cron)\n        if next_run.weekday() in cron[\"dow\"] or next_run.day in cron[\"day\"]:\n            return next_run\n        else:\n            one_day = datetime.timedelta(days=1)\n            next_run = next_run + one_day\nelse:\n    m = next_run.month\n    while True:\n        if next_run.month is not m:\n            next_run = next_run.replace(hour=0, minute=0)\n            next_run = self._calc_month(next_run, cron)\n        # if cron[\"dow\"] is next_run.weekday() or cron[\"day\"] is next_run.day:\n        if next_run.day in cron[\"day\"]:\n            return next_run\n        else:\n            one_day = datetime.timedelta(days=1)\n            next_run = next_run + one_day", "path": "appengine_utilities\\cron.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nThis method will subscribe a callback function to an event name.\n\"\"\"\n", "func_signal": "def subscribe(self, event, callback, args = None):\n", "code": "if not {\"event\": event, \"callback\": callback, \"args\": args, } \\\n    in self.events:\n    self.events.append({\"event\": event, \"callback\": callback, \\\n        \"args\": args, })", "path": "appengine_utilities\\event.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nSet a memcache object with all the session date. Optionally you can\nadd a key and value to the memcache for put operations.\n\"\"\"\n# Pull directly from the datastore in order to ensure that the\n# information is as up to date as possible.\n", "func_signal": "def _set_memcache(self):\n", "code": "data = {}\nsessiondata = self._get()\nif sessiondata is not None:\n    for sd in sessiondata:\n        data[sd.keyname] = pickle.loads(sd.content)\n\nmemcache.set('sid-'+str(self.session.key()), data, \\\n    self.session_expire_time)", "path": "appengine_utilities\\sessions.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nThis method is what a method uses to fire an event,\ninitiating all registered callbacks\n\"\"\"\n", "func_signal": "def fire_event(self, event = None):\n", "code": "for e in self.events:\n    if e[\"event\"] == event:\n        if type(e[\"args\"]) == type([]):\n            e[\"callback\"](*e[\"args\"])\n        elif type(e[\"args\"]) == type({}):\n            e[\"callback\"](**e[\"args\"])\n        elif e[\"args\"] == None:\n            e[\"callback\"]()\n        else:\n            e[\"callback\"](e[\"args\"])", "path": "appengine_utilities\\event.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nValidate the keyname, making sure it is set and not a reserved name.\n\"\"\"\n", "func_signal": "def _validate_key(self, keyname):\n", "code": "if keyname is None:\n    raise ValueError('You must pass a keyname for the session' + \\\n        ' data content.')\nelif keyname in ('sid', 'flash'):\n    raise ValueError(keyname + ' is a reserved keyname.')\n\nif type(keyname) != type([str, unicode]):\n    return str(keyname)\nreturn keyname", "path": "appengine_utilities\\sessions.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nCreate a new session id.\n\"\"\"\n", "func_signal": "def new_sid(self):\n", "code": "sid = sha.new(repr(time.time()) + os.environ['REMOTE_ADDR'] + \\\n        str(random.random())).hexdigest()\nreturn sid", "path": "appengine_utilities\\sessions.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nGet item from session data.\n\nkeyname: The keyname of the mapping.\n\"\"\"\n# flash messages don't go in the datastore\n\n", "func_signal": "def __getitem__(self, keyname):\n", "code": "if self.integrate_flash and (keyname == 'flash'):\n    return self.flash.msg\nif keyname in self.cache:\n    return pickle.loads(str(self.cache[keyname]))\nmc = memcache.get('sid-'+str(self.session.key()))\nif mc is not None:\n    if keyname in mc:\n        return mc[keyname]\ndata = self._get(keyname)\nif data:\n    self.cache[keyname] = data.content\n    self._set_memcache()\n    return pickle.loads(data.content)\nelse:\n    raise KeyError(str(keyname))", "path": "appengine_utilities\\sessions.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nDelete item from session data.\n\nArgs:\n    keyname: The keyname of the object to delete.\n\"\"\"\n", "func_signal": "def __delitem__(self, keyname):\n", "code": "sessdata = self._get(keyname = keyname)\nif sessdata is None:\n    raise KeyError(str(keyname))\nsessdata.delete()\nif keyname in self.cache:\n    del self.cache[keyname]\nself._set_memcache()", "path": "appengine_utilities\\sessions.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nInsert a keyname/value pair into the datastore for the session.\n\nArgs:\n    keyname: The keyname of the mapping.\n    value: The value of the mapping.\n\"\"\"\n", "func_signal": "def _put(self, keyname, value):\n", "code": "keyname = self._validate_key(keyname)\n \nif value is None:\n    raise ValueError('You must pass a value to put.')\nsessdata = self._get(keyname=keyname)\nif sessdata is None:\n    sessdata = _AppEngineUtilities_SessionData()\n    sessdata.session = self.session\n    sessdata.keyname = keyname\nsessdata.content = pickle.dumps(value)\nself.cache[keyname] = pickle.dumps(value)\nsessdata.put()\nself._set_memcache()", "path": "appengine_utilities\\sessions.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "# kludge for issue 842, right now we use request headers\n# to set the host.\n", "func_signal": "def _validate_url(self, url):\n", "code": "if url[0] is not \"/\":\n    url = \"/\" + url\nurl = 'http://' + str(os.environ['HTTP_HOST']) + url\nreturn url\n# content below is for when that issue gets fixed\n#regex = re.compile(\"^(http|https):\\/\\/([a-z0-9-]\\.+)*\", re.IGNORECASE)\n#if regex.match(url) is not None:\n#    return url\n#else:\n#    raise ValueError, \"Invalid url \" + url", "path": "appengine_utilities\\cron.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nParse the field to determine whether it is an integer or lists,\nalso converting strings to integers where necessary. If passed bad\nvalues, raises a ValueError.\n\"\"\"\n", "func_signal": "def _validate_cron(self, cron):\n", "code": "parsers = {\n    'dow': self._validate_dow,\n    'mon': self._validate_mon,\n    'day': self._validate_day,\n    'hour': self._validate_hour,\n    'min': self._validate_min,\n    'url': self. _validate_url,\n}\nfor el in cron:\n    parse = parsers[el]\n    cron[el] = parse(cron[el])\nreturn cron", "path": "appengine_utilities\\cron.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nSet item in session data.\n\nArgs:\n    keyname: They keyname of the mapping.\n    value: The value of mapping.\n\"\"\"\n #       if type(keyname) is type(''):\n    # flash messages don't go in the datastore\n\n", "func_signal": "def __setitem__(self, keyname, value):\n", "code": "if self.integrate_flash and (keyname == 'flash'):\n    self.flash.msg = value\nelse:\n    keyname = self._validate_key(keyname)\n    self.cache[keyname] = value\n    self._set_memcache()\n    return self._put(keyname, value)", "path": "appengine_utilities\\sessions.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nGet the user's session from the datastore\n\"\"\"\n", "func_signal": "def _get_session(self):\n", "code": "query = _AppEngineUtilities_Session.all()\nquery.filter('sid', self.sid)\nif self.check_user_agent:\n    query.filter('ua', os.environ['HTTP_USER_AGENT'])\nif self.check_ip:\n    query.filter('ip', os.environ['REMOTE_ADDR'])\nresults = query.fetch(1)\nif len(results) is 0:\n    return None\nelse:\n    sessionAge = datetime.datetime.now() - results[0].last_activity\n    if sessionAge.seconds > self.session_expire_time:\n        results[0].delete()\n        return None\n    return results[0]", "path": "appengine_utilities\\sessions.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nThis method will unsubscribe a callback from an event.\n\"\"\"\n", "func_signal": "def unsubscribe(self, event, callback, args = None):\n", "code": "if {\"event\": event, \"callback\": callback, \"args\": args, }\\\n    in self.events:\n    self.events.remove({\"event\": event, \"callback\": callback,\\\n        \"args\": args, })", "path": "appengine_utilities\\event.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nReturn size of session.\n\"\"\"\n# check memcache first\n", "func_signal": "def __len__(self):\n", "code": "mc = memcache.get('sid-'+str(self.session.key()))\nif mc is not None:\n    return len(mc)\nresults = self._get()\nreturn len(results)", "path": "appengine_utilities\\sessions.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nDelete expired sessions from the datastore.\n\nThis is only called for CLEAN_CHECK_PERCENT percent of requests because\nit could be rather intensive.\n\"\"\"\n", "func_signal": "def _clean_old_sessions(self):\n", "code": "duration = datetime.timedelta(seconds=self.session_expire_time)\nsession_age = datetime.datetime.now() - duration\nquery = _AppEngineUtilities_Session.all()\nquery.filter('last_activity <', session_age)\nresults = query.fetch(1000)\nfor result in results:\n    data_query = _AppEngineUtilities_SessionData.all()\n    query.filter('session', result)\n    data_results = data_query.fetch(1000)\n    for data_result in data_results:\n        data_result.delete()\n    memcache.delete('sid-'+str(result.key()))\n    result.delete()", "path": "appengine_utilities\\sessions.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nIterate over the keys in the session data.\n\"\"\"\n# try memcache first\n", "func_signal": "def __iter__(self):\n", "code": "mc = memcache.get('sid-'+str(self.session.key()))\nif mc is not None:\n    for k in mc:\n        yield k\nelse:\n    for k in self._get():\n        yield k.keyname", "path": "appengine_utilities\\sessions.py", "repo_name": "codeprimate/appengine_baseapp", "stars": 2, "license": "None", "language": "python", "size": 118}
{"docstring": "\"\"\"\nAttempt to load the associated session using the identifier from\nthe cookie.\n\"\"\"\n", "func_signal": "def _loadSessionFromCookie(self, environ):\n", "code": "C = SimpleCookie(environ.get('HTTP_COOKIE'))\nmorsel = C.get(self._cookieName, None)\nif morsel is not None:\n    self._session = self._store.checkOutSession(morsel.value)\n    self._expired = self._session is None", "path": "wdsession.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "# TODO: implement login by username in addition to email\n", "func_signal": "def login(email='',user='',remember_me=''):\n", "code": "r = '0'\nif remember_me:\n    r = '1'\nlogin_time = int(time.time())\nuser = web.select('users',where='email = $email',vars=locals())[0]\n#print user\nweb.transact()\nweb.query(\"UPDATE users SET login = $login_time, remember_me = $r \\\n    WHERE uid = $user.uid\", vars=locals())\n#print user.uid\ninc.session.regenerate(uid=user.uid)\nweb.commit()", "path": "modules\\user\\user.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"Returns a form item of input formats available to roles.\"\"\"\n", "func_signal": "def form_fields_input_formats(users_roles=[1]):\n", "code": "formats = _formats_available(users_roles)\nformats_allowed = [f.format for f in formats]\nfields = []\nif len(formats) > 1:  # Multiple formats available\n    a = {'desc':'Input Formats'}\n    for f in formats:\n        fields.append(form.Radio('format',\n            [(f.format,f.name)], \n            form.Validator('No permission to use that input format.',\n                lambda x: int(x) in formats_allowed),\n            description=a.pop('desc',''), value=formats[0].format,\n            ))\n\nelse:  # Only one format available: use a hidden form item and only show tips.\n    f = formats[0]\n    fields.append(form.Hidden('format',\n        form.Validator('No permission to use that input format.',\n            lambda x: int(x) in formats_allowed),\n        value=f.format, post=f.tips))\nreturn tuple(fields)", "path": "modules\\filter\\filter.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"Encodes session ID in URL, if necessary.\"\"\"\n", "func_signal": "def encodeURL(self, url):\n", "code": "assert not self._closed\nif not self.encodesSessionInURL or self._session is None:\n    return url\nu = list(urlparse.urlsplit(url))\nq = '%s=%s' % (self._fieldName, self._sessionIdentifier())\nif u[3]:\n    u[3] = q + '&' + u[3]\nelse:\n    u[3] = q\nreturn urlparse.urlunsplit(u)", "path": "wdsession.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"Timeout old sessions. Should be called periodically.\"\"\"\n", "func_signal": "def periodic(self):\n", "code": "self._lock.acquire()\ntry:\n    if not self._shutdownRan:\n        self._periodic()\nfinally:\n    self._lock.release()", "path": "wdsession.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"returns the 'page' number from the GET input after verifying that it's an integer.\"\"\"\n", "func_signal": "def _current_page():\n", "code": "if web.input().has_key('page'):\n    try:\n        return int(re.match(r'\\d+',web.input()['page']).group(0))\n    except:\n        pass\nelse: return 1", "path": "includes\\pager.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"A list of all filter modules available.\"\"\"\n", "func_signal": "def _filters_available():\n", "code": "filters = []\nfor name in mod:\n    if hasattr(mod[name],'drupy_filter'):\n        filters.append(name)\nreturn filters", "path": "modules\\filter\\filter.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"\nGenerate a random session identifier.\n\"\"\"\n", "func_signal": "def generateIdentifier(cls):\n", "code": "raw = os.urandom(cls.identifierLength)\n\nsessId = ''\nfor c in raw:\n    # So we lose 2 bits per random byte...\n    sessId += cls.identifierChars[ord(c) % len(cls.identifierChars)]\nreturn sessId", "path": "wdsession.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"the node_load for story, page, or other genric node types\"\"\"\n", "func_signal": "def node_load(nid, vid):\n", "code": "try:\n    addition = web.query('''SELECT r.vid, r.timestamp \\\n    AS revision_timestamp, r.title, r.body, r.teaser, r.log, r.format, \\\n    r.uid FROM node_revisions r WHERE r.nid = $nid AND r.vid = $vid''', \n    vars=locals())[0]\nexcept IndexError:\n    raise \"node table out of sync with revisions\"\n    # TODO:  Report to watchdog that node table\n    # and this addition table are out of sync for some reason.\nreturn addition", "path": "modules\\node\\generic.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"Called when an anonymous user becomes authenticated or vice-versa.\"\"\"\n", "func_signal": "def regenerate(uid=0):\n", "code": "old_session_id = web.cookies()._SID_\nnew_session_id = _generate_id()\nweb.setcookie(\"_SID_\",new_session_id)\n#uid = int(uid)\n#print web.query(\"UPDATE sessions SET uid = '$uid', sid = $new_session_id WHERE sid = $old_session_id\", vars=locals(),_test=True)\nweb.query(\"UPDATE sessions SET uid = $uid, sid = $new_session_id WHERE sid = $old_session_id\", vars=locals())", "path": "includes\\session.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"\nWraps an iterator so that its close() method calls closeFunc. Respects\nthe existence of __len__ and the iterator's own close() method.\n\nNeed to use metaclass magic because __len__ and next are not\nrecognized unless they're part of the class. (Can't assign at\n__init__ time.)\n\"\"\"\n", "func_signal": "def _addClose(appIter, closeFunc):\n", "code": "class metaIterWrapper(type):\n    def __init__(cls, name, bases, clsdict):\n        super(metaIterWrapper, cls).__init__(name, bases, clsdict)\n        if hasattr(appIter, '__len__'):\n            cls.__len__ = appIter.__len__\n        cls.next = iter(appIter).next\n        if hasattr(appIter, 'close'):\n            def _close(self):\n                appIter.close()\n                closeFunc()\n            cls.close = _close\n        else:\n            cls.close = closeFunc\n\nclass iterWrapper(object):\n    __metaclass__ = metaIterWrapper\n    def __iter__(self):\n        return self\n\nreturn iterWrapper()", "path": "wdsession.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"Clean up outstanding sessions.\"\"\"\n", "func_signal": "def shutdown(self):\n", "code": "self._lock.acquire()\ntry:\n    if not self._shutdownRan:\n        # Save or delete any sessions that are still out there.\n        for key,sess in self._checkOutList.items():\n            if sess.isValid:\n                self._saveSession(sess)\n            else:\n                self._deleteSession(sess.identifier)\n        self._checkOutList.clear()\n        self._shutdown()\n        self._shutdownRan = True\nfinally:\n    self._lock.release()", "path": "wdsession.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"Checks session back into session store.\"\"\"\n", "func_signal": "def close(self):\n", "code": "if self._session is None:\n    return\n# Check the session back in and get rid of our reference.\nself._store.checkInSession(self._session)\nself._session = None\nif __debug__: self._closed = True", "path": "wdsession.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"\nGiven a datatuple of (subject, message, from_email, recipient_list), sends\neach message to each recipient list. Returns the number of e-mails sent.\n\nIf from_email is None, the DEFAULT_FROM_EMAIL setting is used.\nIf auth_user and auth_password are set, they're used to log in.\n\"\"\"\n", "func_signal": "def send_mass_mail(datatuple, fail_silently=False, auth_user=settings.EMAIL_HOST_USER, auth_password=settings.EMAIL_HOST_PASSWORD):\n", "code": "try:\n    if settings.USE_SMTPLIB:\n        server = smtplib.SMTP(settings.EMAIL_HOST, settings.EMAIL_PORT)\n        if auth_user and auth_password:\n            server.login(auth_user, auth_password)\n    else:\n        sendmail = os.popen(\"%s -t\" % settings.SENDMAIL_LOCATION, \"w\")\nexcept:\n    if fail_silently:\n        return\n    raise\nnum_sent = 0\nfor subject, message, from_email, recipient_list in datatuple:\n    if not recipient_list:\n        continue\n    from_email = from_email or settings.DEFAULT_FROM_EMAIL\n    msg = SafeMIMEText(message, 'plain', settings.DEFAULT_CHARSET)\n    msg['Subject'] = subject\n    msg['From'] = from_email\n    msg['To'] = ', '.join(recipient_list)\n    msg['Date'] = rfc822.formatdate()\n    try:\n        if settings.USE_SMTPLIB:\n            server.sendmail(from_email, recipient_list, msg.as_string())\n        else:\n            sendmail.write(msg.as_string())\n        num_sent += 1\n    except:\n        if not fail_silently:\n            raise\ntry:\n    if settings.USE_SMTPLIB:\n        server.quit()\n    else:\n        sendmail.close()\nexcept:\n    if fail_silently:\n        return\n    raise\nreturn num_sent", "path": "includes\\mail.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"Delete all sessions older than lifetime\nWe could call this on every request, but may as well just do it \nat some periodic interval. \"\"\"\n", "func_signal": "def clean(lifetime=2592000):\n", "code": "timestamp = int(time.time()) - lifetime\nweb.query(\"DELETE FROM sessions WHERE timestamp < $timestamp\", vars=locals())\nreturn True", "path": "includes\\session.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"Returns the identifier of the current session.\"\"\"\n", "func_signal": "def _sessionIdentifier(self):\n", "code": "assert self._session is not None\nreturn self._session.identifier", "path": "wdsession.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"\nReturns True if the session cookie should be added to the header\n(if not encoding the session ID in the URL). The cookie is added if\none of these three conditions are true: a) the session was just\ncreated, b) the session is no longer valid, or c) the client is\nassociated with a non-existent session.\n\"\"\"\n", "func_signal": "def _shouldAddCookie(self):\n", "code": "return self._newSession or \\\n       (self._session is not None and not self._session.isValid) or \\\n       (self._session is None and self._expired)", "path": "wdsession.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\" returns a list of tuples like [(1,1),(2,2),(3,3),(4,Next)]\n    This gets passed to the template.  In each tuple, the first\n    parameter is the page number, the second is the link name used\n    in the anchor tag.\n\"\"\"\n", "func_signal": "def _page_nums(self,current,total,show):\n", "code": "p = []\n\nif current > 1:\n    p.append((current-1,'&#171; previous'))\nelse: p.append((None,'&#171; previous'))\n\nif current > show/2+1:\n    p.append((1,1))\nif current > show/2+2:\n    p.append((None,'&#0133;'))\n\nif current <= show/2:\n    for i in range(1,show+1):\n        p.append((i,i))\nelif current >= total-show/2:\n    for i in range(total-show+1,total+1):\n        p.append((i,i))\nelse:\n    for i in range(current-show/2,current+show/2+1):\n        p.append((i,i))\n\nif current < total-show/2-1:\n    p.append((None,'&#0133;'))\nif current < total-show/2:\n    p.append((total,total))\n\nif current <  total:\n    p.append((current+1,'next &#187;'))\nelse: p.append((None,'next &#187;'))\n\nreturn p", "path": "includes\\pager.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"honestly, I'm not sure what this function is for\"\"\"\n", "func_signal": "def user(op):\n", "code": "if op == 'delete':\n    #db_query('UPDATE {watchdog} SET uid = 0 WHERE uid = %d', $user->uid);\n    pass", "path": "modules\\watchdog\\watchdog.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"Invalidate this Session.\"\"\"\n", "func_signal": "def invalidate(self):\n", "code": "self.clear()\nself._creationTime = self._lastAccessTime = 0\nself._isValid = False", "path": "wdsession.py", "repo_name": "keizo/kulu", "stars": 3, "license": "None", "language": "python", "size": 922}
{"docstring": "\"\"\"Convenience method that works with all 2.x versions of Python\nto determine whether or not something is stringlike.\"\"\"\n", "func_signal": "def isString(s):\n", "code": "try:\n    return isinstance(s, unicode) or isinstance(s, basestring)\nexcept NameError:\n    return isinstance(s, str)", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Returns the parents of this Tag that match the given\ncriteria.\"\"\"\n\n", "func_signal": "def findParents(self, name=None, attrs={}, limit=None, **kwargs):\n", "code": "return self._findAll(name, attrs, None, limit, self.parentGenerator,\n                     **kwargs)", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Given a document, tries to detect its XML encoding.\"\"\"\n", "func_signal": "def _detectEncoding(self, xml_data, isHTML=False):\n", "code": "xml_encoding = sniffed_xml_encoding = None\ntry:\n    if xml_data[:4] == '\\x4c\\x6f\\xa7\\x94':\n        # EBCDIC\n        xml_data = self._ebcdic_to_ascii(xml_data)\n    elif xml_data[:4] == '\\x00\\x3c\\x00\\x3f':\n        # UTF-16BE\n        sniffed_xml_encoding = 'utf-16be'\n        xml_data = unicode(xml_data, 'utf-16be').encode('utf-8')\n    elif (len(xml_data) >= 4) and (xml_data[:2] == '\\xfe\\xff') \\\n             and (xml_data[2:4] != '\\x00\\x00'):\n        # UTF-16BE with BOM\n        sniffed_xml_encoding = 'utf-16be'\n        xml_data = unicode(xml_data[2:], 'utf-16be').encode('utf-8')\n    elif xml_data[:4] == '\\x3c\\x00\\x3f\\x00':\n        # UTF-16LE\n        sniffed_xml_encoding = 'utf-16le'\n        xml_data = unicode(xml_data, 'utf-16le').encode('utf-8')\n    elif (len(xml_data) >= 4) and (xml_data[:2] == '\\xff\\xfe') and \\\n             (xml_data[2:4] != '\\x00\\x00'):\n        # UTF-16LE with BOM\n        sniffed_xml_encoding = 'utf-16le'\n        xml_data = unicode(xml_data[2:], 'utf-16le').encode('utf-8')\n    elif xml_data[:4] == '\\x00\\x00\\x00\\x3c':\n        # UTF-32BE\n        sniffed_xml_encoding = 'utf-32be'\n        xml_data = unicode(xml_data, 'utf-32be').encode('utf-8')\n    elif xml_data[:4] == '\\x3c\\x00\\x00\\x00':\n        # UTF-32LE\n        sniffed_xml_encoding = 'utf-32le'\n        xml_data = unicode(xml_data, 'utf-32le').encode('utf-8')\n    elif xml_data[:4] == '\\x00\\x00\\xfe\\xff':\n        # UTF-32BE with BOM\n        sniffed_xml_encoding = 'utf-32be'\n        xml_data = unicode(xml_data[4:], 'utf-32be').encode('utf-8')\n    elif xml_data[:4] == '\\xff\\xfe\\x00\\x00':\n        # UTF-32LE with BOM\n        sniffed_xml_encoding = 'utf-32le'\n        xml_data = unicode(xml_data[4:], 'utf-32le').encode('utf-8')\n    elif xml_data[:3] == '\\xef\\xbb\\xbf':\n        # UTF-8 with BOM\n        sniffed_xml_encoding = 'utf-8'\n        xml_data = unicode(xml_data[3:], 'utf-8').encode('utf-8')\n    else:\n        sniffed_xml_encoding = 'ascii'\n        pass\nexcept:\n    xml_encoding_match = None\nxml_encoding_re = '^<\\?.*encoding=[\\'\"](.*?)[\\'\"].*\\?>'.encode()\nxml_encoding_match = re.compile(xml_encoding_re).match(xml_data)\nif not xml_encoding_match and isHTML:\n    meta_re = '<\\s*meta[^>]+charset=([^>]*?)[;\\'\">]'.encode()\n    regexp = re.compile(meta_re, re.I)\n    xml_encoding_match = regexp.search(xml_data)\nif xml_encoding_match is not None:\n    xml_encoding = xml_encoding_match.groups()[0].decode(\n        'ascii').lower()\n    if isHTML:\n        self.declaredHTMLEncoding = xml_encoding\n    if sniffed_xml_encoding and \\\n       (xml_encoding in ('iso-10646-ucs-2', 'ucs-2', 'csunicode',\n                         'iso-10646-ucs-4', 'ucs-4', 'csucs4',\n                         'utf-16', 'utf-32', 'utf_16', 'utf_32',\n                         'utf16', 'u16')):\n        xml_encoding = sniffed_xml_encoding\nreturn xml_data, xml_encoding, sniffed_xml_encoding", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Treat a bogus SGML declaration as raw data. Treat a CDATA\ndeclaration as a CData object.\"\"\"\n", "func_signal": "def parse_declaration(self, i):\n", "code": "j = None\nif self.rawdata[i:i+9] == '<![CDATA[':\n     k = self.rawdata.find(']]>', i)\n     if k == -1:\n         k = len(self.rawdata)\n     data = self.rawdata[i+9:k]\n     j = k+3\n     self._toStringSubclass(data, CData)\nelse:\n    try:\n        j = HTMLParser.parse_declaration(self, i)\n    except HTMLParseError:\n        toHandle = self.rawdata[i:]\n        self.handle_data(toHandle)\n        j = i + len(toHandle)\nreturn j", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Encodes an object to a string in some encoding, or to Unicode.\n.\"\"\"\n", "func_signal": "def toEncoding(self, s, encoding=None):\n", "code": "if isinstance(s, unicode):\n    if encoding:\n        s = s.encode(encoding)\nelif isinstance(s, str):\n    if encoding:\n        s = s.encode(encoding)\n    else:\n        s = unicode(s)\nelse:\n    if encoding:\n        s  = self.toEncoding(str(s), encoding)\n    else:\n        s = unicode(s)\nreturn s", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Returns either the given Unicode string or its encoding.\"\"\"\n", "func_signal": "def sob(unicode, encoding):\n", "code": "if encoding is None:\n    return unicode\nelse:\n    return unicode.encode(encoding)", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Used in a call to re.sub to replace HTML, XML, and numeric\nentities with the appropriate Unicode characters. If HTML\nentities are being converted, any unrecognized entities are\nescaped.\"\"\"\n", "func_signal": "def _convertEntities(self, match):\n", "code": "x = match.group(1)\nif self.convertHTMLEntities and x in name2codepoint:\n    return unichr(name2codepoint[x])\nelif x in self.XML_ENTITIES_TO_SPECIAL_CHARS:\n    if self.convertXMLEntities:\n        return self.XML_ENTITIES_TO_SPECIAL_CHARS[x]\n    else:\n        return u'&%s;' % x\nelif len(x) > 0 and x[0] == '#':\n    # Handle numeric entities\n    if len(x) > 1 and x[1] == 'x':\n        return unichr(int(x[2:], 16))\n    else:\n        return unichr(int(x[1:]))\n\nelif self.escapeUnrecognizedEntities:\n    return u'&amp;%s;' % x\nelse:\n    return u'&%s;' % x", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "# Convert the document to Unicode.\n", "func_signal": "def _feed(self, inDocumentEncoding=None, isHTML=False):\n", "code": "markup = self.markup\nif isinstance(markup, unicode):\n    if not hasattr(self, 'originalEncoding'):\n        self.originalEncoding = None\nelse:\n    dammit = UnicodeDammit\\\n             (markup, [self.fromEncoding, inDocumentEncoding],\n              smartQuotesTo=self.smartQuotesTo, isHTML=isHTML)\n    markup = dammit.unicode\n    self.originalEncoding = dammit.originalEncoding\n    self.declaredHTMLEncoding = dammit.declaredHTMLEncoding\nif markup:\n    if self.markupMassage:\n        if not isList(self.markupMassage):\n            self.markupMassage = self.MARKUP_MASSAGE\n        for fix, m in self.markupMassage:\n            markup = fix.sub(m, markup)\n        # TODO: We get rid of markupMassage so that the\n        # soup object can be deepcopied later on. Some\n        # Python installations can't copy regexes. If anyone\n        # was relying on the existence of markupMassage, this\n        # might cause problems.\n        del(self.markupMassage)\nself.builder.reset()\n\nself.builder.feed(markup)\n# Close out any unfinished strings and close all the open tags.\nself.endData()\nwhile self.currentTag.name != self.ROOT_TAG_NAME:\n    self.popTag()", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Returns true iff this tag has the same name, the same attributes,\nand the same contents (recursively) as the given tag.\n\nNOTE: right now this will return false if two tags have the\nsame attributes in a different order. Should this be fixed?\"\"\"\n", "func_signal": "def __eq__(self, other):\n", "code": "if not hasattr(other, 'name') or not hasattr(other, 'attrs') or not hasattr(other, 'contents') or self.name != other.name or self.attrs != other.attrs or len(self) != len(other):\n    return False\nfor i in range(0, len(self.contents)):\n    if self.contents[i] != other.contents[i]:\n        return False\nreturn True", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Sets up the initial relations between this element and\nother elements.\"\"\"\n", "func_signal": "def setup(self, parent=None, previous=None):\n", "code": "self.parent = parent\nself.previous = previous\nself.next = None\nself.previousSibling = None\nself.nextSibling = None\nif self.parent and self.parent.contents:\n    self.previousSibling = self.parent.contents[-1]\n    self.previousSibling.nextSibling = self", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "#print \"End tag %s\" % name\n", "func_signal": "def unknown_endtag(self, name):\n", "code": "if self.quoteStack and self.quoteStack[-1] != name:\n    #This is not a real end tag.\n    #print \"</%s> is not real!\" % name\n    self.handle_data('</%s>' % name)\n    return\nself.endData()\nself._popToTag(name)\nif self.quoteStack and self.quoteStack[-1] == name:\n    self.quoteStack.pop()\n    self.literal = (len(self.quoteStack) > 0)", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Turns a list of maps, lists, or scalars into a single map.\nUsed to build the SELF_CLOSING_TAGS, NESTABLE_TAGS, and\nNESTING_RESET_TAGS maps out of lists and partial maps.\"\"\"\n", "func_signal": "def buildTagMap(default, *args):\n", "code": "built = {}\nfor portion in args:\n    if hasattr(portion, 'items'):\n        #It's a map. Merge it.\n        for k,v in portion.items():\n            built[k] = v\n    elif isList(portion) and not isString(portion):\n        #It's a list. Map each item to the default.\n        for k in portion:\n            built[k] = default\n    else:\n        #It's a scalar. Map it to the default.\n        built[portion] = default\nreturn built", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Pops the tag stack up to and including the most recent\ninstance of the given tag. If inclusivePop is false, pops the tag\nstack up to but *not* including the most recent instqance of\nthe given tag.\"\"\"\n#print \"Popping to %s\" % name\n", "func_signal": "def _popToTag(self, name, inclusivePop=True):\n", "code": "if name == self.ROOT_TAG_NAME:\n    return\n\nnumPops = 0\nmostRecentTag = None\nfor i in range(len(self.tagStack)-1, 0, -1):\n    if name == self.tagStack[i].name:\n        numPops = len(self.tagStack)-i\n        break\nif not inclusivePop:\n    numPops = numPops - 1\n\nfor i in range(0, numPops):\n    mostRecentTag = self.popTag()\nreturn mostRecentTag", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "# test in/out equivalence and parsing\n", "func_signal": "def test_parse(self):\n", "code": "res = json.loads(JSON)\nout = json.dumps(res)\nself.assertEquals(res, json.loads(out))", "path": "simplejson\\tests\\test_pass3.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Destructively rips this element out of the tree.\"\"\"\n", "func_signal": "def extract(self):\n", "code": "if self.parent:\n    try:\n        self.parent.contents.remove(self)\n    except ValueError:\n        pass\n\n#Find the two elements that would be next to each other if\n#this element (and any children) hadn't been parsed. Connect\n#the two.\nlastChild = self._lastRecursiveChild()\nnextElement = lastChild.next\n\nif self.previous:\n    self.previous.next = nextElement\nif nextElement:\n    nextElement.previous = self.previous\nself.previous = None\nlastChild.next = None\n\nself.parent = None\nif self.previousSibling:\n    self.previousSibling.nextSibling = self.nextSibling\nif self.nextSibling:\n    self.nextSibling.previousSibling = self.previousSibling\nself.previousSibling = self.nextSibling = None\nreturn self", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Setting tag[key] sets the value of the 'key' attribute for the\ntag.\"\"\"\n", "func_signal": "def __setitem__(self, key, value):\n", "code": "self._getAttrMap()\nself.attrMap[key] = value\nfound = False\nfor i in range(0, len(self.attrs)):\n    if self.attrs[i][0] == key:\n        self.attrs[i] = (key, value)\n        found = True\nif not found:\n    self.attrs.append((key, value))\nself._getAttrMap()[key] = value", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Recursively destroys the contents of this tree.\"\"\"\n", "func_signal": "def decompose(self):\n", "code": "contents = [i for i in self.contents]\nfor i in contents:\n    if isinstance(i, Tag):\n        i.decompose()\n    else:\n        i.extract()\nself.extract()", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Adds a certain piece of text to the tree as a NavigableString\nsubclass.\"\"\"\n", "func_signal": "def _toStringSubclass(self, text, subclass):\n", "code": "self.soup.endData()\nself.handle_data(text)\nself.soup.endData(subclass)", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Returns the closest sibling to this Tag that matches the\ngiven criteria and appears before this Tag in the document.\"\"\"\n", "func_signal": "def findPreviousSibling(self, name=None, attrs={}, text=None, **kwargs):\n", "code": "return self._findOne(self.findPreviousSiblings, name, attrs, text,\n                     **kwargs)", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Returns the closest sibling to this Tag that matches the\ngiven criteria and appears after this Tag in the document.\"\"\"\n", "func_signal": "def findNextSibling(self, name=None, attrs={}, text=None, **kwargs):\n", "code": "return self._findOne(self.findNextSiblings, name, attrs, text,\n                     **kwargs)", "path": "BeautifulSoup.py", "repo_name": "pkeane/bibfinder", "stars": 2, "license": "None", "language": "python", "size": 952}
{"docstring": "\"\"\"Change stopbits size.\"\"\"\n", "func_signal": "def setStopbits(self, stopbits):\n", "code": "if stopbits not in self.STOPBITS: raise ValueError(\"Not a valid stopbit size: %r\" % (stopbits,))\nself._stopbits = stopbits\nif self._isOpen: self._reconfigurePort()", "path": "src\\BoPunk\\lib\\serial\\serialutil.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"Change inter-character timeout setting.\"\"\"\n", "func_signal": "def setInterCharTimeout(self, interCharTimeout):\n", "code": "if interCharTimeout is not None:\n    if interCharTimeout < 0: raise ValueError(\"Not a valid timeout: %r\" % interCharTimeout)\n    try:\n        interCharTimeout + 1     #test if it's a number, will throw a TypeError if not...\n    except TypeError:\n        raise ValueError(\"Not a valid timeout: %r\" % interCharTimeout)\n\nself._interCharTimeout = interCharTimeout\nif self._isOpen: self._reconfigurePort()", "path": "src\\BoPunk\\lib\\serial\\serialutil.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"Set terminal status line: Data Terminal Ready\"\"\"\n", "func_signal": "def setDTR(self, level=True):\n", "code": "if not self._port_handle: raise portNotOpenError\nself._port_handle.DtrEnable = bool(level)", "path": "src\\BoPunk\\lib\\serial\\serialcli.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"Read terminal status line: Clear To Send\"\"\"\n", "func_signal": "def getCTS(self):\n", "code": "if not self._port_handle: raise portNotOpenError\nreturn self._port_handle.CtsHolding", "path": "src\\BoPunk\\lib\\serial\\serialcli.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"Send break condition. Timed, returns to idle state after given duration.\"\"\"\n", "func_signal": "def sendBreak(self, duration=0.25):\n", "code": "if not self._port_handle: raise portNotOpenError\nimport time\nself._port_handle.BreakState = True\ntime.sleep(duration)\nself._port_handle.BreakState = False", "path": "src\\BoPunk\\lib\\serial\\serialcli.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"read a line which is terminated with end-of-line (eol) character\n('\\n' by default) or until timeout\"\"\"\n", "func_signal": "def readline(self, size=None, eol='\\n'):\n", "code": "line = ''\nwhile 1:\n    c = self.read(1)\n    if c:\n        line += c   #not very efficient but lines are usually not that long\n        if c == eol:\n            break\n        if size is not None and len(line) >= size:\n            break\n    else:\n        break\nreturn line", "path": "src\\BoPunk\\lib\\serial\\serialutil.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"Change timeout setting.\"\"\"\n", "func_signal": "def setWriteTimeout(self, timeout):\n", "code": "if timeout is not None:\n    if timeout < 0: raise ValueError(\"Not a valid timeout: %r\" % (timeout,))\n    try:\n        timeout + 1     #test if it's a number, will throw a TypeError if not...\n    except TypeError:\n        raise ValueError(\"Not a valid timeout: %r\" % timeout)\n\nself._writeTimeout = timeout\nif self._isOpen: self._reconfigurePort()", "path": "src\\BoPunk\\lib\\serial\\serialutil.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"\nCall this to remove from the firmware list. Otherwise the tableView\nwill not update.        \n\"\"\"\n# begin/end must be called\n", "func_signal": "def removeRows(self, row, count, parent = QtCore.QModelIndex()):\n", "code": "self.beginRemoveRows(parent, row, row+count-1)\n# do action\nself.endRemoveRows()\nreturn True", "path": "src\\BoPunk\\FirmwareTableModel.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"Close port\"\"\"\n", "func_signal": "def close(self):\n", "code": "if self._isOpen:\n    if self._port_handle:\n        try:\n            self._port_handle.Close()\n        except System.IO.Ports.InvalidOperationException:\n            # ignore errors. can happen for unplugged USB serial devices\n            pass\n        self._port_handle = None\n    self._isOpen = False", "path": "src\\BoPunk\\lib\\serial\\serialcli.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"Change baudrate. It raises a ValueError if the port is open and the\nbaudrate is not possible. If the port is closed, then tha value is\naccepted and the exception is raised when the port is opened.\"\"\"\n#~ if baudrate not in self.BAUDRATES: raise ValueError(\"Not a valid baudrate: %r\" % baudrate)\n", "func_signal": "def setBaudrate(self, baudrate):\n", "code": "try:\n    self._baudrate = int(baudrate)\nexcept TypeError:\n    raise ValueError(\"Not a valid baudrate: %r\" % (baudrate,))\nelse:\n    if self._isOpen:  self._reconfigurePort()", "path": "src\\BoPunk\\lib\\serial\\serialutil.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"Change the port. The attribute portstr is set to a string that\n   contains the name of the port.\"\"\"\n\n", "func_signal": "def setPort(self, port):\n", "code": "was_open = self._isOpen\nif was_open: self.close()\nif port is not None:\n    if type(port) in [type(''), type(u'')]:       #strings are taken directly\n        self.portstr = port\n    else:\n        self.portstr = self.makeDeviceName(port)\nelse:\n    self.portstr = None\nself._port = port\nif was_open: self.open()", "path": "src\\BoPunk\\lib\\serial\\serialutil.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"Return the number of characters currently in the input buffer.\"\"\"\n", "func_signal": "def inWaiting(self):\n", "code": "if not self._port_handle: raise portNotOpenError\nreturn self._port_handle.BytesToRead", "path": "src\\BoPunk\\lib\\serial\\serialcli.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"Set break: Controls TXD. When active, to transmitting is possible.\"\"\"\n", "func_signal": "def setBreak(self, level=True):\n", "code": "if not self._port_handle: raise portNotOpenError\nself._port_handle.BreakState = bool(level)", "path": "src\\BoPunk\\lib\\serial\\serialcli.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"Change parity setting.\"\"\"\n", "func_signal": "def setParity(self, parity):\n", "code": "if parity not in self.PARITIES: raise ValueError(\"Not a valid parity: %r\" % (parity,))\nself._parity = parity\nif self._isOpen: self._reconfigurePort()", "path": "src\\BoPunk\\lib\\serial\\serialutil.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"Read terminal status line: Ring Indicator\"\"\"\n", "func_signal": "def getRI(self):\n", "code": "if not self._port_handle: raise portNotOpenError\n#~ return self._port_handle.XXX\nreturn False #XXX an error would be better", "path": "src\\BoPunk\\lib\\serial\\serialcli.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"\nReturns the data for the various 'roles' used in a table. Currently\nonly the DisplayRole is implemented.\n\"\"\"\n# TODO: add more roles, such as tooltip.\n", "func_signal": "def data(self, index, role):\n", "code": "if not index.isValid():\n    return QVariant()\nelif role != Qt.DisplayRole:\n    return QVariant()\n\n# return the data for a given row/col\n# use the header to get the proper key for the index\nrow = index.row()\nkey = self.myheader[index.column()].lower()\nreturn QVariant(self.feed[row].get(key))", "path": "src\\BoPunk\\FirmwareTableModel.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"Change timeout setting.\"\"\"\n", "func_signal": "def setTimeout(self, timeout):\n", "code": "if timeout is not None:\n    if timeout < 0: raise ValueError(\"Not a valid timeout: %r\" % (timeout,))\n    try:\n        timeout + 1     #test if it's a number, will throw a TypeError if not...\n    except TypeError:\n        raise ValueError(\"Not a valid timeout: %r\" % (timeout,))\n\nself._timeout = timeout\nif self._isOpen: self._reconfigurePort()", "path": "src\\BoPunk\\lib\\serial\\serialutil.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"Change DsrDtr flow control setting.\"\"\"\n", "func_signal": "def setDsrDtr(self, dsrdtr=None):\n", "code": "if dsrdtr is None:\n    #if not set, keep backwards compatibility and follow rtscts setting\n    self._dsrdtr = self._rtscts\nelse:\n    #if defined independently, follow its value\n    self._dsrdtr = dsrdtr\nif self._isOpen: self._reconfigurePort()", "path": "src\\BoPunk\\lib\\serial\\serialutil.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"setup the table of firmware with title/author, etc\"\"\"\n\n", "func_signal": "def setupFirmwareTable(self):\n", "code": "self.header = [\"Title\",\"Updated\",\"Author\",\"Summary\"]\nself.feed_url = \"http://www.bocolab.org/bopunks/feeds/firms.atom.xml\"\nself.feed = FirmwareFeed(url=self.feed_url)\n\n# setup table\nself.tableModel = FirmwareTableModel(self.feed, self.header, self)\ntable = self.firmwareTable\ntable.setModel(self.tableModel)\ntable.verticalHeader().hide()\ntable.horizontalHeader().setStretchLastSection(True)\ntable.horizontalHeader().setHighlightSections(False)\ntable.horizontalHeader().setResizeMode(QHeaderView.ResizeToContents)\n\n# set default selection\ntable.selectRow(0)\n\n# fun hack! but ... still a hack\n# create an anonymous object with functions for row/column\nqmi = type('', (), {'row':lambda s: 0, 'column':lambda s: 0})()\nself.updateSelection(qmi,0)\n\nself.splitter.setStretchFactor(1,4)", "path": "src\\mainwindow.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "\"\"\"\nCall this to add to the firmware list. Otherwise the tableView\nwill not update.\n\"\"\"\n# begin/end must be called\n", "func_signal": "def insertRows(self, row, count, parent = QtCore.QModelIndex()):\n", "code": "self.beginInsertRows(parent, row, row+count-1)\n# do action\nself.endInsertRows()\nreturn True", "path": "src\\BoPunk\\FirmwareTableModel.py", "repo_name": "elcritch/bopunk", "stars": 2, "license": "None", "language": "python", "size": 976}
{"docstring": "'''\n'''\n", "func_signal": "def parse_arguments(self):\n", "code": "(self.option_results, \n self.parser_arguments,) = self.argument_parser.parse_args()\n\nif self.option_results.gae_sdk_path:\n    self.settings['gae_sdk_path'] = os.path.abspath(\n        self.option_results.gae_sdk_path)\n\nif self.option_results.app_name:\n    self.settings['app_name'] = self.option_results.app_name\n\nif self.option_results.verbose:\n    self.settings['verbose'] = self.option_results.verbose\n\nif self.option_results.save_settings:\n    self.save_settings_to_file()\n\nif self.settings['app_name'] is None:\n    raise MissingAppNameError()", "path": "tools\\upload_app.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''Render the entire page, through a cascading series of calls to\nthis class and render listeners.\n'''\n\n# Make some fake data here, and pretend this came from plugins for now.\n", "func_signal": "def render(self):\n", "code": "fakedata = {\n    'spam_block_one':{\n        'block_title':'Spam Block One',\n        'block_content':'Look, I\\'m spam!',\n        'spam_index':0,\n        },\n    'spam_block_two':{\n        'block_title':'Spam Block Two',\n        'block_content':'Look, I\\'m spam!',\n        'spam_index':1,\n        },\n}\n\n# The db knows which block goes in what region. Here we fake it\nblock_region_assignments = {\n    'spam_block_one':'content',\n    'spam_block_two':'footer',\n}\n\n# Store each region's rendered results here so it can then be fed to\n# the page template.\nrendered_region_contents = {}\n\n# Store these locally for speed.\nblock_overrides_by_name = self.block_overrides_by_name\nblock_overrides_by_uri = self.block_overrides_by_uri\n\nfor block_name, region_name in block_region_assignments.items():\n    # Loop through each block and its assigned region.\n\n    if not rendered_region_contents.has_key(region_name):\n        # If the rendered_region_contents doesn't have the region_name\n        # key, we add a default value to it here. This way, later when\n        # it is added to, we don't have to check it there. Which will\n        # be checked more often than here.\n        \n        rendered_region_contents[region_name] = ''\n    \n    if block_overrides_by_name.has_key(block_name):\n        # Check if this region has a name-only match\n\n        for block_matched_by_name in block_overrides_by_name[\n            block_name]:\n            # Loop through all the overrides matching that name\n\n            if block_matched_by_name.uri_match is None:\n                # if the block has no uri_match, use it.\n\n                block_override = block_matched_by_name\n                break\n            elif (re.compile(block_matched_by_name.uri_match).\n                  match(ahhhh_im_not_real) is not None):\n                # If there is a url_match, and it matches the current\n                # url, use it.\n\n                block_override = block_matched_by_name\n                break\n    else:\n        # If we get here, there is no name matching the override, but\n        # there is a uri \n\n        for block_override_by_uri in block_overrides_by_uri:\n            # As slow as it is, here we have to loop through all of the\n            # uri_match strings to find the first one that matches.\n\n            # Create a regex pattern from the uri_match string.\n            # if there isn't one.. somehow... things are bad.\n            regex_pattern = re.compile(block_override_by_uri.uri_match)\n\n            if regex_pattern.match(ahhhh_im_not_real) is not None:\n                block_override = block_override_by_uri\n                break\n        else:\n            # If we loop through all the uri overrides and no match\n            # has been found (if one is found, the loop is broken), we\n            # then assign the block_override to the match-alloverride.\n            block_override = self.block_override_matching_all\n\n    # Create the block mako template\n    if block_override.template_file is not None:\n        block_template = mako.template.Template(\n            filename=block_override.template_file)\n    else:\n        block_template = mako.template.Template(\n            text=block_override.template_file)\n\n    # render the block template by exploding the dict into the\n    # function.\n    rendered_region_contents[region_name] += block_template.render(\n        **fakedata[block_name])\n\ntemplate = mako.template.Template(\n    filename='%s/base.html' % self.theme_rel_path)\nreturn template.render(\n    base_body='Nothing',\n    page_title='Rocket Seat CMS',\n    site_name='Dont crash me',\n    site_js='',\n    site_css=self.rendered_css_html,\n)", "path": "rocketseat\\core\\theme.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''\n'''\n# pickle the settings dict to the .upload_app_cfg file.\n", "func_signal": "def save_settings_to_file(self):\n", "code": "file_object = open('.upload_app_cfg', 'w')\ncPickle.dump(self.settings, file_object)\nfile_object.close()", "path": "tools\\upload_app.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''Initialize all of the plugins that are enabled.\n\nReturns: A dict of key:value pairs in the form of \nplugin_script_name:plugin.\n\nTodo: Optimize this.\n'''\n\n", "func_signal": "def initialize_plugins(bootstrap):\n", "code": "plugin_paths = bootstrap.enabled_plugin_paths\n\ndef import_and_init(plugin_path):\n    # Import the plugin module from the plugin path\n    plugin_module = __import__(plugin_path+'.plugin',\n                               fromlist=['a'])\n\n    # Return the plugin scriptname and an instance of the plugin\n    # as key value pairs.\n    plugin = plugin_module.Plugin(bootstrap)  \n    return (plugin.script_name, plugin)\n\nreturn dict(map(import_and_init, plugin_paths))", "path": "rocketseat\\core\\plugin.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''\n'''\n", "func_signal": "def __init__(self, theme_script_name):\n", "code": "self.theme_script_name = theme_script_name\n#self.core_event_controller = core_event_controller\n\nif os.path.exists('../user/themes/%s' % theme_script_name):\n    self.user_theme = True\n    self.theme_rel_path = '../user/themes/%s' % theme_script_name\n    self.theme_py_path = 'user.themes.%s' % theme_script_name\n    self.theme_static_uri = '/static/themes/user/%s' % theme_script_name\nelif os.path.exists('themes/%s' % theme_script_name):\n    self.user_theme = False\n    self.theme_rel_path = 'themes/%s' % theme_script_name\n    self.theme_py_path = 'core.themes.%s' % theme_script_name\n    self.theme_static_uri = '/static/themes/core/%s' % theme_script_name\nelse:\n    raise core.error.ThemeNotFoundError(theme_script_name)\n\n# Import the user theme module, and grab the settings from it.\ntheme_module = __import__('%s.theme' % self.theme_py_path,\n                          fromlist=['a'])\n\n#: A list of L{css file <CSSFile>} like objects.\nself.css_files = list(theme_module.css_files)\n#: A list of L{js file <JSFile>} like objects.\nself.js_files = list(theme_module.js_files)\n\nself._rendered_css_html = None\nself._rendered_js_html = None\nself._rendered_blocks_html = ''\n\n## Trigger the event, so other plugins can add to the css.\n#plugin_css = event_controller.call_listeners(\n    #'core_p', 'add_plugin_css')\n\n# To make sure atleast 1 handler works (and thus, avoiding a key error)\n# we append the generic, base, block, region, and page handlers to \n# theme module lists.\ntheme_module.bases.append(\n    BaseTemplateOverride(template_text=(\n        '<?xml version=\"1.0\" encoding=\"UTF-8\"?>'\n        '<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"'\n        '    \"DTD/xhtml1-strict.dtd\">'\n        '<html xmlns=\"http://www.w3.org/1999/xhtml\"'\n        '    xml:lang=\"en\" lang=\"en\">'\n        '<head>'\n        '    <title>${page_title} - ${site_name}</title>'\n        '    ${site_js}'\n        '    ${site_css}'\n        '</head>'\n        '<body>'\n        '    ${base_body}'\n        '</body>'\n        '</html>'\n    ))\n)\ntheme_module.blocks.append(\n    BlockTemplateOverride(template_text=(\n        '<div class=\"${block_css_classes}\">'\n        '    <h3>${block_title}</h3>'\n        '    <div>'\n        '        ${block_content}'\n        '    </div>'\n        '</div>'\n    ))\n)\ntheme_module.pages.append(\n    PageTemplateOverride(template_text=(\n        '<div class=\"container grid\">'\n        '    ${region_menu}'\n        '    <div class=\"\">'\n        '    </div>'\n        '</div>'\n    ))\n)\ntheme_module.regions.append(\n    RegionTemplateOverride(template_text=(\n        '<div class=\"${region_css_classes}\">'\n        '    ${blocks}'\n        '</div>'\n    ))\n)\n\n# For the sake of speed on cached loads, we will sort the overrides\n# on a few criteria now, so that later consecutive cached page loads\n# can benefit from this sorting. What we do is group types of overrides\n# based on what information they have to match the page load, and the\n# data loading.\n# \n# The following is the possible groups we will sort all the overrides\n# into:\n# - Overrides with only names (Direct Matches by Name)\n# - Overrides with only uri (Requires regex matching on every item,\n#   costly.)\n# - An override with no name or uri (Only the first instance of this\n#   will match, seeing as the first occurance will _always_ match, the\n#   following ones can be ignore.)\n\n# The keys are the uri regex string.\nbase_overrides_by_uri = {}\n# The first occurance of a \"match all\" override. All others ignored.\nbase_override_matching_all = None\nfor base in theme_module.bases:\n    if base.uri_match is not None:\n        base_overrides_by_uri[base.uri_match] = base\n    elif base_override_matching_all is None:\n        base_override_matching_all = base\n\nself.base_overrides_by_uri = base_overrides_by_uri\nself.base_override_matching_all = base_override_matching_all\n\n# The keys are the block names\nblock_overrides_by_name = {}\n# The keys are the block override's uri regex string\nblock_overrides_by_uri = {}\n# The first occurance of a \"match all\" override. All others are ignored.\nblock_override_matching_all = None\n\nfor block_override in theme_module.blocks:\n    if block_override.name is not None:\n        block_overrides_by_name[block_override.name] = block_override\n\n    elif block_override.uri_match is not None:\n        block_overrides_by_uri[\n            block_override.uri_match] = block_override\n\n    elif block_override_matching_all is None:\n        # If there is no match all block override, assign it now.\n        block_override_matching_all = block\n    # If the code path makes it here, it is a match all, but match\n    # all has already been assigned, so ignore it.\n# Now assign the built groups of block overrides into self.\nself.block_overrides_by_name = block_overrides_by_name\nself.block_overrides_by_uri = block_overrides_by_uri\nself.block_override_matching_all = block_override_matching_all\n\n# The keys are the uri regex string.\npage_overrides_by_uri = {}\n# The first occurance of a \"match all\" override. All others ignored.\npage_override_matching_all = None\nfor page in theme_module.pages:\n    if page.uri_match is not None:\n        page_overrides_by_uri[page.uri_match] = page\n\n    elif page_override_matching_all is None:\n        page_override_matching_all = page\n\nself.page_overrides_by_uri = page_overrides_by_uri\nself.page_override_matching_all = page_override_matching_all\n\n# The keys are the region names\nregion_overrides_by_name = {}\n# The keys are the region override's uri regex string\nregion_overrides_by_uri = {}\n# The first occurance of a \"match all\" override. All others are ignored.\nregion_override_matching_all = None\n\nfor region_override in theme_module.regions:\n    if region_override.name is not None:\n        region_overrides_by_name[region.name] = region_override\n\n    elif region.uri_match is not None:\n        region_overrides_by_uri[block.uri_match] = region_override\n\n    elif region_override_matching_all is None:\n        region_override_matching_all = region_override\n\nself.region_overrides_by_name = region_overrides_by_name\nself.region_overrides_by_uri = region_overrides_by_uri\nself.region_override_matching_all = region_override_matching_all", "path": "rocketseat\\core\\theme.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "''''''\n", "func_signal": "def __init__(self, plugin, bootstrap, *args, **kwargs):\n", "code": "super(PluginListeners, self).__init__(*args, **kwargs)\n\nself.plugin = plugin\nself.bootstrap = bootstrap", "path": "rocketseat\\core\\plugin.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''To allow WingIDE to catch rocketseat exceptions, run this function.\n'''\n\n", "func_signal": "def enable_debugger_catching():\n", "code": "logging.root.addHandler(WingIDEDebuggerExceptionHandler(\n    level=logging.ERROR))", "path": "rocketseat\\core\\lib\\ide_integration\\wingide.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''\n'''\n", "func_signal": "def get(self, uri_arguments=None):\n", "code": "uri_arguments = uri_arguments.split('/')\n\nif uri_arguments is None:\n    return\n\nif uri_arguments[0] == 'empty_memcache':\n    memcache.delete('page_bootstrap')", "path": "rocketseat\\core\\handler.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''\n'''\n", "func_signal": "def create_default_settings(self):\n", "code": "self.settings = {\n    'gae_sdk_path':None,\n    'app_name':None,\n    'verbose':False,\n}", "path": "tools\\upload_app.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''\n'''\n", "func_signal": "def load_settings_file(self):\n", "code": "if not os.path.exists('.upload_app_cfg'):\n    raise NoSettingsFileError()\n\nfile_object = open('.upload_app_cfg', 'r')\nself.settings = cPickle.load(file_object)\nfile_object.close()", "path": "tools\\upload_app.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''Call the except hook with the record's exception.\n'''\n\n", "func_signal": "def emit(self, record):\n", "code": "try:\n    etype, value, tb = record.exc_info\nexcept:\n    return\n\nsys.excepthook(etype, value, tb)", "path": "rocketseat\\core\\lib\\ide_integration\\wingide.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''Get self._rendered_css_html.\n'''\n", "func_signal": "def _get_rendered_css_html(self):\n", "code": "if self._rendered_css_html is None:\n    self._rendered_css_html = self.render_css_html()\nreturn self._rendered_css_html", "path": "rocketseat\\core\\theme.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "''''''\n", "func_signal": "def __init__(self, bootstrap, *args, **kwargs):\n", "code": "super(Plugin, self).__init__(*args, **kwargs)\n\nself.bootstrap = bootstrap\nself.listeners = None", "path": "rocketseat\\core\\plugin.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''Find the themes relative path\n\n@param theme_script_name: The script name of the theme.\n'''\n", "func_signal": "def find_theme_rel_path(theme_script_name):\n", "code": "if os.path.exists('../user/themes/%s' % theme_script_name):\n    return '../themes/%s' % theme_script_name\nelif os.path.exists('themes/%s' % theme_script_name):\n    return 'themes/%s' % theme_script_name\nelse:\n    raise core.error.ThemeNotFoundError(theme_script_name)", "path": "rocketseat\\core\\theme.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''\n'''\n", "func_signal": "def __init__(self, bootstrap):\n", "code": "super(Plugin, self).__init__(bootstrap)\n\nself.listeners = PluginListeners(self, bootstrap)", "path": "rocketseat\\core\\plugins\\block_spammer\\plugin.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''Return the mako template object for this \n'''\n# If template text is defined, use that.\n", "func_signal": "def get_template(self):\n", "code": "if self.template_text is not None:\n    return mako.template.Template(\n        text=self.template_text)\n\n# If we make it here, no template text was defined.. and there\n# _better_ be a template file... or all hell breaks loose.\nreturn mako.template.Template(\n    text=self.template_text)", "path": "rocketseat\\core\\theme.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''Get self._rendered_js_html.\n'''\n", "func_signal": "def _get_rendered_js_html(self):\n", "code": "if self._rendered_js_html is None:\n    self._rendered_js_html = self.render_js_html()\nreturn self._rendered_js_html", "path": "rocketseat\\core\\theme.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''Find the themes absolute path, as found by os.path.abspath()\n\n@param theme_script_name: The script name of the theme.\n'''\n", "func_signal": "def find_theme_abs_path(theme_script_name):\n", "code": "if os.path.exists('../user/themes/%s' % theme_script_name):\n    return os.path.abspath('../themes/%s' % theme_script_name)\nelif os.path.exists('themes/%s' % theme_script_name):\n    return os.path.abspath('themes/%s' % theme_script_name)\nelse:\n    raise core.error.ThemeNotFoundError(theme_script_name)", "path": "rocketseat\\core\\theme.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''\n@param base_theme_static_uri: If supplied, the uri for the css file\nwill have this inserted before it.\n'''\n", "func_signal": "def render_html(self, base_theme_static_uri=None):\n", "code": "if base_theme_static_uri is not None:\n    if not self.ie_only:\n        return '''<link rel=\"stylesheet\"\n        href=\"%s/%s\" type=\"text/css\"\n        media=\"%s\" />''' % (base_theme_static_uri,\n                            self.file_location,\n                            self.media)\n    else:\n        return '''<!--[if IE]><link rel=\"stylesheet\"\n        href=\"%s/%s\" type=\"text/css\"\n        media=\"%s\" /><![endif]-->''' % (base_theme_static_uri,\n                                        self.file_location,\n                                        self.media)", "path": "rocketseat\\core\\theme.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "'''\n'''\n", "func_signal": "def __init__(self, app_name, gae_sdk_path=None, verbose=False):\n", "code": "super(AppUploader, self).__init__()\n\nself.app_name = app_name\nself.gae_sdk_path = gae_sdk_path\nself.verbose = verbose\n\nif gae_sdk_path is not None:\n    sys.path.append(gae_sdk_path)\n\ntry:\n    import google\nexcept ImportError:\n    raise MissingAppEngineLibraryError()", "path": "tools\\lib\\upload.py", "repo_name": "leeola/rocket-seat", "stars": 3, "license": "None", "language": "python", "size": 133}
{"docstring": "\"\"\"Retrieve the value associated with 'key' (in any case).\"\"\"\n", "func_signal": "def __getitem__(self, key):\n", "code": "key = self.__normalize(key)\nreturn super(WWWInsensitiveDefaultDict, self).__getitem__(key)", "path": "web\\client\\util.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\nSets all URL parts, providing sensible defaults.\n\nNot a user function.\n\"\"\"\n", "func_signal": "def __setParts(self):\n", "code": "parts = self.getRawParts()\nself.scheme = parts.scheme or 'http'\nself.path = parts.path or '/'\nself.port = parts.port\nif not self.port:\n    if self.scheme == 'http':\n        self.port = 80\n    else:\n        self.port = 443\nself.netloc, self.query, self.fragment = parts.netloc, parts.query, parts.fragment\nself.hostname = self.netloc", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\nHandles all other errbacks.\n\"\"\"\n", "func_signal": "def __handleErrback(self, e, d):\n", "code": "if d:\n    d.errback(e)\nelse:\n    return self.agent.handleError(e)", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\nChecks if the supplied URI has the same domain scope as ours\n\n@param uri: the URI to check\n@type uri: L{Uri}\n\n@returns C{bool}\n\"\"\"\n", "func_signal": "def isDomainScope(self, uri):\n", "code": "result = False\nif uri:\n    # media.archive.org should give archive.org\n    d1 = self.hostname.replace('www', '')\n    d2 = d1.split('.')\n    # Base domain is entire domain without www.\n    baseDomain = d1\n    # audio.archive.org\n    # NOTE: hostname can be None http://docs.python.org/lib/module-urlparse.html\n    otherDomain = uri.hostname and uri.hostname or ''\n    # audio.archive.org is a sub-domain of archive.org?\n    result = otherDomain.endswith(baseDomain)\nreturn result", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\n@param request: The request to send to a remote server.\n@type request: L{ClientRequest}\n\n@param closeAfter: If True the 'Connection: close' header will be sent,\n    otherwise 'Connection: keep-alive'\n@type closeAfter: C{bool}\n\n@rtype: L{twisted.internet.defer.Deferred}\n@return: A Deferred which will be called back with the\n    L{twisted.web2.http.Response} from the server.\n\"\"\"\n\n# Assert we're in a valid state to submit more\n", "func_signal": "def submitRequest(self, request, closeAfter=True):\n", "code": "assert self.outRequest is None\nassert ((self.readPersistent is PERSIST_NO_PIPELINE\n         and not self.inRequests)\n        or self.readPersistent is PERSIST_PIPELINE), (self, request.uri.url, closeAfter, request.closeAfter)\n        \nself.manager.clientBusy(self)\nif closeAfter:\n    self.readPersistent = False\n    \nself.outRequest = chanRequest = HTTPClientChannelRequest(self,\n                                    request, closeAfter)\nself.inRequests.append(chanRequest)\n\nchanRequest.submit()", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\nChecks if the supplied URI has the same path scope as ours\n\n@param uri: the URI to check\n@type uri: L{Uri}\n\n@returns C{bool}\n\"\"\"\n", "func_signal": "def isPathScope(self, uri):\n", "code": "result = False\nif uri:\n    # http://members.aol.com/~bigbird/ should give members.aol.com/~bigbird\n    basePath = self.netloc + os.path.split(self.path)[0]\n    # http://members.aol.com/~bigbird/profile should give members.aol.com/~bigbird/profile\n    otherPath = uri.netloc + uri.path\n    # members.aol.com/~bigbird/profile comes from same folder as members.aol.com/~bigbird ?\n    result = otherPath.startswith(basePath)\nreturn result", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\nAbort parsing, and depending of the status of the request, either fire\nthe C{responseDefer} if no response has been sent yet, or close the\nstream.\n\"\"\"\n", "func_signal": "def _error(self, err):\n", "code": "self.abortParse()\nif hasattr(self, 'request') and self.request.protocol is not None:\n    self.request.protocol.connectionLost(Failure(CONNECTION_LOST))\nelse:\n    self.responseDefer.errback(err)", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\nThe wonderful handling of possible redirects is done here, for lack\nof a place that makes more sense to me.\n\"\"\"\n", "func_signal": "def __handlePossibleRedirect(self, response, d):\n", "code": "request = response.request\n    \nif response.code in (MOVED_PERMANENTLY,FOUND):\n    # Only auto-handle redirect for GET and POST, per RFC 2616\n    if (request.method in ('GET','POST') and \n        response.headers.hasHeader('Location')):\n        if request.numRedirects < self.maxRedirects:\n            loc = response.headers.getRawHeaders('Location')[0]\n            request.redirect(loc)\n            request.protocol.deferred = Deferred()\n            self.submitRequest(request, d)\n        else:\n            d.errback(RedirectLimitExceededError(request.redirects[-1]))\n    else:\n        d.callback(response)\nelse:\n    d.callback(response)", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\nWe are finished writing data.\n\"\"\"\n", "func_signal": "def loseConnection(self):\n", "code": "if self.chunkedOut:\n    # write last chunk and closing CRLF\n    self.transport.write(\"0\\r\\n\\r\\n\")\n    \nself.finished = True\nself.channel.requestWriteFinished(self)\ndel self.transport", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\nQueued requests can be 'forgotten' if requests for a host do not\nfinish properly. When this happens the queues need to be rotated\nsuch that requests are forced into 'open' mode.\n\n@type host: c{str}\n@param host: An optional host queue to rotate. If no host is\n    provided all queues are rotated.\n\n\"\"\"\n", "func_signal": "def rotateQueue(self, host=None):\n", "code": "def rotateThese(hosts):\n    maxRunnable = self.maxConcurrent - self.runCount()\n    if maxRunnable <= 0: return False\n    rotated = False            \n    for host in hosts:\n        host = host.replace('www.','').strip()\n        for x in xrange(0, len(self.queue[host].pending)):\n            if maxRunnable > 0:\n                d = self.queue[host].get()\n                d.addCallback(self.createClientChannel)\n                d.addErrback(self.__handleConnErrback)\n                maxRunnable -= 1\n            rotated = True\n    return rotated\n\nif host:\n    return rotateThese([host])\nelse:\n    return rotateThese(self.queue.keys())", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\n@param code: The HTTP status code for this Response\n@type code: C{int}\n\n@param headers: Headers to be sent to the client.\n@type headers: C{dict}, L{twisted.web2.http_headers.Headers}, or \n    C{None}\n\n@param data: Content body received\n@type data: C{str} or similar\n\"\"\"\n\n", "func_signal": "def __init__(self, code=None, headers=None, data=None):\n", "code": "if code is not None:\n    self.code = int(code)\n    \nif headers is not None:\n    if isinstance(headers, dict):\n        headers = Headers(headers)\n    self.headers=headers\nelse:\n    self.headers = Headers()\n    \nself.data = data", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\nResets a queue of requests.\n\n@type host: c{str}\n@param host: An option host queue to reset. If no host is provided\n    the entire queue is reset.\n\"\"\"\n", "func_signal": "def resetQueue(self, host=None):\n", "code": "def dq(): return DeferredQueue(self.maxQueued, self.maxBacklog)\nif not host:\n    self.queue = WWWInsensitiveDefaultDict(dq)\nelse:\n    self.queue[host] = dq()", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"docstring for __init__\"\"\"\n", "func_signal": "def __init__(self, maxQueued=None, maxBacklog=None, maxConcurrent=15):\n", "code": "self.maxQueued = maxQueued\nself.maxBacklog = maxBacklog\nself.maxConcurrent = maxConcurrent\nself.resetQueue()", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\nCreates the actual channel for the request.\n\n@param request: The request\n@type request: L{ClientRequest}\n\"\"\"\n", "func_signal": "def createClientChannel(self, request):\n", "code": "c = ClientCreator(reactor, self.clientChannel, self)\nif request.uri.scheme == 'http':\n    d = c.connectTCP(host=request.uri.netloc, port=request.uri.port)\nelse:\n    d = c.connectSSL(host=request.uri.netloc, port=request.uri.port,\n        contextFactory=ssl.ClientContextFactory())\npending = PendingChannel()\npending.host = request.uri.getHost()\nif request.closeAfter:\n    pending.readPersistent = False\nself.pendingChannels.add(pending)\nd.addCallback(self.__request, request, pending)\nd.addErrback(self.__handleConnErrback, request, pending)", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\nReturns a hash of our URL, adding some normalization\n\"\"\"\n", "func_signal": "def getHash(self):\n", "code": "url = self.url\nif url[-1] == '/':\n    url = url[0:-1]\n# technically, www/non-www can be different, but this is never the \n# case\nshash = hash(url.replace('www.', ''))\nreturn shash", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"docstring for redirect\"\"\"\n", "func_signal": "def redirect(self, location):\n", "code": "curHost = self.uri.getHost()\nself.redirects.append(self.uri)\nself.uri.setUrl(location)\nif not self.uri.netloc:\n    self.uri.netloc, self.uri.hostname = (curHost, curHost)\nself.numRedirects += 1", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\n@param method: The HTTP method to for this request, ex: 'GET', 'HEAD',\n    'POST', etc.\n@type method: C{str}\n\n@param uri: The URI of the resource to request, this may be absolute or\n    relative, however the interpretation of this URI is left up to the\n    remote server.\n@type uri: C{str}\n\n@param headers: Headers to be sent to the server.  It is important to\n    note that this object does not create any implicit headers.  So it\n    is up to the HTTP Client to add required headers such as 'Host'.\n@type headers: C{dict}, L{twisted.web2.http_headers.Headers}, or\n    C{None}\n    \n@param protocol: Protocol to manage writing request data and reading\n    response data\n@type protocol: L{twisted.internet.protocol.Protocol} derivative\n\n@param protocol: Indicates that we would like the connection to be\n    closed following this request.\n@type protocol: C{bool}\n\"\"\"\n\n", "func_signal": "def __init__(self, method, uri, protocol, headers=None, closeAfter=True):\n", "code": "self.method = method\nself.uri = uri\nself.closeAfter = closeAfter\nif isinstance(headers, Headers):\n    self.headers = headers\nelse:\n    self.headers = Headers(headers or {})\n    \nif protocol is not None:\n    self.protocol = protocol\nelse:\n    raise RuntimeError(\"You must provide a protocol for the request!\")", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\nDetermines if a request should be queued or made immediately.\n\nA Request should be queued for the following reasons:\n\n    1.  If PERSISTENT and no channel accepting requests\n    2.  If C{maxConcurrent} reached\n    \nC{persistQueueThreshold}\n\n@type request: C{str}\n@param request: L{ClientRequest}\n\"\"\"\n", "func_signal": "def shouldQueue(self, request):\n", "code": "allChannels = self.openChannels.union(self.pendingChannels)\nif self.runCount() >= self.maxConcurrent:\n    return True\n# Connection will persist\nif not request.closeAfter:\n    pCount = 0\n    for chan in allChannels:\n        if chan.host == request.uri.getHost() and chan.readPersistent:\n            pCount += 1\n    # Max concurrent persistent connections for host met\n    if pCount >= 2:\n        # Set to non-persist if threshold met\n        if (self.persistQueueThreshold != 0 and\n        self.queueCount(request.uri.getHost()) >=\n        self.persistQueueThreshold):\n            request.closeAfter = True\n            return False\n        else:\n            return True\nreturn False", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"docstring for test_setUri\"\"\"\n", "func_signal": "def test_setUri(self):\n", "code": "uri = Uri('http://test.com')\nself.assertEquals(uri.url, 'http://test.com')\nself.assertEquals(uri.path, '/')\nself.assertEquals(uri.scheme, 'http')\nself.assertEquals(uri.port, 80)\nself.assertEquals(uri.netloc, 'test.com')\nself.assertEquals(uri.query, '')\nself.assertEquals(uri.fragment, '')\nuri.setUrl('http://test.com:88/path?arg=1')\nself.assertEquals(uri.url, 'http://test.com:88/path/')", "path": "web\\test\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "\"\"\"\nChecks if the supplied URI has the same domain as ours\n\n@param uri: the URI to join\n@type uri: L{Uri}\n\n@returns C{bool}\n\"\"\"\n", "func_signal": "def isSameDomain(self, uri):\n", "code": "result = False\nif uri != None:\n    # Match base urls, most of the time we should get if they are from same domain here\n    result = (self.domainUrl.lower() == uri.domainUrl.lower())                \nreturn result", "path": "web\\client\\http.py", "repo_name": "tdavis/tangled", "stars": 3, "license": "mit", "language": "python", "size": 112}
{"docstring": "# jezeli rekord o podanym id istnieje to stworz ChangeManipulator\n", "func_signal": "def edit_nauczyciel(request, user_id):\n", "code": " try:\n     manipulator = User.ChangeManipulator(user_id)\n except User.DoesNotExist:\n     raise Http404\n\n # Pobieramy oryginalne dane\n osoba = manipulator.original_object\n\n if request.POST:\n     new_data = request.POST.copy()\n     errors = manipulator.get_validation_errors(new_data)\n     if not errors:\n         manipulator.do_html2python(new_data)\n         manipulator.save(new_data)\n\n         # przekierowanie\n         return HttpResponseRedirect(\"/Lista nauczycieli/\")\n else:\n     errors = {}\n     # Dzieki temu formularz poprawnie rozpozna dane dla kazdego pola\n     new_data = osoba.__dict__\n\n form = forms.FormWrapper(manipulator, new_data, errors)\n return render_to_response('forms.html', {'form': form, 'osoba': osoba,'tytul': 'Edycja nauczycieli'})", "path": "e_dziennik\\views_copy.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "# jezeli rekord o podanym id istnieje to stworz ChangeManipulator\n", "func_signal": "def edit_nauczyciel(request, user_id):\n", "code": " try:\n     manipulator = User.ChangeManipulator(user_id)\n except User.DoesNotExist:\n     raise Http404\n\n # Pobieramy oryginalne dane\n osoba = manipulator.original_object\n\n if request.POST:\n     new_data = request.POST.copy()\n     errors = manipulator.get_validation_errors(new_data)\n     if not errors:\n         manipulator.do_html2python(new_data)\n         manipulator.save(new_data)\n\n         # przekierowanie\n         return HttpResponseRedirect(\"/Lista nauczycieli/\")\n else:\n     errors = {}\n     # Dzieki temu formularz poprawnie rozpozna dane dla kazdego pola\n     new_data = osoba.__dict__\n\n form = forms.FormWrapper(manipulator, new_data, errors)\n return render_to_response('forms.html', {'form': form, 'osoba': osoba,'tytul': 'Edycja nauczycieli'})", "path": "e_dziennik\\views_old.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "\"\"\"override save to set defaults\"\"\"\n", "func_signal": "def save(self, **kwargs):\n", "code": "if self.pk:\n\tself.onsitedata = datetime.now()\nsuper(Profile, self).save(**kwargs)", "path": "userpanel\\models.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "\"\"\"\nmain user panel\n\"\"\"\n", "func_signal": "def user_panel(request,header):\n", "code": "from django.conf import settings\nadmin_mail = settings.SERVER_EMAIL \nif not request.user.is_authenticated():\n\treturn HttpResponseRedirect(\"/user/login/\")\nreturn render_to_response('userpanel/panel.html', {'header':header,'admin_mail':admin_mail},context_instance=RequestContext(request))", "path": "userpanel\\views.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "\"\"\"\nlist of topics in a forum\n\n* forum_id - id of a Forum record\n\"\"\"\n", "func_signal": "def topic_list(request, forum_id, pagination_id=1):\n", "code": "try:\n\ttopics = Topic.objects.order_by('-is_global', '-is_sticky', '-topic_modification_date').filter(Q(topic_forum=forum_id) | Q(is_global='1'))\n\tforum_name = Forum.objects.get(id=forum_id)\n\tforum_name = forum_name.forum_name\nexcept:\n\treturn HttpResponseRedirect('/forum/')\nreturn object_list(\n\trequest,\n\tTopic.objects.order_by('-is_global', '-is_sticky', '-topic_modification_date').filter(Q(topic_forum=forum_id) | Q(is_global='1')),\n\tpaginate_by = 10,\n\tallow_empty = True,\n\tpage = pagination_id,\n\textra_context = {'forum': forum_id,'header':header,  'perms': list_perms(request), 'forum_name': forum_name},\n\ttemplate_name = 'myghtyboard/topics_list.html')", "path": "myghtyboard\\views.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "'''Tworzy konto rodzica w modelu User,oraz konto ucznia w modelu Uczniowie'''\n", "func_signal": "def dodaj_rodzica(request,klasa_id,klucz,uczen_id,rodzic=None):\n", "code": "if not request.user.is_authenticated():return HttpResponseRedirect('/')\nmanipulator = User.AddManipulator()\nform1 = UserExist()\nif request.POST:\n        new_data = request.POST.copy()\n        if new_data.has_key('rodzic'): # wybierz istniejace konto\n                grupy('add',new_data['rodzic'],4) # 4-Rodzice\n                rodzic = new_data['rodzic']\n        else:\n                new_data['groups']=4\n                errors = manipulator.get_validation_errors(new_data)\n\n                if not errors:\n                        from django.core.mail import EmailMultiAlternatives\n                        #Wyslanie e-maila z danymi do opiekuna\n                        subject = 'Wiadomo\u015b\u0107 z systemu e-dziennik.'\n                        from_email = request.user.email\n                        to = new_data['email']\n                        text_content = 'Witaj' + new_data['first_name'] + new_data['last_name'] + 'Twoje dane w systemie e-dziennik: login:' + new_data['username'] + 'password:' + new_data['password']\n                        html_content = 'Witaj<b>' + ' ' +new_data['first_name'] + ' ' + new_data['last_name'] + '</b><br><br>Twoje dane w systemie e-dziennik:<br><br>login:<b>' + ' ' + new_data['username'] + '</b><br>password:<b>' + ' ' + new_data['password'] + '</b>'\n                        msg = EmailMultiAlternatives(subject, text_content, from_email, [to])\n                        msg.attach_alternative(html_content, \"text/html\")\n                        msg.send()\n                        u = User()\n                        new_data['password'] = u.set_password(new_data['password'])\n                        manipulator.do_html2python(new_data)\n                        new_r = manipulator.save(new_data)\n                        r = User.objects.get(username = new_data['username'])\n                        rodzic = r.id\n                        u = Uczniowie_tmp.objects.get(id = uczen_id)\n                        #Profil\n                        new_profile = UczenProfile(uczen=u,rodzic_id=rodzic,klasa=u.klasa)\n                        new_profile.save()\n                        return render_to_response('info.html',{'tresc':'''Na podany przy rejestracji e-mail zosta\u0142a\n                                wys\u0142ana wiadomo\u015b\u0107 z loginem i has\u0142em do systemu''',\n                                'back':'/'+klasa_id+'/Lista uczniow/'},context_instance=RequestContext(request))\n                        #return HttpResponseRedirect('/'+klasa_id+'/Lista uczniow/')                  \nelse:  \n        errors = new_data = {}\nform = oldforms.FormWrapper(manipulator,new_data,errors)\nklucz = ''.join(klucz.split())\nu = Uczniowie_tmp.objects.get(id=uczen_id)\nfull_name = u.get_full_name()\nreturn render_to_response('forms_wych.html',{klucz: form,'user_exist':form1,'tytul': 'Dodaj','header': 'Dodaj opiekuna','klasa':klasa_id,\n                                             'dane_ucznia':full_name,},context_instance=RequestContext(request))", "path": "e_dziennik\\wych.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "\"\"\"Zwraca liste odbiorcow wiadomosci i e-maili\"\"\"\n\n", "func_signal": "def get_odbiorcy(klasa_id,send,all_n=('',[]),all_r=('',[])):\n", "code": "n = User.objects.filter(przedmioty__klasa=klasa_id).distinct() #nauczyciele w danej klasie\nr = User.objects.filter(uczenprofile__klasa=klasa_id).distinct()  #rodzice w danej klasie\n# e-mail\nif len(n)!=0 and send=='email':all_n = ('\\n',[(','.join([i.email for i in n]),'--wszyscy nauczyciele--')])\nif len(r)!=0 and send=='email':all_r = ('\\n',[(','.join([i.email for i in r]),'--wszyscy rodzice--')])\n# message\nif len(n)!=0 and send=='msg':all_n = ('\\n',[([int(i.id) for i in n],'--wszyscy nauczyciele--')])\nif len(r)!=0 and send=='msg':all_r = ('\\n',[([int(i.id )for i in r],'--wszyscy rodzice--')])\nodbiorcy = (('Nauczyciele',[(i.id,i.first_name+' '+i.last_name) for i in n]),all_n,\n            ('Rodzice',[(i.id,i.first_name+' '+i.last_name) for i in r]),all_r)\nreturn odbiorcy", "path": "e_dziennik\\all.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "\"\"\"Delete event(s).  Return a list of event(s) deleted\"\"\"\n", "func_signal": "def delEvent(self, day, time):\n", "code": "result = self.getEvents(day, time)\nfor e in result:\n    self.events[day].remove(e)\nif not self.events[day]:\n    del self.events[day]\nreturn result", "path": "cal\\eventCalBase.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "\"\"\"\nlist all users\n\"\"\"\n", "func_signal": "def userlist(request,header):\n", "code": "users = User.objects.all()\nreturn object_list(request, users, extra_context={'header':header},paginate_by = 25, allow_empty = True, template_name = 'userpanel/userlist.html')", "path": "userpanel\\views.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "# jezeli rekord o podanym id istnieje to stworz ChangeManipulator\n", "func_signal": "def edit_nauczyciel(request, user_id):\n", "code": " try:\n     manipulator = User.ChangeManipulator(user_id)\n except User.DoesNotExist:\n     raise Http404\n\n # Pobieramy oryginalne dane\n osoba = manipulator.original_object\n\n if request.POST:\n     new_data = request.POST.copy()\n     errors = manipulator.get_validation_errors(new_data)\n     if not errors:\n         manipulator.do_html2python(new_data)\n         manipulator.save(new_data)\n\n         # przekierowanie\n         return HttpResponseRedirect(\"/Lista nauczycieli/\")\n else:\n     errors = {}\n     # Dzieki temu formularz poprawnie rozpozna dane dla kazdego pola\n     new_data = osoba.__dict__\n\n form = forms.FormWrapper(manipulator, new_data, errors)\n return render_to_response('forms_admin.html', {'form': form, 'osoba': osoba,'tytul': 'Edycja nauczycieli'})", "path": "e_dziennik\\admin.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "\"\"\"Wysylanie wiadomosci za pomoca modelu Message oraz newforms(form_for_model)\"\"\"\n", "func_signal": "def message_send(request,klasa_id,header,error=False):\n", "code": "if request.user.is_authenticated() :\n        if request.user.has_perm('e_dziennik.add_wiadomosci'):\n                MessageForm = form_for_model(Wiadomosci)\n                form = MessageForm()\n                form.fields['user'] = forms.GroupedChoiceField(choices=get_odbiorcy(klasa_id,'msg'))\n                if request.method == 'POST':\n                        new_data = request.POST.copy()\n                        new_data['user']= new_data['user'].strip('[]').split(',')[0]\n                        new_data['sender']=request.user.get_full_name()\n                        form = MessageForm(new_data)\n                        if form.is_valid():\n                                if new_data.has_key('sms'):\n                                        #wyslanie sms-a\n                                        import sms_orangembox\n                                        from sms_orangembox import *\n                                        phones=[]\n                                        for e in request.POST['user'].strip('[]').split(','):\n                                                u = User.objects.get(id = e)\n                                                if u.mobile_phone != None:phones.append(u.mobile_phone)\n                                        if len(phones)==0:error=True\n                                        else:\n                                                for n in phones:sendsms(new_data['sender'],str(n),new_data['message'])\n                                else:\n                                        #wyslanie wiadomosci\n                                        new_msg=form.save(commit=False)\n                                        new_msg.multi_msg(request.POST['user'].strip('[]').split(','))\n                                return render_to_response('msg/message_send_done.html',{'path':request.path,'error':error},\n                                                          context_instance=RequestContext(request))\n                        else:\n                                form.fields['user'] = forms.GroupedChoiceField(choices=get_odbiorcy(klasa_id,'msg'))\n                                return render_to_response('msg/message_send_form.html',\n                                                          {'f':form},context_instance=RequestContext(request))\n                else:\n                        return render_to_response('msg/message_send_form.html',{'f':form,'header':header},\n                                                  context_instance=RequestContext(request))\n        else:\n                #raise Http404\n                return HttpResponseRedirect('/perm/wiadomosci/')            \nelse: return HttpResponseRedirect(\"/\")", "path": "e_dziennik\\all.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "\"\"\"\nEmail-Messages sending\n\"\"\"\n", "func_signal": "def send_pmessage(request, target_user,header):\n", "code": "if request.user.is_authenticated() and str(request.user) != str(target_user) and len(str(target_user)) > 0 and str(target_user) != 'AnonymousUser':\n\truser = User.objects.get(username=str(target_user))\n\n\tmanipulator = PMessage()\n\tif request.POST:\n\t\tnew_data = request.POST.copy()\n\t\terrors = manipulator.get_validation_errors(new_data)\n\t\tif not errors:\n\t\t\tmanipulator.do_html2python(new_data)\n\t\t\tsend_mail(new_data['subject'], new_data['contents'], request.user.email, [ruser.email], fail_silently=False)\n\t\t\treturn HttpResponseRedirect(\"/user/\")\n\telse:\n\t\terrors = new_data = {}\n\tform = forms.FormWrapper(manipulator, new_data, errors)\n\treturn render_to_response('userpanel/pmessage.html', {'form': form,'header':header}, context_instance=RequestContext(request))\nelse:\n\treturn HttpResponseRedirect(\"/user/\")", "path": "userpanel\\views.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "\"\"\"add event to day.  'event' is expected to support interface\n    of event()\"\"\"\n", "func_signal": "def addEvent(self, event, day=datetime.datetime.now().day):\n", "code": "nevent = copy.deepcopy(event)\nif self.checkYMD(1, 1, day):\n    if day in self.events:\n        self.events[day].append(nevent)\n    else:\n        self.events[day] = [nevent]\n\n    # adjust date of nevent\n    date = self.getDate(day)\n    self.events[day][-1].setStart(\n            datetime.datetime.combine(date, nevent.getStart().time()))\n    # finally, sort events for 'day'\n    self.events[day].sort()", "path": "cal\\eventCalBase.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "# Note: self.desc is not compared\n", "func_signal": "def __eq__(self, other):\n", "code": "result = False\ntry:\n   result = self.id == other.id\nexcept:\n    pass\nreturn result", "path": "cal\\eventCalBase.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "\"\"\"check True if data supports datetime.datetime interface, False\n    otherwise\"\"\"\n", "func_signal": "def checkDate(self, data):\n", "code": "try:\n    for attr in ['year', 'month', 'day', 'hour', 'minute', 'second']:\n        getattr(data, attr)\nexcept AttributeError: \n    return False\nreturn True\n\ndatetime.date(year, month, day)\nreturn True", "path": "cal\\eventCalBase.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "\"\"\"check range of year, month and day.  Raise ValueError on error.\n    Return True otherwise\"\"\"\n", "func_signal": "def checkYMD(self, year, month, day):\n", "code": "datetime.date(year, month, day)\nreturn True", "path": "cal\\eventCalBase.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "\"\"\"override save to set defaults\"\"\"\n", "func_signal": "def save(self, **kwargs):\n", "code": "if self.pk:\n\tself.topic_modification_date = datetime.now()\nsuper(Topic, self).save(**kwargs)", "path": "myghtyboard\\models.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "\"\"\"Return all events for 'day', default as today\"\"\"\n", "func_signal": "def getDailyEvents(self, day=datetime.datetime.now().day):\n", "code": "result = []\nif day in self.events:\n    result = self.events[day]\nreturn result", "path": "cal\\eventCalBase.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "#u = User.objects.create_user(username='jaro',password='szakal',email='lennon@thebeatles.com')\n#u.save()\n", "func_signal": "def check_login(request,login):\n", "code": "user = User.objects.filter(username=login)\nif user:return HttpResponse('exist')\n#if user:return HttpResponse(\"<font face=arial size=1 color='blue'>Podany login ju\u017c istnieje,prosz\u0119 wybra\u0107 inny.</font>\")\n#return HttpResponse(\"<font face=arial size=1 color='green'>Login jest dost\u0119pny.</font>\")\nreturn HttpResponse('ok')", "path": "e_dziennik\\wych.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "\"\"\"\nParse emotes, BBcode and format [code] blocks\n\"\"\"\n", "func_signal": "def fbc(value):\n", "code": "value = value.replace(':omg:', '<img src=\"/site_media/forum/smilies/icon_eek.gif\" alt=\"\" />')\nvalue = value.replace(':nice:', '<img src=\"/site_media/forum/smilies/icon_biggrin.gif\" alt=\"\" />')\nvalue = value.replace(':evil:', '<img src=\"/site_media/forum/smilies/icon_evil.gif\" alt=\"\" />')\nvalue = value.replace(':twisted:', '<img src=\"/site_media/forum/smilies/icon_twisted.gif\" alt=\"\" />')\nvalue = value.replace(':grin:', '<img src=\"/site_media/forum/smilies/icon_cheesygrin.gif\" alt=\"\" />')\nvalue = value.replace(':cool:', '<img src=\"/site_media/forum/smilies/icon_cool.gif\" alt=\"\" />')\nvalue = value.replace('[b]', '<b>')\nvalue = value.replace('[/b]', '</b>')\nvalue = value.replace('[i]', '<i>')\nvalue = value.replace('[/i]', '</i>')\nvalue = value.replace('[u]', '<u>')\nvalue = value.replace('[/u]', '</u>')\nvalue = value.replace('[quote]', '<blockquote>')\nvalue = value.replace('[/quote]', '</blockquote>')\nvalue = value.replace('[url]', '')\nvalue = value.replace('[/url]', '')\n\nvalue = value.replace('\\n', '<br />')\ntags = findall( r'(?xs)\\[code\\](.*?)\\[/code]''', value)\nfor i in tags:\n\tj = i.replace('<br />', '')\n\tvalue = value.replace('[code]' + i + '[/code]', '<div class=\"box\" style=\"overflow:auto;font-size:10px;background-color:#EEEEEE;\">' + highlight(j, HtmlLexer(), HtmlFormatter()) + '</div><style>' + HtmlFormatter().get_style_defs('.highlight') + '</style>')\nreturn value", "path": "boxcomments\\templatetags\\fbc.py", "repo_name": "wrabbit/skibi", "stars": 2, "license": "None", "language": "python", "size": 1480}
{"docstring": "\"\"\"\nTest that ``RegistrationForm`` enforces username constraints\nand matching passwords.\n\n\"\"\"\n", "func_signal": "def test_registration_form(self):\n", "code": "invalid_data_dicts = [\n    # Non-alphanumeric username.\n    {\n    'data':\n    { 'username': 'foo/bar',\n      'email': 'foo@example.com',\n      'password1': 'foo',\n      'password2': 'foo' },\n    'error':\n    ('username', [u\"Enter a valid value.\"])\n    },\n    # Already-existing username.\n    {\n    'data':\n    { 'username': 'alice',\n      'email': 'alice@example.com',\n      'password1': 'secret',\n      'password2': 'secret' },\n    'error':\n    ('username', [u\"This username is already taken. Please choose another.\"])\n    },\n    # Mismatched passwords.\n    {\n    'data':\n    { 'username': 'foo',\n      'email': 'foo@example.com',\n      'password1': 'foo',\n      'password2': 'bar' },\n    'error':\n    ('__all__', [u\"You must type the same password each time\"])\n    },\n    ]\n\nfor invalid_dict in invalid_data_dicts:\n    form = forms.RegistrationForm(data=invalid_dict['data'])\n    self.failIf(form.is_valid())\n    self.assertEqual(form.errors[invalid_dict['error'][0]], invalid_dict['error'][1])\n\nform = forms.RegistrationForm(data={ 'username': 'foo',\n                                     'email': 'foo@example.com',\n                                     'password1': 'foo',\n                                     'password2': 'foo' })\nself.failUnless(form.is_valid())", "path": "registration\\tests.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nTest that the registration view rejects invalid submissions,\nand creates a new user and redirects after a valid submission.\n\n\"\"\"\n# Invalid data fails.\n", "func_signal": "def test_registration_view(self):\n", "code": "response = self.client.post(reverse('registration_register'),\n                            data={ 'username': 'alice', # Will fail on username uniqueness.\n                                   'email': 'foo@example.com',\n                                   'password1': 'foo',\n                                   'password2': 'foo' })\nself.assertEqual(response.status_code, 200)\nself.failUnless(response.context['form'])\nself.failUnless(response.context['form'].errors)\n\nresponse = self.client.post(reverse('registration_register'),\n                            data={ 'username': 'foo',\n                                   'email': 'foo@example.com',\n                                   'password1': 'foo',\n                                   'password2': 'foo' })\nself.assertEqual(response.status_code, 302)\nself.assertEqual(response['Location'], 'http://testserver%s' % reverse('registration_complete'))\nself.assertEqual(RegistrationProfile.objects.count(), 3)", "path": "registration\\tests.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nPerform Akismet validation of the message.\n\n\"\"\"\n", "func_signal": "def clean_body(self):\n", "code": "if 'body' in self.cleaned_data and getattr(settings, 'AKISMET_API_KEY', ''):\n    from akismet import Akismet\n    from django.utils.encoding import smart_str\n    akismet_api = Akismet(key=settings.AKISMET_API_KEY,\n                          blog_url='http://%s/' % Site.objects.get_current().domain)\n    if akismet_api.verify_key():\n        akismet_data = { 'comment_type': 'comment',\n                         'referer': self.request.META.get('HTTP_REFERER', ''),\n                         'user_ip': self.request.META.get('REMOTE_ADDR', ''),\n                         'user_agent': self.request.META.get('HTTP_USER_AGENT', '') }\n        if akismet_api.comment_check(smart_str(self.cleaned_data['body']), data=akismet_data, build_data=True):\n            raise forms.ValidationError(u\"Akismet thinks this message is spam\")\nreturn self.cleaned_data['body']", "path": "contact_form\\forms.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nTest that ``RegistrationFormUniqueEmail`` validates uniqueness\nof email addresses.\n\n\"\"\"\n", "func_signal": "def test_registration_form_unique_email(self):\n", "code": "form = forms.RegistrationFormUniqueEmail(data={ 'username': 'foo',\n                                                'email': 'alice@example.com',\n                                                'password1': 'foo',\n                                                'password2': 'foo' })\nself.failIf(form.is_valid())\nself.assertEqual(form.errors['email'], [u\"This email address is already in use. Please supply a different email address.\"])\n\nform = forms.RegistrationFormUniqueEmail(data={ 'username': 'foo',\n                                                'email': 'foo@example.com',\n                                                'password1': 'foo',\n                                                'password2': 'foo' })\nself.failUnless(form.is_valid())", "path": "registration\\tests.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nTest that ``manage.py cleanupregistration`` functions\ncorrectly.\n\n\"\"\"\n", "func_signal": "def test_management_command(self):\n", "code": "management.call_command('cleanupregistration')\nself.assertEqual(RegistrationProfile.objects.count(), 1)", "path": "registration\\tests.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nTest that\n``RegistrationProfile.objects.delete_expired_users()`` deletes\nonly inactive users whose activation window has expired.\n\n\"\"\"\n", "func_signal": "def test_expired_user_deletion(self):\n", "code": "RegistrationProfile.objects.delete_expired_users()\nself.assertEqual(RegistrationProfile.objects.count(), 1)", "path": "registration\\tests.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nReturn the context used to render the templates for the email\nsubject and body.\n\nBy default, this context includes:\n\n* All of the validated values in the form, as variables of the\n  same names as their fields.\n\n* The current ``Site`` object, as the variable ``site``.\n\n* Any additional variables added by context processors (this\n  will be a ``RequestContext``).\n\n\"\"\"\n", "func_signal": "def get_context(self):\n", "code": "if not self.is_valid():\n    raise ValueError(\"Cannot generate Context from invalid contact form\")\nreturn RequestContext(self.request,\n                      dict(self.cleaned_data,\n                           site=Site.objects.get_current()))", "path": "contact_form\\forms.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nTest that user activation actually activates the user and\nproperly resets the activation key, and fails for an\nalready-active or expired user, or an invalid key.\n\n\"\"\"\n# Activating a valid user returns the user.\n", "func_signal": "def test_activation(self):\n", "code": "self.failUnlessEqual(RegistrationProfile.objects.activate_user(RegistrationProfile.objects.get(user=self.sample_user).activation_key).pk,\n                     self.sample_user.pk)\n\n# The activated user must now be active.\nself.failUnless(User.objects.get(pk=self.sample_user.pk).is_active)\n\n# The activation key must now be reset to the \"already activated\" constant.\nself.failUnlessEqual(RegistrationProfile.objects.get(user=self.sample_user).activation_key,\n                     RegistrationProfile.ACTIVATED)\n\n# Activating an expired user returns False.\nself.failIf(RegistrationProfile.objects.activate_user(RegistrationProfile.objects.get(user=self.expired_user).activation_key))\n\n# Activating from a key that isn't a SHA1 hash returns False.\nself.failIf(RegistrationProfile.objects.activate_user('foo'))\n\n# Activating from a key that doesn't exist returns False.\nself.failIf(RegistrationProfile.objects.activate_user(sha.new('foo').hexdigest()))", "path": "registration\\tests.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nDetermine whether this ``RegistrationProfile``'s activation\nkey has expired, returning a boolean -- ``True`` if the key\nhas expired.\n\nKey expiration is determined by a two-step process:\n\n1. If the user has already activated, the key will have been\n   reset to the string constant ``ACTIVATED``. Re-activating\n   is not permitted, and so this method returns ``True`` in\n   this case.\n\n2. Otherwise, the date the user signed up is incremented by\n   the number of days specified in the setting\n   ``ACCOUNT_ACTIVATION_DAYS`` (which should be the number of\n   days after signup during which a user is allowed to\n   activate their account); if the result is less than or\n   equal to the current date, the key has expired and this\n   method returns ``True``.\n\n\"\"\"\n", "func_signal": "def activation_key_expired(self):\n", "code": "expiration_date = datetime.timedelta(days=settings.ACCOUNT_ACTIVATION_DAYS)\nreturn self.activation_key == self.ACTIVATED or \\\n       (self.user.date_joined + expiration_date <= datetime.datetime.now())", "path": "registration\\models.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nValidate an activation key and activate the corresponding\n``User`` if valid.\n\nIf the key is valid and has not expired, return the ``User``\nafter activating.\n\nIf the key is not valid or has expired, return ``False``.\n\nIf the key is valid but the ``User`` is already active,\nreturn ``False``.\n\nTo prevent reactivation of an account which has been\ndeactivated by site administrators, the activation key is\nreset to the string constant ``RegistrationProfile.ACTIVATED``\nafter successful activation.\n\nTo execute customized logic when a ``User`` is activated,\nconnect a function to the signal\n``registration.signals.user_activated``; this signal will be\nsent (with the ``User`` as the value of the keyword argument\n``user``) after a successful activation.\n\n\"\"\"\n", "func_signal": "def activate_user(self, activation_key):\n", "code": "from registration.signals import user_activated\n\n# Make sure the key we're trying conforms to the pattern of a\n# SHA1 hash; if it doesn't, no point trying to look it up in\n# the database.\nif SHA1_RE.search(activation_key):\n    try:\n        profile = self.get(activation_key=activation_key)\n    except self.model.DoesNotExist:\n        return False\n    if not profile.activation_key_expired():\n        user = profile.user\n        user.is_active = True\n        user.save()\n        profile.activation_key = self.model.ACTIVATED\n        profile.save()\n        user_activated.send(sender=self.model, user=user)\n        return user\nreturn False", "path": "registration\\models.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nGenerate the various parts of the message and return them in a\ndictionary, suitable for passing directly as keyword arguments\nto ``django.core.mail.send_mail()``.\n\nBy default, the following values are returned:\n\n* ``from_email``\n\n* ``message``\n\n* ``recipient_list``\n\n* ``subject``\n\n\"\"\"\n", "func_signal": "def get_message_dict(self):\n", "code": "if not self.is_valid():\n    raise ValueError(\"Message cannot be sent from invalid contact form\")\nmessage_dict = {}\nfor message_part in ('from_email', 'message', 'recipient_list', 'subject'):\n    attr = getattr(self, message_part)\n    message_dict[message_part] = callable(attr) and attr() or attr\nreturn message_dict", "path": "contact_form\\forms.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nTest that ``RegistrationFormNoFreeEmail`` disallows\nregistration with free email addresses.\n\n\"\"\"\n", "func_signal": "def test_registration_form_no_free_email(self):\n", "code": "base_data = { 'username': 'foo',\n              'password1': 'foo',\n              'password2': 'foo' }\nfor domain in ('aim.com', 'aol.com', 'email.com', 'gmail.com',\n               'googlemail.com', 'hotmail.com', 'hushmail.com',\n               'msn.com', 'mail.ru', 'mailinator.com', 'live.com'):\n    invalid_data = base_data.copy()\n    invalid_data['email'] = u\"foo@%s\" % domain\n    form = forms.RegistrationFormNoFreeEmail(data=invalid_data)\n    self.failIf(form.is_valid())\n    self.assertEqual(form.errors['email'], [u\"Registration using free email addresses is prohibited. Please supply a different email address.\"])\n\nbase_data['email'] = 'foo@example.com'\nform = forms.RegistrationFormNoFreeEmail(data=base_data)\nself.failUnless(form.is_valid())", "path": "registration\\tests.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nTest that ``RegistrationProfile.activation_key_expired()``\nreturns ``True`` for expired users and for active users, and\n``False`` otherwise.\n\n\"\"\"\n# Unexpired user returns False.\n", "func_signal": "def test_account_expiration_condition(self):\n", "code": "self.failIf(RegistrationProfile.objects.get(user=self.sample_user).activation_key_expired())\n\n# Expired user returns True.\nself.failUnless(RegistrationProfile.objects.get(user=self.expired_user).activation_key_expired())\n\n# Activated user returns True.\nRegistrationProfile.objects.activate_user(RegistrationProfile.objects.get(user=self.sample_user).activation_key)\nself.failUnless(RegistrationProfile.objects.get(user=self.sample_user).activation_key_expired())", "path": "registration\\tests.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nRender the body of the message to a string.\n\n\"\"\"\n", "func_signal": "def message(self):\n", "code": "if callable(self.template_name):\n    template_name = self.template_name()\nelse:\n    template_name = self.template_name\nreturn loader.render_to_string(template_name,\n                               self.get_context())", "path": "contact_form\\forms.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nTest that activation email can be disabled.\n\n\"\"\"\n", "func_signal": "def test_activation_email_disable(self):\n", "code": "RegistrationProfile.objects.create_inactive_user(username='noemail',\n                                                 password='foo',\n                                                 email='nobody@example.com',\n                                                 send_email=False)\nself.assertEqual(len(mail.outbox), 2)", "path": "registration\\tests.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nCreate a ``RegistrationProfile`` for a given\n``User``, and return the ``RegistrationProfile``.\n\nThe activation key for the ``RegistrationProfile`` will be a\nSHA1 hash, generated from a combination of the ``User``'s\nusername and a random salt.\n\n\"\"\"\n", "func_signal": "def create_profile(self, user):\n", "code": "salt = sha_constructor(str(random.random())).hexdigest()[:5]\nactivation_key = sha_constructor(salt+user.username).hexdigest()\nreturn self.create(user=user,\n                   activation_key=activation_key)", "path": "registration\\models.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nTest that the ``user_registered`` and ``user_activated``\nsignals are sent, and that they send the ``User`` as an\nargument.\n\n\"\"\"\n", "func_signal": "def test_signals(self):\n", "code": "def receiver(sender, **kwargs):\n    self.assert_('user' in kwargs)\n    self.assertEqual(kwargs['user'].username, u'signal_test')\n    received_signals.append(kwargs.get('signal'))\n\nreceived_signals = []\nexpected_signals = [signals.user_registered, signals.user_activated]\nfor signal in expected_signals:\n    signal.connect(receiver)\n\nRegistrationProfile.objects.create_inactive_user(username='signal_test',\n                                                 password='foo',\n                                                 email='nobody@example.com',\n                                                 send_email=False)\nRegistrationProfile.objects.activate_user(RegistrationProfile.objects.get(user__username='signal_test').activation_key)\n\nself.assertEqual(received_signals, expected_signals)", "path": "registration\\tests.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nRender the subject of the message to a string.\n\n\"\"\"\n", "func_signal": "def subject(self):\n", "code": "subject = loader.render_to_string(self.subject_template_name,\n                                  self.get_context())\nreturn ''.join(subject.splitlines())", "path": "contact_form\\forms.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nTest that ``RegistrationFormTermsOfService`` requires\nagreement to the terms of service.\n\n\"\"\"\n", "func_signal": "def test_registration_form_tos(self):\n", "code": "form = forms.RegistrationFormTermsOfService(data={ 'username': 'foo',\n                                                   'email': 'foo@example.com',\n                                                   'password1': 'foo',\n                                                   'password2': 'foo' })\nself.failIf(form.is_valid())\nself.assertEqual(form.errors['tos'], [u\"You must agree to the terms to register\"])\n\nform = forms.RegistrationFormTermsOfService(data={ 'username': 'foo',\n                                                   'email': 'foo@example.com',\n                                                   'password1': 'foo',\n                                                   'password2': 'foo',\n                                                   'tos': 'on' })\nself.failUnless(form.is_valid())", "path": "registration\\tests.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nTest that the activation view activates the user from a valid\nkey and fails if the key is invalid or has expired.\n       \n\"\"\"\n# Valid user puts the user account into the context.\n", "func_signal": "def test_activation_view(self):\n", "code": "response = self.client.get(reverse('registration_activate',\n                                   kwargs={ 'activation_key': RegistrationProfile.objects.get(user=self.sample_user).activation_key }))\nself.assertEqual(response.status_code, 200)\nself.assertEqual(response.context['account'].pk, self.sample_user.pk)\n\n# Expired user sets the account to False.\nresponse = self.client.get(reverse('registration_activate',\n                                   kwargs={ 'activation_key': RegistrationProfile.objects.get(user=self.expired_user).activation_key }))\nself.failIf(response.context['account'])\n\n# Invalid key gets to the view, but sets account to False.\nresponse = self.client.get(reverse('registration_activate',\n                                   kwargs={ 'activation_key': 'foo' }))\nself.failIf(response.context['account'])\n\n# Nonexistent key sets the account to False.\nresponse = self.client.get(reverse('registration_activate',\n                                   kwargs={ 'activation_key': sha.new('foo').hexdigest() }))\nself.failIf(response.context['account'])", "path": "registration\\tests.py", "repo_name": "eigenwijsje/festival", "stars": 2, "license": "other", "language": "python", "size": 216}
{"docstring": "\"\"\"\nValidate that the username is alphanumeric and is not already\nin use.\n\n\"\"\"\n", "func_signal": "def clean_username(self):\n", "code": "try:\n    user = User.objects.get(username__iexact=self.cleaned_data['username'])\nexcept User.DoesNotExist:\n    return self.cleaned_data['username']\nraise forms.ValidationError(_(u'This username is already taken. Please choose another.'))", "path": "apps\\registration\\forms.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nTest that ``RegistrationFormUniqueEmail`` validates uniqueness\nof email addresses.\n\n\"\"\"\n", "func_signal": "def test_registration_form_unique_email(self):\n", "code": "form = forms.RegistrationFormUniqueEmail(data={ 'username': 'foo',\n                                                'email': 'alice@example.com',\n                                                'password1': 'foo',\n                                                'password2': 'foo' })\nself.failIf(form.is_valid())\nself.assertEqual(form.errors['email'], [u\"This email address is already in use. Please supply a different email address.\"])\n\nform = forms.RegistrationFormUniqueEmail(data={ 'username': 'foo',\n                                                'email': 'foo@example.com',\n                                                'password1': 'foo',\n                                                'password2': 'foo' })\nself.failUnless(form.is_valid())", "path": "apps\\registration\\tests.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nReturn a form class (a subclass of the default ``ModelForm``)\nsuitable for creating/editing instances of the site-specific user\nprofile model, as defined by the ``AUTH_PROFILE_MODULE``\nsetting. If that setting is missing, raise\n``django.contrib.auth.models.SiteProfileNotAvailable``.\n\n\"\"\"\n", "func_signal": "def get_profile_form():\n", "code": "profile_mod = get_profile_model()\nclass _ProfileForm(forms.ModelForm):\n    class Meta:\n        model = profile_mod\n        exclude = ('user',) # User will be filled in by the view.\nreturn _ProfileForm", "path": "apps\\profiles\\utils.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nTest that ``RegistrationFormNoFreeEmail`` disallows\nregistration with free email addresses.\n\n\"\"\"\n", "func_signal": "def test_registration_form_no_free_email(self):\n", "code": "base_data = { 'username': 'foo',\n              'password1': 'foo',\n              'password2': 'foo' }\nfor domain in ('aim.com', 'aol.com', 'email.com', 'gmail.com',\n               'googlemail.com', 'hotmail.com', 'hushmail.com',\n               'msn.com', 'mail.ru', 'mailinator.com', 'live.com'):\n    invalid_data = base_data.copy()\n    invalid_data['email'] = u\"foo@%s\" % domain\n    form = forms.RegistrationFormNoFreeEmail(data=invalid_data)\n    self.failIf(form.is_valid())\n    self.assertEqual(form.errors['email'], [u\"Registration using free email addresses is prohibited. Please supply a different email address.\"])\n\nbase_data['email'] = 'foo@example.com'\nform = forms.RegistrationFormNoFreeEmail(data=base_data)\nself.failUnless(form.is_valid())", "path": "apps\\registration\\tests.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nVerifiy that the values entered into the two password fields\nmatch. Note that an error here will end up in\n``non_field_errors()`` because it doesn't apply to a single\nfield.\n\n\"\"\"\n", "func_signal": "def clean(self):\n", "code": "if 'password1' in self.cleaned_data and 'password2' in self.cleaned_data:\n    if self.cleaned_data['password1'] != self.cleaned_data['password2']:\n        raise forms.ValidationError(_(u'You must type the same password each time'))\nreturn self.cleaned_data", "path": "apps\\registration\\forms.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nCreate a ``RegistrationProfile`` for a given\n``User``, and return the ``RegistrationProfile``.\n\nThe activation key for the ``RegistrationProfile`` will be a\nSHA1 hash, generated from a combination of the ``User``'s\nusername and a random salt.\n\n\"\"\"\n", "func_signal": "def create_profile(self, user):\n", "code": "salt = sha.new(str(random.random())).hexdigest()[:5]\nactivation_key = sha.new(salt+user.username).hexdigest()\nreturn self.create(user=user,\n                   activation_key=activation_key)", "path": "apps\\registration\\models.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nTest that user activation actually activates the user and\nproperly resets the activation key, and fails for an\nalready-active or expired user, or an invalid key.\n\n\"\"\"\n# Activating a valid user returns the user.\n", "func_signal": "def test_activation(self):\n", "code": "self.failUnlessEqual(RegistrationProfile.objects.activate_user(RegistrationProfile.objects.get(user=self.sample_user).activation_key).pk,\n                     self.sample_user.pk)\n\n# The activated user must now be active.\nself.failUnless(User.objects.get(pk=self.sample_user.pk).is_active)\n\n# The activation key must now be reset to the \"already activated\" constant.\nself.failUnlessEqual(RegistrationProfile.objects.get(user=self.sample_user).activation_key,\n                     RegistrationProfile.ACTIVATED)\n\n# Activating an expired user returns False.\nself.failIf(RegistrationProfile.objects.activate_user(RegistrationProfile.objects.get(user=self.expired_user).activation_key))\n\n# Activating from a key that isn't a SHA1 hash returns False.\nself.failIf(RegistrationProfile.objects.activate_user('foo'))\n\n# Activating from a key that doesn't exist returns False.\nself.failIf(RegistrationProfile.objects.activate_user(sha.new('foo').hexdigest()))", "path": "apps\\registration\\tests.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nTest that\n``RegistrationProfile.objects.delete_expired_users()`` deletes\nonly inactive users whose activation window has expired.\n\n\"\"\"\n", "func_signal": "def test_expired_user_deletion(self):\n", "code": "RegistrationProfile.objects.delete_expired_users()\nself.assertEqual(RegistrationProfile.objects.count(), 1)", "path": "apps\\registration\\tests.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nRemove expired instances of ``RegistrationProfile`` and their\nassociated ``User``s.\n\nAccounts to be deleted are identified by searching for\ninstances of ``RegistrationProfile`` with expired activation\nkeys, and then checking to see if their associated ``User``\ninstances have the field ``is_active`` set to ``False``; any\n``User`` who is both inactive and has an expired activation\nkey will be deleted.\n\nIt is recommended that this method be executed regularly as\npart of your routine site maintenance; this application\nprovides a custom management command which will call this\nmethod, accessible as ``manage.py cleanupregistration``.\n\nRegularly clearing out accounts which have never been\nactivated serves two useful purposes:\n\n1. It alleviates the ocasional need to reset a\n   ``RegistrationProfile`` and/or re-send an activation email\n   when a user does not receive or does not act upon the\n   initial activation email; since the account will be\n   deleted, the user will be able to simply re-register and\n   receive a new activation key.\n\n2. It prevents the possibility of a malicious user registering\n   one or more accounts and never activating them (thus\n   denying the use of those usernames to anyone else); since\n   those accounts will be deleted, the usernames will become\n   available for use again.\n\nIf you have a troublesome ``User`` and wish to disable their\naccount while keeping it in the database, simply delete the\nassociated ``RegistrationProfile``; an inactive ``User`` which\ndoes not have an associated ``RegistrationProfile`` will not\nbe deleted.\n\n\"\"\"\n", "func_signal": "def delete_expired_users(self):\n", "code": "for profile in self.all():\n    if profile.activation_key_expired():\n        user = profile.user\n        if not user.is_active:\n            user.delete()", "path": "apps\\registration\\models.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nDetermine whether this ``RegistrationProfile``'s activation\nkey has expired, returning a boolean -- ``True`` if the key\nhas expired.\n\nKey expiration is determined by a two-step process:\n\n1. If the user has already activated, the key will have been\n   reset to the string ``ALREADY_ACTIVATED``. Re-activating is\n   not permitted, and so this method returns ``True`` in this\n   case.\n\n2. Otherwise, the date the user signed up is incremented by\n   the number of days specified in the setting\n   ``ACCOUNT_ACTIVATION_DAYS`` (which should be the number of\n   days after signup during which a user is allowed to\n   activate their account); if the result is less than or\n   equal to the current date, the key has expired and this\n   method returns ``True``.\n\n\"\"\"\n", "func_signal": "def activation_key_expired(self):\n", "code": "expiration_date = datetime.timedelta(days=settings.ACCOUNT_ACTIVATION_DAYS)\nreturn self.activation_key == self.ACTIVATED or \\\n       (self.user.date_joined + expiration_date <= datetime.datetime.now())", "path": "apps\\registration\\models.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nReturn the model class for the currently-active user profile\nmodel, as defined by the ``AUTH_PROFILE_MODULE`` setting. If that\nsetting is missing, raise\n``django.contrib.auth.models.SiteProfileNotAvailable``.\n\n\"\"\"\n", "func_signal": "def get_profile_model():\n", "code": "if (not hasattr(settings, 'AUTH_PROFILE_MODULE')) or \\\n       (not settings.AUTH_PROFILE_MODULE):\n    raise SiteProfileNotAvailable\nprofile_mod = get_model(*settings.AUTH_PROFILE_MODULE.split('.'))\nif profile_mod is None:\n    raise SiteProfileNotAvailable\nreturn profile_mod", "path": "apps\\profiles\\utils.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nTest that ``RegistrationProfile.activation_key_expired()``\nreturns ``True`` for expired users and for active users, and\n``False`` otherwise.\n\n\"\"\"\n# Unexpired user returns False.\n", "func_signal": "def test_account_expiration_condition(self):\n", "code": "self.failIf(RegistrationProfile.objects.get(user=self.sample_user).activation_key_expired())\n\n# Expired user returns True.\nself.failUnless(RegistrationProfile.objects.get(user=self.expired_user).activation_key_expired())\n\n# Activated user returns True.\nRegistrationProfile.objects.activate_user(RegistrationProfile.objects.get(user=self.sample_user).activation_key)\nself.failUnless(RegistrationProfile.objects.get(user=self.sample_user).activation_key_expired())", "path": "apps\\registration\\tests.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nTest that ``RegistrationFormTermsOfService`` requires\nagreement to the terms of service.\n\n\"\"\"\n", "func_signal": "def test_registration_form_tos(self):\n", "code": "form = forms.RegistrationFormTermsOfService(data={ 'username': 'foo',\n                                                   'email': 'foo@example.com',\n                                                   'password1': 'foo',\n                                                   'password2': 'foo' })\nself.failIf(form.is_valid())\nself.assertEqual(form.errors['tos'], [u\"You must agree to the terms to register\"])\n\nform = forms.RegistrationFormTermsOfService(data={ 'username': 'foo',\n                                                   'email': 'foo@example.com',\n                                                   'password1': 'foo',\n                                                   'password2': 'foo',\n                                                   'tos': 'on' })\nself.failUnless(form.is_valid())", "path": "apps\\registration\\tests.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nTest that the registration view rejects invalid submissions,\nand creates a new user and redirects after a valid submission.\n\n\"\"\"\n# Invalid data fails.\n", "func_signal": "def test_registration_view(self):\n", "code": "response = self.client.post(reverse('registration_register'),\n                            data={ 'username': 'alice', # Will fail on username uniqueness.\n                                   'email': 'foo@example.com',\n                                   'password1': 'foo',\n                                   'password2': 'foo' })\nself.assertEqual(response.status_code, 200)\nself.failUnless(response.context['form'])\nself.failUnless(response.context['form'].errors)\n\nresponse = self.client.post(reverse('registration_register'),\n                            data={ 'username': 'foo',\n                                   'email': 'foo@example.com',\n                                   'password1': 'foo',\n                                   'password2': 'foo' })\nself.assertEqual(response.status_code, 302)\nself.assertEqual(response['Location'], 'http://testserver%s' % reverse('registration_complete'))\nself.assertEqual(RegistrationProfile.objects.count(), 3)", "path": "apps\\registration\\tests.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nValidate an activation key and activate the corresponding\n``User`` if valid.\n\nIf the key is valid and has not expired, return the ``User``\nafter activating.\n\nIf the key is not valid or has expired, return ``False``.\n\nIf the key is valid but the ``User`` is already active,\nreturn ``False``.\n\nTo prevent reactivation of an account which has been\ndeactivated by site administrators, the activation key is\nreset to the string ``ALREADY_ACTIVATED`` after successful\nactivation.\n\n\"\"\"\n# Make sure the key we're trying conforms to the pattern of a\n# SHA1 hash; if it doesn't, no point trying to look it up in\n# the database.\n", "func_signal": "def activate_user(self, activation_key):\n", "code": "if SHA1_RE.search(activation_key):\n    try:\n        profile = self.get(activation_key=activation_key)\n    except self.model.DoesNotExist:\n        return False\n    if not profile.activation_key_expired():\n        user = profile.user\n        user.is_active = True\n        user.save()\n        profile.activation_key = self.model.ACTIVATED\n        profile.save()\n        return user\nreturn False", "path": "apps\\registration\\models.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nCheck the supplied email address against a list of known free\nwebmail domains.\n\n\"\"\"\n", "func_signal": "def clean_email(self):\n", "code": "email_domain = self.cleaned_data['email'].split('@')[1]\nif email_domain in self.bad_domains:\n    raise forms.ValidationError(_(u'Registration using free email addresses is prohibited. Please supply a different email address.'))\nreturn self.cleaned_data['email']", "path": "apps\\registration\\forms.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nTest that ``RegistrationForm`` enforces username constraints\nand matching passwords.\n\n\"\"\"\n", "func_signal": "def test_registration_form(self):\n", "code": "invalid_data_dicts = [\n    # Non-alphanumeric username.\n    {\n    'data':\n    { 'username': 'foo/bar',\n      'email': 'foo@example.com',\n      'password1': 'foo',\n      'password2': 'foo' },\n    'error':\n    ('username', [u\"Enter a valid value.\"])\n    },\n    # Already-existing username.\n    {\n    'data':\n    { 'username': 'alice',\n      'email': 'alice@example.com',\n      'password1': 'secret',\n      'password2': 'secret' },\n    'error':\n    ('username', [u\"This username is already taken. Please choose another.\"])\n    },\n    # Mismatched passwords.\n    {\n    'data':\n    { 'username': 'foo',\n      'email': 'foo@example.com',\n      'password1': 'foo',\n      'password2': 'bar' },\n    'error':\n    ('__all__', [u\"You must type the same password each time\"])\n    },\n    ]\n\nfor invalid_dict in invalid_data_dicts:\n    form = forms.RegistrationForm(data=invalid_dict['data'])\n    self.failIf(form.is_valid())\n    self.assertEqual(form.errors[invalid_dict['error'][0]], invalid_dict['error'][1])\n\nform = forms.RegistrationForm(data={ 'username': 'foo',\n                                     'email': 'foo@example.com',\n                                     'password1': 'foo',\n                                     'password2': 'foo' })\nself.failUnless(form.is_valid())", "path": "apps\\registration\\tests.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nValidate that the supplied email address is unique for the\nsite.\n\n\"\"\"\n", "func_signal": "def clean_email(self):\n", "code": "if User.objects.filter(email__iexact=self.cleaned_data['email']):\n    raise forms.ValidationError(_(u'This email address is already in use. Please supply a different email address.'))\nreturn self.cleaned_data['email']", "path": "apps\\registration\\forms.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nTest that the activation view activates the user from a valid\nkey and fails if the key is invalid or has expired.\n       \n\"\"\"\n# Valid user puts the user account into the context.\n", "func_signal": "def test_activation_view(self):\n", "code": "response = self.client.get(reverse('registration_activate',\n                                   kwargs={ 'activation_key': RegistrationProfile.objects.get(user=self.sample_user).activation_key }))\nself.assertEqual(response.status_code, 200)\nself.assertEqual(response.context['account'].pk, self.sample_user.pk)\n\n# Expired user sets the account to False.\nresponse = self.client.get(reverse('registration_activate',\n                                   kwargs={ 'activation_key': RegistrationProfile.objects.get(user=self.expired_user).activation_key }))\nself.failIf(response.context['account'])\n\n# Invalid key gets to the view, but sets account to False.\nresponse = self.client.get(reverse('registration_activate',\n                                   kwargs={ 'activation_key': 'foo' }))\nself.failIf(response.context['account'])\n\n# Nonexistent key sets the account to False.\nresponse = self.client.get(reverse('registration_activate',\n                                   kwargs={ 'activation_key': sha.new('foo').hexdigest() }))\nself.failIf(response.context['account'])", "path": "apps\\registration\\tests.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "\"\"\"\nCreate the new ``User`` and ``RegistrationProfile``, and\nreturns the ``User``.\n\nThis is essentially a light wrapper around\n``RegistrationProfile.objects.create_inactive_user()``,\nfeeding it the form data and a profile callback (see the\ndocumentation on ``create_inactive_user()`` for details) if\nsupplied.\n\n\"\"\"\n", "func_signal": "def save(self, profile_callback=None):\n", "code": "new_user = RegistrationProfile.objects.create_inactive_user(username=self.cleaned_data['username'],\n                                                            password=self.cleaned_data['password1'],\n                                                            email=self.cleaned_data['email'],\n                                                            profile_callback=profile_callback)\nreturn new_user", "path": "apps\\registration\\forms.py", "repo_name": "fitoria/ecsl-pre-reg", "stars": 3, "license": "None", "language": "python", "size": 269}
{"docstring": "# Wrap up a statement (like an expr_stmt) into a file_input, so we can\n# parse/compile it\n", "func_signal": "def create_file_input(s):\n", "code": "return (symbol.file_input,\n        (symbol.stmt,\n         (symbol.simple_stmt,\n          (symbol.small_stmt, s),\n          (token.NEWLINE, '\\n'))),\n        (token.ENDMARKER, '\\n'))", "path": "hotwire\\externals\\rewrite.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "# print_stmt: 'print' ( [ test (',' test)* [','] ] |\n#                       '>>' test [ (',' test)+ [','] ] )\n", "func_signal": "def _rewrite_print_stmt(t, state):\n", "code": "if state.print_func_name !=None and t[2][0] == symbol.test:\n    return _create_funccall_expr_stmt(state.print_func_name, filter(lambda x: type(x) != int and x[0] == symbol.test, t))\nelse:\n    return t", "path": "hotwire\\externals\\rewrite.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "\"\"\"If argument string is an option, parse it into components and canonicalize it.\nOtherwise, return arg.\"\"\"\n", "func_signal": "def __parse_option_or_arg(opts, arg, raise_on_invalid=True):\n", "code": "if arg.startswith('--'):\n    args = [arg[1:]] # we re-add the '-' below\nelif arg.startswith('-') and len(arg) >= 2:\n    args = list(arg[1:])\nelse:\n    return False\nresults = []\nfor arg in args:\n    found = False\n    if opts is not None:\n        for aliases in opts:\n            if '-'+arg in aliases:\n                results.append(aliases[0])\n                found = True\n                break\n    if (not found) and raise_on_invalid:                \n            raise PipelineParseException(\"Invalid option %s\" % (arg,))\nreturn results", "path": "hotwire\\command.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "# expr_stmt: testlist (augassign (yield_expr|testlist) |\n#                      ('=' (yield_expr|testlist))*)\n\n", "func_signal": "def _rewrite_expr_stmt(t, state):\n", "code": "assert(t[0] == symbol.expr_stmt)\nassert(t[1][0] == symbol.testlist)\n\nif len(t) == 2:\n    # testlist\n    subnode = t[1]\n    for i in xrange(1, len(subnode)):\n        subsubnode = subnode[i]\n        if subsubnode[0] == symbol.test:\n            method_spec = _is_test_method_call(subsubnode)\n            if (method_spec != None):\n                state.add_mutated(method_spec)\n\n    if state.output_func_name != None:\n        args = list(filter(lambda x: type(x) != int and x[0] == symbol.test, subnode))\n        if state.output_func_self != None:\n            args.insert(0, _create_varref(state.output_func_self))\n        return _create_funccall_expr_stmt(state.output_func_name, tuple(args))\n    else:\n        return t\nelse:\n    if (t[2][0] == symbol.augassign):\n        # testlist augassign (yield_expr|testlist)\n        subnode = t[1]\n        assert(len(subnode) == 2) # can only augassign one thing, despite the grammar\n        \n        variable = _is_test_slice(subnode[1])\n        if variable == None:\n            variable = _is_test_attribute(subnode[1])\n        \n        if variable != None:\n            state.add_mutated(variable)\n    else:\n        # testlist ('=' (yield_expr|testlist))+\n        for i in xrange(1, len(t) - 1):\n            if (t[i + 1][0] == token.EQUAL):\n                subnode = t[i]\n                assert(subnode[0] == symbol.testlist)\n                for j in xrange(1, len(subnode)):\n                    subsubnode = subnode[j]\n                    if subsubnode[0] == symbol.test:\n                        variable = _is_test_slice(subsubnode)\n                        if variable == None:\n                            variable = _is_test_attribute(subnode[1])\n                            \n                        if variable != None:\n                            state.add_mutated(variable)\n    return t", "path": "hotwire\\externals\\rewrite.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "# suite: simple_stmt | NEWLINE INDENT stmt+ DEDENT\n", "func_signal": "def _rewrite_suite(t, state):\n", "code": "return _rewrite_tree(t, state,\n                     { symbol.simple_stmt: _rewrite_simple_stmt,\n                       symbol.stmt:        _rewrite_stmt })", "path": "hotwire\\externals\\rewrite.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "\"\"\"Call given func exactly once in the next idle time; if func is already pending,\nit will not be queued multiple times.\"\"\"\n\n", "func_signal": "def call_timeout_once(timeout, func, **kwargs):\n", "code": "if func in _global_call_once_funcs:\n    return\nid = call_timeout(timeout, _run_removing_from_call_once, func, **kwargs)\n_global_call_once_funcs[func] = id\nreturn id", "path": "hotwire\\gutil.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "# Create a test symbol which is a constant number\n", "func_signal": "def create_constant_test(c):\n", "code": "return (symbol.test,\n        (symbol.and_test,\n         (symbol.not_test,\n          (symbol.comparison,\n           (symbol.expr,\n            (symbol.xor_expr,\n             (symbol.and_expr,\n              (symbol.shift_expr,\n               (symbol.arith_expr,\n                (symbol.term,\n                 (symbol.factor,\n                  (symbol.power,\n                   (symbol.atom,\n                    (token.NUMBER, str(c)))))))))))))))", "path": "hotwire\\externals\\rewrite.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "# This converts the various Python string types into a format that is\n# appropriate for .po files, namely much closer to C style.\n", "func_signal": "def normalize(s):\n", "code": "lines = s.split('\\n')\nif len(lines) == 1:\n    s = '\"' + escape(s) + '\"'\nelse:\n    if not lines[-1]:\n        del lines[-1]\n        lines[-1] = lines[-1] + '\\n'\n    for i in range(len(lines)):\n        lines[i] = escape(lines[i])\n    lineterm = '\\\\n\"\\n\"'\n    s = '\"\"\\n\"' + lineterm.join(lines) + '\"'\nreturn s", "path": "DistUtilsExtra\\pygettext.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "# Creates an 'expr_stmt' that calls a function. args is a list of\n# \"test\" AST's to pass as arguments to the function\n", "func_signal": "def _create_funccall_expr_stmt(name, args):\n", "code": "if len(args) == 0:\n    trailer = (symbol.trailer,\n               (token.LPAR, '('),\n               (token.RPAR, ')'))\nelse:\n    arglist = [ symbol.arglist ]\n    for a in args:\n        if len(arglist) > 1:\n            arglist.append((token.COMMA, ','))\n        arglist.append((symbol.argument, a))\n            \n    trailer = (symbol.trailer,\n               (token.LPAR, ')'),\n               arglist,\n               (token.RPAR, ')'))\n\nreturn _do_create_funccall_expr_stmt(name, trailer)", "path": "hotwire\\externals\\rewrite.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "\"\"\"\nCompiles the supplied text into code, while rewriting the parse tree so:\n\n * Print statements without a destination file are transformed into calls to\n  <print_func_name>(*args), if print_func_name is not None\n   \n * Statements which are simply expressions are transformed into calls to\n   <output_func_name>(*args), if output_fnuc_name is not None\n   (More than one argument is passed if the statement is in the form of a list; for example '1,2'.)\n\nAt the same time, the code is scanned for possible mutations, and a list is returned.\nIn the list:\n\n  * A string indicates the mutation of a variable by assignment to a slice of it,\n    or to an attribute.\n\n  * A tuple of (variable_name, method_name) indicates the invocation of a method\n    on the variable; this will sometimes be a mutation (e.g., list.append(value)),\n    and sometimes not.\n\"\"\"\n", "func_signal": "def rewrite_and_compile(code, output_func_name=None, output_func_self=None, print_func_name=None, encoding=\"utf8\"):\n", "code": "state = _RewriteState(output_func_name=output_func_name, output_func_self=output_func_self, print_func_name=print_func_name)\n\nif (isinstance(code, unicode)):\n    code = code.encode(\"utf8\")\n    encoding = \"utf8\"\n\noriginal = parser.suite(code)\nrewritten = _rewrite_file_input(original.totuple(), state)\nencoded = (symbol.encoding_decl, rewritten, encoding)\ncompiled = parser.sequence2ast(encoded).compile()\n\nreturn (compiled, state.mutated)", "path": "hotwire\\externals\\rewrite.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "# Generic rewriting of an AST, actions is a map of symbol/token type to function\n# to call to produce a modified version of the the subtree\n", "func_signal": "def _rewrite_tree(t, state, actions):\n", "code": "result = t\nfor i in xrange(1, len(t)):\n    subnode = t[i]\n    subtype = subnode[0]\n    if actions.has_key(subtype):\n        filtered = actions[subtype](subnode, state)\n        if filtered != subnode:\n            if result is t:\n                result = list(t)\n            result[i] = filtered\n            \nreturn result", "path": "hotwire\\externals\\rewrite.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "# ignore anything until we see the colon\n", "func_signal": "def __suiteseen(self, ttype, tstring, lineno):\n", "code": "if ttype == tokenize.OP and tstring == ':':\n    self.__state = self.__suitedocstring", "path": "DistUtilsExtra\\pygettext.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "\"\"\"Helper for getFilesForName().\"\"\"\n# get extension for python source files\n", "func_signal": "def _visit_pyfiles(list, dirname, names):\n", "code": "if not globals().has_key('_py_ext'):\n    global _py_ext\n    _py_ext = [triple[0] for triple in imp.get_suffixes()\n               if triple[2] == imp.PY_SOURCE][0]\n\n# don't recurse into CVS directories\nif 'CVS' in names:\n    names.remove('CVS')\n\n# add all *.py files to list\nlist.extend(\n    [os.path.join(dirname, file) for file in names\n     if os.path.splitext(file)[1] == _py_ext]\n    )", "path": "DistUtilsExtra\\pygettext.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "# Allow passing plain strings for convenience from Python.\n# Treat them as quoted.\n", "func_signal": "def forcetoken(t):\n", "code": "if isinstance(t, basestring):\n    return ParsedToken(t, -1, quoted=True)\nreturn t", "path": "hotwire\\command.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "# stmt: simple_stmt | compound_stmt\n", "func_signal": "def _rewrite_stmt(t, state):\n", "code": "return _rewrite_tree(t, state,\n                     { symbol.simple_stmt:   _rewrite_simple_stmt,\n                       symbol.compound_stmt: _rewrite_compound_stmt })", "path": "hotwire\\externals\\rewrite.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "# Check if the given AST is a \"test\" of the form 'v.m()' If it\n# matches, returns { 'variable': 'v', \"method\": m }, otherwise returns None\n", "func_signal": "def _is_test_method_call(t):\n", "code": "args = _do_match(t, _method_call_pattern)\nif args == None:\n    return None\nelse:\n    return args['variable'], args['method']", "path": "hotwire\\externals\\rewrite.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "\"\"\"Get a list of module files for a filename, a module or package name,\nor a directory.\n\"\"\"\n", "func_signal": "def getFilesForName(name):\n", "code": "if not os.path.exists(name):\n    # check for glob chars\n    if containsAny(name, \"*?[]\"):\n        files = glob.glob(name)\n        list = []\n        for file in files:\n            list.extend(getFilesForName(file))\n        return list\n\n    # try to find module or package\n    name = _get_modpkg_path(name)\n    if not name:\n        return []\n\nif os.path.isdir(name):\n    # find all python files in directory\n    list = []\n    os.path.walk(name, _visit_pyfiles, list)\n    return list\nelif os.path.exists(name):\n    # a single file\n    return [name]\n\nreturn []", "path": "DistUtilsExtra\\pygettext.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "# Check if the given AST is a attribute of the form 'v.a' If it\n# matches, returns v, otherwise returns None\n", "func_signal": "def _is_test_attribute(t):\n", "code": "args = _do_match(t, _attribute_pattern)\n\nif args == None:\n    return None\nelse:\n    return args['variable']", "path": "hotwire\\externals\\rewrite.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "# simple_stmt: small_stmt (';' small_stmt)* [';'] NEWLINE\n", "func_signal": "def _rewrite_simple_stmt(t, state):\n", "code": "return _rewrite_tree(t, state,\n                     { symbol.small_stmt: _rewrite_small_stmt })", "path": "hotwire\\externals\\rewrite.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "# Check if the given AST is a \"test\" of the form 'v[...]' If it\n# matches, returns v, otherwise returns None\n", "func_signal": "def _is_test_slice(t):\n", "code": "args = _do_match(t, _slice_pattern)\n\nif args == None:\n    return None\nelse:\n    return args['variable']", "path": "hotwire\\externals\\rewrite.py", "repo_name": "zsx/hotwire", "stars": 3, "license": "other", "language": "python", "size": 1156}
{"docstring": "\"\"\"This method routes method call requests to either the SGMLParser\nsuperclass or the Tag superclass, depending on the method name.\"\"\"\n", "func_signal": "def __getattr__(self, methodName):\n", "code": "if methodName.find('start_') == 0 or methodName.find('end_') == 0 \\\n       or methodName.find('do_') == 0:\n    return SGMLParser.__getattr__(self, methodName)\nelif methodName.find('__') != 0:\n    return Tag.__getattr__(self, methodName)\nelse:\n    raise AttributeError", "path": "src\\ibofobi\\utils\\test\\BeautifulSoup.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"Returns true iff this tag has the same name, the same attributes,\nand the same contents (recursively) as the given tag.\n\nNOTE: right now this will return false if two tags have the\nsame attributes in a different order. Should this be fixed?\"\"\"\n", "func_signal": "def __eq__(self, other):\n", "code": "if not hasattr(other, 'name') or not hasattr(other, 'attrs') or not hasattr(other, 'contents') or self.name != other.name or self.attrs != other.attrs or len(self) != len(other):\n    return False\nfor i in range(0, len(self.contents)):\n    if self.contents[i] != other.contents[i]:\n        return False\nreturn True", "path": "src\\ibofobi\\utils\\test\\BeautifulSoup.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "#print \"Push\", tag.name\n", "func_signal": "def pushTag(self, tag):\n", "code": "if self.currentTag:\n    self.currentTag.append(tag)\nself.tagStack.append(tag)\nself.currentTag = self.tagStack[-1]", "path": "src\\ibofobi\\utils\\test\\BeautifulSoup.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"\n    summary: >\n       Simply returns the unquoted string, and the\n       length of the quoted string token at the \n       beginning of the expression.\n\"\"\"\n", "func_signal": "def unquote(expr):\n", "code": "tok = expr[0]\nif \"'\" == tok: \n    idx = 1\n    odd = 0\n    ret = \"\"\n    while idx < len(expr):\n        chr = expr[idx]\n        if \"'\" == chr:\n            if odd: ret += chr\n            odd = not odd\n        else:\n            if odd:\n                tok = expr[:idx]\n                break\n            ret += chr\n        idx += 1\n    if \"'\" == tok: tok = expr\n    return (ret,len(tok))\nif '\"' == tok:\n    idx = 1\n    esc = 0\n    while idx < len(expr):\n        chr = expr[idx]\n        if '\"' == chr and not esc:\n            tok = expr[:idx] + '\"'\n            break\n        if '\\\\' == chr and not esc: esc = 1\n        else: esc = 0\n        idx += 1\n    if '\"' == tok:\n        raise SyntaxError(\"unmatched quote: \" + expr)\n    ret = eval(tok)  #TODO: find better way to unquote\n    return (ret,len(tok))\nreturn (expr,len(expr))", "path": "src\\ibofobi\\utils\\test\\yaml\\timestamp.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"Renders the contents of this tag as a (possibly Unicode) \nstring.\"\"\"\n", "func_signal": "def renderContents(self, showStructureIndent=None, needUnicode=None):\n", "code": "s=[]\nfor c in self:\n    text = None\n    if isinstance(c, NavigableUnicodeString) or type(c) == types.UnicodeType:\n        text = unicode(c)\n    elif isinstance(c, Tag):\n        s.append(c.__str__(needUnicode, showStructureIndent))\n    elif needUnicode:\n        text = unicode(c)\n    else:\n        text = str(c)\n    if text:\n        if showStructureIndent != None:\n            if text[-1] == '\\n':\n                text = text[:-1]\n        s.append(text)\nreturn ''.join(s)", "path": "src\\ibofobi\\utils\\test\\BeautifulSoup.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"Treat a bogus SGML declaration as raw data. Treat a CDATA\ndeclaration as regular data.\"\"\"\n", "func_signal": "def parse_declaration(self, i):\n", "code": "j = None\nif self.rawdata[i:i+9] == '<![CDATA[':\n     k = self.rawdata.find(']]>', i)\n     if k == -1:\n         k = len(self.rawdata)\n     self.handle_data(self.rawdata[i+9:k])\n     j = k+3\nelse:\n    try:\n        j = SGMLParser.parse_declaration(self, i)\n    except SGMLParseError:\n        toHandle = self.rawdata[i:]\n        self.handle_data(toHandle)\n        j = i + len(toHandle)\nreturn j", "path": "src\\ibofobi\\utils\\test\\BeautifulSoup.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"create_object(class, dict) -> class-instance\n\nTurn a dict as returned by yaml.load into a Model-subclass instance,\nmuch like AddManipulator only simpler and for yaml :).\"\"\"\n\n", "func_signal": "def create_object(klass, kwargs):\n", "code": "obj = klass()\n\nfor field in obj._meta.fields:\n    name = field.column\n\n    if not kwargs.has_key(name):\n        if field.default:\n            value = field.default\n        elif field.blank:\n            value = ''\n        elif isinstance(field, fields.AutoField):\n            continue\n        elif isinstance(field, fields.DateTimeField) and (field.auto_now or field.auto_now_add):\n            value = datetime.datetime.now()\n        else:\n            continue\n\n    elif isinstance(field, fields.IntegerField):\n        value = int(kwargs[name])\n\n    elif isinstance(field, fields.BooleanField):\n        if isinstance(kwargs[name], str) and kwargs[name].lower() == 'true':\n            value = True\n        elif kwargs[name] == 1 or kwargs[name] == '1':\n            value = True\n        else:\n            value = False\n\n    elif isinstance(field, fields.DateTimeField):\n        if isinstance(kwargs[name], yaml.timestamp):\n            value = datetime.datetime.fromtimestamp(kwargs[name].mktime())\n        else:\n            raise 'Cannot convert %r to datetime instance' % kwargs[name]\n\n    else:\n        value = kwargs[name]\n\n    setattr(obj, name, value)\n\nobj.save()\nreturn obj", "path": "src\\ibofobi\\utils\\test\\test_app.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "# First, get a session\n", "func_signal": "def login(self, username, password):\n", "code": "self.conn.putrequest('GET', '/')\nself.conn.putheader('User-Agent', self.user_agent)\nself.conn.endheaders()\n\nresp = self.conn.getresponse()\nsoup = BeautifulSoup(resp.read())\nif soup.h1.string == 'error encountered':\n    raise AssertionError\n\nself.session_cookie = resp.getheader('set-cookie').split(';', 1)[0]\n\n# Now login,\nlogin_form = 'username=%s&password=%s&posted=true' % (username, password)\nself.conn.putrequest('POST', '/login.do')\nself.conn.putheader('User-Agent', self.user_agent)\nself.conn.putheader('Content-Type', 'application/x-www-form-urlencoded')\nself.conn.putheader('Content-Length', str(len(login_form)))\nself.conn.putheader('Cookie', self.session_cookie)\nself.conn.endheaders()\nself.conn.send(login_form)\n\nresp = self.conn.getresponse()\nsoup = BeautifulSoup(resp.read())\nif soup.h1.string == 'error encountered':\n    raise AssertionError\nif soup.form.get('name', None) == 'loginForm':\n    raise AssertionError", "path": "src\\ibofobi\\apps\\aurora\\utils\\tvtorrents_fetcher.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"Called when you're done parsing, so that the unclosed tags can be\ncorrectly processed.\"\"\"\n", "func_signal": "def done(self):\n", "code": "self.endData() #NEW\nwhile self.currentTag.name != self.ROOT_TAG_NAME:\n    self.popTag()", "path": "src\\ibofobi\\utils\\test\\BeautifulSoup.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"Returns a string or Unicode representation of this tag and\nits contents.\n\nNOTE: since Python's HTML parser consumes whitespace, this\nmethod is not certain to reproduce the whitespace present in\nthe original string.\"\"\"\n\n", "func_signal": "def __str__(self, needUnicode=None, showStructureIndent=None):\n", "code": "attrs = []\nif self.attrs:\n    for key, val in self.attrs:\n        attrs.append('%s=\"%s\"' % (key, val))\nclose = ''\ncloseTag = ''\nif self.isSelfClosing():\n    close = ' /'\nelse:\n    closeTag = '</%s>' % self.name\nindentIncrement = None        \nif showStructureIndent != None:\n    indentIncrement = showStructureIndent\n    if not self.hidden:\n        indentIncrement += 1\ncontents = self.renderContents(indentIncrement, needUnicode=needUnicode)        \nif showStructureIndent:\n    space = '\\n%s' % (' ' * showStructureIndent)\nif self.hidden:\n    s = contents\nelse:\n    s = []\n    attributeString = ''\n    if attrs:\n        attributeString = ' ' + ' '.join(attrs)            \n    if showStructureIndent:\n        s.append(space)\n    s.append('<%s%s%s>' % (self.name, attributeString, close))\n    s.append(contents)\n    if closeTag and showStructureIndent != None:\n        s.append(space)\n    s.append(closeTag)\n    s = ''.join(s)\nisUnicode = type(s) == types.UnicodeType\nif needUnicode and not isUnicode:\n    s = unicode(s)\nelif isUnicode and needUnicode==False:\n    s = str(s)\nreturn s", "path": "src\\ibofobi\\utils\\test\\BeautifulSoup.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"test_app(app)\n\nTests the application app:\n- a clean sqlite in-memory database is create\n- the applications models are installed\n- the fixtures in path-to-app/fixtures/*.yml are created\n- settings.ROOT_URLCONF is pointed at the applications urls-module\n- the tests in the tests-module are run with doctest.testmod\n  given the fixtures and a browser-instance as globals\n\"\"\"\n\n# Import application module\n", "func_signal": "def test_app(app):\n", "code": "if '.' in app:\n    i = app.rfind('.')\n    app_name = app[i+1:]\nelse:\n    app_name = app\nmodule = __import__(app, None, None, ['*'])\n\n# Reinitialize database\ndb.db.real_close() # this is in effect a 'drop database' with a sqlite :memory: database\nmanagement.init()\n\n# Install models\nfor model in module.models.__all__:\n    management.install(meta.get_app(model))\n\n# Load fixtures\nfiles = os.path.join(os.path.dirname(module.__file__), 'fixtures', '*.yml')\nfixtures = {}\nfor yml in [ yaml.loadFile(f) for f in glob(files) ]:\n    models = yml.next()\n    \n    for model, fixs in models.items():\n        model = meta.get_module(app_name, model)\n        klass = model.Klass\n\n        for name, kwargs in fixs.items():\n            obj = create_object(klass, kwargs)\n            # Load object from database, this normalizes it.\n            fixtures[name] = model.get_object(pk=obj.id)\n\n# Commit fixtures\ndb.db.commit()\n\n# Munge django.conf.settings.ROOT_URLCONF to point to\n# this apps urls-module,\nsettings.ROOT_URLCONF = app + '.urls'\n\n# Run tests\nmodule = __import__(app, None, None, ['tests'])\ntests = getattr(module, 'tests', None)\nif tests:\n    globs = {\n        'browser': Browser(app),\n    }\n    globs.update(fixtures)\n    doctest.testmod(tests, None, globs)", "path": "src\\ibofobi\\utils\\test\\test_app.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"Return only the first child of this\nTag matching the given criteria.\"\"\"\n", "func_signal": "def first(self, name=None, attrs={}, recursive=True, text=None):\n", "code": "r = Null\nl = self.fetch(name, attrs, recursive, text, 1)\nif l:\n    r = l[0]\nreturn r", "path": "src\\ibofobi\\utils\\test\\BeautifulSoup.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"get_month_matrix(year, month) -> [ [ ... ] ... ]\n\nGenerate a cal(1)-like matrix for the given month.\"\"\"\n\n", "func_signal": "def get_month_matrix(year, month):\n", "code": "now = datetime.date.today()\nrecurring = recurringevents.get_list()\n\ndef end_of_month(when):\n    \"\"\"end_of_month(when) -> when\n\n    Find seconds since the epoch on midnight the first of the\n    following month.\"\"\"\n    t = list(time.localtime(when))\n    if t[1] == 12:\n        t[0] = t[0] + 1\n        t[1] = 1\n    else:\n        t[1] = t[1] + 1\n    return time.mktime(t)\n    \ndef get_day(time_epoch):\n    year, month, day, hh, mm, ss, weekday, julian, dst = \\\n        time.localtime(time_epoch)\n    date = datetime.date(year, month, day)\n    return {\n        'events': events.get_list(start_date__lte=date,\n                                  end_date__gte=date),\n        'recurringevents': [ e for e in recurring\n                             if recurringevents.is_here(e, date) ],\n        'year': year,\n        'month': month,\n        'day': day,\n        'today': date == now,\n    }\n\n# set time_epoch to the first day in the matrix\ntime_epoch = time.mktime((year, month, 1, 0, 0, 0, 0, 0, -1))\ntime_tuple = time.localtime(time_epoch) # fills in weekday\nend_time = end_of_month(time_epoch)\ntime_epoch = time_epoch - 24 * 60 * 60 * time_tuple[6]\n\n# create matrix\nmatrix = []\nwhile time_epoch < end_time:\n    matrix.append([])\n    for weekday in range(7):\n        matrix[-1].append(get_day(time_epoch))\n        time_epoch = time_epoch + 24 * 60 * 60\n\nreturn matrix", "path": "src\\ibofobi\\apps\\calendar\\views\\__init__.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"Pops the tag stack up to and including the most recent\ninstance of the given tag. If inclusivePop is false, pops the tag\nstack up to but *not* including the most recent instqance of\nthe given tag.\"\"\"\n", "func_signal": "def _popToTag(self, name, inclusivePop=True):\n", "code": "if name == self.ROOT_TAG_NAME:\n    return            \n\nnumPops = 0\nmostRecentTag = None\nfor i in range(len(self.tagStack)-1, 0, -1):\n    if name == self.tagStack[i].name:\n        numPops = len(self.tagStack)-i\n        break\nif not inclusivePop:\n    numPops = numPops - 1\n\nfor i in range(0, numPops):\n    mostRecentTag = self.popTag()\nreturn mostRecentTag", "path": "src\\ibofobi\\utils\\test\\BeautifulSoup.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"Initializes a map representation of this tag's attributes,\nif not already initialized.\"\"\"\n", "func_signal": "def _getAttrMap(self):\n", "code": "if not getattr(self, 'attrMap'):\n    self.attrMap = {}\n    for (key, value) in self.attrs:\n        self.attrMap[key] = value \nreturn self.attrMap", "path": "src\\ibofobi\\utils\\test\\BeautifulSoup.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "#print 'looking for %s in %s' % (howToMatch, chunk)\n#\n# If given a list of items, return true if the list contains a\n# text element that matches.\n", "func_signal": "def _matches(self, chunk, howToMatch):\n", "code": "if isList(chunk) and not isinstance(chunk, Tag):\n    for tag in chunk:\n        if isinstance(tag, NavigableText) and self._matches(tag, howToMatch):\n            return True\n    return False\nif callable(howToMatch):\n    return howToMatch(chunk)\nif isinstance(chunk, Tag):\n    #Custom match methods take the tag as an argument, but all other\n    #ways of matching match the tag name as a string\n    chunk = chunk.name\n#Now we know that chunk is a string\nif not isinstance(chunk, basestring):\n    chunk = str(chunk)\nif hasattr(howToMatch, 'match'):\n    # It's a regexp object.\n    return howToMatch.search(chunk)\nif isList(howToMatch):\n    return chunk in howToMatch\nif hasattr(howToMatch, 'items'):\n    return howToMatch.has_key(chunk)\n#It's just a string\nreturn str(howToMatch) == chunk", "path": "src\\ibofobi\\utils\\test\\BeautifulSoup.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"Convenience method that works with all 2.x versions of Python\nto determine whether or not something is listlike.\"\"\"\n", "func_signal": "def isList(l):\n", "code": "return hasattr(l, '__iter__') \\\n       or (type(l) in (types.ListType, types.TupleType))", "path": "src\\ibofobi\\utils\\test\\BeautifulSoup.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"Returns the closest parent of this Tag that matches the given\ncriteria.\"\"\"\n", "func_signal": "def findParent(self, name=None, attrs={}):\n", "code": "r = Null\nl = self.fetchParents(name, attrs, 1)\nif l:\n    r = l[0]\nreturn r", "path": "src\\ibofobi\\utils\\test\\BeautifulSoup.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"Turns a list of maps, lists, or scalars into a single map.\nUsed to build the SELF_CLOSING_TAGS and NESTABLE_TAGS maps out\nof lists and partial maps.\"\"\"\n", "func_signal": "def buildTagMap(default, *args):\n", "code": "built = {}\nfor portion in args:\n    if hasattr(portion, 'items'):\n        #It's a map. Merge it.\n        for k,v in portion.items():\n            built[k] = v\n    elif isList(portion):\n        #It's a list. Map each item to the default.\n        for k in portion:\n            built[k] = default\n    else:\n        #It's a scalar. Map it to the default.\n        built[portion] = default\nreturn built", "path": "src\\ibofobi\\utils\\test\\BeautifulSoup.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"Sets up the initial relations between this element and\nother elements.\"\"\"\n", "func_signal": "def setup(self, parent=Null, previous=Null):\n", "code": "self.parent = parent\nself.previous = previous\nself.next = Null\nself.previousSibling = Null\nself.nextSibling = Null\nif self.parent and self.parent.contents:\n    self.previousSibling = self.parent.contents[-1]\n    self.previousSibling.nextSibling = self", "path": "src\\ibofobi\\utils\\test\\BeautifulSoup.py", "repo_name": "kirkeby/django-stuff", "stars": 2, "license": "other", "language": "python", "size": 432}
{"docstring": "\"\"\"Get a throttle option. \n\nInput may either be a percentage or a \"friendly bandwidth value\" as\naccepted by the BytesOption.\n\nValid inputs: 100, 50%, 80.5%, 123M, 45.6k, 12.4G, 100K, 786.0, 0\nInvalid inputs: 100.1%, -4%, -500\n\nReturn value will be a int if a bandwidth value was specified or a\nfloat if a percentage was given.\n\nValueError will be raised if input couldn't be parsed.\n\"\"\"\n", "func_signal": "def parse(self, s):\n", "code": "if len(s) < 1:\n    raise ValueError(\"no value specified\")\n\nif s[-1] == '%':\n    n = s[:-1]\n    try:\n        n = float(n)\n    except ValueError:\n        raise ValueError(\"couldn't convert '%s' to number\" % n)\n    if n < 0 or n > 100:\n        raise ValueError(\"percentage is out of range\")\n    return n / 100.0\nelse:\n    return BytesOption.parse(self, s)", "path": "certmaster\\config.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "\"\"\"Construct and return tupel with IO objects:\np2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite\n\"\"\"\n", "func_signal": "def _get_handles(self, stdin, stdout, stderr):\n", "code": "p2cread, p2cwrite = None, None\nc2pread, c2pwrite = None, None\nerrread, errwrite = None, None\n\nif stdin is None:\n    pass\nelif stdin == PIPE:\n    p2cread, p2cwrite = os.pipe()\nelif isinstance(stdin, int):\n    p2cread = stdin\nelse:\n    # Assuming file-like object\n    p2cread = stdin.fileno()\n\nif stdout is None:\n    pass\nelif stdout == PIPE:\n    c2pread, c2pwrite = os.pipe()\nelif isinstance(stdout, int):\n    c2pwrite = stdout\nelse:\n    # Assuming file-like object\n    c2pwrite = stdout.fileno()\n\nif stderr is None:\n    pass\nelif stderr == PIPE:\n    errread, errwrite = os.pipe()\nelif stderr == STDOUT:\n    errwrite = c2pwrite\nelif isinstance(stderr, int):\n    errwrite = stderr\nelse:\n    # Assuming file-like object\n    errwrite = stderr.fileno()\n\nreturn (p2cread, p2cwrite,\n        c2pread, c2pwrite,\n        errread, errwrite)", "path": "certmaster\\sub_process.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "\"\"\"Wait for child process to terminate.  Returns returncode\nattribute.\"\"\"\n", "func_signal": "def wait(self):\n", "code": "if self.returncode is None:\n    obj = WaitForSingleObject(self._handle, INFINITE)\n    self.returncode = GetExitCodeProcess(self._handle)\nreturn self.returncode", "path": "certmaster\\sub_process.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "'''Called when the option is read (via the descriptor protocol). \n\n@param obj: The configuration instance to modify.\n@param objtype: The type of the config instance (not used).\n@return: The parsed option value or the default value if the value\n    wasn't set in the configuration file.\n'''\n", "func_signal": "def __get__(self, obj, objtype):\n", "code": "if obj is None:\n    return self\n\nreturn getattr(obj, self._attrname, None)", "path": "certmaster\\config.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "'''Set option values from a INI file section.\n\n@param parser: ConfParser instance (or subclass)\n@param section: INI file section to read use.\n@param parent: Optional parent BaseConfig (or subclass) instance to use\n    when doing option value inheritance.\n'''\n", "func_signal": "def populate(self, parser, section, parent=None):\n", "code": "self.cfg = parser\nself._section = section\n\nfor name in self.iterkeys():\n    option = self.optionobj(name)\n    value = None\n    try:\n        value = parser.get(section, name)\n    except (NoSectionError, NoOptionError):\n        # No matching option in this section, try inheriting\n        if parent and option.inherit:\n            value = getattr(parent, name)\n       \n    if value is not None:\n        setattr(self, name, value)", "path": "certmaster\\config.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "\"\"\"Parse a friendly bandwidth option to bytes\n\nThe input should be a string containing a (possibly floating point)\nnumber followed by an optional single character unit. Valid units are\n'k', 'M', 'G'. Case is ignored.\n       \nValid inputs: 100, 123M, 45.6k, 12.4G, 100K, 786.3, 0\nInvalid inputs: -10, -0.1, 45.6L, 123Mb\n\nReturn value will always be an integer\n\n1k = 1024 bytes.\n\nValueError will be raised if the option couldn't be parsed.\n\"\"\"\n", "func_signal": "def parse(self, s):\n", "code": "if len(s) < 1:\n    raise ValueError(\"no value specified\")\n\nif s[-1].isalpha():\n    n = s[:-1]\n    unit = s[-1].lower()\n    mult = self.MULTS.get(unit, None)\n    if not mult:\n        raise ValueError(\"unknown unit '%s'\" % unit)\nelse:\n    n = s\n    mult = 1\n     \ntry:\n    n = float(n)\nexcept ValueError:\n    raise ValueError(\"couldn't convert '%s' to number\" % n)\n\nif n < 0:\n    raise ValueError(\"bytes value may not be negative\")\n\nreturn int(n * mult)", "path": "certmaster\\config.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "\"\"\"Construct and return tupel with IO objects:\np2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite\n\"\"\"\n", "func_signal": "def _get_handles(self, stdin, stdout, stderr):\n", "code": "if stdin is None and stdout is None and stderr is None:\n    return (None, None, None, None, None, None)\n\np2cread, p2cwrite = None, None\nc2pread, c2pwrite = None, None\nerrread, errwrite = None, None\n\nif stdin is None:\n    p2cread = GetStdHandle(STD_INPUT_HANDLE)\nelif stdin == PIPE:\n    p2cread, p2cwrite = CreatePipe(None, 0)\n    # Detach and turn into fd\n    p2cwrite = p2cwrite.Detach()\n    p2cwrite = msvcrt.open_osfhandle(p2cwrite, 0)\nelif isinstance(stdin, int):\n    p2cread = msvcrt.get_osfhandle(stdin)\nelse:\n    # Assuming file-like object\n    p2cread = msvcrt.get_osfhandle(stdin.fileno())\np2cread = self._make_inheritable(p2cread)\n\nif stdout is None:\n    c2pwrite = GetStdHandle(STD_OUTPUT_HANDLE)\nelif stdout == PIPE:\n    c2pread, c2pwrite = CreatePipe(None, 0)\n    # Detach and turn into fd\n    c2pread = c2pread.Detach()\n    c2pread = msvcrt.open_osfhandle(c2pread, 0)\nelif isinstance(stdout, int):\n    c2pwrite = msvcrt.get_osfhandle(stdout)\nelse:\n    # Assuming file-like object\n    c2pwrite = msvcrt.get_osfhandle(stdout.fileno())\nc2pwrite = self._make_inheritable(c2pwrite)\n\nif stderr is None:\n    errwrite = GetStdHandle(STD_ERROR_HANDLE)\nelif stderr == PIPE:\n    errread, errwrite = CreatePipe(None, 0)\n    # Detach and turn into fd\n    errread = errread.Detach()\n    errread = msvcrt.open_osfhandle(errread, 0)\nelif stderr == STDOUT:\n    errwrite = c2pwrite\nelif isinstance(stderr, int):\n    errwrite = msvcrt.get_osfhandle(stderr)\nelse:\n    # Assuming file-like object\n    errwrite = msvcrt.get_osfhandle(stderr.fileno())\nerrwrite = self._make_inheritable(errwrite)\n\nreturn (p2cread, p2cwrite,\n        c2pread, c2pwrite,\n        errread, errwrite)", "path": "certmaster\\sub_process.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "'''Yield (name, value) pairs for every option in the instance.\n\nThe value returned is the parsed, validated option value.\n'''\n# Use dir() so that we see inherited options too\n", "func_signal": "def iteritems(self):\n", "code": "for name in dir(self):\n    if self.isoption(name):\n        yield (name, getattr(self, name))", "path": "certmaster\\config.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "\"\"\"Find and return absolut path to w9xpopen.exe\"\"\"\n", "func_signal": "def _find_w9xpopen(self):\n", "code": "w9xpopen = os.path.join(os.path.dirname(GetModuleFileName(0)),\n                        \"w9xpopen.exe\")\nif not os.path.exists(w9xpopen):\n    # Eeek - file-not-found - possibly an embedding\n    # situation - see if we can locate it in sys.exec_prefix\n    w9xpopen = os.path.join(os.path.dirname(sys.exec_prefix),\n                            \"w9xpopen.exe\")\n    if not os.path.exists(w9xpopen):\n        raise RuntimeError(\"Cannot locate w9xpopen.exe, which is \"\n                           \"needed for Popen to work with your \"\n                           \"shell or platform.\")\nreturn w9xpopen", "path": "certmaster\\sub_process.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "\"\"\"Wait for child process to terminate.  Returns returncode\nattribute.\"\"\"\n", "func_signal": "def wait(self):\n", "code": "if self.returncode is None:\n    pid, sts = os.waitpid(self.pid, 0)\n    self._handle_exitstatus(sts)\nreturn self.returncode", "path": "certmaster\\sub_process.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "\"\"\"Run command with arguments.  Wait for command to complete.  If\nthe exit code was zero then return, otherwise raise\nCalledProcessError.  The CalledProcessError object will have the\nreturn code in the returncode attribute.\n\nThe arguments are the same as for the Popen constructor.  Example:\n\ncheck_call([\"ls\", \"-l\"])\n\"\"\"\n", "func_signal": "def check_call(*popenargs, **kwargs):\n", "code": "retcode = call(*popenargs, **kwargs)\ncmd = kwargs.get(\"args\")\nif cmd is None:\n    cmd = popenargs[0]\nif retcode:\n    raise CalledProcessError(retcode, cmd)\nreturn retcode", "path": "certmaster\\sub_process.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "\"\"\"\nIdentify common network errors that mean we cannot connect to the server\n\"\"\"\n\n# This is a bit complicated by the fact that different versions of\n# M2Crypto & OpenSSL seem to return different error codes for the\n# same type of error\n", "func_signal": "def canIgnoreSSLError(e):\n", "code": "s = \"%s\" % e\nif e[0] == 104:     # Connection refused\n    return True\nelif e[0] == 111:   # Connection reset by peer\n    return True\nelif e[0] == 61:    # Connection refused\n    return True\nelif e[0] == 54:    # Connection reset by peer\n    return True\nelif s == \"no certificate returned\":\n    return True\nelif s == \"wrong version number\":\n    return True\nelif s == \"unexpected eof\":\n    return True\n\nreturn False", "path": "certmaster\\CommonErrors.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "\"\"\"Check if child process has terminated.  Returns returncode\nattribute.\"\"\"\n", "func_signal": "def poll(self, _deadstate=None):\n", "code": "if self.returncode is None:\n    try:\n        pid, sts = os.waitpid(self.pid, os.WNOHANG)\n        if pid == self.pid:\n            self._handle_exitstatus(sts)\n    except os.error:\n        if _deadstate is not None:\n            self.returncode = _deadstate\nreturn self.returncode", "path": "certmaster\\sub_process.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "'''Return the Option instance for the given name\n'''\n", "func_signal": "def optionobj(cls, name):\n", "code": "obj = getattr(cls, name, None)\nif isinstance(obj, Option):\n    return obj\nelse:\n    raise KeyError", "path": "certmaster\\config.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "\"\"\"Check if child process has terminated.  Returns returncode\nattribute.\"\"\"\n", "func_signal": "def poll(self, _deadstate=None):\n", "code": "if self.returncode is None:\n    if WaitForSingleObject(self._handle, 0) == WAIT_OBJECT_0:\n        self.returncode = GetExitCodeProcess(self._handle)\nreturn self.returncode", "path": "certmaster\\sub_process.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "'''Clone an Option instance for the purposes of inheritance. The returned\ninstance has all the same properties as the input Option and shares items\nsuch as the default value. Use this to avoid redefinition of reused\noptions.\n\n@param option_obj: Option instance to inherit.\n@return: New Option instance inherited from the input.\n'''\n", "func_signal": "def Inherit(option_obj):\n", "code": "new_option = option_obj.clone()\nnew_option.inherit = True\nreturn new_option", "path": "certmaster\\config.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "'''Return True if the given name refers to a defined option \n'''\n", "func_signal": "def isoption(cls, name):\n", "code": "try:\n    cls.optionobj(name)\n    return True\nexcept KeyError:\n    return False", "path": "certmaster\\config.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "\"\"\"Converts a string from the config file to a workable list\n\nCommas and spaces are used as separators for the list\n\"\"\"\n# we need to allow for the '\\n[whitespace]' continuation - easier\n# to sub the \\n with a space and then read the lines\n", "func_signal": "def parse(self, s):\n", "code": "s = s.replace('\\n', ' ')\ns = s.replace(',', ' ')\nreturn s.split()", "path": "certmaster\\config.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "'''Return a user friendly list of the allowed schemes\n'''\n", "func_signal": "def _schemelist(self):\n", "code": "if len(self.schemes) < 1:\n    return 'empty'\nelif len(self.schemes) == 1:\n    return self.schemes[0]\nelse:\n    return '%s or %s' % (', '.join(self.schemes[:-1]), self.schemes[-1])", "path": "certmaster\\config.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "\"\"\"Return a duplicate of handle, which is inheritable\"\"\"\n", "func_signal": "def _make_inheritable(self, handle):\n", "code": "return DuplicateHandle(GetCurrentProcess(), handle,\n                       GetCurrentProcess(), 0, 1,\n                       DUPLICATE_SAME_ACCESS)", "path": "certmaster\\sub_process.py", "repo_name": "mpdehaan/certmaster", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 252}
{"docstring": "\"\"\" Decide if the URL is absolute or not \"\"\"\n", "func_signal": "def IsAbsolute(loc):\n", "code": "if not loc:\n  return False\nnarrow = encoder.NarrowText(loc, None)\n(scheme, netloc, path, query, frag) = urlparse.urlsplit(narrow)\nif (not scheme) or (not netloc):\n  return False\nreturn True", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\"Return our URL to our parent.\"\"\"\n", "func_signal": "def Close(self):\n", "code": "if self._loc:\n  temp = self._loc\n  self._loc = None\n  return temp\noutput.Warn('In the Sitemap index file, a \"sitemap\" entry had no \"loc\".')", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\" Dump the contents, empty or not, to the log. \"\"\"\n", "func_signal": "def Log(self, prefix='URL', level=3):\n", "code": "out = prefix + ':'\n\nfor attribute in self.__slots__:\n  value = getattr(self, attribute)\n  if not value:\n    value = ''\n  out = out + ('  %s=[%s]' % (attribute, value))\n\noutput.Log('%s' % encoder.NarrowText(out, None), level)", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\" Log some stats for the URL.  At the moment, that means extension. \"\"\"\n", "func_signal": "def Consume(self, url):\n", "code": "if url and url.loc:\n  (scheme, netloc, path, query, frag) = urlparse.urlsplit(url.loc)\n  if not path:\n    return\n\n  # Recognize directories\n  if path.endswith('/'):\n    if self._extensions.has_key('/'):\n      self._extensions['/'] = self._extensions['/'] + 1\n    else:\n      self._extensions['/'] = 1\n    return\n\n  # Strip to a filename\n  i = path.rfind('/')\n  if i >= 0:\n    assert i < len(path)\n    path = path[i:]\n\n  # Find extension\n  i = path.rfind('.')\n  if i > 0:\n    assert i < len(path)\n    ext = path[i:].lower()\n    if self._extensions.has_key(ext):\n      self._extensions[ext] = self._extensions[ext] + 1\n    else:\n      self._extensions[ext] = 1\n  else:\n    if self._extensions.has_key('(no extension)'):\n      self._extensions['(no extension)'] = self._extensions[\n        '(no extension)'] + 1\n    else:\n      self._extensions['(no extension)'] = 1", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\"Given a list of URLs, munge them into our self._pathlist property.\nWe do this by assuming all the files live in the same directory as\nthe first file in the existing pathlist.  That is, we assume a\nSitemap index points to Sitemaps only in the same directory.  This\nis not true in general, but will be true for any output produced\nby this script.\n\"\"\"\n", "func_signal": "def _MungeLocationListIntoFiles(self, urllist):\n", "code": "assert self._pathlist\npath = self._pathlist[0]\npath = os.path.normpath(path)\ndir  = os.path.dirname(path)\nwide = False\nif type(path) == types.UnicodeType:\n  wide = True\n\nfor url in urllist:\n  url = URL.Canonicalize(URL(), url)\n  output.Log('Index points to Sitemap file at: %s' % url, 2)\n  (scheme, netloc, path, query, frag) = urlparse.urlsplit(url)\n  file = os.path.basename(path)\n  file = urllib.unquote(file)\n  if wide:\n    file = encoder.WidenText(file)\n  if dir:\n    file = dir + os.sep + file\n  if file:\n    self._pathlist.append(file)\n    output.Log('Will attempt to read Sitemap file: %s' % file, 1)", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\"Initialize with a dictionary of attributes from our entry in the\nconfig file.\"\"\"\n", "func_signal": "def __init__(self, attributes):\n", "code": "xml.sax.handler.ContentHandler.__init__(self)\nself._pathlist      = None              # A list of files\nself._current       = -1                # Current context in _contexts\nself._contexts      = None              # The stack of contexts we allow\nself._contexts_idx  = None              # ...contexts for index files\nself._contexts_stm  = None              # ...contexts for Sitemap files\n\nif not ValidateAttributes('SITEMAP', attributes, ['path']):\n  return\n\n# Init the first file path\npath = attributes.get('path')\nif path:\n  path = encoder.MaybeNarrowPath(path)\n  if os.path.isfile(path):\n    output.Log('Input: From SITEMAP \"%s\"' % path, 2)\n    self._pathlist = [path]\n  else:\n    output.Error('Can not locate file \"%s\"' % path)\nelse:\n  output.Error('Sitemap entries must have a \"path\" attribute.')", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\"\nParse command line flags per specified usage, pick off key, value pairs\nAll flags of type \"--key=value\" will be processed as __flags[key] = value,\n                  \"--option\" will be processed as __flags[option] = option\n\"\"\"\n\n", "func_signal": "def ProcessCommandFlags(args):\n", "code": "flags   = {}\nrkeyval = '--(?P<key>\\S*)[=](?P<value>\\S*)' # --key=val\nroption = '--(?P<option>\\S*)'               # --key\nr = '(' + rkeyval + ')|(' + roption + ')'\nrc = re.compile(r)\nfor a in args:\n  try:\n    rcg = rc.search(a).groupdict()\n    if rcg.has_key('key'):\n      flags[rcg['key']] = rcg['value']\n    if rcg.has_key('option'):\n      flags[rcg['option']] = rcg['option']\n  except AttributeError:\n    return None\nreturn flags", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\" Verify the data in this URL is well-formed, and override if not. \"\"\"\n", "func_signal": "def Validate(self, base_url, allow_fragment):\n", "code": "assert type(base_url) == types.StringType\n\n# Test (and normalize) the ref\nif not self.loc:\n  output.Warn('Empty URL')\n  return False\nif allow_fragment:\n  self.loc = urlparse.urljoin(base_url, self.loc)\nif not self.loc.startswith(base_url):\n  output.Log('Discarded URL for not starting with the base_url: %s' %\n              self.loc, 2)\n  self.loc = None\n  return False\n\n# Test the lastmod\nif self.lastmod:\n  match = False\n  self.lastmod = self.lastmod.upper()\n  for pattern in LASTMOD_PATTERNS:\n    match = pattern.match(self.lastmod)\n    if match:\n      break\n  if not match:\n    output.Warn('Lastmod \"%s\" does not appear to be in ISO8601 format on '\n                'URL: %s' % (self.lastmod, self.loc))\n    self.lastmod = None\n\n# Test the changefreq\nif self.changefreq:\n  match = False\n  self.changefreq = self.changefreq.lower()\n  for pattern in CHANGEFREQ_PATTERNS:\n    if self.changefreq == pattern:\n      match = True\n      break\n  if not match:\n    output.Warn('Changefreq \"%s\" is not a valid change frequency on URL '\n                ': %s' % (self.changefreq, self.loc))\n    self.changefreq = None\n\n# Test the priority\nif self.priority:\n  priority = -1.0\n  try:\n    priority = float(self.priority)\n  except ValueError:\n    pass\n  if (priority < 0.0) or (priority > 1.0):\n    output.Warn('Priority \"%s\" is not a number between 0 and 1 inclusive '\n                'on URL: %s' % (self.priority, self.loc))\n    self.priority = None\n\nreturn True", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\" Try to tokenize a logfile line according to CLF pattern and see if\nit works. \"\"\"\n", "func_signal": "def RecognizeCLFLine(self, line):\n", "code": "match = ACCESSLOG_CLF_PATTERN.match(line)\nrecognize = match and (match.group(2) in ('HEAD', 'GET'))\nif recognize:\n  output.Log('Recognized a Common Logfile Format file.', 2)\nreturn recognize", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\"Returns True iff opening a sub-tag is valid in this context.\"\"\"\n", "func_signal": "def AcceptTag(self, tag):\n", "code": "valid = tag in self._allowed_tags\nif valid:\n  self._last_tag = tag\nelse:\n  self._last_tag = None\nreturn valid", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\" Widen a piece of arbitrary text \"\"\"\n", "func_signal": "def WidenText(self, text, encoding):\n", "code": "if type(text) != types.StringType:\n  return text\n\n# Try the passed in preference\nif encoding:\n  try:\n    result = unicode(text, encoding)\n    if not encoding in self._learned:\n      self._learned.append(encoding)\n    return result\n  except UnicodeError:\n    pass\n  except LookupError:\n    output.Warn('Unknown encoding: %s' % encoding)\n\n# Try the user preference\nif self._user:\n  try:\n    return unicode(text, self._user)\n  except UnicodeError:\n    pass\n  except LookupError:\n    temp = self._user\n    self._user = None\n    output.Warn('Unknown default_encoding: %s' % temp)\n\n# Look through learned defaults, knock any failing ones out of the list\nwhile self._learned:\n  try:\n    return unicode(text, self._learned[0])\n  except:\n    del self._learned[0]\n\n# When all other defaults are exhausted, use UTF-8\ntry:\n  return unicode(text, ENC_UTF8)\nexcept UnicodeError:\n  pass\n\n# Getting here means it wasn't UTF-8 and we had no working default.\n# We really don't have anything \"right\" we can do anymore.\noutput.Warn('Unrecognized encoding in text: %s' % text)\nif not self._user:\n  output.Warn('You may need to set a default_encoding in your '\n              'configuration file.')\nreturn text.decode(ENC_ASCII, 'ignore')", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\" Run over all the Inputs and ask them to Produce \"\"\"\n# Run the inputs\n", "func_signal": "def Generate(self):\n", "code": "for input in self._inputs:\n  input.ProduceURLs(self.ConsumeURL)\n\n# Do last flushes\nif len(self._set):\n  self.FlushSet()\nif not self._sitemaps:\n  output.Warn('No URLs were recorded, writing an empty sitemap.')\n  self.FlushSet()\n\n# Write an index as needed\nif self._sitemaps > 1:\n  self.WriteIndex()\n\n# Notify\nself.NotifySearch()\n\n# Dump stats\nself._stat.Log()", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\" Dump non-empty contents to the output file, in XML format. \"\"\"\n", "func_signal": "def WriteXML(self, file):\n", "code": "if not self.loc:\n  return\nout = SITEURL_XML_PREFIX\n\nfor attribute in self.__slots__:\n  value = getattr(self, attribute)\n  if value:\n    if attribute == 'mobile' and value == True:\n      out = out + '  <mobile:mobile/>\\r\\n'\n    elif attribute == 'ignore_querystring':\n      continue\n    else:\n      if type(value) == types.UnicodeType:\n        value = encoder.NarrowText(value, None)\n      elif type(value) != types.StringType:\n        value = str(value)\n      value = xml.sax.saxutils.escape(value)\n      out = out + ('  <%s>%s</%s>\\n' % (attribute, value, attribute))\n\nout = out + SITEURL_XML_SUFFIX\nfile.write(out)", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\" Verifies (and cleans up) the basic user-configurable options. \"\"\"\n", "func_signal": "def ValidateBasicConfig(self):\n", "code": "all_good = True\n\nif self._default_enc:\n  encoder.SetUserEncoding(self._default_enc)\n\n# Canonicalize the base_url\nif all_good and not self._base_url:\n  output.Error('A site needs a \"base_url\" attribute.')\n  all_good = False\nif all_good and not URL.IsAbsolute(self._base_url):\n    output.Error('The \"base_url\" must be absolute, not relative: %s' %\n                 self._base_url)\n    all_good = False\nif all_good:\n  url            = URL()\n  self._base_url = URL.Canonicalize(url, self._base_url)\n  if not self._base_url.endswith('/'):\n    self._base_url = self._base_url + '/'\n  output.Log('BaseURL is set to: %s' % self._base_url, 2)\n\n# Load store_into into a generator\nif all_good:\n  if self._store_into:\n    self._filegen = FilePathGenerator()\n    if not self._filegen.Preload(self._store_into):\n      all_good = False\n  else:\n    output.Error('A site needs a \"store_into\" attribute.')\n    all_good = False\n\n# Ask the generator for patterns on what its output will look like\nif all_good:\n  self._wildurl1 = self._filegen.GenerateWildURL(self._base_url)\n  self._wildurl2 = self._filegen.GenerateURL(SITEINDEX_SUFFIX,\n                                             self._base_url)\n\n# Unify various forms of False\nif all_good:\n  if self._suppress:\n    if (type(self._suppress) == types.StringType) or (type(self._suppress)\n                             == types.UnicodeType):\n      if (self._suppress == '0') or (self._suppress.lower() == 'false'):\n        self._suppress = False\n\n# Done\nif not all_good:\n  output.Log('See \"example_config.xml\" for more information.', 0)\nreturn all_good", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\" Process the URL, as above. \"\"\"\n", "func_signal": "def Apply(self, url):\n", "code": "if (not url) or (not url.loc):\n  return None\n\nif self._wildcard:\n  if fnmatch.fnmatchcase(url.loc, self._wildcard):\n    return self._pass\n  return None\n\nif self._regexp:\n  if self._regexp.search(url.loc):\n    return self._pass\n  return None\n\nassert False # unreachable", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\" SAX processing, called per node in the config stream. \"\"\"\n", "func_signal": "def endElement(self, tag):\n", "code": "if tag == 'site':\n  assert self._in_site\n  self._in_site      = False\n  self._in_site_ever = True", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\"SAX processing, called per node in the config stream.\nThis becomes a call to Close on one context followed by a call\nto Return on the previous.\n\"\"\"\n", "func_signal": "def endElement(self, tag):\n", "code": "tag = tag  # Avoid warning on unused argument\nassert self._current >= 0\nretval = self._contexts[self._current].Close()\nself._current = self._current - 1\nif self._current >= 0:\n  self._contexts[self._current].Return(retval)\nelif retval and (self._contexts == self._contexts_idx):\n  self._MungeLocationListIntoFiles(retval)", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\" Produces URLs from our data source, hands them in to the consumer. \"\"\"\n", "func_signal": "def ProduceURLs(self, consumer):\n", "code": "if self._url:\n  consumer(self._url, True)", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\" Generates a wildcard that should match all our iterations \"\"\"\n", "func_signal": "def GenerateWildURL(self, root_url):\n", "code": "prefix = URL.Canonicalize(URL(), root_url + self._prefix)\ntemp   = URL.Canonicalize(URL(), prefix + self._suffix)\nsuffix = temp[len(prefix):]\nreturn prefix + '*' + suffix", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\" Opens a text file, be it GZip or plain \"\"\"\n\n", "func_signal": "def OpenFileForRead(path, logtext):\n", "code": "frame = None\nfile  = None\n\nif not path:\n  return (frame, file)\n\ntry:\n  if path.endswith('.gz'):\n    frame = open(path, 'rb')\n    file = gzip.GzipFile(fileobj=frame, mode='rt')\n  else:\n    file = open(path, 'rt')\n\n  if logtext:\n    output.Log('Opened %s file: %s' % (logtext, path), 1)\n  else:\n    output.Log('Opened file: %s' % path, 1)\nexcept IOError:\n  output.Error('Can not open file: %s' % path)\n\nreturn (frame, file)", "path": "sitemap_gen_mobile.py", "repo_name": "gami/sitemap_gen_mobile", "stars": 2, "license": "other", "language": "python", "size": 104}
{"docstring": "\"\"\"\nUkoncenie workunitu\n\"\"\"\n", "func_signal": "def abort_result(self, url, name, callback = None):\n", "code": "(dom, request) = self.createRpcRequest()\n\t\nabortResultNode = dom.createElement('abort_result')\nrequest.appendChild(abortResultNode)\n\nself.__addResultInfo(dom, abortResultNode, url, name)\nrequest = dom.toxml()\ndom.unlink()\nself.__conn.sendData(request, self.__recvActionState, callback)", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nVytiahnutie elementy boinc_gui_rpc_reply z retazca\n\nNavratovou hodnotou je DOM a uzol boinc_gui_rpc_reply. DOM je nutne\nrucne dealokovat pomocou metody unlink().\n\"\"\"\n", "func_signal": "def getReply(self,  data):\n", "code": "dataDom = minidom.parseString(data)\nreply = dataDom.documentElement\nif reply.nodeName != \"boinc_gui_rpc_reply\":\n\traise BoincCommException(\"boinc_gui_rpc_reply not found\")\nreturn (dataDom, reply)", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nSpracovanie stringu(data), vytiahnutie tagu, prevod na dict, volanie call\n\"\"\"\n", "func_signal": "def __recvXml(self, data, tag, call = None):\n", "code": "dom, reply = self.getReply(data)\nnodes = reply.getElementsByTagName(tag)\nif nodes.length != 1:\n\tdom.unlink()\n\traise BoincCommException(tag)\nnode = nodes[0]\ndata = self.__xmlToDict(node)\nif call is None:\n\tdom.unlink()\n\treturn data\nelse:\n\tcall(data)\ndom.unlink()", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nVytvorenie noveho rozhania pre pripojenie k systemu BOINC\n\nPripojenie k hostovi (host) cez port (port) s heslom (password) a\nfrontou pre chyby (queue). Pripojenie nie je automaticke.\n\"\"\"\n", "func_signal": "def __init__(self,  host = \"127.0.0.1\",  port = 31416,  password = None, queue = None):\n", "code": "self.__host = str(host)\nself.__port = port\nself.__password = str(password)\nself.__queue = queue", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nPrva faza autorizacie - poslanie prihlasovacich udajov\n\"\"\"\n", "func_signal": "def __auth1(self,  data):\n", "code": "dom, reply = self.getReply(data)\n\nnonceNodes = reply.getElementsByTagName(\"nonce\")\nif nonceNodes.length != 1:\n\tdom.unlink()\n\traise BoincCommException(\"nonce not found\")\nnonceNode = nonceNodes[0]\nnonce = nonceNode.childNodes[0].data\n\nreply = md5.new(nonce+self.__password).hexdigest()\n(doc,  boincGuiRpcRequestElement) = self.createRpcRequest();\nauth2Element = doc.createElement(\"auth2\")\nboincGuiRpcRequestElement.appendChild(auth2Element)\n\nnHashElement = doc.createElement(\"nonce_hash\")\nauth2Element.appendChild(nHashElement)\nnHText = doc.createTextNode(reply)\nnHashElement.appendChild(nHText)\n\nself.__conn.sendData(doc.toxml(),  self.__auth2)\n\ndom.unlink()\ndoc.unlink()", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nOdpojenie sa od klienta, cakanie na ukoncenie sietovych operacii.\n\"\"\"\n", "func_signal": "def disconnect(self):\n", "code": "self.__quit = True\nself.__mutex.acquire()\nif not self.__thread is None:\n\tself.sendData(\"\")\n\tself.__thread.join()\n\tself.__thread = None\n\tif not self.__sock is None:\n\t\tself.__sock.close()\nself.__mutex.release()", "path": "Boinc\\connection.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nPripojenie sa k zvolenemu pc\n\nHost moze byt IP alebo dns adresa pocitaca. Dalej je potrebne uviest\nport na ktory sa pripajame a frontu do ktorej budu posielane chyby.\nPoslednym nepovinnym parametrom (connStateCallback je funkcia ktora\nsa bude volat v pripade zmeny stavu pripojenia)\n\"\"\"\n", "func_signal": "def __init__(self,  host,  port, errQueue, connStateCallback = None):\n", "code": "self.__host = host\nself.__port = port\nself.__commLock = thread.allocate_lock()\nself.__errQueue = errQueue\nself.__connStateCallback = connStateCallback\nself.__sendQueue = Queue()\nself.__mutex = Lock()\nself.__thread = None\nthread.start_new_thread(self.__connectThread, (connStateCallback, ))", "path": "Boinc\\connection.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nZmena stavu pripojenia\n\"\"\"\n", "func_signal": "def __connStateChanged(self, info):\n", "code": "if isinstance(info, Exception):\n\tself.__queue.put(info)\n\tself.__connStateFunc(0)\nelse:\n\tself.__connStateFunc(info)", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nPridanie potrebnych informacii do uzlu (node) o workunite pre akcie s workunitom\n\"\"\"\n", "func_signal": "def __addResultInfo(self, dom, node, url, name):\n", "code": "self.__add_text_node(dom, node, 'project_url', url)\nself.__add_text_node(dom, node, 'name', name)", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nZiskanie celeho cisla z potomka uzla (node) s menom (name).\n\"\"\"\n", "func_signal": "def __getInt(self, node, name):\n", "code": "string = self.__getStr(node, name)\nif string is None:\n\treturn None\ntry:\n\treturn int(string)\nexcept ValueError:\n\ttry:\n\t\treturn int(float(string))\n\texcept ValueError:\n\t\treturn None\n\treturn None", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nDruha faza autorizacie - prijatie informacie o uspesnosti autorizacie\n\"\"\"\n", "func_signal": "def __auth2(self, data):\n", "code": "dom, reply = self.getReply(data)\nauthNodes = reply.getElementsByTagName(\"authorized\")\nif authNodes.length != 1:\n\tself.__connStateFunc(self.unauthorized)\n\tdom.unlink()\n\traise BoincCommException(\"unauthorized\")\nelse:\n\tif not self.__connStateFunc is None:\n\t\tself.__connStateFunc(self.connected)\ndom.unlink()", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nZiskanie textu z netextoveho uzla ktory ma 1 potomka - TEXT_NODE\n\"\"\"\n", "func_signal": "def __getText(self, node):\n", "code": "childNodes = node.childNodes\nif len(childNodes) != 1:\n\treturn None\nvysledokNode = childNodes[0]\nif vysledokNode.nodeType != Node.TEXT_NODE:\n\treturn None\nreturn vysledokNode.nodeValue", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nOdpojenie od klienta BOINC\n\"\"\"\n", "func_signal": "def disconnect(self):\n", "code": "self.__connStateFunc = None;\nself.__conn.disconnect()\nself.__queue = None;\nself.__conn = None", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nFunkcia pre ziskanie informacii uspesnosti volania poziadavky\n\nPo uspesnom volani vracia False, inac vracia text chyby. Tato funkcia\nsa da pouzit len pre prijate v tvare\n<boinc_gui_rpc_reply>\n  <sucess /> alebo <error>sprava o chybe</error>\n</boinc_gui_rpc_reply>\n\"\"\"\n", "func_signal": "def __getReplyState(self, reply):\n", "code": "if len(reply.getElementsByTagName('success')) > 0:\n\treturn False\nelse:\n\terrorNodes = reply.getElementsByTagName('error')\n\tif len(errorNodes) > 0:\n\t\treturn self.__getText(errorNodes[0])", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nPrijatie stavu jednoduchej akcie\n\"\"\"\n", "func_signal": "def __recvActionState(self, data, callback = None):\n", "code": "dom, reply = self.getReply(data)\nstate = self.__getReplyState(reply)\ndom.unlink()\nif not callback is None:\n\tcallback(state)", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nPokracovanie v praci na workunite\n\"\"\"\n", "func_signal": "def resume_result(self, url, name, callback = None):\n", "code": "(dom, request) = self.createRpcRequest()\n\t\nresumeResultNode = dom.createElement('resume_result')\nrequest.appendChild(resumeResultNode)\n\nself.__addResultInfo(dom, resumeResultNode, url, name)\nrequest = dom.toxml()\ndom.unlink()\nself.__conn.sendData(request, self.__recvActionState, callback)", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nVytvorenie jednoduchej akcie s projektom (ako update a pod.)\n\"\"\"\n", "func_signal": "def __createProjectActionRequest(self, actionName, projectUrl):\n", "code": "(dom, request) = self.createRpcRequest()\nactionNode = dom.createElement(actionName)\nrequest.appendChild(actionNode)\n\nself.__add_text_node(dom, actionNode, 'project_url', projectUrl)\n\nrequest = dom.toxml()\ndom.unlink()\nreturn request", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nPokracovanie v projekte\n\"\"\"\n", "func_signal": "def project_resume(self, project, callback = None):\n", "code": "request = self.__createProjectActionRequest('project_resume', project)\nself.__conn.sendData(request, self.__recvActionState, callback)", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nKonverzia xml DOM uzla na slovnik\n\"\"\"\n", "func_signal": "def __xmlToDict(self, node):\n", "code": "slovnik = {}\nchildNodes = node.childNodes;\nif childNodes.length == 1 and childNodes[0].nodeType == Node.TEXT_NODE:\n\treturn childNodes[0].nodeValue\n\nfor n in childNodes:\n\tif n.nodeType == Node.ELEMENT_NODE:\n\t\ttry:\n\t\t\tif type(slovnik[n.nodeName]) == type([]):\n\t\t\t\tslovnik[n.nodeName].append(self.__xmlToDict(n))\n\t\t\telse:\n\t\t\t\tval = slovnik[n.nodeName]\n\t\t\t\tslovnik[n.nodeName] = [val, self.__xmlToDict(n)]\n\t\texcept KeyError:\n\t\t\tslovnik[n.nodeName] = self.__xmlToDict(n)\nreturn slovnik", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"\nVytvorenie dom pre request\n\nVsetky requesty maju tvar\n<boinc_gui_rpc_request></boinc_gui_rpc_request>\nTatp funkcia vytvori prave taku strukturu a vracia objekt typu tuple\ns polozkamy DOM a uzol boinc_gui_rpc_request. DOM je nutne rucne\ndealokovat pomocou metody unlink().\n\"\"\"\n", "func_signal": "def createRpcRequest(self):\n", "code": "doc = minidom.Document();\nboincGuiRpcRequestElement = doc.createElement(\"boinc_gui_rpc_request\")\ndoc.appendChild(boincGuiRpcRequestElement)\nreturn (doc,  boincGuiRpcRequestElement)", "path": "Boinc\\interface.py", "repo_name": "mireq/pyboincgui", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 300}
{"docstring": "\"\"\"Join channel. If password protected, provide key.\"\"\"\n\n", "func_signal": "def join(self, channel, key=None):\n", "code": "if key:\n    self.wline('JOIN %s %s' %(channel, key))\nelse:\n    self.wline('JOIN %s' % channel)", "path": "im\\irc.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Remember this message for someone (Or help them figure out how this works.\"\"\"\n\n", "func_signal": "def remember(line, state, sockwriter):\n", "code": "if len(line.message().split()) < 3:\n    sockwriter.nreply('Usage: !remind <nick> <message>')\nelse:\n    nick = line.message().split()[1]\n    message = ' '.join(line.message().split()[2:])\n    state.messages[nick] = state.messages.get(nick, []) + [(line.nick(), message)]\n    sockwriter.nreply('Will remind %s about %s.' % (nick, message))", "path": "example.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Make a debug dump of all available information.\"\"\"\n\n", "func_signal": "def debug_dump(self):\n", "code": "info = {}\ntry:\n    info['target'] = self.target()\nexcept ParseError:\n    pass\ninfo['nick'] = self.nick()\ninfo['command'] = self.command()\ninfo['params'] = self.params()\ninfo['message'] = self.message()\ninfo['hostmask'] = self.hostmask()\nreturn info", "path": "im\\irc.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Kick nick from channel, optionally providing a comment.\"\"\"\n\n", "func_signal": "def kick(self, channel, nick, comment=None):\n", "code": "if comment:\n    self.wline('KICK %s %s %s' % (channel, nick, comment))\nelse:\n    self.wline('KICK %s %s' % (channel, nick))", "path": "im\\irc.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Send a ping to target.\"\"\"\n\n", "func_signal": "def ping(self, target=None):\n", "code": "if server is None:\n    self.wline('PING :%s' % self.dst)\nelse:\n    self.wline('PING :%s' % server)", "path": "im\\irc.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Log event.\"\"\"\n", "func_signal": "def log(self, event):\n", "code": "if self.logger:\n    self.logger(event)", "path": "im\\selector.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Which command was used?\"\"\"\n\n", "func_signal": "def command(self):\n", "code": "com = self.ircline.split()[1]\nreturn irc2num.num2rpl.get(com, com)", "path": "im\\irc.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Register this irc client.\n\nSends nick, user and ircname.\"\"\"\n\n", "func_signal": "def register(self):\n", "code": "BufferedSockWriter.register(self)\nnick, user = self.state.nick(), self.state.user()\nircname = self.state.ircname()\nself.wline('NICK %s' % nick)\nself.wline('USER %s 0 * : %s' % (user, ircname))", "path": "im\\irc.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Join the channel, or tell the someone how to use our command.\"\"\"\n\n", "func_signal": "def join(line, state, sockwriter):\n", "code": "if len(line.message().split()) < 2:\n    sockwriter.nreply('Usage: !join <channel> [<key>]')\nelse:\n    channel = line.message().split()[1]\n    if len(line.message().split()) == 3:\n        key = line.message().split()[2]\n    else:\n        key = \"\"\n    sockwriter.join(channel, key)", "path": "example.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Send message to whoever asked something of this bot the\nlast time.\"\"\"\n\n", "func_signal": "def reply(self, message):\n", "code": "assert self.line\ntarget = self.line.target()\nif target == self.state.nick():\n    self.privmsg(self.line.nick(),\n                 message)\nelse:\n    self.privmsg(target, message)", "path": "im\\irc.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Run the irc who command.\"\"\"\n\n", "func_signal": "def who(self, mask, operator=False):\n", "code": "if operator:\n    self.wline('WHO %s o' % mask)\nelse:\n    self.wline('WHO %s' % mask)", "path": "im\\irc.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Instanciate a Reactor with a list of clients,\nand a logger, both of which may be None.\n\nA client supports three methods:\nclient.id() - should return a valid file descriptor.\n              in Python most file-like objects can give\n              you their fd by calling object.fileno().\nclient.do_io() - client should deal with it's io,\n                 by reading it and stowing it away in a\n                 buffer, or reacting to it in some way.\nclient.retry() - The client had a socket.error or IOError,\n                 and should try to fix it's problem.\n                 If this returns a false value, it is removed\n                 from the list of clients.\nA logger is simply a callable of one argument, and it's\nobviously meant to log that argument (Which may be a string,\nor an exception).\n\"\"\"\n", "func_signal": "def __init__(self, clients=None, logger=None):\n", "code": "if clients is None:\n    self.clients = []\nelse:\n    self.clients = clients\nself.logger = logger", "path": "im\\selector.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"A list of nicknames to use, an irc username, and an ircname.\"\"\"\n\n# Multiple nicknames, so if the server kicks us off\n# for busy nickname, we can use another.\n", "func_signal": "def __init__(self, nicknames, username, ircname):\n", "code": "self._nicks = nicknames\nself._user = username\nself._ircname = ircname\nself.current_nick = 0\nself.messages = {} # For a handler we'll write.", "path": "example.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Get the target of a command.\"\"\"\n\n", "func_signal": "def target(self):\n", "code": "if self.command() in ('PRIVMSG', 'NOTICE', 'TOPIC',\n                      'JOIN', 'PART', 'KICK'):\n    return self.params().split()[0]\nelse:\n    raise ParseError('Getting target of command %s not yet supported.' % self.command())", "path": "im\\irc.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Loop indefinitely, calling self.tick.\"\"\"\n\n", "func_signal": "def loop(self):\n", "code": "while True:\n    self.tick()", "path": "im\\selector.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Run the IRC names command.\"\"\"\n\n", "func_signal": "def names(self, channels):\n", "code": "if isinstance(channels, list):\n    self.wline('LIST %s' % ','.join(channels))\nelse:\n    self.wline('LIST %s' % channels)", "path": "im\\irc.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Takes two callables as arguments.\"\"\"\n\n", "func_signal": "def __init__(self, interested, run):\n", "code": "self.interested = interested\nself.run = run", "path": "example.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Give the reminders to the person.\"\"\"\n\n", "func_signal": "def tell(line, state, sockwriter):\n", "code": "nick = line.nick()\nmessages = state.messages.pop(nick)\nfor sender, message in messages:\n    sockwriter.notice(nick, '%s told me to remind you about %s' % (sender, message))", "path": "example.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"Send a notice. See privmsg for description of params.\"\"\"\n\n", "func_signal": "def notice(self, target, message):\n", "code": "if isinstance(message, list):\n    for line in message:\n        self.notice(target, message)\nelif isinstance(message, unicode):\n    message = message.encode('utf-8')\nwhile message:\n    line, message = message[:400], message[400:]\n    self.wline('NOTICE %s :%s' % (target, line))", "path": "im\\irc.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "# Select the next nickname to use.\n", "func_signal": "def nick(self):\n", "code": "        nick = self._nicks[self.current_nick]\n        self.current_nick = (self.current_nick + 1) % len(self._nicks)\n        return nick", "path": "example.py", "repo_name": "kaaveland/anybot", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 104}
{"docstring": "\"\"\"\nDetermine if a requested subsystem will be provided to the client on\nthe given channel.  If this method returns C{True}, all future I/O\nthrough this channel will be assumed to be connected to the requested\nsubsystem.  An example of a subsystem is C{sftp}.\n\nThe default implementation checks for a subsystem handler assigned via\nL{Transport.set_subsystem_handler}.\nIf one has been set, the handler is invoked and this method returns\nC{True}.  Otherwise it returns C{False}.\n\n@note: Because the default implementation uses the L{Transport} to\n    identify valid subsystems, you probably won't need to override this\n    method.\n\n@param channel: the L{Channel} the pty request arrived on.\n@type channel: L{Channel}\n@param name: name of the requested subsystem.\n@type name: str\n@return: C{True} if this channel is now hooked up to the requested\n    subsystem; C{False} if that subsystem can't or won't be provided.\n@rtype: bool\n\"\"\"\n", "func_signal": "def check_channel_subsystem_request(self, channel, name):\n", "code": "handler_class, larg, kwarg = channel.get_transport()._get_subsystem_handler(name)\nif handler_class is None:\n    return False\nhandler = handler_class(channel, name, self, *larg, **kwarg)\nhandler.start()\nreturn True", "path": "paramiko\\server.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nSet the access and modified times of the file specified by C{path}.  If\nC{times} is C{None}, then the file's access and modified times are set\nto the current time.  Otherwise, C{times} must be a 2-tuple of numbers,\nof the form C{(atime, mtime)}, which is used to set the access and\nmodified times, respectively.  This bizarre API is mimicked from python\nfor the sake of consistency -- I apologize.\n\n@param path: path of the file to modify\n@type path: str\n@param times: C{None} or a tuple of (access time, modified time) in\n    standard internet epoch time (seconds since 01 January 1970 GMT)\n@type times: tuple(int)\n\"\"\"\n", "func_signal": "def utime(self, path, times):\n", "code": "path = self._adjust_cwd(path)\nif times is None:\n    times = (time.time(), time.time())\nself._log(DEBUG, 'utime(%r, %r)' % (path, times))\nattr = SFTPAttributes()\nattr.st_atime, attr.st_mtime = times\nself._request(CMD_SETSTAT, path, attr)", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nChange the size of the file specified by C{path}.  This usually extends\nor shrinks the size of the file, just like the C{truncate()} method on\npython file objects.\n\n@param path: path of the file to modify\n@type path: str\n@param size: the new size of the file\n@type size: int or long\n\"\"\"\n", "func_signal": "def truncate(self, path, size):\n", "code": "path = self._adjust_cwd(path)\nself._log(DEBUG, 'truncate(%r, %r)' % (path, size))\nattr = SFTPAttributes()\nattr.st_size = size\nself._request(CMD_SETSTAT, path, attr)", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nRetrieve information about a file on the remote system, without\nfollowing symbolic links (shortcuts).  This otherwise behaves exactly\nthe same as L{stat}.\n\n@param path: the filename to stat\n@type path: str\n@return: an object containing attributes about the given file\n@rtype: SFTPAttributes\n\"\"\"\n", "func_signal": "def lstat(self, path):\n", "code": "path = self._adjust_cwd(path)\nself._log(DEBUG, 'lstat(%r)' % path)\nt, msg = self._request(CMD_LSTAT, path)\nif t != CMD_ATTRS:\n    raise SFTPError('Expected attributes')\nreturn SFTPAttributes._from_msg(msg)", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nChange the owner (C{uid}) and group (C{gid}) of a file.  As with\npython's C{os.chown} function, you must pass both arguments, so if you\nonly want to change one, use L{stat} first to retrieve the current\nowner and group.\n\n@param path: path of the file to change the owner and group of\n@type path: str\n@param uid: new owner's uid\n@type uid: int\n@param gid: new group id\n@type gid: int\n\"\"\"\n", "func_signal": "def chown(self, path, uid, gid):\n", "code": "path = self._adjust_cwd(path)\nself._log(DEBUG, 'chown(%r, %r, %r)' % (path, uid, gid))\nattr = SFTPAttributes()\nattr.st_uid, attr.st_gid = uid, gid\nself._request(CMD_SETSTAT, path, attr)", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nChange the mode (permissions) of a file.  The permissions are\nunix-style and identical to those used by python's C{os.chmod}\nfunction.\n\n@param path: path of the file to change the permissions of\n@type path: str\n@param mode: new permissions\n@type mode: int\n\"\"\"\n", "func_signal": "def chmod(self, path, mode):\n", "code": "path = self._adjust_cwd(path)\nself._log(DEBUG, 'chmod(%r, %r)' % (path, mode))\nattr = SFTPAttributes()\nattr.st_mode = mode\nself._request(CMD_SETSTAT, path, attr)", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nRemove the folder named C{path}.\n\n@param path: name of the folder to remove\n@type path: str\n\"\"\"\n", "func_signal": "def rmdir(self, path):\n", "code": "path = self._adjust_cwd(path)\nself._log(DEBUG, 'rmdir(%r)' % path)\nself._request(CMD_RMDIR, path)", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nReturn an adjusted path if we're emulating a \"current working\ndirectory\" for the server.\n\"\"\"\n", "func_signal": "def _adjust_cwd(self, path):\n", "code": "if type(path) is unicode:\n    path = path.encode('utf-8')\nif self._cwd is None:\n    return path\nif (len(path) > 0) and (path[0] == '/'):\n    # absolute path\n    return path\nif self._cwd == '/':\n    return self._cwd + path\nreturn self._cwd + '/' + path", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "# this method may be called from other threads (prefetch)\n", "func_signal": "def _async_request(self, fileobj, t, *arg):\n", "code": "self._lock.acquire()\ntry:\n    msg = Message()\n    msg.add_int(self.request_number)\n    for item in arg:\n        if type(item) is int:\n            msg.add_int(item)\n        elif type(item) is long:\n            msg.add_int64(item)\n        elif type(item) is str:\n            msg.add_string(item)\n        elif type(item) is SFTPAttributes:\n            item._pack(msg)\n        else:\n            raise Exception('unknown type for %r type %r' % (item, type(item)))\n    num = self.request_number\n    self._expecting[num] = fileobj\n    self._send_packet(t, str(msg))\n    self.request_number += 1\nfinally:\n    self._lock.release()\nreturn num", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nCopy a remote file (C{remotepath}) from the SFTP server to the local\nhost as C{localpath}.  Any exception raised by operations will be\npassed through.  This method is primarily provided as a convenience.\n\n@param remotepath: the remote file to copy\n@type remotepath: str\n@param localpath: the destination path on the local host\n@type localpath: str\n@param callback: optional callback function that accepts the bytes\n    transferred so far and the total bytes to be transferred\n    (since 1.7.4)\n@type callback: function(int, int)\n\n@since: 1.4\n\"\"\"\n", "func_signal": "def get(self, remotepath, localpath, callback=None):\n", "code": "fr = self.file(remotepath, 'rb')\nfile_size = self.stat(remotepath).st_size\nfr.prefetch()\nfl = file(localpath, 'wb')\nsize = 0\nwhile True:\n    data = fr.read(32768)\n    if len(data) == 0:\n        break\n    fl.write(data)\n    size += len(data)\n    if callback is not None:\n        callback(size, file_size)\nfl.close()\nfr.close()\ns = os.stat(localpath)\nif s.st_size != size:\n    raise IOError('size mismatch in get!  %d != %d' % (s.st_size, size))", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "# add the display name if required\n", "func_signal": "def get_as_xml(self):\n", "code": "display_name_xml = ''\nif self.display_name:\n    display_name_xml = self.DISPLAY_NAME_XML_TEMPLATE %(self.display_name)\n\nret = Question.QUESTION_XML_TEMPLATE % (self.identifier, \n                                        display_name_xml,\n                                        str(self.is_required).lower(),\n                                        self.content.get_as_xml(), \n                                        self.answer_spec.get_as_xml())\n\nreturn ret", "path": "boto\\mturk\\question.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nCreate a symbolic link (shortcut) of the C{source} path at\nC{destination}.\n\n@param source: path of the original file\n@type source: str\n@param dest: path of the newly created symlink\n@type dest: str\n\"\"\"\n", "func_signal": "def symlink(self, source, dest):\n", "code": "dest = self._adjust_cwd(dest)\nself._log(DEBUG, 'symlink(%r, %r)' % (source, dest))\nif type(source) is unicode:\n    source = source.encode('utf-8')\nself._request(CMD_SYMLINK, source, dest)", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nClose the SFTP session and its underlying channel.\n\n@since: 1.4\n\"\"\"\n", "func_signal": "def close(self):\n", "code": "self._log(INFO, 'sftp session closed.')\nself.sock.close()", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nRename a file or folder from C{oldpath} to C{newpath}.\n\n@param oldpath: existing name of the file or folder\n@type oldpath: str\n@param newpath: new name for the file or folder\n@type newpath: str\n\n@raise IOError: if C{newpath} is a folder, or something else goes\n    wrong\n\"\"\"\n", "func_signal": "def rename(self, oldpath, newpath):\n", "code": "oldpath = self._adjust_cwd(oldpath)\nnewpath = self._adjust_cwd(newpath)\nself._log(DEBUG, 'rename(%r, %r)' % (oldpath, newpath))\nself._request(CMD_RENAME, oldpath, newpath)", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nCopy a local file (C{localpath}) to the SFTP server as C{remotepath}.\nAny exception raised by operations will be passed through.  This\nmethod is primarily provided as a convenience.\n\nThe SFTP operations use pipelining for speed.\n\n@param localpath: the local file to copy\n@type localpath: str\n@param remotepath: the destination path on the SFTP server\n@type remotepath: str\n@param callback: optional callback function that accepts the bytes\n    transferred so far and the total bytes to be transferred\n    (since 1.7.4)\n@type callback: function(int, int)\n@return: an object containing attributes about the given file\n    (since 1.7.4)\n@rtype: SFTPAttributes\n\n@since: 1.4\n\"\"\"\n", "func_signal": "def put(self, localpath, remotepath, callback=None):\n", "code": "file_size = os.stat(localpath).st_size\nfl = file(localpath, 'rb')\nfr = self.file(remotepath, 'wb')\nfr.set_pipelined(True)\nsize = 0\nwhile True:\n    data = fl.read(32768)\n    if len(data) == 0:\n        break\n    fr.write(data)\n    size += len(data)\n    if callback is not None:\n        callback(size, file_size)\nfl.close()\nfr.close()\ns = self.stat(remotepath)\nif s.st_size != size:\n    raise IOError('size mismatch in put!  %d != %d' % (s.st_size, size))\nreturn s", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\ndecode a string as ascii or utf8 if possible (as required by the sftp\nprotocol).  if neither works, just return a byte string because the server\nprobably doesn't know the filename's encoding.\n\"\"\"\n", "func_signal": "def _to_unicode(s):\n", "code": "try:\n    return s.encode('ascii')\nexcept UnicodeError:\n    try:\n        return s.decode('utf-8')\n    except UnicodeError:\n        return s", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nRaises EOFError or IOError on error status; otherwise does nothing.\n\"\"\"\n", "func_signal": "def _convert_status(self, msg):\n", "code": "code = msg.get_int()\ntext = msg.get_string()\nif code == SFTP_OK:\n    return\nelif code == SFTP_EOF:\n    raise EOFError(text)\nelif code == SFTP_NO_SUCH_FILE:\n    # clever idea from john a. meinel: map the error codes to errno\n    raise IOError(errno.ENOENT, text)\nelif code == SFTP_PERMISSION_DENIED:\n    raise IOError(errno.EACCES, text)\nelse:\n    raise IOError(text)", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nRetrieve information about a file on the remote system.  The return\nvalue is an object whose attributes correspond to the attributes of\npython's C{stat} structure as returned by C{os.stat}, except that it\ncontains fewer fields.  An SFTP server may return as much or as little\ninfo as it wants, so the results may vary from server to server.\n\nUnlike a python C{stat} object, the result may not be accessed as a\ntuple.  This is mostly due to the author's slack factor.\n\nThe fields supported are: C{st_mode}, C{st_size}, C{st_uid}, C{st_gid},\nC{st_atime}, and C{st_mtime}.\n\n@param path: the filename to stat\n@type path: str\n@return: an object containing attributes about the given file\n@rtype: SFTPAttributes\n\"\"\"\n", "func_signal": "def stat(self, path):\n", "code": "path = self._adjust_cwd(path)\nself._log(DEBUG, 'stat(%r)' % path)\nt, msg = self._request(CMD_STAT, path)\nif t != CMD_ATTRS:\n    raise SFTPError('Expected attributes')\nreturn SFTPAttributes._from_msg(msg)", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nCreate a new interactive query to send to the client.  The name and\ninstructions are optional, but are generally displayed to the end\nuser.  A list of prompts may be included, or they may be added via\nthe L{add_prompt} method.\n\n@param name: name of this query\n@type name: str\n@param instructions: user instructions (usually short) about this query\n@type instructions: str\n@param prompts: one or more authentication prompts\n@type prompts: str\n\"\"\"\n", "func_signal": "def __init__(self, name='', instructions='', *prompts):\n", "code": "self.name = name\nself.instructions = instructions\nself.prompts = []\nfor x in prompts:\n    if (type(x) is str) or (type(x) is unicode):\n        self.add_prompt(x)\n    else:\n        self.add_prompt(x[0], x[1])", "path": "paramiko\\server.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "\"\"\"\nReturn the target of a symbolic link (shortcut).  You can use\nL{symlink} to create these.  The result may be either an absolute or\nrelative pathname.\n\n@param path: path of the symbolic link file\n@type path: str\n@return: target path\n@rtype: str\n\"\"\"\n", "func_signal": "def readlink(self, path):\n", "code": "path = self._adjust_cwd(path)\nself._log(DEBUG, 'readlink(%r)' % path)\nt, msg = self._request(CMD_READLINK, path)\nif t != CMD_NAME:\n    raise SFTPError('Expected name response')\ncount = msg.get_int()\nif count == 0:\n    return None\nif count != 1:\n    raise SFTPError('Readlink returned %d results' % count)\nreturn _to_unicode(msg.get_string())", "path": "paramiko\\sftp_client.py", "repo_name": "marshall/pynaries", "stars": 3, "license": "other", "language": "python", "size": 420}
{"docstring": "# To keep rendering order consistent, we can't just iterate over items().\n# We need to sort the keys, and iterate over the sorted list.\n", "func_signal": "def render_css(self):\n", "code": "media = self._css.keys()\nmedia.sort()\nreturn chain(*[\n    [u'<link href=\"%s\" type=\"text/css\" media=\"%s\" rel=\"stylesheet\" />' % (self.absolute_path(path), medium)\n            for path in self._css[medium]]\n        for medium in media])", "path": "app\\django\\forms\\widgets.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "# The 'rows' and 'cols' attributes are required for HTML correctness.\n", "func_signal": "def __init__(self, attrs=None):\n", "code": "self.attrs = {'cols': '40', 'rows': '10'}\nif attrs:\n    self.attrs.update(attrs)", "path": "app\\django\\forms\\widgets.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "# Override the default renderer if we were passed one.\n", "func_signal": "def __init__(self, *args, **kwargs):\n", "code": "renderer = kwargs.pop('renderer', None)\nif renderer:\n    self.renderer = renderer\nsuper(RadioSelect, self).__init__(*args, **kwargs)", "path": "app\\django\\forms\\widgets.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "\"\"\"\nDecode a JSON document from ``s`` (a ``str`` or ``unicode`` beginning\nwith a JSON document) and return a 2-tuple of the Python\nrepresentation and the index in ``s`` where the document ended.\n\nThis can be used to decode a JSON document from a string that may\nhave extraneous data at the end.\n\"\"\"\n", "func_signal": "def raw_decode(self, s, **kw):\n", "code": "kw.setdefault('context', self)\ntry:\n    obj, end = self._scanner.iterscan(s, **kw).next()\nexcept StopIteration:\n    raise ValueError(\"No JSON object could be decoded\")\nreturn obj, end", "path": "app\\django\\utils\\simplejson\\decoder.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "\"\"\"\nDoes an equivalence test on the OGR type with the given\nother OGRGeomType, the short-hand string, or the integer.\n\"\"\"\n", "func_signal": "def __eq__(self, other):\n", "code": "if isinstance(other, OGRGeomType):\n    return self.num == other.num\nelif isinstance(other, basestring):\n    return self.name.lower() == other.lower()\nelif isinstance(other, int):\n    return self.num == other\nelse:\n    return False", "path": "app\\django\\contrib\\gis\\gdal\\geomtype.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "\"\"\"\nWas something modified since the user last downloaded it?\n\nheader\n  This is the value of the If-Modified-Since header.  If this is None,\n  I'll just return True.\n\nmtime\n  This is the modification time of the item we're talking about.\n\nsize\n  This is the size of the item we're talking about.\n\"\"\"\n", "func_signal": "def was_modified_since(header=None, mtime=0, size=0):\n", "code": "try:\n    if header is None:\n        raise ValueError\n    matches = re.match(r\"^([^;]+)(; length=([0-9]+))?$\", header,\n                       re.IGNORECASE)\n    header_mtime = mktime_tz(parsedate_tz(matches.group(1)))\n    header_len = matches.group(3)\n    if header_len and int(header_len) != size:\n        raise ValueError\n    if mtime > header_mtime:\n        raise ValueError\nexcept (AttributeError, ValueError):\n    return True\nreturn False", "path": "app\\django\\views\\static.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "\"\"\"Returns an instance of the renderer.\"\"\"\n", "func_signal": "def get_renderer(self, name, value, attrs=None, choices=()):\n", "code": "if value is None: value = ''\nstr_value = force_unicode(value) # Normalize to string.\nfinal_attrs = self.build_attrs(attrs)\nchoices = list(chain(self.choices, choices))\nreturn self.renderer(name, str_value, final_attrs, choices)", "path": "app\\django\\forms\\widgets.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "\"\"\"\nInitializes the GeoIP object, no parameters are required to use default\nsettings.  Keyword arguments may be passed in to customize the locations\nof the GeoIP data sets.\n\n* path: Base directory to where GeoIP data is located or the full path\n    to where the city or country data files (*.dat) are located.\n    Assumes that both the city and country data sets are located in\n    this directory; overrides the GEOIP_PATH settings attribute.\n\n* cache: The cache settings when opening up the GeoIP datasets,\n    and may be an integer in (0, 1, 2, 4) corresponding to\n    the GEOIP_STANDARD, GEOIP_MEMORY_CACHE, GEOIP_CHECK_CACHE,\n    and GEOIP_INDEX_CACHE `GeoIPOptions` C API settings,\n    respectively.  Defaults to 0, meaning that the data is read\n    from the disk.\n\n* country: The name of the GeoIP country data file.  Defaults to\n    'GeoIP.dat'; overrides the GEOIP_COUNTRY settings attribute.\n\n* city: The name of the GeoIP city data file.  Defaults to\n    'GeoLiteCity.dat'; overrides the GEOIP_CITY settings attribute.\n\"\"\"\n# Checking the given cache option.\n", "func_signal": "def __init__(self, path=None, cache=0, country=None, city=None):\n", "code": "if cache in self.cache_options:\n    self._cache = self.cache_options[cache]\nelse:\n    raise GeoIPException('Invalid caching option: %s' % cache)\n\n# Getting the GeoIP data path.\nif not path:\n    path = GEOIP_SETTINGS.get('GEOIP_PATH', None)\n    if not path: raise GeoIPException('GeoIP path must be provided via parameter or the GEOIP_PATH setting.')\nif not isinstance(path, basestring):\n    raise TypeError('Invalid path type: %s' % type(path).__name__)\n\ncntry_ptr, city_ptr = (None, None)\nif os.path.isdir(path):\n    # Getting the country and city files using the settings\n    # dictionary.  If no settings are provided, default names\n    # are assigned.\n    country = os.path.join(path, country or GEOIP_SETTINGS.get('GEOIP_COUNTRY', 'GeoIP.dat'))\n    city = os.path.join(path, city or GEOIP_SETTINGS.get('GEOIP_CITY', 'GeoLiteCity.dat'))\nelif os.path.isfile(path):\n    # Otherwise, some detective work will be needed to figure\n    # out whether the given database path is for the GeoIP country\n    # or city databases.\n    ptr = geoip_open(path, cache)\n    info = geoip_dbinfo(ptr)\n    if lite_regex.match(info):\n        # GeoLite City database.\n        city, city_ptr = path, ptr\n    elif free_regex.match(info):\n        # GeoIP Country database.\n        country, cntry_ptr = path, ptr\n    else:\n        raise GeoIPException('Unable to recognize database edition: %s' % info)\nelse:\n    raise GeoIPException('GeoIP path must be a valid file or directory.')\n\n# `_init_db` does the dirty work.\nself._init_db(country, cache, '_country', cntry_ptr)\nself._init_db(city, cache, '_city', city_ptr)", "path": "app\\django\\contrib\\gis\\utils\\geoip.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "# See the comment for RadioSelect.id_for_label()\n", "func_signal": "def id_for_label(self, id_):\n", "code": "if id_:\n    id_ += '_0'\nreturn id_", "path": "app\\django\\forms\\widgets.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "\"\"\"\nReturn the Python representation of ``s`` (a ``str`` or ``unicode``\ninstance containing a JSON document)\n\"\"\"\n", "func_signal": "def decode(self, s, _w=WHITESPACE.match):\n", "code": "obj, end = self.raw_decode(s, idx=_w(s, 0).end())\nend = _w(s, end).end()\nif end != len(s):\n    raise ValueError(errmsg(\"Extra data\", s, end, len(s)))\nreturn obj", "path": "app\\django\\utils\\simplejson\\decoder.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "# RadioSelect is represented by multiple <input type=\"radio\"> fields,\n# each of which has a distinct ID. The IDs are made distinct by a \"_X\"\n# suffix, where X is the zero-based index of the radio field. Thus,\n# the label for a RadioSelect should reference the first one ('_0').\n", "func_signal": "def id_for_label(self, id_):\n", "code": "if id_:\n    id_ += '_0'\nreturn id_", "path": "app\\django\\forms\\widgets.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "# value is a list of values, each corresponding to a widget\n# in self.widgets.\n", "func_signal": "def render(self, name, value, attrs=None):\n", "code": "if not isinstance(value, list):\n    value = self.decompress(value)\noutput = []\nfinal_attrs = self.build_attrs(attrs)\nid_ = final_attrs.get('id', None)\nfor i, widget in enumerate(self.widgets):\n    try:\n        widget_value = value[i]\n    except IndexError:\n        widget_value = None\n    if id_:\n        final_attrs = dict(final_attrs, id='%s_%s' % (id_, i))\n    output.append(widget.render(name + '_%s' % i, widget_value, final_attrs))\nreturn mark_safe(self.format_output(output))", "path": "app\\django\\forms\\widgets.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "\"\"\"\nReturn True if data differs from initial.\n\"\"\"\n# For purposes of seeing whether something has changed, None is\n# the same as an empty string, if the data or inital value we get\n# is None, replace it w/ u''.\n", "func_signal": "def _has_changed(self, initial, data):\n", "code": "if data is None:\n    data_value = u''\nelse:\n    data_value = data\nif initial is None:\n    initial_value = u''\nelse:\n    initial_value = initial\nif force_unicode(initial_value) != force_unicode(data_value):\n    return True\nreturn False", "path": "app\\django\\forms\\widgets.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "# XXX: (Temporary) workaround for ticket #1796: force early loading of all\n# models from installed apps.\n", "func_signal": "def handle_noargs(self, **options):\n", "code": "from django.db.models.loading import get_models\nloaded_models = get_models()\n\nuse_plain = options.get('plain', False)\n\ntry:\n    if use_plain:\n        # Don't bother loading IPython, because the user wants plain Python.\n        raise ImportError\n    import IPython\n    # Explicitly pass an empty list as arguments, because otherwise IPython\n    # would use sys.argv from this script.\n    shell = IPython.Shell.IPShell(argv=[])\n    shell.mainloop()\nexcept ImportError:\n    import code\n    # Set up a dictionary to serve as the environment for the shell, so\n    # that tab completion works on objects that are imported at runtime.\n    # See ticket 5082.\n    imported_objects = {}\n    try: # Try activating rlcompleter, because it's handy.\n        import readline\n    except ImportError:\n        pass\n    else:\n        # We don't have to wrap the following import in a 'try', because\n        # we already know 'readline' was imported successfully.\n        import rlcompleter\n        readline.set_completer(rlcompleter.Completer(imported_objects).complete)\n        readline.parse_and_bind(\"tab:complete\")\n\n    # We want to honor both $PYTHONSTARTUP and .pythonrc.py, so follow system\n    # conventions and get $PYTHONSTARTUP first then import user.\n    if not use_plain: \n        pythonrc = os.environ.get(\"PYTHONSTARTUP\") \n        if pythonrc and os.path.isfile(pythonrc): \n            try: \n                execfile(pythonrc) \n            except NameError: \n                pass\n        # This will import .pythonrc.py as a side-effect\n        import user\n    code.interact(local=imported_objects)", "path": "app\\django\\core\\management\\commands\\shell.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "# Get the media property of the superclass, if it exists\n", "func_signal": "def _media(self):\n", "code": "if hasattr(super(cls, self), 'media'):\n    base = super(cls, self).media\nelse:\n    base = Media()\n\n# Get the media definition for this class\ndefinition = getattr(cls, 'Media', None)\nif definition:\n    extend = getattr(definition, 'extend', True)\n    if extend:\n        if extend == True:\n            m = base\n        else:\n            m = Media()\n            for medium in extend:\n                m = m + base[medium]\n        return m + Media(definition)\n    else:\n        return Media(definition)\nelse:\n    return base", "path": "app\\django\\forms\\widgets.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "\"\"\"\nReturns a dictonary with with the country code and name when given an \nIP address or a Fully Qualified Domain Name (FQDN).  For example, both\n'24.124.1.80' and 'djangoproject.com' are valid parameters.\n\"\"\"\n# Returning the country code and name\n", "func_signal": "def country(self, query):\n", "code": "return {'country_code' : self.country_code(query), \n        'country_name' : self.country_name(query),\n        }", "path": "app\\django\\contrib\\gis\\utils\\geoip.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "# strip spaces and dashes\n", "func_signal": "def clean(self, value):\n", "code": "value = value.strip().replace(' ', '').replace('-', '')\n\nsuper(ZAIDField, self).clean(value)\n\nif value in EMPTY_VALUES:\n    return u''\n\nmatch = re.match(id_re, value)\n\nif not match:\n    raise ValidationError(self.error_messages['invalid'])\n\ng = match.groupdict()\n\ntry:\n    # The year 2000 is conveniently a leapyear.\n    # This algorithm will break in xx00 years which aren't leap years\n    # There is no way to guess the century of a ZA ID number\n    d = date(int(g['yy']) + 2000, int(g['mm']), int(g['dd']))\nexcept ValueError:\n    raise ValidationError(self.error_messages['invalid'])\n\nif not luhn(value):\n    raise ValidationError(self.error_messages['invalid'])\n\nreturn value", "path": "app\\django\\contrib\\localflavor\\za\\forms.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "\"\"\"Outputs a <ul> for this set of radio fields.\"\"\"\n", "func_signal": "def render(self):\n", "code": "return mark_safe(u'<ul>\\n%s\\n</ul>' % u'\\n'.join([u'<li>%s</li>'\n        % force_unicode(w) for w in self]))", "path": "app\\django\\forms\\widgets.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "\"\"\"\nReturns a dictionary of city information for the given IP address or\nFully Qualified Domain Name (FQDN).  Some information in the dictionary\nmay be undefined (None).\n\"\"\"\n", "func_signal": "def city(self, query):\n", "code": "self._check_query(query, city=True)\nif ipregex.match(query):\n    # If an IP address was passed in\n    ptr = rec_by_addr(self._city, c_char_p(query))\nelse:\n    # If a FQDN was passed in.\n    ptr = rec_by_name(self._city, c_char_p(query))\n\n# Checking the pointer to the C structure, if valid pull out elements\n# into a dicionary and return.\nif bool(ptr):\n    record = ptr.contents\n    return dict((tup[0], getattr(record, tup[0])) for tup in record._fields_)\nelse:\n    return None", "path": "app\\django\\contrib\\gis\\utils\\geoip.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "# See the comment for RadioSelect.id_for_label()\n", "func_signal": "def id_for_label(self, id_):\n", "code": "if id_:\n    id_ += '_0'\nreturn id_", "path": "app\\django\\forms\\widgets.py", "repo_name": "bmander/amaurot", "stars": 2, "license": "None", "language": "python", "size": 3148}
{"docstring": "\"\"\"Destructively rips this element out of the tree.\"\"\"\n", "func_signal": "def extract(self):\n", "code": "if self.parent:\n    try:\n        self.parent.contents.remove(self)\n    except ValueError:\n        pass\n\n#Find the two elements that would be next to each other if\n#this element (and any children) hadn't been parsed. Connect\n#the two.\nlastChild = self._lastRecursiveChild()\nnextElement = lastChild.next\n\nif self.previous:\n    self.previous.next = nextElement\nif nextElement:\n    nextElement.previous = self.previous\nself.previous = None\nlastChild.next = None\n\nself.parent = None\nif self.previousSibling:\n    self.previousSibling.nextSibling = self.nextSibling\nif self.nextSibling:\n    self.nextSibling.previousSibling = self.previousSibling\nself.previousSibling = self.nextSibling = None\nreturn self", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Returns the closest parent of this Tag that matches the given\ncriteria.\"\"\"\n# NOTE: We can't use _findOne because findParents takes a different\n# set of arguments.\n", "func_signal": "def findParent(self, name=None, attrs={}, **kwargs):\n", "code": "r = None\nl = self.findParents(name, attrs, 1)\nif l:\n    r = l[0]\nreturn r", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Returns either the given Unicode string or its encoding.\"\"\"\n", "func_signal": "def sob(unicode, encoding):\n", "code": "if encoding is None:\n    return unicode\nelse:\n    return unicode.encode(encoding)", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Returns the parents of this Tag that match the given\ncriteria.\"\"\"\n\n", "func_signal": "def findParents(self, name=None, attrs={}, limit=None, **kwargs):\n", "code": "return self._findAll(name, attrs, None, limit, self.parentGenerator,\n                     **kwargs)", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Beautiful Soup can detect a charset included in a META tag,\ntry to convert the document to that charset, and re-parse the\ndocument from the beginning.\"\"\"\n", "func_signal": "def extractCharsetFromMeta(self, attrs):\n", "code": "httpEquiv = None\ncontentType = None\ncontentTypeIndex = None\ntagNeedsEncodingSubstitution = False\n\nfor i in range(0, len(attrs)):\n    key, value = attrs[i]\n    key = key.lower()\n    if key == 'http-equiv':\n        httpEquiv = value\n    elif key == 'content':\n        contentType = value\n        contentTypeIndex = i\n\nif httpEquiv and contentType: # It's an interesting meta tag.\n    match = self.CHARSET_RE.search(contentType)\n    if match:\n        if (self.declaredHTMLEncoding is not None or\n            self.originalEncoding == self.fromEncoding):\n            # An HTML encoding was sniffed while converting\n            # the document to Unicode, or an HTML encoding was\n            # sniffed during a previous pass through the\n            # document, or an encoding was specified\n            # explicitly and it worked. Rewrite the meta tag.\n            def rewrite(match):\n                return match.group(1) + \"%SOUP-ENCODING%\"\n            newAttr = self.CHARSET_RE.sub(rewrite, contentType)\n            attrs[contentTypeIndex] = (attrs[contentTypeIndex][0],\n                                       newAttr)\n            tagNeedsEncodingSubstitution = True\n        else:\n            # This is our first pass through the document.\n            # Go through it again with the encoding information.\n            newCharset = match.group(3)\n            if newCharset and newCharset != self.originalEncoding:\n                self.declaredHTMLEncoding = newCharset\n                self._feed(self.declaredHTMLEncoding)\n                raise StopParsing\n            pass\ntag = self.unknown_starttag(\"meta\", attrs)\nif tag and tagNeedsEncodingSubstitution:\n    tag.containsSubstitutions = True", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Setting tag[key] sets the value of the 'key' attribute for the\ntag.\"\"\"\n", "func_signal": "def __setitem__(self, key, value):\n", "code": "self._getAttrMap()\nself.attrMap[key] = value\nfound = False\nfor i in range(0, len(self.attrs)):\n    if self.attrs[i][0] == key:\n        self.attrs[i] = (key, value)\n        found = True\nif not found:\n    self.attrs.append((key, value))\nself._getAttrMap()[key] = value", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Given a document, tries to detect its XML encoding.\"\"\"\n", "func_signal": "def _detectEncoding(self, xml_data, isHTML=False):\n", "code": "xml_encoding = sniffed_xml_encoding = None\ntry:\n    if xml_data[:4] == '\\x4c\\x6f\\xa7\\x94':\n        # EBCDIC\n        xml_data = self._ebcdic_to_ascii(xml_data)\n    elif xml_data[:4] == '\\x00\\x3c\\x00\\x3f':\n        # UTF-16BE\n        sniffed_xml_encoding = 'utf-16be'\n        xml_data = unicode(xml_data, 'utf-16be').encode('utf-8')\n    elif (len(xml_data) >= 4) and (xml_data[:2] == '\\xfe\\xff') \\\n             and (xml_data[2:4] != '\\x00\\x00'):\n        # UTF-16BE with BOM\n        sniffed_xml_encoding = 'utf-16be'\n        xml_data = unicode(xml_data[2:], 'utf-16be').encode('utf-8')\n    elif xml_data[:4] == '\\x3c\\x00\\x3f\\x00':\n        # UTF-16LE\n        sniffed_xml_encoding = 'utf-16le'\n        xml_data = unicode(xml_data, 'utf-16le').encode('utf-8')\n    elif (len(xml_data) >= 4) and (xml_data[:2] == '\\xff\\xfe') and \\\n             (xml_data[2:4] != '\\x00\\x00'):\n        # UTF-16LE with BOM\n        sniffed_xml_encoding = 'utf-16le'\n        xml_data = unicode(xml_data[2:], 'utf-16le').encode('utf-8')\n    elif xml_data[:4] == '\\x00\\x00\\x00\\x3c':\n        # UTF-32BE\n        sniffed_xml_encoding = 'utf-32be'\n        xml_data = unicode(xml_data, 'utf-32be').encode('utf-8')\n    elif xml_data[:4] == '\\x3c\\x00\\x00\\x00':\n        # UTF-32LE\n        sniffed_xml_encoding = 'utf-32le'\n        xml_data = unicode(xml_data, 'utf-32le').encode('utf-8')\n    elif xml_data[:4] == '\\x00\\x00\\xfe\\xff':\n        # UTF-32BE with BOM\n        sniffed_xml_encoding = 'utf-32be'\n        xml_data = unicode(xml_data[4:], 'utf-32be').encode('utf-8')\n    elif xml_data[:4] == '\\xff\\xfe\\x00\\x00':\n        # UTF-32LE with BOM\n        sniffed_xml_encoding = 'utf-32le'\n        xml_data = unicode(xml_data[4:], 'utf-32le').encode('utf-8')\n    elif xml_data[:3] == '\\xef\\xbb\\xbf':\n        # UTF-8 with BOM\n        sniffed_xml_encoding = 'utf-8'\n        xml_data = unicode(xml_data[3:], 'utf-8').encode('utf-8')\n    else:\n        sniffed_xml_encoding = 'ascii'\n        pass\nexcept:\n    xml_encoding_match = None\nxml_encoding_re = '^<\\?.*encoding=[\\'\"](.*?)[\\'\"].*\\?>'.encode()\nxml_encoding_match = re.compile(xml_encoding_re).match(xml_data)\nif not xml_encoding_match and isHTML:\n    meta_re = '<\\s*meta[^>]+charset=([^>]*?)[;\\'\">]'.encode()\n    regexp = re.compile(meta_re, re.I)\n    xml_encoding_match = regexp.search(xml_data)\nif xml_encoding_match is not None:\n    xml_encoding = xml_encoding_match.groups()[0].decode(\n        'ascii').lower()\n    if isHTML:\n        self.declaredHTMLEncoding = xml_encoding\n    if sniffed_xml_encoding and \\\n       (xml_encoding in ('iso-10646-ucs-2', 'ucs-2', 'csunicode',\n                         'iso-10646-ucs-4', 'ucs-4', 'csucs4',\n                         'utf-16', 'utf-32', 'utf_16', 'utf_32',\n                         'utf16', 'u16')):\n        xml_encoding = sniffed_xml_encoding\nreturn xml_data, xml_encoding, sniffed_xml_encoding", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Convenience method that works with all 2.x versions of Python\nto determine whether or not something is stringlike.\"\"\"\n", "func_signal": "def isString(s):\n", "code": "try:\n    return isinstance(s, unicode) or isinstance(s, basestring)\nexcept NameError:\n    return isinstance(s, str)", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Changes a MS smart quote character to an XML or HTML\nentity.\"\"\"\n", "func_signal": "def _subMSChar(self, match):\n", "code": "orig = match.group(1)\nsub = self.MS_CHARS.get(orig)\nif type(sub) == types.TupleType:\n    if self.smartQuotesTo == 'xml':\n        sub = '&#x'.encode() + sub[1].encode() + ';'.encode()\n    else:\n        sub = '&'.encode() + sub[0].encode() + ';'.encode()\nelse:\n    sub = sub.encode()\nreturn sub", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Initializes a map representation of this tag's attributes,\nif not already initialized.\"\"\"\n", "func_signal": "def _getAttrMap(self):\n", "code": "if not getattr(self, 'attrMap'):\n    self.attrMap = {}\n    for (key, value) in self.attrs:\n        self.attrMap[key] = value\nreturn self.attrMap", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Treat a bogus SGML declaration as raw data. Treat a CDATA\ndeclaration as a CData object.\"\"\"\n", "func_signal": "def parse_declaration(self, i):\n", "code": "j = None\nif self.rawdata[i:i+9] == '<![CDATA[':\n     k = self.rawdata.find(']]>', i)\n     if k == -1:\n         k = len(self.rawdata)\n     data = self.rawdata[i+9:k]\n     j = k+3\n     self._toStringSubclass(data, CData)\nelse:\n    try:\n        j = HTMLParser.parse_declaration(self, i)\n    except HTMLParseError:\n        toHandle = self.rawdata[i:]\n        self.handle_data(toHandle)\n        j = i + len(toHandle)\nreturn j", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Turns a list of maps, lists, or scalars into a single map.\nUsed to build the SELF_CLOSING_TAGS, NESTABLE_TAGS, and\nNESTING_RESET_TAGS maps out of lists and partial maps.\"\"\"\n", "func_signal": "def buildTagMap(default, *args):\n", "code": "built = {}\nfor portion in args:\n    if hasattr(portion, 'items'):\n        #It's a map. Merge it.\n        for k,v in portion.items():\n            built[k] = v\n    elif isList(portion) and not isString(portion):\n        #It's a list. Map each item to the default.\n        for k in portion:\n            built[k] = default\n    else:\n        #It's a scalar. Map it to the default.\n        built[portion] = default\nreturn built", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "#print \"Matching %s against %s\" % (markup, matchAgainst)\n", "func_signal": "def _matches(self, markup, matchAgainst):\n", "code": "result = False\nif matchAgainst == True and type(matchAgainst) == types.BooleanType:\n    result = markup != None\nelif callable(matchAgainst):\n    result = matchAgainst(markup)\nelse:\n    #Custom match methods take the tag as an argument, but all\n    #other ways of matching match the tag name as a string.\n    if isinstance(markup, Tag):\n        markup = markup.name\n    if markup is not None and not isString(markup):\n        markup = unicode(markup)\n    #Now we know that chunk is either a string, or None.\n    if hasattr(matchAgainst, 'match'):\n        # It's a regexp object.\n        result = markup and matchAgainst.search(markup)\n    elif (isList(matchAgainst)\n          and (markup is not None or not isString(matchAgainst))):\n        result = markup in matchAgainst\n    elif hasattr(matchAgainst, 'items'):\n        result = markup.has_key(matchAgainst)\n    elif matchAgainst and isString(markup):\n        if isinstance(markup, unicode):\n            matchAgainst = unicode(matchAgainst)\n        else:\n            matchAgainst = str(matchAgainst)\n\n    if not result:\n        result = matchAgainst == markup\nreturn result", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Pops the tag stack up to and including the most recent\ninstance of the given tag. If inclusivePop is false, pops the tag\nstack up to but *not* including the most recent instqance of\nthe given tag.\"\"\"\n#print \"Popping to %s\" % name\n", "func_signal": "def _popToTag(self, name, inclusivePop=True):\n", "code": "if name == self.ROOT_TAG_NAME:\n    return\n\nnumPops = 0\nmostRecentTag = None\nfor i in range(len(self.tagStack)-1, 0, -1):\n    if name == self.tagStack[i].name:\n        numPops = len(self.tagStack)-i\n        break\nif not inclusivePop:\n    numPops = numPops - 1\n\nfor i in range(0, numPops):\n    mostRecentTag = self.popTag()\nreturn mostRecentTag", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "# Convert the document to Unicode.\n", "func_signal": "def _feed(self, inDocumentEncoding=None, isHTML=False):\n", "code": "markup = self.markup\nif isinstance(markup, unicode):\n    if not hasattr(self, 'originalEncoding'):\n        self.originalEncoding = None\nelse:\n    dammit = UnicodeDammit\\\n             (markup, [self.fromEncoding, inDocumentEncoding],\n              smartQuotesTo=self.smartQuotesTo, isHTML=isHTML)\n    markup = dammit.unicode\n    self.originalEncoding = dammit.originalEncoding\n    self.declaredHTMLEncoding = dammit.declaredHTMLEncoding\nif markup:\n    if self.markupMassage:\n        if not isList(self.markupMassage):\n            self.markupMassage = self.MARKUP_MASSAGE\n        for fix, m in self.markupMassage:\n            markup = fix.sub(m, markup)\n        # TODO: We get rid of markupMassage so that the\n        # soup object can be deepcopied later on. Some\n        # Python installations can't copy regexes. If anyone\n        # was relying on the existence of markupMassage, this\n        # might cause problems.\n        del(self.markupMassage)\nself.builder.reset()\n\nself.builder.feed(markup)\n# Close out any unfinished strings and close all the open tags.\nself.endData()\nwhile self.currentTag.name != self.ROOT_TAG_NAME:\n    self.popTag()", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "#print \"End tag %s\" % name\n", "func_signal": "def unknown_endtag(self, name):\n", "code": "if self.quoteStack and self.quoteStack[-1] != name:\n    #This is not a real end tag.\n    #print \"</%s> is not real!\" % name\n    self.handle_data('</%s>' % name)\n    return\nself.endData()\nself._popToTag(name)\nif self.quoteStack and self.quoteStack[-1] == name:\n    self.quoteStack.pop()\n    self.literal = (len(self.quoteStack) > 0)", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Handle a processing instruction as a ProcessingInstruction\nobject, possibly one with a %SOUP-ENCODING% slot into which an\nencoding will be plugged later.\"\"\"\n", "func_signal": "def handle_pi(self, text):\n", "code": "if text[:3] == \"xml\":\n    text = u\"xml version='1.0' encoding='%SOUP-ENCODING%'\"\nself._toStringSubclass(text, ProcessingInstruction)", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Returns true iff the given string is the name of a\nself-closing tag according to this parser.\"\"\"\n", "func_signal": "def isSelfClosingTag(self, name):\n", "code": "return self.SELF_CLOSING_TAGS.has_key(name) \\\n       or self.instanceSelfClosingTags.has_key(name)", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "'''Given a string and its encoding, decodes the string into Unicode.\n%encoding is a string recognized by encodings.aliases'''\n\n# strip Byte Order Mark (if present)\n", "func_signal": "def _toUnicode(self, data, encoding):\n", "code": "if (len(data) >= 4) and (data[:2] == '\\xfe\\xff') \\\n       and (data[2:4] != '\\x00\\x00'):\n    encoding = 'utf-16be'\n    data = data[2:]\nelif (len(data) >= 4) and (data[:2] == '\\xff\\xfe') \\\n         and (data[2:4] != '\\x00\\x00'):\n    encoding = 'utf-16le'\n    data = data[2:]\nelif data[:3] == '\\xef\\xbb\\xbf':\n    encoding = 'utf-8'\n    data = data[3:]\nelif data[:4] == '\\x00\\x00\\xfe\\xff':\n    encoding = 'utf-32be'\n    data = data[4:]\nelif data[:4] == '\\xff\\xfe\\x00\\x00':\n    encoding = 'utf-32le'\n    data = data[4:]\nnewdata = unicode(data, encoding)\nreturn newdata", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Convenience method that works with all 2.x versions of Python\nto determine whether or not something is listlike.\"\"\"\n", "func_signal": "def isList(l):\n", "code": "return ((hasattr(l, '__iter__') and not isString(l))\n        or (type(l) in (types.ListType, types.TupleType)))", "path": "BeautifulSoup.py", "repo_name": "arsatiki/tpbv6-scraper", "stars": 2, "license": "None", "language": "python", "size": 100}
{"docstring": "# colors 0..15: 16 basic colors\n\n", "func_signal": "def _build_color_table(self):\n", "code": "self.xterm_colors.append((0x00, 0x00, 0x00)) # 0\nself.xterm_colors.append((0xcd, 0x00, 0x00)) # 1\nself.xterm_colors.append((0x00, 0xcd, 0x00)) # 2\nself.xterm_colors.append((0xcd, 0xcd, 0x00)) # 3\nself.xterm_colors.append((0x00, 0x00, 0xee)) # 4\nself.xterm_colors.append((0xcd, 0x00, 0xcd)) # 5\nself.xterm_colors.append((0x00, 0xcd, 0xcd)) # 6\nself.xterm_colors.append((0xe5, 0xe5, 0xe5)) # 7\nself.xterm_colors.append((0x7f, 0x7f, 0x7f)) # 8\nself.xterm_colors.append((0xff, 0x00, 0x00)) # 9\nself.xterm_colors.append((0x00, 0xff, 0x00)) # 10\nself.xterm_colors.append((0xff, 0xff, 0x00)) # 11\nself.xterm_colors.append((0x5c, 0x5c, 0xff)) # 12\nself.xterm_colors.append((0xff, 0x00, 0xff)) # 13\nself.xterm_colors.append((0x00, 0xff, 0xff)) # 14\nself.xterm_colors.append((0xff, 0xff, 0xff)) # 15\n\n# colors 16..232: the 6x6x6 color cube\n\nvaluerange = (0x00, 0x5f, 0x87, 0xaf, 0xd7, 0xff)\n\nfor i in range(217):\n    r = valuerange[(i / 36) % 6]\n    g = valuerange[(i / 6) % 6]\n    b = valuerange[i % 6]\n    self.xterm_colors.append((r, g, b))\n\n# colors 233..253: grayscale\n\nfor i in range(1, 22):\n    v = 8 + i * 10\n    self.xterm_colors.append((v, v, v))", "path": "console\\app\\pygments\\formatters\\terminal256.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"get the next character, excluding comments. peek() is used to see\n   if a '/' is followed by a '/' or '*'.\n\"\"\"\n", "func_signal": "def _next(self):\n", "code": "c = self._get()\nif c == '/':\n    p = self._peek()\n    if p == '/':\n        c = self._get()\n        while c > '\\n':\n            c = self._get()\n        return c\n    if p == '*':\n        c = self._get()\n        while 1:\n            c = self._get()\n            if c == '*':\n                if self._peek() == '/':\n                    self._get()\n                    return ' '\n            if c == '\\000':\n                raise UnterminatedComment()\n\nreturn c", "path": "utils\\js\\jsmin.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"\nReturns the Routes RequestConfig object.\n\nTo get the Routes RequestConfig:\n\n>>> from routes import *\n>>> config = request_config()\n\nThe following attributes must be set on the config object every request:\n\nmapper\n    mapper should be a Mapper instance thats ready for use\nhost\n    host is the hostname of the webapp\nprotocol\n    protocol is the protocol of the current request\nmapper_dict\n    mapper_dict should be the dict returned by mapper.match()\nredirect\n    redirect should be a function that issues a redirect, \n    and takes a url as the sole argument\nprefix (optional)\n    Set if the application is moved under a URL prefix. Prefix\n    will be stripped before matching, and prepended on generation\nenviron (optional)\n    Set to the WSGI environ for automatic prefix support if the\n    webapp is underneath a 'SCRIPT_NAME'\n    \n    Setting the environ will use information in environ to try and\n    populate the host/protocol/mapper_dict options if you've already\n    set a mapper.\n\n**Using your own requst local**\n\nIf you have your own request local object that you'd like to use instead of the default\nthread local provided by Routes, you can configure Routes to use it::\n    \n    from routes import request_config()\n    config = request_config()\n    if hasattr(config, 'using_request_local'):\n        config.request_local = YourLocalCallable\n        config = request_config()\n\nOnce you have configured request_config, its advisable you retrieve it again to get the\nobject you wanted. The variable you assign to request_local is assumed to be a callable\nthat will get the local config object you wish.\n\nThis example tests for the presence of the 'using_request_local' attribute which will be\npresent if you haven't assigned it yet. This way you can avoid repeat assignments of the\nrequest specific callable.\n\nShould you want the original object, perhaps to change the callable its using or stop\nthis behavior, call request_config(original=True).\n\"\"\"\n", "func_signal": "def request_config(original=False):\n", "code": "obj = _RequestConfig()\nif hasattr(obj, 'request_local') and original is False:\n    return getattr(obj, 'request_local')()\nelse:\n    obj.using_request_local = False\nreturn _RequestConfig()", "path": "utils\\routes\\__init__.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"Constructor.\n\nArgs:\n  # email is optional. it defaults to the current user.\n  email: string\n\"\"\"\n", "func_signal": "def __init__(self, email=None, _auth_domain=None):\n", "code": "if _auth_domain is None:\n  _auth_domain = os.environ.get('AUTH_DOMAIN')\nelse:\n  assert email is not None\n\nassert _auth_domain\n\nif email is None:\n  assert 'USER_EMAIL' in os.environ\n  email = os.environ['USER_EMAIL']\n\nif not email:\n  raise UserNotFoundError\n\nself.__email = email\nself.__auth_domain = _auth_domain", "path": "utils\\users.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"return the next character from stdin. Watch out for lookahead. If\n   the character is a control character, translate it to a space or\n   linefeed.\n\"\"\"\n", "func_signal": "def _get(self):\n", "code": "c = self.theLookahead\nself.theLookahead = None\nif c == None:\n    c = self.instream.read(1)\nif c >= ' ' or c == '\\n':\n    return c\nif c == '': # EOF\n    return '\\000'\nif c == '\\r':\n    return '\\n'\nreturn ' '", "path": "utils\\js\\jsmin.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"\nLoad the protocol/server info from the environ and store it.\nAlso, match the incoming URL if there's already a mapper, and\nstore the resulting match dict in mapper_dict.\n\"\"\"\n", "func_signal": "def load_wsgi_environ(self, environ):\n", "code": "if environ.get('HTTPS') or environ.get('wsgi.url_scheme') == 'https' \\\n   or environ.get('HTTP_X_FORWARDED_PROTO') == 'https':\n    self.__shared_state.protocol = 'https'\nelse:\n    self.__shared_state.protocol = 'http'\nif hasattr(self, 'mapper'):\n    self.mapper.environ = environ\nif 'PATH_INFO' in environ and hasattr(self, 'mapper'):\n    mapper = self.mapper\n    path = environ['PATH_INFO']\n    result = mapper.routematch(path)\n    if result is not None:\n        self.__shared_state.mapper_dict = result[0]\n        self.__shared_state.route = result[1]\n    else:\n        self.__shared_state.mapper_dict = None\n        self.__shared_state.route = None\n\nif environ.get('HTTP_X_FORWARDED_HOST'):\n    self.__shared_state.host = environ['HTTP_X_FORWARDED_HOST']\nelif environ.get('HTTP_HOST'):\n    self.__shared_state.host = environ['HTTP_HOST']\nelse:\n    self.__shared_state.host = environ['SERVER_NAME']\n    if environ['wsgi.url_scheme'] == 'https':\n        if environ['SERVER_PORT'] != '443':\n            self.__shared_state.host += ':' + environ['SERVER_PORT']\n    else:\n        if environ['SERVER_PORT'] != '80':\n            self.__shared_state.host += ':' + environ['SERVER_PORT']", "path": "utils\\routes\\__init__.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"Removes a name from the list of unpicklable names, if it exists.\n\nArgs:\n  name: string, the name of the unpicklable global to remove\n\"\"\"\n", "func_signal": "def remove_unpicklable_name(self, name):\n", "code": "if name in self.unpicklable_names:\n  self.unpicklable_names.remove(name)", "path": "utils\\shell\\shell.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"\nIf the name is environ, load the wsgi envion with load_wsgi_environ\nand set the environ\n\"\"\"\n", "func_signal": "def __setattr__(self, name, value):\n", "code": "if name == 'environ':\n    self.load_wsgi_environ(value)\n    return self.__shared_state.__setattr__(name, value)\nreturn self.__shared_state.__setattr__(name, value)", "path": "utils\\routes\\__init__.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "# set up the session. TODO: garbage collect old shell sessions\n", "func_signal": "def get(self):\n", "code": "session_key = self.request.get('session')\nif session_key:\n  session = ShellSession.get(session_key)\nelse:\n  # create a new session\n  session = ShellSession()\n  session.unpicklables = [db.Text(line) for line in INITIAL_UNPICKLABLES]\n  session_key = session.put()\n\ntemplate_file = os.path.join(config.APP_ROOT_DIR, 'views', 'shell', 'shell.html')\nsession_url = '/?session=%s' % session_key\nvars = { 'server_software': os.environ['SERVER_SOFTWARE'],\n         'python_version': sys.version,\n         'session': str(session_key),\n         'user': users.get_current_user(),\n         'login_url': users.create_login_url(session_url),\n         'logout_url': users.create_logout_url(session_url),\n         }\nrendered = webapp.template.render(template_file, vars, debug=_DEBUG)\nself.response.out.write(rendered)", "path": "utils\\shell\\shell.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"Returns a dictionary view of the globals.\n\"\"\"\n", "func_signal": "def globals_dict(self):\n", "code": "return dict((name, pickle.loads(val))\n            for name, val in zip(self.global_names, self.globals))", "path": "utils\\shell\\shell.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"Adds a statement and list of names to the unpicklables.\n\nAlso removes the names from the globals.\n\nArgs:\n  statement: string, the statement that created new unpicklable global(s).\n  names: list of strings; the names of the globals created by the statement.\n\"\"\"\n", "func_signal": "def add_unpicklable(self, statement, names):\n", "code": "self.unpicklables.append(db.Text(statement))\n\nfor name in names:\n  self.remove_global(name)\n  if name not in self.unpicklable_names:\n    self.unpicklable_names.append(db.Text(name))", "path": "utils\\shell\\shell.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"Copy the input to the output, deleting the characters which are\n   insignificant to JavaScript. Comments will be removed. Tabs will be\n   replaced with spaces. Carriage returns will be replaced with linefeeds.\n   Most spaces and linefeeds will be removed.\n\"\"\"\n", "func_signal": "def _jsmin(self):\n", "code": "self.theA = '\\n'\nself._action(3)\n\nwhile self.theA != '\\000':\n    if self.theA == ' ':\n        if isAlphanum(self.theB):\n            self._action(1)\n        else:\n            self._action(2)\n    elif self.theA == '\\n':\n        if self.theB in ['{', '[', '(', '+', '-']:\n            self._action(1)\n        elif self.theB == ' ':\n            self._action(3)\n        else:\n            if isAlphanum(self.theB):\n                self._action(1)\n            else:\n                self._action(2)\n    else:\n        if self.theB == ' ':\n            if isAlphanum(self.theA):\n                self._action(1)\n            else:\n                self._action(3)\n        elif self.theB == '\\n':\n            if self.theA in ['}', ']', ')', '+', '-', '\"', '\\'']:\n                self._action(1)\n            else:\n                if isAlphanum(self.theA):\n                    self._action(1)\n                else:\n                    self._action(3)\n        else:\n            self._action(1)", "path": "utils\\js\\jsmin.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"\nConvert a string into a token type::\n\n    >>> string_to_token('String.Double')\n    Token.Literal.String.Double\n    >>> string_to_token('Token.Literal.Number')\n    Token.Literal.Number\n    >>> string_to_token('')\n    Token\n\nTokens that are already tokens are returned unchanged:\n\n    >>> string_to_token(String)\n    Token.Literal.String\n\"\"\"\n", "func_signal": "def string_to_tokentype(s):\n", "code": "if isinstance(s, _TokenType):\n    return s\nif not s:\n    return Token\nnode = Token\nfor item in s.split('.'):\n    node = getattr(node, item)\nreturn node", "path": "console\\app\\pygments\\token.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"Return this user's nickname.\n\nThe nickname will be a unique, human readable identifier for this user\nwith respect to this application. It will be an email address for some\nusers, but not all.\n\"\"\"\n", "func_signal": "def nickname(self):\n", "code": "if (self.__email and self.__auth_domain and\n    self.__email.endswith('@' + self.__auth_domain)):\n  suffix_len = len(self.__auth_domain) + 1\n  return self.__email[:-suffix_len]\nelse:\n  return self.__email", "path": "utils\\users.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"return true if the character is a letter, digit, underscore,\n       dollar sign, or non-ASCII character.\n\"\"\"\n", "func_signal": "def isAlphanum(c):\n", "code": "return ((c >= 'a' and c <= 'z') or (c >= '0' and c <= '9') or\n        (c >= 'A' and c <= 'Z') or c == '_' or c == '$' or c == '\\\\' or (c is not None and ord(c) > 126));", "path": "utils\\js\\jsmin.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"Runs your WSGI-compliant application object in a CGI environment.\n\nCompared to wsgiref.handlers.CGIHandler().run(application), this\nfunction takes some shortcuts.  Those are possible because the\napp server makes stronger promises than the CGI standard.\n\"\"\"\n", "func_signal": "def run_wsgi_app(application):\n", "code": "env = dict(os.environ)\nenv[\"wsgi.input\"] = sys.stdin\nenv[\"wsgi.errors\"] = sys.stderr\nenv[\"wsgi.version\"] = (1, 0)\nenv[\"wsgi.run_once\"] = True\nenv[\"wsgi.url_scheme\"] = wsgiref.util.guess_scheme(env)\nenv[\"wsgi.multithread\"] = False\nenv[\"wsgi.multiprocess\"] = False\nresult = application(env, _start_response)\nif result is not None:\n  for data in result:\n    sys.stdout.write(data)", "path": "utils\\webapp\\util.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"Removes a global, if it exists.\n\nArgs:\n  name: string, the name of the global to remove\n\"\"\"\n", "func_signal": "def remove_global(self, name):\n", "code": "if name in self.global_names:\n  index = self.global_names.index(name)\n  del self.global_names[index]\n  del self.globals[index]", "path": "utils\\shell\\shell.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"Return True if user is authenticated.\"\"\"\n", "func_signal": "def authorized(handler):\n", "code": "user = users.get_current_user()\nif not user:\n\thandler.redirect('/login')\nelse:\n\t#auth_user = Admin.gql(\"where user = :1\", user).get()\n\tauth_user = False\n\tif not auth_user:\n\t  logging.warning('An unauthorized user has attempted to enter an authorized page')\n\t  handler.redirect('/')\n\t  return False\n\telse:\n\t\treturn True", "path": "utils\\webapp\\util.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"\nFormat ``text`` with a color and/or some attributes::\n\n    color       normal color\n    *color*     bold color\n    _color_     underlined color\n    +color+     blinking color\n\"\"\"\n", "func_signal": "def ansiformat(attr, text):\n", "code": "result = []\nif attr[:1] == attr[-1:] == '+':\n    result.append(codes['blink'])\n    attr = attr[1:-1]\nif attr[:1] == attr[-1:] == '*':\n    result.append(codes['bold'])\n    attr = attr[1:-1]\nif attr[:1] == attr[-1:] == '_':\n    result.append(codes['underline'])\n    attr = attr[1:-1]\nresult.append(codes[attr])\nresult.append(text)\nresult.append(codes['reset'])\nreturn ''.join(result)", "path": "console\\app\\pygments\\console.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"do something! What you do is determined by the argument:\n   1   Output A. Copy B to A. Get the next B.\n   2   Copy B to A. Get the next B. (Delete A).\n   3   Get the next B. (Delete B).\n   action treats a string as a single character. Wow!\n   action recognizes a regular expression if it is preceded by ( or , or =.\n\"\"\"\n", "func_signal": "def _action(self, action):\n", "code": "if action <= 1:\n    self._outA()\n\nif action <= 2:\n    self.theA = self.theB\n    if self.theA == \"'\" or self.theA == '\"':\n        while 1:\n            self._outA()\n            self.theA = self._get()\n            if self.theA == self.theB:\n                break\n            if self.theA <= '\\n':\n                raise UnterminatedStringLiteral()\n            if self.theA == '\\\\':\n                self._outA()\n                self.theA = self._get()\n\n\nif action <= 3:\n    self.theB = self._next()\n    if self.theB == '/' and (self.theA == '(' or self.theA == ',' or\n                             self.theA == '=' or self.theA == ':' or\n                             self.theA == '[' or self.theA == '?' or\n                             self.theA == '!' or self.theA == '&' or\n                             self.theA == '|' or self.theA == ';' or\n                             self.theA == '{' or self.theA == '}' or\n                             self.theA == '\\n'):\n        self._outA()\n        self._outB()\n        while 1:\n            self.theA = self._get()\n            if self.theA == '/':\n                break\n            elif self.theA == '\\\\':\n                self._outA()\n                self.theA = self._get()\n            elif self.theA <= '\\n':\n                raise UnterminatedRegularExpression()\n            self._outA()\n        self.theB = self._next()", "path": "utils\\js\\jsmin.py", "repo_name": "jaytoday/quizthebill", "stars": 2, "license": "None", "language": "python", "size": 3212}
{"docstring": "\"\"\"Adds a segment to this set.\"\"\"\n\n", "func_signal": "def append(self, segment):\n", "code": "self.segments.append(segment)\nself._doc_offsets = self.doc_offsets()", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"Returns the generation number of the latest generation of this\nindex.\n\"\"\"\n\n", "func_signal": "def latest_generation(self):\n", "code": "pattern = _toc_pattern(self.indexname)\n\nmax = -1\nfor filename in self.storage:\n    m = pattern.match(filename)\n    if m:\n        num = int(m.group(1))\n        if num > max: max = num\nreturn max", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"Deletes the given document number. The document is not actually\nremoved from the index until it is optimized.\n\n:docnum: The document number to delete.\n:delete: If False, this undeletes a deleted document.\n\"\"\"\n\n", "func_signal": "def delete_document(self, docnum, delete = True):\n", "code": "if delete:\n    if self.deleted is None:\n        self.deleted = set()\n    elif docnum in self.deleted:\n        raise KeyError(\"Document %s in segment %r is already deleted\"\n                       % (docnum, self.name))\n    \n    self.deleted.add(docnum)\nelse:\n    if self.deleted is None or docnum not in self.deleted:\n        raise KeyError(\"Document %s is not deleted\" % docnum)\n    \n    self.deleted.remove(docnum)", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"Returns an (index.Segment, segment_docnum) pair for the\nsegment containing the given document number.\n\"\"\"\n\n", "func_signal": "def _segment_and_docnum(self, docnum):\n", "code": "segmentnum = self._document_segment(docnum)\noffset = self._doc_offsets[segmentnum]\nsegment = self.segments[segmentnum]\nreturn segment, docnum - offset", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"Deletes any documents matching a query object.\n\nNote that this method opens and closes a Searcher. If you are calling\nthis method repeatedly (for example, deleting changed documents before\nreindexing them), you should open your own Searcher object and\npass it in with the 'searcher' keyword argument for efficiency.\n\n:*returns*: the number of documents deleted.\n\"\"\"\n\n", "func_signal": "def delete_by_query(self, q, searcher = None):\n", "code": "if searcher is None:\n    from whoosh.searching import Searcher\n    s = Searcher(self)\nelse:\n    s = searcher  \n\ncount = 0\ntry:\n    for docnum in q.docs(s):\n        self.delete_document(docnum)\n        count += 1\n    return count\n\nfinally:\n    if searcher is None:\n        s.close()\n\nreturn count", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"\n:*returns*: True if a given document number is deleted but not yet\n    optimized out of the index.\n\"\"\"\n\n", "func_signal": "def is_deleted(self, docnum):\n", "code": "segment, segdocnum = self._segment_and_docnum(docnum)\nreturn segment.is_deleted(segdocnum)", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"Parses querystring, runs the query in this index, and returns a\nResult object. Any additional keyword arguments are passed to\nSearcher.search() along with the parsed query.\n\n:querystring: The query string to parse and search for.\n:parser: A Parser object to use to parse 'querystring'.\n    The default is to use a standard qparser.QueryParser.\n    This object must implement a parse(str) method which returns a\n    query.Query instance.\n:*returns*: searching.Results\n\"\"\"\n\n", "func_signal": "def find(self, querystring, parser = None, **kwargs):\n", "code": "if parser is None:\n    from whoosh.qparser import QueryParser\n    parser = QueryParser(self.schema)\n    \nreturn self.searcher().search(parser.parse(querystring), **kwargs)", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"\n:*returns*: the maximum frequency of any term in the set.\n\"\"\"\n\n", "func_signal": "def max_weight(self):\n", "code": "if not self.segments:\n    return 0\nreturn max(s.max_weight for s in self.segments)", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"Deletes any documents containing \"term\" in the \"fieldname\"\nfield. This is useful when you have an indexed field containing\na unique ID (such as \"pathname\") for each document.\n\nNote that this method opens and closes a Searcher. If you are calling\nthis method repeatedly (for example, deleting changed documents before\nreindexing them), you will want to open your own Searcher object and\npass it in with the 'searcher' keyword argument for efficiency.\n\n:*returns*: the number of documents deleted.\n\"\"\"\n\n", "func_signal": "def delete_by_term(self, fieldname, text, searcher = None):\n", "code": "from whoosh.query import Term\nq = Term(fieldname, text)\nreturn self.delete_by_query(q, searcher = searcher)", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"Returns an IndexWriter object for this index.\n\n:*returns*: writing.IndexWriter\n\"\"\"\n", "func_signal": "def writer(self, **kwargs):\n", "code": "from whoosh.writing import IndexWriter\nreturn IndexWriter(self, **kwargs)", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"Returns a TermReader object for this index.\n\n:*returns*: reading.TermReader\n\"\"\"\n\n", "func_signal": "def term_reader(self):\n", "code": "from whoosh import reading\nsegments = self.segments\n\nif len(segments) == 1:\n    return reading.TermReader(self.storage, segments[0], self.schema)\nelse:\n    term_readers = [reading.TermReader(self.storage, s, self.schema)\n                    for s in segments]\n    doc_offsets = segments.doc_offsets()\n    return reading.MultiTermReader(term_readers, doc_offsets, self.schema)", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"Deletes a document by number.\n\nYou must call Index.commit() for the deletion to be written to disk.\n\"\"\"\n\n", "func_signal": "def delete_document(self, docnum, delete = True):\n", "code": "segment, segdocnum = self._segment_and_docnum(docnum)\nsegment.delete_document(segdocnum, delete = delete)", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\":*returns*: True if the given document number is deleted.\"\"\"\n\n", "func_signal": "def is_deleted(self, docnum):\n", "code": "if self.deleted is None: return False\nreturn docnum in self.deleted", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"Returns a new Index object representing the latest generation\nof this index (if this object is the latest generation, returns\nself).\n:*returns*: index.Index\n\"\"\"\n\n", "func_signal": "def refresh(self):\n", "code": "if not self.up_to_date():\n    return self.__class__(self.storage, indexname = self.indexname)\nelse:\n    return self", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"Returns the total number of terms in a given field.\nThis is used by some scoring algorithms. Note that this\nnecessarily includes terms in deleted documents.\n\"\"\"\n\n", "func_signal": "def field_length(self, fieldid):\n", "code": "fieldnum = self.schema.to_number(fieldid)\nreturn sum(s.field_length(fieldnum) for s in self.segments)", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"Optimizes this index's segments. This will fail if the index\nis already locked for writing.\n\"\"\"\n\n", "func_signal": "def optimize(self):\n", "code": "if len(self.segments) < 2 and not self.segments.has_deletions():\n    return\n\nfrom whoosh import writing\nw = writing.IndexWriter(self)\nw.commit(writing.OPTIMIZE)", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\":*returns*: the total number of deleted documents in this segment.\"\"\"\n", "func_signal": "def deleted_count(self):\n", "code": "if self.deleted is None: return 0\nreturn len(self.deleted)", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"Commits pending edits (such as deletions) to this index object.\nRaises OutOfDateError if this index is not the latest generation\n(that is, if someone has updated the index since you opened\nthis object).\n\n:new_segments: a replacement SegmentSet. This is used by\n    IndexWriter to update the index after it finishes\n    writing.\n\"\"\"\n\n", "func_signal": "def commit(self, new_segments = None):\n", "code": "if not self.up_to_date():\n    raise OutOfDateError\n\nif new_segments:\n    self.segments = new_segments\n\nself.generation += 1\nself._write()\nself.clean_files()", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"Convenience function for opening an index in a directory. Takes care of creating\na FileStorage object for you. dirname is the filename of the directory in\ncontaining the index. indexname is the name of the index to create; you only need to\nspecify this if you have multiple indexes within the same storage object.\n\nReturns an Index object.\n\"\"\"\n\n", "func_signal": "def open_dir(dirname, indexname = None):\n", "code": "if indexname is None:\n    indexname = _DEF_INDEX_NAME\n\nreturn Index(store.FileStorage(dirname), indexname = indexname)", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "\"\"\"Returns True if dirname contains a Whoosh index.\"\"\"\n\n", "func_signal": "def exists_in(dirname, indexname = None):\n", "code": "if indexname is None:\n    indexname = _DEF_INDEX_NAME\n\nif os.path.exists(dirname):\n    try:\n        ix = open_dir(dirname)\n        return ix.latest_generation() > -1\n    except EmptyIndexError:\n        pass\n\nreturn False", "path": "src\\whoosh\\index.py", "repo_name": "ryszard/whoosh", "stars": 3, "license": "apache-2.0", "language": "python", "size": 372}
{"docstring": "# GMT and UTC offsets have inverted signal when compared to the\n# usual TZ variable handling.\n", "func_signal": "def testGMTOffset(self):\n", "code": "dt = datetime(2007,8,6,4,10, tzinfo=tzutc())\nself.assertEquals(dt.astimezone(tz=tzstr(\"GMT+2\")),\n                  datetime(2007,8,6,6,10, tzinfo=tzstr(\"GMT+2\")))\nself.assertEquals(dt.astimezone(tz=gettz(\"UTC-2\")),\n                  datetime(2007,8,6,2,10, tzinfo=tzstr(\"UTC-2\")))", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# This timezone has an offset of 5992 seconds in 1900-01-01.\n", "func_signal": "def testRoundNonFullMinutes(self):\n", "code": "tz = tzfile(StringIO(base64.decodestring(self.EUROPE_HELSINKI)))\nself.assertEquals(str(datetime(1900,1,1,0,0, tzinfo=tz)),\n                  \"1900-01-01 00:00:00+01:40\")", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# Another nice test. The last days of week number 52/53\n# may be in the next year.\n", "func_signal": "def testMonthlyByWeekNoAndWeekDayLarge(self):\n", "code": "self.assertEqual(list(rrule(MONTHLY,\n                      count=3,\n                      byweekno=52,\n                      byweekday=SU,\n                      dtstart=parse(\"19970902T090000\"))),\n                 [datetime(1997, 12, 28, 9, 0),\n                  datetime(1998, 12, 27, 9, 0),\n                  datetime(2000, 1, 2, 9, 0)])", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# We can't use mktime here. It is unstable when deciding if\n# the hour near to a change is DST or not.\n# \n# timestamp = time.mktime((dt.year, dt.month, dt.day, dt.hour,\n#                         dt.minute, dt.second, dt.weekday(), 0, -1))\n# return time.localtime(timestamp).tm_isdst\n#\n# The code above yields the following result:\n#\n#>>> import tz, datetime\n#>>> t = tz.tzlocal()\n#>>> datetime.datetime(2003,2,15,23,tzinfo=t).tzname()\n#'BRDT'\n#>>> datetime.datetime(2003,2,16,0,tzinfo=t).tzname()\n#'BRST'\n#>>> datetime.datetime(2003,2,15,23,tzinfo=t).tzname()\n#'BRST'\n#>>> datetime.datetime(2003,2,15,22,tzinfo=t).tzname()\n#'BRDT'\n#>>> datetime.datetime(2003,2,15,23,tzinfo=t).tzname()\n#'BRDT'\n#\n# Here is a more stable implementation:\n#\n", "func_signal": "def _isdst(self, dt):\n", "code": "timestamp = ((dt.toordinal() - EPOCHORDINAL) * 86400\n             + dt.hour * 3600\n             + dt.minute * 60\n             + dt.second)\nreturn time.localtime(timestamp+time.timezone).tm_isdst", "path": "dateutil\\tz.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# Another nice test. The last days of week number 52/53\n# may be in the next year.\n", "func_signal": "def testDailyByWeekNoAndWeekDayLarge(self):\n", "code": "self.assertEqual(list(rrule(DAILY,\n                      count=3,\n                      byweekno=52,\n                      byweekday=SU,\n                      dtstart=parse(\"19970902T090000\"))),\n                 [datetime(1997, 12, 28, 9, 0),\n                  datetime(1998, 12, 27, 9, 0),\n                  datetime(2000, 1, 2, 9, 0)])", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# Another nice test. The last days of week number 52/53\n# may be in the next year.\n", "func_signal": "def testYearlyByWeekNoAndWeekDayLarge(self):\n", "code": "self.assertEqual(list(rrule(YEARLY,\n                      count=3,\n                      byweekno=52,\n                      byweekday=SU,\n                      dtstart=parse(\"19970902T090000\"))),\n                 [datetime(1997, 12, 28, 9, 0),\n                  datetime(1998, 12, 27, 9, 0),\n                  datetime(2000, 1, 2, 9, 0)])", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# Another nice test. The last days of week number 52/53\n# may be in the next year.\n", "func_signal": "def testWeeklyByWeekNoAndWeekDayLarge(self):\n", "code": "self.assertEqual(list(rrule(WEEKLY,\n                      count=3,\n                      byweekno=52,\n                      byweekday=SU,\n                      dtstart=parse(\"19970902T090000\"))),\n                 [datetime(1997, 12, 28, 9, 0),\n                  datetime(1998, 12, 27, 9, 0),\n                  datetime(2000, 1, 2, 9, 0)])", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# This timezone has leapcnt, and failed to decode until\n# Eugene Oden notified about the issue.\n", "func_signal": "def testLeapCountDecodesProperly(self):\n", "code": "tz = tzfile(StringIO(base64.decodestring(self.NEW_YORK)))\nself.assertEquals(datetime(2007,3,31,20,12).tzname(), None)", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# That's a nice one. The first days of week number one\n# may be in the last year.\n", "func_signal": "def testYearlyByWeekNoAndWeekDay(self):\n", "code": "self.assertEqual(list(rrule(YEARLY,\n                      count=3,\n                      byweekno=1,\n                      byweekday=MO,\n                      dtstart=parse(\"19970902T090000\"))),\n                 [datetime(1997, 12, 29, 9, 0),\n                  datetime(1999, 1, 4, 9, 0),\n                  datetime(2000, 1, 3, 9, 0)])", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# This is interesting because the TH(-3) ends up before\n# the TU(3).\n", "func_signal": "def testYearlyByMonthAndNWeekDayLarge(self):\n", "code": "self.assertEqual(list(rrule(YEARLY,\n                      count=3,\n                      bymonth=(1,3),\n                      byweekday=(TU(3),TH(-3)),\n                      dtstart=parse(\"19970902T090000\"))),\n                 [datetime(1998, 1, 15, 9, 0),\n                  datetime(1998, 1, 20, 9, 0),\n                  datetime(1998, 3, 12, 9, 0)])", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# Custom parser info wasn't working, as Michael Elsd\u00f6rfer discovered.\n", "func_signal": "def testCustomParserInfo(self):\n", "code": "from dateutil.parser import parserinfo, parser\nclass myparserinfo(parserinfo):\n    MONTHS = parserinfo.MONTHS[:]\n    MONTHS[0] = (\"Foo\", \"Foo\")\nmyparser = parser(myparserinfo())\ndt = myparser.parse(\"01/Foo/2007\")\nself.assertEquals(dt, datetime(2007, 1, 1))", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# tzstr(\"GMT+2\") improperly considered daylight saving time.\n# Issue reported by Lennart Regebro.\n", "func_signal": "def testGMTHasNoDaylight(self):\n", "code": "dt = datetime(2007,8,6,4,10)\nself.assertEquals(gettz(\"GMT+2\").dst(dt), timedelta(0))", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# That's a nice one. The first days of week number one\n# may be in the last year.\n", "func_signal": "def testMonthlyByWeekNoAndWeekDay(self):\n", "code": "self.assertEqual(list(rrule(MONTHLY,\n                      count=3,\n                      byweekno=1,\n                      byweekday=MO,\n                      dtstart=parse(\"19970902T090000\"))),\n                 [datetime(1997, 12, 29, 9, 0),\n                  datetime(1999, 1, 4, 9, 0),\n                  datetime(2000, 1, 3, 9, 0)])", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# That's a nice one. The first days of week number one\n# may be in the last year.\n", "func_signal": "def testWeeklyByWeekNoAndWeekDay(self):\n", "code": "self.assertEqual(list(rrule(WEEKLY,\n                      count=3,\n                      byweekno=1,\n                      byweekday=MO,\n                      dtstart=parse(\"19970902T090000\"))),\n                 [datetime(1997, 12, 29, 9, 0),\n                  datetime(1999, 1, 4, 9, 0),\n                  datetime(2000, 1, 3, 9, 0)])", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# tzrange._isdst() was using a date() rather than a datetime().\n# Issue reported by Lennart Regebro.\n", "func_signal": "def testBrokenIsDstHandling(self):\n", "code": "dt = datetime(2007,8,6,4,10, tzinfo=tzutc())\nself.assertEquals(dt.astimezone(tz=gettz(\"GMT+2\")),\n                  datetime(2007,8,6,6,10, tzinfo=tzstr(\"GMT+2\")))", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# This test will check 200 different years, every month, every day,\n# every hour, every minute, every second, and every weekday, using\n# a delta of more or less 1 year, 1 month, 1 day, 1 minute and\n# 1 second.\n", "func_signal": "def testIncreasingCTime(self):\n", "code": "delta = timedelta(days=365+31+1, seconds=1+60+60*60)\ndt = datetime(1900, 1, 1, 0, 0, 0, 0)\nfor i in range(200):\n    self.assertEqual(parse(dt.ctime()), dt)\n    dt += delta", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# This test is interesting, because it crosses the year\n# boundary in a weekly period to find day '1' as a\n# valid recurrence.\n", "func_signal": "def testWeeklyByMonthAndWeekDay(self):\n", "code": "self.assertEqual(list(rrule(WEEKLY,\n                      count=3,\n                      bymonth=(1,3),\n                      byweekday=(TU,TH),\n                      dtstart=parse(\"19970902T090000\"))),\n                 [datetime(1998, 1, 1, 9, 0),\n                  datetime(1998, 1, 6, 9, 0),\n                  datetime(1998, 1, 8, 9, 0)])", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# One more precision issue, discovered by Eric Brown.  This should\n# be the last one, as we're no longer using floating points.\n", "func_signal": "def testMicrosecondPrecisionErrorReturns(self):\n", "code": "for ms in [100001, 100000, 99999, 99998,\n            10001,  10000,  9999,  9998,\n             1001,   1000,   999,   998,\n              101,    100,    99,    98]:\n    dt = datetime(2008, 2, 27, 21, 26, 1, ms)\n    self.assertEquals(parse(dt.isoformat()), dt)", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# Skip found out that sad precision problem. :-(\n", "func_signal": "def testMicrosecondsPrecisionError(self):\n", "code": "dt1 = parse(\"00:11:25.01\")\ndt2 = parse(\"00:12:10.01\")\nself.assertEquals(dt1.microsecond, 10000)\nself.assertEquals(dt2.microsecond, 10000)", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "# That's a nice one. The first days of week number one\n# may be in the last year.\n", "func_signal": "def testDailyByWeekNoAndWeekDay(self):\n", "code": "self.assertEqual(list(rrule(DAILY,\n                      count=3,\n                      byweekno=1,\n                      byweekday=MO,\n                      dtstart=parse(\"19970902T090000\"))),\n                 [datetime(1997, 12, 29, 9, 0),\n                  datetime(1999, 1, 4, 9, 0),\n                  datetime(2000, 1, 3, 9, 0)])", "path": "test.py", "repo_name": "clones/python-dateutil", "stars": 3, "license": "other", "language": "python", "size": 300}
{"docstring": "\"\"\" De-serialize the given string into it's original form. \"\"\"\n", "func_signal": "def loads(objstr):\n", "code": "obj = cerealizer.loads(objstr)\nreturn obj", "path": "src\\rounder\\network\\serialize.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\"\nthe equivalent of 'add half and chop'\nincrement the quotient if\n     the remainder is greater than half of the divisor\n  or the remainder is exactly half the divisor and the quotient is >= 0\n\"\"\"\n", "func_signal": "def addHalfAndChop(self, dividend, divisor, quotient, remainder):\n", "code": "c = cmp(remainder << 1, divisor)\n# c < 0 <-> remainder < divisor/2, etc\nif c > 0 or (c == 0 and quotient >= 0):\n    quotient += 1\nreturn quotient", "path": "src\\rounder\\fixedpoint.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\" Registers all classes we'll be serializing with cerealizer. \"\"\"\n", "func_signal": "def register_message_classes():\n", "code": "l = [\n    Card,\n    Suit,\n    TableState,\n    TableListing,\n    PotState,\n    PotWinner,\n    Currency,\n    PlayerState,\n    PostBlind,\n    Call,\n    Raise,\n    Fold,\n\n    Limit,\n    FixedLimit,\n]\nl.extend(ALL_EVENTS)\n\nfor message_class in l:\n    try:\n        cerealizer.register(message_class)\n    except ValueError:\n        logger.debug(\"Class already registered w/ cerealizer: %s\"\n                % message_class)", "path": "src\\rounder\\network\\serialize.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\"EJG/DF - Should this round instead?\n    Note e.g. long(-1.9) == -1L and long(1.9) == 1L in Python\n    Note that __int__ inherits whatever __long__ does,\n         and .frac() is affected too\n\"\"\"\n", "func_signal": "def __long__(self):\n", "code": "answer = abs(self.n) / _tento(self.p)\nif self.n < 0:\n    answer = -answer\nreturn answer", "path": "src\\rounder\\fixedpoint.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\" Return n, p s.t. self == n/10**p and n % 10 != 0\"\"\"\n", "func_signal": "def __reduce(self):\n", "code": "n, p = self.n, self.p\nif n == 0:\n    p = 0\nwhile p and n % 10 == 0:\n    p = p - 1\n    n = n / 10\nreturn n, p", "path": "src\\rounder\\fixedpoint.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "# No legit client would allow this, but a modified one might:\n", "func_signal": "def test_player_attempts_to_be_seated_twice(self):\n", "code": "self.__create_table(2, 0)\nsame_player = Player('player1', Currency(CHIPS))\nself.assertRaises(RounderException, self.table.seat_player,\n    same_player, 5)", "path": "test\\table-tests.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\"Write a message to the file.\"\"\"\n", "func_signal": "def log(self, message):\n", "code": "timestamp = time.strftime(\"[%H:%M:%S]\", time.localtime(time.time()))\nself.file.write('%s %s\\n' % (timestamp, message))\nself.file.flush()", "path": "src\\rounder-irc.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\"Called when an IRC user changes their nickname.\"\"\"\n", "func_signal": "def irc_NICK(self, prefix, params):\n", "code": "old_nick = prefix.split('!')[0]\nnew_nick = params[0]\nself.logger.log(\"%s is now known as %s\" % (old_nick, new_nick))", "path": "src\\rounder-irc.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\"\nMake FixedPoint objext - Return a new FixedPoint object with the selected\nprecision.\n\"\"\"\n", "func_signal": "def _mkFP(n, p, FixedPoint=FixedPoint):\n", "code": "f = FixedPoint()\n#print '_mkFP Debug: %s, value=%s' % (type(f),n)\nf.n = n\nf.p = p\nreturn f", "path": "src\\rounder\\fixedpoint.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\"\nReturns new FixedPoint containing the absolute value of\nthis FixedPoint\n\"\"\"\n", "func_signal": "def __abs__(self):\n", "code": "if self.n >= 0:\n    return self.copy()\nelse:\n    return -self", "path": "src\\rounder\\fixedpoint.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\"\nDivide x by y,\nreturn the result of rounding\nDevelopers may substitute their own 'round' for custom rounding\ny must be > 0\n\"\"\"\n", "func_signal": "def _roundquotient(self, x, y):\n", "code": "assert y > 0\nn, leftover = divmod(x, y)\nreturn self.round(x, y, n, leftover)", "path": "src\\rounder\\fixedpoint.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\"\nCreate the following seat structure:\n\nSeat 0: Player 0, sitting out\nSeat 1: Player 1, sitting in\nSeat 2: Empty\nSeat 3: Player 3, sitting in\nSeat 4: Empty\nSeat 5: Empty\nSeat 6: Player 6, sitting out\nSeat 7: Player 7, sitting in\nSeat 8: Empty\nSeat 9: Empty\n\"\"\"\n\n", "func_signal": "def __create_mixed_seats(self):\n", "code": "self.seats = Seats(10)\nself.player0 = Player(\"Player 0\")\nself.player1 = Player(\"Player 1\")\nself.player3 = Player(\"Player 3\")\nself.player6 = Player(\"Player 6\")\nself.player7 = Player(\"Player 7\")\n\nself.player0.sit_out()\nself.player6.sit_out()\n\nself.seats.seat_player(self.player0, 0)\nself.seats.seat_player(self.player1, 1)\nself.seats.seat_player(self.player3, 3)\nself.seats.seat_player(self.player6, 6)\nself.seats.seat_player(self.player7, 7)", "path": "test\\table-tests.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\"\nrounding via nearest-even\nincrement the quotient if\n     the remainder is more than half of the divisor\n  or the remainder is exactly half the divisor and the quotient is odd\n\"\"\"\n", "func_signal": "def bankersRounding(self, dividend, divisor, quotient, remainder):\n", "code": "c = cmp(remainder << 1, divisor)\n# c < 0 <-> remainder < divisor/2, etc\nif c > 0 or (c == 0 and (quotient & 1) == 1):\n    quotient += 1\nreturn quotient", "path": "src\\rounder\\fixedpoint.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\"\nScan the Python path and locate a file with the given name.\n\nSee:\n  http://www.linuxjournal.com/xstatic/articles/lj/0087/4702/4702l2.html\n\"\"\"\n\n", "func_signal": "def find_file_on_path(pathname):\n", "code": "if os.path.isabs(pathname):\n    return pathname\nfor dirname in sys.path:\n    candidate = os.path.join(dirname, pathname)\n    if os.path.isfile(candidate):\n        return candidate\nraise Exception(\"Could not find %s on the Python path.\"\n    % pathname)", "path": "src\\rounder\\ui\\gtk\\util.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\"Return the floating point representation of this FixedPoint.\n    Caution! float can lose precision.\n\"\"\"\n", "func_signal": "def __float__(self):\n", "code": "n, p = self.__reduce()\nreturn float(n) / float(_tento(p))", "path": "src\\rounder\\fixedpoint.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\"This will get called when the bot sees someone do an action.\"\"\"\n", "func_signal": "def action(self, user, channel, msg):\n", "code": "user = user.split('!', 1)[0]\nself.logger.log(\"* %s %s\" % (user, msg))", "path": "src\\rounder-irc.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\" Serialize the given object and return it's string form. \"\"\"\n", "func_signal": "def dumps(obj):\n", "code": "objstr = cerealizer.dumps(obj)\nreturn objstr", "path": "src\\rounder\\network\\serialize.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "# Dealer should be the small blind in a heads up match:\n", "func_signal": "def test_heads_up_blinds(self):\n", "code": "self.__create_table(2, 0)\nself.table.begin()\n\nself.table.process_action(self.players[0].username, 0, [])\nself.assertEquals(self.players[0], self.table.small_blind)\n\nself.table.process_action(self.players[1].username, 0, [])\nself.assertEquals(self.players[1], self.table.big_blind)", "path": "test\\table-tests.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "# XXX Be nicer about this\n", "func_signal": "def do(state, args):\n", "code": "from twisted.internet import reactor\nreactor.stop()", "path": "src\\rounder\\ui\\curses\\commands.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\" Caution!  == values must have equal hashes, and a FixedPoint\n    is essentially a rational in unnormalized form.  There's\n    really no choice here but to normalize it, so hash is\n    potentially expensive.\n    n, p = self.__reduce()\n\n    Obscurity: if the value is an exact integer, p will be 0 now,\n    so the hash expression reduces to hash(n).  So FixedPoints\n    that happen to be exact integers hash to the same things as\n    their int or long equivalents.  This is Good.  But if a\n    FixedPoint happens to have a value exactly representable as\n    a float, their hashes may differ.  This is a teensy bit Bad.\n\"\"\"\n", "func_signal": "def __hash__(self):\n", "code": "n, p = self.__reduce()\nreturn hash(n) ^ hash(p)", "path": "src\\rounder\\fixedpoint.py", "repo_name": "dgoodwin/rounder", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 848}
{"docstring": "\"\"\"Installs zc.buildout and buildout recipes for use by other tasks\"\"\"\n", "func_signal": "def install_recipes():\n", "code": "root = sys.prefix\ntry:\n    import zc.buildout\n    import zc.recipe.egg\n    import hexagonit.recipe.cmmi\nexcept ImportError:\n    sh(sjoin(sys.executable, pip_path, 'install -r recipes.txt --ignore-installed'))\n    rolluts.add_to_sys_path('hexagonit')\n    rolluts.add_to_sys_path('hexagonit.recipe.cmmi')\n    rolluts.add_to_sys_path('zc')\n    rolluts.add_to_sys_path('zc.buildout')\n    rolluts.add_to_sys_path('zc.recipe.egg')\n    import hexagonit.recipe.cmmi\n    import zc.buildout\n    import zc.recipe.egg", "path": "pavement.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"\nMake a filename relative, where the filename is dest, and it is\nbeing referred to from the filename source.\n\n    >>> make_relative_path('/usr/share/something/a-file.pth',\n    ...                    '/usr/share/another-place/src/Directory')\n    '../another-place/src/Directory'\n    >>> make_relative_path('/usr/share/something/a-file.pth',\n    ...                    '/home/user/src/Directory')\n    '../../../home/user/src/Directory'\n    >>> make_relative_path('/usr/share/a-file.pth', '/usr/share/')\n    './'\n\"\"\"\n", "func_signal": "def make_relative_path(source, dest, dest_is_directory=True):\n", "code": "source = os.path.dirname(source)\nif not dest_is_directory:\n    dest_filename = os.path.basename(dest)\n    dest = os.path.dirname(dest)\ndest = os.path.normpath(os.path.abspath(dest))\nsource = os.path.normpath(os.path.abspath(source))\ndest_parts = dest.strip(os.path.sep).split(os.path.sep)\nsource_parts = source.strip(os.path.sep).split(os.path.sep)\nwhile dest_parts and source_parts and dest_parts[0] == source_parts[0]:\n    dest_parts.pop(0)\n    source_parts.pop(0)\nfull_parts = ['..']*len(source_parts) + dest_parts\nif not dest_is_directory:\n    full_parts.append(dest_filename)\nif not full_parts:\n    # Special case for the current directory (otherwise it'd be '')\n    return './'\nreturn os.path.sep.join(full_parts)", "path": "psid_env.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"Delete 'bin' and 'lib'. Not reversible\"\"\"\n", "func_signal": "def de_env():\n", "code": "shutil.rmtree(os.path.join(sys.prefix, 'bin'))\nshutil.rmtree(os.path.join(sys.prefix, 'lib'))", "path": "pavement.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"Take the thing to wrap.\"\"\"\n", "func_signal": "def __init__(self, app, extra_props=None):\n", "code": "self.app = app\nself.extra_props = extra_props\nif self.extra_props:\n    import pdb;pdb.set_trace()", "path": "psid\\wsgi.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"\nMakes the already-existing environment use relative paths, and takes out \nthe #!-based environment selection in scripts.\n\"\"\"\n", "func_signal": "def make_environment_relocatable(home_dir):\n", "code": "activate_this = os.path.join(home_dir, 'bin', 'activate_this.py')\nif not os.path.exists(activate_this):\n    logger.fatal(\n        'The environment doesn\\'t have a file %s -- please re-run virtualenv '\n        'on this environment to update it' % activate_this)\nfixup_scripts(home_dir)\nfixup_pth_and_egg_link(home_dir)", "path": "psid_env.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"\nIf the executable given isn't an absolute path, search $PATH for the interpreter\n\"\"\"\n", "func_signal": "def resolve_interpreter(exe):\n", "code": "if os.path.abspath(exe) != exe:\n    paths = os.environ.get('PATH', '').split(os.pathsep)\n    for path in paths:\n        if os.path.exists(os.path.join(path, exe)):\n            exe = os.path.join(path, exe)\n            break\nif not os.path.exists(exe):\n    logger.fatal('The executable %s (from --python=%s) does not exist' % (exe, exe))\n    sys.exit(3)\nreturn exe", "path": "psid_env.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "# This is what we expect at the top of scripts:\n", "func_signal": "def fixup_scripts(home_dir):\n", "code": "shebang = '#!%s/bin/python' % os.path.normcase(os.path.abspath(home_dir))\n# This is what we'll put:\nnew_shebang = '#!/usr/bin/env python%s' % sys.version[:3]\nactivate = \"import os; activate_this=os.path.join(os.path.dirname(__file__), 'activate_this.py'); execfile(activate_this, dict(__file__=activate_this)); del os, activate_this\"\nbin_dir = os.path.join(home_dir, 'bin')\nfor filename in os.listdir(bin_dir):\n    filename = os.path.join(bin_dir, filename)\n    f = open(filename, 'rb')\n    lines = f.readlines()\n    f.close()\n    if not lines:\n        logger.warn('Script %s is an empty file' % filename)\n        continue\n    if lines[0].strip() != shebang:\n        if os.path.basename(filename) in OK_ABS_SCRIPTS:\n            logger.debug('Cannot make script %s relative' % filename)\n        if lines[0].strip() == new_shebang:\n            logger.info('Script %s has already been made relative' % filename)\n        else:\n            logger.warn('Script %s cannot be made relative (it\\'s not a normal script that starts with %s)'\n                        % (filename, shebang))\n        continue\n    logger.notify('Making script %s relative' % filename)\n    lines = [new_shebang+'\\n', activate+'\\n'] + lines[1:]\n    f = open(filename, 'wb')\n    f.writelines(lines)\n    f.close()", "path": "psid_env.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"create a simple pypi style index for for this virtualenv\"\"\"\n", "func_signal": "def compose_index():\n", "code": "try:\n    import compoze\nexcept ImportError:\n    sh(sjoin(sys.executable, pip_path, 'install -i http://dist.repoze.org/simple compoze'))\ndlpath = os.path.join(sys.prefix, 'downloads')\nsh(sjoin('%s/bin/compoze' %sys.prefix, 'fetch --path ', dlpath, ' --fetch-site-packages',\n         'index --path', dlpath ))", "path": "pavement.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"Makes .pth and .egg-link files use relative paths\"\"\"\n", "func_signal": "def fixup_pth_and_egg_link(home_dir):\n", "code": "home_dir = os.path.normcase(os.path.abspath(home_dir))\nfor path in sys.path:\n    if not path:\n        path = '.'\n    if not os.path.isdir(path):\n        continue\n    path = os.path.normcase(os.path.abspath(path))\n    if not path.startswith(home_dir):\n        logger.debug('Skipping system (non-environment) directory %s' % path)\n        continue\n    for filename in os.listdir(path):\n        filename = os.path.join(path, filename)\n        if filename.endswith('.pth'):\n            if not os.access(filename, os.W_OK):\n                logger.warn('Cannot write .pth file %s, skipping' % filename)\n            else:\n                fixup_pth_file(filename)\n        if filename.endswith('.egg-link'):\n            if not os.access(filename, os.W_OK):\n                logger.warn('Cannot write .egg-link file %s, skipping' % filename)\n            else:\n                fixup_egg_link(filename)", "path": "psid_env.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"\nCreates a bootstrap script, which is like this script but with\nextend_parser, adjust_options, and after_install hooks.\n\nThis returns a string that (written to disk of course) can be used\nas a bootstrap script with your own customizations.  The script\nwill be the standard virtualenv.py script, with your extra text\nadded (your extra text should be Python code).\n\nIf you include these functions, they will be called:\n\n``extend_parser(optparse_parser)``:\n    You can add or remove options from the parser here.\n\n``adjust_options(options, args)``:\n    You can change options here, or change the args (if you accept\n    different kinds of arguments, be sure you modify ``args`` so it is\n    only ``[DEST_DIR]``).\n\n``after_install(options, home_dir)``:\n\n    After everything is installed, this function is called.  This\n    is probably the function you are most likely to use.  An\n    example would be::\n\n        def after_install(options, home_dir):\n            subprocess.call([join(home_dir, 'bin', 'easy_install'),\n                             'MyPackage'])\n            subprocess.call([join(home_dir, 'bin', 'my-package-script'),\n                             'setup', home_dir])\n\n    This example immediately installs a package, and runs a setup\n    script from that package.\n\nIf you provide something like ``python_version='2.4'`` then the\nscript will start with ``#!/usr/bin/env python2.4`` instead of\n``#!/usr/bin/env python``.  You can use this when the script must\nbe run with a particular Python version.\n\"\"\"\n", "func_signal": "def create_bootstrap_script(extra_text, python_version=''):\n", "code": "filename = __file__\nif filename.endswith('.pyc'):\n    filename = filename[:-1]\nf = open(filename, 'rb')\ncontent = f.read()\nf.close()\npy_exe = 'python%s' % python_version\ncontent = (('#!/usr/bin/env %s\\n' % py_exe)\n           + '## WARNING: This file is generated\\n'\n           + content)\nreturn content.replace('##EXT' 'END##', extra_text)", "path": "psid_env.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"\n>>> l = Logger()\n>>> l.level_matches(3, 4)\nFalse\n>>> l.level_matches(3, 2)\nTrue\n>>> l.level_matches(slice(None, 3), 3)\nFalse\n>>> l.level_matches(slice(None, 3), 2)\nTrue\n>>> l.level_matches(slice(1, 3), 1)\nTrue\n>>> l.level_matches(slice(2, 3), 1)\nFalse\n\"\"\"\n", "func_signal": "def level_matches(self, level, consumer_level):\n", "code": "if isinstance(level, slice):\n    start, stop = level.start, level.stop\n    if start is not None and start > consumer_level:\n        return False\n    if stop is not None or stop <= consumer_level:\n        return False\n    return True\nelse:\n    return level >= consumer_level", "path": "psid_env.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"Install Rtree distribution according to arguments in buildout.cfg\"\"\"\n# rewrite to not use buildout\n", "func_signal": "def install_rtree_egg():\n", "code": "section = 'rtree'\ndef set_libspatial_path(fake_buildout):\n    import sys\n    ls_path = os.path.join(sys.prefix, 'lib', 'libspatialindex') \n    lsl = fake_buildout.setdefault('libspatialindex', dict(location=ls_path)) \n    return fake_buildout\ntry:\n    rollbo.custom_egg_brute_install(\"rtree\", _buildout, mod_buildout=set_libspatial_path)\nexcept :\n    raise\n    import pdb, sys; pdb.post_mortem(sys.exc_info()[2])", "path": "pavement.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"\n\"\"\"\n", "func_signal": "def get_uid(self, request):\n", "code": "uid = request.environ['selector.vars']['uid']\ntry:\n    # attempt to coerce uid to int\n    uid = int(uid)\nexcept ValueError:\n    pass\nreturn uid", "path": "psid\\app.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"If we are in a progress scope, and no log messages have been\nshown, write out another '.'\"\"\"\n", "func_signal": "def show_progress(self):\n", "code": "if self.in_progress_hanging:\n    sys.stdout.write('.')\n    sys.stdout.flush()", "path": "psid_env.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"\nSome platforms (particularly Gentoo on x64) put things in lib64/pythonX.Y\ninstead of lib/pythonX.Y.  If this is such a platform we'll just create a\nsymlink so lib64 points to lib\n\"\"\"\n", "func_signal": "def fix_lib64(lib_dir):\n", "code": "if [(i,j) for (i,j) in distutils.sysconfig.get_config_vars().items() \n    if isinstance(j, basestring) and 'lib64' in j]:\n    logger.debug('This system uses lib64; symlinking lib64 to lib')\n    assert os.path.basename(lib_dir) == 'python%s' % sys.version[:3], (\n        \"Unexpected python lib dir: %r\" % lib_dir)\n    lib_parent = os.path.dirname(lib_dir)\n    assert os.path.basename(lib_parent) == 'lib', (\n        \"Unexpected parent dir: %r\" % lib_parent)\n    copyfile(lib_parent, os.path.join(os.path.dirname(lib_parent), 'lib64'))", "path": "psid_env.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"Installs headers and libraries for libspatialindex\"\"\"\n", "func_signal": "def install_spatialindex():\n", "code": "name = 'libspatialindex'\nrollbo.hexagonit_cmmi(name, _buildout)", "path": "pavement.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"dispatch for GET conditions\"\"\"\n", "func_signal": "def GET(self, req, start_response):\n", "code": "path_seg = self.path_seg = req.path.split(\"/\")\n\nif not req.GET:\n    return self.index(req, start_response)\n\nreturn self.query(req, start_response)", "path": "psid\\app.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"Installs pip, easy_installs better behaved younger brother\"\"\"\n", "func_signal": "def install_pip():\n", "code": "root = sys.prefix\nglobal pip\ntry:\n    import pip\nexcept ImportError:\n    sh(easy_install_path+' pip')\n    site_packages_dir = os.path.dirname(os.__file__) +'/site-packages/'\n    for path in os.listdir(site_packages_dir):\n        if path.startswith('pip'):\n            sys.path.append(site_packages_dir+path)\n            working_set.add_entry(site_packages_dir+path)\n            return\nimport pip", "path": "pavement.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"load up buildout configuration for use by recipes\"\"\"\n", "func_signal": "def load_config():\n", "code": "global _buildout\n_buildout = rollbo.BuildoutCfg.loadfn('buildout.cfg')", "path": "pavement.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"Returns the level that stdout runs at\"\"\"\n", "func_signal": "def _stdout_level(self):\n", "code": "for level, consumer in self.consumers:\n    if consumer is sys.stdout:\n        return level\nreturn self.FATAL", "path": "psid_env.py", "repo_name": "whitmo/psid", "stars": 3, "license": "None", "language": "python", "size": 192}
{"docstring": "\"\"\"\nTest contrib.formtools.preview form retrieval.\n\nUse the client library to see if we can sucessfully retrieve\nthe form (mostly testing the setup ROOT_URLCONF\nprocess). Verify that an additional  hidden input field\nis created to manage the stage.\n\n\"\"\"\n", "func_signal": "def test_form_get(self):\n", "code": "response = self.client.get('/test1/')\nstage = self.input % 1\nself.assertContains(response, stage, 1)", "path": "django\\contrib\\formtools\\tests.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"\nFlags a comment. Confirmation on GET, action on POST.\n\nTemplates: `comments/flag_verify`, `comments/flag_done`\nContext:\n    comment\n        the flagged `comments.comments` object\n\"\"\"\n", "func_signal": "def flag(request, comment_id, extra_context=None, context_processors=None):\n", "code": "if extra_context is None: extra_context = {}\ncomment = get_object_or_404(Comment,pk=comment_id, site__id__exact=settings.SITE_ID)\nif request.POST:\n    UserFlag.objects.flag(comment, request.user)\n    return HttpResponseRedirect('%sdone/' % request.path)\nreturn render_to_response('comments/flag_verify.html', {'comment': comment},\n    context_instance=RequestContext(request, extra_context, context_processors))", "path": "django\\contrib\\comments\\views\\userflags.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "# 'LIMIT 20,40'\n", "func_signal": "def limit_offset_sql(self, limit, offset=None):\n", "code": "sql = \"LIMIT \"\nif offset and offset != 0:\n    sql += \"%s,\" % offset\nreturn sql + str(limit)", "path": "django\\db\\backends\\mysql\\base.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"\nGiven a first-choice name, adds an underscore to the name until it\nreaches a name that isn't claimed by any field in the form.\n\nThis is calculated rather than being hard-coded so that no field names\nare off-limits for use in the form.\n\"\"\"\n", "func_signal": "def unused_name(self, name):\n", "code": "while 1:\n    try:\n        f = self.form.base_fields[name]\n    except KeyError:\n        break # This field name isn't being used by the form.\n    name += '_'\nreturn name", "path": "django\\contrib\\formtools\\preview.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"\n>>> get_text_list(['a', 'b', 'c', 'd'])\nu'a, b, c or d'\n>>> get_text_list(['a', 'b', 'c'], 'and')\nu'a, b and c'\n>>> get_text_list(['a', 'b'], 'and')\nu'a and b'\n>>> get_text_list(['a'])\nu'a'\n>>> get_text_list([])\nu''\n\"\"\"\n", "func_signal": "def get_text_list(list_, last_word=ugettext_lazy(u'or')):\n", "code": "if len(list_) == 0: return u''\nif len(list_) == 1: return force_unicode(list_[0])\nreturn u'%s %s %s' % (', '.join([force_unicode(i) for i in list_][:-1]), force_unicode(last_word), force_unicode(list_[-1]))", "path": "django\\utils\\text.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"\nDeserialize a stream or a string. Returns an iterator that yields ``(obj,\nm2m_relation_dict)``, where ``obj`` is a instantiated -- but *unsaved* --\nobject, and ``m2m_relation_dict`` is a dictionary of ``{m2m_field_name :\nlist_of_related_objects}``.\n\"\"\"\n", "func_signal": "def deserialize(format, stream_or_string):\n", "code": "d = get_deserializer(format)\nreturn d(stream_or_string)", "path": "django\\core\\serializers\\__init__.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"\nTruncates html to a certain number of words (not counting tags and\ncomments). Closes opened tags if they were correctly closed in the given\nhtml.\n\"\"\"\n", "func_signal": "def truncate_html_words(s, num):\n", "code": "s = force_unicode(s)\nlength = int(num)\nif length <= 0:\n    return u''\nhtml4_singlets = ('br', 'col', 'link', 'base', 'img', 'param', 'area', 'hr', 'input')\n# Set up regular expressions\nre_words = re.compile(r'&.*?;|<.*?>|(\\w[\\w-]*)', re.U)\nre_tag = re.compile(r'<(/)?([^ ]+?)(?: (/)| .*?)?>')\n# Count non-HTML words and keep note of open tags\npos = 0\nellipsis_pos = 0\nwords = 0\nopen_tags = []\nwhile words <= length:\n    m = re_words.search(s, pos)\n    if not m:\n        # Checked through whole string\n        break\n    pos = m.end(0)\n    if m.group(1):\n        # It's an actual non-HTML word\n        words += 1\n        if words == length:\n            ellipsis_pos = pos\n        continue\n    # Check for tag\n    tag = re_tag.match(m.group(0))\n    if not tag or ellipsis_pos:\n        # Don't worry about non tags or tags after our truncate point\n        continue\n    closing_tag, tagname, self_closing = tag.groups()\n    tagname = tagname.lower()  # Element names are always case-insensitive\n    if self_closing or tagname in html4_singlets:\n        pass\n    elif closing_tag:\n        # Check for match in open tags list\n        try:\n            i = open_tags.index(tagname)\n        except ValueError:\n            pass\n        else:\n            # SGML: An end tag closes, back to the matching start tag, all unclosed intervening start tags with omitted end tags\n            open_tags = open_tags[i+1:]\n    else:\n        # Add it to the start of the open tags list\n        open_tags.insert(0, tagname)\nif words <= length:\n    # Don't try to close tags if we don't need to truncate\n    return s\nout = s[:ellipsis_pos] + ' ...'\n# Close any tags still open\nfor tag in open_tags:\n    out += '</%s>' % tag\n# Return string\nreturn out", "path": "django\\utils\\text.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"\nConvert the filename into an md5 string. We'll turn the first couple\nbits of the path into directory prefixes to be nice to filesystems\nthat have problems with large numbers of files in a directory.\n\nThus, a cache key of \"foo\" gets turnned into a file named\n``{cache-dir}ac/bd/18db4cc2f85cedef654fccc4a4d8``.\n\"\"\"\n", "func_signal": "def _key_to_file(self, key):\n", "code": "path = md5.new(key.encode('utf-8')).hexdigest()\npath = os.path.join(path[:2], path[2:4], path[4:])\nreturn os.path.join(self._dir, path)", "path": "django\\core\\cache\\backends\\filebased.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "# NB: The generated SQL below is specific to MySQL\n# 'TRUNCATE x;', 'TRUNCATE y;', 'TRUNCATE z;'... style SQL statements\n# to clear all tables of all data\n", "func_signal": "def sql_flush(self, style, tables, sequences):\n", "code": "if tables:\n    sql = ['SET FOREIGN_KEY_CHECKS = 0;']\n    for table in tables:\n        sql.append('%s %s;' % (style.SQL_KEYWORD('TRUNCATE'), style.SQL_FIELD(self.quote_name(table))))\n    sql.append('SET FOREIGN_KEY_CHECKS = 1;')\n\n    # 'ALTER TABLE table AUTO_INCREMENT = 1;'... style SQL statements\n    # to reset sequence indices\n    sql.extend([\"%s %s %s %s %s;\" % \\\n        (style.SQL_KEYWORD('ALTER'),\n         style.SQL_KEYWORD('TABLE'),\n         style.SQL_TABLE(self.quote_name(sequence['table'])),\n         style.SQL_KEYWORD('AUTO_INCREMENT'),\n         style.SQL_FIELD('= 1'),\n        ) for sequence in sequences])\n    return sql\nelse:\n    return []", "path": "django\\db\\backends\\mysql\\base.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"\nA word-wrap function that preserves existing line breaks and most spaces in\nthe text. Expects that existing line breaks are posix newlines.\n\"\"\"\n", "func_signal": "def wrap(text, width):\n", "code": "text = force_unicode(text)\ndef _generator():\n    it = iter(text.split(' '))\n    word = it.next()\n    yield word\n    pos = len(word) - word.rfind('\\n') - 1\n    for word in it:\n        if \"\\n\" in word:\n            lines = word.split('\\n')\n        else:\n            lines = (word,)\n        pos += len(lines[0]) + 1\n        if pos > width:\n            yield '\\n'\n            pos = len(lines[-1])\n        else:\n            yield ' '\n            if len(lines) > 1:\n                pos = len(lines[-1])\n        yield word\nreturn u''.join(_generator())", "path": "django\\utils\\text.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"\nTest contrib.formtools.preview form submittal.\n\nUse the client library to POST to the form with stage set to 3\nto see if our forms done() method is called. Check first\nwithout the security hash, verify failure, retry with security\nhash and verify sucess.\n\n\"\"\"\n# Pass strings for form submittal and add stage variable to\n# show we previously saw first stage of the form.\n", "func_signal": "def test_form_submit(self):\n", "code": "test_data.update({'stage': 2})\nresponse = self.client.post('/test1/', test_data)\nself.failIfEqual(response.content, success_string)\nhash = self.preview.security_hash(None, TestForm(test_data))\ntest_data.update({'hash': hash})\nresponse = self.client.post('/test1/', test_data)\nself.assertEqual(response.content, success_string)", "path": "django\\contrib\\formtools\\tests.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"\nRedirect to a given URL.\n\nThe given url may contain dict-style string formatting, which will be\ninterpolated against the params in the URL.  For example, to redirect from\n``/foo/<id>/`` to ``/bar/<id>/``, you could use the following URLconf::\n\n    urlpatterns = patterns('',\n        ('^foo/(?P<id>\\d+)/$', 'django.views.generic.simple.redirect_to', {'url' : '/bar/%(id)s/'}),\n    )\n\nIf the given url is ``None``, a HttpResponseGone (410) will be issued.\n\"\"\"\n", "func_signal": "def redirect_to(request, url, **kwargs):\n", "code": "if url is not None:\n    return HttpResponsePermanentRedirect(url % kwargs)\nelse:\n    return HttpResponseGone()", "path": "django\\views\\generic\\simple.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"\nTest contrib.formtools.preview form preview rendering.\n\nUse the client library to POST to the form to see if a preview\nis returned.  If we do get a form back check that the hidden\nvalue is correctly managing the state of the form.\n\n\"\"\"\n# Pass strings for form submittal and add stage variable to\n# show we previously saw first stage of the form.\n", "func_signal": "def test_form_preview(self):\n", "code": "test_data.update({'stage': 1})\nresponse = self.client.post('/test1/', test_data)\n# Check to confirm stage is set to 2 in output form.\nstage = self.input % 2\nself.assertContains(response, stage, 1)", "path": "django\\contrib\\formtools\\tests.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"Register a new serializer by passing in a module name.\"\"\"\n", "func_signal": "def register_serializer(format, serializer_module):\n", "code": "module = __import__(serializer_module, {}, {}, [''])\n_serializers[format] = module", "path": "django\\core\\serializers\\__init__.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"\nCalculates the security hash for the given Form instance.\n\nThis creates a list of the form field names/values in a deterministic\norder, pickles the result with the SECRET_KEY setting and takes an md5\nhash of that.\n\nSubclasses may want to take into account request-specific information\nsuch as the IP address.\n\"\"\"\n", "func_signal": "def security_hash(self, request, form):\n", "code": "data = [(bf.name, bf.data or '') for bf in form] + [settings.SECRET_KEY]\n# Use HIGHEST_PROTOCOL because it's the most efficient. It requires\n# Python 2.3, but Django requires 2.3 anyway, so that's OK.\npickled = pickle.dumps(data, pickle.HIGHEST_PROTOCOL)\nreturn md5.new(pickled).hexdigest()", "path": "django\\contrib\\formtools\\preview.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"\nRegister built-in and settings-defined serializers. This is done lazily so\nthat user code has a chance to (e.g.) set up custom settings without\nneeding to be careful of import order.\n\"\"\"\n", "func_signal": "def _load_serializers():\n", "code": "for format in BUILTIN_SERIALIZERS:\n    register_serializer(format, BUILTIN_SERIALIZERS[format])\nif hasattr(settings, \"SERIALIZATION_MODULES\"):\n    for format in settings.SERIALIZATION_MODULES:\n        register_serializer(format, settings.SERIALIZATION_MODULES[format])", "path": "django\\core\\serializers\\__init__.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "# It's not worth compressing non-OK or really short responses.\n", "func_signal": "def process_response(self, request, response):\n", "code": "if response.status_code != 200 or len(response.content) < 200:\n    return response\n\npatch_vary_headers(response, ('Accept-Encoding',))\n\n# Avoid gzipping if we've already got a content-encoding.\nif response.has_header('Content-Encoding'):\n    return response\n\n# Older versions of IE have issues with gzipped pages containing either\n# Javascript and PDF.\nif \"msie\" in request.META.get('HTTP_USER_AGENT', '').lower():\n    ctype = response.get('Content-Type', '').lower()\n    if \"javascript\" in ctype or ctype == \"application/pdf\":\n        return response\n\nae = request.META.get('HTTP_ACCEPT_ENCODING', '')\nif not re_accepts_gzip.search(ae):\n    return response\n\nresponse.content = compress_string(response.content)\nresponse['Content-Encoding'] = 'gzip'\nresponse['Content-Length'] = str(len(response.content))\nreturn response", "path": "django\\middleware\\gzip.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"\nSerialize a queryset (or any iterator that returns database objects) using\na certain serializer.\n\"\"\"\n", "func_signal": "def serialize(format, queryset, **options):\n", "code": "s = get_serializer(format)()\ns.serialize(queryset, **options)\nreturn s.getvalue()", "path": "django\\core\\serializers\\__init__.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"\nDeletes a comment. Confirmation on GET, action on POST.\n\nTemplates: `comments/delete_verify`, `comments/delete_done`\nContext:\n    comment\n        the flagged `comments.comments` object\n\"\"\"\n", "func_signal": "def delete(request, comment_id, extra_context=None, context_processors=None):\n", "code": "if extra_context is None: extra_context = {}\ncomment = get_object_or_404(Comment,pk=comment_id, site__id__exact=settings.SITE_ID)\nif not Comment.objects.user_is_moderator(request.user):\n    raise Http404\nif request.POST:\n    # If the comment has already been removed, silently fail.\n    if not comment.is_removed:\n        comment.is_removed = True\n        comment.save()\n        m = ModeratorDeletion(None, request.user.id, comment.id, None)\n        m.save()\n    return HttpResponseRedirect('%sdone/' % request.path)\nreturn render_to_response('comments/delete_verify.html', {'comment': comment},\n    context_instance=RequestContext(request, extra_context, context_processors))", "path": "django\\contrib\\comments\\views\\userflags.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "\"\"\"\nRender a given template with any extra URL parameters in the context as\n``{{ params }}``.\n\"\"\"\n", "func_signal": "def direct_to_template(request, template, extra_context=None, mimetype=None, **kwargs):\n", "code": "if extra_context is None: extra_context = {}\ndictionary = {'params': kwargs}\nfor key, value in extra_context.items():\n    if callable(value):\n        dictionary[key] = value()\n    else:\n        dictionary[key] = value\nc = RequestContext(request, dictionary)\nt = loader.get_template(template)\nreturn HttpResponse(t.render(c), mimetype=mimetype)", "path": "django\\views\\generic\\simple.py", "repo_name": "kkubasik/human-evolution-database", "stars": 3, "license": "None", "language": "python", "size": 2232}
{"docstring": "# Models can define a CLEANUP_REFERENCES attribute if they have\n# reference properties that must get geleted with the model.\n", "func_signal": "def _get_included_cleanup_entities(entities, rels_seen, to_delete, to_put):\n", "code": "include_references = getattr(entities[0], 'CLEANUP_REFERENCES', None)\nif include_references:\n    if not isinstance(include_references, (list, tuple)):\n        include_references = (include_references,)\n    prefetch_references(entities, include_references)\n    for entity in entities:\n        for name in include_references:\n            subentity = getattr(entity, name)\n            to_delete.append(subentity)\n            get_cleanup_entities(subentity, rels_seen=rels_seen,\n                    to_delete=to_delete, to_put=to_put)", "path": "LazyLecturer\\cook\\common\\appenginepatch\\ragendja\\dbutils.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"Helper method for get_filtered.\"\"\"\n", "func_signal": "def get_filters(*filters):\n", "code": "if len(filters) % 2 == 1:\n    raise ValueError('You must supply an even number of arguments!')\nreturn zip(filters[::2], filters[1::2])", "path": "LazyLecturer\\cook\\common\\appenginepatch\\ragendja\\dbutils.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"Assign a set of tags to a single bundle, wipes away previous\nsettings for bundle. Returns a `result` messages or raises an\n``DeliciousError``. See ``self.request()``.\n\n&bundle (required)\n    the bundle name.\n&tags (required)\n    list of tags.\n\"\"\"\n", "func_signal": "def bundles_set(self, bundle, tags, **kwds):\n", "code": "if type(tags)==list:\n    tags = \" \".join(tags)\nreturn self.request(\"tags/bundles/set\", bundle=bundle, tags=tags,\n        **kwds)", "path": "LazyLecturer\\cook\\pydelicious\\__init__.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"Decorator that always runs the given function in a transaction.\"\"\"\n", "func_signal": "def transaction(func):\n", "code": "def _transaction(*args, **kwargs):\n    return db.run_in_transaction(func, *args, **kwargs)\n# In case you need to run it without a transaction you can call\n# <func>.non_transactional(...)\n_transaction.non_transactional = func\nreturn _transaction", "path": "LazyLecturer\\cook\\common\\appenginepatch\\ragendja\\dbutils.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"\nThis function creates an object transactionally if it does not exist in\nthe datastore. Otherwise it returns None.\n\"\"\"\n", "func_signal": "def db_add(model, key_name, parent=None, **kwargs):\n", "code": "existing = model.get_by_key_name(key_name, parent=parent)\nif not existing:\n    new_entity = model(parent=parent, key_name=key_name, **kwargs)\n    new_entity.put()\n    return new_entity\nreturn None", "path": "LazyLecturer\\cook\\common\\appenginepatch\\ragendja\\dbutils.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"Copy all media files directly\"\"\"\n", "func_signal": "def add_uncombined_app_media(env, app):\n", "code": "path = os.path.join(\n    os.path.dirname(__import__(app, {}, {}, ['']).__file__), 'media')\napp = app.rsplit('.', 1)[-1]\nfor root, dirs, files in os.walk(path):\n    for file in files:\n        if file.endswith(('.css', '.js')):\n            base = os.path.join(root, file)[len(path):].replace(os.sep,\n                '/').lstrip('/')\n            target = '%s/%s' % (app, base)\n            add_app_media(env, target, target)", "path": "LazyLecturer\\cook\\common\\appenginepatch\\ragendja\\settings_post.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"Helper method for get_xxx_or_404.\"\"\"\n", "func_signal": "def get_filtered(data, *filters):\n", "code": "for filter in get_filters(*filters):\n    data.filter(*filter)\nreturn data", "path": "LazyLecturer\\cook\\common\\appenginepatch\\ragendja\\dbutils.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"\nBuild a urllib2 style opener with HTTP Basic authorization for one host\nand additional error handling.\n\"\"\"\n", "func_signal": "def build_api_opener(host, user, passwd, extra_handlers=()):\n", "code": "if DEBUG: httplib.HTTPConnection.debuglevel = 1\n\npassword_manager = urllib2.HTTPPasswordMgrWithDefaultRealm()\npassword_manager.add_password(None, host, user, passwd)\nauth_handler = urllib2.HTTPBasicAuthHandler(password_manager)\n\nhttp_error_handler = HTTPErrorHandler()\n\nreturn urllib2.build_opener(auth_handler, http_error_handler, *extra_handlers)", "path": "LazyLecturer\\cook\\pydelicious\\__init__.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"\nConverts a models into dicts for use with JSONResponse.\n\nYou can either pass a single model instance and get a single dict\nor a list of models and get a list of dicts.\n\nFor security reasons only the properties in the property_list will get\nadded. If the value of the property has a json_data function its result\nwill be added, instead.\n\"\"\"\n", "func_signal": "def to_json_data(model_instance, property_list):\n", "code": "if hasattr(model_instance, '__iter__'):\n    return [to_json_data(item, property_list) for item in model_instance]\njson_data = {}\nfor property in property_list:\n    property_instance = None\n    try:\n        property_instance = getattr(model_instance.__class__,\n            property.split('.', 1)[0])\n    except:\n        pass\n    key_access = property[len(property.split('.', 1)[0]):]\n    if isinstance(property_instance, db.ReferenceProperty) and \\\n            key_access in ('.key', '.key.name'):\n        key = property_instance.get_value_for_datastore(model_instance)\n        if key_access == '.key':\n            json_data[property] = str(key)\n        else:\n            json_data[property] = key.name()\n        continue\n    value = getattr_by_path(model_instance, property, None)\n    value = getattr_by_path(value, 'json_data', value)\n    json_data[property] = value\nreturn json_data", "path": "LazyLecturer\\cook\\common\\appenginepatch\\ragendja\\dbutils.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"Returns posts matching the arguments. If no date or url is given,\nmost recent date will be used.\n::\n\n    <posts dt=\"CCYY-MM-DD\" tag=\"...\" user=\"...\">\n        <post ...>\n\n&tag={TAG} {TAG} ... {TAG}\n    (optional) Filter by this/these tag(s).\n&dt={CCYY-MM-DDThh:mm:ssZ}\n    (optional) Filter by this date, defaults to the most recent date on\n    which bookmarks were saved.\n&url={URL}\n    (optional) Fetch a bookmark for this URL, regardless of date.\n&hashes={MD5} {MD5} ... {MD5}\n    (optional) Fetch multiple bookmarks by one or more URL MD5s\n    regardless of date.\n&meta=yes\n    (optional) Include change detection signatures on each item in a\n    'meta' attribute. Clients wishing to maintain a synchronized local\n    store of bookmarks should retain the value of this attribute - its\n    value will change when any significant field of the bookmark\n    changes.\n\"\"\"\n", "func_signal": "def posts_get(self, tag=\"\", dt=\"\", url=\"\", hashes=[], meta=True, **kwds):\n", "code": "return self.request(\"posts/get\", tag=tag, dt=dt, url=url,\n        hashes=hashes, meta=meta, **kwds)", "path": "LazyLecturer\\cook\\pydelicious\\__init__.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "# Remove modules that we want to override\n", "func_signal": "def patch_python():\n", "code": "for module in ('memcache',):\n    if module in sys.modules:\n        del sys.modules[module]\n\n# For some reason the imp module can't be replaced via sys.path\nfrom appenginepatcher import have_appserver\nif have_appserver:\n    from appenginepatcher import imp\n    sys.modules['imp'] = imp\n\nif have_appserver:\n    def unlink(_):\n        raise NotImplementedError('App Engine does not support FS writes!')\n    os.unlink = unlink", "path": "LazyLecturer\\cook\\common\\appenginepatch\\appenginepatcher\\patch.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"\nDereferences the given (Key)ReferenceProperty fields of a list of objects\nin as few get() calls as possible.\n\"\"\"\n", "func_signal": "def prefetch_references(object_list, references):\n", "code": "if object_list and references:\n    if not isinstance(references, (list, tuple)):\n        references = (references,)\n    model = object_list[0].__class__\n    targets = {}\n    # Collect models and keys of all reference properties.\n    # Storage format of targets: models -> keys -> instance, property\n    for name in set(references):\n        property = getattr(model, name)\n        is_key_reference = isinstance(property, KeyReferenceProperty)\n        if is_key_reference:\n            target_model = property.target_model\n        else:\n            target_model = property.reference_class\n        prefetch = targets.setdefault(target_model.kind(),\n                                      (target_model, {}))[1]\n        for item in object_list:\n            if is_key_reference:\n                # Check if we already dereferenced the property\n                if hasattr(item, '_ref_cache_for_' + property.target_name):\n                    continue\n                key = getattr(item, property.target_name)\n                if property.use_key_name and key:\n                    key = db.Key.from_path(target_model.kind(), key)\n            else:\n                if ReferenceProperty.is_resolved(property, item):\n                    continue\n                key = property.get_value_for_datastore(item)\n            if key:\n                key = str(key)\n                prefetch[key] = prefetch.get(key, ()) + ((item, name),)\n    for target_model, prefetch in targets.values():\n        prefetched_items = target_model.get(prefetch.keys())\n        for prefetched, group in zip(prefetched_items, prefetch.values()):\n            for item, reference in group:\n                # If prefetched is None we only update the cache\n                if not prefetched:\n                    property = getattr(model, reference)\n                    if isinstance(property, KeyReferenceProperty):\n                        setattr(item,\n                            '_ref_cache_for_' + property.target_name, None)\n                    else:\n                        continue\n                setattr(item, reference, prefetched)\nreturn object_list", "path": "LazyLecturer\\cook\\common\\appenginepatch\\ragendja\\dbutils.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"\nuser\natleast=###         include only tags for which there are at least ### \n                    number of posts.\ncount=###           include ### tags, counting down from the top.\nsort={alpha|count}  construct the object with tags in alphabetic order \n                    (alpha), or by count of posts (count).\ncallback=NAME       wrap the object definition in a function call NAME(...),\n                    thus invoking that function when the feed is executed.\nraw                 a pure JSON object is returned, instead of code that \n                    will construct an object named Delicious.tags.\n\"\"\"\n", "func_signal": "def json_tags(user, atleast, count, sort='alpha', raw=True, callback=None):\n", "code": "url = 'http://del.icio.us/feeds/json/tags/' + \\\n        dlcs_encode_params({0:user})[0]\nreturn dlcs_feed(url, atleast=atleast, count=count, sort=sort, raw=raw, \n        callback=callback)", "path": "LazyLecturer\\cook\\pydelicious\\__init__.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"Sends a request message to `path` in the API, and parses the results\nfrom XML. Use with ``_raw=True`` or ``call request_raw()`` directly\nto get the filehandler and process the response message manually.\n\nCalls to some paths will return a `result` message, i.e.::\n\n    <result code=\"...\" />\n\nor::\n\n    <result>...</result>\n\nThese should all be parsed to ``{'result':(Boolean, MessageString)}``,\nthis method raises a ``DeliciousError`` on negative `result` answers.\nPositive answers are silently accepted and nothing is returned.\n\nUsing ``_raw=True`` bypasses all parsing and never raises\n``DeliciousError``.\n\nSee ``dlcs_parse_xml()`` and ``self.request_raw()``.\"\"\"\n\n", "func_signal": "def request(self, path, _raw=False, **params):\n", "code": "if _raw:\n    # return answer\n    return self.request_raw(path, **params)\n\nelse:\n    params = self._encode_params(params, self.codec)\n\n    # get answer and parse\n    fl = self._api_request(path, params=params, opener=self._opener)\n    rs = self._parse_response(fl)\n\n    if type(rs) == dict and 'result' in rs:\n        if not rs['result'][0]:\n            # Raise an error for negative 'result' answers\n            errmsg = \"\"\n            if len(rs['result'])>0:\n                errmsg = rs['result'][1]\n            DeliciousError.raiseFor(errmsg, path, **params)\n\n        else:\n            # not out-of-the-oridinary result, OK\n            return\n\n    return rs", "path": "LazyLecturer\\cook\\pydelicious\\__init__.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"\ncallback=NAME       wrap the object definition in a function call NAME(...)\n?raw                a raw JSON object is returned, instead of an object named \n                    Delicious.posts\n\"\"\"\n", "func_signal": "def json_network(user, raw=True, callback=None):\n", "code": "url = 'http://del.icio.us/feeds/json/network/' + \\\n        dlcs_encode_params({0:user})[0]\nreturn dlcs_feed(url, raw=raw, callback=callback)", "path": "LazyLecturer\\cook\\pydelicious\\__init__.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"\nEscapes a string such that it can be used safely as a key_name.\n\nYou can pass multiple values in order to build a path.\n\"\"\"\n", "func_signal": "def generate_key_name(*values):\n", "code": "return KEY_NAME_PREFIX + '/'.join(\n    [value.replace('%', '%1').replace('/', '%2') for value in values])", "path": "LazyLecturer\\cook\\common\\appenginepatch\\ragendja\\dbutils.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "# Remove the standard version of Django\n", "func_signal": "def setup_project():\n", "code": "for k in [k for k in sys.modules if k.startswith('django')]:\n    del sys.modules[k]\n\nfrom appenginepatcher import on_production_server\nif on_production_server:\n    # This fixes a pwd import bug for os.path.expanduser()\n    global env_ext\n    env_ext['HOME'] = PROJECT_DIR\n\nos.environ.update(env_ext)\n\n# Add the two parent folders and appenginepatcher's lib folder to sys.path.\n# The current folder has to be added in main.py or setup_env(). This\n# suggests a folder structure where you separate reusable code from project\n# code:\n# project -> common -> appenginepatch\n# You can put a custom Django version into the \"common\" folder, for example.\nEXTRA_PATHS = [\n    PROJECT_DIR,\n    COMMON_DIR,\n]\n\nthis_folder = os.path.abspath(os.path.dirname(__file__))\nEXTRA_PATHS.append(os.path.join(this_folder, 'appenginepatcher', 'lib'))\n\n# We support zipped packages in the common and project folders.\n# The files must be in the packages folder.\nfor packages_dir in ZIP_PACKAGES_DIRS:\n    if os.path.isdir(packages_dir):\n        for zip_package in os.listdir(packages_dir):\n            EXTRA_PATHS.append(os.path.join(packages_dir, zip_package))\n\nsys.path = EXTRA_PATHS + sys.path", "path": "LazyLecturer\\cook\\common\\appenginepatch\\aecmd.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"Calls the path in the API, returns the filehandle. Returned file-\nlike instances have an ``HTTPMessage`` instance with HTTP header\ninformation available. Use ``filehandle.info()`` or refer to the\n``urllib2.openurl`` documentation.\n\"\"\"\n# see `request()` on how the response can be handled\n", "func_signal": "def request_raw(self, path, **params):\n", "code": "params = self._encode_params(params, self.codec)\nreturn self._api_request(path, params=params, opener=self._opener)", "path": "LazyLecturer\\cook\\pydelicious\\__init__.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"\nuser\ncount=###   the number of posts you want to get (default is 15, maximum \n            is 100)\nraw         a raw JSON object is returned, instead of an object named \n            Delicious.posts\n\"\"\"\n", "func_signal": "def json_posts(user, count=15, tag=None, raw=True):\n", "code": "url = \"http://del.icio.us/feeds/json/\" + \\\n        dlcs_encode_params({0:user})[0]\nif tag: url += '/'+dlcs_encode_params({0:tag})[0]\n\nreturn dlcs_feed(url, count=count, raw=raw)", "path": "LazyLecturer\\cook\\pydelicious\\__init__.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"\ncallback=NAME       wrap the object definition in a function call NAME(...)\n?raw                a pure JSON object is returned, instead of an object named \n                    Delicious.\n\"\"\"\n", "func_signal": "def json_fans(user, raw=True, callback=None):\n", "code": "url = 'http://del.icio.us/feeds/json/fans/' + \\\n        dlcs_encode_params({0:user})[0]\nreturn dlcs_feed(url, raw=raw, callback=callback)", "path": "LazyLecturer\\cook\\pydelicious\\__init__.py", "repo_name": "ianibo/dev8d", "stars": 2, "license": "None", "language": "python", "size": 3576}
{"docstring": "\"\"\"Turns a list of maps, lists, or scalars into a single map.\nUsed to build the SELF_CLOSING_TAGS, NESTABLE_TAGS, and\nNESTING_RESET_TAGS maps out of lists and partial maps.\"\"\"\n", "func_signal": "def buildTagMap(default, *args):\n", "code": "built = {}\nfor portion in args:\n    if hasattr(portion, 'items'):\n        #It's a map. Merge it.\n        for k,v in portion.items():\n            built[k] = v\n    elif isList(portion):\n        #It's a list. Map each item to the default.\n        for k in portion:\n            built[k] = default\n    else:\n        #It's a scalar. Map it to the default.\n        built[portion] = default\nreturn built", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Destructively rips this element out of the tree.\"\"\"\n", "func_signal": "def extract(self):\n", "code": "if self.parent:\n    try:\n        self.parent.contents.remove(self)\n    except ValueError:\n        pass\n\n#Find the two elements that would be next to each other if\n#this element (and any children) hadn't been parsed. Connect\n#the two.\nlastChild = self._lastRecursiveChild()\nnextElement = lastChild.next\n\nif self.previous:\n    self.previous.next = nextElement\nif nextElement:\n    nextElement.previous = self.previous\nself.previous = None\nlastChild.next = None\n\nself.parent = None\nif self.previousSibling:\n    self.previousSibling.nextSibling = self.nextSibling\nif self.nextSibling:\n    self.nextSibling.previousSibling = self.previousSibling\nself.previousSibling = self.nextSibling = None", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "# Convert the document to Unicode.\n", "func_signal": "def _feed(self, inDocumentEncoding=None):\n", "code": "markup = self.markup\nif isinstance(markup, unicode):\n    if not hasattr(self, 'originalEncoding'):\n        self.originalEncoding = None\nelse:\n    dammit = UnicodeDammit\\\n             (markup, [self.fromEncoding, inDocumentEncoding],\n              smartQuotesTo=self.smartQuotesTo)\n    markup = dammit.unicode\n    self.originalEncoding = dammit.originalEncoding\nif markup:\n    if self.markupMassage:\n        if not isList(self.markupMassage):\n            self.markupMassage = self.MARKUP_MASSAGE\n        for fix, m in self.markupMassage:\n            markup = fix.sub(m, markup)\n        # TODO: We get rid of markupMassage so that the\n        # soup object can be deepcopied later on. Some\n        # Python installations can't copy regexes. If anyone\n        # was relying on the existence of markupMassage, this\n        # might cause problems.\n        del(self.markupMassage)\nself.reset()\n\nSGMLParser.feed(self, markup)\n# Close out any unfinished strings and close all the open tags.\nself.endData()\nwhile self.currentTag.name != self.ROOT_TAG_NAME:\n    self.popTag()", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Setting tag[key] sets the value of the 'key' attribute for the\ntag.\"\"\"\n", "func_signal": "def __setitem__(self, key, value):\n", "code": "self._getAttrMap()\nself.attrMap[key] = value\nfound = False\nfor i in range(0, len(self.attrs)):\n    if self.attrs[i][0] == key:\n        self.attrs[i] = (key, value)\n        found = True\nif not found:\n    self.attrs.append((key, value))\nself._getAttrMap()[key] = value", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Used in a call to re.sub to replace HTML, XML, and numeric\nentities with the appropriate Unicode characters. If HTML\nentities are being converted, any unrecognized entities are\nescaped.\"\"\"\n", "func_signal": "def _convertEntities(self, match):\n", "code": "x = match.group(1)\nif self.convertHTMLEntities and x in name2codepoint:\n    return unichr(name2codepoint[x])\nelif x in self.XML_ENTITIES_TO_SPECIAL_CHARS:\n    if self.convertXMLEntities:\n        return self.XML_ENTITIES_TO_SPECIAL_CHARS[x]\n    else:\n        return u'&%s;' % x\nelif len(x) > 0 and x[0] == '#':\n    # Handle numeric entities\n    if len(x) > 1 and x[1] == 'x':\n        return unichr(int(x[2:], 16))\n    else:\n        return unichr(int(x[1:]))\n\nelif self.escapeUnrecognizedEntities:\n    return u'&amp;%s;' % x\nelse:\n    return u'&%s;' % x", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Changes a MS smart quote character to an XML or HTML\nentity.\"\"\"\n", "func_signal": "def _subMSChar(self, orig):\n", "code": "sub = self.MS_CHARS.get(orig)\nif type(sub) == types.TupleType:\n    if self.smartQuotesTo == 'xml':\n        sub = '&#x%s;' % sub[1]\n    else:\n        sub = '&%s;' % sub[0]\nreturn sub", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Returns the closest sibling to this Tag that matches the\ngiven criteria and appears after this Tag in the document.\"\"\"\n", "func_signal": "def findNextSibling(self, name=None, attrs={}, text=None, **kwargs):\n", "code": "return self._findOne(self.findNextSiblings, name, attrs, text,\n                     **kwargs)", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Pops the tag stack up to and including the most recent\ninstance of the given tag. If inclusivePop is false, pops the tag\nstack up to but *not* including the most recent instqance of\nthe given tag.\"\"\"\n#print \"Popping to %s\" % name\n", "func_signal": "def _popToTag(self, name, inclusivePop=True):\n", "code": "if name == self.ROOT_TAG_NAME:\n    return\n\nnumPops = 0\nmostRecentTag = None\nfor i in range(len(self.tagStack)-1, 0, -1):\n    if name == self.tagStack[i].name:\n        numPops = len(self.tagStack)-i\n        break\nif not inclusivePop:\n    numPops = numPops - 1\n\nfor i in range(0, numPops):\n    mostRecentTag = self.popTag()\nreturn mostRecentTag", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "#print \"End tag %s\" % name\n", "func_signal": "def unknown_endtag(self, name):\n", "code": "if self.quoteStack and self.quoteStack[-1] != name:\n    #This is not a real end tag.\n    #print \"</%s> is not real!\" % name\n    self.handle_data('</%s>' % name)\n    return\nself.endData()\nself._popToTag(name)\nif self.quoteStack and self.quoteStack[-1] == name:\n    self.quoteStack.pop()\n    self.literal = (len(self.quoteStack) > 0)", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "#print \"Push\", tag.name\n", "func_signal": "def pushTag(self, tag):\n", "code": "if self.currentTag:\n    self.currentTag.contents.append(tag)\nself.tagStack.append(tag)\nself.currentTag = self.tagStack[-1]", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Returns true iff this tag has the same name, the same attributes,\nand the same contents (recursively) as the given tag.\n\nNOTE: right now this will return false if two tags have the\nsame attributes in a different order. Should this be fixed?\"\"\"\n", "func_signal": "def __eq__(self, other):\n", "code": "if not hasattr(other, 'name') or not hasattr(other, 'attrs') or not hasattr(other, 'contents') or self.name != other.name or self.attrs != other.attrs or len(self) != len(other):\n    return False\nfor i in range(0, len(self.contents)):\n    if self.contents[i] != other.contents[i]:\n        return False\nreturn True", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "'''Given a string and its encoding, decodes the string into Unicode.\n%encoding is a string recognized by encodings.aliases'''\n\n# strip Byte Order Mark (if present)\n", "func_signal": "def _toUnicode(self, data, encoding):\n", "code": "if (len(data) >= 4) and (data[:2] == '\\xfe\\xff') \\\n       and (data[2:4] != '\\x00\\x00'):\n    encoding = 'utf-16be'\n    data = data[2:]\nelif (len(data) >= 4) and (data[:2] == '\\xff\\xfe') \\\n         and (data[2:4] != '\\x00\\x00'):\n    encoding = 'utf-16le'\n    data = data[2:]\nelif data[:3] == '\\xef\\xbb\\xbf':\n    encoding = 'utf-8'\n    data = data[3:]\nelif data[:4] == '\\x00\\x00\\xfe\\xff':\n    encoding = 'utf-32be'\n    data = data[4:]\nelif data[:4] == '\\xff\\xfe\\x00\\x00':\n    encoding = 'utf-32le'\n    data = data[4:]\nnewdata = unicode(data, encoding)\nreturn newdata", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Returns the parents of this Tag that match the given\ncriteria.\"\"\"\n\n", "func_signal": "def findParents(self, name=None, attrs={}, limit=None, **kwargs):\n", "code": "return self._findAll(name, attrs, None, limit, self.parentGenerator,\n                     **kwargs)", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Encodes an object to a string in some encoding, or to Unicode.\n.\"\"\"\n", "func_signal": "def toEncoding(self, s, encoding=None):\n", "code": "if isinstance(s, unicode):\n    if encoding:\n        s = s.encode(encoding)\nelif isinstance(s, str):\n    if encoding:\n        s = s.encode(encoding)\n    else:\n        s = unicode(s)\nelse:\n    if encoding:\n        s  = self.toEncoding(str(s), encoding)\n    else:\n        s = unicode(s)\nreturn s", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"This method fixes a bug in Python's SGMLParser.\"\"\"\n", "func_signal": "def convert_charref(self, name):\n", "code": "try:\n    n = int(name)\nexcept ValueError:\n    return\nif not 0 <= n <= 127 : # ASCII ends at 127, not 255\n    return\nreturn self.convert_codepoint(n)", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Initializes a map representation of this tag's attributes,\nif not already initialized.\"\"\"\n", "func_signal": "def _getAttrMap(self):\n", "code": "if not getattr(self, 'attrMap'):\n    self.attrMap = {}\n    for (key, value) in self.attrs:\n        self.attrMap[key] = value\nreturn self.attrMap", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Handle entity references as data, possibly converting known\nHTML and/or XML entity references to the corresponding Unicode\ncharacters.\"\"\"\n", "func_signal": "def handle_entityref(self, ref):\n", "code": "data = None\nif self.convertHTMLEntities:\n    try:\n        data = unichr(name2codepoint[ref])\n    except KeyError:\n        pass\n\nif not data and self.convertXMLEntities:\n        data = self.XML_ENTITIES_TO_SPECIAL_CHARS.get(ref)\n\nif not data and self.convertHTMLEntities and \\\n    not self.XML_ENTITIES_TO_SPECIAL_CHARS.get(ref):\n        # TODO: We've got a problem here. We're told this is\n        # an entity reference, but it's not an XML entity\n        # reference or an HTML entity reference. Nonetheless,\n        # the logical thing to do is to pass it through as an\n        # unrecognized entity reference.\n        #\n        # Except: when the input is \"&carol;\" this function\n        # will be called with input \"carol\". When the input is\n        # \"AT&T\", this function will be called with input\n        # \"T\". We have no way of knowing whether a semicolon\n        # was present originally, so we don't know whether\n        # this is an unknown entity or just a misplaced\n        # ampersand.\n        #\n        # The more common case is a misplaced ampersand, so I\n        # escape the ampersand and omit the trailing semicolon.\n        data = \"&amp;%s\" % ref\nif not data:\n    # This case is different from the one above, because we\n    # haven't already gone through a supposedly comprehensive\n    # mapping of entities to Unicode characters. We might not\n    # have gone through any mapping at all. So the chances are\n    # very high that this is a real entity, and not a\n    # misplaced ampersand.\n    data = \"&%s;\" % ref\nself.handle_data(data)", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Returns the closest sibling to this Tag that matches the\ngiven criteria and appears before this Tag in the document.\"\"\"\n", "func_signal": "def findPreviousSibling(self, name=None, attrs={}, text=None, **kwargs):\n", "code": "return self._findOne(self.findPreviousSiblings, name, attrs, text,\n                     **kwargs)", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Given a document, tries to detect its XML encoding.\"\"\"\n", "func_signal": "def _detectEncoding(self, xml_data):\n", "code": "xml_encoding = sniffed_xml_encoding = None\ntry:\n    if xml_data[:4] == '\\x4c\\x6f\\xa7\\x94':\n        # EBCDIC\n        xml_data = self._ebcdic_to_ascii(xml_data)\n    elif xml_data[:4] == '\\x00\\x3c\\x00\\x3f':\n        # UTF-16BE\n        sniffed_xml_encoding = 'utf-16be'\n        xml_data = unicode(xml_data, 'utf-16be').encode('utf-8')\n    elif (len(xml_data) >= 4) and (xml_data[:2] == '\\xfe\\xff') \\\n             and (xml_data[2:4] != '\\x00\\x00'):\n        # UTF-16BE with BOM\n        sniffed_xml_encoding = 'utf-16be'\n        xml_data = unicode(xml_data[2:], 'utf-16be').encode('utf-8')\n    elif xml_data[:4] == '\\x3c\\x00\\x3f\\x00':\n        # UTF-16LE\n        sniffed_xml_encoding = 'utf-16le'\n        xml_data = unicode(xml_data, 'utf-16le').encode('utf-8')\n    elif (len(xml_data) >= 4) and (xml_data[:2] == '\\xff\\xfe') and \\\n             (xml_data[2:4] != '\\x00\\x00'):\n        # UTF-16LE with BOM\n        sniffed_xml_encoding = 'utf-16le'\n        xml_data = unicode(xml_data[2:], 'utf-16le').encode('utf-8')\n    elif xml_data[:4] == '\\x00\\x00\\x00\\x3c':\n        # UTF-32BE\n        sniffed_xml_encoding = 'utf-32be'\n        xml_data = unicode(xml_data, 'utf-32be').encode('utf-8')\n    elif xml_data[:4] == '\\x3c\\x00\\x00\\x00':\n        # UTF-32LE\n        sniffed_xml_encoding = 'utf-32le'\n        xml_data = unicode(xml_data, 'utf-32le').encode('utf-8')\n    elif xml_data[:4] == '\\x00\\x00\\xfe\\xff':\n        # UTF-32BE with BOM\n        sniffed_xml_encoding = 'utf-32be'\n        xml_data = unicode(xml_data[4:], 'utf-32be').encode('utf-8')\n    elif xml_data[:4] == '\\xff\\xfe\\x00\\x00':\n        # UTF-32LE with BOM\n        sniffed_xml_encoding = 'utf-32le'\n        xml_data = unicode(xml_data[4:], 'utf-32le').encode('utf-8')\n    elif xml_data[:3] == '\\xef\\xbb\\xbf':\n        # UTF-8 with BOM\n        sniffed_xml_encoding = 'utf-8'\n        xml_data = unicode(xml_data[3:], 'utf-8').encode('utf-8')\n    else:\n        sniffed_xml_encoding = 'ascii'\n        pass\n    xml_encoding_match = re.compile \\\n                         ('^<\\?.*encoding=[\\'\"](.*?)[\\'\"].*\\?>')\\\n                         .match(xml_data)\nexcept:\n    xml_encoding_match = None\nif xml_encoding_match:\n    xml_encoding = xml_encoding_match.groups()[0].lower()\n    if sniffed_xml_encoding and \\\n       (xml_encoding in ('iso-10646-ucs-2', 'ucs-2', 'csunicode',\n                         'iso-10646-ucs-4', 'ucs-4', 'csucs4',\n                         'utf-16', 'utf-32', 'utf_16', 'utf_32',\n                         'utf16', 'u16')):\n        xml_encoding = sniffed_xml_encoding\nreturn xml_data, xml_encoding, sniffed_xml_encoding", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Sets up the initial relations between this element and\nother elements.\"\"\"\n", "func_signal": "def setup(self, parent=None, previous=None):\n", "code": "self.parent = parent\nself.previous = previous\nself.next = None\nself.previousSibling = None\nself.nextSibling = None\nif self.parent and self.parent.contents:\n    self.previousSibling = self.parent.contents[-1]\n    self.previousSibling.nextSibling = self", "path": "BeautifulSoup.py", "repo_name": "myles-archive/django-basic-social", "stars": 3, "license": "None", "language": "python", "size": 100}
{"docstring": "\"\"\"Changes the strictness behavior.\n\nPass True to be very strict about JSON syntax, or False to be looser.\n\"\"\"\n", "func_signal": "def _set_strictness(self, strict):\n", "code": "self._allow_any_type_at_start = not strict\nself._allow_all_numeric_signs = not strict\nself._allow_comments = not strict\nself._allow_control_char_in_string = not strict\nself._allow_hex_numbers = not strict\nself._allow_initial_decimal_point = not strict\nself._allow_js_string_escapes = not strict\nself._allow_non_numbers = not strict\nself._allow_nonescape_characters = not strict  # \"\\z\" -> \"z\"\nself._allow_nonstring_keys = not strict\nself._allow_omitted_array_elements = not strict\nself._allow_single_quoted_strings = not strict\nself._allow_trailing_comma_in_literal = not strict\nself._allow_undefined_values = not strict\nself._allow_unicode_format_control_chars = not strict\nself._allow_unicode_whitespace = not strict\n# Always disable this by default\nself._allow_octal_numbers = False", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Takes a single unicode character and returns a sequence of surrogate pairs.\n\nThe output of this function is a tuple consisting of one or two unicode\ncharacters, such that if the input character is outside the BMP range\nthen the output is a two-character surrogate pair representing that character.\n\nIf the input character is inside the BMP then the output tuple will have\njust a single character...the same one.\n\n\"\"\"\n", "func_signal": "def unicode_as_surrogate_pair( c ):\n", "code": "n = ord(c)\nif n < 0x10000:\n    return (unichr(n),)  # in BMP, surrogate pair not required\nv = n - 0x10000\nvh = (v >> 10) & 0x3ff   # highest 10 bits\nvl = v & 0x3ff  # lowest 10 bits\nw1 = 0xD800 | vh\nw2 = 0xDC00 | vl\nreturn (unichr(w1), unichr(w2))", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Intermediate-level JSON decoder for composite literal types (array and object).\n\nTakes text and a starting index, and returns either a Python list or\ndictionary and the index of the next unparsed character.\n\n\"\"\"\n", "func_signal": "def decode_composite(self, txt, i=0, imax=None):\n", "code": "if imax is None:\n    imax = len(txt)\ni = self.skipws(txt, i, imax)\nstarti = i\nif i >= imax or txt[i] not in '{[':\n    raise JSONDecodeError('composite object must start with \"[\" or \"{\"',txt[i:])\nif txt[i] == '[':\n    isdict = False\n    closer = ']'\n    obj = []\nelse:\n    isdict = True\n    closer = '}'\n    obj = {}\ni += 1 # skip opener\ni = self.skipws(txt, i, imax)\n\nif i < imax and txt[i] == closer:\n    # empty composite\n    i += 1\n    done = True\nelse:\n    saw_value = False   # set to false at beginning and after commas\n    done = False\n    while i < imax:\n        i = self.skipws(txt, i, imax)\n        if i < imax and (txt[i] == ',' or txt[i] == closer):\n            c = txt[i]\n            i += 1\n            if c == ',':\n                if not saw_value:\n                    # no preceeding value, an elided (omitted) element\n                    if isdict:\n                        raise JSONDecodeError('can not omit elements of an object (dictionary)')\n                    if self._allow_omitted_array_elements:\n                        if self._allow_undefined_values:\n                            obj.append( undefined )\n                        else:\n                            obj.append( None )\n                    else:\n                        raise JSONDecodeError('strict JSON does not permit omitted array (list) elements',txt[i:])\n                saw_value = False\n                continue\n            else: # c == closer\n                if not saw_value and not self._allow_trailing_comma_in_literal:\n                    if isdict:\n                        raise JSONDecodeError('strict JSON does not allow a final comma in an object (dictionary) literal',txt[i-2:])\n                    else:\n                        raise JSONDecodeError('strict JSON does not allow a final comma in an array (list) literal',txt[i-2:])\n                done = True\n                break\n\n        # Decode the item\n        if isdict and self._allow_nonstring_keys:\n            r = self.decodeobj(txt, i, identifier_as_string=True)\n        else:\n            r = self.decodeobj(txt, i, identifier_as_string=False)\n        if r:\n            if saw_value:\n                # two values without a separating comma\n                raise JSONDecodeError('values must be separated by a comma', txt[i:r[1]])\n            saw_value = True\n            i = self.skipws(txt, r[1], imax)\n            if isdict:\n                key = r[0]  # Ref 11.1.5\n                if not isstringtype(key):\n                    if isnumbertype(key):\n                        if not self._allow_nonstring_keys:\n                            raise JSONDecodeError('strict JSON only permits string literals as object properties (dictionary keys)',txt[starti:])\n                    else:\n                        raise JSONDecodeError('object properties (dictionary keys) must be either string literals or numbers',txt[starti:])\n                if i >= imax or txt[i] != ':':\n                    raise JSONDecodeError('object property (dictionary key) has no value, expected \":\"',txt[starti:])\n                i += 1\n                i = self.skipws(txt, i, imax)\n                rval = self.decodeobj(txt, i)\n                if rval:\n                    i = self.skipws(txt, rval[1], imax)\n                    obj[key] = rval[0]\n                else:\n                    raise JSONDecodeError('object property (dictionary key) has no value',txt[starti:])\n            else: # list\n                obj.append( r[0] )\n        else: # not r\n            if isdict:\n                raise JSONDecodeError('expected a value, or \"}\"',txt[i:])\n            elif not self._allow_omitted_array_elements:\n                raise JSONDecodeError('expected a value or \"]\"',txt[i:])\n            else:\n                raise JSONDecodeError('expected a value, \",\" or \"]\"',txt[i:])\n    # end while\nif not done:\n    if isdict:\n        raise JSONDecodeError('object literal (dictionary) is not terminated',txt[starti:])\n    else:\n        raise JSONDecodeError('array literal (list) is not terminated',txt[starti:])\nreturn obj, i", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Decodes a JSON-endoded string into a Python object.\"\"\"\n", "func_signal": "def decode(self, txt):\n", "code": "if self._allow_unicode_format_control_chars:\n    txt = self.strip_format_control_chars(txt)\nr = self.decodeobj(txt, 0, only_object_or_array=not self._allow_any_type_at_start)\nif not r:\n    raise JSONDecodeError('can not decode value',txt)\nelse:\n    obj, i = r\n    i = self.skipws(txt, i)\n    if i < len(txt):\n        raise JSONDecodeError('unexpected or extra text',txt[i:])\nreturn obj", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Allow the specified behavior (turn off a strictness check).\n\nThe list of all possible behaviors is available in the behaviors property.\nYou can see which behaviors are currently allowed by accessing the\nallowed_behaviors property.\n\n\"\"\"\n", "func_signal": "def allow(self, behavior):\n", "code": "p = '_allow_' + behavior\nif hasattr(self, p):\n    setattr(self, p, True)\nelse:\n    raise AttributeError('Behavior is not known',behavior)", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Filters out all Unicode format control characters from the string.\n\nECMAScript permits any Unicode \"format control characters\" to\nappear at any place in the source code.  They are to be\nignored as if they are not there before any other lexical\ntokenization occurs.  Note that JSON does not allow them.\n\nRef. ECMAScript section 7.1.\n\n\"\"\"\n", "func_signal": "def strip_format_control_chars(self, txt):\n", "code": "import unicodedata\ntxt2 = filter( lambda c: unicodedata.category(unicode(c)) != 'Cf',\n               txt )\nreturn txt2", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Encodes a Python string into a JSON string literal.\n\n\"\"\"\n# Must handle instances of UserString specially in order to be\n# able to use ord() on it's simulated \"characters\".\n", "func_signal": "def encode_string(self, s):\n", "code": "import UserString\nif isinstance(s, (UserString.UserString, UserString.MutableString)):\n    def tochar(c):\n        return c.data\nelse:\n    # Could use \"lambda c:c\", but that is too slow.  So we set to None\n    # and use an explicit if test inside the loop.\n    tochar = None\n\nchunks = []\nchunks.append('\"')\nrevesc = self._rev_escapes\nasciiencodable = self._asciiencodable\nencunicode = self._encode_unicode_as_escapes\ni = 0\nimax = len(s)\nwhile i < imax:\n    if tochar:\n        c = tochar(s[i])\n    else:\n        c = s[i]\n    cord = ord(c)\n    if cord < 256 and asciiencodable[cord] and isinstance(encunicode, bool):\n        # Contiguous runs of plain old printable ASCII can be copied\n        # directly to the JSON output without worry (unless the user\n        # has supplied a custom is-encodable function).\n        j = i\n        i += 1\n        while i < imax:\n            if tochar:\n                c = tochar(s[i])\n            else:\n                c = s[i]\n            cord = ord(c)\n            if cord < 256 and asciiencodable[cord]:\n                i += 1\n            else:\n                break\n        chunks.append( unicode(s[j:i]) )\n    elif revesc.has_key(c):\n        # Has a shortcut escape sequence, like \"\\n\"\n        chunks.append(revesc[c])\n        i += 1\n    elif cord <= 0x1F:\n        # Always unicode escape ASCII-control characters\n        chunks.append(r'\\u%04x' % cord)\n        i += 1\n    elif 0xD800 <= cord <= 0xDFFF:\n        # A raw surrogate character!  This should never happen\n        # and there's no way to include it in the JSON output.\n        # So all we can do is complain.\n        cname = 'U+%04X' % cord\n        raise JSONEncodeError('can not include or escape a Unicode surrogate character',cname)\n    elif cord <= 0xFFFF:\n        # Other BMP Unicode character\n        if isinstance(encunicode, bool):\n            doesc = encunicode\n        else:\n            doesc = encunicode( c )\n        if doesc:\n            chunks.append(r'\\u%04x' % cord)\n        else:\n            chunks.append( c )\n        i += 1\n    else: # ord(c) >= 0x10000\n        # Non-BMP Unicode\n        if isinstance(encunicode, bool):\n            doesc = encunicode\n        else:\n            doesc = encunicode( c )\n        if doesc:\n            for surrogate in unicode_as_surrogate_pair(c):\n                chunks.append(r'\\u%04x' % ord(surrogate))\n        else:\n            chunks.append( c )\n        i += 1\nchunks.append('\"')\nreturn ''.join( chunks )", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Skips an ECMAScript comment, either // or /* style.\n\nThe contents of the comment are returned as a string, as well\nas the index of the character immediately after the comment.\n\n\"\"\"\n", "func_signal": "def skip_comment(self, txt, i=0):\n", "code": "if i+1 >= len(txt) or txt[i] != '/' or txt[i+1] not in '/*':\n    return None, i\nif not self._allow_comments:\n    raise JSONDecodeError('comments are not allowed in strict JSON',txt[i:])\nmultiline = (txt[i+1] == '*')\nistart = i\ni += 2\nwhile i < len(txt):\n    if multiline:\n        if txt[i] == '*' and i+1 < len(txt) and txt[i+1] == '/':\n            j = i+2\n            break\n        elif txt[i] == '/' and i+1 < len(txt) and txt[i+1] == '*':\n            raise JSONDecodeError('multiline /* */ comments may not nest',txt[istart:i+1])\n    else:\n        if self.islineterm(txt[i]):\n            j = i  # line terminator is not part of comment\n            break\n    i += 1\n\nif i >= len(txt):\n    if not multiline:\n        j = len(txt)  # // comment terminated by end of file is okay\n    else:\n        raise JSONDecodeError('comment was never terminated',txt[istart:])\nreturn txt[istart:j], j", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Is the object of a Python number type (excluding complex)?\"\"\"\n", "func_signal": "def isnumbertype( obj ):\n", "code": "return isinstance(obj, (int,long,float)) \\\n       and not isinstance(obj, bool) \\\n       or obj is nan or obj is inf or obj is neginf", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "#print 'encode_helper(chunklist=%r, obj=%r, nest_level=%r)'%(chunklist,obj,nest_level)\n", "func_signal": "def encode_helper(self, chunklist, obj, nest_level):\n", "code": "if hasattr(obj, 'json_equivalent'):\n    json = self.encode_equivalent( obj, nest_level=nest_level )\n    if json is not None:\n        chunklist.append( json )\n        return\nif obj is None:\n    chunklist.append( self.encode_null() )\nelif obj is undefined:\n    if self._allow_undefined_values:\n        chunklist.append( self.encode_undefined() )\n    else:\n        raise JSONEncodeError('strict JSON does not permit \"undefined\" values')\nelif isinstance(obj, bool):\n    chunklist.append( self.encode_boolean(obj) )\nelif isinstance(obj, (int,long,float,complex)) or \\\n         (decimal and isinstance(obj, decimal.Decimal)):\n    chunklist.append( self.encode_number(obj) )\nelif isinstance(obj, basestring) or isstringtype(obj):\n    chunklist.append( self.encode_string(obj) )\nelse:\n    self.encode_composite(chunklist, obj, nest_level)", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Prevent the specified behavior (turn on a strictness check).\n\nThe list of all possible behaviors is available in the behaviors property.\nYou can see which behaviors are currently prevented by accessing the\nprevented_behaviors property.\n\n\"\"\"\n", "func_signal": "def prevent(self, behavior):\n", "code": "p = '_allow_' + behavior\nif hasattr(self, p):\n    setattr(self, p, False)\nelse:\n    raise AttributeError('Behavior is not known',behavior)", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"This method is used to encode user-defined class objects.\n\nThe object being encoded should have a json_equivalent()\nmethod defined which returns another equivalent object which\nis easily JSON-encoded.  If the object in question has no\njson_equivalent() method available then None is returned\ninstead of a string so that the encoding will attempt the next\nstrategy.\n\nIf a caller wishes to disable the calling of json_equivalent()\nmethods, then subclass this class and override this method\nto just return None.\n\n\"\"\"\n", "func_signal": "def encode_equivalent( self, obj, nest_level=0 ):\n", "code": "if hasattr(obj, 'json_equivalent') \\\n       and callable(getattr(obj,'json_equivalent')):\n    obj2 = obj.json_equivalent()\n    if obj2 is obj:\n        # Try to prevent careless infinite recursion\n        raise JSONEncodeError('object has a json_equivalent() method that returns itself',obj)\n    json2 = self.encode( obj2, nest_level=nest_level )\n    return json2\nelse:\n    return None", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Decodes a hexadecimal string into it's integer value.\"\"\"\n# We don't use the builtin 'hex' codec in python since it can\n# not handle odd numbers of digits, nor raise the same type\n# of exceptions we want to.\n", "func_signal": "def decode_hex( hexstring ):\n", "code": "n = 0\nfor c in hexstring:\n    if '0' <= c <= '9':\n        d = ord(c) - ord('0')\n    elif 'a' <= c <= 'f':\n        d = ord(c) - ord('a') + 10\n    elif 'A' <= c <= 'F':\n        d = ord(c) - ord('A') + 10\n    else:\n        raise JSONDecodeError('not a hexadecimal number',hexstring)\n    # Could use ((n << 4 ) | d), but python 2.3 issues a FutureWarning.\n    n = (n * 16) + d\nreturn n", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Skips all whitespace, including comments and unicode whitespace\n\nTakes a string and a starting index, and returns the index of the\nnext non-whitespace character.\n\nIf skip_comments is True and not running in strict JSON mode, then\ncomments will be skipped over just like whitespace.\n\n\"\"\"\n", "func_signal": "def skipws_any(self, txt, i=0, imax=None, skip_comments=True):\n", "code": "if imax is None:\n    imax = len(txt)\nwhile i < imax:\n    if txt[i] == '/':\n        cmt, i = self.skip_comment(txt, i)\n    if i < imax and self.isws(txt[i]):\n        i += 1\n    else:\n        break\nreturn i", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Skips whitespace.\n\"\"\"\n", "func_signal": "def skipws(self, txt, i=0, imax=None, skip_comments=True):\n", "code": "if not self._allow_comments and not self._allow_unicode_whitespace:\n    if imax is None:\n        imax = len(txt)\n    while i < imax and txt[i] in ' \\r\\n\\t':\n        i += 1\n    return i\nelse:\n    return self.skipws_any(txt, i, imax, skip_comments)", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Encodes a Unicode string into a UTF-32LE encoded byte string.\"\"\"\n", "func_signal": "def utf32le_encode( obj, errors='strict' ):\n", "code": "import struct\ntry:\n    import cStringIO as sio\nexcept ImportError:\n    import StringIO as sio\nf = sio.StringIO()\nwrite = f.write\npack = struct.pack\nfor c in obj:\n    n = ord(c)\n    if 0xD800 <= n <= 0xDFFF: # surrogate codepoints are prohibited by UTF-32\n        if errors == 'ignore':\n            continue\n        elif errors == 'replace':\n            n = ord('?')\n        else:\n            cname = 'U+%04X'%n\n            raise UnicodeError('UTF-32 can not encode surrogate characters',cname)\n    write( pack('<L', n) )\nreturn f.getvalue()", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Encodes just dictionaries, lists, or sequences.\n\nBasically handles any python type for which iter() can create\nan iterator object.\n\nThis method is not intended to be called directly.  Use the\nencode() method instead.\n\n\"\"\"\n#print 'encode_complex_helper(chunklist=%r, obj=%r, nest_level=%r)'%(chunklist,obj,nest_level)\n", "func_signal": "def encode_composite(self, chunklist, obj, nest_level):\n", "code": "try:\n    # Is it a dictionary or UserDict?  Try iterkeys method first.\n    it = obj.iterkeys()\nexcept AttributeError:\n    try:\n        # Is it a sequence?  Try to make an iterator for it.\n        it = iter(obj)\n    except TypeError:\n        it = None\nif it is not None:\n    # Does it look like a dictionary?  Check for a minimal dict or\n    # UserDict interface.\n    isdict = hasattr(obj, '__getitem__') and hasattr(obj, 'keys')\n    compactly = self._encode_compactly\n    if isdict:\n        chunklist.append('{')\n        if compactly:\n            dictcolon = ':'\n        else:\n            dictcolon = ' : '\n    else:\n        chunklist.append('[')\n    #print nest_level, 'opening sequence:', repr(chunklist)\n    if not compactly:\n        indent0 = '  ' * nest_level\n        indent = '  ' * (nest_level+1)\n        chunklist.append(' ')\n    sequence_chunks = []  # use this to allow sorting afterwards if dict\n    try: # while not StopIteration\n        numitems = 0\n        while True:\n            obj2 = it.next()\n            if obj2 is obj:\n                raise JSONEncodeError('trying to encode an infinite sequence',obj)\n            if isdict and not isstringtype(obj2):\n                # Check JSON restrictions on key types\n                if isnumbertype(obj2):\n                    if not self._allow_nonstring_keys:\n                        raise JSONEncodeError('object properties (dictionary keys) must be strings in strict JSON',obj2)\n                else:\n                    raise JSONEncodeError('object properties (dictionary keys) can only be strings or numbers in ECMAScript',obj2)\n\n            # Encode this item in the sequence and put into item_chunks\n            item_chunks = []\n            self.encode_helper( item_chunks, obj2, nest_level=nest_level+1 )\n            if isdict:\n                item_chunks.append(dictcolon)\n                obj3 = obj[obj2]\n                self.encode_helper(item_chunks, obj3, nest_level=nest_level+2)\n\n            #print nest_level, numitems, 'item:', repr(obj2)\n            #print nest_level, numitems, 'sequence_chunks:', repr(sequence_chunks)\n            #print nest_level, numitems, 'item_chunks:', repr(item_chunks)\n            #extend_list_with_sep(sequence_chunks, item_chunks)\n            sequence_chunks.append(item_chunks)\n            #print nest_level, numitems, 'new sequence_chunks:', repr(sequence_chunks)\n            numitems += 1\n    except StopIteration:\n        pass\n\n    if isdict and self._sort_dictionary_keys:\n        sequence_chunks.sort()  # Note sorts by JSON repr, not original Python object\n    if compactly:\n        sep = ','\n    else:\n        sep = ',\\n' + indent\n\n    #print nest_level, 'closing sequence'\n    #print nest_level, 'chunklist:', repr(chunklist)\n    #print nest_level, 'sequence_chunks:', repr(sequence_chunks)\n    extend_and_flatten_list_with_sep( chunklist, sequence_chunks, sep )\n    #print nest_level, 'new chunklist:', repr(chunklist)\n\n    if not compactly:\n        if numitems > 1:\n            chunklist.append('\\n' + indent0)\n        else:\n            chunklist.append(' ')\n    if isdict:\n        chunklist.append('}')\n    else:\n        chunklist.append(']')\nelse: # Can't create an iterator for the object\n    json2 = self.encode_default( obj, nest_level=nest_level )\n    chunklist.append( json2 )", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Is the object of a Python string type?\"\"\"\n", "func_signal": "def isstringtype( obj ):\n", "code": "if isinstance(obj, basestring):\n    return True\n# Must also check for some other pseudo-string types\nimport types, UserString\nreturn isinstance(obj, types.StringTypes) \\\n       or isinstance(obj, UserString.UserString) \\\n       or isinstance(obj, UserString.MutableString)", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Decodes a JSON-encoded string into a Python object.\n\nIf 'strict' is set to True, then those strings that are not\nentirely strictly conforming to JSON will result in a\nJSONDecodeError exception.\n\nThe input string can be either a python string or a python unicode\nstring.  If it is already a unicode string, then it is assumed\nthat no character set decoding is required.\n\nHowever, if you pass in a non-Unicode text string (i.e., a python\ntype 'str') then an attempt will be made to auto-detect and decode\nthe character encoding.  This will be successful if the input was\nencoded in any of UTF-8, UTF-16 (BE or LE), or UTF-32 (BE or LE),\nand of course plain ASCII works too.\n\nNote though that if you know the character encoding, then you\nshould convert to a unicode string yourself, or pass it the name\nof the 'encoding' to avoid the guessing made by the auto\ndetection, as with\n\n    python_object = demjson.decode( input_bytes, encoding='utf8' )\n\nOptional keywords arguments must be of the form\n    allow_xxxx=True/False\nor\n    prevent_xxxx=True/False\nwhere each will allow or prevent the specific behavior, after the\nevaluation of the 'strict' argument.  For example, if strict=True\nthen by also passing 'allow_comments=True' then comments will be\nallowed.  If strict=False then prevent_comments=True will allow\neverything except comments.\n\n\"\"\"\n# Initialize the JSON object\n", "func_signal": "def decode( txt, strict=False, encoding=None, **kw ):\n", "code": "j = JSON( strict=strict )\nfor keyword, value in kw.items():\n    if keyword.startswith('allow_'):\n        behavior = keyword[6:]\n        allow = bool(value)\n    elif keyword.startswith('prevent_'):\n        behavior = keyword[8:]\n        allow = not bool(value)\n    else:\n        raise ValueError('unknown keyword argument', keyword)\n    if allow:\n        j.allow(behavior)\n    else:\n        j.prevent(behavior)\n\n# Convert the input string into unicode if needed.\nif isinstance(txt,unicode):\n    unitxt = txt\nelse:\n    if encoding is None:\n        unitxt = auto_unicode_decode( txt )\n    else:\n        cdk = None # codec\n        decoder = None\n        import codecs\n        try:\n            cdk = codecs.lookup(encoding)\n        except LookupError:\n            encoding = encoding.lower()\n            decoder = None\n            if encoding.startswith('utf-32') \\\n                   or encoding.startswith('ucs4') \\\n                   or encoding.startswith('ucs-4'):\n                # Python doesn't natively have a UTF-32 codec, but JSON\n                # requires that it be supported.  So we must decode these\n                # manually.\n                if encoding.endswith('le'):\n                    decoder = utf32le_decode\n                elif encoding.endswith('be'):\n                    decoder = utf32be_decode\n                else:\n                    if txt.startswith( codecs.BOM_UTF32_BE ):\n                        decoder = utf32be_decode\n                        txt = txt[4:]\n                    elif txt.startswith( codecs.BOM_UTF32_LE ):\n                        decoder = utf32le_decode\n                        txt = txt[4:]\n                    else:\n                        if encoding.startswith('ucs'):\n                            raise JSONDecodeError('UCS-4 encoded string must start with a BOM')\n                        decoder = utf32be_decode # Default BE for UTF, per unicode spec\n            elif encoding.startswith('ucs2') or encoding.startswith('ucs-2'):\n                # Python has no UCS-2, but we can simulate with\n                # UTF-16.  We just need to force us to not try to\n                # encode anything past the BMP.\n                encoding = 'utf-16'\n\n        if decoder:\n            unitxt = decoder(txt)\n        elif encoding:\n            unitxt = txt.decode(encoding)\n        else:\n            raise JSONDecodeError('this python has no codec for this character encoding',encoding)\n\n    # Check that the decoding seems sane.  Per RFC 4627 section 3:\n    #    \"Since the first two characters of a JSON text will\n    #    always be ASCII characters [RFC0020], ...\"\n    #\n    # This check is probably not necessary, but it allows us to\n    # raise a suitably descriptive error rather than an obscure\n    # syntax error later on.\n    #\n    # Note that the RFC requirements of two ASCII characters seems\n    # to be an incorrect statement as a JSON string literal may\n    # have as it's first character any unicode character.  Thus\n    # the first two characters will always be ASCII, unless the\n    # first character is a quotation mark.  And in non-strict\n    # mode we can also have a few other characters too.\n    if len(unitxt) > 2:\n        first, second = unitxt[:2]\n        if first in '\"\\'':\n            pass # second can be anything inside string literal\n        else:\n            if ((ord(first) < 0x20 or ord(first) > 0x7f) or \\\n                (ord(second) < 0x20 or ord(second) > 0x7f)) and \\\n                (not j.isws(first) and not j.isws(second)):\n                # Found non-printable ascii, must check unicode\n                # categories to see if the character is legal.\n                # Only whitespace, line and paragraph separators,\n                # and format control chars are legal here.\n                import unicodedata\n                catfirst = unicodedata.category(unicode(first))\n                catsecond = unicodedata.category(unicode(second))\n                if catfirst not in ('Zs','Zl','Zp','Cf') or \\\n                       catsecond not in ('Zs','Zl','Zp','Cf'):\n                    raise JSONDecodeError('the decoded string is gibberish, is the encoding correct?',encoding)\n# Now ready to do the actual decoding\nobj = j.decode( unitxt )\nreturn obj", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"Encodes the Python boolean into a JSON Boolean literal.\"\"\"\n", "func_signal": "def encode_boolean(self, b):\n", "code": "if bool(b):\n    return 'true'\nreturn 'false'", "path": "json\\demjson.py", "repo_name": "rictic/launchdate", "stars": 2, "license": "None", "language": "python", "size": 252}
{"docstring": "\"\"\"\nReturn a JSON string representation of a Python data structure.\n\n>>> JSONEncoder().encode({\"foo\": [\"bar\", \"baz\"]})\n'{\"foo\": [\"bar\", \"baz\"]}'\n\"\"\"\n# This is for extremely simple cases and benchmarks.\n", "func_signal": "def encode(self, o):\n", "code": "if isinstance(o, basestring):\n    if isinstance(o, str):\n        _encoding = self.encoding\n        if (_encoding is not None \n                and not (_encoding == 'utf-8')):\n            o = o.decode(_encoding)\n    if self.ensure_ascii:\n        return encode_basestring_ascii(o)\n    else:\n        return encode_basestring(o)\n# This doesn't pass the iterator directly to ''.join() because the\n# exceptions aren't as detailed.  The list call should be roughly\n# equivalent to the PySequence_Fast that ''.join() would do.\nchunks = list(self.iterencode(o))\nreturn ''.join(chunks)", "path": "gaeo\\controller\\jsonencoder.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\"Update the specified properties\"\"\"\n", "func_signal": "def set_attributes(self, **kwds):\n", "code": "props = self.properties()\nfor prop in props.values():\n    if prop.name in kwds:\n        prop.__set__(self, kwds[prop.name])", "path": "gaeo_old\\model\\__init__.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\" Convert a dict to JSON. Inspired from SimpleJSON \"\"\"\n", "func_signal": "def to_json(self, obj, **kwds):\n", "code": "from gaeo.controller.jsonencoder import JSONEncoder\n\nif not kwds:\n    return JSONEncoder(skipkeys=False, ensure_ascii=True, check_circular=True,\n        allow_nan=True, indent=None, separators=None, encoding='utf-8',\n        default=None).encode(obj)\nelse:\n    return JSONEncoder(\n        skipkeys=False, ensure_ascii=True, check_circular=True,\n        allow_nan=True, indent=None, separators=None,\n        encoding='utf-8', default=None, **kwds).encode(obj)", "path": "gaeo\\controller\\__init__.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\" for detecting iPhone/iPod \"\"\"\n", "func_signal": "def __detect_iphone(self):\n", "code": "ua = self.request.headers.get('User-Agent')\nif ua:\n    ua = ua.lower();\n    return ua.find('iphone') > -1 or ua.find('ipod') > -1\nelse:\n    return False", "path": "gaeo\\controller\\__init__.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\"\nEncode the given object and yield each string\nrepresentation as available.\n\nFor example::\n    \n    for chunk in JSONEncoder().iterencode(bigobject):\n        mysocket.write(chunk)\n\"\"\"\n", "func_signal": "def iterencode(self, o):\n", "code": "if self.check_circular:\n    markers = {}\nelse:\n    markers = None\nreturn self._iterencode(o, markers)", "path": "gaeo\\controller\\jsonencoder.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\"\nReturn a JSON representation of a Python string\n\"\"\"\n", "func_signal": "def encode_basestring(s):\n", "code": "def replace(match):\n    return ESCAPE_DCT[match.group(0)]\nreturn '\"' + ESCAPE.sub(replace, s) + '\"'", "path": "gaeo\\controller\\jsonencoder.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\"Invalidates the session data\"\"\"\n", "func_signal": "def invalidate(self):\n", "code": "self._hnd.response.headers.add_header(\n    'Set-Cookie',\n    '%s=; expires=Thu, 1-Jan-1970 00:00:00 GMT;' % self._name\n)\nmemcache.delete(self._id)\nself.clear()\nself._invalidated = True", "path": "gaeo\\session\\memcache.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\"Update the specified properties\"\"\"\n", "func_signal": "def update_attributes(self, kwd_dict = {}, **kwds):\n", "code": "need_change = False\n\n# if user passed a dict, merge to kwds (Issue #3)\nif kwd_dict:\n    kwd_dict.update(kwds)\n    kwds = kwd_dict\n\nprops = self.properties()\nfor prop in props.values():\n    if prop.name in kwds:\n        if not need_change:\n            need_change = True\n        prop.__set__(self, kwds[prop.name])\n\nif need_change:\n    self.update()", "path": "gaeo\\model\\__init__.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\" Set the root (/) routing... \"\"\"\n", "func_signal": "def root(self, **map):\n", "code": "self.__routing_root['controller'] = \\\n    map.get('controller', self.__routing_root['controller'])\nself.__routing_root['action'] = \\\n    map.get('action', self.__routing_root['action'])", "path": "gaeo_old\\dispatch\\router.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\" Resolve the url to the correct mapping \"\"\"\n\n", "func_signal": "def resolve(self, url):\n", "code": "if url == '/':\n    return self.__routing_root\n\nret = self.__resolve_by_table(url, self.__routing_table)\nif ret is None: # fallback\n    ret = self.__resolve_by_table(url, self.__routing_table_fallback)\nreturn ret", "path": "gaeo_old\\dispatch\\router.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\" Resolve url by the given table \"\"\"\n", "func_signal": "def __resolve_by_table(self, url, rules):\n", "code": "for r in rules:\n    ret = r.match_url(url)\n    if ret:\n        return ret\nreturn None", "path": "gaeo_old\\dispatch\\router.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\"Invalidates the session data\"\"\"\n", "func_signal": "def invalidate(self):\n", "code": "self._hnd.response.headers.add_header(\n    'Set-Cookie',\n    '%s=; expires=Thu, 1-Jan-1970 00:00:00 GMT;' % self._name\n)\nmemcache.delete(self._id)\nself.clear()\nself._invalidated = True", "path": "gaeo_old\\session\\memcache.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "# add the project's directory to the import path list.\n", "func_signal": "def main():\n", "code": "sys.path.append(os.path.dirname(__file__))\nsys.path.append(os.path.join(os.path.dirname(__file__), 'application'))\n\n# get the gaeo's config (singleton)\nconfig = gaeo.Config()\n# setup the templates' location\nconfig.template_dir = os.path.join(\n    os.path.dirname(__file__), 'application', 'templates')\n\ninitRoutes()\n\napp = webapp.WSGIApplication([\n            (r'.*', gaeo.MainHandler),\n        ], debug=True)\nwsgiref.handlers.CGIHandler().run(app)", "path": "main.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\"set the specified properties, but not update\"\"\"\n\n# Issue #3\n", "func_signal": "def set_attributes(self, kwd_dict = {}, **kwds):\n", "code": "if kwd_dict:\n    kwd_dict.update(kwds)\n    kwds = kwd_dict\n\nprops = self.properties()\nfor prop in props.values():\n    if prop.name in kwds:\n        prop.__set__(self, kwds[prop.name])", "path": "gaeo\\model\\__init__.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\"The Session's constructor.\n\n@param hnd      The webapp.ReqeustHanlder object.\n@param name     The session name.\n@param timeout  The time interval (in sec) that the session expired.\n\"\"\"\n\n", "func_signal": "def __init__(self, hnd, name, timeout):\n", "code": "dict.__init__(self)\nself._name = name\nself._hnd = hnd\nself._timeout = timeout\nself._id = ''.join([ choice(POOL) for i in range(SESSIONID_LEN) ])\n\nself._invalidated = False", "path": "gaeo_old\\session\\__init__.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\"The Session's constructor.\n\n@param hnd      The webapp.ReqeustHanlder object.\n@param name     The session name.\n@param timeout  The time interval (in sec) that the session expired.\n\"\"\"\n\n", "func_signal": "def __init__(self, hnd, name, timeout):\n", "code": "dict.__init__(self)\nself._name = name\nself._hnd = hnd\nself._timeout = timeout\nself._id = ''.join([ choice(POOL) for i in range(SESSIONID_LEN) ])\n\nself._invalidated = False", "path": "gaeo\\session\\__init__.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\" for detecting iPhone/iPod \"\"\"\n", "func_signal": "def __detect_iphone(self):\n", "code": "ua = self.request.headers.get('User-Agent')\nif ua:\n    ua = ua.lower();\n    return ua.find('iphone') > -1 or ua.find('ipod') > -1\nelse:\n    return False", "path": "gaeo_old\\controller\\__init__.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\"Update the specified properties\"\"\"\n", "func_signal": "def update_attributes(self, kwds):\n", "code": "need_change = False\nprops = self.properties()\nfor prop in props.values():\n    if prop.name in kwds:\n        if not need_change:\n            need_change = True\n        prop.__set__(self, kwds[prop.name])\n\nif need_change:\n    self.update()", "path": "gaeo_old\\model\\__init__.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "# Check for specials.  Note that this type of test is processor- and/or\n# platform-specific, so do tests which don't depend on the internals.\n\n", "func_signal": "def floatstr(o, allow_nan=True):\n", "code": "if o != o:\n    text = 'NaN'\nelif o == INFINITY:\n    text = 'Infinity'\nelif o == -INFINITY:\n    text = '-Infinity'\nelse:\n    return FLOAT_REPR(o)\n\nif not allow_nan:\n    raise ValueError(\"Out of range float values are not JSON compliant: %r\"\n        % (o,))\n\nreturn text", "path": "gaeo\\controller\\jsonencoder.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "\"\"\" Add routing pattern \"\"\"\n\n", "func_signal": "def connect(self, pattern, **tbl):\n", "code": "rule = Rule(pattern, **tbl)\nif rule not in self.__routing_table:\n    self.__routing_table.append(rule)", "path": "gaeo_old\\dispatch\\router.py", "repo_name": "tomaash/gaeotest", "stars": 2, "license": "None", "language": "python", "size": 120}
{"docstring": "'''Get a sequence of status messages representing the 20 most recent\nreplies (status updates prefixed with @username) to the authenticating\nuser.\n\nReturns:\n  A sequence of twitter.Status instances, one for each reply to the user.\n'''\n", "func_signal": "def GetReplies(self):\n", "code": "url = 'http://twitter.com/statuses/replies.json'\nif not self._username:\n  raise TwitterError(\"The twitter.Api instance must be authenticated.\")\njson = self._FetchUrl(url)\ndata = simplejson.loads(json)\nreturn [Status.NewFromJsonDict(x) for x in data]", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Post a twitter direct message from the authenticated user\n\nThe twitter.Api instance must be authenticated.\n\nArgs:\n  user: The ID or screen name of the recipient user.\n  text: The message text to be posted.  Must be less than 140 characters.\n\nReturns:\n  A twitter.DirectMessage instance representing the message posted\n'''\n", "func_signal": "def PostDirectMessage(self, user, text):\n", "code": "if not self._username:\n  raise TwitterError(\"The twitter.Api instance must be authenticated.\")\nurl = 'http://twitter.com/direct_messages/new.json'\ndata = {'text': text, 'user': user}\njson = self._FetchUrl(url, post_data=data)\ndata = simplejson.loads(json)\nreturn DirectMessage.NewFromJsonDict(data)", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Fetch the sequnce of public twitter.Status message for all users.\n\nArgs:\n  since_id:\n    Returns only public statuses with an ID greater than (that is,\n    more recent than) the specified ID. [Optional]\n\nReturns:\n  An sequence of twitter.Status instances, one for each message\n'''\n", "func_signal": "def GetPublicTimeline(self, since_id=None):\n", "code": "parameters = {}\nif since_id:\n  parameters['since_id'] = since_id\nurl = 'http://twitter.com/statuses/public_timeline.json'\njson = self._FetchUrl(url,  parameters=parameters)\ndata = simplejson.loads(json)\nreturn [Status.NewFromJsonDict(x) for x in data]", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Fetch the sequence of public twitter.Status messages for a single user.\n\nThe twitter.Api instance must be authenticated if the user is private.\n\nArgs:\n  user:\n    either the username (short_name) or id of the user to retrieve.  If\n    not specified, then the current authenticated user is used. [optional]\n  count: the number of status messages to retrieve [optional]\n  since:\n    Narrows the returned results to just those statuses created\n    after the specified HTTP-formatted date. [optional]\n\nReturns:\n  A sequence of twitter.Status instances, one for each message up to count\n'''\n", "func_signal": "def GetUserTimeline(self, user=None, count=None, since=None):\n", "code": "try:\n  if count:\n    int(count)\nexcept:\n  raise TwitterError(\"Count must be an integer\")\nparameters = {}\nif count:\n  parameters['count'] = count\nif since:\n  parameters['since'] = since\nif user:\n  url = 'http://twitter.com/statuses/user_timeline/%s.json' % user\nelif not user and not self._username:\n  raise TwitterError(\"User must be specified if API is not authenticated.\")\nelse:\n  url = 'http://twitter.com/statuses/user_timeline.json'\njson = self._FetchUrl(url, parameters=parameters)\ndata = simplejson.loads(json)\nreturn [Status.NewFromJsonDict(x) for x in data]", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Fetch the sequence of twitter.User instances, one for each follower\n\nThe twitter.Api instance must be authenticated.\n\nReturns:\n  A sequence of twitter.User instances, one for each follower\n'''\n", "func_signal": "def GetFollowers(self):\n", "code": "if not self._username:\n  raise TwitterError(\"twitter.Api instance must be authenticated\")\nurl = 'http://twitter.com/statuses/followers.json'\njson = self._FetchUrl(url)\ndata = simplejson.loads(json)\nreturn [User.NewFromJsonDict(x) for x in data]", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Destroys the status specified by the required ID parameter.\n\nThe twitter.Api instance must be authenticated and thee\nauthenticating user must be the author of the specified status.\n\nArgs:\n  id: The numerical ID of the status you're trying to destroy.\n\nReturns:\n  A twitter.Status instance representing the destroyed status message\n'''\n", "func_signal": "def DestroyStatus(self, id):\n", "code": "try:\n  if id:\n    int(id)\nexcept:\n  raise TwitterError(\"id must be an integer\")\nurl = 'http://twitter.com/statuses/destroy/%s.json' % id\njson = self._FetchUrl(url, post_data={})\ndata = simplejson.loads(json)\nreturn Status.NewFromJsonDict(data)", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Returns a single status message.\n\nThe twitter.Api instance must be authenticated if the status message is private.\n\nArgs:\n  id: The numerical ID of the status you're trying to retrieve.\n\nReturns:\n  A twitter.Status instance representing that status message\n'''\n", "func_signal": "def GetStatus(self, id):\n", "code": "try:\n  if id:\n    int(id)\nexcept:\n  raise TwitterError(\"id must be an integer\")\nurl = 'http://twitter.com/statuses/show/%s.json' % id\njson = self._FetchUrl(url)\ndata = simplejson.loads(json)\nreturn Status.NewFromJsonDict(data)", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Set the username and password for this instance\n\nArgs:\n  username: The twitter username.\n  password: The twitter password.\n'''\n", "func_signal": "def SetCredentials(self, username, password):\n", "code": "self._username = username\nself._password = password", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Destroys the direct message specified in the required ID parameter.\n\nThe twitter.Api instance must be authenticated, and the\nauthenticating user must be the recipient of the specified direct\nmessage.\n\nArgs:\n  id: The id of the direct message to be destroyed\n\nReturns:\n  A twitter.DirectMessage instance representing the message destroyed\n'''\n", "func_signal": "def DestroyDirectMessage(self, id):\n", "code": "url = 'http://twitter.com/direct_messages/destroy/%s.json' % id\njson = self._FetchUrl(url, post_data={})\ndata = simplejson.loads(json)\nreturn DirectMessage.NewFromJsonDict(data)", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Returns a single user.\n\nThe twitter.Api instance must be authenticated.\n\nArgs:\n  user: The username or id of the user to retrieve.\n\nReturns:\n  A twitter.User instance representing that user\n'''\n", "func_signal": "def GetUser(self, user):\n", "code": "url = 'http://twitter.com/users/show/%s.json' % user\njson = self._FetchUrl(url)\ndata = simplejson.loads(json)\nreturn User.NewFromJsonDict(data)", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Fetch the sequence of twitter.User instances, one for each friend.\n\nArgs:\n  user: the username or id of the user whose friends you are fetching.  If\n  not specified, defaults to the authenticated user. [optional]\n\nThe twitter.Api instance must be authenticated.\n\nReturns:\n  A sequence of twitter.User instances, one for each friend\n'''\n", "func_signal": "def GetFriends(self, user=None):\n", "code": "if not self._username:\n  raise TwitterError(\"twitter.Api instance must be authenticated\")\nif user:\n  url = 'http://twitter.com/statuses/friends/%s.json' % user\nelse:\n  url = 'http://twitter.com/statuses/friends.json'\njson = self._FetchUrl(url)\ndata = simplejson.loads(json)\nreturn [User.NewFromJsonDict(x) for x in data]", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''A dict representation of this twitter.DirectMessage instance.\n\nThe return value uses the same key names as the JSON representation.\n\nReturn:\n  A dict representing this twitter.DirectMessage instance\n'''\n", "func_signal": "def AsDict(self):\n", "code": "data = {}\nif self.id:\n  data['id'] = self.id\nif self.created_at:\n  data['created_at'] = self.created_at\nif self.sender_id:\n  data['sender_id'] = self.sender_id\nif self.sender_screen_name:\n  data['sender_screen_name'] = self.sender_screen_name\nif self.recipient_id:\n  data['recipient_id'] = self.recipient_id\nif self.recipient_screen_name:\n  data['recipient_screen_name'] = self.recipient_screen_name\nif self.text:\n  data['text'] = self.text\nreturn data", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Discontinues friendship with the user specified in the user parameter.\n\nThe twitter.Api instance must be authenticated.\n\nArgs:\n  The ID or screen name of the user  with whom to discontinue friendship.\nReturns:\n  A twitter.User instance representing the discontinued friend.\n'''\n", "func_signal": "def DestroyFriendship(self, user):\n", "code": "url = 'http://twitter.com/friendships/destroy/%s.json' % user\njson = self._FetchUrl(url, post_data={})\ndata = simplejson.loads(json)\nreturn User.NewFromJsonDict(data)", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Post a twitter status message from the authenticated user.\n\nThe twitter.Api instance must be authenticated.\n\nArgs:\n  text: The message text to be posted.  Must be less than 140 characters.\n\nReturns:\n  A twitter.Status instance representing the message posted\n'''\n", "func_signal": "def PostUpdate(self, text):\n", "code": "if not self._username:\n  raise TwitterError(\"The twitter.Api instance must be authenticated.\")\nif len(text) > 140:\n  raise TwitterError(\"Text must be less than or equal to 140 characters.\")\nurl = 'http://twitter.com/statuses/update.json'\ndata = {'status': text}\njson = self._FetchUrl(url, post_data=data)\ndata = simplejson.loads(json)\nreturn Status.NewFromJsonDict(data)", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Create a new instance based on a JSON dict.\n\nArgs:\n  data: A JSON dict, as converted from the JSON in the twitter API\nReturns:\n  A twitter.Status instance\n'''\n", "func_signal": "def NewFromJsonDict(data):\n", "code": "if 'user' in data:\n  user = User.NewFromJsonDict(data['user'])\nelse:\n  user = None\nreturn Status(created_at=data.get('created_at', None),\n              id=data.get('id', None),\n              text=data.get('text', None),\n              user=user)", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Clear the username and password for this instance\n'''\n", "func_signal": "def ClearCredentials(self):\n", "code": "self._username = None\nself._password = None", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Fetch the sequence of twitter.Status messages for a user's friends\n\nThe twitter.Api instance must be authenticated if the user is private.\n\nArgs:\n  user:\n    Specifies the ID or screen name of the user for whom to return\n    the friends_timeline.  If unspecified, the username and password\n    must be set in the twitter.Api instance.  [optional]\n  since:\n    Narrows the returned results to just those statuses created\n    after the specified HTTP-formatted date. [optional]\n\nReturns:\n  A sequence of twitter.Status instances, one for each message\n'''\n", "func_signal": "def GetFriendsTimeline(self, user=None, since=None):\n", "code": "if user:\n  url = 'http://twitter.com/statuses/friends_timeline/%s.json' % user\nelif not user and not self._username:\n  raise TwitterError(\"User must be specified if API is not authenticated.\")\nelse:\n  url = 'http://twitter.com/statuses/friends_timeline.json'\nparameters = {}\nif since:\n  parameters['since'] = since\njson = self._FetchUrl(url, parameters=parameters)\ndata = simplejson.loads(json)\nreturn [Status.NewFromJsonDict(x) for x in data]", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "# Break url into consituent parts\n", "func_signal": "def _BuildUrl(self, url, path_elements=None, extra_params=None):\n", "code": "(scheme, netloc, path, params, query, fragment) = urlparse.urlparse(url)\n\n# Add any additional path elements to the path\nif path_elements:\n  # Filter out the path elements that have a value of None\n  p = [i for i in path_elements if i]\n  if not path.endswith('/'):\n    path += '/'\n  path += '/'.join(p)\n\n# Add any additional query parameters to the query string\nif extra_params and len(extra_params) > 0:\n  extra_query = self._EncodeParameters(extra_params)\n  # Add it to the existing query\n  if query:\n    query += '&' + extra_query\n  else:\n    query = extra_query\n\n# Return the rebuilt URL\nreturn urlparse.urlunparse((scheme, netloc, path, params, query, fragment))", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Fetch the sequence of twitter.User instances featured on twitter.com\n\nThe twitter.Api instance must be authenticated.\n\nReturns:\n  A sequence of twitter.User instances\n'''\n", "func_signal": "def GetFeatured(self):\n", "code": "url = 'http://twitter.com/statuses/featured.json'\njson = self._FetchUrl(url)\ndata = simplejson.loads(json)\nreturn [User.NewFromJsonDict(x) for x in data]", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "'''Create a new instance based on a JSON dict.\n\nArgs:\n  data: A JSON dict, as converted from the JSON in the twitter API\nReturns:\n  A twitter.DirectMessage instance\n'''\n", "func_signal": "def NewFromJsonDict(data):\n", "code": "return DirectMessage(created_at=data.get('created_at', None),\n                     recipient_id=data.get('recipient_id', None),\n                     sender_id=data.get('sender_id', None),\n                     text=data.get('text', None),\n                     sender_screen_name=data.get('sender_screen_name', None),\n                     id=data.get('id', None),\n                     recipient_screen_name=data.get('recipient_screen_name', None))", "path": "prev_twitter_libs\\twitter.appengine.py", "repo_name": "affectlabs/findfollow", "stars": 2, "license": "None", "language": "python", "size": 244}
{"docstring": "\"\"\"\nAdds the column 'name' to the table 'table_name'.\nUses the 'field' paramater, a django.db.models.fields.Field instance,\nto generate the necessary sql\n\n@param table_name: The name of the table to add the column to\n@param name: The name of the column to add\n@param field: The field to use\n\"\"\"\n", "func_signal": "def add_column(self, table_name, name, field):\n", "code": "qn = connection.ops.quote_name\nsql = self.column_sql(table_name, name, field)\nif sql:\n    params = (\n        qn(table_name),\n        sql,\n    )\n    sql = 'ALTER TABLE %s ADD COLUMN %s;' % params\n    self.execute(sql)", "path": "db\\generic.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\"\nAlters the given column name so it will match the given field.\nNote that conversion between the two by the database must be possible.\n\n@param table_name: The name of the table to add the column to\n@param name: The name of the column to alter\n@param field: The new field definition to use\n\"\"\"\n\n# hook for the field to do any resolution prior to it's attributes being queried\n", "func_signal": "def alter_column(self, table_name, name, field):\n", "code": "if hasattr(field, 'south_init'):\n    field.south_init()\n\nqn = connection.ops.quote_name\n\n# First, change the type\nparams = {\n    \"column\": qn(name),\n    \"type\": field.db_type(),\n}\nsqls = [self.alter_string_set_type % params]\n\n\n# Next, set any default\nparams = (\n    qn(name),\n)\n\nif not field.null and field.has_default():\n    default = field.get_default()\n    if isinstance(default, basestring):\n        default = \"'%s'\" % default\n    params += (\"SET DEFAULT %s\",)\nelse:\n    params += (\"DROP DEFAULT\",)\n\nsqls.append('ALTER COLUMN %s %s ' % params)\n\n\n# Next, nullity\nparams = {\n    \"column\": qn(name),\n    \"type\": field.db_type(),\n}\nif field.null:\n    sqls.append(self.alter_string_drop_null % params)\nelse:\n    sqls.append(self.alter_string_set_null % params)\n\n\n# TODO: Unique\n\nself.execute(\"ALTER TABLE %s %s;\" % (qn(table_name), \", \".join(sqls)))", "path": "db\\generic.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\"\nCreates the table 'table_name'. 'fields' is a tuple of fields,\neach repsented by a 2-part tuple of field name and a\ndjango.db.models.fields.Field object\n\"\"\"\n", "func_signal": "def create_table(self, table_name, fields):\n", "code": "qn = connection.ops.quote_name\ncolumns = [\n    self.column_sql(table_name, field_name, field)\n    for field_name, field in fields\n]\n\nself.execute('CREATE TABLE %s (%s);' % (qn(table_name), ', '.join([col for col in columns if col])))", "path": "db\\generic.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\"\nMakes sure the following commands are inside a transaction.\nMust be followed by a (commit|rollback)_transaction call.\n\"\"\"\n", "func_signal": "def start_transaction(self):\n", "code": "if self.dry_run:\n    return\ntransaction.commit_unless_managed()\ntransaction.enter_transaction_management()\ntransaction.managed(True)", "path": "db\\generic.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\"\nInspects the source code of 'model' to find the code used to generate 'field'\n\"\"\"\n", "func_signal": "def generate_field_definition(model, field):\n", "code": "def test_field(field_definition):\n    try:\n        parser.suite(field_definition)\n        return True\n    except SyntaxError:\n        return False\n        \ndef strip_comments(field_definition):\n    # remove any comments at the end of the field definition string.\n    field_definition = field_definition.strip()\n    if '#' not in field_definition:\n        return field_definition\n        \n    index = field_definition.index('#')\n    while index:\n        stripped_definition = field_definition[:index].strip()\n        # if the stripped definition is parsable, then we've removed\n        # the correct comment.\n        if test_field(stripped_definition):\n            return stripped_definition\n            \n        index = field_definition.index('#', index+1)\n        \n    return field_definition\n    \n# give field subclasses a chance to do anything tricky\n# with the field definition\nif hasattr(field, 'south_field_definition'):\n    return field.south_field_definition()\n\nfield_pieces = []\nfound_field = False\nsource = inspect.getsourcelines(model)\nif not source:\n    raise Exception(\"Could not find source to model: '%s'\" % (model.__name__))\n    \n# look for a line starting with the field name\nstart_field_re = re.compile(r'\\s*%s\\s*=\\s*(.*)' % field.name)\nfor line in source[0]:\n    # if the field was found during a previous iteration, \n    # we're here because the field spans across multiple lines\n    # append the current line and try again\n    if found_field:\n        field_pieces.append(line.strip())\n        if test_field(' '.join(field_pieces)):\n            return strip_comments(' '.join(field_pieces))\n        continue\n    \n    match = start_field_re.match(line)\n    if match:\n        found_field = True\n        field_pieces.append(match.groups()[0].strip())\n        if test_field(' '.join(field_pieces)):\n            return strip_comments(' '.join(field_pieces))\n\n# the 'id' field never gets defined, so return what django does by default\n# django.db.models.options::_prepare\nif field.name == 'id' and field.__class__ == models.AutoField:\n    return \"models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)\"\n\n# search this classes parents\nfor base in model.__bases__:\n    # we don't want to scan the django base model\n    if base == models.Model:\n        continue\n        \n    field_definition = generate_field_definition(base, field)\n    if field_definition:\n        return field_definition\n        \nreturn None", "path": "management\\commands\\startmigration.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\"\nSends a post_syncdb signal for the model specified.\n\nIf the model is not found (perhaps it's been deleted?),\nno signal is sent.\n\nTODO: The behavior of django.contrib.* apps seems flawed in that\nthey don't respect created_models.  Rather, they blindly execute\nover all models within the app sending the signal.  This is a\npatch we should push Django to make  For now, this should work.\n\"\"\"\n", "func_signal": "def send_create_signal(self, app_label, model_names):\n", "code": "app = models.get_app(app_label)\nif not app:\n    return\n    \ncreated_models = []\nfor model_name in model_names:\n    model = models.get_model(app_label, model_name)\n    if model:\n        created_models.append(model)\n        \nif created_models:\n    # syncdb defaults -- perhaps take these as options?\n    verbosity = 1\n    interactive = True\n    \n    if hasattr(dispatcher, \"send\"):\n        dispatcher.send(signal=models.signals.post_syncdb, sender=app,\n        app=app, created_models=created_models,\n        verbosity=verbosity, interactive=interactive)\n    else:\n        models.signals.post_syncdb.send(sender=app,\n        app=app, created_models=created_models,\n        verbosity=verbosity, interactive=interactive)", "path": "db\\generic.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\"\nGenerates a full SQL statement to add a foreign key constraint\n\"\"\"\n", "func_signal": "def foreign_key_sql(self, from_table_name, from_column_name, to_table_name, to_column_name):\n", "code": "constraint_name = '%s_refs_%s_%x' % (from_column_name, to_column_name, abs(hash((from_table_name, to_table_name))))\nreturn 'ALTER TABLE %s ADD CONSTRAINT %s FOREIGN KEY (%s) REFERENCES %s (%s)%s;' % (\n    from_table_name,\n    truncate_name(constraint_name, connection.ops.max_name_length()),\n    from_column_name,\n    to_table_name,\n    to_column_name,\n    connection.ops.deferrable_sql() # Django knows this\n)", "path": "db\\generic.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\"\nRenames the table 'old_table_name' to 'table_name'.\n\"\"\"\n", "func_signal": "def rename_table(self, old_table_name, table_name):\n", "code": "if old_table_name == table_name:\n    # No Operation\n    return\nqn = connection.ops.quote_name\nparams = (qn(old_table_name), qn(table_name))\nself.execute('ALTER TABLE %s RENAME TO %s;' % params)", "path": "db\\generic.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\"\nTest column renaming\n\"\"\"\n", "func_signal": "def test_rename(self):\n", "code": "cursor = connection.cursor()\ndb.create_table(\"test2\", [('spam', models.BooleanField(default=False))])\ndb.start_transaction()\n# Make sure we can select the column\ncursor.execute(\"SELECT spam FROM test2\")\n# Rename it\ndb.rename_column(\"test2\", \"spam\", \"eggs\")\ncursor.execute(\"SELECT eggs FROM test2\")\ntry:\n    cursor.execute(\"SELECT spam FROM test2\")\n    self.fail(\"Just-renamed column could be selected!\")\nexcept:\n    pass\ndb.rollback_transaction()", "path": "tests\\db.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\"\nDeletes the table 'table_name'.\n\"\"\"\n", "func_signal": "def delete_table(self, table_name):\n", "code": "qn = connection.ops.quote_name\nparams = (qn(table_name), )\nself.execute('DROP TABLE %s;' % params)", "path": "db\\generic.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\"\nCreates the SQL snippet for a column. Used by add_column and add_table.\n\"\"\"\n", "func_signal": "def column_sql(self, table_name, field_name, field, tablespace=''):\n", "code": "qn = connection.ops.quote_name\n\nfield.set_attributes_from_name(field_name)\n\n# hook for the field to do any resolution prior to it's attributes being queried\nif hasattr(field, 'south_init'):\n    field.south_init()\n\nsql = field.db_type()\nif sql:        \n    field_output = [qn(field.column), sql]\n    field_output.append('%sNULL' % (not field.null and 'NOT ' or ''))\n    if field.primary_key:\n        field_output.append('PRIMARY KEY')\n    elif field.unique:\n        field_output.append('UNIQUE')\n\n    tablespace = field.db_tablespace or tablespace\n    if tablespace and connection.features.supports_tablespaces and field.unique:\n        # We must specify the index tablespace inline, because we\n        # won't be generating a CREATE INDEX statement for this field.\n        field_output.append(connection.ops.tablespace_sql(tablespace, inline=True))\n    \n    sql = ' '.join(field_output)\n    sqlparams = ()\n    # if the field is \"NOT NULL\" and a default value is provided, create the column with it\n    # this allows the addition of a NOT NULL field to a table with existing rows\n    if not field.null and field.has_default():\n        default = field.get_default()\n        if isinstance(default, basestring):\n            default = \"'%s'\" % default.replace(\"'\", \"''\")\n        elif isinstance(default, datetime.date):\n            default = \"'%s'\" % default\n        sql += \" DEFAULT %s\"\n        sqlparams = (default)\n    \n    if field.rel:\n        self.add_deferred_sql(\n            self.foreign_key_sql(\n                table_name,\n                field.column,\n                field.rel.to._meta.db_table,\n                field.rel.to._meta.get_field(field.rel.field_name).column\n            )\n        )\n    \n    if field.db_index and not field.unique:\n        self.add_deferred_sql(self.create_index_sql(table_name, [field.column]))\n    \nif hasattr(field, 'post_create_sql'):\n    style = no_style()\n    for stmt in field.post_create_sql(style, table_name):\n        self.add_deferred_sql(stmt)\n\nif sql:\n    return sql % sqlparams\nelse:\n    return None", "path": "db\\generic.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\"\nExecutes all deferred SQL, resetting the deferred_sql list\n\"\"\"\n", "func_signal": "def execute_deferred_sql(self):\n", "code": "for sql in self.deferred_sql:\n    self.execute(sql)\n    \nself.deferred_sql = []", "path": "db\\generic.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\"\nGenerate a unique name for the index\n\"\"\"\n", "func_signal": "def create_index_name(self, table_name, column_names):\n", "code": "index_unique_name = ''\nif len(column_names) > 1:\n    index_unique_name = '_%x' % abs(hash((table_name, ','.join(column_names))))\n\nreturn '%s_%s%s' % (table_name, column_names[0], index_unique_name)", "path": "db\\generic.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "# wrap 'search_string' in both ' and \" chars when searching\n", "func_signal": "def replace_model_string(field_definition, search_string, model_name):\n", "code": "quotes = [\"'\", '\"']\nfor quote in quotes:\n    test = \"%s%s%s\" % (quote, search_string, quote)\n    if test in field_definition:\n        return field_definition.replace(test, model_name)\n        \nreturn None", "path": "management\\commands\\startmigration.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\"\nTest creation and deletion of tables.\n\"\"\"\n", "func_signal": "def test_create(self):\n", "code": "cursor = connection.cursor()\n# It needs to take at least 2 args\nself.assertRaises(TypeError, db.create_table)\nself.assertRaises(TypeError, db.create_table, \"test1\")\n# Empty tables (i.e. no columns) are not fine, so make at least 1\ndb.create_table(\"test1\", [('email_confirmed', models.BooleanField(default=False))])\ndb.start_transaction()\n# And should exist\ncursor.execute(\"SELECT * FROM test1\")\n# Make sure we can't do the same query on an empty table\ntry:\n    cursor.execute(\"SELECT * FROM nottheretest1\")\n    self.fail(\"Non-existent table could be selected!\")\nexcept:\n    pass\n# Clear the dirty transaction\ndb.rollback_transaction()\ndb.start_transaction()\n# Remove the table\ndb.delete_table(\"test1\")\n# Make sure it went\ntry:\n    cursor.execute(\"SELECT * FROM test1\")\n    self.fail(\"Just-deleted table could be selected!\")\nexcept:\n    pass\n# Clear the dirty transaction\ndb.rollback_transaction()\ndb.start_transaction()\n# Try deleting a nonexistent one\ntry:\n    db.delete_table(\"nottheretest1\")\n    self.fail(\"Non-existent table could be deleted!\")\nexcept:\n    pass\ndb.rollback_transaction()", "path": "tests\\db.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\"\nDeletes an index created with create_index.\nThis is possible using only columns due to the deterministic\nindex naming function which relies on column names.\n\"\"\"\n", "func_signal": "def delete_index(self, table_name, column_names, db_tablespace=''):\n", "code": "name = self.create_index_name(table_name, column_names)\nsql = \"DROP INDEX %s\" % name\nself.execute(sql)", "path": "db\\generic.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\"\nRolls back the current transaction.\nMust be preceded by a start_transaction call.\n\"\"\"\n", "func_signal": "def rollback_transaction(self):\n", "code": "if self.dry_run:\n    return\ntransaction.rollback()\ntransaction.leave_transaction_management()", "path": "db\\generic.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "# Model 'Spam'\n", "func_signal": "def forwards(self):\n", "code": "        db.create_table(\"southtest_spam\", (\n            ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)),\n            ('weight', models.FloatField()),\n            ('expires', models.DateTimeField()),\n            ('name', models.CharField(max_length=255))\n        ))", "path": "tests\\fakeapp\\migrations\\0001_spam.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\" Executes a create index statement \"\"\"\n", "func_signal": "def create_index(self, table_name, column_names, unique=False, db_tablespace=''):\n", "code": "sql = self.create_index_sql(table_name, column_names, unique, db_tablespace)\nself.execute(sql)", "path": "db\\generic.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "# if the field definition contains any of the following strings,\n# replace them with the model definition:\n#   applabel.modelname\n#   modelname\n#   django.db.models.fields.related.RECURSIVE_RELATIONSHIP_CONSTANT\n", "func_signal": "def related_field_definition(field, field_definition):\n", "code": "strings = [\n    '%s.%s' % (field.rel.to._meta.app_label, field.rel.to._meta.object_name),\n    '%s' % field.rel.to._meta.object_name,\n    RECURSIVE_RELATIONSHIP_CONSTANT\n]\n\nfor test in strings:\n    fd = replace_model_string(field_definition, test, field.rel.to._meta.object_name)\n    if fd:\n        return fd\n\nreturn field_definition", "path": "management\\commands\\startmigration.py", "repo_name": "akaihola/django-south", "stars": 2, "license": "None", "language": "python", "size": 168}
{"docstring": "\"\"\" Draw the DetailsView on screen. \"\"\"\n", "func_signal": "def paint(self):\n", "code": "(height, width) = self.window.getmaxyx()\n       \nself.window.clear()\nself.details_pad.clear()\n\nif self.model:\n    self.window.addstr(0, 0, self.model.name)\n    # TODO: Only show this when there is more to display\n    self.window.addstr(height - 1, 0, \"press d for more.\")\n    if type(self.model) == DetailsModel:\n        self.paint_summary()\n\nself.details_pad.refresh()\nself.window.refresh()", "path": "src\\packagelist.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\" Draw a list on the screen. \"\"\"\n# FIXME: Too much duplicated code and nastiness\n# Could use a generator here to provide items in the list.\n", "func_signal": "def __paint_list(self, list_model, row, depth):\n", "code": "if (row >= self.scroll_top and row <= self.scroll_bottom):\n    attribute = self.__get_attribute(row)\n    self.__add_menu_title(row - self.scroll_top, 5, list_model.title,\n        depth, attribute)\nfor i in range(len(list_model.packages)):\n    entry = list_model.packages[i]\n    draw_row = i + row + 1\n    if entry.__class__ == ListModel:\n        self.__paint_list(entry, draw_row, depth + 1)\n    else:\n        if (draw_row >= self.scroll_top and\n            draw_row <= self.scroll_bottom):\n            self.__add_menu_package(draw_row, entry)", "path": "src\\packagelist.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\" Draw the package's full details. \"\"\"\n", "func_signal": "def paint_full(self):\n", "code": "self.details_pad.addstr(0, 0, \"Name: %s\" % self.model.name)\nself.details_pad.addstr(1, 0,\n    \"Version: %s\" % self.model.version)\nself.details_pad.addstr(2, 0,\n    \"Release: %s\" % self.model.release)\nself.details_pad.addstr(3, 0,\n    \"Architecture: %s\" % self.model.arch)\nself.details_pad.addstr(4, 0,\n    \"Details: %s\" % self.model.description)", "path": "src\\packagelist.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\" Return the length of the list including sublists. \"\"\"\n", "func_signal": "def __get_length(self):\n", "code": "length = 1 # Include the title.\nfor entry in self.packages:\n    if entry.__class__ == ListModel:\n        length = length + entry.__get_length()\n    else:\n        length = length + 1\nreturn length", "path": "src\\yumlistmodel.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\" Return the length of the list including sublists. \"\"\"\n", "func_signal": "def __get_length(self):\n", "code": "length = 1 # Include the title.\nfor entry in self.packages:\n    if entry.__class__ == ListModel:\n        length = length + entry.__get_length()\n    else:\n        length = length + 1\nreturn length", "path": "src\\packagelist.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\" Move the selection down one entry. \"\"\"\n", "func_signal": "def move_down(self):\n", "code": "if (self.selected_entry < self.length - 1):\n    self.selected_entry = self.selected_entry + 1\nself.emit_signal(\"selection-changed\")", "path": "src\\yumlistmodel.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\" Move the selection up one entry. \"\"\"\n", "func_signal": "def move_up(self):\n", "code": "if (self.selected_entry > 0):\n    self.selected_entry = self.selected_entry - 1\nself.emit_signal(\"selection-changed\")", "path": "src\\yumlistmodel.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "# From pirut.\n# FIXME: doing this directly instead of using self.rpmdb.installed()\n# speeds things up by 400%\n", "func_signal": "def simpleDBInstalled(self, yum_base, name):\n", "code": "mi = yum_base.ts.ts.dbMatch('name', name)\nif mi.count() > 0:\n    return True\nreturn False", "path": "src\\yumlistmodel.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\" Draw the list on screen. \"\"\"\n", "func_signal": "def paint(self):\n", "code": "self.window.addstr(0, 0, \"EIOM Pri Section  Package      \" + \\\n        \"Inst.ver    Avail.ver   Description\")\nself.__adjust_scroll_window()\nself.__paint_list(self._model, 0, 1)\nself.pad.refresh()", "path": "src\\packagelist.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\" Draw the package view onscreen. \"\"\"\n", "func_signal": "def paint(self):\n", "code": "self.list_view.paint()\nself.details_view.paint()\n\nself.window.addstr(0, 0, \n    \"yselect - inspection of package states (avail., priority)\")\n\nself.window.refresh()", "path": "src\\packagelist.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\"\nAdd an observer of the given signal to this object.\n\nsignal_name is the name of an already registered signal on this object.\nRaises a NoSuchSignalException if signal_name is not registered on this\nobject.\n\"\"\"\n", "func_signal": "def add_observer(self, signal_name, observer):\n", "code": "if not self.signals.has_key(signal_name):\n    raise NoSuchSignalException\nsignal_observers = self.signals[signal_name]\nif signal_observers.count(observer) == 0:\n    self.signals[signal_name].append(observer)", "path": "src\\observable.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\"\nDetermine if row is the selected_entry or not.\n\nReturn the appropriate curses attribute.\n\"\"\"\n", "func_signal": "def __get_attribute(self, row):\n", "code": "if (row == self._model.selected_entry):\n    attribute = curses.A_REVERSE\nelse:\n    attribute = curses.A_NORMAL\nreturn attribute", "path": "src\\packagelist.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\" Move the selection up one entry. \"\"\"\n", "func_signal": "def move_up(self):\n", "code": "if (self.selected_entry > 0):\n    self.selected_entry = self.selected_entry - 1\nself.emit_signal(\"selection-changed\")", "path": "src\\packagelist.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\" \nMove the scrolling list window.\n\nWe only adjust if the model's selected entry is at the bottom or the\ntop of the scroll window.\n\"\"\"\n", "func_signal": "def __adjust_scroll_window(self):\n", "code": "if (self._model.selected_entry < self.scroll_top):\n    self.scroll_top = self.scroll_top - 1\n    self.scroll_bottom = self.scroll_bottom - 1\n\nif (self._model.selected_entry > self.scroll_bottom):\n    self.scroll_top = self.scroll_top + 1\n    self.scroll_bottom = self.scroll_bottom + 1", "path": "src\\packagelist.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\"\nDraw a menu title on the screen.\n\nStarting at position x,y draw a menu title. depth indicates how many\nparents the menu has. Title is rendered in bold.\n\"\"\"\n", "func_signal": "def __add_menu_title(self, cur_y, cur_x, title, depth, attribute):\n", "code": "line_length = depth * 2 - 1\n       \nself.pad.addstr(cur_y, 0, cur_x * \" \", attribute) \nself.pad.hline(cur_y, cur_x, curses.ACS_HLINE, line_length, attribute)\nself.pad.addstr(cur_y, cur_x + line_length, \" %s \" % title,\n    curses.A_BOLD and attribute)\nself.pad.hline(cur_y, cur_x + line_length + 2 + len(title),\n    curses.ACS_HLINE, line_length, attribute)\n\n(max_y, max_x) = self.pad.getmaxyx()\nline_end = max_x - (cur_x + 2 * line_length + 2 + len(title))\nself.pad.addstr(cur_y, cur_x + 2 * line_length + 2 + len(title),\n    line_end * \" \", attribute)", "path": "src\\packagelist.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\" Draw a package line in the menu. \"\"\"\n", "func_signal": "def __add_menu_package(self, cur_y, package):\n", "code": "format_string = self.__make_package_format_string() \npkg_string = format_string % \\\n    (package.eiom, package.priority, package.section, package.name,\n    package.version, package.avail_version, package.summary)\nattribute = self.__get_attribute(cur_y)\nself.pad.addstr(cur_y - self.scroll_top, 0, pkg_string, attribute)", "path": "src\\packagelist.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\" Register a new signal for this object to emit. \"\"\"\n", "func_signal": "def register_signal(self, signal_name):\n", "code": "if not self.signals.has_key(signal_name):\n    self.signals[signal_name] = []", "path": "src\\observable.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\" React to keyboard input. \"\"\"\n#Try Super's implementation first.\n", "func_signal": "def handle_input(self, key):\n", "code": "handled = super(ListController, self).handle_input(key)\nif not handled:\n    if key == ord('-') or key == ord('_'):\n        self._model.selected.action = 'REMOVE'\n        handled = True\n    elif key == ord('+'):\n        self._model.selected.action = 'INSTALL'\n        handled = True\n    elif key == ord('x'):\n        self.emit_signal(\"return\")\n        handled = True\n\nreturn handled", "path": "src\\packagelist.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\"\nFill in the correct amounts to pad each column on the right with.\n\"\"\"\n", "func_signal": "def __make_package_format_string(self):\n", "code": "format_string = \"%%-%d.%ds %%-%d.%ds %%-%d.%ds %%-%d.%ds %%-%d.%ds \" \\\n    \"%%-%d.%ds %%-%d.%ds\" % \\\n    (self.EIOM_col_width, self.EIOM_col_width,\n    self.priority_col_width, self.priority_col_width, \n    self.section_col_width, self.section_col_width,\n    self.package_col_width, self.package_col_width,\n    self.installed_col_width, self.installed_col_width,\n    self.available_col_width, self.available_col_width, \n    self.description_col_width, self.description_col_width)\nreturn format_string", "path": "src\\packagelist.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\" Move the selection down one entry. \"\"\"\n", "func_signal": "def move_down(self):\n", "code": "if (self.selected_entry < self.length - 1):\n    self.selected_entry = self.selected_entry + 1\nself.emit_signal(\"selection-changed\")", "path": "src\\packagelist.py", "repo_name": "crawl-space/yselect", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 156}
{"docstring": "\"\"\"Extracts the Blogger id of this blog.\nThis method is useful when contructing URLs by hand. The blog id is\noften used in blogger operation URLs. This should not be confused with\nthe id member of a BloggerBlog. The id element is the Atom id XML element.\nThe blog id which this method returns is a part of the Atom id.\n\nReturns:\n  The blog's unique id as a string.\n\"\"\"\n", "func_signal": "def GetBlogId(self):\n", "code": "if self.id.text:\n  return self.blog_id_pattern.match(self.id.text).group(2)\nreturn None", "path": "conduit\\modules\\GoogleModule\\gdata\\blogger\\__init__.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "# Convert the members of this class which are XML child nodes.\n# This uses the class's _children dictionary to find the members which\n# should become XML child nodes.\n", "func_signal": "def _AddMembersToElementTree(self, tree):\n", "code": "member_node_names = [values[0] for tag, values in\n                                   self.__class__._children.iteritems()]\nfor member_name in member_node_names:\n  member = getattr(self, member_name)\n  if member is None:\n    pass\n  elif isinstance(member, list):\n    for instance in member:\n      instance._BecomeChildElement(tree)\n  else:\n    member._BecomeChildElement(tree)\n# Special logic to set the desired XML attribute.\nkey = self.findKey(self.value)\nif key is not None:\n  tree.attrib[self.attrib_name]=key\n# Convert the members of this class which are XML attributes.\nfor xml_attribute, member_name in self.__class__._attributes.iteritems():\n  member = getattr(self, member_name)\n  if member is not None:\n    tree.attrib[xml_attribute] = member\n# Lastly, call the parent's _AddMembersToElementTree to get any\n# extension elements.\natom.ExtensionContainer._AddMembersToElementTree(self, tree)", "path": "conduit\\modules\\GoogleModule\\gdata\\calendar\\__init__.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "# Special logic to use the enum_map to set the value of the object's value member.\n", "func_signal": "def _ConvertElementAttributeToMember(self, attribute, value):\n", "code": "if attribute == self.attrib_name and value != '':\n  self.value = self.enum_map[value]\n  return\n# Find the attribute in this class's list of attributes.\nif self.__class__._attributes.has_key(attribute):\n  # Find the member of this class which corresponds to the XML attribute\n  # (lookup in current_class._attributes) and set this member to the\n  # desired value (using self.__dict__).\n  setattr(self, self.__class__._attributes[attribute], value)\nelse:\n  # The current class doesn't map this attribute, so try to parent class.\n  atom.ExtensionContainer._ConvertElementAttributeToMember(self, \n                                                           attribute,\n                                                           value)", "path": "conduit\\modules\\GoogleModule\\gdata\\calendar\\__init__.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "\"\"\"\nAccepts a vfs file. Must be made local.\nI also store a md5 of the photos uri to check for duplicates\n\"\"\"\n", "func_signal": "def put(self, photo, overwrite, LUID=None):\n", "code": "DataProvider.DataSink.put(self, photo, overwrite, LUID)\n\noriginalName = photo.get_filename()\n#Gets the local URI (/foo/bar). If this is a remote file then\n#it is first transferred to the local filesystem\nphotoURI = photo.get_local_uri()\nmimeType = photo.get_mimetype()\ntags = photo.get_tags ()\ncaption = photo.get_caption()\n\nuploadInfo = UploadInfo(photoURI, mimeType, originalName, tags, caption)\n       \n#Check if we have already uploaded the photo\nif LUID != None:\n    info = self._get_photo_info(LUID)\n    #check if a photo exists at that UID\n    if info != None:\n        if overwrite == True:\n            #replace the photo\n            return self._replace_photo(LUID, uploadInfo)\n        else:\n            #Only upload the photo if it is newer than the Remote one\n            url = self._get_raw_photo_url(info)\n            remoteFile = File.File(url)\n\n            #this is a limited test for equality type comparison\n            comp = photo.compare(remoteFile,True)\n            log.debug(\"Compared %s with %s to check if they are the same (size). Result = %s\" % \n                    (photo.get_filename(),remoteFile.get_filename(),comp))\n            if comp != conduit.datatypes.COMPARISON_EQUAL:\n                raise Exceptions.SynchronizeConflictError(comp, photo, remoteFile)\n            else:\n                return conduit.datatypes.Rid(uid=LUID)\n\nlog.debug(\"Uploading Photo URI = %s, Mimetype = %s, Original Name = %s\" % (photoURI, mimeType, originalName))\n\n#upload the file\nreturn self._upload_photo (uploadInfo)", "path": "conduit\\dataproviders\\Image.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "# Special logic to handle Web Content links\n", "func_signal": "def _ConvertElementTreeToMember(self, child_tree):\n", "code": "if (child_tree.tag == '{%s}link' % atom.ATOM_NAMESPACE and \n    child_tree.attrib['rel'] == WEB_CONTENT_LINK_REL):\n  if self.link is None:\n    self.link = []\n  self.link.append(atom._CreateClassFromElementTree(WebContentLink, \n                                                    child_tree))\n  return\n# Find the element's tag in this class's list of child members\nif self.__class__._children.has_key(child_tree.tag):\n  member_name = self.__class__._children[child_tree.tag][0]\n  member_class = self.__class__._children[child_tree.tag][1]\n  # If the class member is supposed to contain a list, make sure the\n  # matching member is set to a list, then append the new member\n  # instance to the list.\n  if isinstance(member_class, list):\n    if getattr(self, member_name) is None:\n      setattr(self, member_name, [])\n    getattr(self, member_name).append(atom._CreateClassFromElementTree(\n        member_class[0], child_tree))\n  else:\n    setattr(self, member_name,\n            atom._CreateClassFromElementTree(member_class, child_tree))\nelse:\n  atom.ExtensionContainer._ConvertElementTreeToMember(self, child_tree)", "path": "conduit\\modules\\GoogleModule\\gdata\\calendar\\__init__.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "\"\"\"\niPod needs a local path to the DB, not a URI\n\"\"\"\n", "func_signal": "def get_args(self, udi, **kwargs):\n", "code": "kwargs[\"mount_path\"] = self._get_mount_path(kwargs)\nreturn (kwargs['mount_path'], udi)", "path": "conduit\\modules\\iPodModule\\iPodModule.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "#Read information about the ipod, like if it supports\n#photos or not\n", "func_signal": "def get_dataproviders(self, udi, **kwargs):\n", "code": "d = gpod.itdb_device_new()\ngpod.itdb_device_set_mountpoint(d,self._get_mount_path(kwargs))\nsupportsPhotos = gpod.itdb_device_supports_photo(d)\ngpod.itdb_device_free(d)\nif supportsPhotos:\n    return [IPodMusicTwoWay, IPodVideoTwoWay, IPodNoteTwoWay, IPodContactsTwoWay, IPodCalendarTwoWay, IPodPhotoSink]\nelse:\n    log.info(\"iPod does not report photo support\")\n    return [IPodMusicTwoWay, IPodVideoTwoWay, IPodNoteTwoWay, IPodContactsTwoWay, IPodCalendarTwoWay]", "path": "conduit\\modules\\iPodModule\\iPodModule.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "\"\"\"\nData is a 2 numeric char string. The first char is the\nUID of the data, and the second is a day past my bday\ne.g.\n10 -> uid=1, mtime - 16/8/1983\n72 -> uid=7, mtime - 18/8/1983   \n\"\"\"\n", "func_signal": "def __init__(self, data, **kwargs):\n", "code": "DataType.DataType.__init__(self)\nassert(len(data) == 2)\nself.data = data\nself.set_UID(data[0])\nself.set_mtime(datetime.datetime(1983,8,16+int(data[1])))", "path": "test\\python-tests\\TestCoreSyncLogic.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "\"\"\"\nReturns the name of a non-existant file on the\nipod within directory\n\n@param directory: Name of the directory within the device root to make\nthe random file in\n\"\"\"\n", "func_signal": "def _get_unique_filename(self, directory):\n", "code": "done = False\nwhile not done:\n    f = os.path.join(self.mountPoint,directory,Utils.random_string())\n    if not os.path.exists(f):\n        done = True\nreturn f", "path": "conduit\\modules\\iPodModule\\iPodModule.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "\"\"\"\nConnects to the system bus and configures avahi to listen for\nConduit services\n\"\"\"\n", "func_signal": "def __init__(self):\n", "code": "bus = dbus.SystemBus()\nself.server = dbus.Interface(\n                    bus.get_object(\n                        avahi.DBUS_NAME,\n                        avahi.DBUS_PATH_SERVER),\n                    avahi.DBUS_INTERFACE_SERVER)\nobj = bus.get_object(\n                    avahi.DBUS_NAME,\n                    self.server.ServiceBrowserNew(\n                        avahi.IF_UNSPEC,\n                        avahi.PROTO_UNSPEC,\n                        AVAHI_SERVICE_NAME, \n                        AVAHI_SERVICE_DOMAIN,\n                        dbus.UInt32(0)\n                        )\n                    )\nbrowser = dbus.Interface(obj, avahi.DBUS_INTERFACE_SERVICE_BROWSER)\nbrowser.connect_to_signal('ItemNew', self._new_service)\nbrowser.connect_to_signal('ItemRemove', self._remove_service)", "path": "scripts\\ConduitAvahiListener.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "'''\nWraps an iPod track in a Datatype. \nPassing a file creates a new track in the iPod db, with media information \nfrom that file. Use copy_ipod to transfer it into the iPod.\nPassing an existing iPod track exports the track's information as a \nMedia datatype.\n\n@param ipod_track: An iPod track to wrap\n@param f: A File to extract the information from\n'''\n", "func_signal": "def __init__(self, db, track = None, f = None):\n", "code": "self.db = db\nif track:\n    self.track = track\nelse:\n    self.track = self.db.new_Track()\nif f:\n    self.set_info_from_file(f)", "path": "conduit\\modules\\iPodModule\\iPodModule.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "\"\"\"\nThe LUID for a note in the iPod is the note title\n\"\"\"\n", "func_signal": "def put(self, note, overwrite, LUID=None):\n", "code": "DataProvider.TwoWay.put(self, note, overwrite, LUID)\n\nif LUID != None:\n    #Check if both the shadow copy and the ipodified version exists\n    if self._note_exists(LUID):\n        if overwrite == True:\n            #replace the note\n            log.debug(\"Replacing Note %s\" % LUID)\n            return self._save_note_to_ipod(LUID, note)\n        else:\n            #only overwrite if newer\n            log.warn(\"OVERWRITE IF NEWER NOT IMPLEMENTED\")\n            return self._save_note_to_ipod(LUID, note)\n\n#make a new note\nlog.warn(\"CHECK IF EXISTS, COMPARE, SAVE\")\nreturn self._save_note_to_ipod(note.title, note)", "path": "conduit\\modules\\iPodModule\\iPodModule.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "\"\"\"\nSave a simple iPod note in /Notes\nIf the note has raw then also save that in shadowdir\nuid is the note title.\n\"\"\"\n# the normal note viewed by the iPod\n# inject an encoding declaration if it is missing.\n", "func_signal": "def _save_note_to_ipod(self, uid, note):\n", "code": "contents = note.get_contents()\nif not self.ENCODING_DECLARATION in contents:\n    contents = ''.join([self.ENCODING_DECLARATION, contents])\nipodnote = Utils.new_tempfile(contents)\n\nipodnote.transfer(os.path.join(self.dataDir,uid), overwrite=True)\nipodnote.set_mtime(note.get_mtime())\nipodnote.set_UID(uid)\n\n#the raw pickled note for sync\nraw = open(os.path.join(self._get_shadow_dir(),uid),'wb')\npickle.dump(note, raw, -1)\nraw.close()\n\nreturn ipodnote.get_rid()", "path": "conduit\\modules\\iPodModule\\iPodModule.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "\"\"\"\nGets a note from the ipod, If the pickled shadow copy exists\nthen return that\n\"\"\"\n", "func_signal": "def _get_note_from_ipod(self, uid):\n", "code": "rawNoteURI = os.path.join(self._get_shadow_dir(),uid)\nif os.path.exists(rawNoteURI):\n    raw = open(rawNoteURI,'rb')\n    try:\n        n = pickle.load(raw)\n        raw.close()\n        return n\n    except:\n        raw.close()\n\nnoteURI = os.path.join(self.dataDir, uid)\nnoteFile = File.File(URI=noteURI)\n#get the contents from the note, get the raw from the raw copy.\n#the UID for notes from the ipod is the filename\nn = Note.Note(\n            title=uid,\n            contents=noteFile.get_contents_as_text().replace(\n                self.ENCODING_DECLARATION, '', 1),\n            )\nn.set_UID(uid)\nn.set_mtime(noteFile.get_mtime())\nn.set_open_URI(noteURI)\nreturn n", "path": "conduit\\modules\\iPodModule\\iPodModule.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "\"\"\"Finds the name of this blog as used in the 'alternate' URL.\nAn alternate URL is in the form 'http://blogName.blogspot.com/'. For an\nentry representing the above example, this method would return 'blogName'.\n\nReturns:\n  The blog's URL name component as a string.\n\"\"\"\n", "func_signal": "def GetBlogName(self):\n", "code": "for link in self.link:\n  if link.rel == 'alternate':\n    return self.blog_name_pattern.match(link.href).group(2)\nreturn None", "path": "conduit\\modules\\GoogleModule\\gdata\\blogger\\__init__.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "'''\nInitialize a new Video track for this db and file.\n'''\n", "func_signal": "def __init__(self, *args, **kwargs):\n", "code": "IPodFileBase.__init__(self, *args, **kwargs)\nVideo.Video.__init__(self, URI = self.get_track_filename())\n\nlog.debug('Video kind selected: %s' % (kwargs['video_kind']))\nself.video_kind = kwargs['video_kind']", "path": "conduit\\modules\\iPodModule\\iPodModule.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "\"\"\"Finds the first link with rel set to WEB_CONTENT_REL\n\nReturns:\n  A gdata.calendar.WebContentLink or none if none of the links had rel \n  equal to WEB_CONTENT_REL\n\"\"\"\n\n", "func_signal": "def GetWebContentLink(self):\n", "code": "for a_link in self.link:\n  if a_link.rel == WEB_CONTENT_LINK_REL:\n    return a_link\nreturn None", "path": "conduit\\modules\\GoogleModule\\gdata\\calendar\\__init__.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "\"\"\"\nAccepts a vfs file. Must be made local.\nI also store a md5 of the photos uri to check for duplicates\n\"\"\"\n", "func_signal": "def put(self, photo, overwrite, LUID=None):\n", "code": "DataProvider.DataSink.put(self, photo, overwrite, LUID)\n\noriginalName = photo.get_filename()\n#Gets the local URI (/foo/bar). If this is a remote file then\n#it is first transferred to the local filesystem\nphotoURI = photo.get_local_uri()\nmimeType = photo.get_mimetype()\ntags = photo.get_tags ()\ncaption = photo.get_caption()\n\nuploadInfo = UploadInfo(photoURI, mimeType, originalName, tags, caption)\n\nif overwrite and LUID:\n    rid = self._replace_photo(LUID, uploadInfo)\nelse:\n    if LUID and self._get_photo_info(LUID):\n        remotePhoto = self.get(LUID)\n        comp = photo.compare(remotePhoto, False)\n        log.debug(\"Compared %s with %s. Result = %s\" % \n                  (photo.get_filename(),remotePhoto.get_filename(),comp))\n\n        if LUID != None and comp == conduit.datatypes.COMPARISON_NEWER:\n            rid = self._replace_photo(LUID, uploadInfo)\n        elif comp == conduit.datatypes.COMPARISON_EQUAL:                    \n            rid = remotePhoto.get_rid()\n        else:\n            raise Exceptions.SynchronizeConflictError(comp, photo, remotePhoto)\n    else:\n        log.debug(\"Uploading Photo URI = %s, Mimetype = %s, Original Name = %s\" %\n                  (photoURI, mimeType, originalName))\n        rid = self._upload_photo (uploadInfo)\n\nif not rid:\n    raise Exceptions.SyncronizeError(\"Error putting/updating photo\")\nelse:\n    return rid", "path": "conduit\\dataproviders\\Image.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "#Check if both the shadow copy and the ipodified version exists\n", "func_signal": "def _note_exists(self, uid):\n", "code": "shadowDir = self._get_shadow_dir()\nreturn os.path.exists(os.path.join(shadowDir,uid)) and os.path.exists(os.path.join(self.dataDir,uid))", "path": "conduit\\modules\\iPodModule\\iPodModule.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "'''\nInitialize a new Audio track for this db and file.\n'''\n", "func_signal": "def __init__(self, *args, **kwargs):\n", "code": "IPodFileBase.__init__(self, *args, **kwargs)\nAudio.Audio.__init__(self, URI = self.get_track_filename())", "path": "conduit\\modules\\iPodModule\\iPodModule.py", "repo_name": "arsfeld/conduit", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 5388}
{"docstring": "\"\"\"Return a Boolean denoting whether the object contains\nprivate components.\"\"\"\n", "func_signal": "def has_private(self):\n", "code": "if hasattr(self, 'x'):\n    return 1\nelse:\n    return 0", "path": "gdata\\Crypto\\PublicKey\\ElGamal.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "# Find the element's tag in this class's list of child members\n", "func_signal": "def _ConvertElementTreeToMember(self, child_tree):\n", "code": "if self.__class__._children.has_key(child_tree.tag):\n  member_name = self.__class__._children[child_tree.tag][0]\n  member_class = self.__class__._children[child_tree.tag][1]\n  # If the class member is supposed to contain a list, make sure the\n  # matching member is set to a list, then append the new member\n  # instance to the list.\n  if isinstance(member_class, list):\n    if getattr(self, member_name) is None:\n      setattr(self, member_name, [])\n    getattr(self, member_name).append(_CreateClassFromElementTree(\n        member_class[0], child_tree))\n  else:\n    setattr(self, member_name, \n            _CreateClassFromElementTree(member_class, child_tree))\nelse:\n  ExtensionContainer._ConvertElementTreeToMember(self, child_tree)", "path": "atom\\__init__.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "\"\"\"Create a new MAC_SSL object.\n\nkey:       key for the keyed hash object.\nmsg:       Initial input for the hash, if provided.\ndigestmod: A module supporting PEP 247. Defaults to the md5 module.\n\"\"\"\n", "func_signal": "def __init__(self, key, msg = None, digestmod = None):\n", "code": "if digestmod is None:\n    import md5\n    digestmod = md5\n\nif key == None: #TREVNEW - for faster copying\n    return      #TREVNEW\n\nself.digestmod = digestmod\nself.outer = digestmod.new()\nself.inner = digestmod.new()\nself.digest_size = digestmod.digest_size\n\nipad = \"\\x36\" * 40\nopad = \"\\x5C\" * 40\n\nself.inner.update(key)\nself.inner.update(ipad)\nself.outer.update(key)\nself.outer.update(opad)\nif msg is not None:\n    self.update(msg)", "path": "gdata\\tlslite\\mathtls.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "\"\"\"\n\nNote: Only for use with classes that have a _tag and _namespace class \nmember. It is in AtomBase so that it can be inherited but it should\nnot be called on instances of AtomBase.\n\n\"\"\"\n", "func_signal": "def _BecomeChildElement(self, tree):\n", "code": "new_child = ElementTree.Element('')\ntree.append(new_child)\nnew_child.tag = '{%s}%s' % (self.__class__._namespace, \n                            self.__class__._tag)\nself._AddMembersToElementTree(new_child)", "path": "atom\\__init__.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "\"\"\"Return a separate copy of this hashing object.\n\nAn update to this copy won't affect the original object.\n\"\"\"\n", "func_signal": "def copy(self):\n", "code": "other = MAC_SSL(None) #TREVNEW - for faster copying\nother.digest_size = self.digest_size #TREVNEW\nother.digestmod = self.digestmod\nother.inner = self.inner.copy()\nother.outer = self.outer.copy()\nreturn other", "path": "gdata\\tlslite\\mathtls.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "\"\"\"Find the first link with rel set to 'self'\n\nReturns:\n  An atom.Link or none if none of the links had rel equal to 'self'\n\"\"\"\n\n", "func_signal": "def GetSelfLink(self):\n", "code": "for a_link in self.link:\n  if a_link.rel == 'self':\n    return a_link\nreturn None", "path": "atom\\__init__.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "\"\"\"Searches child nodes for objects with the desired tag/namespace.\n\nReturns a list of extension elements within this object whose tag\nand/or namespace match those passed in. To find all children in\na particular namespace, specify the namespace but not the tag name.\nIf you specify only the tag, the result list may contain extension\nelements in multiple namespaces.\n\nArgs:\n  tag: str (optional) The desired tag\n  namespace: str (optional) The desired namespace\n\nReturns:\n  A list of elements whose tag and/or namespace match the parameters\n  values\n\"\"\"\n\n", "func_signal": "def FindChildren(self, tag=None, namespace=None):\n", "code": "results = []\n\nif tag and namespace:\n  for element in self.children:\n    if element.tag == tag and element.namespace == namespace:\n      results.append(element)\nelif tag and not namespace:\n  for element in self.children:\n    if element.tag == tag:\n      results.append(element)\nelif namespace and not tag:\n  for element in self.children:\n    if element.namespace == namespace:\n      results.append(element)\nelse:\n  for element in self.children:\n    results.append(element)\n\nreturn results", "path": "atom\\__init__.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "\"\"\"Instantiates the class and populates members according to the tree.\n\nNote: Only use this function with classes that have _namespace and _tag\nclass members.\n\nArgs:\n  target_class: class The class which will be instantiated and populated\n      with the contents of the XML.\n  tree: ElementTree An element tree whose contents will be converted into\n      members of the new target_class instance.\n  namespace: str (optional) The namespace which the XML tree's root node must\n      match. If omitted, the namespace defaults to the _namespace of the \n      target class.\n  tag: str (optional) The tag which the XML tree's root node must match. If\n      omitted, the tag defaults to the _tag class member of the target \n      class.\n\n  Returns:\n    An instance of the target class - or None if the tag and namespace of \n    the XML tree's root node did not match the desired namespace and tag.\n\"\"\"\n", "func_signal": "def _CreateClassFromElementTree(target_class, tree, namespace=None, tag=None):\n", "code": "if namespace is None:\n  namespace = target_class._namespace\nif tag is None:\n  tag = target_class._tag\nif tree.tag == '{%s}%s' % (namespace, tag):\n  target = target_class()\n  target._HarvestElementTree(tree)\n  return target\nelse:\n  return None", "path": "atom\\__init__.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "\"\"\"Creates an instance of the target class from the string contents.\n\nArgs:\n  target_class: class The class which will be instantiated and populated\n      with the contents of the XML. This class must have a _tag and a\n      _namespace class variable.\n  xml_string: str A string which contains valid XML. The root element\n      of the XML string should match the tag and namespace of the desired\n      class.\n  string_encoding: str The character encoding which the xml_string should\n      be converted to before it is interpreted and translated into \n      objects. The default is None in which case the string encoding\n      is not changed.\n\nReturns:\n  An instance of the target class with members assigned according to the\n  contents of the XML - or None if the root XML tag and namespace did not\n  match those of the target class.\n\"\"\"\n", "func_signal": "def CreateClassFromXMLString(target_class, xml_string, string_encoding=None):\n", "code": "encoding = string_encoding or XML_STRING_ENCODING\nif encoding and isinstance(xml_string, unicode):\n  xml_string = xml_string.encode(encoding)\ntree = ElementTree.fromstring(xml_string)\nreturn _CreateClassFromElementTree(target_class, tree)", "path": "atom\\__init__.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "# Fill in the instance members from the contents of the XML tree.\n", "func_signal": "def _HarvestElementTree(self, tree):\n", "code": "for child in tree:\n  self._ConvertElementTreeToMember(child)\nfor attribute, value in tree.attrib.iteritems():\n  self._ConvertElementAttributeToMember(attribute, value)\n# Encode the text string according to the desired encoding type. (UTF-8)\nif tree.text:\n  if MEMBER_STRING_ENCODING is unicode:\n    self.text = tree.text\n  else:\n    self.text = tree.text.encode(MEMBER_STRING_ENCODING)", "path": "atom\\__init__.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "\"\"\"Converts this object into an etree element and adds it as a child node.\n\nAdds self to the ElementTree. This method is required to avoid verbose XML\nwhich constantly redefines the namespace.\n\nArgs:\n  element_tree: ElementTree._Element The element to which this object's XML\n      will be added.\n\"\"\"\n", "func_signal": "def _BecomeChildElement(self, element_tree):\n", "code": "new_element = ElementTree.Element('')\nelement_tree.append(new_element)\nself._TransferToElementTree(new_element)", "path": "atom\\__init__.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "# Convert the members of this class which are XML child nodes. \n# This uses the class's _children dictionary to find the members which\n# should become XML child nodes.\n", "func_signal": "def _AddMembersToElementTree(self, tree):\n", "code": "member_node_names = [values[0] for tag, values in \n                                   self.__class__._children.iteritems()]\nfor member_name in member_node_names:\n  member = getattr(self, member_name)\n  if member is None:\n    pass\n  elif isinstance(member, list):\n    for instance in member:\n      instance._BecomeChildElement(tree)\n  else:\n    member._BecomeChildElement(tree)\n# Convert the members of this class which are XML attributes.\nfor xml_attribute, member_name in self.__class__._attributes.iteritems():\n  member = getattr(self, member_name)\n  if member is not None:\n    if isinstance(member, unicode) or MEMBER_STRING_ENCODING is unicode:\n      tree.attrib[xml_attribute] = member\n    else:\n      tree.attrib[xml_attribute] = member.decode(MEMBER_STRING_ENCODING)\n# Lastly, call the ExtensionContainers's _AddMembersToElementTree to \n# convert any extension attributes.\nExtensionContainer._AddMembersToElementTree(self, tree)", "path": "atom\\__init__.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "\"\"\"An HttpClient which responds to request with stored data.\n\nThe request-response pairs are stored as tuples in a member list named\nrecordings.\n\nThe MockHttpClient can be switched from replay mode to record mode by\nsetting the real_client member to an instance of an HttpClient which will\nmake real HTTP requests and store the server's response in list of \nrecordings.\n\nArgs:\n  headers: dict containing HTTP headers which should be included in all\n      HTTP requests.\n  recordings: The initial recordings to be used for responses. This list\n      contains tuples in the form: (MockRequest, MockResponse)\n  real_client: An HttpClient which will make a real HTTP request. The \n      response will be converted into a MockResponse and stored in \n      recordings.\n\"\"\"\n", "func_signal": "def __init__(self, headers=None, recordings=None, real_client=None):\n", "code": "self.recordings = recordings or []\nself.real_client = real_client\nself.headers = headers or {}", "path": "atom\\mock_http.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "\"\"\"Searches extension elements for child nodes with the desired name.\n\nReturns a list of extension elements within this object whose tag\nand/or namespace match those passed in. To find all extensions in\na particular namespace, specify the namespace but not the tag name.\nIf you specify only the tag, the result list may contain extension\nelements in multiple namespaces.\n\nArgs:\n  tag: str (optional) The desired tag\n  namespace: str (optional) The desired namespace\n\nReturns:\n  A list of elements whose tag and/or namespace match the parameters\n  values\n\"\"\"\n\n", "func_signal": "def FindExtensions(self, tag=None, namespace=None):\n", "code": "results = []\n\nif tag and namespace:\n  for element in self.extension_elements:\n    if element.tag == tag and element.namespace == namespace:\n      results.append(element)\nelif tag and not namespace:\n  for element in self.extension_elements:\n    if element.tag == tag:\n      results.append(element)\nelif namespace and not tag:\n  for element in self.extension_elements:\n    if element.namespace == namespace:\n      results.append(element)\nelse:\n  for element in self.extension_elements:\n    results.append(element)\n\nreturn results", "path": "atom\\__init__.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "\"\"\"Returns a matching MockResponse from the recordings.\n\nIf the real_client is set, the request will be passed along and the \nserver's response will be added to the recordings and also returned. \n\nIf there is no match, a NoRecordingFound error will be raised.\n\"\"\"\n", "func_signal": "def request(self, operation, url, data=None, headers=None):\n", "code": "if self.real_client is None:\n  if isinstance(url, (str, unicode)):\n    url = atom.url.parse_url(url)\n  for recording in self.recordings:\n    if recording[0].operation == operation and recording[0].url == url:\n      return recording[1]\n  raise NoRecordingFound('No recodings found for %s %s' % (\n      operation, url))\nelse:\n  # There is a real HTTP client, so make the request, and record the \n  # response.\n  response = self.real_client.request(operation, url, data=data, \n      headers=headers)\n  # TODO: copy the headers\n  stored_response = MockResponse(body=response, status=response.status,\n      reason=response.reason)\n  self.add_response(stored_response, operation, url, data=data, \n      headers=headers)\n  return stored_response", "path": "atom\\mock_http.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "\"\"\"generate(bits:int, randfunc:callable, progress_func:callable)\n\nGenerate an ElGamal key of length 'bits', using 'randfunc' to get\nrandom data and 'progress_func', if present, to display\nthe progress of the key generation.\n\"\"\"\n", "func_signal": "def generate(bits, randfunc, progress_func=None):\n", "code": "obj=ElGamalobj()\n# Generate prime p\nif progress_func:\n    progress_func('p\\n')\nobj.p=bignum(getPrime(bits, randfunc))\n# Generate random number g\nif progress_func:\n    progress_func('g\\n')\nsize=bits-1-(ord(randfunc(1)) & 63) # g will be from 1--64 bits smaller than p\nif size<1:\n    size=bits-1\nwhile (1):\n    obj.g=bignum(getPrime(size, randfunc))\n    if obj.g < obj.p:\n        break\n    size=(size+1) % bits\n    if size==0:\n        size=4\n# Generate random number x\nif progress_func:\n    progress_func('x\\n')\nwhile (1):\n    size=bits-1-ord(randfunc(1)) # x will be from 1 to 256 bits smaller than p\n    if size>2:\n        break\nwhile (1):\n    obj.x=bignum(getPrime(size, randfunc))\n    if obj.x < obj.p:\n        break\n    size = (size+1) % bits\n    if size==0:\n        size=4\nif progress_func:\n    progress_func('y\\n')\nobj.y = pow(obj.g, obj.x, obj.p)\nreturn obj", "path": "gdata\\Crypto\\PublicKey\\ElGamal.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "\"\"\"\n\nNote, this method is designed to be used only with classes that have a \n_tag and _namespace. It is placed in AtomBase for inheritance but should\nnot be called on this class.\n\n\"\"\"\n", "func_signal": "def _ToElementTree(self):\n", "code": "new_tree = ElementTree.Element('{%s}%s' % (self.__class__._namespace,\n                                           self.__class__._tag))\nself._AddMembersToElementTree(new_tree)\nreturn new_tree", "path": "atom\\__init__.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "\"\"\"Like digest(), but returns a string of hexadecimal digits instead.\n\"\"\"\n", "func_signal": "def hexdigest(self):\n", "code": "return \"\".join([hex(ord(x))[2:].zfill(2)\n                for x in tuple(self.digest())])", "path": "gdata\\tlslite\\mathtls.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "#Split the secret into left and right halves\n", "func_signal": "def PRF(secret, label, seed, length):\n", "code": "S1 = secret[ : int(math.ceil(len(secret)/2.0))]\nS2 = secret[ int(math.floor(len(secret)/2.0)) : ]\n\n#Run the left half through P_MD5 and the right half through P_SHA1\np_md5 = P_hash(md5, S1, concatArrays(stringToBytes(label), seed), length)\np_sha1 = P_hash(sha, S2, concatArrays(stringToBytes(label), seed), length)\n\n#XOR the output values and return the result\nfor x in range(length):\n    p_md5[x] ^= p_sha1[x]\nreturn p_md5", "path": "gdata\\tlslite\\mathtls.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "# Encode the attribute value's string with the desired type Default UTF-8\n", "func_signal": "def _ConvertElementAttributeToMember(self, attribute, value):\n", "code": "if value:\n  if MEMBER_STRING_ENCODING is unicode:\n    self.extension_attributes[attribute] = value\n  else:\n    self.extension_attributes[attribute] = value.encode(\n      MEMBER_STRING_ENCODING)", "path": "atom\\__init__.py", "repo_name": "richardkeen/reboot11-gae", "stars": 3, "license": "None", "language": "python", "size": 600}
{"docstring": "\"\"\"Returns the potential of a thermocouple input.\n\nThis value is returned in millivolts. This value will always be between getPotentialMin and getPotentialMax.\nThis is very accurate, as it is a raw value from the A/D.\nThis is the value that is internally used to calculate temperature in the library.\n\nParameters:\n    index<int>: index of the thermocouple input.\n\nReturns:\n    Potential in millivolts <double>.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached, index is out of range.\n\"\"\"\n", "func_signal": "def getPotential(self, index):\n", "code": "potential = c_double()\nresult = self.dll.CPhidgetTemperatureSensor_getPotential(self.handle, c_int(index), byref(potential))\nif result > 0:\n    raise PhidgetException(result)\nelse:\n    return potential.value", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"The Constructor Method for the LED Class\n\"\"\"\n", "func_signal": "def __init__(self):\n", "code": "Phidget.__init__(self)\n\nself.dll.CPhidgetLED_create(byref(self.handle))", "path": "Phidgets\\Devices\\LED.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Returns the number of thermocouples.\n\nReturns:\n    Number of thermocouple temperature inputs <int>.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached.\n\"\"\"\n", "func_signal": "def getTemperatureInputCount(self):\n", "code": "inputCount = c_int()\nresult = self.dll.CPhidgetTemperatureSensor_getTemperatureInputCount(self.handle, byref(inputCount))\nif result > 0:\n    raise PhidgetException(result)\nelse:\n    return inputCount.value", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Returns the temperature of the ambient sensor.\n\nThis value is returned in degrees celcius but can easily be converted into other units.\nThis value will always be between getAmbientTemperatureMin and getAmbientTemperatureMax.\nThis is the temperature of the board at the thermocouple cold junction.\n\nReturns:\n    Ambient Temperature in derees celcius <double>.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached.\n\"\"\"\n", "func_signal": "def getAmbientTemperature(self):\n", "code": "ambient = c_double()\nresult = self.dll.CPhidgetTemperatureSensor_getAmbientTemperature(self.handle, byref(ambient))\nif result > 0:\n    raise PhidgetException(result)\nelse:\n    return ambient.value", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Sets the thermocouple type for an input.\n\nThe Phidget Temperature Sensor board can be used with K, E, J and T-Type Thermocouples.\nSupport for other thermocouple types, and voltage sources other then thermocouples in the valid range\n(between getPotentialMin and getPotentialMax) can be achieved using getPotential.\n\nThe possible values for type are PHIDGET_TEMPERATURE_SENSOR_K_TYPE, PHIDGET_TEMPERATURE_SENSOR_J_TYPE,\nPHIDGET_TEMPERATURE_SENSOR_E_TYPE and PHIDGET_TEMPERATURE_SENSOR_T_TYPE.\n\nBy default, type is set to PHIDGET_TEMPERATURE_SENSOR_K_TYPE.\n\n(See ThermocoupleType class for values associated with these names)\n\nParameters:\n    index<int>: index of the thermocouple input.\n    value<int>: The Thermocouple Type.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached, index or value are out of range.\n\"\"\"\n", "func_signal": "def setThermocoupleType(self, index, value):\n", "code": "result = self.dll.CPhidgetTemperatureSensor_setThermocoupleType(self.handle, c_int(index), c_int(value))\nif result > 0:\n    raise PhidgetException(result)", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Returns the minimum temperature that will be returned by the ambient sensor.\n\nReturns:\n    Minimum Ambient Temperature in derees celcius <double>.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached.\n\"\"\"\n", "func_signal": "def getAmbientTemperatureMin(self):\n", "code": "ambientMin = c_double()\nresult = self.dll.CPhidgetTemperatureSensor_getAmbientTemperatureMin(self.handle, byref(ambientMin))\nif result > 0:\n    raise PhidgetException(result)\nelse:\n    return ambientMin.value", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Sets the brightness of an LED.\n\nValid values are 0-100, with 0 being off and 100 being the brightest.\nThis 0-100 value is converted internally to a 6-bit value (0-63) so only 64 levels of brightness are actually possible.\n\nParameters:\n    index<int>: index of the Discrete LED.\n    value<int>: brightness value of the Discrete LED.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached, or if the index or brightness value are out of range.\n\"\"\"\n", "func_signal": "def setDiscreteLED(self, index, value):\n", "code": "result = self.dll.CPhidgetLED_setDiscreteLED(self.handle,  c_int(index), c_int(value))\nif result > 0:\n    raise PhidgetException(result)", "path": "Phidgets\\Devices\\LED.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Returns the minimum potential that will be returned by a thermocouple input.\n\nParameters:\n    index<int>: index of the thermocouple input.\n\nReturns:\n    Minimum Potential in millivolts <double>.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached, index is out of range.\n\"\"\"\n", "func_signal": "def getPotentialMin(self, index):\n", "code": "potentialMin = c_double()\nresult = self.dll.CPhidgetTemperatureSensor_getPotentialMin(self.handle, c_int(index), byref(potentialMin))\nif result > 0:\n    raise PhidgetException(result)\nelse:\n    return potentialMin.value", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Returns the maximum temperature that will be returned by the ambient sensor.\n\nReturns:\n    Maximum Ambient Temperature in derees celcius <double>.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached.\n\"\"\"\n", "func_signal": "def getAmbientTemperatureMax(self):\n", "code": "ambientMax = c_double()\nresult = self.dll.CPhidgetTemperatureSensor_getAmbientTemperatureMax(self.handle, byref(ambientMax))\nif result > 0:\n    raise PhidgetException(result)\nelse:\n    return ambientMax.value", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Returns the temperature of a thermocouple.\n\nThis value is returned in degrees celcius but can easily be converted into other units.\nThis value will always be between getTemperatureMin and getTemperatureMax.\nThe accuracy depends on the thermocouple used. The board is calibrated during manufacture.\n\nParameters:\n    index<int>: index of the thermocouple input.\n\nReturns:\n    Temperature in degrees celcius <double>.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached, index is out of range.\n\"\"\"\n", "func_signal": "def getTemperature(self, index):\n", "code": "temperature = c_double()\nresult = self.dll.CPhidgetTemperatureSensor_getTemperature(self.handle, c_int(index), byref(temperature))\nif result > 0:\n    raise PhidgetException(result)\nelse:\n    return temperature.value", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Sets the Temperature Change Event Handler.\n\nThe temperature change handler is a method that will be called when the temperature has changed by at least the Trigger that has been set.\n\nParameters:\n    temperatureChangeHandler: hook to the temperatureChangeHandler callback function.\n\nExceptions:\n    PhidgetException\n\"\"\"\n", "func_signal": "def setOnTemperatureChangeHandler(self, temperatureChangeHandler):\n", "code": "self.__tempChange = temperatureChangeHandler\nself.__onTemperatureChange = self.__TEMPCHANGEHANDLER(self.__nativeTemperatureChangeEvent)\nresult = self.dll.CPhidgetTemperatureSensor_set_OnTemperatureChange_Handler(self.handle, self.__onTemperatureChange, None)\nif result > 0:\n    raise PhidgetException(result)", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Returns the minimum temperature that will be returned by a thermocouple input.\n\nThis value depends on the thermocouple type.\n\nParameters:\n    index<int>: index of the thermocouple input.\n\nReturns:\n    Minimum temperature in degrees celcius <double>.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached, index is out of range.\n\"\"\"\n", "func_signal": "def getTemperatureMin(self, index):\n", "code": "temperatureMin = c_double()\nresult = self.dll.CPhidgetTemperatureSensor_getTemperatureMin(self.handle, c_int(index), byref(temperatureMin))\nif result > 0:\n    raise PhidgetException(result)\nelse:\n    return temperatureMin.value", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Returns the maximum potential that will be returned by a thermocouple input.\n\nParameters:\n    index<int>: index of the thermocouple input.\n\nReturns:\n    Maximum Potential in millivolts <double>.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached, index is out of range.\n\"\"\"\n", "func_signal": "def getPotentialMax(self, index):\n", "code": "potentialMax = c_double()\nresult = self.dll.CPhidgetTemperatureSensor_getPotentialMax(self.handle, c_int(index), byref(potentialMax))\nif result > 0:\n    raise PhidgetException(result)\nelse:\n    return potentialMax.value", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Returns the change trigger for an input.\n\nThis is the amount by which the sensed temperature must change between TemperatureChangeEvents.\nBy default this is set to 0.5.\n\nParameters:\n    index<int>: index of the thermocouple input.\n\nReturns:\n    The temperature change trigger value <double>.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached, index is out of range.\n\"\"\"\n", "func_signal": "def getTemperatureChangeTrigger(self, index):\n", "code": "sensitivity = c_double()\nresult = self.dll.CPhidgetTemperatureSensor_getTemperatureChangeTrigger(self.handle, c_int(index), byref(sensitivity))\nif result > 0:\n    raise PhidgetException(result)\nelse:\n    return sensitivity.value", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Returns the maximum temperature that will be returned by a thermocouple input.\n\nThis value depends on the thermocouple type.\n\nParameters:\n    index<int>: index of the thermocouple input.\n\nReturns:\n    Maximum temperature in degrees celcius <double>.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached, index is out of range.\n\"\"\"\n", "func_signal": "def getTemperatureMax(self, index):\n", "code": "temperatureMax = c_double()\nresult = self.dll.CPhidgetTemperatureSensor_getTemperatureMax(self.handle, c_int(index), byref(temperatureMax))\nif result > 0:\n    raise PhidgetException(result)\nelse:\n    return temperatureMax.value", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Returns the number of LEDs that this board can drive.\n\nThis may not correspond to the actual number of LEDs attached.\n\nReturns:\n    The number of available LEDs <int>.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached.\n\"\"\"\n", "func_signal": "def getLEDCount(self):\n", "code": "LEDCount = c_int()\nresult = self.dll.CPhidgetLED_getLEDCount(self.handle, byref(LEDCount))\nif result > 0:\n    raise PhidgetException(result)\nelse:\n    return LEDCount.value", "path": "Phidgets\\Devices\\LED.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Sets the change trigger for an input.\n\nThis is the amount by which the sensed temperature must change between TemperatureChangeEvents.\nBy default this is set to 0.5.\n\nParameters:\n    index<int>: index of the thermocouple input.\n    value<double>: temperature change trigger value.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached, or index or value are out of range.\n\"\"\"\n", "func_signal": "def setTemperatureChangeTrigger(self, index, value):\n", "code": "result = self.dll.CPhidgetTemperatureSensor_setTemperatureChangeTrigger(self.handle, c_int(index), c_double(value))\nif result > 0:\n    raise PhidgetException(result)", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"The Constructor Method for the TemperatureSensor Class\n\"\"\"\n", "func_signal": "def __init__(self):\n", "code": "Phidget.__init__(self)\n\nself.__tempChange = None\n\nself.__onTemperatureChange = None\n\nself.dll.CPhidgetTemperatureSensor_create(byref(self.handle))\n\nif sys.platform == 'win32':\n    self.__TEMPCHANGEHANDLER = WINFUNCTYPE(c_int, c_void_p, c_void_p, c_int, c_double)\nelif sys.platform == 'darwin' or sys.platform == 'linux2':\n    self.__TEMPCHANGEHANDLER = CFUNCTYPE(c_int, c_void_p, c_void_p, c_int, c_double)", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Returns the brightness value of an LED.\n\nThis value ranges from 0-100.\n\nParameters:\n    index<int>: index of the Discrete LED.\n\nReturns:\n    Brightness of the LED <int>.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached, or if the index is out of range.\n\"\"\"\n", "func_signal": "def getDiscreteLED(self, index):\n", "code": "ledVal = c_int()\nresult = self.dll.CPhidgetLED_getDiscreteLED(self.handle, c_int(index), byref(ledVal))\nif result > 0:\n    raise PhidgetException(result)\nelse:\n    return ledVal.value", "path": "Phidgets\\Devices\\LED.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Returns the thermocouple type for an input.\n\nThe possible values for type are PHIDGET_TEMPERATURE_SENSOR_K_TYPE,\nPHIDGET_TEMPERATURE_SENSOR_J_TYPE, PHIDGET_TEMPERATURE_SENSOR_E_TYPE and\nPHIDGET_TEMPERATURE_SENSOR_T_TYPE.\n\n(See ThermocoupleType class for values associated with these names)\n\nParameters:\n    index<int>: index of the thermocouple input.\n\nReturns:\n    The Thermocouple Type <int>.\n\nExceptions:\n    PhidgetException: If this Phidget is not opened and attached, index is out of range.\n\"\"\"\n", "func_signal": "def getThermocoupleType(self, index):\n", "code": "thermocoupleType = c_int()\nresult = self.dll.CPhidgetTemperatureSensor_getThermocoupleType(self.handle, c_int(index), byref(thermocoupleType))\nif result > 0:\n    raise PhidgetException(result)\nelse:\n    return thermocoupleType.value", "path": "Phidgets\\Devices\\TemperatureSensor.py", "repo_name": "cmkimerer/mrpickles", "stars": 2, "license": "None", "language": "python", "size": 152}
{"docstring": "\"\"\"Creates a database.\n\"\"\"\n", "func_signal": "def __init__(self, db_module, keywords):\n", "code": "self.db_module = db_module\nself.keywords = keywords\n\nself._ctx = threadeddict()\n# flag to enable/disable printing queries\nself.printing = False\nself.supports_multiple_insert = False\n\ntry:\n    import DBUtils\n    # enable pooling if DBUtils module is available.\n    self.has_pooling = True\nexcept ImportError:\n    self.has_pooling = False\n    \n# Pooling can be disabled by passing pooling=False in the keywords.\nself.has_pooling = self.has_pooling and self.keywords.pop('pooling', True)", "path": "web\\db.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"\nMakes url by concatinating web.ctx.homepath and path and the \nquery string created using the arguments.\n\"\"\"\n", "func_signal": "def url(path=None, **kw):\n", "code": "if path is None:\n    path = web.ctx.path\nif path.startswith(\"/\"):\n    out = web.ctx.homepath + path\nelse:\n    out = path\n\nif kw:\n    out += '?' + urlencode(kw)\n\nreturn out", "path": "web\\http.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "# do db rollback and release the connection if pooling is enabled.\n", "func_signal": "def rollback():\n", "code": "ctx.db.rollback()\nif self.has_pooling:\n    self._unload_context(self._ctx)", "path": "web\\db.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"\nReturns a `storage` object with all the cookies in it.\nSee `storify` for how `requireds` and `defaults` work.\n\"\"\"\n", "func_signal": "def cookies(*requireds, **defaults):\n", "code": "cookie = Cookie.SimpleCookie()\ncookie.load(ctx.env.get('HTTP_COOKIE', ''))\ntry:\n    d = storify(cookie, *requireds, **defaults)\n    for k, v in d.items():\n        d[k] = urllib.unquote(v)\n    return d\nexcept KeyError:\n    badrequest()\n    raise StopIteration", "path": "web\\webapi.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "# do db commit and release the connection if pooling is enabled.            \n", "func_signal": "def commit(unload=True):\n", "code": "ctx.db.commit()\nif unload and self.has_pooling:\n    self._unload_context(self._ctx)", "path": "web\\db.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"Sets a cookie.\"\"\"\n", "func_signal": "def setcookie(name, value, expires=\"\", domain=None, secure=False):\n", "code": "if expires < 0: \n    expires = -1000000000 \nkargs = {'expires': expires, 'path':'/'}\nif domain: \n    kargs['domain'] = domain\nif secure:\n    kargs['secure'] = secure\n# @@ should we limit cookies to a different path?\ncookie = Cookie.SimpleCookie()\ncookie[name] = urllib.quote(utf8(value))\nfor key, val in kargs.iteritems(): \n    cookie[name][key] = val\nheader('Set-Cookie', cookie.items()[0][1].OutputString())", "path": "web\\webapi.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "# test in/out equivalence and parsing\n", "func_signal": "def test_parse(self):\n", "code": "res = S.loads(JSON)\nout = S.dumps(res)\nself.assertEquals(res, S.loads(out))", "path": "simplejson\\tests\\test_pass3.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"\nSorry, this function is really difficult to explain.\nMaybe some other time.\n\"\"\"\n", "func_signal": "def prefixurl(base=''):\n", "code": "url = web.ctx.path.lstrip('/')\nfor i in xrange(url.count('/')): \n    base += '../'\nif not base: \n    base = './'\nreturn base", "path": "web\\http.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"\nReturns a `status` redirect to the new URL. \n`url` is joined with the base URL so that things like \n`redirect(\"about\") will work properly.\n\"\"\"\n", "func_signal": "def __init__(self, url, status='301 Moved Permanently', absolute=False):\n", "code": "newloc = urlparse.urljoin(ctx.path, url)\n\nif newloc.startswith('/'):\n    if absolute:\n        home = ctx.realhome\n    else:\n        home = ctx.home\n    newloc = home + newloc\n\nheaders = {\n    'Content-Type': 'text/html',\n    'Location': newloc\n}\nHTTPError.__init__(self, status, headers, \"\")", "path": "web\\webapi.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"\nConverts a standard CGI-style string response into `header` and \n`output` calls.\n\"\"\"\n", "func_signal": "def write(cgi_response):\n", "code": "cgi_response = str(cgi_response)\ncgi_response.replace('\\r\\n', '\\n')\nhead, body = cgi_response.split('\\n\\n', 1)\nlines = head.split('\\n')\n\nfor line in lines:\n    if line.isspace(): \n        continue\n    hdr, value = line.split(\":\", 1)\n    value = value.strip()\n    if hdr.lower() == \"status\": \n        web.ctx.status = value\n    else: \n        web.header(hdr, value)\n\nweb.output(body)", "path": "web\\http.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"Creates a new SQLQuery.\n\n    >>> SQLQuery(\"x\")\n    <sql: 'x'>\n    >>> q = SQLQuery(['SELECT * FROM ', 'test', ' WHERE x=', SQLParam(1)])\n    >>> q\n    <sql: 'SELECT * FROM test WHERE x=1'>\n    >>> q.query(), q.values()\n    ('SELECT * FROM test WHERE x=%s', [1])\n    >>> SQLQuery(SQLParam(1))\n    <sql: '1'>\n\"\"\"\n", "func_signal": "def __init__(self, items=[]):\n", "code": "if isinstance(items, list):\n    self.items = items\nelif isinstance(items, SQLParam):\n    self.items = [items]\nelif isinstance(items, SQLQuery):\n    self.items = list(items.items)\nelse:\n    self.items = [str(items)]\n    \n# Take care of SQLLiterals\nfor i, item in enumerate(self.items):\n    if isinstance(item, SQLParam) and isinstance(item.value, SQLLiteral):\n        self.items[i] = item.value.v", "path": "web\\db.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"Returns HTTPError with '404 Not Found' error from the active application.\n\"\"\"\n", "func_signal": "def NotFound(message=None):\n", "code": "if message:\n    return _NotFound(message)\nelif ctx.get('app_stack'):\n    return ctx.app_stack[-1].notfound()\nelse:\n    return _NotFound()", "path": "web\\webapi.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"Returns HTTPError with '500 internal error' error from the active application.\n\"\"\"\n", "func_signal": "def InternalError(message=None):\n", "code": "if message:\n    return _InternalError(message)\nelif ctx.get('app_stack'):\n    return ctx.app_stack[-1].internalerror()\nelse:\n    return _InternalError()", "path": "web\\webapi.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"\nPrints a prettyprinted version of `args` to stderr.\n\"\"\"\n", "func_signal": "def debug(*args):\n", "code": "try: \n    out = ctx.environ['wsgi.errors']\nexcept: \n    out = sys.stderr\nfor arg in args:\n    print >> out, pprint.pformat(arg)\nreturn ''", "path": "web\\webapi.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"\nImagine you're at `/foo?a=1&b=2`. Then `changequery(a=3)` will return\n`/foo?a=3&b=2` -- the same URL but with the arguments you requested\nchanged.\n\"\"\"\n", "func_signal": "def changequery(query=None, **kw):\n", "code": "if query is None:\n    query = web.input(_method='get')\nfor k, v in kw.iteritems():\n    if v is None:\n        query.pop(k, None)\n    else:\n        query[k] = v\nout = web.ctx.path\nif query:\n    out += '?' + urlencode(query)\nreturn out", "path": "web\\http.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "# test in/out equivalence and parsing\n", "func_signal": "def test_parse(self):\n", "code": "res = S.loads(JSON)\nout = S.dumps(res)\nself.assertEquals(res, S.loads(out))\ntry:\n    S.dumps(res, allow_nan=False)\nexcept ValueError:\n    pass\nelse:\n    self.fail(\"23456789012E666 should be out of range\")", "path": "simplejson\\tests\\test_pass1.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"\n`left is a SQL clause like `tablename.arg = ` \nand `lst` is a list of values. Returns a reparam-style\npair featuring the SQL that ORs together the clause\nfor each item in the lst.\n\n    >>> sqlors('foo = ', [])\n    <sql: '1=2'>\n    >>> sqlors('foo = ', [1])\n    <sql: 'foo = 1'>\n    >>> sqlors('foo = ', 1)\n    <sql: 'foo = 1'>\n    >>> sqlors('foo = ', [1,2,3])\n    <sql: '(foo = 1 OR foo = 2 OR foo = 3 OR 1=2)'>\n\"\"\"\n", "func_signal": "def sqlors(left, lst):\n", "code": "if isinstance(lst, iters):\n    lst = list(lst)\n    ln = len(lst)\n    if ln == 0:\n        return SQLQuery(\"1=2\")\n    if ln == 1:\n        lst = lst[0]\n\nif isinstance(lst, iters):\n    return SQLQuery(['('] + \n      sum([[left, sqlparam(x), ' OR '] for x in lst], []) +\n      ['1=2)']\n    )\nelse:\n    return left + sqlparam(lst)", "path": "web\\db.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"\nReturns the query part of the sql query.\n    >>> q = SQLQuery([\"SELECT * FROM test WHERE name=\", SQLParam('joe')])\n    >>> q.query()\n    'SELECT * FROM test WHERE name=%s'\n    >>> q.query(paramstyle='qmark')\n    'SELECT * FROM test WHERE name=?'\n\"\"\"\n", "func_signal": "def query(self, paramstyle=None):\n", "code": "s = ''\nfor x in self.items:\n    if isinstance(x, SQLParam):\n        x = x.get_marker(paramstyle)\n    s += x\nreturn s", "path": "web\\db.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"\nSame as urllib.urlencode, but supports unicode strings.\n\n    >>> urlencode({'text':'foo bar'})\n    'text=foo+bar'\n\"\"\"\n", "func_signal": "def urlencode(query):\n", "code": "query = dict([(k, utils.utf8(v)) for k, v in query.items()])\nreturn urllib.urlencode(query)", "path": "web\\http.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"Returns the data sent with the request.\"\"\"\n", "func_signal": "def data():\n", "code": "if 'data' not in ctx:\n    cl = intget(ctx.env.get('CONTENT_LENGTH'), 0)\n    ctx.data = ctx.env['wsgi.input'].read(cl)\nreturn ctx.data", "path": "web\\webapi.py", "repo_name": "tzuryby/weblishr", "stars": 2, "license": "None", "language": "python", "size": 752}
{"docstring": "\"\"\"Returns the query or POST argument with the given name.\n\nWe parse the query string and POST payload lazily, so this will be a\nslower operation on the first call.\n\nArgs:\n  argument_name: the name of the query or POST argument\n  default_value: the value to return if the given argument is not present\n  allow_multiple: return a list of values with the given name (deprecated)\n\nReturns:\n  If allow_multiple is False (which it is by default), we return the first\n  value with the given name given in the request. If it is True, we always\n  return an list.\n\"\"\"\n", "func_signal": "def get(self, argument_name, default_value='', allow_multiple=False):\n", "code": "param_value = self.get_all(argument_name)\nif allow_multiple:\n  return param_value\nelse:\n  if len(param_value) > 0:\n    return param_value[0]\n  else:\n    return default_value", "path": "google\\appengine\\ext\\webapp\\__init__.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"\nA simple method for encoding multipart POST data from a dictionary of\nform values.\n\nThe key will be used as the form data name; the value will be transmitted\nas content. If the value is a file, the contents of the file will be sent\nas an application/octet-stream; otherwise, str(value) will be sent.\n\"\"\"\n", "func_signal": "def encode_multipart(boundary, data):\n", "code": "lines = []\nfor (key, value) in data.items():\n    if isinstance(value, file):\n        lines.extend([\n            '--' + boundary,\n            'Content-Disposition: form-data; name=\"%s\"' % key,\n            '',\n            '--' + boundary,\n            'Content-Disposition: form-data; name=\"%s_file\"; filename=\"%s\"' % (key, value.name),\n            'Content-Type: application/octet-stream',\n            '',\n            value.read()\n        ])\n    elif hasattr(value, '__iter__'): \n        for item in value:\n            lines.extend([ \n                '--' + boundary, \n                'Content-Disposition: form-data; name=\"%s\"' % key, \n                '', \n                str(item) \n            ])\n    else:\n        lines.extend([\n            '--' + boundary,\n            'Content-Disposition: form-data; name=\"%s\"' % key,\n            '',\n            str(value)\n        ])\n\nlines.extend([\n    '--' + boundary + '--',\n    '',\n])\nreturn '\\r\\n'.join(lines)", "path": "lib\\django\\django\\test\\client.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"Return a list of SQL statements required to remove all data from\nall tables in the database (without actually removing the tables\nthemselves) and put the database in an empty 'initial' state\n\"\"\"\n# Return a list of 'TRUNCATE x;', 'TRUNCATE y;', 'TRUNCATE z;'... style SQL statements\n# TODO - SQL not actually tested against Oracle yet!\n# TODO - autoincrement indices reset required? See other get_sql_flush() implementations\n", "func_signal": "def get_sql_flush(style, tables, sequences):\n", "code": "sql = ['%s %s;' % \\\n        (style.SQL_KEYWORD('TRUNCATE'),\n         style.SQL_FIELD(quote_name(table))\n         )  for table in tables]", "path": "lib\\django\\django\\db\\backends\\oracle\\base.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"Initializes the maps needed for mapping urls to handlers and handlers\nto urls.\n\nArgs:\n  handler_tuples: list of (URI, RequestHandler) pairs.\n\"\"\"\n\n", "func_signal": "def _init_url_mappings(self, handler_tuples):\n", "code": "handler_map = {}\npattern_map = {}\nurl_mapping = []\n\nfor regexp, handler in handler_tuples:\n\n  handler_map[handler.__name__] = handler\n\n  if not regexp.startswith('^'):\n    regexp = '^' + regexp\n  if not regexp.endswith('$'):\n    regexp += '$'\n\n  compiled = re.compile(regexp)\n  url_mapping.append((compiled, handler))\n\n  num_groups = len(RE_FIND_GROUPS.findall(regexp))\n  handler_patterns = pattern_map.setdefault(handler, [])\n  handler_patterns.append((compiled, num_groups))\n\nself._handler_map = handler_map\nself._pattern_map = pattern_map\nself._url_mapping = url_mapping", "path": "google\\appengine\\ext\\webapp\\__init__.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"Returns the url for the given handler.\n\nThe default implementation uses the patterns passed to the active\nWSGIApplication and the django urlresolvers module to create a url.\nHowever, it is different from urlresolvers.reverse() in the following ways:\n  - It does not try to resolve handlers via module loading\n  - It does not support named arguments\n  - It performs some post-prosessing on the url to remove some regex\n    operators that urlresolvers.reverse_helper() seems to miss.\n  - It will try to fill in the left-most missing arguments with the args\n    used in the active request.\n\nArgs:\n  args: Parameters for the url pattern's groups.\n  kwargs: Optionally contains 'implicit_args' that can either be a boolean\n          or a tuple. When it is True, it will use the arguments to the\n          active request as implicit arguments. When it is False (default),\n          it will not use any implicit arguments. When it is a tuple, it\n          will use the tuple as the implicit arguments.\n          the left-most args if some are missing from args.\n\nReturns:\n  The url for this handler/args combination.\n\nRaises:\n  NoUrlFoundError: No url pattern for this handler has the same\n    number of args that were passed in.\n\"\"\"\n\n", "func_signal": "def get_url(cls, *args, **kargs):\n", "code": "app = WSGIApplication.active_instance\npattern_map = app._pattern_map\n\nimplicit_args = kargs.get('implicit_args', ())\nif implicit_args == True:\n  implicit_args = app.current_request_args\n\nmin_params = len(args)\n\nurlresolvers = None\n\nfor pattern_tuple in pattern_map.get(cls, ()):\n  num_params_in_pattern = pattern_tuple[1]\n  if num_params_in_pattern < min_params:\n    continue\n\n  if urlresolvers is None:\n    from django.core import urlresolvers\n\n  try:\n    num_implicit_args = max(0, num_params_in_pattern - len(args))\n    merged_args = implicit_args[:num_implicit_args] + args\n    url = urlresolvers.reverse_helper(pattern_tuple[0], *merged_args)\n    url = url.replace('\\\\', '')\n    url = url.replace('?', '')\n    return url\n  except urlresolvers.NoReverseMatch:\n    continue\n\nlogging.warning('get_url failed for Handler name: %r, Args: %r',\n                cls.__name__, args)\nraise NoUrlFoundError", "path": "google\\appengine\\ext\\webapp\\__init__.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"Called if this handler throws an exception during execution.\n\nThe default behavior is to call self.error(500) and print a stack trace\nif debug_mode is True.\n\nArgs:\n  exception: the exception that was thrown\n  debug_mode: True if the web application is running in debug mode\n\"\"\"\n", "func_signal": "def handle_exception(self, exception, debug_mode):\n", "code": "self.error(500)\nlogging.exception(exception)\nif debug_mode:\n  lines = ''.join(traceback.format_exception(*sys.exc_info()))\n  self.response.clear()\n  self.response.out.write('<pre>%s</pre>' % (cgi.escape(lines, quote=True)))", "path": "google\\appengine\\ext\\webapp\\__init__.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"Constructs a Request object from a WSGI environment.\n\nIf the charset isn't specified in the Content-Type header, defaults\nto UTF-8.\n\nArgs:\n  environ: A WSGI-compliant environment dictionary.\n\"\"\"\n", "func_signal": "def __init__(self, environ):\n", "code": "match = _CHARSET_RE.search(environ.get('CONTENT_TYPE', ''))\nif match:\n  charset = match.group(1).lower()\nelse:\n  charset = 'utf-8'\n\nwebob.Request.__init__(self, environ, charset=charset,\n                       unicode_errors= 'ignore', decode_param_names=True)", "path": "google\\appengine\\ext\\webapp\\__init__.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"\nYield match, end_idx for each match\n\"\"\"\n", "func_signal": "def iterscan(self, string, idx=0, context=None):\n", "code": "match = self.scanner.scanner(string, idx).match\nactions = self.actions\nlastend = idx\nend = len(string)\nwhile True:\n    m = match()\n    if m is None:\n        break\n    matchbegin, matchend = m.span()\n    if lastend == matchend:\n        break\n    action = actions[m.lastindex]\n    if action is not None:\n        rval, next_pos = action(m, context)\n        if next_pos is not None and next_pos != matchend:\n            # \"fast forward\" the scanner\n            matchend = next_pos\n            match = self.scanner.scanner(string, matchend).match\n        yield rval, matchend\n    lastend = matchend", "path": "lib\\django\\django\\utils\\simplejson\\scanner.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"\nReturns the 1-based index of the last object on the given page,\nrelative to total objects found (hits).\n\"\"\"\n", "func_signal": "def last_on_page(self, page_number):\n", "code": "page_number = self.validate_page_number(page_number)\npage_number += 1   # 1-base\nif page_number == self.pages:\n    return self.hits\nreturn page_number * self.num_per_page", "path": "lib\\django\\django\\core\\paginator.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"\nDeserialize simple Python objects back into Django ORM instances.\n\nIt's expected that you pass the Python objects themselves (instead of a\nstream or a string) to the constructor\n\"\"\"\n", "func_signal": "def Deserializer(object_list, **options):\n", "code": "models.get_apps()\nfor d in object_list:\n    # Look up the model and starting build a dict of data for it.\n    Model = _get_model(d[\"model\"])\n    data = {Model._meta.pk.attname : Model._meta.pk.to_python(d[\"pk\"])}\n    m2m_data = {}\n    \n    # Handle each field\n    for (field_name, field_value) in d[\"fields\"].iteritems():\n        if isinstance(field_value, unicode):\n            field_value = field_value.encode(options.get(\"encoding\", settings.DEFAULT_CHARSET))\n            \n        field = Model._meta.get_field(field_name)\n        \n        # Handle M2M relations\n        if field.rel and isinstance(field.rel, models.ManyToManyRel):\n            pks = []\n            m2m_convert = field.rel.to._meta.pk.to_python\n            for pk in field_value:\n                if isinstance(pk, unicode):\n                    pks.append(m2m_convert(pk.encode(options.get(\"encoding\", settings.DEFAULT_CHARSET))))\n                else:\n                    pks.append(m2m_convert(pk))\n            m2m_data[field.name] = pks\n            \n        # Handle FK fields\n        elif field.rel and isinstance(field.rel, models.ManyToOneRel):\n            data[field.attname] = field.rel.to._meta.pk.to_python(field_value)\n                \n        # Handle all other fields\n        else:\n            data[field.name] = field.to_python(field_value)\n            \n    yield base.DeserializedObject(Model(**data), m2m_data)", "path": "lib\\django\\django\\core\\serializers\\python.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"@brief Unpack the runlength encoded table data.\n\nTerence implemented packed table initializers, because Java has a\nsize restriction on .class files and the lookup tables can grow\npretty large. The generated JavaLexer.java of the Java.g example\nwould be about 15MB with uncompressed array initializers.\n\nPython does not have any size restrictions, but the compilation of\nsuch large source files seems to be pretty memory hungry. The memory\nconsumption of the python process grew to >1.5GB when importing a\n15MB lexer, eating all my swap space and I was to impacient to see,\nif it could finish at all. With packed initializers that are unpacked\nat import time of the lexer module, everything works like a charm.\n\n\"\"\"\n\n", "func_signal": "def unpack(cls, string):\n", "code": "ret = []\nfor i in range(len(string) / 2):\n    (n, v) = ord(string[i*2]), ord(string[i*2+1])\n\n    # Is there a bitwise operation to do this?\n    if v == 0xFFFF:\n        v = -1\n\n    ret += [v] * n\n\nreturn ret", "path": "lib\\antlr3\\antlr3\\dfa.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"\nClear out the content-type cache. This needs to happen during database\nflushes to prevent caching of \"stale\" content type IDs (see\ndjango.contrib.contenttypes.management.create_contenttypes for where\nthis gets called).\n\"\"\"\n", "func_signal": "def clear_cache(self):\n", "code": "global CONTENT_TYPE_CACHE\nCONTENT_TYPE_CACHE = {}", "path": "lib\\django\\django\\contrib\\contenttypes\\models.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"\nA specialized sequence of GET and POST to log into a view that\nis protected by a @login_required access decorator.\n\npath should be the URL of the page that is login protected.\n\nReturns the response from GETting the requested URL after\nlogin is complete. Returns False if login process failed.\n\"\"\"\n# First, GET the page that is login protected.\n# This page will redirect to the login page.\n", "func_signal": "def login(self, path, username, password, **extra):\n", "code": "response = self.get(path)\nif response.status_code != 302:\n    return False\n\n_, _, login_path, _, data, _= urlparse(response['Location'])\nnext = data.split('=')[1]\n\n# Second, GET the login page; required to set up cookies\nresponse = self.get(login_path, **extra)\nif response.status_code != 200:\n    return False\n\n# Last, POST the login data.\nform_data = {\n    'username': username,\n    'password': password,\n    'next' : next,\n}\nresponse = self.post(login_path, data=form_data, **extra)\n\n# Login page should 302 redirect to the originally requested page\nif (response.status_code != 302 or \n        urlparse(response['Location'])[2] != path):\n    return False\n\n# Since we are logged in, request the actual page again\nreturn self.get(path)", "path": "lib\\django\\django\\test\\client.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"Clears the response output stream and sets the given HTTP error code.\n\nArgs:\n  code: the HTTP status error code (e.g., 501)\n\"\"\"\n", "func_signal": "def error(self, code):\n", "code": "self.response.set_status(code)\nself.response.clear()", "path": "google\\appengine\\ext\\webapp\\__init__.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"\nHelper to look up a model from an \"app_label.module_name\" string.\n\"\"\"\n", "func_signal": "def _get_model(model_identifier):\n", "code": "try:\n    Model = models.get_model(*model_identifier.split(\".\"))\nexcept TypeError:\n    Model = None\nif Model is None:\n    raise base.DeserializationError(\"Invalid model identifier: '%s'\" % model_identifier)\nreturn Model", "path": "lib\\django\\django\\core\\serializers\\python.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"Waits on the API call associated with this RPC.\"\"\"\n", "func_signal": "def Wait(self):\n", "code": "assert self.__state is not RPC.IDLE, ('RPC for %s.%s has not been started' %\n                                      (self.package, self.call))\nrpc_completed = self._WaitImpl()\n\nassert rpc_completed, ('RPC for %s.%s was not completed, and no other ' +\n                       'exception was raised ' % (self.package, self.call))", "path": "google\\appengine\\api\\apiproxy_rpc.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "# replace occurances of \"%s\" with \":arg\" - Oracle requires colons for parameter placeholders.\n", "func_signal": "def convert_arguments(self, query, num_params):\n", "code": "args = [':arg' for i in range(num_params)]\nreturn query % tuple(args)", "path": "lib\\django\\django\\db\\backends\\oracle\\base.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"Returns the default HTTP status message for the given code.\n\nArgs:\n  code: the HTTP code for which we want a message\n\"\"\"\n", "func_signal": "def http_status_message(code):\n", "code": "if not Response.__HTTP_STATUS_MESSAGES.has_key(code):\n  raise Error('Invalid HTTP status code: %d' % code)\nreturn Response.__HTTP_STATUS_MESSAGES[code]", "path": "google\\appengine\\ext\\webapp\\__init__.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"Initializes this request handler with the given Request and Response.\"\"\"\n", "func_signal": "def initialize(self, request, response):\n", "code": "self.request = request\nself.response = response", "path": "google\\appengine\\ext\\webapp\\__init__.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"Clears all data written to the output stream so that it is empty.\"\"\"\n", "func_signal": "def clear(self):\n", "code": "self.out.seek(0)\nself.out.truncate(0)", "path": "google\\appengine\\ext\\webapp\\__init__.py", "repo_name": "Arachnid/google_appengine", "stars": 3, "license": "other", "language": "python", "size": 2542}
{"docstring": "\"\"\"Set instance attributes for x and y top left corner coordinates\nand width and heigth for the window.\"\"\"\n", "func_signal": "def size(self):\n", "code": "h, w = stdscr.getmaxyx()\nself.y = 0\nself.w = w\nself.h = h-1\nself.x = 0", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"This needs to override the default traceback thing\nso it can put it into a pretty colour and maybe other\nstuff, I don't know\"\"\"\n", "func_signal": "def showtraceback(self):\n", "code": "try:\n    t, v, tb = sys.exc_info()\n    sys.last_type = t\n    sys.last_value = v\n    sys.last_traceback = tb\n    tblist = traceback.extract_tb(tb)\n    del tblist[:1]\n\n    l = traceback.format_list(tblist)\n    if l:\n        l.insert(0, \"Traceback (most recent call last):\\n\")\n    l[len(l):] = traceback.format_exception_only(t, v)\nfinally:\n    tblist = tb = None\n\nself.writetb(l)", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"Use the shlex module to make a simple lexer for the settings,\nit also attempts to convert any integers to Python ints, otherwise\nleaves them as strings and handles hopefully all the sane ways of\nrepresenting a boolean.\"\"\"\n\n", "func_signal": "def loadrc():\n", "code": "if len(sys.argv) > 2:\n    path = sys.argv[2]\nelse:\n    path = os.path.expanduser('~/.bpythonrc')\n\nif not os.path.isfile(path):\n    return\n\nf = open(path)\nparser = shlex.shlex(f)\n\nbools = {\n    'true': True,\n    'yes': True,\n    'on': True,\n    'false': False,\n    'no': False,\n    'off': False\n}\n\nconfig = {}\nwhile True:\n    k = parser.get_token()\n    v = None\n\n    if not k:\n        break\n\n    k = k.lower()\n\n    if parser.get_token() == '=':\n        v = parser.get_token() or None\n\n    if v is not None:\n        try:\n            v = int(v)\n        except ValueError:\n            if v.lower() in bools:\n                v = bools[v.lower()]\n\n        config[k] = v\nf.close()\n\nfor k, v in config.iteritems():\n    if hasattr(OPTS, k):\n        setattr(OPTS, k, v)", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"Display a message for a short n seconds on the statusbar and return\nit to its original state.\"\"\"\n", "func_signal": "def message(self, s, n=3):\n", "code": "self.timer = time.time() + n\nself.settext(s)", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"Get a line of text and return it\nThis function initialises an empty string and gets the\ncurses cursor position on the screen and stores it\nfor the echo() function to use later (I think).\nThen it waits for key presses and passes them to p_key(),\nwhich returns None if Enter is pressed (that means \"Return\",\nidiot).\"\"\"\n\n", "func_signal": "def get_line(self):\n", "code": "self.ts = ''\n\nindent_spaces = 0\nfor c in self.s:\n    if c == ' ':\n        indent_spaces += 1\n    else:\n        break\n\nindent = self.s.rstrip().endswith(':')\n\nself.s = ''\nself.iy, self.ix = self.scr.getyx()\n\nfor _ in range(indent_spaces // OPTS.tab_length):\n    self.c = '\\t'\n    self.p_key()\n\nif indent:\n    self.c = '\\t'\n    self.p_key()\n\nself.c = None\nself.cpos = 0\n\nwhile True:\n    self.c = self.get_key()\n    if self.p_key() is None:\n        return self.s", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"Same as back() but, well, forward\"\"\"\n\n", "func_signal": "def fwd(self):\n", "code": "self.enter_hist()\n\nself.cpos = 0\n\nif self.h_i > 1:\n    self.h_i -= 1\n    self.s = self.rl_hist[-self.h_i]\nelse:\n    self.h_i = 0\n    self.s = self.ts\n    self.ts = ''\n    self.in_hist = False\n\nself.print_line(self.s, clr=True)", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"Show the appropriate Python prompt\"\"\"\n", "func_signal": "def prompt(self, more):\n", "code": "if not more:\n    self.echo(\"\\x01g\\x03>>> \")\n    self.stdout_hist += '>>> '\n    self.s_hist.append('\\x01g\\x03>>> \\x04')\nelse:\n    self.echo(\"\\x01r\\x03... \")\n    self.stdout_hist += '... '\n    self.s_hist.append('\\x01r\\x03... \\x04')", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"Initialise the repl and jump into the loop. This method also has to\nkeep a stack of lines entered for the horrible \"undo\" feature. It also\ntracks everything that would normally go to stdout in the normal Python\ninterpreter so it can quickly write it to stdout on exit after\ncurses.endwin(), as well as a history of lines entered for using\nup/down to go back and forth (which has to be separate to the\nevaluation history, which will be truncated when undoing.\"\"\"\n\n# This was a feature request to have the PYTHONSTARTUP\n# file executed on startup - I personally don't use this\n# feature so please notify me of any breakage.\n", "func_signal": "def repl(self):\n", "code": "filename = os.environ.get('PYTHONSTARTUP')\nif filename and os.path.isfile(filename):\n    f = open(filename, 'r')\n    code_obj = compile(f.read(), filename, 'exec')\n    f.close()\n    self.interp.runcode(code_obj)", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"Override the regular handler, the code's copied and pasted from\ncode.py, as per showtraceback, but with the syntaxerror callback called\nand the text in a pretty colour.\"\"\"\n", "func_signal": "def showsyntaxerror(self, filename=None):\n", "code": "if self.syntaxerror_callback is not None:\n    self.syntaxerror_callback()\n\ntype, value, sys.last_traceback = sys.exc_info()\nsys.last_type = type\nsys.last_value = value\nif filename and type is SyntaxError:\n    # Work hard to stuff the correct filename in the exception\n    try:\n        msg, (dummy_filename, lineno, offset, line) = value\n    except:\n        # Not the format we expect; leave it alone\n        pass\n    else:\n        # Stuff in the right filename\n        value = SyntaxError(msg, (filename, lineno, offset, line))\n        sys.last_value = value\nlist = traceback.format_exception_only(type, value)\nmap(self.writetb, list)", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"This method moves the cursor relatively from the current\nposition, where:\n    0 == (right) end of current line\n    length of current line len(self.s) == beginning of current line\nand:\n    current cursor position + i\n    for positive values of i the cursor will move towards the beginning\n    of the line, negative values the opposite.\"\"\"\n", "func_signal": "def mvc(self, i, refresh=True):\n", "code": "y, x = self.scr.getyx()\n\nif self.cpos == 0 and i < 0:\n    return False\n\nif x == self.ix and y == self.iy and i >= 1:\n    return False\n\nh, w = gethw()\nif x - i < 0:\n    y -= 1\n    x = w\n\nif x - i >= w:\n    y += 1\n    x = 0 + i\n\nself.cpos += i\nself.scr.move(y, x - i)\nif refresh:\n    self.scr.refresh()\n\nreturn True", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"Process a keypress\"\"\"\n\n", "func_signal": "def p_key(self):\n", "code": "if self.c is None:\n    return ''\n\nif self.c == chr(8): # C-Backspace (on my computer anyway!)\n    self.clrtobol()\n    self.c = '\\n'\n    # Don't return; let it get handled\nif self.c == chr(27):\n    return ''\n\nif self.c in (chr(127), 'KEY_BACKSPACE'):\n    self.bs()\n    self.complete()\n    return ''\n\nelif self.c == 'KEY_DC': # Del\n    self.delete()\n    self.complete()\n    return ''\n\nelif self.c == chr(18): # C-r\n    self.undo()\n    return ''\n\nelif self.c == 'KEY_UP': # Cursor Up\n    self.back()\n    return ''\n\nelif self.c == 'KEY_DOWN': # Cursor Down\n    self.fwd()\n    return ''\n\nelif self.c == 'KEY_LEFT': # Cursor Left\n    self.mvc(1)\n\nelif self.c == 'KEY_RIGHT': # Cursor Right\n    self.mvc(-1)\n\nelif self.c in (\"KEY_HOME\", '^A', chr(1)): # home or ^A\n    self.mvc(len(self.s) - self.cpos)\n\nelif self.c in (\"KEY_END\", '^E', chr(5)): # end or ^E\n    self.mvc(-self.cpos)\n\nelif self.c in ('^K', chr(11)): # cut to buffer\n    self.cut_to_buffer()\n    return ''\n\nelif self.c in ('^Y', chr(25)): # yank from buffer\n    self.yank_from_buffer()\n    return ''\n\nelif self.c in ('^W', chr(23)): # C-w\n    self.bs_word()\n    self.complete()\n    return ''\n\nelif self.c in ('^U', chr(21)): # C-u\n    self.clrtobol()\n    return ''\n\nelif self.c in ('^L', chr(12)): # C-l\n    # TODO: Show the repl after clearing the screen.\n    self.scr.clear()\n    return ''\n\nelif self.c in (chr(4), '^D'): # C-d\n    if not self.s:\n        self.do_exit = True\n        return None\n    else:\n        return ''\n\nelif self.c == 'KEY_F(2)':\n    self.write2file()\n    return ''\n\nelif self.c == 'KEY_F(8)':\n    self.pastebin()\n    return ''\n\nelif self.c == '\\n':\n    self.lf()\n    return None\n\nelif self.c == '\\t':\n    return self.tab()\n\nelif len(self.c) == 1 and self.c in string.printable:\n    self.addstr(self.c)\n    self.print_line(self.s)\n\nelse:\n    return ''\n\n\nreturn True", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"Redraw the screen.\"\"\"\n", "func_signal": "def redraw(self):\n", "code": "self.scr.erase()\nfor k, s in enumerate(self.s_hist):\n    if not s:\n        continue\n    self.iy, self.ix = self.scr.getyx()\n    for i in s.split('\\x04'):\n        self.echo(i, redraw=False)\n    if k < len(self.s_hist) -1:\n        self.scr.addstr('\\n')\nself.iy, self.ix = self.scr.getyx()\nself.print_line(self.s)\nself.scr.refresh()\nself.statusbar.refresh()", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"This figures out what to do with the argspec and puts it nicely into\nthe list window. It returns the number of lines used to display the\nargspec.  It's also kind of messy due to it having to call so many\naddstr() to get the colouring right, but it seems to be pretty\nsturdy.\"\"\"\n\n", "func_signal": "def mkargspec(self, topline, down):\n", "code": "r = 3\nfn = topline[0]\nargs = topline[1][0]\nkwargs = topline[1][3]\n_args = topline[1][1]\n_kwargs = topline[1][2]\nmax_w = int(self.scr.getmaxyx()[1] * 0.6)\nself.list_win.erase()\nself.list_win.resize(3, max_w)\nh, w = self.list_win.getmaxyx()\n\nself.list_win.addstr('\\n  ')\nself.list_win.addstr(fn,\n    curses.color_pair(self._C[\"b\"]+1) | curses.A_BOLD)\nself.list_win.addstr(': (', curses.color_pair(self._C[\"y\"]+1))\nmaxh = self.scr.getmaxyx()[0]\n\nfor k, i in enumerate(args):\n    y, x = self.list_win.getyx()\n    ln = len(str(i))\n    kw = None\n    if kwargs and k+1 > len(args) - len(kwargs):\n        kw = '%s' % str(kwargs[k - (len(args) - len(kwargs))])\n        ln += len(kw) + 1\n\n    if ln + x >= w:\n        ty = self.list_win.getbegyx()[0]\n        if not down and ty > 0:\n            h +=1\n            self.list_win.mvwin(ty-1, 1)\n            self.list_win.resize(h, w)\n        elif down and h + r < maxh-ty:\n            h += 1\n            self.list_win.resize(h, w)\n        else:\n            break\n        r += 1\n        self.list_win.addstr('\\n\\t')\n\n    if str(i) == 'self' and k == 0:\n        color = self._C[\"r\"]\n    else:\n        color = self._C[\"g\"]\n\n    self.list_win.addstr(str(i),\n        curses.color_pair(color + 1) | curses.A_BOLD)\n    if kw:\n        self.list_win.addstr('=', curses.color_pair(self._C[\"c\"]+1))\n        self.list_win.addstr(kw, curses.color_pair(self._C[\"g\"]+1))\n    if k != len(args) -1:\n        self.list_win.addstr(', ', curses.color_pair(self._C[\"g\"]+1))\n\nif _args:\n    self.list_win.addstr(', ',\n        curses.color_pair(self._C[\"g\"]+1))\n    self.list_win.addstr('*%s' % _args,\n        curses.color_pair(self._C[\"m\"]+1))\nif _kwargs:\n    self.list_win.addstr(', ',\n        curses.color_pair(self._C[\"g\"]+1))\n    self.list_win.addstr('**%s' % _kwargs,\n        curses.color_pair(self._C[\"m\"]+1))\nself.list_win.addstr(')', curses.color_pair(self._C[\"y\"]+1))\n\nreturn r", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"This is the method that should be called every half second or so\nto see if the status bar needs updating.\"\"\"\n", "func_signal": "def check(self):\n", "code": "if not self.timer:\n    return\n\nif time.time() < self.timer:\n    return\n\nself.settext(self._s)", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"Push a line of code onto the buffer so it can process it all\nat once when a code block ends\"\"\"\n", "func_signal": "def push(self, s):\n", "code": "s = s.rstrip('\\n')\nself.buffer.append(s)\n\nmore = self.interp.runsource(\"\\n\".join(self.buffer))\n\nif not more:\n    self.buffer = []\n\nreturn more", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"I can't think of any reason why anything other than readline would\nbe useful in the context of an interactive interpreter so this is the\nonly one I've done anything with. The others are just there in case\nsomeone does something weird to stop it from blowing up.\"\"\"\n\n", "func_signal": "def readline(self):\n", "code": "buffer = ''\nwhile True:\n    key = self.interface.get_key()\n    sys.stdout.write(key)", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"Wrap the _complete method to determine the visibility of list_win\nsince there can be several reasons why it won't be displayed; this\nmakes it more manageable.\"\"\"\n\n", "func_signal": "def complete(self, tab=False):\n", "code": "if self.list_win_visible and not OPTS.auto_display_list:\n    self.scr.touchwin()\n    self.list_win_visible = False\n    return\n\nif OPTS.auto_display_list or tab:\n    self.list_win_visible = self._complete(tab)\n    return", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"For overriding stdout defaults\"\"\"\n", "func_signal": "def write(self, s):\n", "code": "if s.rstrip() and '\\x03' in s:\n        t = s.split('\\x03')[1]\nelse:\n    t = s\n\nif isinstance(t, unicode):\n    t = t.encode(sys.__stdout__.encoding)\n\nif not self.stdout_hist:\n    self.stdout_hist = t\nelse:\n    self.stdout_hist += t\n\nself.echo(s)\nself.s_hist.append(s.rstrip())", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"This method exists simply to keep it straight forward when\ninitialising a window and resizing it.\"\"\"\n", "func_signal": "def resize(self, refresh=True):\n", "code": "self.size()\nself.win.mvwin(self.y, self.x)\nself.win.resize(self.h, self.w)\nif refresh:\n    self.refresh()", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"Init all the colours in curses and bang them into a dictionary\"\"\"\n\n", "func_signal": "def make_colours():\n", "code": "for i in range(63):\n    if i > 7:\n        j = i / 8\n    else:\n        j = -1\n    curses.init_pair(i+1, i % 8, j)\n\n# blacK, Red, Green, Yellow, Blue, Magenta, Cyan, White, Default:\nc = {\n    'k' : 0,\n    'r' : 1,\n    'g' : 2,\n    'y' : 3,\n    'b' : 4,\n    'm' : 5,\n    'c' : 6,\n    'w' : 7,\n    'd' : -1,\n}\nreturn c", "path": "bpython\\cli.py", "repo_name": "hyperboreean/bpython", "stars": 2, "license": "mit", "language": "python", "size": 185}
{"docstring": "\"\"\"\nReturn a JSON string representation of a Python data structure.\n\n>>> JSONEncoder().encode({\"foo\": [\"bar\", \"baz\"]})\n'{\"foo\": [\"bar\", \"baz\"]}'\n\"\"\"\n# This is for extremely simple cases and benchmarks.\n", "func_signal": "def encode(self, o):\n", "code": "if isinstance(o, basestring):\n    if isinstance(o, str):\n        _encoding = self.encoding\n        if (_encoding is not None \n                and not (_encoding == 'utf-8')):\n            o = o.decode(_encoding)\n    if self.ensure_ascii:\n        return encode_basestring_ascii(o)\n    else:\n        return encode_basestring(o)\n# This doesn't pass the iterator directly to ''.join() because the\n# exceptions aren't as detailed.  The list call should be roughly\n# equivalent to the PySequence_Fast that ''.join() would do.\nchunks = list(self.iterencode(o))\nreturn ''.join(chunks)", "path": "build\\libs\\django\\utils\\simplejson\\encoder.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nDeserialize a stream or string of YAML data.\n\"\"\"\n", "func_signal": "def Deserializer(stream_or_string, **options):\n", "code": "if isinstance(stream_or_string, basestring):\n    stream = StringIO(stream_or_string)\nelse:\n    stream = stream_or_string\nfor obj in PythonDeserializer(yaml.load(stream)):\n    yield obj", "path": "build\\libs\\django\\core\\serializers\\pyyaml.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nCreate the file object to append to as data is coming in.\n\"\"\"\n", "func_signal": "def new_file(self, file_name, *args, **kwargs):\n", "code": "super(TemporaryFileUploadHandler, self).new_file(file_name, *args, **kwargs)\nself.file = TemporaryUploadedFile(self.file_name, self.content_type, 0, self.charset)", "path": "build\\libs\\django\\core\\files\\uploadhandler.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\" get the project root directory \"\"\"\n", "func_signal": "def get_project_root():\n", "code": "settings_mod = __import__(settings.SETTINGS_MODULE, {}, {}, [''])\nreturn os.path.dirname(os.path.abspath(settings_mod.__file__))", "path": "build\\libs\\django_extensions\\management\\utils.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nFor date values that are tomorrow, today or yesterday compared to\npresent day returns representing string. Otherwise, returns a string\nformatted according to settings.DATE_FORMAT.\n\"\"\"\n", "func_signal": "def naturalday(value, arg=None):\n", "code": "try: \n    value = date(value.year, value.month, value.day)\nexcept AttributeError:\n    # Passed value wasn't a date object\n    return value\nexcept ValueError:\n    # Date arguments out of range\n    return value\ndelta = value - date.today()\nif delta.days == 0:\n    return _(u'today')\nelif delta.days == 1:\n    return _(u'tomorrow')\nelif delta.days == -1:\n    return _(u'yesterday')\nreturn defaultfilters.date(value, arg)", "path": "build\\libs\\django\\contrib\\humanize\\templatetags\\humanize.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nConverts an integer to a string containing commas every three digits.\nFor example, 3000 becomes '3,000' and 45000 becomes '45,000'.\n\"\"\"\n", "func_signal": "def intcomma(value):\n", "code": "orig = force_unicode(value)\nnew = re.sub(\"^(-?\\d+)(\\d{3})\", '\\g<1>,\\g<2>', orig)\nif orig == new:\n    return new\nelse:\n    return intcomma(new)", "path": "build\\libs\\django\\contrib\\humanize\\templatetags\\humanize.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nConverts a large integer to a friendly text representation. Works best for\nnumbers over 1 million. For example, 1000000 becomes '1.0 million', 1200000\nbecomes '1.2 million' and '1200000000' becomes '1.2 billion'.\n\"\"\"\n", "func_signal": "def intword(value):\n", "code": "value = int(value)\nif value < 1000000:\n    return value\nif value < 1000000000:\n    new_value = value / 1000000.0\n    return ungettext('%(value).1f million', '%(value).1f million', new_value) % {'value': new_value}\nif value < 1000000000000:\n    new_value = value / 1000000000.0\n    return ungettext('%(value).1f billion', '%(value).1f billion', new_value) % {'value': new_value}\nif value < 1000000000000000:\n    new_value = value / 1000000000000.0\n    return ungettext('%(value).1f trillion', '%(value).1f trillion', new_value) % {'value': new_value}\nreturn value", "path": "build\\libs\\django\\contrib\\humanize\\templatetags\\humanize.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nValue must be an 11-digit number.\n\"\"\"\n", "func_signal": "def clean(self, value):\n", "code": "value = super(PERUCField, self).clean(value)\nif value in EMPTY_VALUES:\n    return u''\nif not value.isdigit():\n    raise ValidationError(self.error_messages['invalid'])\nif len(value) != 11:\n    raise ValidationError(self.error_messages['max_digits'])\nreturn value", "path": "build\\libs\\django\\contrib\\localflavor\\pe\\forms.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "# A nasty special case: base YAML doesn't support serialization of time\n# types (as opposed to dates or datetimes, which it does support). Since\n# we want to use the \"safe\" serializer for better interoperability, we\n# need to do something with those pesky times. Converting 'em to strings\n# isn't perfect, but it's better than a \"!!python/time\" type which would\n# halt deserialization under any other language.\n", "func_signal": "def handle_field(self, obj, field):\n", "code": "if isinstance(field, models.TimeField) and getattr(obj, field.name) is not None:\n    self._current[field.name] = str(getattr(obj, field.name))\nelse:\n    super(Serializer, self).handle_field(obj, field)", "path": "build\\libs\\django\\core\\serializers\\pyyaml.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nUse the content_length to signal whether or not this handler should be in use.\n\"\"\"\n# Check the content-length header to see if we should\n# If the the post is too large, we cannot use the Memory handler.\n", "func_signal": "def handle_raw_input(self, input_data, META, content_length, boundary, encoding=None):\n", "code": "if content_length > settings.FILE_UPLOAD_MAX_MEMORY_SIZE:\n    self.activated = False\nelse:\n    self.activated = True", "path": "build\\libs\\django\\core\\files\\uploadhandler.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nFor numbers 1-9, returns the number spelled out. Otherwise, returns the\nnumber. This follows Associated Press style.\n\"\"\"\n", "func_signal": "def apnumber(value):\n", "code": "try:\n    value = int(value)\nexcept ValueError:\n    return value\nif not 0 < value < 10:\n    return value\nreturn (_('one'), _('two'), _('three'), _('four'), _('five'), _('six'), _('seven'), _('eight'), _('nine'))[value-1]", "path": "build\\libs\\django\\contrib\\humanize\\templatetags\\humanize.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nReturn a JSON representation of a Python string\n\"\"\"\n", "func_signal": "def encode_basestring(s):\n", "code": "def replace(match):\n    return ESCAPE_DCT[match.group(0)]\nreturn '\"' + ESCAPE.sub(replace, s) + '\"'", "path": "build\\libs\\django\\utils\\simplejson\\encoder.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nSignal that a new file has been started.\n\nWarning: As with any data from the client, you should not trust\ncontent_length (and sometimes won't even get it).\n\"\"\"\n", "func_signal": "def new_file(self, field_name, file_name, content_type, content_length, charset=None):\n", "code": "self.field_name = field_name\nself.file_name = file_name\nself.content_type = content_type\nself.content_length = content_length\nself.charset = charset", "path": "build\\libs\\django\\core\\files\\uploadhandler.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "# Check for specials.  Note that this type of test is processor- and/or\n# platform-specific, so do tests which don't depend on the internals.\n\n", "func_signal": "def floatstr(o, allow_nan=True):\n", "code": "if o != o:\n    text = 'NaN'\nelif o == INFINITY:\n    text = 'Infinity'\nelif o == -INFINITY:\n    text = '-Infinity'\nelse:\n    return FLOAT_REPR(o)\n\nif not allow_nan:\n    raise ValueError(\"Out of range float values are not JSON compliant: %r\"\n        % (o,))\n\nreturn text", "path": "build\\libs\\django\\utils\\simplejson\\encoder.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nIf the request method is HEAD and either the IP is internal or the\nuser is a logged-in staff member, quickly return with an x-header\nindicating the view function.  This is used by the documentation module\nto lookup the view function for an arbitrary page.\n\"\"\"\n", "func_signal": "def process_view(self, request, view_func, view_args, view_kwargs):\n", "code": "if request.method == 'HEAD' and (request.META.get('REMOTE_ADDR') in settings.INTERNAL_IPS or (request.user.is_authenticated() and request.user.is_staff)):\n    response = http.HttpResponse()\n    response['X-View'] = \"%s.%s\" % (view_func.__module__, view_func.__name__)\n    return response", "path": "build\\libs\\django\\middleware\\doc.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nValue must be a string in the XXXXXXXX formats.\n\"\"\"\n", "func_signal": "def clean(self, value):\n", "code": "value = super(PEDNIField, self).clean(value)\nif value in EMPTY_VALUES:\n    return u''\nif not value.isdigit():\n    raise ValidationError(self.error_messages['invalid'])\nif len(value) != 8:\n    raise ValidationError(self.error_messages['max_digits'])\n\nreturn value", "path": "build\\libs\\django\\contrib\\localflavor\\pe\\forms.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nConverts an integer to its ordinal as a string. 1 is '1st', 2 is '2nd',\n3 is '3rd', etc. Works for any integer.\n\"\"\"\n", "func_signal": "def ordinal(value):\n", "code": "try:\n    value = int(value)\nexcept ValueError:\n    return value\nt = (_('th'), _('st'), _('nd'), _('rd'), _('th'), _('th'), _('th'), _('th'), _('th'), _('th'))\nif value % 100 in (11, 12, 13): # special case\n    return u\"%d%s\" % (value, t[0])\nreturn u'%d%s' % (value, t[value % 10])", "path": "build\\libs\\django\\contrib\\humanize\\templatetags\\humanize.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nReturn a file object if we're activated.\n\"\"\"\n", "func_signal": "def file_complete(self, file_size):\n", "code": "if not self.activated:\n    return\n\nreturn InMemoryUploadedFile(\n    file = self.file,\n    field_name = self.field_name,\n    name = self.file_name,\n    content_type = self.content_type,\n    size = file_size,\n    charset = self.charset\n)", "path": "build\\libs\\django\\core\\files\\uploadhandler.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nAdd the data to the StringIO file.\n\"\"\"\n", "func_signal": "def receive_data_chunk(self, raw_data, start):\n", "code": "if self.activated:\n    self.file.write(raw_data)\nelse:\n    return raw_data", "path": "build\\libs\\django\\core\\files\\uploadhandler.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nEncode the given object and yield each string\nrepresentation as available.\n\nFor example::\n    \n    for chunk in JSONEncoder().iterencode(bigobject):\n        mysocket.write(chunk)\n\"\"\"\n", "func_signal": "def iterencode(self, o):\n", "code": "if self.check_circular:\n    markers = {}\nelse:\n    markers = None\nreturn self._iterencode(o, markers)", "path": "build\\libs\\django\\utils\\simplejson\\encoder.py", "repo_name": "taylanpince/trip_lister", "stars": 2, "license": "None", "language": "python", "size": 2972}
{"docstring": "\"\"\"\nGenerator that yields dictionaries of all models that have this\nEasyInstance's model as a ForeignKey or ManyToManyField, along with\nlists of related objects.\n\"\"\"\n", "func_signal": "def related_objects(self):\n", "code": "for rel_object in self.model.model._meta.get_all_related_objects() + self.model.model._meta.get_all_related_many_to_many_objects():\n    if rel_object.model not in self.model.model_list:\n        continue # Skip models that aren't in the model_list\n    em = EasyModel(self.model.site, rel_object.model)\n    yield {\n        'model': em,\n        'related_field': rel_object.field.verbose_name,\n        'object_list': [EasyInstance(em, i) for i in getattr(self.instance, rel_object.get_accessor_name()).all()],\n    }", "path": "build\\src\\Django-1.0.2-final\\django\\contrib\\databrowse\\datastructures.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nConcatenating a safe unicode object with another safe string or safe\nunicode object is safe. Otherwise, the result is no longer safe.\n\"\"\"\n", "func_signal": "def __add__(self, rhs):\n", "code": "t = super(SafeUnicode, self).__add__(rhs)\nif isinstance(rhs, SafeData):\n    return SafeUnicode(t)\nreturn t", "path": "build\\src\\Django-1.0.2-final\\django\\utils\\safestring.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nAuto-discover INSTALLED_APPS admin.py modules and fail silently when \nnot present. This forces an import on them to register any admin bits they\nmay want.\n\"\"\"\n", "func_signal": "def autodiscover():\n", "code": "import imp\nfrom django.conf import settings\n\nfor app in settings.INSTALLED_APPS:\n    # For each app, we need to look for an admin.py inside that app's\n    # package. We can't use os.path here -- recall that modules may be\n    # imported different ways (think zip files) -- so we need to get\n    # the app's __path__ and look for admin.py on that path.\n\n    # Step 1: find out the app's __path__ Import errors here will (and\n    # should) bubble up, but a missing __path__ (which is legal, but weird)\n    # fails silently -- apps that do weird things with __path__ might\n    # need to roll their own admin registration.\n    try:\n        app_path = __import__(app, {}, {}, [app.split('.')[-1]]).__path__\n    except AttributeError:\n        continue\n\n    # Step 2: use imp.find_module to find the app's admin.py. For some\n    # reason imp.find_module raises ImportError if the app can't be found\n    # but doesn't actually try to import the module. So skip this app if\n    # its admin.py doesn't exist\n    try:\n        imp.find_module('admin', app_path)\n    except ImportError:\n        continue\n\n    # Step 3: import the app's admin file. If this has errors we want them\n    # to bubble up.\n    __import__(\"%s.admin\" % app)", "path": "build\\src\\Django-1.0.2-final\\django\\contrib\\admin\\__init__.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nValidates the input and returns a string that contains only numbers.\nReturns an empty string for empty values.\n\"\"\"\n", "func_signal": "def clean(self, value):\n", "code": "v = super(SKPostalCodeField, self).clean(value)\nreturn v.replace(' ', '')", "path": "build\\src\\Django-1.0.2-final\\django\\contrib\\localflavor\\sk\\forms.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nConcatenating a safe string with another safe string or safe unicode\nobject is safe. Otherwise, the result is no longer safe.\n\"\"\"\n", "func_signal": "def __add__(self, rhs):\n", "code": "t = super(SafeString, self).__add__(rhs)\nif isinstance(rhs, SafeUnicode):\n    return SafeUnicode(t)\nelif isinstance(rhs, SafeString):\n    return SafeString(t)\nreturn t", "path": "build\\src\\Django-1.0.2-final\\django\\utils\\safestring.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nProvides a proper substitution value for Geometries that are not in the\nSRID of the field.  Specifically, this routine will substitute in the\nSDO_CS.TRANSFORM() function call.\n\"\"\"\n", "func_signal": "def get_placeholder(self, value):\n", "code": "if value is None:\n    return '%s'\nelif value.srid != self._srid:\n    # Adding Transform() to the SQL placeholder.\n    return '%s(SDO_GEOMETRY(%%s, %s), %s)' % (TRANSFORM, value.srid, self._srid)\nelse:\n    return 'SDO_GEOMETRY(%%s, %s)' % self._srid", "path": "build\\src\\Django-1.0.2-final\\django\\contrib\\gis\\db\\backend\\oracle\\field.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nGenerator that yields EasyInstanceFields for each field in this\nEasyInstance's model.\n\"\"\"\n", "func_signal": "def fields(self):\n", "code": "for f in self.model.model._meta.fields + self.model.model._meta.many_to_many:\n    yield EasyInstanceField(self.model, self, f)", "path": "build\\src\\Django-1.0.2-final\\django\\contrib\\databrowse\\datastructures.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nWrap a call to a normal unicode method up so that we return safe\nresults. The method that is being wrapped is passed in the 'method'\nargument.\n\"\"\"\n", "func_signal": "def _proxy_method(self, *args, **kwargs):\n", "code": "method = kwargs.pop('method')\ndata = method(self, *args, **kwargs)\nif isinstance(data, str):\n    return SafeString(data)\nelse:\n    return SafeUnicode(data)", "path": "build\\src\\Django-1.0.2-final\\django\\utils\\safestring.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nAdds this geometry column into the Oracle USER_SDO_GEOM_METADATA\ntable.\n\"\"\"\n\n# Checking the dimensions.\n# TODO: Add support for 3D geometries.\n", "func_signal": "def _add_geom(self, style, db_table):\n", "code": "if self._dim != 2:\n    raise Exception('3D geometries not yet supported on Oracle Spatial backend.')\n\n# Constructing the SQL that will be used to insert information about\n# the geometry column into the USER_GSDO_GEOM_METADATA table.\nmeta_sql = style.SQL_KEYWORD('INSERT INTO ') + \\\n           style.SQL_TABLE('USER_SDO_GEOM_METADATA') + \\\n           ' (%s, %s, %s, %s)\\n  ' % tuple(map(qn, ['TABLE_NAME', 'COLUMN_NAME', 'DIMINFO', 'SRID'])) + \\\n           style.SQL_KEYWORD(' VALUES ') + '(\\n    ' + \\\n           style.SQL_TABLE(gqn(db_table)) + ',\\n    ' + \\\n           style.SQL_FIELD(gqn(self.column)) + ',\\n    ' + \\\n           style.SQL_KEYWORD(\"MDSYS.SDO_DIM_ARRAY\") + '(\\n      ' + \\\n           style.SQL_KEYWORD(\"MDSYS.SDO_DIM_ELEMENT\") + \\\n           (\"('LONG', %s, %s, %s),\\n      \" % (self._extent[0], self._extent[2], self._tolerance)) + \\\n           style.SQL_KEYWORD(\"MDSYS.SDO_DIM_ELEMENT\") + \\\n           (\"('LAT', %s, %s, %s)\\n    ),\\n\" % (self._extent[1], self._extent[3], self._tolerance)) + \\\n           '    %s\\n  );' % self._srid\nreturn meta_sql", "path": "build\\src\\Django-1.0.2-final\\django\\contrib\\gis\\db\\backend\\oracle\\field.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "# Model 'Spam'\n", "func_signal": "def forwards(self):\n", "code": "        db.create_table(\"southtest_spam\", (\n            ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)),\n            ('weight', models.FloatField()),\n            ('expires', models.DateTimeField()),\n            ('name', models.CharField(max_length=255))\n        ))", "path": "build\\src\\south-0.4\\tests\\fakeapp\\migrations\\0001_spam.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nWrap a call to a normal unicode method up so that we return safe\nresults. The method that is being wrapped is passed in the 'method'\nargument.\n\"\"\"\n", "func_signal": "def _proxy_method(self, *args, **kwargs):\n", "code": "method = kwargs.pop('method')\ndata = method(self, *args, **kwargs)\nif isinstance(data, str):\n    return SafeString(data)\nelse:\n    return SafeUnicode(data)", "path": "build\\src\\Django-1.0.2-final\\django\\utils\\safestring.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nArgument is a Geometry, return type is double that is passed\nin by reference as the last argument.\n\"\"\"\n", "func_signal": "def dbl_from_geom(func, num_geom=1):\n", "code": "argtypes = [GEOM_PTR for i in xrange(num_geom)]\nargtypes += [POINTER(c_double)]\nfunc.argtypes = argtypes\nfunc.restype = c_int # Status code returned\nfunc.errcheck = check_dbl\nreturn func", "path": "build\\src\\Django-1.0.2-final\\django\\contrib\\gis\\geos\\prototypes\\misc.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nExplicitly mark a string as safe for (HTML) output purposes. The returned\nobject can be used everywhere a string or unicode object is appropriate.\n\nCan be called multiple times on a single string.\n\"\"\"\n", "func_signal": "def mark_safe(s):\n", "code": "if isinstance(s, SafeData):\n    return s\nif isinstance(s, str) or (isinstance(s, Promise) and s._delegate_str):\n    return SafeString(s)\nif isinstance(s, (unicode, Promise)):\n    return SafeUnicode(s)\nreturn SafeString(str(s))", "path": "build\\src\\Django-1.0.2-final\\django\\utils\\safestring.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nExplicitly mark a string as requiring HTML escaping upon output. Has no\neffect on SafeData subclasses.\n\nCan be called multiple times on a single string (the resulting escaping is\nonly applied once).\n\"\"\"\n", "func_signal": "def mark_for_escaping(s):\n", "code": "if isinstance(s, (SafeData, EscapeData)):\n    return s\nif isinstance(s, str) or (isinstance(s, Promise) and s._delegate_str):\n    return EscapeString(s)\nif isinstance(s, (unicode, Promise)):\n    return EscapeUnicode(s)\nreturn EscapeString(str(s))", "path": "build\\src\\Django-1.0.2-final\\django\\utils\\safestring.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nReturns SQL that will be executed after the model has been\ncreated.\n\"\"\"\n# Getting the meta geometry information.\n", "func_signal": "def post_create_sql(self, style, db_table):\n", "code": "post_sql = self._add_geom(style, db_table)\n\n# Getting the geometric index for this Geometry column.\nif self._index:\n    return (post_sql, self._geom_index(style, db_table))\nelse:\n    return (post_sql,)", "path": "build\\src\\Django-1.0.2-final\\django\\contrib\\gis\\db\\backend\\oracle\\field.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nDecorator for views that checks that the user passes the given test,\nredirecting to the log-in page if necessary. The test should be a callable\nthat takes the user object and returns True if the user passes.\n\"\"\"\n", "func_signal": "def user_passes_test(test_func, login_url=None, redirect_field_name=REDIRECT_FIELD_NAME):\n", "code": "def decorate(view_func):\n    return _CheckLogin(view_func, test_func, login_url, redirect_field_name)\nreturn decorate", "path": "build\\src\\Django-1.0.2-final\\django\\contrib\\auth\\decorators.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nOracle Spatial backend needs to have the extent -- for projected coordinate\nsystems _you must define the extent manually_, since the coordinates are\nfor geodetic systems.  The `tolerance` keyword specifies the tolerance\nfor error (in meters), and defaults to 0.05 (5 centimeters).\n\"\"\"\n# Oracle Spatial specific keyword arguments.\n", "func_signal": "def __init__(self, extent=(-180.0, -90.0, 180.0, 90.0), tolerance=0.05, **kwargs):\n", "code": "self._extent = extent\nself._tolerance = tolerance\n# Calling the Django field initialization.\nsuper(OracleSpatialField, self).__init__(**kwargs)", "path": "build\\src\\Django-1.0.2-final\\django\\contrib\\gis\\db\\backend\\oracle\\field.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nIf the request method is HEAD and either the IP is internal or the\nuser is a logged-in staff member, quickly return with an x-header\nindicating the view function.  This is used by the documentation module\nto lookup the view function for an arbitrary page.\n\"\"\"\n", "func_signal": "def process_view(self, request, view_func, view_args, view_kwargs):\n", "code": "if request.method == 'HEAD' and (request.META.get('REMOTE_ADDR') in settings.INTERNAL_IPS or (request.user.is_authenticated() and request.user.is_staff)):\n    response = http.HttpResponse()\n    response['X-View'] = \"%s.%s\" % (view_func.__module__, view_func.__name__)\n    return response", "path": "build\\src\\Django-1.0.2-final\\django\\middleware\\doc.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nReturns a list of values for this field for this instance. It's a list\nso we can accomodate many-to-many fields.\n\"\"\"\n# This import is deliberately inside the function because it causes\n# some settings to be imported, and we don't want to do that at the\n# module level.\n", "func_signal": "def values(self):\n", "code": "if self.field.rel:\n    if isinstance(self.field.rel, models.ManyToOneRel):\n        objs = getattr(self.instance.instance, self.field.name)\n    elif isinstance(self.field.rel, models.ManyToManyRel): # ManyToManyRel\n        return list(getattr(self.instance.instance, self.field.name).all())\nelif self.field.choices:\n    objs = dict(self.field.choices).get(self.raw_value, EMPTY_VALUE)\nelif isinstance(self.field, models.DateField) or isinstance(self.field, models.TimeField):\n    if self.raw_value:\n        date_format, datetime_format, time_format = get_date_formats()\n        if isinstance(self.field, models.DateTimeField):\n            objs = capfirst(dateformat.format(self.raw_value, datetime_format))\n        elif isinstance(self.field, models.TimeField):\n            objs = capfirst(dateformat.time_format(self.raw_value, time_format))\n        else:\n            objs = capfirst(dateformat.format(self.raw_value, date_format))\n    else:\n        objs = EMPTY_VALUE\nelif isinstance(self.field, models.BooleanField) or isinstance(self.field, models.NullBooleanField):\n    objs = {True: 'Yes', False: 'No', None: 'Unknown'}[self.raw_value]\nelse:\n    objs = self.raw_value\nreturn [objs]", "path": "build\\src\\Django-1.0.2-final\\django\\contrib\\databrowse\\datastructures.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nDecorator for views that checks that the user is logged in, redirecting\nto the log-in page if necessary.\n\"\"\"\n", "func_signal": "def login_required(function=None, redirect_field_name=REDIRECT_FIELD_NAME):\n", "code": "actual_decorator = user_passes_test(\n    lambda u: u.is_authenticated(),\n    redirect_field_name=redirect_field_name\n)\nif function:\n    return actual_decorator(function)\nreturn actual_decorator", "path": "build\\src\\Django-1.0.2-final\\django\\contrib\\auth\\decorators.py", "repo_name": "taylanpince/alghalia", "stars": 2, "license": "None", "language": "python", "size": 5668}
{"docstring": "\"\"\"\nUpdates a given page.\n\"\"\"\n", "func_signal": "def updatePage(self, pagename, fields):\n", "code": "targetpath = self.getPath(pagename)\nif(not os.path.exists(targetpath)):\n  os.makedirs(targetpath)\nfilename = os.path.join(targetpath,BASE_FILENAME) \ntry:\n  open(filename, \"wb\").write((BASE_PAGE % fields).encode('utf-8'))\nexcept IOError:\n  return None\nreturn True", "path": "apps\\wiki\\yaki\\store.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"Emit a single node.\"\"\"\n\n", "func_signal": "def emit_node(self, node):\n", "code": "emit = getattr(self, '%s_emit' % node.kind, self.default_emit)\nreturn emit(node)", "path": "contrib\\markup\\creole2html.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nThis function is used to tell akismet that a comment it marked as ham,\nis really spam.\n\nIt takes all the same arguments as ``comment_check``, except for\n*DEBUG*.\n\"\"\"\n", "func_signal": "def submit_spam(self, comment, data=None, build_data=True):\n", "code": "if self.key is None:\n    raise APIKeyError(\"Your have not set an API key.\")\nif data is None:\n    data = {}\nif build_data:\n    self._build_data(comment, data)\nurl = '%ssubmit-spam' % self._getURL()\n# we *don't* trap the error here\n# so if akismet is down it will raise an HTTPError or URLError\nheaders = {'User-Agent' : self.user_agent}\nself._safeRequest(url, urlencode(data), headers)", "path": "contrib\\utils\\akismet.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nEnumerate all pages and their last modification time\n\"\"\"\n", "func_signal": "def allPages(self):\n", "code": "for folder, subfolders, files in os.walk(self.path):\n  if( \"index.txt\" in files ):\n    # Check for modification date of markup file only\n    # (we can use the folder modification time instead)\n    mtime = os.stat(os.path.join(folder,BASE_FILENAME))[stat.ST_MTIME]\n    # Add each path (removing the self.path prefix)\n    self.pages[folder[len(self.path)+1:]] = mtime\n\nfor name in self.pages.keys():\n  base = os.path.basename(name).lower()\n  if base in self.aliases.keys():\n    if len(self.aliases[base]) > len(name):\n      self.aliases[base] = name\n  else:\n    self.aliases[base] = name        \n  for replacement in ALIASING_CHARS:\n    alias = name.lower().replace(' ',replacement)\n    self.aliases[alias] = name\nreturn self.pages", "path": "apps\\wiki\\yaki\\store.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nEquivalent to str.split, except splitting from the right.\n\"\"\"\n", "func_signal": "def rsplit(s, sep=None, maxsplit=-1):\n", "code": "if sys.version_info < (2, 4, 0):\n  if sep is not None:\n    sep = sep[::-1]\n  L = s[::-1].split(sep, maxsplit)\n  L.reverse()\n  return [s[::-1] for s in L]\nelse:\n  return s.rsplit(sep, maxsplit)", "path": "apps\\wiki\\yaki\\utils.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nRetrieve a page's stored date (or fall back to mtime)\n\"\"\"\n", "func_signal": "def date(self, pagename):\n", "code": "if pagename in self.dates.keys():\n  return self.dates[pagename]\nelse:\n  return self.mtime(pagename)", "path": "apps\\wiki\\yaki\\store.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nThis is the function that checks comments.\n\nIt returns ``True`` for spam and ``False`` for ham.\n\nIf you set ``DEBUG=True`` then it will return the text of the response,\ninstead of the ``True`` or ``False`` object.\n\nIt raises ``APIKeyError`` if you have not yet set an API key.\n\nIf the connection to Akismet fails then the ``HTTPError`` or\n``URLError`` will be propogated.\n\nAs a minimum it requires the body of the comment. This is the\n``comment`` argument.\n\nAkismet requires some other arguments, and allows some optional ones.\nThe more information you give it, the more likely it is to be able to\nmake an accurate diagnosise.\n\nYou supply these values using a mapping object (dictionary) as the\n``data`` argument.\n\nIf ``build_data`` is ``True`` (the default), then *akismet.py* will\nattempt to fill in as much information as possible, using default\nvalues where necessary. This is particularly useful for programs\nrunning in a {acro;CGI} environment. A lot of useful information\ncan be supplied from evironment variables (``os.environ``). See below.\n\nYou *only* need supply values for which you don't want defaults filled\nin for. All values must be strings.\n\nThere are a few required values. If they are not supplied, and\ndefaults can't be worked out, then an ``AkismetError`` is raised.\n\nIf you set ``build_data=False`` and a required value is missing an\n``AkismetError`` will also be raised.\n\nThe normal values (and defaults) are as follows : ::\n\n    'user_ip':          os.environ['REMOTE_ADDR']       (*)\n    'user_agent':       os.environ['HTTP_USER_AGENT']   (*)\n    'referrer':         os.environ.get('HTTP_REFERER', 'unknown') [#]_\n    'permalink':        ''\n    'comment_type':     'comment' [#]_\n    'comment_author':   ''\n    'comment_author_email': ''\n    'comment_author_url': ''\n    'SERVER_ADDR':      os.environ.get('SERVER_ADDR', '')\n    'SERVER_ADMIN':     os.environ.get('SERVER_ADMIN', '')\n    'SERVER_NAME':      os.environ.get('SERVER_NAME', '')\n    'SERVER_PORT':      os.environ.get('SERVER_PORT', '')\n    'SERVER_SIGNATURE': os.environ.get('SERVER_SIGNATURE', '')\n    'SERVER_SOFTWARE':  os.environ.get('SERVER_SOFTWARE', '')\n    'HTTP_ACCEPT':      os.environ.get('HTTP_ACCEPT', '')\n\n(*) Required values\n\nYou may supply as many additional 'HTTP_*' type values as you wish.\nThese should correspond to the http headers sent with the request.\n\n.. [#] Note the spelling \"referrer\". This is a required value by the\n    akismet api - however, referrer information is not always\n    supplied by the browser or server. In fact the HTTP protocol\n    forbids relying on referrer information for functionality in \n    programs.\n.. [#] The `API docs <http://akismet.com/development/api/>`_ state that this value\n    can be \" *blank, comment, trackback, pingback, or a made up value*\n    *like 'registration'* \".\n\"\"\"\n", "func_signal": "def comment_check(self, comment, data=None, build_data=True, DEBUG=False):\n", "code": "if self.key is None:\n    raise APIKeyError(\"Your have not set an API key.\")\nif data is None:\n    data = {}\nif build_data:\n    self._build_data(comment, data)\nurl = '%scomment-check' % self._getURL()\n# we *don't* trap the error here\n# so if akismet is down it will raise an HTTPError or URLError\nheaders = {'User-Agent' : self.user_agent}\nresp = self._safeRequest(url, urlencode(data), headers)\nif DEBUG:\n    return resp\nresp = resp.lower()\nif resp == 'true':\n    return True\nelif resp == 'false':\n    return False\nelse:\n    # NOTE: Happens when you get a 'howdy wilbur' response !\n    raise AkismetError('missing required argument.')", "path": "contrib\\utils\\akismet.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nParse a TextMate date (YYYY-MM-DD HH-MM-SS, no time zone)\n\"\"\"\n", "func_signal": "def parseDate(date):\n", "code": "m = _textmate_date_re.match(date)\nif not m:\n  return time.mktime(feedparser._parse_date(date))\nisodate = '%(year)s-%(month)s-%(day)sT%(hour)s:%(minute)s:%(second)s%(zonediff)s' % {'year': m.group(1), 'month': m.group(2), 'day': m.group(3), 'hour': m.group(4), 'minute': m.group(5), 'second': m.group(6), 'zonediff': '+00:00'} \nreturn time.mktime(feedparser._parse_date(isodate))", "path": "apps\\wiki\\yaki\\utils.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nTime string in ISO format\n\"\"\"\n", "func_signal": "def isoTime(value=None):\n", "code": "if value == None:\n  value = time.localtime()\ntz = time.timezone/3600\nreturn time.strftime(\"%Y-%m-%dT%H:%M:%S-\", value) + (\"%(tz)02d:00\" % vars())", "path": "apps\\wiki\\yaki\\utils.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nThis function builds the data structure required by ``comment_check``,\n``submit_spam``, and ``submit_ham``.\n\nIt modifies the ``data`` dictionary you give it in place. (and so\ndoesn't return anything)\n\nIt raises an ``AkismetError`` if the user IP or user-agent can't be\nworked out.\n\"\"\"\n", "func_signal": "def _build_data(self, comment, data):\n", "code": "data['comment_content'] = comment\nif not 'user_ip' in data:\n    try:\n        val = os.environ['REMOTE_ADDR']\n    except KeyError:\n        raise AkismetError(\"No 'user_ip' supplied\")\n    data['user_ip'] = val\nif not 'user_agent' in data:\n    try:\n        val = os.environ['HTTP_USER_AGENT']\n    except KeyError:\n        raise AkismetError(\"No 'user_agent' supplied\")\n    data['user_agent'] = val\n#\ndata.setdefault('referrer', os.environ.get('HTTP_REFERER', 'unknown'))\ndata.setdefault('permalink', '')\ndata.setdefault('comment_type', 'comment')\ndata.setdefault('comment_author', '')\ndata.setdefault('comment_author_email', '')\ndata.setdefault('comment_author_url', '')\ndata.setdefault('SERVER_ADDR', os.environ.get('SERVER_ADDR', ''))\ndata.setdefault('SERVER_ADMIN', os.environ.get('SERVER_ADMIN', ''))\ndata.setdefault('SERVER_NAME', os.environ.get('SERVER_NAME', ''))\ndata.setdefault('SERVER_PORT', os.environ.get('SERVER_PORT', ''))\ndata.setdefault('SERVER_SIGNATURE', os.environ.get('SERVER_SIGNATURE',\n    ''))\ndata.setdefault('SERVER_SOFTWARE', os.environ.get('SERVER_SOFTWARE',\n    ''))\ndata.setdefault('HTTP_ACCEPT', os.environ.get('HTTP_ACCEPT', ''))\ndata.setdefault('blog', self.blog_url)", "path": "contrib\\utils\\akismet.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nHuman-readable time strings, based on Natalie Downe's code from\nhttp://blog.natbat.co.uk/archive/2003/Jun/14/time_since\nAssumes time parameters are in seconds\n\"\"\"\n", "func_signal": "def timeSince(i18n, older=None,newer=None,detail=2):\n", "code": "intervals = {\n  31556926: 'year', # corrected from the initial 31536000\n  2592000: 'month',\n  604800: 'week',\n  86400: 'day',\n  3600: 'hour',\n  60: 'minute',\n}\nchunks = intervals.keys()\n\n# Reverse sort using a lambda (for Python 2.3 backwards compatibility)\nchunks.sort(lambda x, y: y-x)\n\nif newer == None:\n  newer = time.time()\n\ninterval = newer - older\nif interval < 0:\n  return i18n['some_time']\n  # We should ideally do this:\n  # raise ValueError('Time interval cannot be negative')\n  # but it makes sense to fail gracefully here\nif interval < 60:\n  return i18n['less_1min']\n\noutput = ''\nfor steps in range(detail):\n  for seconds in chunks:\n    count = math.floor(interval/seconds)\n    unit = intervals[seconds]\n    if count != 0:\n      break\n  if count > 1:\n    unit = unit + 's'\n  if count != 0:\n    output = output + \"%d %s, \" % (count, i18n[unit])\n  interval = interval - (count * seconds)\noutput = output[:-2]\nreturn output", "path": "apps\\wiki\\yaki\\utils.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nReturns the filename for an attachment\n\"\"\"\n", "func_signal": "def getAttachmentFilename(self, pagename, attachment):\n", "code": "targetpath = self.getPath(pagename)\ntargetfile = os.path.join(targetpath,attachment)\nreturn targetfile", "path": "apps\\wiki\\yaki\\store.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nThis equates to the ``verify-key`` call against the akismet API.\n\nIt returns ``True`` if the key is valid.\n\nThe docs state that you *ought* to call this at the start of the\ntransaction.\n\nIt raises ``APIKeyError`` if you have not yet set an API key.\n\nIf the connection to akismet fails, it allows the normal ``HTTPError``\nor ``URLError`` to be raised.\n(*akismet.py* uses `urllib2 <http://docs.python.org/lib/module-urllib2.html>`_)\n\"\"\"\n", "func_signal": "def verify_key(self):\n", "code": "if self.key is None:\n    raise APIKeyError(\"Your have not set an API key.\")\ndata = { 'key': self.key, 'blog': self.blog_url }\n# this function *doesn't* use the key as part of the URL\nurl = 'http://%sverify-key' % self.baseurl\n# we *don't* trap the error here\n# so if akismet is down it will raise an HTTPError or URLError\nheaders = {'User-Agent' : self.user_agent}\nresp = self._safeRequest(url, urlencode(data), headers)\nif resp.lower() == 'valid':\n    return True\nelse:\n    return False", "path": "contrib\\utils\\akismet.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"Automatically calls ``setAPIKey``.\"\"\"\n", "func_signal": "def __init__(self, key=None, blog_url=None, agent=None):\n", "code": "if agent is None:\n    agent = DEFAULTAGENT % __version__\nself.user_agent = user_agent % (agent, __version__)\nself.setAPIKey(key, blog_url)", "path": "contrib\\utils\\akismet.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nTime string for HTTP headers\n\"\"\"\n", "func_signal": "def httpTime(value=None):\n", "code": "if value == None:\n  value = time.localtime()\nreturn time.strftime(\"%a, %d %b %Y %H:%M:%S GMT\", time.gmtime(value))", "path": "apps\\wiki\\yaki\\utils.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nGenerator for iterating inside a file tree\n\"\"\"\n", "func_signal": "def locate(pattern, root=os.getcwd()):\n", "code": "for path, dirs, files in os.walk(root):\n  for filename in [os.path.abspath(os.path.join(path, filename)) for filename in files if fnmatch.fnmatch(filename, pattern)]:\n    yield filename", "path": "apps\\wiki\\yaki\\utils.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nShrinks a string, adding an ellipsis to the middle\n\"\"\"\n", "func_signal": "def shrink(line,bound=50,rep='[...]'):\n", "code": "l = len(line)\nif l < bound:\n  return line\nif bound <= len(rep):\n  return rep\nk = bound - len(rep)\nreturn line[0:k/2] + rep + line[-k/2:]", "path": "apps\\wiki\\yaki\\utils.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"Constructor\"\"\"\n", "func_signal": "def __init__(self, path=\"space\"):\n", "code": "self.path = path\nself.pages={}\nself.aliases={}\nself.dates={}", "path": "apps\\wiki\\yaki\\store.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nA simple time string\n\"\"\"\n", "func_signal": "def plainTime(i18n, value=None):\n", "code": "value = float(value)\nformat = \"%H:%M\"\nif time.gmtime(value)[0] != time.gmtime()[0]:\n  # we have a different year\n  format = \"%Y, \" + format\nformat = i18n[time.strftime(\"%b\",time.gmtime(value))] + \" %d, \" + format\nreturn time.strftime(format, time.gmtime(value))", "path": "apps\\wiki\\yaki\\utils.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "\"\"\"\nSet the wordpress API key for all transactions.\n\nIf you don't specify an explicit API ``key`` and ``blog_url`` it will\nattempt to load them from a file called ``apikey.txt`` in the current\ndirectory.\n\nThis method is *usually* called automatically when you create a new\n``Akismet`` instance.\n\"\"\"\n", "func_signal": "def setAPIKey(self, key=None, blog_url=None):\n", "code": "if key is None and isfile('apikey.txt'):\n    the_file = [l.strip() for l in open('apikey.txt').readlines()\n        if l.strip() and not l.strip().startswith('#')]\n    try:\n        self.key = the_file[0]\n        self.blog_url = the_file[1]\n    except IndexError:\n        raise APIKeyError(\"Your 'apikey.txt' is invalid.\")\nelse:\n    self.key = key\n    self.blog_url = blog_url", "path": "contrib\\utils\\akismet.py", "repo_name": "myles-archive/comfy", "stars": 2, "license": "None", "language": "python", "size": 612}
{"docstring": "# file_input: (NEWLINE | stmt)* ENDMARKER\n", "func_signal": "def _rewrite_file_input(t, state):\n", "code": "if state.future_features:\n    # Ideally, we'd be able to pass in flags to the AST.compile() operation as we can with the\n    # builtin compile() function. Lacking that ability, we just munge an import statement into\n    # the start of the syntax tree\n    return ((symbol.file_input, _create_future_import_statement(state.future_features)) +\n            tuple((_rewrite_stmt(x, state) if x[0] == symbol.stmt else x) for x in t[1:]))\n    \nelse:\n    return _rewrite_tree(t, state, { symbol.stmt: _rewrite_stmt })", "path": "lib\\reinteract\\rewrite.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "\"\"\"End the effect of the previous call to pop\"\"\"\n\n", "func_signal": "def pop(self):\n", "code": "if not isinstance(sys.stdout, _StdoutStack):\n    raise RuntimeError(\"stdout_capture.init() has not been called, or sys.stdout has been overridden again\")\n\nsys.stdout.pop()", "path": "lib\\reinteract\\stdout_capture.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "\"\"\"\nCompiles the parse tree into code, while rewriting the parse tree according to the\noutput_func_name and print_func_name arguments.\n\nAt the same time, the code is scanned for possible mutations, and a list is returned.\nIn the list:\n\n - A string indicates the mutation of a variable by assignment to a slice of it,\n   or to an attribute.\n\n - A tuple of (variable_name, method_name) indicates the invocation of a method\n   on the variable; this will sometimes be a mutation (e.g., list.append(value)),\n   and sometimes not.\n\n@param output_func_name: the name of function used to wrap statements that are simply expressions.\n   (More than one argument will be passed if the statement is in the form of a list.)\n   Can be None.\n\n@param print_func_name: the name of a function used to replace print statements without a destination\n  file. Can be None.\n\n@returns: a tuple of the compiled code followed by a list of mutations\n\"\"\"\n", "func_signal": "def rewrite_and_compile(self, output_func_name=None, print_func_name=None):\n", "code": "state = _RewriteState(output_func_name=output_func_name,\n                      print_func_name=print_func_name,\n                      future_features=self.future_features)\n\nrewritten = _rewrite_file_input(self.original, state)\nencoded = (symbol.encoding_decl, rewritten, self.encoding)\ncompiled = parser.sequence2ast(encoded).compile()\n\nreturn (compiled, state.mutated)", "path": "lib\\reinteract\\rewrite.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "# Not absolutely necessary, but makes things less confusing if we do\n# this between tests\n", "func_signal": "def cleanup_pyc():\n", "code": "for root, dirs, files in os.walk(base, topdown=False):\n    for name in files:\n        if name.endswith(\".pyc\"):\n            os.remove(os.path.join(root, name))", "path": "lib\\reinteract\\notebook.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "# Create a test symbol which is a constant number\n", "func_signal": "def create_constant_test(c):\n", "code": "return (symbol.test,\n        (symbol.and_test,\n         (symbol.not_test,\n          (symbol.comparison,\n           (symbol.expr,\n            (symbol.xor_expr,\n             (symbol.and_expr,\n              (symbol.shift_expr,\n               (symbol.arith_expr,\n                (symbol.term,\n                 (symbol.factor,\n                  (symbol.power,\n                   (symbol.atom,\n                    (token.NUMBER, str(c)))))))))))))))", "path": "lib\\reinteract\\rewrite.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "\"\"\"Initialize the stdout_capture module. This must be called before using the StdoutCapture class\"\"\"\n", "func_signal": "def init():\n", "code": "global _saved_stdout\n_saved_stdout = sys.stdout\nsys.stdout = _StdoutStack()", "path": "lib\\reinteract\\stdout_capture.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "# Check if the given AST is a \"test\" of the form 'v[...]' If it\n# matches, returns v, otherwise returns None\n", "func_signal": "def _is_test_slice(t):\n", "code": "args = _do_match(t, _slice_pattern)\n\nif args == None:\n    return None\nelse:\n    return args['variable']", "path": "lib\\reinteract\\rewrite.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "# Match an AST tree against a pattern. Along with symbol/token names, patterns\n# can contain strings:\n#\n#  '': ignore the matched item\n#  'name': store the matched item into the result dict under 'name'\n#  '*': matches items to the end of the sequence; ignore matched items\n#  '*name': matches items to the end of the sequence; store the matched items as a sequence into the result dict\n#\n# Things following '*\" like ((token.LPAR, ''), '*', (token.RPAR, '')) are not currently\n# supported, but could be if needed\n#\n# Returns None if nothing matched or a dict of key/value pairs\n#\n", "func_signal": "def _do_match(t, pattern):\n", "code": "if (t[0] != pattern[0]):\n    return None\n\nresult = {}\nfor i in (xrange(1, len(pattern))):\n    if i >= len(t):\n        return None\n    if isinstance(pattern[i], tuple):\n        subresult = _do_match(t[i], pattern[i])\n        if subresult == None:\n            return None\n        result.update(subresult)\n    else:\n        if pattern[i] == '':\n            pass\n        elif pattern[i][0] == '*':\n            if pattern[i] != '*':\n                result[pattern[i][1:]] = t[i:]\n        else:\n            result[pattern[i]] = t[i]\n\nreturn result", "path": "lib\\reinteract\\rewrite.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "# Check if the given AST is a \"test\" of the form 'v.m()' If it\n# matches, returns { 'variable': 'v', \"method\": m }, otherwise returns None\n", "func_signal": "def _is_test_method_call(t):\n", "code": "args = _do_match(t, _method_call_pattern)\nif args == None:\n    return None\nelse:\n    return args['variable'], args['method']", "path": "lib\\reinteract\\rewrite.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "# Wrap up a statement (like an expr_stmt) into a file_input, so we can\n# parse/compile it\n", "func_signal": "def create_file_input(s):\n", "code": "return (symbol.file_input,\n        (symbol.stmt,\n         (symbol.simple_stmt,\n          (symbol.small_stmt, s),\n          (token.NEWLINE, '\\n'))),\n        (token.ENDMARKER, '\\n'))", "path": "lib\\reinteract\\rewrite.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "\"\"\"Update the division of the worksheet into chunks based on the current text.\n\nAs the buffer is edited, the division of the buffer into chunks is updated\nblindly without attention to the details of the new text. Normally, we will\nrescan and figure out the real chunks at the end of a user operation, however\nit is occasionally useful to do this early, for example, if we want to use\nthe tokenized representation of a statement for the second part of a user\noperation.\n\n\"\"\"\n\n", "func_signal": "def rescan(self):\n", "code": "_debug(\"  Changed %s,%s (%s), scan_adjacent=%d\", self.__changes.start, self.__changes.end, self.__changes.delta, self.__scan_adjacent)\n\nif self.__changes.empty():\n    return\n\nif self.__scan_adjacent:\n    rescan_start = self.__changes.start\n    rescan_end = self.__changes.end\n\n    while rescan_start > 0:\n        rescan_start -= 1\n        chunk = self.__chunks[rescan_start]\n        if isinstance(chunk, StatementChunk):\n            rescan_start = chunk.start\n            break\n\n    while rescan_end < len(self.__lines):\n        chunk = self.__chunks[rescan_end]\n        # The check for continuation line is needed because the first statement\n        # in a buffer can start with a continuation line\n        if isinstance(chunk, StatementChunk) and \\\n                chunk.start == rescan_end and \\\n                not CONTINUATION_RE.match(self.__lines[chunk.start]):\n            break\n        rescan_end = chunk.end\nelse:\n    rescan_start = self.__changes.start\n    rescan_end = self.__changes.end\n\nself.__changes.clear()\nself.__scan_adjacent = False\n\nif self.__chunks[rescan_start] != None:\n    rescan_start = self.__chunks[rescan_start].start;\nif self.__chunks[rescan_end - 1] != None:\n    rescan_end = self.__chunks[rescan_end - 1].end;\n\n_debug(\"  Rescanning lines %s-%s\", rescan_start, rescan_end)\n\nchunk_start = rescan_start\nstatement_end = rescan_start\nchunk_lines = []\n\nseen_start = False\nfor line in xrange(rescan_start, rescan_end):\n    line_text = self.__lines[line]\n\n    line_class = calc_line_class(line_text)\n    if line_class == BLANK:\n        chunk_lines.append(line_text)\n    elif line_class == COMMENT:\n        chunk_lines.append(line_text)\n    elif line_class == CONTINUATION and seen_start:\n        chunk_lines.append(line_text)\n        statement_end = line + 1\n    else:\n        seen_start = True\n        if len(chunk_lines) > 0:\n            self.__assign_lines(chunk_start, chunk_lines, statement_end)\n        chunk_start = line\n        statement_end = line + 1\n        chunk_lines = [line_text]\n\nself.__assign_lines(chunk_start, chunk_lines, statement_end)", "path": "lib\\reinteract\\worksheet.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "# Creates an 'expr_stmt' that calls a function. args is a list of\n# \"test\" AST's to pass as arguments to the function\n", "func_signal": "def _create_funccall_expr_stmt(name, args):\n", "code": "if len(args) == 0:\n    trailer = (symbol.trailer,\n               (token.LPAR, '('),\n               (token.RPAR, ')'))\nelse:\n    arglist = [ symbol.arglist ]\n    for a in args:\n        if len(arglist) > 1:\n            arglist.append((token.COMMA, ','))\n        arglist.append((symbol.argument, a))\n            \n    trailer = (symbol.trailer,\n               (token.LPAR, ')'),\n               arglist,\n               (token.RPAR, ')'))\n\nreturn _do_create_funccall_expr_stmt(name, trailer)", "path": "lib\\reinteract\\rewrite.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "# small_stmt: (expr_stmt | print_stmt  | del_stmt | pass_stmt | flow_stmt |\n#              import_stmt | global_stmt | exec_stmt | assert_return)\n", "func_signal": "def _rewrite_small_stmt(t, state):\n", "code": "return _rewrite_tree(t, state,\n                     { symbol.expr_stmt:  _rewrite_expr_stmt,\n                       symbol.print_stmt: _rewrite_print_stmt,\n                       symbol.global_stmt: _rewrite_global_stmt })\n\n# Future special handling: import_stmt\n# Not valid: flow_stmt, global_stmt", "path": "lib\\reinteract\\rewrite.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "# expr_stmt: testlist (augassign (yield_expr|testlist) |\n#                      ('=' (yield_expr|testlist))*)\n\n", "func_signal": "def _rewrite_expr_stmt(t, state):\n", "code": "assert(t[0] == symbol.expr_stmt)\nassert(t[1][0] == symbol.testlist)\n\nif len(t) == 2:\n    # testlist\n    subnode = t[1]\n    for i in xrange(1, len(subnode)):\n        subsubnode = subnode[i]\n        if subsubnode[0] == symbol.test:\n            method_spec = _is_test_method_call(subsubnode)\n            if (method_spec != None):\n                state.add_mutated(method_spec)\n\n    if state.output_func_name != None:\n        return _create_funccall_expr_stmt(state.output_func_name, filter(lambda x: type(x) != int and x[0] == symbol.test, subnode))\n    else:\n        return t\nelse:\n    if (t[2][0] == symbol.augassign):\n        # testlist augassign (yield_expr|testlist)\n        subnode = t[1]\n        assert(len(subnode) == 2) # can only augassign one thing, despite the grammar\n        \n        variable = _is_test_slice(subnode[1])\n        if variable == None:\n            variable = _is_test_attribute(subnode[1])\n        \n        if variable != None:\n            state.add_mutated(variable)\n    else:\n        # testlist ('=' (yield_expr|testlist))+\n        for i in xrange(1, len(t) - 1):\n            if (t[i + 1][0] == token.EQUAL):\n                subnode = t[i]\n                assert(subnode[0] == symbol.testlist)\n                for j in xrange(1, len(subnode)):\n                    subsubnode = subnode[j]\n                    if subsubnode[0] == symbol.test:\n                        variable = _is_test_slice(subsubnode)\n                        if variable == None:\n                            variable = _is_test_attribute(subnode[1])\n                            \n                        if variable != None:\n                            state.add_mutated(variable)\n    return t", "path": "lib\\reinteract\\rewrite.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "\"\"\"Returns a list of possible completions at the given position.\n\nEach element in the returned list is a tuple of (display_form,\ntext_to_insert, object_completed_to)' where\nobject_completed_to can be used to determine the type of the\ncompletion or get docs about it.\n\n\"\"\"\n\n", "func_signal": "def find_completions(self, line, offset):\n", "code": "chunk = self.__chunks[line]\nif not isinstance(chunk, StatementChunk) and not isinstance(chunk, BlankChunk):\n    return []\n\nscope = self.__get_last_scope(chunk)\n\nif isinstance(chunk, StatementChunk):\n    return chunk.tokenized.find_completions(line - chunk.start,\n                                            offset,\n                                            scope)\nelse:\n    # A BlankChunk Create a dummy TokenizedStatement to get the completions\n    # appropriate for the start of a line\n    ts = TokenizedStatement()\n    ts.set_lines([''])\n    return ts.find_completions(0, 0, scope)", "path": "lib\\reinteract\\worksheet.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "\"\"\"Mark statements for execution after a change to the given module\"\"\"\n\n", "func_signal": "def module_changed(self, module_name):\n", "code": "for chunk in self.iterate_chunks():\n    if not isinstance(chunk, StatementChunk):\n        continue\n    if chunk.statement == None:\n        continue\n\n    imports = chunk.statement.imports\n    if imports == None:\n        continue\n\n    for module, _ in imports:\n        if module == module_name:\n            self.__mark_rest_for_execute(chunk.start)", "path": "lib\\reinteract\\worksheet.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "# stmt: simple_stmt | compound_stmt\n", "func_signal": "def _rewrite_stmt(t, state):\n", "code": "return _rewrite_tree(t, state,\n                     { symbol.simple_stmt:   _rewrite_simple_stmt,\n                       symbol.compound_stmt: _rewrite_compound_stmt })", "path": "lib\\reinteract\\rewrite.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "# Get the last result scope we have that precedes the specified chunk\n\n", "func_signal": "def __get_last_scope(self, chunk):\n", "code": "scope = None\nline = chunk.start - 1\nwhile line >= 0:\n    previous_chunk = self.__chunks[line]\n\n    # We intentionally don't check \"needs_execute\" ... if there is a result scope,\n    # it's fair game for completion/help, even if it's old\n    if isinstance(previous_chunk, StatementChunk) and previous_chunk.statement != None and previous_chunk.statement.result_scope != None:\n        return previous_chunk.statement.result_scope\n        break\n\n    line = previous_chunk.start - 1\n\nreturn self.global_scope", "path": "lib\\reinteract\\worksheet.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "# Delete an integral number of lines, fixing up the affected chunks\n# and the __chunks[]/__lines[] arrays\n\n", "func_signal": "def __delete_lines(self, start_line, end_line):\n", "code": "if end_line == start_line: # No lines deleted\n    return\n\nfor chunk in self.iterate_chunks(start_line):\n    if chunk.start >= end_line:\n        chunk.start -= (end_line - start_line)\n        chunk.end -= (end_line - start_line)\n    elif chunk.start >= start_line:\n        if chunk.end <= end_line:\n            self.__remove_chunk(chunk)\n        else:\n            chunk.delete_lines(chunk.start, end_line)\n            self.__chunk_changed(chunk)\n            chunk.end -= chunk.start - start_line\n            chunk.start = start_line\n    else:\n        chunk.delete_lines(start_line, chunk.start)\n        self.__chunk_changed(chunk)\n\nself.__lines[start_line:end_line] = ()\nself.__chunks[start_line:end_line] = ()\n\nself.__changes.delete_range(start_line, end_line)\nself.__scan_adjacent = True\nself.emit('lines-deleted', start_line, end_line)", "path": "lib\\reinteract\\worksheet.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "# Holding the import lock around the whole import process matches what\n# Python does internally. This does mean that the machinery of loading a slow\n# import blocks the import of an already loaded module in a different thread.\n# You could imagine trying to do the lookup without the lock and locking only\n# for loading, but ensuring the safety of that would be quite complex\n", "func_signal": "def do_import(self, name, globals=None, locals=None, fromlist=None, level=None):\n", "code": "imp.acquire_lock()\ntry:\n    names = name.split('.')\n\n    module, local =  self.__import_recurse(names)\n\n    if fromlist != None:\n        # In 'from a.b import c', if a.b.c doesn't exist after loading a.b, The built-in\n        # __import__ will try to load a.b.c as a module; do the same here.\n        for fromname in fromlist:\n            if fromname == \"*\":\n                try:\n                    all = getattr(module, \"__all__\")\n                    for allname in all:\n                        self.__ensure_from_list_item(name, allname, module, local)\n                except AttributeError:\n                    pass\n            else:\n                self.__ensure_from_list_item(name, fromname, module, local)\n\n        return module\n    elif local:\n        return self.__modules[names[0]]\n    else:\n        return sys.modules[names[0]]\nfinally:\n    imp.release_lock()", "path": "lib\\reinteract\\notebook.py", "repo_name": "jonkuhn/reinteract-jk", "stars": 3, "license": "bsd-2-clause", "language": "python", "size": 724}
{"docstring": "\"\"\"Append a Shader to the Program.\n\n\"\"\"\n", "func_signal": "def append(self, shader):\n", "code": "list.append(self, shader)\n\nif self.bound:\n    self.bind()", "path": "scikits\\gpu\\shader.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Query OpenGL for a list of active uniforms.\n\nThis is needed, because we are only allowed to set and query the\nvalues of active uniforms.\n\n\"\"\"\n# Query number of active uniforms\n", "func_signal": "def active_uniforms(self):\n", "code": "nr_uniforms = gl.GLint()\ngl.glGetProgramiv(self.handle, gl.GL_ACTIVE_UNIFORMS,\n                  byref(nr_uniforms))\nnr_uniforms = nr_uniforms.value\n\nlength = gl.GLsizei()\nsize = gl.GLsizei()\nenum = gl.GLenum()\nname = create_string_buffer(self._ACTIVE_UNIFORM_MAX_LENGTH)\n\nuniforms = []\nfor i in range(nr_uniforms):\n    gl.glGetActiveUniform(self.handle, i, 20, byref(length), byref(size),\n                          byref(enum), name)\n    uniforms.append(name.value)\n\nreturn uniforms", "path": "scikits\\gpu\\shader.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Bind the program into the rendering pipeline.\n\n\"\"\"\n", "func_signal": "def use(self):\n", "code": "if not self.linked:\n    self._link()\n\n# bind the program\ngl.glUseProgram(self.handle)\nself.bound = True", "path": "scikits\\gpu\\shader.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Add texture image to the framebuffer object.\n\nParameters\n----------\nshape : tuple of ints\n    Dimension of framebuffer.  Note that for earlier versions\n    of OpenGL, height and width dimensions must be a power of\n    two.  Valid shapes include (16,), (16, 17), (16, 16, 3).\ndtype : opengl data-type, e.g. GL_FLOAT, GL_UNSIGNED_BYTE\n\nReturns\n-------\nslot : int\n    The slot number to which the texture was bound.  E.g., in the\n    case of GL_COLOR_ATTACHMENT3_EXT, returns 3.\n\n\"\"\"\n", "func_signal": "def add_texture(self, shape, dtype=gl.GL_FLOAT):\n", "code": "if dtype != gl.GL_FLOAT:\n    warnings.warn(\"While OpenGL < 3.0 implementations allow the \"\n                  \"storage of textures with data-types other \"\n                  \"than FLOAT, gl_FragColor only accepts \"\n                  \"assigned a floating point value.  In OpenGL 3.0 \"\n                  \"this can be changed (see READING.txt).\",\n                  RuntimeWarning)\n\nif len(self._textures) >= MAX_COLOR_ATTACHMENTS:\n    raise RuntimeError(\"Maximum number of textures reached.  This \"\n                       \"platform supports %d attachments.\" % \\\n                       MAX_COLOR_ATTACHMENTS)\n\nslot = getattr(gl, \"GL_COLOR_ATTACHMENT%d_EXT\" % len(self._textures))\n\nwidth, height, bands = _shape_to_3d(shape)\n\nif bands > 4:\n    raise ValueError(\"Texture cannot have more than 4 colour layers.\")\n\ncolour_bands = {1: gl.GL_LUMINANCE,\n                2: gl.GL_LUMINANCE_ALPHA,\n                3: gl.GL_RGB,\n                4: gl.GL_RGBA}\n\n# allocate a texture and add to the frame buffer\ntex = Texture(width, height,\n              format=colour_bands[bands],\n              dtype=dtype,\n              internalformat=gl.GL_RGB32F_ARB,\n              )\n\ngl.glBindTexture(tex.target, tex.id)\ngl.glFramebufferTexture2DEXT(gl.GL_FRAMEBUFFER_EXT,\n                             gl.GL_COLOR_ATTACHMENT0_EXT,\n                             tex.target, tex.id, 0)\nif (gl.glGetError() != gl.GL_NO_ERROR):\n    raise RuntimeError(\"Could not create framebuffer texture.\")\n\nstatus = gl.glCheckFramebufferStatusEXT(gl.GL_FRAMEBUFFER_EXT)\nif not (status == gl.GL_FRAMEBUFFER_COMPLETE_EXT):\n    raise RuntimeError(\"Could not set up framebuffer.\")\n\nself._textures.append(tex)\nreturn len(self._textures) - 1", "path": "scikits\\gpu\\framebuffer.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Get uniform value.\n\n\"\"\"\n", "func_signal": "def __getitem__(self, var):\n", "code": "loc, container, container_nested, dtype = \\\n     self._uniform_loc_storage_and_type(var)\nvar_info = self._uniform_type_info[var]\ndata = container_nested()\n\nif dtype == gl.GLint:\n    get_func = gl.glGetUniformiv\nelse:\n    get_func = gl.glGetUniformfv\n\nalen = var_info['array']\nfor i in range(alen):\n    if i > 0:\n        # Query the location of each array element\n        loc = gl.glGetUniformLocation(self.handle, var + '[%d]' % i)\n\n    assert loc != -1\n\n    get_func(self.handle, loc, data[i])\n\n# Convert to a NumPy array for easier processing\ndata = np.array(data)\n\n# Scalar\nif data.size == 1:\n    return data[0]\n# Array, matrix, vector\nelif var_info['kind'] == 'mat':\n    count, n_sqr = data.shape\n    n = np.sqrt(n_sqr)\n\n    data = data.reshape((count, n, n), order='F')\n\nreturn data", "path": "scikits\\gpu\\shader.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Return the uniform location and a container that can\nstore its value.\n\nParameters\n----------\nvar : string\n    Uniform name.\n\n\"\"\"\n", "func_signal": "def _uniform_loc_storage_and_type(self, var):\n", "code": "if var not in self.active_uniforms:\n    raise GLSLError(\"Uniform '%s' is not active.  Make sure the \"\n                    \"variable is used in the source code.\" % var)\n\ntry:\n    var_info = self._uniform_type_info[var]\nexcept KeyError:\n    raise ValueError(\"Uniform variable '%s' is not defined in \"\n                     \"shader source.\" % var)\n\n# If this is an array, how many values are involved?\ncount = var_info['array']\n\nif var_info['kind'] in ['int']:\n    data_type = gl.GLint\nelse:\n    data_type = gl.GLfloat\n\nassert gl.glIsProgram(self.handle) == True\nassert self.linked\n\nloc = gl.glGetUniformLocation(self.handle, var)\n\nif loc == -1:\n    raise RuntimeError(\"Could not query uniform location \"\n                       \"for '%s'.\" % var)\n\nstorage = data_type * (count * var_info['size'])\nstorage_nested = count * (data_type * var_info['size'])\n\nreturn loc, storage, storage_nested, data_type", "path": "scikits\\gpu\\shader.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Returns the hardware-specific target to render textures to.  For\nnon-power-of-two textures, an OpenGL extension is required.\n\nParameters\n----------\nx, y : int\n    Dimensions of the texture to be rendered.\n\n\"\"\"\n", "func_signal": "def texture_target(height, width):\n", "code": "def power_of_two(n):\n    f = math.log(n, 2)\n    return f == math.floor(f)\n\nif power_of_two(height) and power_of_two(width):\n    return gl.GL_TEXTURE_2D\nelif gl.gl_info.have_extension('GL_ARB_texture_rectangle'):\n    return gl.GL_TEXTURE_RECTANGLE_ARB\nelse:\n    raise HardwareSupportError(\"Hardware does not support non-power-of-two\"\n                               \" textures.\")", "path": "scikits\\gpu\\texture.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Determine the numeric types of uniform variables.\n\nUpdates the internal dictionary _uniform_type_info[var] with:\n\nkind : {'mat', 'vec', 'int', 'float'}\n    The kind of numeric type.\nsize : {2, 3, 4}\n    The size of the type, e.g., 4 for vec4, 4 for mat2, 1 for scalar.\narray : bool\n    Whether the variable is defined as an array, e.g.,\n    uniform vec4 x[]; ==> true.\n\n\"\"\"\n", "func_signal": "def _update_uniform_types(self):\n", "code": "source = \";\".join([s.source for s in self])\n\n# And look at each statement individually\nsource = [s.strip() for s in source.split(';')]\n\n# Now look only at uniform declarations\nsource = [s[len('uniform')+1:] for s in source if s.startswith('uniform')]\n\ntypes = [desc_name.split(' ')[:2] for desc_name in source]\n\n# Handle declarations of the form uniform float f=3.0\ntypes = [(desc, name.split('=')[0]) for (desc, name) in types]\n\ntype_info = {}\n\nfor desc, name in types:\n    # Check for vector type, e.g. float x[12]\n    name_array = name.split('[')\n    var_name = name_array[0]\n\n    # If array size is specified, see what it is\n    if len(name_array) > 1:\n        array_size = name_array[1].split(']')[0].strip()\n        if not array_size:\n            raise RuntimeError(\"Array declaration without size is not \"\n                               \"supported.\")\n\n        array_size = int(array_size)\n    else:\n        array_size = 1\n\n    # Check if type is, e.g., vec3\n    vec_param = desc[-1]\n    if vec_param.isdigit():\n        size = int(vec_param)\n        desc = desc[:-1]\n    else:\n        size = 1\n\n    # For a square matrix, we have the side dimension.  To get\n    # the size, we need to square that.\n    if desc == 'mat':\n        size *= size\n\n    var_info = {\n        'kind': desc,\n        'size': size,\n        'array': array_size}\n\n    if type_info.has_key(var_name) and \\\n           type_info[var_name] != var_info:\n        raise GLSLError(\"Inconsistent definition of variable '%s'.\" % \\\n                        var_name)\n    else:\n        type_info[var_name] = var_info\n\nself._uniform_type_info = type_info", "path": "scikits\\gpu\\shader.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Decorator: Execute this function if and only if the program is in use.\n\n\"\"\"\n", "func_signal": "def if_in_use(f):\n", "code": "def execute_if_in_use(self, *args, **kwargs):\n    if not self.bound:\n        raise GLSLError(\"Shader is not bound.  Cannot execute assignment.\")\n\n    f(self, *args, **kwargs)\n\nfor attr in [\"func_name\", \"__name__\", \"__dict__\", \"__doc__\"]:\n    setattr(execute_if_in_use, attr, getattr(f, attr))\n\nreturn execute_if_in_use", "path": "scikits\\gpu\\shader.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Set the FBO as the active rendering buffer.\n\n\"\"\"\n", "func_signal": "def bind(self):\n", "code": "if self.id:\n    gl.glBindFramebufferEXT(gl.GL_FRAMEBUFFER_EXT, self.id)\nelse:\n    raise RuntimeError(\"Cannot bind to deleted framebuffer.\")", "path": "scikits\\gpu\\framebuffer.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"\nVertex, Fragment, or Geometry shader.\n\nParameters\n----------\nsource : string or list\n    String or list of strings.  The GLSL source code for the shader.\ntype : {'vertex', 'fragment', 'geometry'}\n    Type of shader.\n\n\"\"\"\n", "func_signal": "def __init__(self, source=\"\", type='vertex'):\n", "code": "shader_type = {'vertex': gl.GL_VERTEX_SHADER,\n               'fragment': gl.GL_FRAGMENT_SHADER,}\n##             'geometry': gl.GL_GEOMETRY_SHADER}\n\nif isinstance(source, basestring):\n    source = [source]\n\ncount = len(source)\n# if we have no source code, ignore this shader\nif count < 1:\n    raise GLSLError(\"No GLSL source provided.\")\n\n# create the shader handle\nshader = gl.glCreateShader(shader_type[type])\n\n# convert the source strings into a ctypes pointer-to-char array,\n# and upload them.  This is deep, dark, dangerous black magick -\n# don't try stuff like this at home!\nsrc = (c_char_p * count)(*source)\ngl.glShaderSource(shader, count,\n                  cast(pointer(src), POINTER(POINTER(c_char))),\n               None)\n\n# compile the shader\ngl.glCompileShader(shader)\n\ntemp = c_int(0)\n# retrieve the compile status\ngl.glGetShaderiv(shader, gl.GL_COMPILE_STATUS, byref(temp))\n\n# if compilation failed, print the log\nif not temp:\n    # retrieve the log length\n    gl.glGetShaderiv(shader, gl.GL_INFO_LOG_LENGTH, byref(temp))\n    # create a buffer for the log\n    buffer = create_string_buffer(temp.value)\n    # retrieve the log text\n    gl.glGetShaderInfoLog(shader, temp, None, buffer)\n    # print the log to the console\n    raise GLSLError(buffer.value)\n\nself.handle = shader\nself.source = \"\\n\".join(source)", "path": "scikits\\gpu\\shader.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Return a shape with 3-dimensions, even if lower dimensional\nshape is provided.\n\n>>> _shape_to_3d([5])\n[5, 1, 1]\n\n>>> _shape_to_3d([5, 2])\n[5, 2, 1]\n\n>>> _shape_to_3d([5, 3, 1])\n[5, 3, 1]\n\n>>> try:\n...     _shape_to_3d([5, 3, 3, 1])\n... except ValueError:\n...     pass\n\n\"\"\"\n", "func_signal": "def _shape_to_3d(shape):\n", "code": "shape = list(shape)\nL = len(shape)\n\nif L > 3:\n    raise ValueError(\"Shape cannot be higher than 3-dimensional.\")\n\nshape += [1,]*(3 - L)\n\nreturn shape", "path": "scikits\\gpu\\framebuffer.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Generate a pass-through VertexShader.\n\n\"\"\"\n", "func_signal": "def default_vertex_shader():\n", "code": "return VertexShader(\"\"\"\n       varying vec2 vertex;\n\n       void main(void) {\n           vertex.xy = gl_Vertex.xy;\n           gl_Position = ftransform();\n       }\"\"\")", "path": "scikits\\gpu\\shader.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Fill the screen with the specified shade of grey.\n\n\"\"\"\n", "func_signal": "def whitewash(level=1.0):\n", "code": "return default_vertex_shader(), \\\n       FragmentShader(\"\"\"\n       void main(void)\n       { gl_FragColor = vec4(%(level)s, %(level)s, %(level)s, 1.0); }\"\"\" % \\\n                      {'level': level})", "path": "examples\\zoo.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"For a given OpenGL type, such as GL_BYTE, return the corresponding\nctypes data-type, in this case c_ubyte.  If type is a ctype, it is simply\npassed through.\n\nParameters\n----------\nT : OpenGL type or ctype.\n\nReturns\n-------\ntype : ctype\n    The ctype corresponding to `T`.\n\n\n\"\"\"\n", "func_signal": "def memory_type(T):\n", "code": "if isinstance(T, type):\n    return T\nelif isinstance(T, int):\n    return opengl_ctypes[T]\nelse:\n    raise ValueError(\"Cannot convert provided type to ctype.\")", "path": "scikits\\gpu\\ntypes.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Return shaders for generating Mandelbrot fractals.\n\nGLSL code based on http://nuclear.sdf-eu.org/articles/sdr_fract\nby John Tsiombikas\n\nUniforms\n--------\noffset : vec2\n    Position at which the fractal is calculated.\nwidth_ratio : float\n    The aspect ratio of the screen: width/height.\nzoom : float\n    Zoom factor.\n\n\"\"\"\n", "func_signal": "def mandelbrot():\n", "code": "v = VertexShader(\"\"\"\nuniform vec2 offset;\nuniform float zoom;\nuniform float width_ratio;\n\nvarying vec2 pos;\n\nvoid main(void) {\n    pos.x = gl_Vertex.x * width_ratio / zoom + offset.x;\n    pos.y = gl_Vertex.y / zoom + offset.y;\n    gl_Position = ftransform();\n}\n\"\"\")\n\nf = FragmentShader(\"\"\"\nvarying vec2 pos;\n\nvoid main(void) {\n    int j;\n    float k;\n    float r = 0.0, i = 0.0;\n    float a, b;\n    for (k = 0.0; k < 1.0; k += 0.005) {\n        a = r*r - i*i + pos.x;\n        b = 2*r*i + pos.y;\n\n        if ((a*a + b*b) > 4) break;\n\n        r = a;\n        i = b;\n    }\n\n    gl_FragColor = vec4(k, 3*sin(k), sin(k*3.141/2.), 1.0);\n}\n\"\"\")\n\nreturn v, f", "path": "examples\\zoo.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Fill the screen with checkered blocks.\n\n\"\"\"\n", "func_signal": "def checker():\n", "code": "v = VertexShader(\"\"\"\nvarying vec2 pos;\n\nvoid main(void) {\n    pos.xy = gl_Vertex.xy;\n    gl_Position = ftransform();\n}\"\"\")\n\nf = FragmentShader(\"\"\"\nvarying vec2 pos;\n\nvoid main(void) {\n    if (fract(pos.x * 5) > 0.5)\n        pos.y += 0.5;\n\n    if (fract(pos.y * 5) > 0.5) {\n        gl_FragColor = vec4(0, 0, 0, 1);\n    } else {\n        gl_FragColor = vec4(1, 1, 1, 1);\n    }\n}\n\"\"\")\n\nreturn v, f", "path": "examples\\zoo.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Framebuffer Object (FBO) for off-screen rendering.\n\nA framebuffer object contains one or more\nframebuffer-attachable images.  These can be either\nrenderbuffers or texture images.\n\nFor now the framebuffer object handles only textures.\n\n\"\"\"\n## Create a framebuffer object\n", "func_signal": "def __init__(self):\n", "code": "framebuffer = gl.GLuint()\ngl.glGenFramebuffersEXT(1, ctypes.byref(framebuffer))\ngl.glBindFramebufferEXT(gl.GL_FRAMEBUFFER_EXT, framebuffer)\n\nself.id = framebuffer\nself.MAX_COLOR_ATTACHMENTS = MAX_COLOR_ATTACHMENTS\n\nself._textures = []", "path": "scikits\\gpu\\framebuffer.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "# Draw full-screen canvas\n", "func_signal": "def draw_canvas():\n", "code": "gl.glDrawBuffer(gl.GL_COLOR_ATTACHMENT0_EXT)\ngl.glBegin(gl.GL_QUADS)\nfor coords in [(-1.0, -1.0),\n               (1.0, -1.0),\n               (1.0, 1.0),\n               (-1.0,  1.0)]:\n    gl.glVertex3f(coords[0], coords[1], 0.0)\n\ngl.glEnd()", "path": "examples\\shader_offscreen.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"Delete the framebuffer from the graphics card's memory.\n\n\"\"\"\n", "func_signal": "def __del__(self):\n", "code": "self.unbind()\nif self.id:\n    gl.glDeleteFramebuffersEXT(1, self.id)\n    self.id = None", "path": "scikits\\gpu\\framebuffer.py", "repo_name": "certik/scikits.gpu", "stars": 2, "license": "other", "language": "python", "size": 140}
{"docstring": "\"\"\"\nRead the next lexical token from the stream and return a\ntuple (value, text), where |value| is the value associated with\nthe token as specified by the Lexicon, and |text| is the actual\nstring read from the stream. Returns (None, '') on end of file.\n\"\"\"\n", "func_signal": "def read(self):\n", "code": "queue = self.queue\nwhile not queue:\n    self.text, action = self.scan_a_token()\n    if action is None:\n        self.produce(None)\n        self.eof()\n    else:\n        value = action.perform(self, self.text)\n        if value is not None:\n            self.produce(value)\nresult = queue[0]\ndel queue[0]\nreturn result", "path": "Plex\\Scanners.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "#print \"Destroying\", self ###\n", "func_signal": "def destroy(self):\n", "code": "self.transitions = None\nself.action = None\nself.epsilon_closure = None", "path": "Plex\\Machines.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nGiven a state |s| of machine |m|, return a new state\nreachable from |s| on character |c| or epsilon.\n\"\"\"\n", "func_signal": "def build_opt(self, m, initial_state, c):\n", "code": "s = m.new_state()\ninitial_state.link_to(s)\ninitial_state.add_transition(c, s)\nreturn s", "path": "Plex\\Regexps.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nRun the machine until no more transitions are possible.\n\"\"\"\n", "func_signal": "def run_machine(self):\n", "code": "self.state = self.initial_state\nself.backup_state = None\nwhile self.transition():\n    pass\nreturn self.back_up()", "path": "Plex\\Scanners.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nGiven a list of codes as returned by chars_to_ranges, return\nan RE which will match a character in any of the ranges.\n\"\"\"\n", "func_signal": "def CodeRanges(code_list):\n", "code": "re_list = []\nfor i in xrange(0, len(code_list), 2):\n    re_list.append(CodeRange(code_list[i], code_list[i + 1]))\nreturn Alt(*re_list)", "path": "Plex\\Regexps.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"Return a list of character codes consisting of pairs [code1a, code1b,\ncode2a, code2b,...] which cover all the characters in |s|.\n\"\"\"\n", "func_signal": "def chars_to_ranges(s):\n", "code": "char_list = list(s)\nchar_list.sort()\ni = 0\nn = len(char_list)\nresult = []\nwhile i < n:\n    code1 = ord(char_list[i])\n    code2 = code1 + 1\n    i = i + 1\n    while i < n and code2 >= ord(char_list[i]):\n        code2 = code2 + 1\n        i = i + 1\n    result.append(code1)\n    result.append(code2)\nreturn result", "path": "Plex\\Regexps.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nRecursively add to |state_set| states reachable from the given state\nby epsilon moves.\n\"\"\"\n", "func_signal": "def add_to_epsilon_closure(state_set, state):\n", "code": "if not state_set.get(state, 0):\n    state_set[state] = 1\n    state_set_2 = state.transitions.get_epsilon()\n    if state_set_2:\n        for state2 in state_set_2.keys():\n            add_to_epsilon_closure(state_set, state2)", "path": "Plex\\DFA.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nStr1(s) is an RE which matches the literal string |s|.\n\"\"\"\n", "func_signal": "def Str1(s):\n", "code": "result = apply(Seq, tuple(map(Char, s)))\nresult.str = \"Str(%s)\" % repr(s)\nreturn result", "path": "Plex\\Regexps.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "# Sequences 'bol bol' and 'bol eof' are impossible, so only need\n# to allow for bol if sym is eol\n", "func_signal": "def build_machine(self, m, initial_state, final_state, match_bol, nocase):\n", "code": "if match_bol and self.sym == EOL:\n    initial_state = self.build_opt(m, initial_state, BOL)\ninitial_state.add_transition(self.sym, final_state)", "path": "Plex\\Regexps.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "# Preinitialise the list of empty transitions, because\n# the nfa-to-dfa algorithm needs it\n#self.transitions = {'':[]}\n", "func_signal": "def __init__(self):\n", "code": "self.transitions = TransitionMap()\nself.action = None # Action\nself.number = 0 # for debug output\nself.action_priority = LOWEST_PRIORITY\nself.epsilon_closure = None # used by nfa_to_dfa()", "path": "Plex\\Machines.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nGiven a nondeterministic Machine, return a new equivalent\nMachine which is deterministic.\n\"\"\"\n# We build a new machine whose states correspond to sets of states\n# in the old machine. Initially we add a new state corresponding to\n# the epsilon-closure of each initial old state. Then we give transitions\n# to each new state which are the union of all transitions out of any\n# of the corresponding old states. The new state reached on a given\n# character is the one corresponding to the set of states reachable\n# on that character from any of the old states. As new combinations of\n# old states are created, new states are added as needed until closure\n# is reached.\n", "func_signal": "def nfa_to_dfa(old_machine, debug = None):\n", "code": "new_machine = Machines.FastMachine()\nstate_map = StateMap(new_machine)\n# Seed the process using the initial states of the old machine.\n# Make the corresponding new states into initial states of the new\n# machine with the same names.\nfor (key, old_state) in old_machine.initial_states.items():\n    new_state = state_map.old_to_new(epsilon_closure(old_state))\n    new_machine.make_initial_state(key, new_state)\n# Tricky bit here: we add things to the end of this list while we're\n# iterating over it. The iteration stops when closure is achieved.\nfor new_state in new_machine.states:\n    transitions = TransitionMap()\n    for old_state in state_map.new_to_old(new_state).keys():\n        for event, old_target_states in old_state.transitions.items():\n            if event and old_target_states:\n                transitions.add_set(event, set_epsilon_closure(old_target_states))\n    for event, old_states in transitions.items():\n        new_machine.add_transitions(new_state, event, state_map.old_to_new(old_states))\nif debug:\n    debug.write(\"\\n===== State Mapping =====\\n\")\n    state_map.dump(debug)\nreturn new_machine", "path": "Plex\\DFA.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"Set the current state of the scanner to the named state.\"\"\"\n", "func_signal": "def begin(self, state_name):\n", "code": "self.initial_state = (\n    self.lexicon.get_initial_state(state_name))\nself.state_name = state_name", "path": "Plex\\Scanners.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nReturn the set of states reachable from the given state\nby epsilon moves.\n\"\"\"\n# Cache the result\n", "func_signal": "def epsilon_closure(state):\n", "code": "result = state.epsilon_closure\nif result is None:\n    result = {}\n    state.epsilon_closure = result\n    add_to_epsilon_closure(result, state)\nreturn result", "path": "Plex\\DFA.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"Make this an accepting state with the given action. If\nthere is already an action, choose the action with highest\npriority.\"\"\"\n", "func_signal": "def set_action(self, action, priority):\n", "code": "if priority > self.action_priority:\n    self.action = action\n    self.action_priority = priority", "path": "Plex\\Machines.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"Add a new state to the machine and return it.\"\"\"\n", "func_signal": "def new_state(self):\n", "code": "s = Node()\ns.number = self.next_state_number\nself.states.append(s)\n\nself.next_state_number += 1\nreturn s", "path": "Plex\\Machines.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nOpt(re) is an RE which matches either |re| or the empty string.\n\"\"\"\n", "func_signal": "def Opt(re):\n", "code": "result = Alt(re, Empty)\nresult.str = \"Opt(%s)\" % re\nreturn result", "path": "Plex\\Regexps.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nGiven a set of states, return the union of the epsilon\nclosures of its member states.\n\"\"\"\n", "func_signal": "def set_epsilon_closure(state_set):\n", "code": "result = {}\nfor state1 in state_set.keys():\n    for state2 in epsilon_closure(state1).keys():\n        result[state2] = 1\nreturn result", "path": "Plex\\DFA.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nIf the range of characters from code1 to code2-1 includes any\nlower case letters, return the corresponding upper case range.\n\"\"\"\n", "func_signal": "def uppercase_range(code1, code2):\n", "code": "code3 = max(code1, ord('a'))\ncode4 = min(code2, ord('z') + 1)\nif code3 < code4:\n    d = ord('A') - ord('a')\n    return (code3 + d, code4 + d)\nelse:\n    return None", "path": "Plex\\Regexps.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nScanner(lexicon, stream, name = '')\n\n    |lexicon| is a Plex.Lexicon instance specifying the lexical tokens\n    to be recognised.\n\n    |stream| can be a file object or anything which implements a\n    compatible read() method.\n\n    |name| is optional, and may be the name of the file being\n    scanned or any other identifying string.\n\"\"\"\n", "func_signal": "def __init__(self, lexicon, stream, name=''):\n", "code": "self.lexicon = lexicon\nself.stream = stream\nself.name = name\nself.queue = []\nself.initial_state = None\nself.begin('')\nself.next_pos = 0\nself.cur_pos = 0\nself.cur_line_start = 0\nself.cur_char = BOL\nself.input_state = 1", "path": "Plex\\Scanners.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nIf the range of characters from code1 to code2-1 includes any\nupper case letters, return the corresponding lower case range.\n\"\"\"\n", "func_signal": "def lowercase_range(code1, code2):\n", "code": "code3 = max(code1, ord('A'))\ncode4 = min(code2, ord('Z') + 1)\nif code3 < code4:\n    d = ord('a') - ord('A')\n    return (code3 + d, code4 + d)\nelse:\n    return None", "path": "Plex\\Regexps.py", "repo_name": "kylev/plex-clean", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "#Forgot password form and it's processing\n", "func_signal": "def forgot(request):\n", "code": "return password_reset(request,\n                      template_name='resetpassword/form.html',\n                      email_template_name= 'resetpassword/email.html',\n                      post_reset_redirect='/forgot/done/')", "path": "testsite\\mainapp\\views.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nCheck and return the next physical line. This method can be\nused to feed tokenize.generate_tokens.\n\"\"\"\n", "func_signal": "def readline_check_physical(self):\n", "code": "line = self.readline()\nif line:\n    self.check_physical(line)\nreturn line", "path": "testsite\\pep8.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nJCR: The last line should have a newline.\n\"\"\"\n", "func_signal": "def missing_newline(physical_line):\n", "code": "if physical_line.rstrip() == physical_line:\n    return len(physical_line), \"W292 no newline at end of file\"", "path": "testsite\\pep8.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nJCR: Each comma, semicolon or colon should be followed by whitespace.\n\"\"\"\n", "func_signal": "def missing_whitespace(logical_line):\n", "code": "line = logical_line\nfor index in range(len(line) - 1):\n    char = line[index]\n    if char in ',;:' and line[index + 1] != ' ':\n        before = line[:index]\n        if char == ':' and before.count('[') > before.count(']'):\n            continue # Slice syntax, no space required\n        return index, \"E231 missing whitespace after '%s'\" % char", "path": "testsite\\pep8.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "#User register as new user and login to his account\n", "func_signal": "def test_register_and_login():\n", "code": "url = SITE_URL+\"/register/\"\nLogin = \"aleksey2\"\nPassword = \"aleksey2\"\nEmail = \"aleksey2@aleksey2.com\"\ngo(url)\nformclear('1')\nfv(\"1\", \"UserLogin\", Login)\nfv(\"1\", \"UserPassword\", Password)\nfv(\"1\", \"UserEmail\", Email)\nsubmit()\nfind(\"been registered\", \"m\")\n\nurl = SITE_URL+\"/login/\"\ngo(url)\nformclear('1')\nfv(\"1\", \"UserLogin\", Login)\nfv(\"1\", \"UserPassword\", Password)\nsubmit()\nfind(\"Valid\", \"m\")", "path": "tests.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nRun all checks on a Python source file.\n\"\"\"\n", "func_signal": "def input_file(filename):\n", "code": "if excluded(filename) or not filename_match(filename):\n    return {}\nif options.verbose:\n    message('checking ' + filename)\noptions.counters['files'] = options.counters.get('files', 0) + 1\nerrors = Checker(filename).check_all()\nif options.testsuite and not errors:\n    message(\"%s: %s\" % (filename, \"no errors found\"))", "path": "testsite\\pep8.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "#User try to login with incorrect username\n", "func_signal": "def test_login_incorrect_username():\n", "code": "url = SITE_URL+\"/login/\"\ngo(url)\nformclear('1')\nfv(\"1\", \"UserLogin\", \"1aleksey\")\nfv(\"1\", \"UserPassword\", \"1\")\nsubmit()\nfind(\"wrong login\", \"m\")", "path": "tests.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nCheck all Python source files in this directory and all subdirectories.\n\"\"\"\n", "func_signal": "def input_dir(dirname):\n", "code": "dirname = dirname.rstrip('/')\nif excluded(dirname):\n    return\nfor root, dirs, files in os.walk(dirname):\n    if options.verbose:\n        message('directory ' + root)\n    options.counters['directories'] = \\\n        options.counters.get('directories', 0) + 1\n    dirs.sort()\n    for subdir in dirs:\n        if excluded(subdir):\n            dirs.remove(subdir)\n    files.sort()\n    for filename in files:\n        input_file(os.path.join(root, filename))", "path": "testsite\\pep8.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nCompound statements (multiple statements on the same line) are\ngenerally discouraged.\n\"\"\"\n", "func_signal": "def compound_statements(logical_line):\n", "code": "line = logical_line\nfound = line.find(':')\nif -1 < found < len(line) - 1:\n    before = line[:found]\n    if (before.count('{') <= before.count('}') and # {'a': 1} (dict)\n        before.count('[') <= before.count(']') and # [1:2] (slice)\n        not re.search(r'\\blambda\\b', before)):     # lambda x: x\n        return found, \"E701 multiple statements on one line (colon)\"\nfound = line.find(';')\nif -1 < found:\n    return found, \"E702 multiple statements on one line (semicolon)\"", "path": "testsite\\pep8.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "#User try to login with incorrect password\n", "func_signal": "def test_login_incorrect_password():\n", "code": "url = SITE_URL+\"/login/\"\ngo(url)\nformclear('1')\nfv(\"1\", \"UserLogin\", \"aleksey\")\nfv(\"1\", \"UserPassword\", \"11\")\nsubmit()\nfind(\"wrong password\", \"m\")", "path": "tests.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nRun all physical checks on a raw input line.\n\"\"\"\n", "func_signal": "def check_physical(self, line):\n", "code": "self.physical_line = line\nif self.indent_char is None and len(line) and line[0] in ' \\t':\n    self.indent_char = line[0]\nfor name, check, argument_names in self.physical_checks:\n    result = self.run_check(check, argument_names)\n    if result is not None:\n        offset, text = result\n        self.report_error(self.line_number, offset, text, check)", "path": "testsite\\pep8.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "#Login page\n", "func_signal": "def login(request):\n", "code": "Content = {}\nContent[\"CustomErrors\"] = []\nif request.method == 'POST':\n    form = LoginForm(request.POST)\n    if form.is_valid():\n        try:\n            #Check for user login\n            User.objects.get(\n                username__exact=form.cleaned_data['UserLogin'])\n        except:\n            #Wrong login\n            Content[\"CustomErrors\"].append(\"You've entered wrong login.\")\n        else:\n            user = authenticate(username=form.cleaned_data['UserLogin'],\n            password=form.cleaned_data['UserPassword'])\n            if user is None:\n                #Wrong password\n                Content[\"CustomErrors\"].\\\n                    append(\"You've entered wrong password.\")\n            else:\n                #Let's try to get profile\n                try:\n                    user.get_profile()\n                except:\n                    Content[\"CustomErrors\"].\\\n                        append(\"Sorry, we don't have you profile\")\n                else:\n                    Content[\"CustomErrors\"].\\\n                        append(\"Grats! Valid login and password.\")\n\n\nelse:\n    form = LoginForm()\nContent[\"form\"] = form\nPageContent = CustomReturnToResponse('loginform.html', Content)\nreturn render_to_response('index.html',\n        {'PageTitle': 'Login', 'PageContent': PageContent})", "path": "testsite\\mainapp\\views.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nNever mix tabs and spaces.\n\nThe most popular way of indenting Python is with spaces only.  The\nsecond-most popular way is with tabs only.  Code indented with a mixture\nof tabs and spaces should be converted to using spaces exclusively.  When\ninvoking the Python command line interpreter with the -t option, it issues\nwarnings about code that illegally mixes tabs and spaces.  When using -tt\nthese warnings become errors.  These options are highly recommended!\n\"\"\"\n", "func_signal": "def tabs_or_spaces(physical_line, indent_char):\n", "code": "indent = indent_match(physical_line).group(1)\nfor offset, char in enumerate(indent):\n    if char != indent_char:\n        return offset, \"E101 indentation contains mixed spaces and tabs\"", "path": "testsite\\pep8.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nBuild a logical line from tokens.\n\"\"\"\n", "func_signal": "def build_tokens_line(self):\n", "code": "self.mapping = []\nlogical = []\nlength = 0\nprevious = None\nfor token in self.tokens:\n    token_type, text = token[0:2]\n    if token_type in (tokenize.COMMENT, tokenize.NL,\n                      tokenize.INDENT, tokenize.DEDENT,\n                      tokenize.NEWLINE):\n        continue\n    if token_type == tokenize.STRING:\n        text = mute_string(text)\n    if previous:\n        end_line, end = previous[3]\n        start_line, start = token[2]\n        if end_line != start_line: # different row\n            if self.lines[end_line - 1][end - 1] not in '{[(':\n                logical.append(' ')\n                length += 1\n        elif end != start: # different column\n            fill = self.lines[end_line - 1][end:start]\n            logical.append(fill)\n            length += len(fill)\n    self.mapping.append((length, token))\n    logical.append(text)\n    length += len(text)\n    previous = token\nself.logical_line = ''.join(logical)\nassert self.logical_line.lstrip() == self.logical_line\nassert self.logical_line.rstrip() == self.logical_line", "path": "testsite\\pep8.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "#Output message. Shown after successful forgot password processing\n", "func_signal": "def forgot_message(request):\n", "code": "return render_to_response('index.html',\n    {'PageTitle': 'Login', 'PageContent': \"Please check your mail\"})", "path": "testsite\\mainapp\\views.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "#Index page. Output menu\n", "func_signal": "def index(request):\n", "code": "PageContent = CustomReturnToResponse('main.html',\n     {\"abslturl\": ReturnAbsoluteUrl()})\nreturn render_to_response('index.html',\n    {'PageTitle': 'Main Page', 'PageContent': PageContent})", "path": "testsite\\mainapp\\views.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nAvoid extraneous whitespace in the following situations:\n\n- Immediately inside parentheses, brackets or braces.\n\n- Immediately before a comma, semicolon, or colon.\n\"\"\"\n", "func_signal": "def extraneous_whitespace(logical_line):\n", "code": "line = logical_line\nfor char in '([{':\n    found = line.find(char + ' ')\n    if found > -1:\n        return found + 1, \"E201 whitespace after '%s'\" % char\nfor char in '}])':\n    found = line.find(' ' + char)\n    if found > -1 and line[found - 1] != ',':\n        return found, \"E202 whitespace before '%s'\" % char\nfor char in ',;:':\n    found = line.find(' ' + char)\n    if found > -1:\n        return found, \"E203 whitespace before '%s'\" % char", "path": "testsite\\pep8.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nFind all globally visible functions where the first argument name\nstarts with argument_name.\n\"\"\"\n", "func_signal": "def find_checks(argument_name):\n", "code": "checks = []\nfunction_type = type(find_checks)\nfor name, function in globals().iteritems():\n    if type(function) is function_type:\n        args = inspect.getargspec(function)[0]\n        if len(args) >= 1 and args[0].startswith(argument_name):\n            checks.append((name, function, args))\nchecks.sort()\nreturn checks", "path": "testsite\\pep8.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nAvoid extraneous whitespace in the following situations:\n\n- More than one space around an assignment (or other) operator to\n  align it with another.\n\"\"\"\n", "func_signal": "def whitespace_around_operator(logical_line):\n", "code": "line = logical_line\nfor operator in operators:\n    found = line.find('  ' + operator)\n    if found > -1:\n        return found, \"E221 multiple spaces before operator\"\n    found = line.find(operator + '  ')\n    if found > -1:\n        return found, \"E222 multiple spaces after operator\"\n    found = line.find('\\t' + operator)\n    if found > -1:\n        return found, \"E223 tab before operator\"\n    found = line.find(operator + '\\t')\n    if found > -1:\n        return found, \"E224 tab after operator\"", "path": "testsite\\pep8.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nCheck if options.ignore contains a prefix of the error code.\n\"\"\"\n", "func_signal": "def ignore_code(code):\n", "code": "for ignore in options.ignore:\n    if code.startswith(ignore):\n        return True", "path": "testsite\\pep8.py", "repo_name": "alekseysribnyj/twilltestproject", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nUsed for __repr__ and __str__\n\n>>> r1 = repr(OrderedDict((('a', 'b'), ('c', 'd'), ('e', 'f'))))\n>>> r1\n\"OrderedDict([('a', 'b'), ('c', 'd'), ('e', 'f')])\"\n>>> r2 = repr(OrderedDict((('a', 'b'), ('e', 'f'), ('c', 'd'))))\n>>> r2\n\"OrderedDict([('a', 'b'), ('e', 'f'), ('c', 'd')])\"\n>>> r1 == str(OrderedDict((('a', 'b'), ('c', 'd'), ('e', 'f'))))\nTrue\n>>> r2 == str(OrderedDict((('a', 'b'), ('e', 'f'), ('c', 'd'))))\nTrue\n\"\"\"\n", "func_signal": "def __repr__(self):\n", "code": "return '%s([%s])' % (self.__class__.__name__, ', '.join(\n    ['(%r, %r)' % (key, self[key]) for key in self._sequence]))", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"Add an item to the end.\"\"\"\n# FIXME: this is only append if the key isn't already present\n", "func_signal": "def append(self, item):\n", "code": "key, value = item\nself._main[key] = value", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"\n>>> ii = OrderedDict(((1, 3), (3, 2), (2, 1))).iteritems()\n>>> ii.next()\n(1, 3)\n>>> ii.next()\n(3, 2)\n>>> ii.next()\n(2, 1)\n>>> ii.next()\nTraceback (most recent call last):\nStopIteration\n\"\"\"\n", "func_signal": "def iteritems(self):\n", "code": "def make_iter(self=self):\n    keys = self.iterkeys()\n    while True:\n        key = keys.next()\n        yield (key, self[key])\nreturn make_iter()", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"\n>>> iv = OrderedDict(((1, 3), (3, 2), (2, 1))).itervalues()\n>>> iv.next()\n3\n>>> iv.next()\n2\n>>> iv.next()\n1\n>>> iv.next()\nTraceback (most recent call last):\nStopIteration\n\"\"\"\n", "func_signal": "def itervalues(self):\n", "code": "def make_iter(self=self):\n    keys = self.iterkeys()\n    while True:\n        yield self[keys.next()]\nreturn make_iter()", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"\n>>> d = OrderedDict(((1, 3), (3, 2), (2, 1)))\n>>> d != OrderedDict(d)\nFalse\n>>> d != OrderedDict(((1, 3), (2, 1), (3, 2)))\nTrue\n>>> d != OrderedDict(((1, 0), (3, 2), (2, 1)))\nTrue\n>>> d == OrderedDict(((0, 3), (3, 2), (2, 1)))\nFalse\n>>> d != dict(d)\nTrue\n>>> d != False\nTrue\n\"\"\"\n", "func_signal": "def __ne__(self, other):\n", "code": "if isinstance(other, OrderedDict):\n    # FIXME: efficiency?\n    #   Generate both item lists for each compare\n    return not (self.items() == other.items())\nelse:\n    return True", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"Delete the item at position i.\"\"\"\n", "func_signal": "def __delitem__(self, i):\n", "code": "key = self._main._sequence[i]\nif isinstance(i, types.SliceType):\n    for k in key:\n        # FIXME: efficiency?\n        del self._main[k]\nelse:\n    del self._main[key]", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"\nTakes ``index``, ``key``, and ``value`` as arguments.\n\nSets ``key`` to ``value``, so that ``key`` is at position ``index`` in\nthe OrderedDict.\n\n>>> d = OrderedDict(((1, 3), (3, 2), (2, 1)))\n>>> d.insert(0, 4, 0)\n>>> d\nOrderedDict([(4, 0), (1, 3), (3, 2), (2, 1)])\n>>> d.insert(0, 2, 1)\n>>> d\nOrderedDict([(2, 1), (4, 0), (1, 3), (3, 2)])\n>>> d.insert(8, 8, 1)\n>>> d\nOrderedDict([(2, 1), (4, 0), (1, 3), (3, 2), (8, 1)])\n\"\"\"\n", "func_signal": "def insert(self, index, key, value):\n", "code": "if key in self:\n    # FIXME: efficiency?\n    del self[key]\nself._sequence.insert(index, key)\ndict.__setitem__(self, key, value)", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"Protect keys, items, and values.\"\"\"\n", "func_signal": "def __setattr__(self, name, value):\n", "code": "if not '_att_dict' in self.__dict__:\n    object.__setattr__(self, name, value)\nelse:\n    try:\n        fun = self._att_dict[name]\n    except KeyError:\n        OrderedDict.__setattr__(self, name, value)\n    else:\n        fun(value)", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"\nYou can pass in a list of values, which will replace the\ncurrent list. The value list must be the same len as the OrderedDict.\n\n(Or a ``ValueError`` is raised.)\n\n>>> d = OrderedDict(((1, 3), (3, 2), (2, 1)))\n>>> d.setvalues((1, 2, 3))\n>>> d\nOrderedDict([(1, 1), (3, 2), (2, 3)])\n>>> d.setvalues([6])\nTraceback (most recent call last):\nValueError: Value list is not the same length as the OrderedDict.\n\"\"\"\n", "func_signal": "def setvalues(self, values):\n", "code": "if len(values) != len(self):\n    # FIXME: correct error to raise?\n    raise ValueError('Value list is not the same length as the '\n        'OrderedDict.')\nself.update(zip(self, values))", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"\nDelete and return an item specified by index, not a random one as in\ndict. The index is -1 by default (the last item).\n\n>>> d = OrderedDict(((1, 3), (3, 2), (2, 1)))\n>>> d.popitem()\n(2, 1)\n>>> d\nOrderedDict([(1, 3), (3, 2)])\n>>> d.popitem(0)\n(1, 3)\n>>> OrderedDict().popitem()\nTraceback (most recent call last):\nKeyError: 'popitem(): dictionary is empty'\n>>> d.popitem(2)\nTraceback (most recent call last):\nIndexError: popitem(): index 2 not valid\n\"\"\"\n", "func_signal": "def popitem(self, i=-1):\n", "code": "if not self._sequence:\n    raise KeyError('popitem(): dictionary is empty')\ntry:\n    key = self._sequence[i]\nexcept IndexError:\n    raise IndexError('popitem(): index %s not valid' % i)\nreturn (key, self.pop(key))", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"\n>>> d = OrderedDict(((1, 3), (3, 2), (2, 1)))\n>>> d == OrderedDict(d)\nTrue\n>>> d == OrderedDict(((1, 3), (2, 1), (3, 2)))\nFalse\n>>> d == OrderedDict(((1, 0), (3, 2), (2, 1)))\nFalse\n>>> d == OrderedDict(((0, 3), (3, 2), (2, 1)))\nFalse\n>>> d == dict(d)\nFalse\n>>> d == False\nFalse\n\"\"\"\n", "func_signal": "def __eq__(self, other):\n", "code": "if isinstance(other, OrderedDict):\n    # FIXME: efficiency?\n    #   Generate both item lists for each compare\n    return (self.items() == other.items())\nelse:\n    return False", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"Set item at position i to item.\"\"\"\n", "func_signal": "def __setitem__(self, index, item):\n", "code": "if isinstance(index, types.SliceType):\n    # NOTE: item must be an iterable (list of tuples)\n    self._main[index] = OrderedDict(item)\nelse:\n    # FIXME: Does this raise a sensible error?\n    orig = self._main.keys[index]\n    key, value = item\n    if self._main.strict and key in self and (key != orig):\n        raise ValueError('slice assignment must be from '\n                'unique keys')\n    # delete the current one\n    del self._main[self._main._sequence[index]]\n    self._main.insert(index, key, value)", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"\nYou cannot assign to keys, but you can do slice assignment to re-order\nthem.\n\nYou can only do slice assignment if the new set of keys is a reordering\nof the original set.\n\"\"\"\n", "func_signal": "def __setitem__(self, index, name):\n", "code": "if isinstance(index, types.SliceType):\n    # FIXME: efficiency?\n    # check length is the same\n    indexes = range(len(self._main._sequence))[index]\n    if len(indexes) != len(name):\n        raise ValueError('attempt to assign sequence of size %s '\n            'to slice of size %s' % (len(name), len(indexes)))\n    # check they are the same keys\n    # FIXME: Use set\n    old_keys = self._main._sequence[index]\n    new_keys = list(name)\n    old_keys.sort()\n    new_keys.sort()\n    if old_keys != new_keys:\n        raise KeyError('Keylist is not the same as current keylist.')\n    orig_vals = [self._main[k] for k in name]\n    del self._main[index]\n    vals = zip(indexes, name, orig_vals)\n    vals.sort()\n    for i, k, v in vals:\n        if self._main.strict and k in self._main:\n            raise ValueError('slice assignment must be from '\n                'unique keys')\n        self._main.insert(i, k, v)\nelse:\n    raise ValueError('Cannot assign to keys')", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"Sort the values.\"\"\"\n", "func_signal": "def sort(self, *args, **kwds):\n", "code": "vals = self._main.values()\nvals.sort(*args, **kwds)\nself[:] = vals", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"\n>>> d = OrderedDict(((1, 3), (3, 2), (2, 1)))\n>>> c = OrderedDict(((0, 3), (3, 2), (2, 1)))\n>>> c < d\nTrue\n>>> d < c\nFalse\n>>> d < dict(c)\nTraceback (most recent call last):\nTypeError: Can only compare with other OrderedDicts\n\"\"\"\n", "func_signal": "def __lt__(self, other):\n", "code": "if not isinstance(other, OrderedDict):\n    raise TypeError('Can only compare with other OrderedDicts')\n# FIXME: efficiency?\n#   Generate both item lists for each compare\nreturn (self.items() < other.items())", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"\n>>> d = OrderedDict(((1, 3), (3, 2), (2, 1)))\n>>> c = OrderedDict(((0, 3), (3, 2), (2, 1)))\n>>> e = OrderedDict(d)\n>>> c >= d\nFalse\n>>> d >= c\nTrue\n>>> d >= dict(c)\nTraceback (most recent call last):\nTypeError: Can only compare with other OrderedDicts\n>>> e >= d\nTrue\n\"\"\"\n", "func_signal": "def __ge__(self, other):\n", "code": "if not isinstance(other, OrderedDict):\n    raise TypeError('Can only compare with other OrderedDicts')\n# FIXME: efficiency?\n#   Generate both item lists for each compare\nreturn (self.items() >= other.items())", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"Fetch the item at position i.\"\"\"\n", "func_signal": "def __getitem__(self, index):\n", "code": "if isinstance(index, types.SliceType):\n    # fetching a slice returns an OrderedDict\n    return self._main[index].items()\nkey = self._main._sequence[index]\nreturn (key, self._main[key])", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"Fetch the value at position i.\"\"\"\n", "func_signal": "def __getitem__(self, index):\n", "code": "if isinstance(index, types.SliceType):\n    return [self._main[key] for key in self._main._sequence[index]]\nelse:\n    return self._main[self._main._sequence[index]]", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"\nThis method allows you to set the items in the dict.\n\nIt takes a list of tuples - of the same sort returned by the ``items``\nmethod.\n\n>>> d = OrderedDict()\n>>> d.setitems(((3, 1), (2, 3), (1, 2)))\n>>> d\nOrderedDict([(3, 1), (2, 3), (1, 2)])\n\"\"\"\n", "func_signal": "def setitems(self, items):\n", "code": "self.clear()\n# FIXME: this allows you to pass in an OrderedDict as well :-)\nself.update(items)", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"\n>>> d = OrderedDict(((1, 3), (3, 2), (2, 1)))\n>>> d.setdefault(1)\n3\n>>> d.setdefault(4) is None\nTrue\n>>> d\nOrderedDict([(1, 3), (3, 2), (2, 1), (4, None)])\n>>> d.setdefault(5, 0)\n0\n>>> d\nOrderedDict([(1, 3), (3, 2), (2, 1), (4, None), (5, 0)])\n\"\"\"\n", "func_signal": "def setdefault(self, key, defval = None):\n", "code": "if key in self:\n    return self[key]\nelse:\n    self[key] = defval\n    return defval", "path": "__init__.py", "repo_name": "b1tr0t/odict", "stars": 2, "license": "None", "language": "python", "size": 84}
{"docstring": "\"\"\"Invoke reinitialized command `cmdname` with keyword args\"\"\"\n", "func_signal": "def call_command(self,cmdname,**kw):\n", "code": "for dirname in INSTALL_DIRECTORY_ATTRS:\n    kw.setdefault(dirname,self.bdist_dir)\nkw.setdefault('skip_build',self.skip_build)\nkw.setdefault('dry_run', self.dry_run)\ncmd = self.reinitialize_command(cmdname, **kw)\nself.run_command(cmdname)\nreturn cmd", "path": "setuptools\\setuptools\\command\\bdist_egg.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"apply a caller_stack compatibility decorator to a plain Python function.\"\"\"\n", "func_signal": "def supports_caller(func):\n", "code": "def wrap_stackframe(context,  *args, **kwargs):\n    context.caller_stack._push_frame()\n    try:\n        return func(context, *args, **kwargs)\n    finally:\n        context.caller_stack._pop_frame()\nreturn wrap_stackframe", "path": "mako\\lib\\mako\\runtime.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "# check for existing flag in EGG-INFO\n", "func_signal": "def analyze_egg(egg_dir, stubs):\n", "code": "for flag,fn in safety_flags.items():\n    if os.path.exists(os.path.join(egg_dir,'EGG-INFO',fn)):\n        return flag\nif not can_scan(): return False\nsafe = True\nfor base, dirs, files in walk_egg(egg_dir):\n    for name in files:\n        if name.endswith('.py') or name.endswith('.pyw'):\n            continue\n        elif name.endswith('.pyc') or name.endswith('.pyo'):\n            # always scan, even if we already know we're not safe\n            safe = scan_module(egg_dir, base, name, stubs) and safe\nreturn safe", "path": "setuptools\\setuptools\\command\\bdist_egg.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"return a namespace corresponding to the given template uri.\n\nif a relative uri, it is adjusted to that of the template of this namespace\"\"\"\n", "func_signal": "def get_namespace(self, uri):\n", "code": "key = (self, uri)\nif self.context.namespaces.has_key(key):\n    return self.context.namespaces[key]\nelse:\n    ns = Namespace(uri, self.context._copy(), templateuri=uri, calling_uri=self._templateuri) \n    self.context.namespaces[key] = ns\n    return ns", "path": "mako\\lib\\mako\\runtime.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"execute the given template def, capturing the output into a buffer.\"\"\"\n", "func_signal": "def capture(context, callable_, *args, **kwargs):\n", "code": "if not callable(callable_):\n    raise exceptions.RuntimeException(\"capture() function expects a callable as its argument (i.e. capture(func, *args, **kwargs))\")\ncontext._push_buffer()\ntry:\n    callable_(*args, **kwargs)\nfinally:\n    buf = context._pop_buffer()\nreturn buf.getvalue()", "path": "mako\\lib\\mako\\runtime.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"Yield names and strings used by `code` and its nested code objects\"\"\"\n", "func_signal": "def iter_symbols(code):\n", "code": "for name in code.co_names: yield name\nfor const in code.co_consts:\n    if isinstance(const,basestring):\n        yield const\n    elif isinstance(const,CodeType):\n        for name in iter_symbols(const):\n            yield name", "path": "setuptools\\setuptools\\command\\bdist_egg.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"push a capturing buffer onto this Context and return the new Writer function.\"\"\"\n\n", "func_signal": "def _push_writer(self):\n", "code": "buf = util.FastEncodingBuffer()\nself._buffer_stack.append(buf)\nreturn buf.write", "path": "mako\\lib\\mako\\runtime.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "# Hack for packages that install data to install's --install-lib\n", "func_signal": "def do_install_data(self):\n", "code": "self.get_finalized_command('install').install_lib = self.bdist_dir\n\nsite_packages = os.path.normcase(os.path.realpath(get_python_lib()))\nold, self.distribution.data_files = self.distribution.data_files,[]\n\nfor item in old:\n    if isinstance(item,tuple) and len(item)==2:\n        if os.path.isabs(item[0]):\n            realpath = os.path.realpath(item[0])\n            normalized = os.path.normcase(realpath)\n            if normalized==site_packages or normalized.startswith(\n                site_packages+os.sep\n            ):\n                item = realpath[len(site_packages)+1:], item[1]\n            # XXX else: raise ???\n    self.distribution.data_files.append(item)\n\ntry:\n    log.info(\"installing package data to %s\" % self.bdist_dir)\n    self.call_command('install_data', force=0, root=None)\nfinally:\n    self.distribution.data_files = old", "path": "setuptools\\setuptools\\command\\bdist_egg.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"create a Context and return the string output of the given template and template callable.\"\"\"\n\n", "func_signal": "def _render(template, callable_, args, data, as_unicode=False):\n", "code": "if as_unicode:\n    buf = util.FastEncodingBuffer(unicode=True)\nelif template.output_encoding:\n    buf = util.FastEncodingBuffer(unicode=as_unicode, encoding=template.output_encoding, errors=template.encoding_errors)\nelse:\n    buf = util.StringIO()\ncontext = Context(buf, **data)\ncontext._with_template = template\n_render_context(template, callable_, context, *args, **_kwargs_for_callable(callable_, data))\nreturn context._pop_buffer().getvalue()", "path": "mako\\lib\\mako\\runtime.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"pop the most recent capturing buffer from this Context \nand return the current writer after the pop.\n\n\"\"\"\n\n", "func_signal": "def _pop_buffer_and_writer(self):\n", "code": "buf = self._buffer_stack.pop()\nreturn buf, self._buffer_stack[-1].write", "path": "mako\\lib\\mako\\runtime.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"Check whether module possibly uses unsafe-for-zipfile stuff\"\"\"\n\n", "func_signal": "def scan_module(egg_dir, base, name, stubs):\n", "code": "filename = os.path.join(base,name)\nif filename[:-1] in stubs:\n    return True     # Extension module\npkg = base[len(egg_dir)+1:].replace(os.sep,'.')\nmodule = pkg+(pkg and '.' or '')+os.path.splitext(name)[0]\nf = open(filename,'rb'); f.read(8)   # skip magic & date\ncode = marshal.load(f);  f.close()\nsafe = True\nsymbols = dict.fromkeys(iter_symbols(code))\nfor bad in ['__file__', '__path__']:\n    if bad in symbols:\n        log.warn(\"%s: module references %s\", module, bad)\n        safe = False\nif 'inspect' in symbols:\n    for bad in [\n        'getsource', 'getabsfile', 'getsourcefile', 'getfile'\n        'getsourcelines', 'findsource', 'getcomments', 'getframeinfo',\n        'getinnerframes', 'getouterframes', 'stack', 'trace'\n    ]:\n        if bad in symbols:\n            log.warn(\"%s: module MAY be using inspect.%s\", module, bad)\n            safe = False\nif '__name__' in symbols and '__main__' in symbols and '.' not in module:\n    if sys.version[:3]==\"2.4\":  # -m works w/zipfiles in 2.5\n        log.warn(\"%s: top-level module may be 'python -m' script\", module)\n        safe = False\nreturn safe", "path": "setuptools\\setuptools\\command\\bdist_egg.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"Walk an unpacked egg's contents, skipping the metadata directory\"\"\"\n", "func_signal": "def walk_egg(egg_dir):\n", "code": "walker = os.walk(egg_dir)\nbase,dirs,files = walker.next()\nif 'EGG-INFO' in dirs:\n    dirs.remove('EGG-INFO')\nyield base,dirs,files\nfor bdf in walker:\n    yield bdf", "path": "setuptools\\setuptools\\command\\bdist_egg.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"create a new copy of this Context with tokens related to inheritance state removed.\"\"\"\n", "func_signal": "def _clean_inheritance_tokens(self):\n", "code": "c = self._copy()\nx = c._data\nx.pop('self', None)\nx.pop('parent', None)\nx.pop('next', None)\nreturn c", "path": "mako\\lib\\mako\\runtime.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "# hexdigest is new with Python 2.0\n", "func_signal": "def test_hexdigest(self):\n", "code": "m = md5('testing the hexdigest method')\nh = m.hexdigest()\nself.assertEqual(hexstr(m.digest()), h)", "path": "jython\\CPythonLib\\test\\test_md5.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "# Generate metadata first\n", "func_signal": "def run(self):\n", "code": "self.run_command(\"egg_info\")\n\n# We run install_lib before install_data, because some data hacks\n# pull their data path from the install_lib command.\nlog.info(\"installing library code to %s\" % self.bdist_dir)\ninstcmd = self.get_finalized_command('install')\nold_root = instcmd.root; instcmd.root = None\ncmd = self.call_command('install_lib', warn_dir=0)\ninstcmd.root = old_root\n\nall_outputs, ext_outputs = self.get_ext_outputs()\nself.stubs = []\nto_compile = []\nfor (p,ext_name) in enumerate(ext_outputs):\n    filename,ext = os.path.splitext(ext_name)\n    pyfile = os.path.join(self.bdist_dir, strip_module(filename)+'.py')\n    self.stubs.append(pyfile)\n    log.info(\"creating stub loader for %s\" % ext_name)\n    if not self.dry_run:\n        write_stub(os.path.basename(ext_name), pyfile)\n    to_compile.append(pyfile)\n    ext_outputs[p] = ext_name.replace(os.sep,'/')\n\nto_compile.extend(self.make_init_files())\nif to_compile:\n    cmd.byte_compile(to_compile)\n\nif self.distribution.data_files:\n    self.do_install_data()\n\n# Make the EGG-INFO directory\narchive_root = self.bdist_dir\negg_info = os.path.join(archive_root,'EGG-INFO')\nself.mkpath(egg_info)\nif self.distribution.scripts:\n    script_dir = os.path.join(egg_info, 'scripts')\n    log.info(\"installing scripts to %s\" % script_dir)\n    self.call_command('install_scripts',install_dir=script_dir,no_ep=1)\n\nnative_libs = os.path.join(self.egg_info,\"native_libs.txt\")\nif all_outputs:\n    log.info(\"writing %s\" % native_libs)\n    if not self.dry_run:\n        libs_file = open(native_libs, 'wt')\n        libs_file.write('\\n'.join(all_outputs))\n        libs_file.write('\\n')\n        libs_file.close()\nelif os.path.isfile(native_libs):\n    log.info(\"removing %s\" % native_libs)\n    if not self.dry_run:\n        os.unlink(native_libs)\n\nself.copy_metadata_to(egg_info)\n\nwrite_safety_flag(\n    os.path.join(archive_root,'EGG-INFO'), self.zip_safe()\n)\n\nif os.path.exists(os.path.join(self.egg_info,'depends.txt')):\n    log.warn(\n        \"WARNING: 'depends.txt' will not be used by setuptools 0.6!\\n\"\n        \"Use the install_requires/extras_require setup() args instead.\"\n    )\n\nif self.exclude_source_files:\n    self.zap_pyfiles()\n\n# Make the archive\nmake_zipfile(self.egg_output, archive_root, verbose=self.verbose,\n                  dry_run=self.dry_run, mode=self.gen_header())\nif not self.keep_temp:\n    remove_tree(self.bdist_dir, dry_run=self.dry_run)\n\n# Add to 'Distribution.dist_files' so that the \"upload\" command works\ngetattr(self.distribution,'dist_files',[]).append(\n    ('bdist_egg',get_python_version(),self.egg_output))", "path": "setuptools\\setuptools\\command\\bdist_egg.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"create a new Context with a copy of this Context's current state, updated with the given dictionary.\"\"\"\n", "func_signal": "def locals_(self, d):\n", "code": "if len(d) == 0:\n    return self\nc = self._copy()\nc._data.update(d)\nreturn c", "path": "mako\\lib\\mako\\runtime.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"called by the _inherit method in template modules to set up the inheritance chain at the start\nof a template's execution.\"\"\"\n", "func_signal": "def _inherit_from(context, uri, calling_uri):\n", "code": "if uri is None:\n    return None\ntemplate = _lookup_template(context, uri, calling_uri)\nself_ns = context['self']\nih = self_ns\nwhile ih.inherits is not None:\n    ih = ih.inherits\nlclcontext = context.locals_({'next':ih})\nih.inherits = Namespace(\"self:%s\" % template.uri, lclcontext, template = template, populate_self=False)\ncontext._data['parent'] = lclcontext._data['local'] = ih.inherits\ncallable_ = getattr(template.module, '_mako_inherit', None)\nif callable_ is not None:\n    ret = callable_(template, lclcontext)\n    if ret:\n        return ret\n\ngen_ns = getattr(template.module, '_mako_generate_namespaces', None)\nif gen_ns is not None:\n    gen_ns(context)\nreturn (template.callable_, lclcontext)", "path": "mako\\lib\\mako\\runtime.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"locate the template from the given uri and include it in the current output.\"\"\"\n", "func_signal": "def _include_file(context, uri, calling_uri, **kwargs):\n", "code": "template = _lookup_template(context, uri, calling_uri)\n(callable_, ctx) = _populate_self_namespace(context._clean_inheritance_tokens(), template)\ncallable_(ctx, **_kwargs_for_callable(callable_, context._data, **kwargs))", "path": "mako\\lib\\mako\\runtime.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"Create missing package __init__ files\"\"\"\n", "func_signal": "def make_init_files(self):\n", "code": "init_files = []\nfor base,dirs,files in walk_egg(self.bdist_dir):\n    if base==self.bdist_dir:\n        # don't put an __init__ in the root\n        continue\n    for name in files:\n        if name.endswith('.py'):\n            if '__init__.py' not in files:\n                pkg = base[len(self.bdist_dir)+1:].replace(os.sep,'.')\n                if self.distribution.has_contents_for(pkg):\n                    log.warn(\"Creating missing __init__.py for %s\",pkg)\n                    filename = os.path.join(base,'__init__.py')\n                    if not self.dry_run:\n                        f = open(filename,'w'); f.write(NS_PKG_STUB)\n                        f.close()\n                    init_files.append(filename)\n            break\n    else:\n        # not a package, don't traverse to subdirectories\n        dirs[:] = []\n\nreturn init_files", "path": "setuptools\\setuptools\\command\\bdist_egg.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"Get a list of relative paths to C extensions in the output distro\"\"\"\n\n", "func_signal": "def get_ext_outputs(self):\n", "code": "all_outputs = []\next_outputs = []\n\npaths = {self.bdist_dir:''}\nfor base, dirs, files in os.walk(self.bdist_dir):\n    for filename in files:\n        if os.path.splitext(filename)[1].lower() in NATIVE_EXTENSIONS:\n            all_outputs.append(paths[base]+filename)\n    for filename in dirs:\n        paths[os.path.join(base,filename)] = paths[base]+filename+'/'\n\nif self.distribution.has_ext_modules():\n    build_cmd = self.get_finalized_command('build_ext')\n    for ext in build_cmd.extensions:\n        if isinstance(ext,Library):\n            continue\n        fullname = build_cmd.get_ext_fullname(ext.name)\n        filename = build_cmd.get_ext_filename(fullname)\n        if not os.path.basename(filename).startswith('dl-'):\n            if os.path.exists(os.path.join(self.bdist_dir,filename)):\n                ext_outputs.append(filename)\n\nreturn all_outputs, ext_outputs", "path": "setuptools\\setuptools\\command\\bdist_egg.py", "repo_name": "arianepaola/tg2jython", "stars": 2, "license": "None", "language": "python", "size": 26148}
{"docstring": "\"\"\"\nDeserialize a stream or string of YAML data.\n\"\"\"\n", "func_signal": "def Deserializer(stream_or_string, **options):\n", "code": "if isinstance(stream_or_string, basestring):\n    stream = StringIO(stream_or_string)\nelse:\n    stream = stream_or_string\nfor obj in PythonDeserializer(yaml.load(stream)):\n    yield obj", "path": "lib\\django\\django\\core\\serializers\\pyyaml.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "\"\"\"\nDoes a \"reverse\" lookup -- returns the URL for the given args/kwargs.\nThe args/kwargs are applied to the given compiled regular expression.\nFor example:\n\n    >>> reverse_helper(re.compile('^places/(\\d+)/$'), 3)\n    'places/3/'\n    >>> reverse_helper(re.compile('^places/(?P<id>\\d+)/$'), id=3)\n    'places/3/'\n    >>> reverse_helper(re.compile('^people/(?P<state>\\w\\w)/(\\w+)/$'), 'adrian', state='il')\n    'people/il/adrian/'\n\nRaises NoReverseMatch if the args/kwargs aren't valid for the regex.\n\"\"\"\n# TODO: Handle nested parenthesis in the following regex.\n", "func_signal": "def reverse_helper(regex, *args, **kwargs):\n", "code": "result = re.sub(r'\\(([^)]+)\\)', MatchChecker(args, kwargs), regex.pattern)\nreturn result.replace('^', '').replace('$', '')", "path": "lib\\django\\django\\core\\urlresolvers.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "\"\"\"\nParse the first YAML document in a stream\nand produce the corresponding Python object.\n\"\"\"\n", "func_signal": "def load(stream, Loader=Loader):\n", "code": "loader = Loader(stream)\nif loader.check_data():\n    return loader.get_data()", "path": "lib\\yaml\\lib\\yaml\\__init__.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "\"\"\"\nAdd a path based resolver for the given tag.\nA path is a list of keys that forms a path\nto a node in the representation tree.\nKeys can be string values, integers, or None.\n\"\"\"\n", "func_signal": "def add_path_resolver(tag, path, kind=None, Loader=Loader, Dumper=Dumper):\n", "code": "Loader.add_path_resolver(tag, path, kind)\nDumper.add_path_resolver(tag, path, kind)", "path": "lib\\yaml\\lib\\yaml\\__init__.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "# regex is a string representing a regular expression.\n# callback is either a string like 'foo.views.news.stories.story_detail'\n# which represents the path to a module and a view function name, or a\n# callable object (view).\n", "func_signal": "def __init__(self, regex, callback, default_args=None):\n", "code": "self.regex = re.compile(regex)\nif callable(callback):\n    self._callback = callback\nelse:\n    self._callback = None\n    self._callback_str = callback\nself.default_args = default_args or {}", "path": "lib\\django\\django\\core\\urlresolvers.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "\"\"\"\nSaves bound Form ``form``'s clean_data into model instance ``instance``.\n\nAssumes ``form`` has a field for every non-AutoField database field in\n``instance``. If commit=True, then the changes to ``instance`` will be\nsaved to the database. Returns ``instance``.\n\"\"\"\n", "func_signal": "def save_instance(form, instance, commit=True):\n", "code": "from django.db import models\nopts = instance.__class__._meta\nif form.errors:\n    raise ValueError(\"The %s could not be changed because the data didn't validate.\" % opts.object_name)\nclean_data = form.clean_data\nfor f in opts.fields:\n    if not f.editable or isinstance(f, models.AutoField):\n        continue\n    setattr(instance, f.name, clean_data[f.name])\nif commit:\n    instance.save()\n    for f in opts.many_to_many:\n        setattr(instance, f.attname, clean_data[f.name])\n# GOTCHA: If many-to-many data is given and commit=False, the many-to-many\n# data will be lost. This happens because a many-to-many options cannot be\n# set on an object until after it's saved. Maybe we should raise an\n# exception in that case.\nreturn instance", "path": "lib\\django\\django\\newforms\\models.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "# Handle initalizing an object with the generic FK instaed of \n# content-type/object-id fields.        \n", "func_signal": "def instance_pre_init(self, signal, sender, args, kwargs):\n", "code": "if kwargs.has_key(self.name):\n    value = kwargs.pop(self.name)\n    kwargs[self.ct_field] = self.get_content_type(value)\n    kwargs[self.fk_field] = value._get_pk_val()", "path": "lib\\django\\django\\db\\models\\fields\\generic.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "\"\"\"\nParse all YAML documents in a stream\nand produce corresponding Python objects.\n\"\"\"\n", "func_signal": "def load_all(stream, Loader=Loader):\n", "code": "loader = Loader(stream)\nwhile loader.check_data():\n    yield loader.get_data()", "path": "lib\\yaml\\lib\\yaml\\__init__.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "\"\"\"\nParse all YAML documents in a stream\nand produce corresponsing representation trees.\n\"\"\"\n", "func_signal": "def compose_all(stream, Loader=Loader):\n", "code": "loader = Loader(stream)\nwhile loader.check_node():\n    yield loader.get_node()", "path": "lib\\yaml\\lib\\yaml\\__init__.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "# Make sure the fields exist (these raise FieldDoesNotExist, \n# which is a fine error to raise here)\n", "func_signal": "def contribute_to_class(self, cls, name):\n", "code": "self.name = name\nself.model = cls\nself.cache_attr = \"_%s_cache\" % name\n\n# For some reason I don't totally understand, using weakrefs here doesn't work.\ndispatcher.connect(self.instance_pre_init, signal=signals.pre_init, sender=cls, weak=False)\n\n# Connect myself as the descriptor for this field\nsetattr(cls, name, self)", "path": "lib\\django\\django\\db\\models\\fields\\generic.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "# Convenience function using get_model avoids a circular import when using this model\n", "func_signal": "def get_content_type(self, obj):\n", "code": "ContentType = get_model(\"contenttypes\", \"contenttype\")\nreturn ContentType.objects.get_for_model(obj)", "path": "lib\\django\\django\\db\\models\\fields\\generic.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "\"\"\"\nConvert a Python object to a representation node.\n\"\"\"\n", "func_signal": "def to_yaml(cls, dumper, data):\n", "code": "return dumper.represent_yaml_object(cls.yaml_tag, data, cls,\n        flow_style=cls.yaml_flow_style)", "path": "lib\\yaml\\lib\\yaml\\__init__.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "\"\"\"\nFactory function for a manager that subclasses 'superclass' (which is a\nManager) and adds behavior for generic related objects.\n\"\"\"\n\n", "func_signal": "def create_generic_related_manager(superclass):\n", "code": "class GenericRelatedObjectManager(superclass):\n    def __init__(self, model=None, core_filters=None, instance=None, symmetrical=None,\n                 join_table=None, source_col_name=None, target_col_name=None, content_type=None,\n                 content_type_field_name=None, object_id_field_name=None):\n        \n        super(GenericRelatedObjectManager, self).__init__()\n        self.core_filters = core_filters or {}\n        self.model = model\n        self.content_type = content_type\n        self.symmetrical = symmetrical\n        self.instance = instance\n        self.join_table = join_table\n        self.join_table = model._meta.db_table\n        self.source_col_name = source_col_name\n        self.target_col_name = target_col_name\n        self.content_type_field_name = content_type_field_name\n        self.object_id_field_name = object_id_field_name\n        self.pk_val = self.instance._get_pk_val()\n                    \n    def get_query_set(self):\n        query = {\n            '%s__pk' % self.content_type_field_name : self.content_type.id, \n            '%s__exact' % self.object_id_field_name : self.pk_val,\n        }\n        return superclass.get_query_set(self).filter(**query)\n\n    def add(self, *objs):\n        for obj in objs:\n            setattr(obj, self.content_type_field_name, self.content_type)\n            setattr(obj, self.object_id_field_name, self.pk_val)\n            obj.save()\n    add.alters_data = True\n\n    def remove(self, *objs):\n        for obj in objs:\n            obj.delete()\n    remove.alters_data = True\n\n    def clear(self):\n        for obj in self.all():\n            obj.delete()\n    clear.alters_data = True\n\n    def create(self, **kwargs):\n        kwargs[self.content_type_field_name] = self.content_type\n        kwargs[self.object_id_field_name] = self.pk_val\n        obj = self.model(**kwargs)\n        obj.save()\n        return obj\n    create.alters_data = True\n\nreturn GenericRelatedObjectManager", "path": "lib\\django\\django\\db\\models\\fields\\generic.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "\"\"\"\nParse the first YAML document in a stream\nand produce the corresponding representation tree.\n\"\"\"\n", "func_signal": "def compose(stream, Loader=Loader):\n", "code": "loader = Loader(stream)\nif loader.check_node():\n    return loader.get_node()", "path": "lib\\yaml\\lib\\yaml\\__init__.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "\"\"\"\nScan a YAML stream and produce scanning tokens.\n\"\"\"\n", "func_signal": "def scan(stream, Loader=Loader):\n", "code": "loader = Loader(stream)\nwhile loader.check_token():\n    yield loader.get_token()", "path": "lib\\yaml\\lib\\yaml\\__init__.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "# match_obj.group(1) is the contents of the parenthesis.\n# First we need to figure out whether it's a named or unnamed group.\n#\n", "func_signal": "def __call__(self, match_obj):\n", "code": "grouped = match_obj.group(1)\nm = re.search(r'^\\?P<(\\w+)>(.*?)$', grouped)\nif m: # If this was a named group...\n    # m.group(1) is the name of the group\n    # m.group(2) is the regex.\n    try:\n        value = self.kwargs[m.group(1)]\n    except KeyError:\n        # It was a named group, but the arg was passed in as a\n        # positional arg or not at all.\n        try:\n            value = self.args[self.current_arg]\n            self.current_arg += 1\n        except IndexError:\n            # The arg wasn't passed in.\n            raise NoReverseMatch('Not enough positional arguments passed in')\n    test_regex = m.group(2)\nelse: # Otherwise, this was a positional (unnamed) group.\n    try:\n        value = self.args[self.current_arg]\n        self.current_arg += 1\n    except IndexError:\n        # The arg wasn't passed in.\n        raise NoReverseMatch('Not enough positional arguments passed in')\n    test_regex = grouped\n# Note we're using re.match here on purpose because the start of\n# to string needs to match.\nif not re.match(test_regex + '$', str(value)): # TODO: Unicode?\n    raise NoReverseMatch(\"Value %r didn't match regular expression %r\" % (value, test_regex))\nreturn str(value) # TODO: Unicode?", "path": "lib\\django\\django\\core\\urlresolvers.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "# Converts 'django.views.news.stories.story_detail' to\n# ['django.views.news.stories', 'story_detail']\n", "func_signal": "def get_mod_func(callback):\n", "code": "try:\n    dot = callback.rindex('.')\nexcept ValueError:\n    return callback, ''\nreturn callback[:dot], callback[dot+1:]", "path": "lib\\django\\django\\core\\urlresolvers.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "# If self._choices is set, then somebody must have manually set\n# the property self.choices. In this case, just return self._choices.\n", "func_signal": "def _get_choices(self):\n", "code": "if hasattr(self, '_choices'):\n    return self._choices\n# Otherwise, execute the QuerySet in self.queryset to determine the\n# choices dynamically. Return a fresh QuerySetIterator that has not\n# been consumed. Note that we're instantiating a new QuerySetIterator\n# *each* time _get_choices() is called (and, thus, each time\n# self.choices is accessed) so that we can ensure the QuerySet has not\n# been consumed.\nreturn QuerySetIterator(self.queryset, self.empty_label, self.cache_choices)", "path": "lib\\django\\django\\newforms\\models.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "\"\"\"\nParse a YAML stream and produce parsing events.\n\"\"\"\n", "func_signal": "def parse(stream, Loader=Loader):\n", "code": "loader = Loader(stream)\nwhile loader.check_event():\n    yield loader.get_event()", "path": "lib\\yaml\\lib\\yaml\\__init__.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "# regex is a string representing a regular expression.\n# urlconf_name is a string representing the module containing urlconfs.\n", "func_signal": "def __init__(self, regex, urlconf_name, default_kwargs=None):\n", "code": "self.regex = re.compile(regex)\nself.urlconf_name = urlconf_name\nself.callback = None\nself.default_kwargs = default_kwargs or {}", "path": "lib\\django\\django\\core\\urlresolvers.py", "repo_name": "vin/gerbilcount", "stars": 3, "license": "other", "language": "python", "size": 2244}
{"docstring": "\"\"\"\nFinds the element with the given DN and returns it. If no element was\nfound or more than one element was found an Exception is risen.\n\ndn -- the DN of the element\n\"\"\"\n", "func_signal": "def _find_element(self, dn):\n", "code": "results = filter(lambda i: i.dn == dn, self.elements)\nif len(results) != 1:\n\traise RuntimeError(\"No such element with the dn: %s\" % dn)\nreturn results[0]", "path": "src\\active_ldap\\ldap_stubber\\ldap_stubber.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nReturns the initial combination-value for the given operator\n\nop -- the operator \n\"\"\"\n", "func_signal": "def _init_for_op(self, op):\n", "code": "if op == '&': \n\treturn True\nreturn False", "path": "src\\active_ldap\\ldap_stubber\\ldap_stubber.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nReturns all attributes as a dictionary.\n\"\"\"\n", "func_signal": "def _result_dict(self):\n", "code": "dict = {}\nfor attr in self.attributes:\n\tdict[attr] = getattr(self, attr)\nreturn dict", "path": "src\\active_ldap\\ldap_stubber\\ldap_stubber.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nReturns the callbacks. If the attribute is not existing it will be\ninitialized.\n\"\"\"\n", "func_signal": "def get_callbacks(self):\n", "code": "if not hasattr(self, '_callbacks'):\n\tself._callbacks = {}\nreturn self._callbacks", "path": "src\\active_ldap\\signals\\signals.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nReturns true if the element has the given prefix\n\nprefix -- the ldap-prefix of the object\nscope -- the scope of the search operation\n\"\"\"\n", "func_signal": "def has_prefix(self, prefix, scope=ldap.SCOPE_SUBTREE):\n", "code": "if scope == ldap.SCOPE_SUBTREE:\n\treturn self.dn.endswith(prefix)\nreturn re.sub(r'.*?,', '', self.dn, 1) == prefix", "path": "src\\active_ldap\\ldap_stubber\\ldap_stubber.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nNotifies all callbacks, which are registered for the given event and\nsends them the given message.\n\nevent -- the event which occured\nmessage -- the message which should be send\n\"\"\"\n", "func_signal": "def notify(self, event, *messages):\n", "code": "for callback in self.catchall_callbacks:\n\tcallback(event, *messages)\nif event not in self.callbacks:\n\treturn\nfor callback in self.callbacks[event]:\n\tcallback(event, *messages)", "path": "src\\active_ldap\\signals\\signals.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nHandles regular filter expressions like attr1=value.\n\nop -- the operator\nmatch -- the filter expression\n\"\"\"\n", "func_signal": "def _handle_attribute(self, op, match):\n", "code": "try:\n\tattr, val = match.split('=')\n\treturn val in getattr(self, attr)\nexcept:\n\treturn False", "path": "src\\active_ldap\\ldap_stubber\\ldap_stubber.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nReplaces the entire values of the given attribute with the new values\n\nattr -- The attribute\n\"\"\"\n", "func_signal": "def _replace(self, attr, val):\n", "code": "if not isinstance(val, list):\n\tval = [ val ]\nsetattr(self, attr, val)", "path": "src\\active_ldap\\ldap_stubber\\ldap_stubber.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nModifies the DN of the element.\n\ndn -- the full distinguished name of the element\nrdn -- the new RDN of the element\nflag -- True if the old element should be destroyed\n\"\"\"\n", "func_signal": "def modrdn_s(self, dn, rdn, flag):\n", "code": "if flag == False:\n\traise RuntimeError(\"Operation not supported\")\nelement = self._find_element(dn)\nelement.modrdn(rdn)", "path": "src\\active_ldap\\ldap_stubber\\ldap_stubber.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nUnregisters the callback for the given event\n\nevent -- the event for which the callback should be unregistered\ncallback -- the callback which should be removed\n\"\"\"\n", "func_signal": "def unregister(self, event, callback):\n", "code": "if event == '__all__':\n\tself.catchall_callbacks.remove(callback)\n\treturn\nif event not in self.callbacks:\n\treturn\nself.callbacks[event].remove(callback)", "path": "src\\active_ldap\\signals\\signals.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nHandles an filter-expression element like (attr1=value1)(attr2=value2)\nor attr1=value1.\nIt returns either true or false if the elements are matching or not.\n\nop -- is the operator which should be used for combining the elements\nmatch -- is the filter sub-expression\n\"\"\"\n# an element like (attr1=b)(attr2=c) is given. Thus we are splitting\n# those elements up and calling matches recursively\n", "func_signal": "def _handle_element(self, op, match):\n", "code": "if '(' in match:\n\treturn self._handle_nodes(op, match)\n# normal handling of elements\nreturn self._handle_attribute(op, match)", "path": "src\\active_ldap\\ldap_stubber\\ldap_stubber.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nReturns a list of callbacks which should be called everytime a new\nevent occured.\n\"\"\"\n", "func_signal": "def get_catchall_callbacks(self):\n", "code": "if not hasattr(self, '_catchall_callbacks'):\n\tself._catchall_callbacks = []\nreturn self._catchall_callbacks", "path": "src\\active_ldap\\signals\\signals.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nModifies an ldap object\n\ndn -- the DN of the object\nattrs -- The new attributes\n\"\"\"\n", "func_signal": "def modify_s(self, dn, attrs):\n", "code": "element = self._find_element(dn)\nelement.modify(attrs)", "path": "src\\active_ldap\\ldap_stubber\\ldap_stubber.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nThis decorator emits an event before the encapsulated function is called\nand after the encapsulated function is called. The event has the name\nbefore_<function_name> and after_<function_name>. The encapsulated function\n_must_ be a instance-method, or maybe a class-method, otherwise the\nautomatic dispatch-mechanism with the Sendable metaclass will probably \nfail.\n\"\"\"\n", "func_signal": "def send_event(func):\n", "code": "def new_fun(self, *args, **kwds):\n\tbefore_name = 'before_%s' % func.__name__\n\tafter_name  = 'after_%s' % func.__name__\n\n\tself.events.notify(before_name, self)\n\tresult = func(self, *args, **kwds)\n\tself.events.notify(after_name, self)\n\n\treturn result\nreturn new_fun", "path": "src\\active_ldap\\signals\\signals.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nAdds a new value to the list\n\nattr -- the attribute which should be modified\nval -- the value which should be added\n\"\"\"\n", "func_signal": "def _add(self, attr, val):\n", "code": "if not hasattr(self, attr):\n\tsetattr(self, attr, [])\n\nlist = getattr(self, attr)\nlist += val\nsetattr(self, attr, list)", "path": "src\\active_ldap\\ldap_stubber\\ldap_stubber.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nReturns true if the element matches the given filter\n\nfilter -- a LDAP-Filter expression\n\"\"\"\n", "func_signal": "def matches(self, filter):\n", "code": "ops = [ '&', '|' ]\nmatch = self.parenthesis.match(filter).groups()\nop = '&'\nif match[0]:\n\top = match[0]\nmatch = match[1:]\nrv = self._init_for_op(op)\nfor i in match:\n\trv = self._combine(op, rv, self._handle_element(op, i))\nreturn rv", "path": "src\\active_ldap\\ldap_stubber\\ldap_stubber.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nHandles elements like '(attr1=b)(attr2=c)'. It splits those elements up\nand calls for each filter-element recursively the matches-method.\n\nop -- the operator\nmatch -- the filter expression\n\"\"\"\n", "func_signal": "def _handle_nodes(self, op, match):\n", "code": "nodes = parse_expression(match)\nrv = self._init_for_op(op)\nfor node in nodes:\n\trv = self._combine(op, rv, self.matches(node))\nreturn rv", "path": "src\\active_ldap\\ldap_stubber\\ldap_stubber.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nThis method is called if a event was received. It tries to find methods\nwith the same name as the event on the item which sent the message and\ncalls them. The first element in the messages-array _must_ therefore be\nthe object whose methods should be called.\n\nevent -- the received event.\nmessages -- the received messages.\n\"\"\"\n", "func_signal": "def _event_received(self, event, *messages):\n", "code": "obj = messages[0]\nif hasattr(obj, event):\n\tgetattr(obj, event)(*messages[1:])", "path": "src\\active_ldap\\signals\\signals.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nCombines the given values with the given operator.\n\nop -- either & or |\nval1 -- the first boolean value\nval2 -- the second boolean value\n\"\"\"\n", "func_signal": "def _combine(self, op, val1, val2):\n", "code": "if op == '&':\n\treturn val1 and val2\nif op == '|':\n\treturn val1 or val2", "path": "src\\active_ldap\\ldap_stubber\\ldap_stubber.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nAppends the given attribute to the internal list of attributes. If the\nattribute already exists within the list it won't be added.\n\nattr -- the name of the new attribute which should be added\n\"\"\"\n", "func_signal": "def _append_attribute(self, attr):\n", "code": "if attr not in self.attributes:\n\tself.attributes.append(attr)", "path": "src\\active_ldap\\ldap_stubber\\ldap_stubber.py", "repo_name": "mop/python-activeldap", "stars": 3, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"\nThis function builds the data structure required by ``comment_check``,\n``submit_spam``, and ``submit_ham``.\n\nIt modifies the ``data`` dictionary you give it in place. (and so\ndoesn't return anything)\n\nIt raises an ``AkismetError`` if the user IP or user-agent can't be\nworked out.\n\"\"\"\n", "func_signal": "def _build_data(self, comment, data):\n", "code": "data['comment_content'] = comment\nif not 'user_ip' in data:\n    try:\n        val = os.environ['REMOTE_ADDR']\n    except KeyError:\n        raise AkismetError(\"No 'user_ip' supplied\")\n    data['user_ip'] = val\nif not 'user_agent' in data:\n    try:\n        val = os.environ['HTTP_USER_AGENT']\n    except KeyError:\n        raise AkismetError(\"No 'user_agent' supplied\")\n    data['user_agent'] = val\n#\ndata.setdefault('referrer', os.environ.get('HTTP_REFERER', 'unknown'))\ndata.setdefault('permalink', '')\ndata.setdefault('comment_type', 'comment')\ndata.setdefault('comment_author', '')\ndata.setdefault('comment_author_email', '')\ndata.setdefault('comment_author_url', '')\ndata.setdefault('SERVER_ADDR', os.environ.get('SERVER_ADDR', ''))\ndata.setdefault('SERVER_ADMIN', os.environ.get('SERVER_ADMIN', ''))\ndata.setdefault('SERVER_NAME', os.environ.get('SERVER_NAME', ''))\ndata.setdefault('SERVER_PORT', os.environ.get('SERVER_PORT', ''))\ndata.setdefault('SERVER_SIGNATURE', os.environ.get('SERVER_SIGNATURE',\n    ''))\ndata.setdefault('SERVER_SOFTWARE', os.environ.get('SERVER_SOFTWARE',\n    ''))\ndata.setdefault('HTTP_ACCEPT', os.environ.get('HTTP_ACCEPT', ''))\ndata.setdefault('blog', self.blog_url)", "path": "akismet.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nThis function is used to tell akismet that a comment it marked as ham,\nis really spam.\n\nIt takes all the same arguments as ``comment_check``, except for\n*DEBUG*.\n\"\"\"\n", "func_signal": "def submit_spam(self, comment, data=None, build_data=True):\n", "code": "if self.key is None:\n    raise APIKeyError(\"Your have not set an API key.\")\nif data is None:\n    data = {}\nif build_data:\n    self._build_data(comment, data)\nurl = '%ssubmit-spam' % self._getURL()\n# we *don't* trap the error here\n# so if akismet is down it will raise an HTTPError or URLError\nheaders = {'User-Agent' : self.user_agent}\nself._safeRequest(url, urlencode(data), headers)", "path": "akismet.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nPrint to the ``stdout``.\n\nSet ``unbuff=True`` to flush the buffer after every write.\n\nIt prints the inline you send it, followed by the ``line_end``. By default this \nis ``\\r\\n`` - which is the standard specified by the RFC for http headers.\n\"\"\"\n", "func_signal": "def cgiprint(inline='', unbuff=False, line_end='\\r\\n'):\n", "code": "sys.stdout.write(inline)\nsys.stdout.write(line_end)\nif unbuff:\n    sys.stdout.flush()", "path": "cgiutils.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nThis is the function that checks comments.\n\nIt returns ``True`` for spam and ``False`` for ham.\n\nIf you set ``DEBUG=True`` then it will return the text of the response,\ninstead of the ``True`` or ``False`` object.\n\nIt raises ``APIKeyError`` if you have not yet set an API key.\n\nIf the connection to Akismet fails then the ``HTTPError`` or\n``URLError`` will be propogated.\n\nAs a minimum it requires the body of the comment. This is the\n``comment`` argument.\n\nAkismet requires some other arguments, and allows some optional ones.\nThe more information you give it, the more likely it is to be able to\nmake an accurate diagnosise.\n\nYou supply these values using a mapping object (dictionary) as the\n``data`` argument.\n\nIf ``build_data`` is ``True`` (the default), then *akismet.py* will\nattempt to fill in as much information as possible, using default\nvalues where necessary. This is particularly useful for programs\nrunning in a {acro;CGI} environment. A lot of useful information\ncan be supplied from evironment variables (``os.environ``). See below.\n\nYou *only* need supply values for which you don't want defaults filled\nin for. All values must be strings.\n\nThere are a few required values. If they are not supplied, and\ndefaults can't be worked out, then an ``AkismetError`` is raised.\n\nIf you set ``build_data=False`` and a required value is missing an\n``AkismetError`` will also be raised.\n\nThe normal values (and defaults) are as follows : ::\n\n    'user_ip':          os.environ['REMOTE_ADDR']       (*)\n    'user_agent':       os.environ['HTTP_USER_AGENT']   (*)\n    'referrer':         os.environ.get('HTTP_REFERER', 'unknown') [#]_\n    'permalink':        ''\n    'comment_type':     'comment' [#]_\n    'comment_author':   ''\n    'comment_author_email': ''\n    'comment_author_url': ''\n    'SERVER_ADDR':      os.environ.get('SERVER_ADDR', '')\n    'SERVER_ADMIN':     os.environ.get('SERVER_ADMIN', '')\n    'SERVER_NAME':      os.environ.get('SERVER_NAME', '')\n    'SERVER_PORT':      os.environ.get('SERVER_PORT', '')\n    'SERVER_SIGNATURE': os.environ.get('SERVER_SIGNATURE', '')\n    'SERVER_SOFTWARE':  os.environ.get('SERVER_SOFTWARE', '')\n    'HTTP_ACCEPT':      os.environ.get('HTTP_ACCEPT', '')\n\n(*) Required values\n\nYou may supply as many additional 'HTTP_*' type values as you wish.\nThese should correspond to the http headers sent with the request.\n\n.. [#] Note the spelling \"referrer\". This is a required value by the\n    akismet api - however, referrer information is not always\n    supplied by the browser or server. In fact the HTTP protocol\n    forbids relying on referrer information for functionality in \n    programs.\n.. [#] The `API docs <http://akismet.com/development/api/>`_ state that this value\n    can be \" *blank, comment, trackback, pingback, or a made up value*\n    *like 'registration'* \".\n\"\"\"\n", "func_signal": "def comment_check(self, comment, data=None, build_data=True, DEBUG=False):\n", "code": "if self.key is None:\n    raise APIKeyError(\"Your have not set an API key.\")\nif data is None:\n    data = {}\nif build_data:\n    self._build_data(comment, data)\nurl = '%scomment-check' % self._getURL()\n# we *don't* trap the error here\n# so if akismet is down it will raise an HTTPError or URLError\nheaders = {'User-Agent' : self.user_agent}\nresp = self._safeRequest(url, urlencode(data), headers)\nif DEBUG:\n    return resp\nresp = resp.lower()\nif resp == 'true':\n    return True\nelif resp == 'false':\n    return False\nelse:\n    # NOTE: Happens when you get a 'howdy wilbur' response !\n    raise AkismetError('missing required argument.')", "path": "akismet.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nSet the wordpress API key for all transactions.\n\nIf you don't specify an explicit API ``key`` and ``blog_url`` it will\nattempt to load them from a file called ``apikey.txt`` in the current\ndirectory.\n\nThis method is *usually* called automatically when you create a new\n``Akismet`` instance.\n\"\"\"\n", "func_signal": "def setAPIKey(self, key=None, blog_url=None):\n", "code": "if key is None and isfile('apikey.txt'):\n    the_file = [l.strip() for l in open('apikey.txt').readlines()\n        if l.strip() and not l.strip().startswith('#')]\n    try:\n        self.key = the_file[0]\n        self.blog_url = the_file[1]\n    except IndexError:\n        raise APIKeyError(\"Your 'apikey.txt' is invalid.\")\nelse:\n    self.key = key\n    self.blog_url = blog_url", "path": "akismet.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"Returns some data about the CGI environment, in a way that can be mailed.\"\"\"\n", "func_signal": "def environdata():\n", "code": "ENVIRONLIST = [ 'REQUEST_URI','HTTP_USER_AGENT','REMOTE_ADDR','HTTP_FROM','REMOTE_HOST','REMOTE_PORT','SERVER_SOFTWARE','HTTP_REFERER','REMOTE_IDENT','REMOTE_USER','QUERY_STRING','DATE_LOCAL' ]  # XXX put this in template ??\nenvirons = []\nenvirons.append(\"\\n\\n---------------------------------------\\n\")\nfor x in ENVIRONLIST:\n    if os.environ.has_key(x):\n        environs.append(\"%s: %s\\n\" % (x, os.environ[x]))\nenvirons.append(\"---------------------------------------\\n\")\nreturn ''.join(environs)", "path": "cgiutils.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nA quick function to do a basic email validation.\nReturns False or the email address.\n\"\"\"\n", "func_signal": "def validemail(email):\n", "code": "if ' ' in email:\n    return False\ndot = email.rfind('.')\nat = email.find('@')\nif dot == -1 or at < 1 or at > dot:\n    return False\nreturn email", "path": "cgiutils.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nPassed a form (FieldStorage instance) return all the values.\nThis doesn't take into account file uploads.\n\nAlso accepts the 'nolist' keyword argument as ``getform``.\n\nReturns a dictionary.\n\"\"\"\n", "func_signal": "def getall(theform, nolist=False):\n", "code": "data = {}\nfor field in theform.keys():\n    if not isinstance(theform[field], list):\n        data[field] = theform[field].value\n    else:\n        if not nolist:\n            # allows for list type values\n            data[field] = [x.value for x in theform[field]]\n        else:\n            # just fetch the first item\n            data[field] = theform[field][0].value\nreturn data", "path": "cgiutils.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nAccepts a string as input.\n\nIf the string is one of  ``True``, ``On``, ``Yes``, or ``1`` it returns \n``True``.\n\nIf the string is one of  ``False``, ``Off``, ``No``, or ``0`` it returns \n``False``.\n\n``istrue`` is not case sensitive.\n\nAny other input will raise a ``KeyError``. \n\"\"\"\n", "func_signal": "def istrue(value):\n", "code": "return {\n    'yes': True, 'no': False,\n    'on': True, 'off': False, \n    '1': True, '0': False,\n    'true': True, 'false': False,\n    }[value.lower()]", "path": "cgiutils.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nInitialise the ``FieldStorage`` and return the specified list of values as \na dictionary.\n\nIf you don't specify a list of values, then *all* values will be returned.\n\nIf you set ``nolist`` to ``True`` then any parameters supplied as lists \nwill only have their first entry returned.\n\"\"\"\n", "func_signal": "def getrequest(valuelist=None, nolist=False):\n", "code": "import cgi\nform = cgi.FieldStorage()\nif valuelist is not None:\n    return getform(valuelist, form, nolist=nolist)\nelse:\n    return getall(form, nolist=nolist)", "path": "cgiutils.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nMake a menu line for a given number of inputs, with a certain number per page.\nWill look something like : ::\n\n    First  Previous  22 23 24 25 26 27 28 29 30 31 32  Next  Last\n\nEach number or word will be a link to the relevant page.\n\nurl should be in the format : ``'<a href=\"script.py?startpage=%s\">%s</a>'`` - \nit will have the two ``%s`` values filled in by the function.\n\nThe url will automatically be put between ``<strong></strong>`` tags. Your \nscript needs to accepts a parameter ``start`` telling it which page to display.\n\n``startpage`` is the page actually being viewed - which won't be a link.\n\n``total`` is the number of total inputs.\n\n``numonpage`` is the number of inputs per page - this tells makeindexline how \nmany pages to divide the total into.\n\nThe links shown will be some before startpage and some after. The amount of \npages links are shown for is ``pagesonscreen``. (The actual total number shown \nwill be *2 \\* pagesonscreen + 1*).\n\nThe indexes generated are *a bit* like the ones created by google. Unlike \ngoogle however, next and previous jump you into the *middle* of the next set of \nlinks. i.e. If you are on page 27 next will take you to 33 and previous to 21. \n(assuming pagesonscreen is 5). This makes it possible to jump more quickly \nthrough a lot of links. Also - the current page will always be in the center of \nthe index. (So you never *need* Next just to get to the next page).\n\"\"\"\n", "func_signal": "def makeindexline(url, startpage, total, numonpage=10, pagesonscreen=5):\n", "code": "b = '<strong>%s</strong>'\nurl = b % url\noutlist = []\nlast = ''\nnext = ''\nnumpages = total//numonpage\nif total%numonpage:\n    numpages += 1\nif startpage - pagesonscreen > 1:\n    outlist.append(url % (1, 'First'))\n    outlist.append('&nbsp;')\n    outlist.append(url % (startpage-pagesonscreen-1, 'Previous'))\n    outlist.append('&nbsp;')\nindex = max(startpage - pagesonscreen, 1)\nend = min(startpage+pagesonscreen, numpages)\nwhile index <= end:\n    if index == startpage:\n        outlist.append(b % startpage)\n    else:\n        outlist.append(url % (index, index))\n    index += 1\noutlist.append('&nbsp;')\nif (startpage+pagesonscreen) < numpages:\n    outlist.append(url % (startpage+pagesonscreen+1, 'Next'))\n    outlist.append('&nbsp;')\n    outlist.append(url % (numpages, 'Last'))\n\nreturn '&nbsp;'.join(outlist)", "path": "cgiutils.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"Automatically calls ``setAPIKey``.\"\"\"\n", "func_signal": "def __init__(self, key=None, blog_url=None, agent=None):\n", "code": "if agent is None:\n    agent = DEFAULTAGENT % __version__\nself.user_agent = user_agent % (agent, __version__)\nself.setAPIKey(key, blog_url)", "path": "akismet.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nThis function provides a simple but effective template system for your html \npages. Effectively it is a convenient way of doing multiple replaces in a \nsingle string.\n\nTakes a string and a dictionary of replacements. \n\nThis function goes through the string and replaces every occurrence of every \ndicitionary key with it's value.\n\n``indict`` can also be a list of tuples instead of a dictionary (or anything \naccepted by the dict function).\n\"\"\"\n", "func_signal": "def replace(instring, indict):\n", "code": "indict = dict(indict)\nif len(indict) > 40:\n    regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, indict.keys())))\n    # For each match, look-up corresponding value in dictionary\n    return regex.sub(lambda mo: indict[mo.string[mo.start():mo.end()]],\n                                                                instring)\nfor key in indict:\n    instring = instring.replace(key, indict[key])\nreturn instring", "path": "cgiutils.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nThis function is used to tell akismet that a comment it marked as spam,\nis really ham.\n\nIt takes all the same arguments as ``comment_check``, except for\n*DEBUG*.\n\"\"\"\n", "func_signal": "def submit_ham(self, comment, data=None, build_data=True):\n", "code": "if self.key is None:\n    raise APIKeyError(\"Your have not set an API key.\")\nif data is None:\n    data = {}\nif build_data:\n    self._build_data(comment, data)\nurl = '%ssubmit-ham' % self._getURL()\n# we *don't* trap the error here\n# so if akismet is down it will raise an HTTPError or URLError\nheaders = {'User-Agent' : self.user_agent}\nself._safeRequest(url, urlencode(data), headers)", "path": "akismet.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"Decode a single string back into a form like dictionary.\"\"\"\n", "func_signal": "def formdecode(thestring):\n", "code": "from cgi import parse_qs\nfrom urllib import unquote_plus \nreturn parse_qs(unquote_plus(thestring), True)", "path": "cgiutils.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nReturns ``True`` if ip address is a blacklisted IP (i.e. from a spammer).\n\nip can also be a domain name - this raises ``socket.gaierror`` if the ip is\na domain name that cannot be resolved.\n\nThe DNS blacklist host (``DNSBL_HOST``) defaults to *sbl-xbl.spamhaus.org*.\n\nOther ones you could use include :\n\n- 'relays.ordb.org'\n- 'dns.rfc-ignorant.org'\n- 'postmaster.rfc-ignorant.org'\n- 'http.dnsbl.sorbs.net'\n- 'misc.dnsbl.sorbs.net'\n- 'spam.dnsbl.sorbs.net'\n- 'bl.spamcop.net'\n\nUseful for vetting user added information posted to web applications.\n\"\"\"\n# turn '1.2.3.4' into '4.3.2.1.sbl-xbl.spamhaus.org'\n", "func_signal": "def blacklisted(ip, DNSBL_HOST='sbl-xbl.spamhaus.org'):\n", "code": "import socket\n# convert domain name to IP\n# raises an error if domain name can't be resolved\nip = socket.gethostbyname(ip)\niplist = ip.split('.')\niplist.reverse()\nip = '%s.%s' % ('.'.join(iplist), DNSBL_HOST)\ntry:\n    socket.gethostbyname(ip)\n    return True\nexcept socket.gaierror:\n    return False", "path": "cgiutils.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nThis equates to the ``verify-key`` call against the akismet API.\n\nIt returns ``True`` if the key is valid.\n\nThe docs state that you *ought* to call this at the start of the\ntransaction.\n\nIt raises ``APIKeyError`` if you have not yet set an API key.\n\nIf the connection to akismet fails, it allows the normal ``HTTPError``\nor ``URLError`` to be raised.\n(*akismet.py* uses `urllib2 <http://docs.python.org/lib/module-urllib2.html>`_)\n\"\"\"\n", "func_signal": "def verify_key(self):\n", "code": "if self.key is None:\n    raise APIKeyError(\"Your have not set an API key.\")\ndata = { 'key': self.key, 'blog': self.blog_url }\n# this function *doesn't* use the key as part of the URL\nurl = 'http://%sverify-key' % self.baseurl\n# we *don't* trap the error here\n# so if akismet is down it will raise an HTTPError or URLError\nheaders = {'User-Agent' : self.user_agent}\nresp = self._safeRequest(url, urlencode(data), headers)\nif resp.lower() == 'valid':\n    return True\nelse:\n    return False", "path": "akismet.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nA version that turns a cgi form into a single string.\nIt only handles single and list values, not multipart.\nThis allows the contents of a form requested to be encoded into a single value as part of another request.\n\"\"\"\n", "func_signal": "def formencode(theform):\n", "code": "from urllib import urlencode, quote_plus\nreturn quote_plus(urlencode(getall(theform)))", "path": "cgiutils.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "\"\"\"\nA unicode version of ``cgiprint``. It allows you to store everything in your \nscript as unicode and just do your encoding in one place.\n\nPrint to the ``stdout``.\n\nSet ``unbuff=True`` to flush the buffer after every write.\n\nIt prints the inline you send it, followed by the ``line_end``. By default this \nis ``\\r\\n`` - which is the standard specified by the RFC for http headers.\n\n``inline`` should be a unicode string.\n\n``encoding`` is the encoding used to encode ``inline`` to a byte-string. It \ndefaults to ``UTF-8``, set it to ``None`` if you pass in ``inline`` as a byte \nstring rather than a unicode string.\n\"\"\"\n", "func_signal": "def ucgiprint(inline='', unbuff=False, encoding='UTF-8', line_end='\\r\\n'):\n", "code": "if encoding:\n    inline = inline.encode(encoding)\n    # don't need to encode the line endings\nsys.stdout.write(inline)\nsys.stdout.write(line_end)\nif unbuff:\n    sys.stdout.flush()", "path": "cgiutils.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "#\n# FIXME: could break here if apikey.txt exists, but has no key/blog_url\n", "func_signal": "def results(req):\n", "code": "api = Akismet()\nif api.key is None:\n    # apikey.txt file\n    return no_key % ''\nif not api.verify_key():\n    # invalid key\n    return no_key % 'Valid '\n# check the form - it contains some relevant data\n# the rest will be filled in with defaults\nfor entry, val in os.environ.items():\n    if entry.startswith('HTTP'):\n        req[entry] = val\nresult = api.comment_check(req['comment'], req, DEBUG=DEBUG)\nif DEBUG:\n    return res_line % result\nelif result:\n    return res_line % 'Spam'\nelse:\n    return res_line % 'Ham'", "path": "test_akismet.py", "repo_name": "clones/python-akismet", "stars": 3, "license": "None", "language": "python", "size": 184}
{"docstring": "'''write a nicely packed, ordered hex file'''\n", "func_signal": "def write_hex(datastr, outfile):\n", "code": "file = open(outfile, 'w')\n\neof = 0\naddress = 0\t\nwhile not eof:\n\taddr = '%.4X' %address\n\ttype = '00'\n\tif len(datastr) > DLEN*2:\n\t\tcount = '%.2X' %DLEN\n\t\tdata, datastr = datastr[0:32], datastr[32:]\n\t\taddress += DLEN\n\telse:\n\t\tcount = '%.2X' %(len(datastr)/2)\n\t\tdata = datastr\n\t\teof = 1\n\n\tline = '%s%s%s%s'%(count, addr, type, data)\n\tchecksum = getchecksum(line)\t\t\n\tfile.write(':%s%s\\n' %(line,checksum))\n\nfile.write(':00000001FF\\n')\t\nfile.close()", "path": "Eco-build-Keilc\\eco-dev\\FFT_TEST_permute_bitrev\\eeprep.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print s_name \n", "func_signal": "def _check_segment(self,s_name):\n", "code": "if s_name.find('?C_') != -1 or s_name.find('?C?') != -1:\n    #print '\\t\\t%s is system c library' %s_name\n    return False\nelif s_name.find('RF_CH1_RECV') != -1:\n    return False\nelif s_name.find('?MAIN?') != -1:\n    return False\nelif s_name.find('?CO?') != -1:\n    #print '\\t\\t%s is constant data memory' %s_name\n    return False\nelse:\n    reg_int = re.search('[\\?][$\\d]',s_name)\n    if reg_int:\n        return False\n    elif s_name.find('ECO_PAGE') != -1:\n        return False\n    return True", "path": "Eco-build-Keilc\\eco-dev\\FFT_256_RR_OP\\tools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print s_name \n", "func_signal": "def _check_segment(self,s_name):\n", "code": "if s_name.find('?C_') != -1 or s_name.find('?C?') != -1:\n    #print '\\t\\t%s is system c library' %s_name\n    return False\nelif s_name.find('RF_CH1_RECV') != -1:\n    return False\nelif s_name.find('?MAIN?') != -1:\n    return False\nelif s_name.find('?CO?') != -1:\n    #print '\\t\\t%s is constant data memory' %s_name\n    return False\nelif s_name.find('TIMER0') != -1:\n    return False\nelse:\n    reg_int = re.search('[\\?][$\\d]',s_name)\n    if reg_int:\n        return False\n    elif s_name.find('ECO_PAGE') != -1:\n        return False\n    return True", "path": "Eco-build-Keilc\\eco-dev\\test_serial_print_p128_LRU\\tools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print 'calculate reserved space'\n\n", "func_signal": "def calculate_reserved_space(self):\n", "code": "temp_code_memory = 0\n \nfor i in range(len(self.code_memory_list)):\n    if not self._check_segment(self.code_memory_segment_name[i]):\n        #print self.code_memory_segment_name[i] \n        temp_code_memory += int(self.code_memory_length[i][0:-1],16)\n\n\n#print 'reserved code_memory = ',temp_code_memory   \n \nself.ECO_RESERVED_SIZE = int(math.ceil(temp_code_memory / float(self.ECO_PAGE_SIZE)) * self.ECO_PAGE_SIZE)\n\n#print 'self.ECO_RESERVED_SIZE = ',self.ECO_RESERVED_SIZE", "path": "Eco-build-Keilc\\eco-dev\\FFT_128_RR\\tools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print s_name \n", "func_signal": "def _check_segment(self,s_name):\n", "code": "if s_name.find('?C_') != -1 or s_name.find('?C?') != -1:\n    #print '\\t\\t%s is system c library' %s_name\n    return False\nelif s_name.find('RF_CH1_RECV') != -1:\n    return False\nelif s_name.find('?MAIN?') != -1:\n    return False\nelif s_name.find('?CO?') != -1:\n    #print '\\t\\t%s is constant data memory' %s_name\n    return False\nelse:\n    reg_int = re.search('[\\?][$\\d]',s_name)\n    if reg_int:\n        return False\n    elif s_name.find('ECO_PAGE') != -1:\n        return False\n    return True", "path": "Eco-build-Keilc\\eco-dev\\test_library_page\\toools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print 'calculate reserved space'\n\n", "func_signal": "def calculate_reserved_space(self):\n", "code": "temp_code_memory = 0\n \nfor i in range(len(self.code_memory_list)):\n    if not self._check_segment(self.code_memory_segment_name[i]):\n        #print self.code_memory_segment_name[i] \n        temp_code_memory += int(self.code_memory_length[i][0:-1],16)\n\n\n#print 'reserved code_memory = ',temp_code_memory   \n \nself.ECO_RESERVED_SIZE = int(math.ceil(temp_code_memory / float(self.ECO_PAGE_SIZE)) * self.ECO_PAGE_SIZE)\n\n#print 'self.ECO_RESERVED_SIZE = ',self.ECO_RESERVED_SIZE", "path": "Eco-build-Keilc\\eco-dev\\test_datagrabber_algorithm2\\tools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print '---------------------------'\n#print 'relocate code memory'\n#print '---------------------------' \n\n#start from reserved size \n", "func_signal": "def relocate_code_memory(self):\n", "code": "code_start_address = self.ECO_RESERVED_SIZE \n\n#print self.code_memory_start\n#print self.code_memory_end \n#print self.code_memory_length\n#print self.code_memory_segment_name\n\nfor i in range(len(self.code_memory_list)):\n    if self._check_segment(self.code_memory_segment_name[i]):\n        #print '----------------------------------------'\n        #print '%s can be relocated' %self.code_memory_segment_name[i]\n        if (code_start_address/self.ECO_PAGE_SIZE) != ((code_start_address + int(self.code_memory_length[i][0:-1],16))/self.ECO_PAGE_SIZE):\n            #print 'cross page line'\n            code_start_address = (((code_start_address + int(self.code_memory_length[i][0:-1],16))/self.ECO_PAGE_SIZE) * self.ECO_PAGE_SIZE)\n            \n            if (code_start_address >> self.ECO_PAGE_MASK) not in self.eco_page_vid:\n                self.eco_page_vid.append(code_start_address >> self.ECO_PAGE_MASK)\n            \n            #print 'SEGMENTS\\\\(' + self.code_memory_segment_name[i] + '\\\\(C:' + hex(code_start_address) + '\\\\)\\\\)'\n            self.SEG_DIRECTIVE += ' SEGMENTS\\\\(' + self.code_memory_segment_name[i] + '\\\\(C:' + hex(code_start_address) + '\\\\)\\\\)'\n\n            #print '%s is located at %X' %(self.code_memory_segment_name[i],code_start_address) \n              \n        else:\n            #print 'still in page size'\n            \n            if (code_start_address >> self.ECO_PAGE_MASK) not in self.eco_page_vid:\n                self.eco_page_vid.append(code_start_address >> self.ECO_PAGE_MASK)\n\n            #print 'SEGMENTS\\\\(' + self.code_memory_segment_name[i] + '\\\\(C:' + hex(code_start_address) + '\\\\)\\\\)'\n            self.SEG_DIRECTIVE += ' SEGMENTS\\\\(' + self.code_memory_segment_name[i] + '\\\\(C:' + hex(code_start_address) + '\\\\)\\\\)'\n            \n            #print '%s is located at %X' %(self.code_memory_segment_name[i],code_start_address) \n\n        code_start_address = code_start_address + int(self.code_memory_length[i][0:-1],16)                 \n         \n        #print '----------------------------------------'\n \n#print self.SEG_DIRECTIVE\n#print 'self.eco_page_vid len = %d' %(len(self.eco_page_vid))\n#print 'self.eco_page_vid = ', self.eco_page_vid", "path": "Eco-build-Keilc\\eco-dev\\FFT_128_RR\\tools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "'''write a nicely packed, ordered hex file'''\n", "func_signal": "def write_hex(datastr, outfile):\n", "code": "file = open(outfile, 'w')\n\neof = 0\naddress = 0\t\nwhile not eof:\n\taddr = '%.4X' %address\n\ttype = '00'\n\tif len(datastr) > DLEN*2:\n\t\tcount = '%.2X' %DLEN\n\t\tdata, datastr = datastr[0:32], datastr[32:]\n\t\taddress += DLEN\n\telse:\n\t\tcount = '%.2X' %(len(datastr)/2)\n\t\tdata = datastr\n\t\teof = 1\n\n\tline = '%s%s%s%s'%(count, addr, type, data)\n\tchecksum = getchecksum(line)\t\t\n\tfile.write(':%s%s\\n' %(line,checksum))\n\nfile.write(':00000001FF\\n')\t\nfile.close()", "path": "Eco-build-Keilc\\eco-dev\\paging\\eeprep.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print s_name \n", "func_signal": "def _check_segment(self,s_name):\n", "code": "if s_name.find('?C_') != -1 or s_name.find('?C?') != -1:\n    #print '\\t\\t%s is system c library' %s_name\n    return False\nelif s_name.find('RF_CH1_RECV') != -1:\n    return False\nelif s_name.find('?MAIN?') != -1:\n    return False\nelif s_name.find('?CO?') != -1:\n    #print '\\t\\t%s is constant data memory' %s_name\n    return False\nelif s_name.find('TIMER0') != -1:\n    return False\nelse:\n    reg_int = re.search('[\\?][$\\d]',s_name)\n    if reg_int:\n        return False\n    elif s_name.find('ECO_PAGE') != -1:\n        return False\n    return True", "path": "Eco-build-Keilc\\eco-dev\\test_serial_print_p256\\tools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print s_name \n", "func_signal": "def _check_segment(self,s_name):\n", "code": "if s_name.find('?C_') != -1 or s_name.find('?C?') != -1:\n    #print '\\t\\t%s is system c library' %s_name\n    return False\nelif s_name.find('RF_CH1_RECV') != -1:\n    return False\nelif s_name.find('?MAIN?') != -1:\n    return False\nelif s_name.find('?CO?') != -1:\n    #print '\\t\\t%s is constant data memory' %s_name\n    return False\nelse:\n    reg_int = re.search('[\\?][$\\d]',s_name)\n    if reg_int:\n        return False\n    elif s_name.find('ECO_PAGE') != -1:\n        return False\n    return True", "path": "Eco-build-Keilc\\eco-dev\\test_datagrabber_algorithm2\\tools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print 'calculate reserved space'\n\n", "func_signal": "def calculate_reserved_space(self):\n", "code": "temp_code_memory = 0\n \nfor i in range(len(self.code_memory_list)):\n    if not self._check_segment(self.code_memory_segment_name[i]):\n        #print self.code_memory_segment_name[i] \n        temp_code_memory += int(self.code_memory_length[i][0:-1],16)\n\n\n#print 'reserved code_memory = ',temp_code_memory   \n \nself.ECO_RESERVED_SIZE = int(math.ceil(temp_code_memory / float(self.ECO_PAGE_SIZE)) * self.ECO_PAGE_SIZE)\n\n#print 'self.ECO_RESERVED_SIZE = ',self.ECO_RESERVED_SIZE", "path": "Eco-build-Keilc\\eco-dev\\FFT_256_RR_OP\\tools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print '---------------------------'\n#print 'parse code memory'\n#print '---------------------------' \n#print self.lines\n\n", "func_signal": "def parse_code_memory(self):\n", "code": "code_memory_flag = False\ncode_memory_counter = 0\n\nfor map_line in self.lines:\n    #reg = re.search(self.PATTERN_CODE_MEMORY,map_line)\n    #if reg:\n    #    print 'reg.group(0) = ', reg.group(0) \n    if map_line.find('*   C O D E   M E M O R Y   *') != -1:\n        code_memory_flag = True\n        continue\n\n    if code_memory_counter >= 3:\n        #print 'code memory is over'\n        code_memory_flag = False \n        break\n\n    if code_memory_flag:\n        #reg_code = re.search(self.PATTERN_CODE,map_line)\n        reg_code = re.search(self.PATTERN_CODE,map_line)\n        if reg_code:\n            #print reg_code.group(0)\n            code_memory_counter = 0\n            self.code_memory_list.append(reg_code.group(0))\n            self.code_memory_start.append(reg_code.group(1))\n            self.code_memory_end.append(reg_code.group(2))\n            self.code_memory_length.append(reg_code.group(3))\n            self.code_memory_segment_name.append(reg_code.group(7))\n        elif map_line == '\\n':\n            code_memory_counter += 1                \n        #print map_line", "path": "Eco-build-Keilc\\eco-dev\\test_datagrabber_algorithm2\\tools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print s_name \n", "func_signal": "def _check_segment(self,s_name):\n", "code": "if s_name.find('?C_') != -1 or s_name.find('?C?') != -1:\n    #print '\\t\\t%s is system c library' %s_name\n    return False\nelif s_name.find('RF_CH1_RECV') != -1:\n    return False\nelif s_name.find('?MAIN?') != -1:\n    return False\nelif s_name.find('?CO?') != -1:\n    #print '\\t\\t%s is constant data memory' %s_name\n    return False\nelse:\n    reg_int = re.search('[\\?][$\\d]',s_name)\n    if reg_int:\n        return False\n    elif s_name.find('ECO_PAGE') != -1:\n        return False\n    return True", "path": "Eco-build-Keilc\\eco-dev\\FFT_128_RR\\tools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print '---------------------------'\n#print 'parse code memory'\n#print '---------------------------' \n#print self.lines\n\n", "func_signal": "def parse_code_memory(self):\n", "code": "code_memory_flag = False\ncode_memory_counter = 0\n\nfor map_line in self.lines:\n    #reg = re.search(self.PATTERN_CODE_MEMORY,map_line)\n    #if reg:\n    #    print 'reg.group(0) = ', reg.group(0) \n    if map_line.find('*   C O D E   M E M O R Y   *') != -1:\n        code_memory_flag = True\n        continue\n\n    if code_memory_counter >= 3:\n        #print 'code memory is over'\n        code_memory_flag = False \n        break\n\n    if code_memory_flag:\n        #reg_code = re.search(self.PATTERN_CODE,map_line)\n        reg_code = re.search(self.PATTERN_CODE,map_line)\n        if reg_code:\n            #print reg_code.group(0)\n            code_memory_counter = 0\n            self.code_memory_list.append(reg_code.group(0))\n            self.code_memory_start.append(reg_code.group(1))\n            self.code_memory_end.append(reg_code.group(2))\n            self.code_memory_length.append(reg_code.group(3))\n            self.code_memory_segment_name.append(reg_code.group(7))\n        elif map_line == '\\n':\n            code_memory_counter += 1                \n        #print map_line", "path": "Eco-build-Keilc\\eco-dev\\FFT_128_RR\\tools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "'''write a nicely packed, ordered hex file'''\n", "func_signal": "def write_hex(datastr, outfile):\n", "code": "file = open(outfile, 'w')\n\neof = 0\naddress = 0\t\nwhile not eof:\n\taddr = '%.4X' %address\n\ttype = '00'\n\tif len(datastr) > DLEN*2:\n\t\tcount = '%.2X' %DLEN\n\t\tdata, datastr = datastr[0:32], datastr[32:]\n\t\taddress += DLEN\n\telse:\n\t\tcount = '%.2X' %(len(datastr)/2)\n\t\tdata = datastr\n\t\teof = 1\n\n\tline = '%s%s%s%s'%(count, addr, type, data)\n\tchecksum = getchecksum(line)\t\t\n\tfile.write(':%s%s\\n' %(line,checksum))\n\nfile.write(':00000001FF\\n')\t\nfile.close()", "path": "Eco-build-Keilc\\eco-dev\\mac_test\\eeprep.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print '---------------------------'\n#print 'parse code memory'\n#print '---------------------------' \n#print self.lines\n\n", "func_signal": "def parse_code_memory(self):\n", "code": "code_memory_flag = False\ncode_memory_counter = 0\n\nfor map_line in self.lines:\n    #reg = re.search(self.PATTERN_CODE_MEMORY,map_line)\n    #if reg:\n    #    print 'reg.group(0) = ', reg.group(0) \n    if map_line.find('*   C O D E   M E M O R Y   *') != -1:\n        code_memory_flag = True\n        continue\n\n    if code_memory_counter >= 3:\n        #print 'code memory is over'\n        code_memory_flag = False \n        break\n\n    if code_memory_flag:\n        #reg_code = re.search(self.PATTERN_CODE,map_line)\n        reg_code = re.search(self.PATTERN_CODE,map_line)\n        if reg_code:\n            #print reg_code.group(0)\n            code_memory_counter = 0\n            self.code_memory_list.append(reg_code.group(0))\n            self.code_memory_start.append(reg_code.group(1))\n            self.code_memory_end.append(reg_code.group(2))\n            self.code_memory_length.append(reg_code.group(3))\n            self.code_memory_segment_name.append(reg_code.group(7))\n        elif map_line == '\\n':\n            code_memory_counter += 1                \n        #print map_line", "path": "Eco-build-Keilc\\eco-dev\\FFT_256_RR_OP\\tools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print '---------------------------'\n#print 'relocate code memory'\n#print '---------------------------' \n\n#start from reserved size \n", "func_signal": "def relocate_code_memory(self):\n", "code": "code_start_address = self.ECO_RESERVED_SIZE \n\n#print self.code_memory_start\n#print self.code_memory_end \n#print self.code_memory_length\n#print self.code_memory_segment_name\n\nfor i in range(len(self.code_memory_list)):\n    if self._check_segment(self.code_memory_segment_name[i]):\n        #print '----------------------------------------'\n        #print '%s can be relocated' %self.code_memory_segment_name[i]\n        if (code_start_address/self.ECO_PAGE_SIZE) != ((code_start_address + int(self.code_memory_length[i][0:-1],16))/self.ECO_PAGE_SIZE):\n            #print 'cross page line'\n            code_start_address = (((code_start_address + int(self.code_memory_length[i][0:-1],16))/self.ECO_PAGE_SIZE) * self.ECO_PAGE_SIZE)\n            \n            if (code_start_address >> self.ECO_PAGE_MASK) not in self.eco_page_vid:\n                self.eco_page_vid.append(code_start_address >> self.ECO_PAGE_MASK)\n            \n            #print 'SEGMENTS\\\\(' + self.code_memory_segment_name[i] + '\\\\(C:' + hex(code_start_address) + '\\\\)\\\\)'\n            self.SEG_DIRECTIVE += ' SEGMENTS\\\\(' + self.code_memory_segment_name[i] + '\\\\(C:' + hex(code_start_address) + '\\\\)\\\\)'\n\n            #print '%s is located at %X' %(self.code_memory_segment_name[i],code_start_address) \n              \n        else:\n            #print 'still in page size'\n            \n            if (code_start_address >> self.ECO_PAGE_MASK) not in self.eco_page_vid:\n                self.eco_page_vid.append(code_start_address >> self.ECO_PAGE_MASK)\n\n            #print 'SEGMENTS\\\\(' + self.code_memory_segment_name[i] + '\\\\(C:' + hex(code_start_address) + '\\\\)\\\\)'\n            self.SEG_DIRECTIVE += ' SEGMENTS\\\\(' + self.code_memory_segment_name[i] + '\\\\(C:' + hex(code_start_address) + '\\\\)\\\\)'\n            \n            #print '%s is located at %X' %(self.code_memory_segment_name[i],code_start_address) \n\n        code_start_address = code_start_address + int(self.code_memory_length[i][0:-1],16)                 \n         \n        #print '----------------------------------------'\n \n#print self.SEG_DIRECTIVE\n#print 'self.eco_page_vid len = %d' %(len(self.eco_page_vid))\n#print 'self.eco_page_vid = ', self.eco_page_vid", "path": "Eco-build-Keilc\\eco-dev\\FFT_256_RR_OP\\tools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print '---------------------------'\n#print 'relocate code memory'\n#print '---------------------------' \n\n#start from reserved size \n", "func_signal": "def relocate_code_memory(self):\n", "code": "code_start_address = self.ECO_RESERVED_SIZE \n\n#print self.code_memory_start\n#print self.code_memory_end \n#print self.code_memory_length\n#print self.code_memory_segment_name\n\nfor i in range(len(self.code_memory_list)):\n    if self._check_segment(self.code_memory_segment_name[i]):\n        #print '----------------------------------------'\n        #print '%s can be relocated' %self.code_memory_segment_name[i]\n        if (code_start_address/self.ECO_PAGE_SIZE) != ((code_start_address + int(self.code_memory_length[i][0:-1],16))/self.ECO_PAGE_SIZE):\n            #print 'cross page line'\n            code_start_address = (((code_start_address + int(self.code_memory_length[i][0:-1],16))/self.ECO_PAGE_SIZE) * self.ECO_PAGE_SIZE)\n            \n            if (code_start_address >> self.ECO_PAGE_MASK) not in self.eco_page_vid:\n                self.eco_page_vid.append(code_start_address >> self.ECO_PAGE_MASK)\n            \n            #print 'SEGMENTS\\\\(' + self.code_memory_segment_name[i] + '\\\\(C:' + hex(code_start_address) + '\\\\)\\\\)'\n            self.SEG_DIRECTIVE += ' SEGMENTS\\\\(' + self.code_memory_segment_name[i] + '\\\\(C:' + hex(code_start_address) + '\\\\)\\\\)'\n\n            #print '%s is located at %X' %(self.code_memory_segment_name[i],code_start_address) \n              \n        else:\n            #print 'still in page size'\n            \n            if (code_start_address >> self.ECO_PAGE_MASK) not in self.eco_page_vid:\n                self.eco_page_vid.append(code_start_address >> self.ECO_PAGE_MASK)\n\n            #print 'SEGMENTS\\\\(' + self.code_memory_segment_name[i] + '\\\\(C:' + hex(code_start_address) + '\\\\)\\\\)'\n            self.SEG_DIRECTIVE += ' SEGMENTS\\\\(' + self.code_memory_segment_name[i] + '\\\\(C:' + hex(code_start_address) + '\\\\)\\\\)'\n            \n            #print '%s is located at %X' %(self.code_memory_segment_name[i],code_start_address) \n\n        code_start_address = code_start_address + int(self.code_memory_length[i][0:-1],16)                 \n         \n        #print '----------------------------------------'\n \n#print self.SEG_DIRECTIVE\n#print 'self.eco_page_vid len = %d' %(len(self.eco_page_vid))\n#print 'self.eco_page_vid = ', self.eco_page_vid", "path": "Eco-build-Keilc\\eco-dev\\test_datagrabber_algorithm2\\tools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "'''write a nicely packed, ordered hex file'''\n", "func_signal": "def write_hex(datastr, outfile):\n", "code": "file = open(outfile, 'w')\n\neof = 0\naddress = 0\t\nwhile not eof:\n\taddr = '%.4X' %address\n\ttype = '00'\n\tif len(datastr) > DLEN*2:\n\t\tcount = '%.2X' %DLEN\n\t\tdata, datastr = datastr[0:32], datastr[32:]\n\t\taddress += DLEN\n\telse:\n\t\tcount = '%.2X' %(len(datastr)/2)\n\t\tdata = datastr\n\t\teof = 1\n\n\tline = '%s%s%s%s'%(count, addr, type, data)\n\tchecksum = getchecksum(line)\t\t\n\tfile.write(':%s%s\\n' %(line,checksum))\n\nfile.write(':00000001FF\\n')\t\nfile.close()", "path": "Eco-build-Keilc\\eco-dev\\test_eeprom\\eeprep.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "#print s_name \n", "func_signal": "def _check_segment(self,s_name):\n", "code": "if s_name.find('?C_') != -1 or s_name.find('?C?') != -1:\n    #print '\\t\\t%s is system c library' %s_name\n    return False\nelif s_name.find('RF_CH1_RECV') != -1:\n    return False\nelif s_name.find('?MAIN?') != -1:\n    return False\nelif s_name.find('?CO?') != -1:\n    #print '\\t\\t%s is constant data memory' %s_name\n    return False\nelif s_name.find('TIMER0') != -1:\n    return False\nelse:\n    reg_int = re.search('[\\?][$\\d]',s_name)\n    if reg_int:\n        return False\n    elif s_name.find('ECO_PAGE') != -1:\n        return False\n    return True", "path": "Eco-build-Keilc\\eco-dev\\test_serial_print_p128_op\\tools\\Funct_Relocation.py", "repo_name": "xwaynec/eplab", "stars": 3, "license": "None", "language": "python", "size": 4896}
{"docstring": "\"\"\" Creates internal structures for newly registered namespace.\n    You can register handlers for this namespace afterwards. By default one namespace\n    already registered (jabber:client or jabber:component:accept depending on context. \"\"\"\n", "func_signal": "def RegisterNamespace(self,xmlns,order='info'):\n", "code": "self.DEBUG('Registering namespace \"%s\"'%xmlns,order)\nself.handlers[xmlns]={}\nself.RegisterProtocol('unknown',Protocol,xmlns=xmlns)\nself.RegisterProtocol('default',Protocol,xmlns=xmlns)", "path": "robot\\xmpp\\dispatcher.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "# This has to be done before binding, because we can receive a route stanza before binding finishes\n", "func_signal": "def dobind(self, sasl):\n", "code": "self._route = self.route\nif self.bind:\n    for domain in self.domains:\n        auth.ComponentBind(sasl).PlugIn(self)\n        while self.ComponentBind.bound is None: self.Process(1)\n        if (not self.ComponentBind.Bind(domain)):\n            self.ComponentBind.PlugOut()\n            return\n        self.ComponentBind.PlugOut()", "path": "robot\\xmpp\\client.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" Unregister handler after first call (not implemented yet). \"\"\"\n", "func_signal": "def RegisterHandlerOnce(self,name,handler,typ='',ns='',xmlns=None,makefirst=0, system=0):\n", "code": "if not xmlns: xmlns=self._owner.defaultNamespace\nself.RegisterHandler(name, handler, typ, ns, xmlns, makefirst, system)", "path": "robot\\xmpp\\dispatcher.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" Called on disconnection. Calls disconnect handlers and cleans things up. \"\"\"\n", "func_signal": "def disconnected(self):\n", "code": "self.connected=''\nself.DEBUG(self.DBG,'Disconnect detected','stop')\nself.disconnect_handlers.reverse()\nfor i in self.disconnect_handlers: i()\nself.disconnect_handlers.reverse()\nif self.__dict__.has_key('TLS'): self.TLS.PlugOut()", "path": "robot\\xmpp\\client.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" Return stanza back to the sender with <feature-not-implemennted/> error set. \"\"\"\n", "func_signal": "def returnStanzaHandler(self,conn,stanza):\n", "code": "if stanza.getType() in ['get','set']:\n    conn.send(Error(stanza,ERR_FEATURE_NOT_IMPLEMENTED))", "path": "robot\\xmpp\\dispatcher.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" This will connect to the server, and if the features tag is found then set\n    the namespace to be jabber:client as that is required for jabberd2.\n    'server' and 'proxy' arguments have the same meaning as in xmpp.Client.connect() \"\"\"\n", "func_signal": "def connect(self,server=None,proxy=None):\n", "code": "if self.sasl:\n    self.Namespace=auth.NS_COMPONENT_1\n    self.Server=server[0]\nCommonClient.connect(self,server=server,proxy=proxy)\nif self.connected and (self.typ=='jabberd2' or not self.typ and self.Dispatcher.Stream.features != None) and (not self.xcp):\n    self.defaultNamespace=auth.NS_CLIENT\n    self.Dispatcher.RegisterNamespace(self.defaultNamespace)\n    self.Dispatcher.RegisterProtocol('iq',dispatcher.Iq)\n    self.Dispatcher.RegisterProtocol('message',dispatcher.Message)\n    self.Dispatcher.RegisterProtocol('presence',dispatcher.Presence)\nreturn self.connected", "path": "robot\\xmpp\\client.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" Prepares instance to be destructed. \"\"\"\n", "func_signal": "def plugout(self):\n", "code": "self.Stream.dispatch=None\nself.Stream.DEBUG=None\nself.Stream.features=None\nself.Stream.destroy()", "path": "robot\\xmpp\\dispatcher.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" Authenticate connnection and bind resource. If resource is not provided\n    random one or library name used. \"\"\"\n", "func_signal": "def auth(self,user,password,resource='',sasl=1):\n", "code": "self._User,self._Password,self._Resource=user,password,resource\nwhile not self.Dispatcher.Stream._document_attrs and self.Process(1): pass\nif self.Dispatcher.Stream._document_attrs.has_key('version') and self.Dispatcher.Stream._document_attrs['version']=='1.0':\n    while not self.Dispatcher.Stream.features and self.Process(1): pass      # If we get version 1.0 stream the features tag MUST BE presented\nif sasl: auth.SASL(user,password).PlugIn(self)\nif not sasl or self.SASL.startsasl=='not-supported':\n    if not resource: resource='xmpppy'\n    if auth.NonSASL(user,password,resource).PlugIn(self):\n        self.connected+='+old_auth'\n        return 'old_auth'\n    return\nself.SASL.auth()\nwhile self.SASL.startsasl=='in-process' and self.Process(1): pass\nif self.SASL.startsasl=='success':\n    auth.Bind().PlugIn(self)\n    while self.Bind.bound is None and self.Process(1): pass\n    if self.Bind.Bind(resource):\n        self.connected+='+sasl'\n        return 'sasl'\nelse:\n    if self.__dict__.has_key('SASL'): self.SASL.PlugOut()", "path": "robot\\xmpp\\client.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" Make a tcp/ip connection, protect it with tls/ssl if possible and start XMPP stream.\n    Returns None or 'tcp' or 'tls', depending on the result.\"\"\"\n", "func_signal": "def connect(self,server=None,proxy=None,ssl=None,use_srv=None):\n", "code": "if not server: server=(self.Server,self.Port)\nif proxy: sock=transports.HTTPPROXYsocket(proxy,server,use_srv)\nelse: sock=transports.TCPsocket(server,use_srv)\nconnected=sock.PlugIn(self)\nif not connected: \n    sock.PlugOut()\n    return\nself._Server,self._Proxy=server,proxy\nself.connected='tcp'\nif (ssl is None and self.Connection.getPort() in (5223, 443)) or ssl:\n    try:               # FIXME. This should be done in transports.py\n        transports.TLS().PlugIn(self,now=1)\n        self.connected='ssl'\n    except socket.sslerror:\n        return\ndispatcher.Dispatcher().PlugIn(self)\nwhile self.Dispatcher.Stream._document_attrs is None:\n    if not self.Process(1): return\nif self.Dispatcher.Stream._document_attrs.has_key('version') and self.Dispatcher.Stream._document_attrs['version']=='1.0':\n    while not self.Dispatcher.Stream.features and self.Process(1): pass      # If we get version 1.0 stream the features tag MUST BE presented\nreturn self.connected", "path": "robot\\xmpp\\client.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" Plug the Dispatcher instance into Client class instance and send initial stream header. Used internally.\"\"\"\n", "func_signal": "def plugin(self, owner):\n", "code": "self._init()\nfor method in self._old_owners_methods:\n    if method.__name__=='send': self._owner_send=method; break\nself._owner.lastErrNode=None\nself._owner.lastErr=None\nself._owner.lastErrCode=None\nself.StreamInit()", "path": "robot\\xmpp\\dispatcher.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" Send an initial stream header. \"\"\"\n", "func_signal": "def StreamInit(self):\n", "code": "self.Stream=simplexml.NodeBuilder()\nself.Stream._dispatch_depth=2\nself.Stream.dispatch=self.dispatch\nself.Stream.stream_header_received=self._check_stream_start\nself._owner.debug_flags.append(simplexml.DBG_NODEBUILDER)\nself.Stream.DEBUG=self._owner.DEBUG\nself.Stream.features=None\nself._metastream=Node('stream:stream')\nself._metastream.setNamespace(self._owner.Namespace)\nself._metastream.setAttr('version','1.0')\nself._metastream.setAttr('xmlns:stream',NS_STREAMS)\nself._metastream.setAttr('to',self._owner.Server)\nself._owner.send(\"<?xml version='1.0'?>%s>\"%str(self._metastream)[:-2])", "path": "robot\\xmpp\\dispatcher.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" Used to declare some top-level stanza name to dispatcher.\n   Needed to start registering handlers for such stanzas.\n   Iq, message and presence protocols are registered by default. \"\"\"\n", "func_signal": "def RegisterProtocol(self,tag_name,Proto,xmlns=None,order='info'):\n", "code": "if not xmlns: xmlns=self._owner.defaultNamespace\nself.DEBUG('Registering protocol \"%s\" as %s(%s)'%(tag_name,Proto,xmlns), order)\nself.handlers[xmlns][tag_name]={type:Proto, 'default':[]}", "path": "robot\\xmpp\\dispatcher.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" Init function for Components.\n    As components use a different auth mechanism which includes the namespace of the component.\n    Jabberd1.4 and Ejabberd use the default namespace then for all client messages.\n    Jabberd2 uses jabber:client.\n    'server' argument is a server name that you are connecting to (f.e. \"localhost\").\n    'port' can be specified if 'server' resolves to correct IP. If it is not then you'll need to specify IP \n    and port while calling \"connect()\".\"\"\"\n", "func_signal": "def __init__(self,server,port=5347,typ=None,debug=['always', 'nodebuilder'],domains=None,sasl=0,bind=0,route=0,xcp=0):\n", "code": "CommonClient.__init__(self,server,port=port,debug=debug)\nself.typ=typ\nself.sasl=sasl\nself.bind=bind\nself.route=route\nself.xcp=xcp\nif domains:\n    self.domains=domains\nelse:\n    self.domains=[server]", "path": "robot\\xmpp\\client.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\"\nif multiple instances of Debug is used in same app, \nsome flags might be created multiple time, filter out dupes\n\"\"\"\n", "func_signal": "def _remove_dupe_flags( self ):\n", "code": "unique_flags = []\nfor f in self.debug_flags:\n    if f not in unique_flags:\n        unique_flags.append(f)\nself.debug_flags = unique_flags", "path": "robot\\xmpp\\debug.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" Unregister all our staff from main instance and detach from it. \"\"\"\n", "func_signal": "def PlugOut(self):\n", "code": "self.DEBUG('Plugging %s out of %s.'%(self,self._owner),'stop')\nret = None\nif self.__class__.__dict__.has_key('plugout'): ret = self.plugout()\nself._owner.debug_flags.remove(self.DBG_LINE)\nfor method in self._exported_methods: del self._owner.__dict__[method.__name__]\nfor method in self._old_owners_methods: self._owner.__dict__[method.__name__]=method\ndel self._owner.__dict__[self.__class__.__name__]\nreturn ret", "path": "robot\\xmpp\\client.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" Attach to main instance and register ourself and all our staff in it. \"\"\"\n", "func_signal": "def PlugIn(self,owner):\n", "code": "self._owner=owner\nif self.DBG_LINE not in owner.debug_flags:\n    owner.debug_flags.append(self.DBG_LINE)\nself.DEBUG('Plugging %s into %s'%(self,self._owner),'start')\nif owner.__dict__.has_key(self.__class__.__name__):\n    return self.DEBUG('Plugging ignored: another instance already plugged.','error')\nself._old_owners_methods=[]\nfor method in self._exported_methods:\n    if owner.__dict__.has_key(method.__name__):\n        self._old_owners_methods.append(owner.__dict__[method.__name__])\n    owner.__dict__[method.__name__]=method\nowner.__dict__[self.__class__.__name__]=self\nif self.__class__.__dict__.has_key('plugin'): return self.plugin(owner)", "path": "robot\\xmpp\\client.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" Block and wait until stanza with specific \"id\" attribute will come.\n    If no such stanza is arrived within timeout, return None.\n    If operation failed for some reason then owner's attributes\n    lastErrNode, lastErr and lastErrCode are set accordingly. \"\"\"\n", "func_signal": "def WaitForResponse(self, ID, timeout=DefaultTimeout):\n", "code": "self._expected[ID]=None\nhas_timed_out=0\nabort_time=time.time() + timeout\nself.DEBUG(\"Waiting for ID:%s with timeout %s...\" % (ID,timeout),'wait')\nwhile not self._expected[ID]:\n    if not self.Process(0.04):\n        self._owner.lastErr=\"Disconnect\"\n        return None\n    if time.time() > abort_time:\n        self._owner.lastErr=\"Timeout\"\n        return None\nresponse=self._expected[ID]\ndel self._expected[ID]\nif response.getErrorCode():\n    self._owner.lastErrNode=response\n    self._owner.lastErr=response.getError()\n    self._owner.lastErrCode=response.getErrorCode()\nreturn response", "path": "robot\\xmpp\\dispatcher.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" Registers default namespaces/protocols/handlers. Used internally.  \"\"\"\n", "func_signal": "def _init(self):\n", "code": "self.RegisterNamespace('unknown')\nself.RegisterNamespace(NS_STREAMS)\nself.RegisterNamespace(self._owner.defaultNamespace)\nself.RegisterProtocol('iq',Iq)\nself.RegisterProtocol('presence',Presence)\nself.RegisterProtocol('message',Message)\nself.RegisterDefaultHandler(self.returnStanzaHandler)\nself.RegisterHandler('error',self.streamErrorHandler,xmlns=NS_STREAMS)", "path": "robot\\xmpp\\dispatcher.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\"Register user callback as stanzas handler of declared type. Callback must take\n   (if chained, see later) arguments: dispatcher instance (for replying), incomed\n   return of previous handlers.\n   The callback must raise xmpp.NodeProcessed just before return if it want preven\n   callbacks to be called with the same stanza as argument _and_, more importantly\n   library from returning stanza to sender with error set (to be enabled in 0.2 ve\n    Arguments:\n      \"name\" - name of stanza. F.e. \"iq\".\n      \"handler\" - user callback.\n      \"typ\" - value of stanza's \"type\" attribute. If not specified any value match\n      \"ns\" - namespace of child that stanza must contain.\n      \"chained\" - chain together output of several handlers.\n      \"makefirst\" - insert handler in the beginning of handlers list instead of\n        adding it to the end. Note that more common handlers (i.e. w/o \"typ\" and \"\n        will be called first nevertheless.\n      \"system\" - call handler even if NodeProcessed Exception were raised already.\n    \"\"\"\n", "func_signal": "def RegisterHandler(self,name,handler,typ='',ns='',xmlns=None, makefirst=0, system=0):\n", "code": "if not xmlns: xmlns=self._owner.defaultNamespace\nself.DEBUG('Registering handler %s for \"%s\" type->%s ns->%s(%s)'%(handler,name,typ,ns,xmlns), 'info')\nif not typ and not ns: typ='default'\nif not self.handlers.has_key(xmlns): self.RegisterNamespace(xmlns,'warn')\nif not self.handlers[xmlns].has_key(name): self.RegisterProtocol(name,Protocol,xmlns,'warn')\nif not self.handlers[xmlns][name].has_key(typ+ns): self.handlers[xmlns][name][typ+ns]=[]\nif makefirst: self.handlers[xmlns][name][typ+ns].insert(0,{'func':handler,'system':system})\nelse: self.handlers[xmlns][name][typ+ns].append({'func':handler,'system':system})", "path": "robot\\xmpp\\dispatcher.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\" Example of reconnection method. In fact, it can be used to batch connection and auth as well. \"\"\"\n", "func_signal": "def reconnectAndReauth(self):\n", "code": "handlerssave=self.Dispatcher.dumpHandlers()\nif self.__dict__.has_key('ComponentBind'): self.ComponentBind.PlugOut()\nif self.__dict__.has_key('Bind'): self.Bind.PlugOut()\nself._route=0\nif self.__dict__.has_key('NonSASL'): self.NonSASL.PlugOut()\nif self.__dict__.has_key('SASL'): self.SASL.PlugOut()\nif self.__dict__.has_key('TLS'): self.TLS.PlugOut()\nself.Dispatcher.PlugOut()\nif self.__dict__.has_key('HTTPPROXYsocket'): self.HTTPPROXYsocket.PlugOut()\nif self.__dict__.has_key('TCPsocket'): self.TCPsocket.PlugOut()\nif not self.connect(server=self._Server,proxy=self._Proxy): return\nif not self.auth(self._User,self._Password,self._Resource): return\nself.Dispatcher.restoreHandlers(handlerssave)\nreturn self.connected", "path": "robot\\xmpp\\client.py", "repo_name": "gnuget/mbot", "stars": 3, "license": "None", "language": "python", "size": 248}
{"docstring": "\"\"\"\n\"\"\"\n", "func_signal": "def get_by_mac_address(self, token, args):\n", "code": "required = ('mac_address',)\nFieldValidator(args).verify_required(required)\nsession = db.open_session()\ntry:\n    result = []\n    # creation gives uppercase MAC addresses, so be sure\n    # we search on the same criteria until the DB search\n    # can be made case insensitive.  (FIXME)\n    mac_address = args['mac_address'].replace(\"_\",\":\").upper()\n    offset, limit = self.offset_and_limit(args)\n    query = session.query(db.Deployment).limit(limit).offset(offset)\n    for machine in query.select_by(mac_address = mac_address):\n        result.append(self.expand(machine))\n    return success(result)\nfinally:\n    session.close()", "path": "service\\modules\\deployment.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "#TODO: Do better implicit typing\n", "func_signal": "def __init__(self,key):\n", "code": "try:\n   key = int(key)\nexcept: pass\nself.key = key", "path": "service\\server\\yaml\\ypath.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "\"\"\"\nGet a deployment by id.\n@param token: A security token.\n@type token: string\n@param args: A dictionary of query attributes.\n    - id\n@type args: dict\n@return: A deployment.\n@rtype: dict\n@raise SQLException: On database error\n@raise NoSuchObjectException: On object not found.\n\"\"\"\n\n\n", "func_signal": "def get(self, token, args):\n", "code": "required = ('id',)\nFieldValidator(args).verify_required(required)\nsession = db.open_session()\ntry:\n    deployment = db.Deployment.get(session, args['id'])\n    results = self.expand(deployment)\n\n    self.logger.info(\"your deployment is: %s\" % results)\n \n    # we want the state \"now\" so we must contact the node\n    # to update it!\n    self.refresh(token, results)\n\n    # now re-get the updated record which will have an\n    # accurate state.\n    deployment = db.Deployment.get(session, args['id'])\n    return success(self.expand(deployment))\n\nfinally:\n    session.close()", "path": "service\\modules\\deployment.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "# delete queues\n# delete exchanges\n", "func_signal": "def shutdown_if_done(self):\n", "code": "if (self.poll_done and self.write_done):\n    qpid_util.delete_queue(self, queue_name=self.queue_name)\n    #qpid_util.delete_exchange(self, exchange_name=self.exchange_name)", "path": "common\\busrpc\\busrpc\\qpid_transport.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "# should return a machine_id, maybe more\n", "func_signal": "def register(self, hostname, ip, mac, profile_name, virtual):\n", "code": "self.logger.info(\"--------------------\")\nself.logger.info(\"Registering...\")\nself.logger.info(\"  token=%s\" % self.token)\nself.logger.info(\"  hostname=%s\" % hostname)\nself.logger.info(\"  ip=%s\" % ip)\nself.logger.info(\"  mac=%s\" % mac)\nself.logger.info(\"  profile_name=%s\" % profile_name)\nself.logger.info(\"  virtual=%s\" % virtual)\nself.logger.info(\"---------------------\")\nif profile_name is None:\n    profile_name = \"\"\nif mac is None:\n    mac = \"00:00:00:00:00:00\"\n\ntry:\n    rc = self.server.register_system(self.token, hostname, ip, mac, profile_name, virtual)\nexcept TypeError:\n    (t, v, tb) = sys.exc_info()\n    self.logger.error(\"error running registration.\")\n    self.logger.debug(\"Exception occured: %s\" % t )\n    self.logger.debug(\"Exception value: %s\" % v)\n    self.logger.error(\"Exception Info:\\n%s\" % string.join(traceback.format_list(traceback.extract_tb(tb))))\n    sys.exit(1)\nif rc[0] == 0:\n    self.logger.info(\"Registration succeeded.\")\n    fd1 = open(\"/etc/sysconfig/virt-factory/token\",\"w+\")\n    fd1.write(self.token)\n    fd1.close()\n    fd2 = open(\"/etc/sysconfig/virt-factory/server\",\"w+\")\n    fd2.write(self.server_host)\n    fd2.close()\n    fd3 = open(\"/etc/sysconfig/virt-factory/mac\", \"w+\")\n    fd3.write(mac)\n    fd3.close()\n    fd4 = open(\"/etc/sysconfig/virt-factory/profile\", \"w+\")\n    fd4.write(profile_name)\n    fd4.close()\n    self.update_puppet_sysconfig(self.server_host)\n    puppetcmd = \"/usr/sbin/puppetd --waitforcert 0 --server \" + self.server_host + \" --certname \" + hostname + \" --test\"\n    self.logger.info(\"puppet cmd: %s\" % puppetcmd)\n    puppet_in, puppet_out = os.popen4(puppetcmd)\n    for line in puppet_out.readlines():\n        self.logger.info(\"puppet: %s\" % line.strip())\n    puppet_in.close()\n    puppet_out.close()\n\n    rc2 = self.server.sign_node_cert(self.token, hostname)\n    if rc2[0] != 0:\n        self.logger.error(\"Failed: %s\" % rc2)\n        rc = rc2\n    \nelse:\n    self.logger.info(\"Failed: %s\" % rc)\nreturn rc", "path": "register\\register\\register.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "\"\"\"\nIf any entries are None in the datastructure, prune them.\nXMLRPC can't marshall None and this is our workaround.  Objects\nthat are None are removed from the hash -- including hash keys that\nare not None and have None for the value.  The WUI or other SW\nshould know how to deal with these returns.\n\"\"\"\n", "func_signal": "def remove_nulls(self, x):\n", "code": "assert x is not None, \"datastructure is None\"\nif type(x) == list:\n    newx = []\n    for i in x:\n        if type(i) == list or type(i) == dict:\n            newx.append(self.remove_nulls(i))\n        elif i is not None:\n            newx.append(i)\n    x = newx\nelif type(x) == dict:\n    newx = {}\n    for i,j in x.iteritems():\n        if type(j) == list or type(j) == dict:\n            newx[i] = self.remove_nulls(x)\n        elif j is not None:\n            newx[i] = j\n    x = newx\nreturn x", "path": "service\\modules\\baseobj.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "\"\"\"\nReturn a list of all deployments tagged with the given tag\n\"\"\"\n", "func_signal": "def get_by_tag(self, token, args):\n", "code": "required = ('tag_id',)\nFieldValidator(args).verify_required(required)\ntag_id = args['tag_id']\nsession = db.open_session()\ntry:\n    name = args['name']\n    deployment_tags = db.Database.table['deployment_tags']\n    deployments = session.query(db.Deployment).select((deployment_tags.c.tag_id==tag_id &\n                                                 deployment_tags.c.deployment_id==db.Deployment.c.id))\n    if deployments:\n        deployments = self.expand(deployments)\n    return codes.success(deployments)\nfinally:\n    session.close()", "path": "service\\modules\\deployment.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "\"\"\"\n    args:\n        parent: parent context (or None if this is the root)\n        key:    mapping key or index for this context\n        value:  value of current location...\n\"\"\"\n", "func_signal": "def __init__(self,parent,key,value):\n", "code": "self.parent = parent\nself.key    = key\nself.value  = value\nif parent: \n    assert parent.__class__ is self.__class__\n    self.path = parent.path + (escape(key),)\n    self.root = parent.root\nelse:      \n    assert not key\n    self.path = tuple()\n    self.root = self", "path": "service\\server\\yaml\\ypath.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "\"\"\"\nFIXME: authentication details TBA.\nrequires: mac_address, state\n\"\"\"\n\n", "func_signal": "def set_state(self, token, args):\n", "code": "required = ('mac_address','state')\nFieldValidator(args).verify_required(required)\n\nwhich = self.get_by_mac_address(token,args)\nself.logger.debug(\"set_state on %s to %s\" % (args[\"mac_address\"],args[\"state\"]))\nif which.error_code != 0:\n   raise InvalidArgumentsException(comment=\"missing item\")\nif len(which.data) == 0:\n   raise InvalidArgumentsException(comment=\"missing item (no %s)\" % args[\"mac_address\"]) \nid = which.data[0][\"id\"] \n\nsession = db.open_session()\n# BOOKMARK \ndeployment = db.Deployment.get(session, id)\nresults = self.expand(deployment)\n\nresults[\"state\"] = args[\"state\"]\n\n# misnomer: this is the time of the last status update\nresults[\"last_heartbeat\"] = int(time.time())\n  \nself.logger.debug(\"setting deployment status: %s\" % results)\nself.edit(token, results)\n\nreturn success(results)", "path": "service\\modules\\deployment.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "\"\"\"\nReturn a hash representation of this object.\nDefers to self.to_datastruct_internal which subclasses must implement.\n\"\"\"\n", "func_signal": "def to_datastruct(self,to_caller=False):\n", "code": "ds = self.to_datastruct_internal()\nif to_caller:\n    # don't send NULLs\n    ds = self.remove_nulls(ds)\nreturn ds", "path": "service\\modules\\baseobj.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "# pick an offset into the XenSource range as given by the highest used object id\n# FIXME: verify that sqlite id fields work as counters and don't fill in on deletes\n# FIXME: verify math below\n", "func_signal": "def generate_mac_address(self, id):\n", "code": "x = id + 1\nhigh = x / (127*256)\nmid  = (x % (127*256)) / 256\nlow  = x % 256 \nreturn \":\".join([ \"00\", \"16\", \"3E\", \"%02x\" % high, \"%02x\" % mid, \"%02x\" % low ])", "path": "service\\modules\\deployment.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "\"\"\"\nGiven  deployment id and tag string, remove the tag from the deployment\n@param token: A security token.\n@type token: string\n@param args: A dictionary of deployment attributes.\n    - id\n    - tag_id\n@type args: dict\n@raise SQLException: On database error\n@raise NoSuchObjectException: On object not found.\n\"\"\"\n", "func_signal": "def remove_tag(self, token, args):\n", "code": "required = ('id', 'tag_id',)\nFieldValidator(args).verify_required(required)\ndeployment = self.get(token, {\"id\": args[\"id\"]}).data\ntag_id = args[\"tag_id\"]\ntag_ids = deployment[\"tag_ids\"]\nif int(tag_id) in tag_ids:\n    tag_ids.remove(int(tag_id))\n    self.edit(token, {\"id\": args[\"id\"], \"tag_ids\": tag_ids})\nreturn success()", "path": "service\\modules\\deployment.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "\"\"\"\n    This the parser entry point, the top level node\n    is always a root or self segment.  The self isn't\n    strictly necessary, but it keeps things simple.\n\"\"\"\n", "func_signal": "def parse(expr):\n", "code": "(ypth,expr) = parse_start(expr)\nwhile expr:\n    tok = expr[0]\n    if '/' == tok:\n        (child, expr) = parse_segment(expr[1:])    \n        if child: ypth = conn_seg(ypth,child)\n        continue\n    if '[' == tok:\n        (filter, expr) = parse_predicate(expr[1:])\n        assert ']' == expr[0]\n        expr = expr[1:]\n        ypth = pred_seg(ypth,filter)\n        continue\n    if '|' == tok:\n        (rhs, expr) = parse(expr[1:])\n        ypth = or_seg(ypth,rhs)\n        continue\n    if '(' == tok:\n        (child,expr) = parse(expr[1:])\n        assert ')' == expr[0]\n        expr = expr[1:]\n        ypth = conn_seg(ypth,child)\n        continue\n    break\nreturn (ypth,expr)", "path": "service\\server\\yaml\\ypath.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "# FIXME: use regex package\n\n", "func_signal": "def is_printable(self, stringy):\n", "code": "if stringy == None:\n   return False\nif type(stringy) != str:\n   stringy = \"%s\" % stringy\ntry:\n    for letter in stringy:\n        if letter not in string.printable:\n            return False\n    return True\nexcept:\n    return False", "path": "service\\modules\\baseobj.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "\"\"\"\nGet a list of all deployments.\n@param token: A security token.\n@type token: string\n@param args: A dictionary of query arguments.\n@type args: dict\n    - offset (optional)\n    - limit (optional)\n@return: A list of deployments.\n@rtype: [dict,]\n@raise SQLException: On database error\n\"\"\"\n\n# it is going to be expensive to query all of the list results\n# for an update.  so right now, we're doing it only for 1-item\n# gets, with the thought that nodes should be sending async\n# updates, or that we are periodically polling them for status\n\n", "func_signal": "def list(self, token, args):\n", "code": "session = db.open_session()\ntry:\n    result = []\n    offset, limit = self.offset_and_limit(args)\n    for deployment in db.Deployment.list(session, offset, limit):\n        result.append(self.expand(deployment))\n    return success(result)\nfinally:\n    session.close()", "path": "service\\modules\\deployment.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "\"\"\"\nCreate all tables, indexes and constraints that have not\nyet been created.\n\"\"\"\n", "func_signal": "def create(self):\n", "code": "for t in Database.tables:\n    t.create(checkfirst=True)", "path": "service\\server\\db.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "\"\"\"\n    summary: >\n        This function escapes a given key so that it\n        may appear within a ypath.  URI style escaping\n        is used so that ypath expressions can be a \n        valid URI expression.\n\"\"\"\n", "func_signal": "def escape(node):\n", "code": "typ = type(node)\nif typ is IntType: return str(node)\nif typ is StringType: \n    return quote(node,'')\nraise ValueError(\"TODO: Support more than just string and integer keys.\")", "path": "service\\server\\yaml\\ypath.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "\"\"\"\nDrop all tables, indexes and constraints.\n\"\"\"\n", "func_signal": "def drop(self):\n", "code": "mylist = list(Database.tables)\nmylist.reverse()\nfor t in mylist:\n    t.drop(checkfirst=True)", "path": "service\\server\\db.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "\"\"\"\n    Initial checking on the expression, and \n    determine if it is relative or absolute.\n\"\"\"\n", "func_signal": "def parse_start(expr):\n", "code": "if type(expr) != StringType or len(expr) < 1: \n    raise TypeError(\"string required: \" + repr(expr))\nif '/' == expr[0]:\n    ypth = root_seg()\nelse:\n    ypth = self_seg()\n    expr = '/' + expr\nreturn (ypth,expr)", "path": "service\\server\\yaml\\ypath.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "\"\"\"\nReturns parent node and class list for a given puppet node.\n\"\"\"\n", "func_signal": "def node_info(self, token, nodename):\n", "code": "found_node = None\ndeployment_obj = deployment.Deployment()\ndeployment_list_return = deployment_obj.get_by_hostname(None, {\"hostname\": nodename})\nif (deployment_list_return.error_code != ERR_SUCCESS):\n    return deployment_list_return\n\n# TODO: should we complain if more than 1 deployments are returned?\nif (len(deployment_list_return.data) > 0):\n    found_node = deployment_list_return.data[0]\n\n# if no deployment found, search for machine\nif (found_node is None):\n    machine_obj = machine.Machine()\n    machine_list_return = machine_obj.get_by_hostname(None, {\"hostname\": nodename})\n    if (machine_list_return.error_code != ERR_SUCCESS):\n        return machine_list_return\n\n    # TODO: should we complain if more than 1 machines are returned?\n    if (len(machine_list_return.data) > 0):\n        found_node = machine_list_return.data[0]\n\n\ndata = {}\nif found_node is not None:\n    profile = found_node[\"profile\"]\n    if profile is not None:\n        puppet_str = profile[\"puppet_classes\"]\n        if puppet_str is not None:\n            puppet_classes = puppet_str.split()\n        else:\n            puppet_classes = []\n    else:\n        puppet_classes = []\n    if \"puppet_node_diff\" in found_node:\n        override_str = found_node[\"puppet_node_diff\"]\n        if (override_str is not None):\n            for override in override_str.split():\n                if (override[0] == '-'):\n                    override = override[1:]\n                    if override in puppet_classes:\n                        puppet_classes.remove(override)\n                else:\n                    if override not in puppet_classes:\n                        puppet_classes.append(override)\n\nelse:\n    #FIXME: check deployments here\n    return NoSuchObjectException()\ndata[\"puppet_classes\"] = puppet_classes\n#data[\"parent\"] = foo\nreturn success(data)", "path": "service\\modules\\puppet.py", "repo_name": "mpdehaan/virt-factory", "stars": 2, "license": "None", "language": "python", "size": 5696}
{"docstring": "\"\"\"Test a regular duplicate synonym\"\"\"\n", "func_signal": "def testSynonymDuplicate(self):\n", "code": "one = spinner.Word.objects.get_single('mac', True)\ntwo = spinner.Word.objects.get_single('macintosh', True)\n\t\nsyn = spinner.Synonym.objects.get_single(one, two, True)\n\nsyn2 = spinner.Synonym.objects.get_single(two, one, True)\n\nassert syn == syn2\n\nsyn.delete()\none.delete()\ntwo.delete()", "path": "spinner\\tests\\basic_test.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Return a single word. If create is True, one will be created if it\ndoesn't exist\"\"\"\n\n", "func_signal": "def get_single(self, name, create = None):\n", "code": "if create is None:\n\t\tcreate = False\n\ntry:\n\t\treturn self.get(name=name)\n\nexcept Word.DoesNotExist:\n\t\tif create:\n\t\t\t\tword = Word(name=name)\n\t\t\t\tword.save()\n\t\t\t\treturn word\nreturn None", "path": "spinner\\models.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Test WordNet synonyms\"\"\"\n", "func_signal": "def testWordnetSynonyms(self):\n", "code": "wordnet = proxy.WordNet()\nresults = wordnet.synonym('business directory')", "path": "spyder\\tests\\basic_test.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Clean a string by removing all non-alpha or space characters\"\"\"\n", "func_signal": "def clean(phrase):\n", "code": "phrase = strip_tags(phrase)\nreturn re.sub('[^a-zA-Z ,&\\-]', '', phrase).strip()", "path": "wordle\\__init__.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Remove HTML tags\"\"\"\n", "func_signal": "def strip_tags(data):\n", "code": "p = re.compile(r'<.*?>')\nreturn p.sub('', data)", "path": "wordle\\__init__.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Test if we can add words in bulk\"\"\"\n\n", "func_signal": "def testAddWords(self):\n", "code": "words = ['mac', 'tips', 'tricks', 'macintosh', 'help', 'hack']\nspinner.Word.objects.add(words)\nfor word in words:\n\t\tword = spinner.Word.objects.get(name=word)\n\t\tword.delete()", "path": "spinner\\tests\\basic_test.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"This algorithm queries BOSS, gathers each result's title and folds\nthe title into synonyms.\"\"\"\n\n", "func_signal": "def testBOSSFoldTitles(self):\n", "code": "boss = proxy.BOSS()\nresults = boss.get_results(self.query)\ntitles = [wordle.clean(result['title']) for result in results]\n\nfolder = wordle.TitleFolder()\nsynonyms = folder.get_synonyms(titles, self.query)\n\npprint.pprint(synonyms)", "path": "spinner\\tests\\algorithms.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Convert everything to lowercase and normalize commas. Also split on\ndashes and | signs\"\"\"\n\n", "func_signal": "def fix_data(self, data):\n", "code": "data = data.lower()\ndata = re.sub('(and|\\&amp\\;|\\/)', ',', data)\nparts = re.split('\\s(\\-|\\|)\\s', data)\nparts = [clean(part) for part in parts]\ndata = filter(self.check_data, parts)\nreturn data", "path": "wordle\\__init__.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Test if karma is approrpriately working\"\"\"\n\n", "func_signal": "def testKarma(self):\n", "code": "spinner.Synonym.objects.add('directory', 'catalog', 10, True)\nspinner.Synonym.objects.add('list', 'directory', 20, True)\nspinner.Synonym.objects.add('directory', 'guide', 10, True)\n\nsynonyms = spinner.Synonym.objects.get_synonyms(['directory'])[0]\n\nfor word in synonyms:\n\t\tif word.total_karma < 10:\n\t\t\t\tassert False, 'Karma was not recorded correctly'", "path": "spinner\\tests\\basic_test.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Check our get_single() for Word object\"\"\"\n\n", "func_signal": "def testGetSingleWordCreate(self):\n", "code": "word = spinner.Word.objects.get_single('mac', True)\nassert isinstance(word, spinner.Word), word\nword.delete()\n\nword = spinner.Word.objects.get_single('mac', True)\nassert isinstance(word, spinner.Word), word\nword.delete()", "path": "spinner\\tests\\basic_test.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Helper function for adding synonyms\"\"\"\n\n", "func_signal": "def testAddSyn(self):\n", "code": "syn = spinner.Synonym.objects.get_single('mac', 'macintosh')\nassert syn is None, syn\n\nsyn = spinner.Synonym.objects.add('mac', 'macintosh', 5)\nassert isinstance(syn, spinner.Synonym), syn\nsyn.delete()", "path": "spinner\\tests\\basic_test.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Add a set of words into the list database and return a reference to\neach\"\"\"\n\n", "func_signal": "def add(self, words):\n", "code": "for name in words:\n\t\ttry:\n\t\t\t\tword = self.get(name=name)\n\t\texcept Word.DoesNotExist:\n\t\t\t\tword = Word(name=name)\n\t\t\t\tword.save()", "path": "spinner\\models.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Get the BOSS keyterms back\"\"\"\n", "func_signal": "def testGetKeyterms(self):\n", "code": "boss = proxy.BOSS()\nkeyterms = boss.get_keyterms('mac tips')\nassert len(keyterms)", "path": "spyder\\tests\\basic_test.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Match all of a query's synonyms in a phrase.\n\nTHIS ISN\"T WORKING\"\"\"\n\n", "func_signal": "def match_synonyms(self, data, query):\n", "code": "query_parts = query.split()\nmax = len(query_parts)\n\nfor i in xrange(max):\n    for part in data:\n\n        if i == 0:\n            regex = '%s (\\w+)'\n        elif i == max:\n            regex = '(\\w+) %s'\n        else:\n            regex = '(\\w+) %s (\\w+)'\n\n        regex = regex % query_parts[i]\n\n        matches = re.findall(regex, part)\n\n        print (query_parts[i], matches)", "path": "wordle\\__init__.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Test for one word. If you pass in 1 word you should get an array of\nwords back that are synonymous\"\"\"\n\n", "func_signal": "def testOneWord(self):\n", "code": "spinner.Synonym.objects.add('directory', 'catalog', 10)\nspinner.Synonym.objects.add('list', 'directory', 20)\nspinner.Synonym.objects.add('directory', 'guide', 10)\n\nsynonyms = spinner.Synonym.objects.get_synonyms(['directory'])\nassert len(synonyms) < 3, synonyms", "path": "spinner\\tests\\basic_test.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Test if we can add words individually\"\"\"\n\n", "func_signal": "def testWords(self):\n", "code": "words = ['mac', 'tips', 'tricks', 'macintosh', 'help', 'hack']\n\nfor word in words:\n\t\tref = spinner.Word.objects.get_single(word, True)\n\t\tassert isinstance(ref, spinner.Word)\n\t\tref.delete()", "path": "spinner\\tests\\basic_test.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Check if data is valid. Used for filter functions\"\"\"\n\n", "func_signal": "def check_data(self, data):\n", "code": "data = re.sub('(\\-|\\|)', '', data)\ndata = data.strip()\nreturn len(data)", "path": "wordle\\__init__.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Get the BOSS titles back\"\"\"\n", "func_signal": "def testGetTitles(self):\n", "code": "boss = proxy.BOSS()\ntitles = boss.get_titles('mac tips')\nassert len(titles)", "path": "spyder\\tests\\basic_test.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Return a synonym regardless of order\"\"\"\n\n", "func_signal": "def get_single(self, word_one, word_two, create = None):\n", "code": "if create is None:\n\t\tcreate = False\n\nword_one = Word.objects.get_single(word_one, True)\nword_two = Word.objects.get_single(word_two, True)\n\nsyn = None\n\ntry:\n\t\tsyn = Synonym.objects.get(word_one=word_one, word_two=word_two)\nexcept (Synonym.DoesNotExist):\n\t\ttry:\n\t\t\t\tsyn = Synonym.objects.get(word_one=word_two, word_two=word_one)\n\t\texcept (Synonym.DoesNotExist):\n\t\t\t\tif create:\n\t\t\t\t\t\tsyn = Synonym(word_one=word_one, word_two=word_two)\n\t\t\t\t\t\tsyn.save()\n\nreturn syn", "path": "spinner\\models.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"Return all synonyms for a word\"\"\"\n\n", "func_signal": "def get_all(self, word):\n", "code": "word = Word.objects.get_single(word, True)\n\nall = Synonym.objects.filter(\n\t\tmodels.Q(word_one=word) | models.Q(word_two=word)\n)\n\nfinal = []\nfor syn in all:\n\t\tif syn.word_one == word:\n\t\t\t\tother_word = syn.word_two\n\t\telse:\n\t\t\t\tother_word = syn.word_one\n\n\t\tother_word.total_karma = other_word.karma * syn.karma\n\t\tfinal.append(other_word)\n\nfinal.sort(key=lambda i: (i.total_karma))\nfinal.reverse()\n\nreturn final", "path": "spinner\\models.py", "repo_name": "bradjasper/instockdomains", "stars": 3, "license": "None", "language": "python", "size": 135}
{"docstring": "\"\"\"\nHighlighted the lines specified in the `hl_lines` option by\npost-processing the token stream coming from `_format_lines`.\n\"\"\"\n", "func_signal": "def _highlight_lines(self, tokensource):\n", "code": "hls = self.hl_lines\n\nfor i, (t, value) in enumerate(tokensource):\n    if t != 1:\n        yield t, value\n    if i + 1 in hls: # i + 1 because Python indexes start at 0\n        yield 1, '<span class=\"hll\">%s</span>' % value\n    else:\n        yield 1, value", "path": "pygments\\formatters\\html.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "\"\"\"\nCreate drawables for the line numbers.\n\"\"\"\n", "func_signal": "def _draw_line_numbers(self):\n", "code": "if not self.line_numbers:\n    return\nfor i in xrange(self.maxlineno):\n    if ((i + 1) % self.line_number_step) == 0:\n        self._draw_linenumber(i)", "path": "pygments\\formatters\\img.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "\"\"\"\nDecorator that converts a function into a filter::\n\n    @simplefilter\n    def lowercase(lexer, stream, options):\n        for ttype, value in stream:\n            yield ttype, value.lower()\n\"\"\"\n", "func_signal": "def simplefilter(f):\n", "code": "return type(f.__name__, (FunctionFilter,), {\n            'function':     f,\n            '__module__':   getattr(f, '__module__'),\n            '__doc__':      f.__doc__\n        })", "path": "pygments\\filter.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "\"\"\"\nThe formatting process uses several nested generators; which of\nthem are used is determined by the user's options.\n\nEach generator should take at least one argument, ``inner``,\nand wrap the pieces of text generated by this.\n\nAlways yield 2-tuples: (code, text). If \"code\" is 1, the text\nis part of the original tokensource being highlighted, if it's\n0, the text is some piece of wrapping. This makes it possible to\nuse several different wrappers that process the original source\nlinewise, e.g. line number generators.\n\"\"\"\n", "func_signal": "def format(self, tokensource, outfile):\n", "code": "source = self._format_lines(tokensource)\nif self.hl_lines:\n    source = self._highlight_lines(source)\nif not self.nowrap:\n    if self.linenos == 2:\n        source = self._wrap_inlinelinenos(source)\n    if self.lineanchors:\n        source = self._wrap_lineanchors(source)\n    source = self.wrap(source, outfile)\n    if self.linenos == 1:\n        source = self._wrap_tablelinenos(source)\n    if self.full:\n        source = self._wrap_full(source, outfile)\n\nfor t, piece in source:\n    outfile.write(piece)", "path": "pygments\\formatters\\html.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "\"\"\"\nFormat ``tokensource``, an iterable of ``(tokentype, tokenstring)``\ntuples and write it into ``outfile``.\n\nThis implementation calculates where it should draw each token on the\npixmap, then calculates the required pixmap size and draws the items.\n\"\"\"\n", "func_signal": "def format(self, tokensource, outfile):\n", "code": "self._create_drawables(tokensource)\nself._draw_line_numbers()\nim = Image.new(\n    'RGB',\n    self._get_image_size(self.maxcharno, self.maxlineno),\n    self.background_color\n)\nself._paint_line_number_bg(im)\ndraw = ImageDraw.Draw(im)\nfor pos, value, font, kw in self.drawables:\n    draw.text(pos, value, font=font, **kw)\nim.save(outfile, self.image_format.upper())", "path": "pygments\\formatters\\img.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "# empty strings, should give a small performance improvment\n", "func_signal": "def _escape_text(self, text):\n", "code": "if not text:\n    return ''\n\n# escape text\ntext = self._escape(text)\nencoding = self.encoding or 'iso-8859-15'\n\nbuf = []\nfor c in text:\n    if ord(c) > 128:\n        ansic = c.encode(encoding, 'ignore') or '?'\n        if ord(ansic) > 128:\n            ansic = '\\\\\\'%x' % ord(ansic)\n        buf.append(r'\\ud{\\u%d%s}' % (ord(c), ansic))\n    else:\n        buf.append(str(c))\n\nreturn ''.join(buf).replace('\\n', '\\\\par\\n')", "path": "pygments\\formatters\\rtf.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "\"\"\"\nReturn CSS style definitions for the classes produced by the current\nhighlighting style. ``arg`` can be a string or list of selectors to\ninsert before the token type classes.\n\"\"\"\n", "func_signal": "def get_style_defs(self, arg=None):\n", "code": "if arg is None:\n    arg = ('cssclass' in self.options and '.'+self.cssclass or '')\nif isinstance(arg, basestring):\n    args = [arg]\nelse:\n    args = list(arg)\n\ndef prefix(cls):\n    if cls:\n        cls = '.' + cls\n    tmp = []\n    for arg in args:\n        tmp.append((arg and arg + ' ' or '') + cls)\n    return ', '.join(tmp)\n\nstyles = [(level, ttype, cls, style)\n          for cls, (style, ttype, level) in self.class2style.iteritems()\n          if cls and style]\nstyles.sort()\nlines = ['%s { %s } /* %s */' % (prefix(cls), style, repr(ttype)[6:])\n         for (level, ttype, cls, style) in styles]\nif arg and not self.nobackground and \\\n   self.style.background_color is not None:\n    text_style = ''\n    if Text in self.ttype2class:\n        text_style = ' ' + self.class2style[self.ttype2class[Text]][0]\n    lines.insert(0, '%s { background: %s;%s }' %\n                 (prefix(''), self.style.background_color, text_style))\nif self.style.highlight_color is not None:\n    lines.insert(0, '%s.hll { background-color: %s }' %\n                 (prefix(''), self.style.highlight_color))\nreturn '\\n'.join(lines)", "path": "pygments\\formatters\\html.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "\"\"\"\nGet the font based on bold and italic flags.\n\"\"\"\n", "func_signal": "def get_font(self, bold, oblique):\n", "code": "if bold and oblique:\n    return self.fonts['BOLDITALIC']\nelif bold:\n    return self.fonts['BOLD']\nelif oblique:\n    return self.fonts['ITALIC']\nelse:\n    return self.fonts['NORMAL']", "path": "pygments\\formatters\\img.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "\"\"\"\nGet the correct color for the token from the style.\n\"\"\"\n", "func_signal": "def _get_text_color(self, style):\n", "code": "if style['color'] is not None:\n    fill = '#' + style['color']\nelse:\n    fill = '#000'\nreturn fill", "path": "pygments\\formatters\\img.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "\"\"\"Return a random id for javascript fields.\"\"\"\n", "func_signal": "def get_random_id():\n", "code": "from random import random\nfrom time import time\ntry:\n    from hashlib import sha1 as sha\nexcept ImportError:\n    import sha\n    sha = sha.new\nreturn sha('%s|%s' % (random(), time())).hexdigest()", "path": "pygments\\formatters\\html.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "\"\"\"\nPaint the line number background on the image.\n\"\"\"\n", "func_signal": "def _paint_line_number_bg(self, im):\n", "code": "if not self.line_numbers:\n    return\nif self.line_number_fg is None:\n    return\ndraw = ImageDraw.Draw(im)\nrecth = im.size[-1]\nrectw = self.image_pad + self.line_number_width - self.line_number_pad\ndraw.rectangle([(0, 0),\n                (rectw, recth)],\n     fill=self.line_number_bg)\ndraw.line([(rectw, 0), (rectw, recth)], fill=self.line_number_fg)\ndel draw", "path": "pygments\\formatters\\img.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "\"\"\"\nGet the required image size.\n\"\"\"\n", "func_signal": "def _get_image_size(self, maxcharno, maxlineno):\n", "code": "return (self._get_char_x(maxcharno) + self.image_pad,\n        self._get_line_y(maxlineno + 0) + self.image_pad)", "path": "pygments\\formatters\\img.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "# pylint: disable-msg=E1102\n", "func_signal": "def filter(self, lexer, stream):\n", "code": "for ttype, value in self.function(lexer, stream, self.options):\n    yield ttype, value", "path": "pygments\\filter.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "# need a list of lines since we need the width of a single number :(\n", "func_signal": "def _wrap_inlinelinenos(self, inner):\n", "code": "lines = list(inner)\nsp = self.linenospecial\nst = self.linenostep\nnum = self.linenostart\nmw = len(str(len(lines) + num - 1))\n\nif sp:\n    for t, line in lines:\n        yield 1, '<span class=\"lineno%s\">%*s</span> ' % (\n            num%sp == 0 and ' special' or '', mw,\n            (num%st and ' ' or num)) + line\n        num += 1\nelse:\n    for t, line in lines:\n        yield 1, '<span class=\"lineno\">%*s</span> ' % (\n            mw, (num%st and ' ' or num)) + line\n        num += 1", "path": "pygments\\formatters\\html.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "\"\"\"\nUse this method to apply an iterable of filters to\na stream. If lexer is given it's forwarded to the\nfilter, otherwise the filter receives `None`.\n\"\"\"\n", "func_signal": "def apply_filters(stream, filters, lexer=None):\n", "code": "def _apply(filter_, stream):\n    for token in filter_.filter(lexer, stream):\n        yield token\nfor filter_ in filters:\n    stream = _apply(filter_, stream)\nreturn stream", "path": "pygments\\filter.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "\"\"\"\n:param text:    The text which should be scanned\n:param flags:   default regular expression flags\n\"\"\"\n", "func_signal": "def __init__(self, text, flags=0):\n", "code": "self.data = text\nself.data_length = len(text)\nself.start_pos = 0\nself.pos = 0\nself.flags = flags\nself.last = None\nself.match = None\nself._re_cache = {}", "path": "pygments\\scanner.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "\"\"\"Return the css class of this token type prefixed with\nthe classprefix option.\"\"\"\n", "func_signal": "def _get_css_class(self, ttype):\n", "code": "if ttype in self._class_cache:\n    return self._class_cache[ttype]\nreturn self.classprefix + _get_ttype_class(ttype)", "path": "pygments\\formatters\\html.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "# rtf 1.8 header\n", "func_signal": "def format(self, tokensource, outfile):\n", "code": "outfile.write(r'{\\rtf1\\ansi\\deff0'\n              r'{\\fonttbl{\\f0\\fmodern\\fprq1\\fcharset0%s;}}'\n              r'{\\colortbl;' % (self.fontface and\n                                ' ' + self._escape(self.fontface) or\n                                ''))\n\n# convert colors and save them in a mapping to access them later.\ncolor_mapping = {}\noffset = 1\nfor _, style in self.style:\n    for color in style['color'], style['bgcolor'], style['border']:\n        if color and color not in color_mapping:\n            color_mapping[color] = offset\n            outfile.write(r'\\red%d\\green%d\\blue%d;' % (\n                int(color[0:2], 16),\n                int(color[2:4], 16),\n                int(color[4:6], 16)\n            ))\n            offset += 1\noutfile.write(r'}\\f0')\n\n# highlight stream\nfor ttype, value in tokensource:\n    while not self.style.styles_token(ttype) and ttype.parent:\n        ttype = ttype.parent\n    style = self.style.style_for_token(ttype)\n    buf = []\n    if style['bgcolor']:\n        buf.append(r'\\cb%d' % color_mapping[style['bgcolor']])\n    if style['color']:\n        buf.append(r'\\cf%d' % color_mapping[style['color']])\n    if style['bold']:\n        buf.append(r'\\b')\n    if style['italic']:\n        buf.append(r'\\i')\n    if style['underline']:\n        buf.append(r'\\ul')\n    if style['border']:\n        buf.append(r'\\chbrdr\\chcfpat%d' %\n                   color_mapping[style['border']])\n    start = ''.join(buf)\n    if start:\n        outfile.write('{%s ' % start)\n    outfile.write(self._escape_text(value))\n    if start:\n        outfile.write('}')\n\noutfile.write('}')", "path": "pygments\\formatters\\rtf.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "\"\"\"Return an generator for all styles by name,\nboth builtin and plugin.\"\"\"\n", "func_signal": "def get_all_styles():\n", "code": "for name in STYLE_MAP:\n    yield name\nfor name, _ in find_plugin_styles():\n    yield name", "path": "pygments\\styles\\__init__.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "\"\"\"\nAdditional options accepted:\n\n``fontface``\n    Name of the font used. Could for example be ``'Courier New'``\n    to further specify the default which is ``'\\fmodern'``. The RTF\n    specification claims that ``\\fmodern`` are \"Fixed-pitch serif\n    and sans serif fonts\". Hope every RTF implementation thinks\n    the same about modern...\n\"\"\"\n", "func_signal": "def __init__(self, **options):\n", "code": "Formatter.__init__(self, **options)\nself.fontface = options.get('fontface') or ''\nif self.encoding in ('utf-8', 'utf-16', 'utf-32'):\n    self.encoding = None", "path": "pygments\\formatters\\rtf.py", "repo_name": "mbialon/yashapp", "stars": 2, "license": "None", "language": "python", "size": 448}
{"docstring": "# XXX This logic should be moved into the treebuilder\n# AT should use reversed instead of [::-1] when Python 2.4 == True.\n", "func_signal": "def endTagOther(self, name):\n", "code": "for node in self.tree.openElements[::-1]:\n    if node.name == name:\n        self.tree.generateImpliedEndTags()\n        if self.tree.openElements[-1].name != name:\n            self.parser.parseError(\"unexpected-end-tag\", {\"name\": name})\n        while self.tree.openElements.pop() != node:\n            pass\n        break\n    else:\n        if node.name in specialElements | scopingElements:\n            self.parser.parseError(\"unexpected-end-tag\", {\"name\": name})\n            break", "path": "html5lib\\html5parser.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "# We need to imply </option> if <option> is the current node.\n", "func_signal": "def startTagOption(self, name, attributes):\n", "code": "if self.tree.openElements[-1].name == \"option\":\n    self.tree.openElements.pop()\nself.tree.insertElement(name, attributes)", "path": "html5lib\\html5parser.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "# Sometimes (start of <pre>, <listing>, and <textarea> blocks) we\n# want to drop leading newlines\n", "func_signal": "def processSpaceCharactersDropNewline(self, data):\n", "code": "self.processSpaceCharacters = self.processSpaceCharactersNonPre\nif (data.startswith(\"\\n\") and\n    self.tree.openElements[-1].name in (\"pre\", \"listing\", \"textarea\") and\n    not self.tree.openElements[-1].hasContent()):\n    data = data[1:]\nif data:\n    self.tree.reconstructActiveFormattingElements()\n    self.tree.insertText(data)", "path": "html5lib\\html5parser.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "# AT Could merge this with the Block case\n", "func_signal": "def endTagListItem(self, name):\n", "code": "if self.tree.elementInScope(name):\n    self.tree.generateImpliedEndTags(name)\n\nif self.tree.openElements[-1].name != name:\n    self.parser.parseError(\"end-tag-too-early\", {\"name\": name})\n\nif self.tree.elementInScope(name):\n    node = self.tree.openElements.pop()\n    while node.name != name:\n        node = self.tree.openElements.pop()", "path": "html5lib\\html5parser.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "# XXX Form element pointer checking here as well...\n", "func_signal": "def startTagTextarea(self, name, attributes):\n", "code": "self.tree.insertElement(name, attributes)\nself.parser.tokenizer.contentModelFlag = contentModelFlags[\"RCDATA\"]\nself.processSpaceCharacters = self.processSpaceCharactersDropNewline", "path": "html5lib\\html5parser.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "\"\"\"Get a TreeWalker class for various types of tree with built-in support\n\ntreeType - the name of the tree type required (case-insensitive). Supported\n           values are \"simpletree\", \"dom\", \"etree\" and \"beautifulsoup\"\n\n           \"simpletree\" - a built-in DOM-ish tree type with support for some\n                          more pythonic idioms.\n            \"dom\" - The xml.dom.minidom DOM implementation\n            \"pulldom\" - The xml.dom.pulldom event stream\n            \"etree\" - A generic walker for tree implementations exposing an\n                      elementtree-like interface (known to work with\n                      ElementTree, cElementTree and lxml.etree).\n            \"lxml\" - Optimized walker for lxml.etree\n            \"beautifulsoup\" - Beautiful soup (if installed)\n            \"genshi\" - a Genshi stream\n\nimplementation - (Currently applies to the \"etree\" tree type only). A module\n                  implementing the tree type e.g. xml.etree.ElementTree or\n                  cElementTree.\"\"\"\n\n", "func_signal": "def getTreeWalker(treeType, implementation=None, **kwargs):\n", "code": "treeType = treeType.lower()\nif treeType not in treeWalkerCache:\n    if treeType in (\"dom\", \"pulldom\", \"simpletree\"):\n        mod = __import__(treeType, globals())\n        treeWalkerCache[treeType] = mod.TreeWalker\n    elif treeType == \"genshi\":\n        import genshistream\n        treeWalkerCache[treeType] = genshistream.TreeWalker\n    elif treeType == \"beautifulsoup\":\n        import soup\n        treeWalkerCache[treeType] = soup.TreeWalker\n    elif treeType == \"lxml\":\n        import lxmletree\n        treeWalkerCache[treeType] = lxmletree.TreeWalker\n    elif treeType == \"etree\":\n        import etree\n        # XXX: NEVER cache here, caching is done in the etree submodule\n        return etree.getETreeModule(implementation, **kwargs).TreeWalker\nreturn treeWalkerCache.get(treeType)", "path": "html5lib\\treewalkers\\__init__.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "# XXX The specification says to do this for every character at the\n# moment, but apparently that doesn't match the real world so we don't\n# do it for space characters.\n", "func_signal": "def processCharacters(self, data):\n", "code": "self.tree.reconstructActiveFormattingElements()\nself.tree.insertText(data)", "path": "html5lib\\html5parser.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "# Sanitize From/Time\n", "func_signal": "def GET(self, pos_type, pos_value, time_value):\n", "code": "pos_type = type(pos_type)\n\ntry:\n\tpos_value = unicode(pos_value.encode('iso-8859-1'), 'utf-8')\nexcept UnicodeDecodeError:\n\tpass\n\t\npos = toarray(unquote(pos_value), pos_type)\n\ntime_value = requesttime(unquote(time_value))\nfilters = web.input(apikey=None)\n\ns = station.Station(pos, time_value, filters)\nxml = u''\nif s.error:\n\txml = s.xmlerror\nelse:\n\txml = s.xml\n\nweb.header('Content-Type', 'text/xml')\nreturn '<?xml version=\"1.0\"?><station>'+ s.xmlinfo + xml + '</station>'", "path": "schedule.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "# XXX The idea is to make errorcode mandatory.\n", "func_signal": "def parseError(self, errorcode=\"XXX-undefined-error\", datavars={}):\n", "code": "self.errors.append((self.tokenizer.stream.position(), errorcode, datavars))\nif self.strict:\n    raise ParseError", "path": "html5lib\\html5parser.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "# A really slow request:\n", "func_signal": "def profile():\n", "code": "time_type = 'dep'\ntime_value = requesttime('2009-04-01 09:14')\n#source_type = 'addr'\n#source_value = u'Badenerstrasse 363, 8003, Zrich'\n#destination_type = 'addr'\n#destination_value = u'Schweighofstrasse 418, 8055 Zrich'\nsource_type = 'addr'\nsource_value = u'Z\u00fcrich, Schaufelbergerstrasse'\ndestination_type = 'stat'\ndestination_value = u'Z\u00fcrich, Thurgauerstrasse 4'\t\nfilters = {'changetime':0, 'changes':None, 'suppresslong':False, 'groups':False, 'bicycles':False, 'flat':False, 'apikey':None}\nsource = toarray(source_value, source_type)\ndestination = toarray(destination_value, destination_type)\ntime = toarray(time_value, time_type)\n\ns = schedule.Schedule()\nxml = s.load_XML(source, destination, time, filters)\t\nweb.debug(xml)", "path": "schedule.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "# \"clear the stack back to a table context\"\n", "func_signal": "def clearStackToTableContext(self):\n", "code": "while self.tree.openElements[-1].name not in (\"table\", \"html\"):\n    #self.parser.parseError(\"unexpected-implied-end-tag-in-table\",\n    #  {\"name\":  self.tree.openElements[-1].name})\n    self.tree.openElements.pop()\n# When the current node is <html> it's an innerHTML case", "path": "html5lib\\html5parser.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "# XXX AT Any ideas on how to share this with endTagTable?\n", "func_signal": "def startTagTableOther(self, name, attributes):\n", "code": "if (self.tree.elementInScope(\"tbody\", True) or\n    self.tree.elementInScope(\"thead\", True) or\n    self.tree.elementInScope(\"tfoot\", True)):\n    self.clearStackToTableBodyContext()\n    self.endTagTableRowGroup(self.tree.openElements[-1].name)\n    self.parser.phase.processStartTag(name, attributes)\nelse:\n    # innerHTML case\n    self.parser.parseError()", "path": "html5lib\\html5parser.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "# </optgroup> implicitly closes <option>\n", "func_signal": "def endTagOptgroup(self, name):\n", "code": "if self.tree.openElements[-1].name == \"option\" and \\\n  self.tree.openElements[-2].name == \"optgroup\":\n    self.tree.openElements.pop()\n# It also closes </optgroup>\nif self.tree.openElements[-1].name == \"optgroup\":\n    self.tree.openElements.pop()\n# But nothing else\nelse:\n    self.parser.parseError(\"unexpected-end-tag-in-select\",\n      {\"name\": \"optgroup\"})", "path": "html5lib\\html5parser.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "# The name of this method is mostly historical. (It's also used in the\n# specification.)\n", "func_signal": "def resetInsertionMode(self):\n", "code": "last = False\nnewModes = {\n    \"select\":\"inSelect\",\n    \"td\":\"inCell\",\n    \"th\":\"inCell\",\n    \"tr\":\"inRow\",\n    \"tbody\":\"inTableBody\",\n    \"thead\":\"inTableBody\",\n    \"tfoot\":\"inTableBody\",\n    \"caption\":\"inCaption\",\n    \"colgroup\":\"inColumnGroup\",\n    \"table\":\"inTable\",\n    \"head\":\"inBody\",\n    \"body\":\"inBody\",\n    \"frameset\":\"inFrameset\"\n}\nfor node in self.tree.openElements[::-1]:\n    nodeName = node.name\n    if node == self.tree.openElements[0]:\n        last = True\n        if nodeName not in ['td', 'th']:\n            # XXX\n            assert self.innerHTML\n            nodeName = self.innerHTML\n    # Check for conditions that should only happen in the innerHTML\n    # case\n    if nodeName in (\"select\", \"colgroup\", \"head\", \"frameset\"):\n        # XXX\n        assert self.innerHTML\n    if nodeName in newModes:\n        self.phase = self.phases[newModes[nodeName]]\n        break\n    elif nodeName == \"html\":\n        if self.tree.headPointer is None:\n            self.phase = self.phases[\"beforeHead\"]\n        else:\n           self.phase = self.phases[\"afterHead\"]\n        break\n    elif last:\n        self.phase = self.phases[\"inBody\"]\n        break", "path": "html5lib\\html5parser.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "\"\"\" HTML5 specific normalizations to the token stream \"\"\"\n\n", "func_signal": "def normalizeToken(self, token):\n", "code": "if token[\"type\"] == \"EmptyTag\":\n    # When a solidus (/) is encountered within a tag name what happens\n    # depends on whether the current tag name matches that of a void\n    # element.  If it matches a void element atheists did the wrong\n    # thing and if it doesn't it's wrong for everyone.\n\n    if token[\"name\"] not in voidElements:\n        self.parseError(\"incorrectly-placed-solidus\")\n\n    token[\"type\"] = \"StartTag\"\n\nif token[\"type\"] == \"StartTag\":\n    token[\"data\"] = dict(token[\"data\"][::-1])\n\nreturn token", "path": "html5lib\\html5parser.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "# Sanitize From/To/Types\n", "func_signal": "def GET(self, source_type, source_value, destination_type, destination_value, time_type, time_value):\n", "code": "source_type = type(source_type)\ndestination_type = type(destination_type)\t\nlogging.debug(time_value)\t\t\n\t\ntry:\n\tdest = destination_value.encode('iso-8859-1')\n\tdestination_value = unicode(dest, 'utf-8')\n\tsrc = source_value.encode('iso-8859-1')\n\tsource_value = unicode(src, 'utf-8')\nexcept UnicodeDecodeError:\n\tpass\n\nsource = toarray(unicode(unquote(source_value)), source_type)\ndestination = toarray(unicode(unquote(destination_value)), destination_type)\n\n# Sanitize Date/Time\ntime_type = timetype(time_type)\ntime_value = requesttime(unquote(time_value))\nlogging.debug(time_value)\ntime = toarray(time_value, time_type)\n\nfilters = web.input(changetime=0, changes=None, suppresslong=False,\\\n\t\t\t\t\tgroups=False, bicycles=False, flat=False, apikey=None, format=u'xml')\n\t\t\t\t\ns = schedule.Schedule()\nxml = s.load_XML(source, destination, time, filters)\n\n\nxmlcontent = '<?xml version=\"1.0\" encoding=\"UTF-8\"?><schedules>' + xml + '</schedules>'\nif (filters['format'] == u'xml'):\n\tweb.header('Content-Type', 'text/xml; charset=utf-8')\n\treturn xmlcontent\nelif (filters['format'] == u'html'):\n\tweb.header('Content-Type', 'text/html; charset=utf-8')\n\txml_tree = etree.parse(StringIO(xmlcontent))\n\txsl_tree = etree.parse(open('./xsl/schedule.xsl', 'r'))\n\ttransform = etree.XSLT(xsl_tree)\n\tresult_tree = transform(xml_tree)\n\treturn etree.tostring(result_tree, encoding='utf8')", "path": "schedule.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "\"\"\"Generic (R)CDATA Parsing algorithm\ncontentType - RCDATA or CDATA\n\"\"\"\n", "func_signal": "def parseRCDataCData(self, name, attributes, contentType):\n", "code": "assert contentType in (\"CDATA\", \"RCDATA\")\n\nelement = self.tree.insertElement(name, attributes)\nself.tokenizer.contentModelFlag = contentModelFlags[contentType]\n\nfor token in self.normalizedTokens():\n    if token[\"type\"] in (\"Characters\", \"SpaceCharacters\"):\n        self.tree.insertText(token[\"data\"])\n    elif token[\"type\"] == \"ParseError\":\n        self.parseError(token[\"data\"], token.get(\"datavars\", {}))\n    else:\n        assert self.tokenizer.contentModelFlag == contentModelFlags[\"PCDATA\"]\n        assert token[\"type\"] == \"EndTag\" and token[\"name\"] == name, repr(token)\n        popped = self.tree.openElements.pop()\n        assert popped == element\n        return\n#Otherwise we hit EOF\npopped = self.tree.openElements.pop()\nassert popped == element\nself.parseError(\"expected-closing-tag-but-got-eof\")", "path": "html5lib\\html5parser.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "#Put us back in the right whitespace handling mode\n", "func_signal": "def endTagBlock(self, name):\n", "code": "if name == \"pre\":\n    self.processSpaceCharacters = self.processSpaceCharactersNonPre\ninScope = self.tree.elementInScope(name)\nif inScope:\n    self.tree.generateImpliedEndTags()\nif self.tree.openElements[-1].name != name:\n     self.parser.parseError(\"end-tag-too-early\", {\"name\": name})\nif inScope:\n    node = self.tree.openElements.pop()\n    while node.name != name:\n        node = self.tree.openElements.pop()", "path": "html5lib\\html5parser.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "\"\"\"The much-feared adoption agency algorithm\n\"\"\"\n# http://www.whatwg.org/specs/web-apps/current-work/#adoptionAgency\n# XXX Better parseError messages appreciated.\n", "func_signal": "def endTagFormatting(self, name):\n", "code": "while True:\n    # Step 1 paragraph 1\n    afeElement = self.tree.elementInActiveFormattingElements(name)\n    if not afeElement or (afeElement in self.tree.openElements and\n      not self.tree.elementInScope(afeElement.name)):\n        self.parser.parseError(\"adoption-agency-1.1\", {\"name\": name})\n        return\n\n    # Step 1 paragraph 2\n    elif afeElement not in self.tree.openElements:\n        self.parser.parseError(\"adoption-agency-1.2\", {\"name\": name})\n        self.tree.activeFormattingElements.remove(afeElement)\n        return\n\n    # Step 1 paragraph 3\n    if afeElement != self.tree.openElements[-1]:\n        self.parser.parseError(\"adoption-agency-1.3\", {\"name\": name})\n\n    # Step 2\n    # Start of the adoption agency algorithm proper\n    afeIndex = self.tree.openElements.index(afeElement)\n    furthestBlock = None\n    for element in self.tree.openElements[afeIndex:]:\n        if element.name in specialElements | scopingElements:\n            furthestBlock = element\n            break\n\n    # Step 3\n    if furthestBlock is None:\n        element = self.tree.openElements.pop()\n        while element != afeElement:\n            element = self.tree.openElements.pop()\n        self.tree.activeFormattingElements.remove(element)\n        return\n    commonAncestor = self.tree.openElements[afeIndex-1]\n\n    # Step 5\n    if furthestBlock.parent:\n        furthestBlock.parent.removeChild(furthestBlock)\n\n    # Step 6\n    # The bookmark is supposed to help us identify where to reinsert\n    # nodes in step 12. We have to ensure that we reinsert nodes after\n    # the node before the active formatting element. Note the bookmark\n    # can move in step 7.4\n    bookmark = self.tree.activeFormattingElements.index(afeElement)\n\n    # Step 7\n    lastNode = node = furthestBlock\n    while True:\n        # AT replace this with a function and recursion?\n        # Node is element before node in open elements\n        node = self.tree.openElements[\n            self.tree.openElements.index(node)-1]\n        while node not in self.tree.activeFormattingElements:\n            tmpNode = node\n            node = self.tree.openElements[\n                self.tree.openElements.index(node)-1]\n            self.tree.openElements.remove(tmpNode)\n        # Step 7.3\n        if node == afeElement:\n            break\n        # Step 7.4\n        if lastNode == furthestBlock:\n            # XXX should this be index(node) or index(node)+1\n            # Anne: I think +1 is ok. Given x = [2,3,4,5]\n            # x.index(3) gives 1 and then x[1 +1] gives 4...\n            bookmark = self.tree.activeFormattingElements.\\\n              index(node) + 1\n        # Step 7.5\n        cite = node.parent\n        if node.hasContent():\n            clone = node.cloneNode()\n            # Replace node with clone\n            self.tree.activeFormattingElements[\n              self.tree.activeFormattingElements.index(node)] = clone\n            self.tree.openElements[\n              self.tree.openElements.index(node)] = clone\n            node = clone\n        # Step 7.6\n        # Remove lastNode from its parents, if any\n        if lastNode.parent:\n            lastNode.parent.removeChild(lastNode)\n        node.appendChild(lastNode)\n        # Step 7.7\n        lastNode = node\n        # End of inner loop\n\n    # Step 8\n    if lastNode.parent:\n        lastNode.parent.removeChild(lastNode)\n    commonAncestor.appendChild(lastNode)\n\n    # Step 9\n    clone = afeElement.cloneNode()\n\n    # Step 10\n    furthestBlock.reparentChildren(clone)\n\n    # Step 11\n    furthestBlock.appendChild(clone)\n\n    # Step 12\n    self.tree.activeFormattingElements.remove(afeElement)\n    self.tree.activeFormattingElements.insert(bookmark, clone)\n\n    # Step 13\n    self.tree.openElements.remove(afeElement)\n    self.tree.openElements.insert(\n      self.tree.openElements.index(furthestBlock) + 1, clone)", "path": "html5lib\\html5parser.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "\"\"\" Get Information about a station (Departures and Arrivals)\"\"\"\n# Setup output vars\n", "func_signal": "def __init__(self, query, time, filters):\n", "code": "self.stations = None\nself.data = None\nself.xml = u''\nself.xmlinfo = u''\nself.error = None\nself.xmlerror = u''\n\n# Setup privates\nself._time = time\nself._query = query\nself._filters = filters\nself._backendtime = 0\n\nself.location = None\nself.cachekey = query['value'] + query['type'] + str(time)\n\ntry:\n\tself._setup_xmlinfo()\nexcept Exception:\n\tself.error = {'message':u'Internal error', 'id':105}\n\tself._setup_xmlerror()\n\treturn\n\n# Try to get the stations\ntry:\n\tself._setup_stations()\nexcept Exception:\n\traise\n\tself.error = {'message':u'Malformed input','id':101}\n\tself._setup_xmlerror()\n\treturn\n\n\nif len(self.stations) == 0:\n\tself.error = {'message':u'Could not find any Stations','id':102}\n\tself._setup_xmlerror()\n\treturn\n\n# Try to fetch the data via StationThread\ntry:\n\tself._load_data()\nexcept Exception:\n\traise\n\tself.error = {'message':u'Error retrieving data', 'id':103}\n\tself._setup_xmlerror()\n\treturn\n\n\n# Try to setup the xml\ntry:\n\tself._setup_xml()\nexcept Exception:\n\tself.error = {'message':u'Internal error', 'id':104}\n\tself._setup_xmlerror()\n\treturn\n\nif self.xml == '':\n\tself.error = {'message':u'guru meditation - unexpected error occured', 'id':1099}\n\tself._setup_xmlerror()\n\treturn", "path": "models\\station.py", "repo_name": "marcammann/zvvapi", "stars": 2, "license": "None", "language": "python", "size": 1228}
{"docstring": "\"\"\"\nAssociates the given object with a tag.\n\"\"\"\n", "func_signal": "def add_tag(self, obj, tag_name):\n", "code": "tag_names = parse_tag_input(tag_name)\nif not len(tag_names):\n    raise AttributeError(_('No tags were given: \"%s\".') % tag_name)\nif len(tag_names) > 1:\n    raise AttributeError(_('Multiple tags were given: \"%s\".') % tag_name)\ntag_name = tag_names[0]\nif settings.FORCE_LOWERCASE_TAGS:\n    tag_name = tag_name.lower()\ntag, created = self.get_or_create(name=tag_name)\nctype = ContentType.objects.get_for_model(obj)\nTaggedItem._default_manager.get_or_create(\n    tag=tag, content_type=ctype, object_id=obj.pk)", "path": "generic\\tagging\\models.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nCreate a ``QuerySet`` containing instances of the specified\nmodel associated with a given tag or list of tags.\n\"\"\"\n", "func_signal": "def get_by_model(self, queryset_or_model, tags):\n", "code": "tags = get_tag_list(tags)\ntag_count = len(tags)\nif tag_count == 0:\n    # No existing tags were given\n    queryset, model = get_queryset_and_model(queryset_or_model)\n    return model._default_manager.none()\nelif tag_count == 1:\n    # Optimisation for single tag - fall through to the simpler\n    # query below.\n    tag = tags[0]\nelse:\n    return self.get_intersection_by_model(queryset_or_model, tags)\n\nqueryset, model = get_queryset_and_model(queryset_or_model)\ncontent_type = ContentType.objects.get_for_model(model)\nopts = self.model._meta\ntagged_item_table = qn(opts.db_table)\nreturn queryset.extra(\n    tables=[opts.db_table],\n    where=[\n        '%s.content_type_id = %%s' % tagged_item_table,\n        '%s.tag_id = %%s' % tagged_item_table,\n        '%s.%s = %s.object_id' % (qn(model._meta.db_table),\n                                  qn(model._meta.pk.column),\n                                  tagged_item_table)\n    ],\n    params=[content_type.pk, tag.pk],\n)", "path": "generic\\tagging\\models.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nCreate a queryset matching all tags associated with the given\nobject.\n\"\"\"\n", "func_signal": "def get_for_object(self, obj):\n", "code": "ctype = ContentType.objects.get_for_model(obj)\nreturn self.filter(items__content_type__pk=ctype.pk,\n                   items__object_id=obj.pk)", "path": "generic\\tagging\\models.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nApplies text-to-HTML conversion to a string, and returns the\nHTML.\n\n\"\"\"\n", "func_signal": "def __call__(self, text, **kwargs):\n", "code": "if 'filter_name' in kwargs:\n    filter_name = kwargs['filter_name']\n    del kwargs['filter_name']\n    filter_kwargs = {}\nelse:\n    from django.conf import settings\n    filter_name, filter_kwargs = settings.MARKUP_FILTER\nif filter_name is None:\n    return text\nif filter_name not in self._filters:\n    raise ValueError(\"'%s' is not a registered markup filter. Registered filters are: %s.\" % (filter_name,\n                                                                                               ', '.join(self._filters.iterkeys())))\nfilter_func = self._filters[filter_name]\nfilter_kwargs.update(**kwargs)\nreturn filter_func(text, **filter_kwargs)", "path": "generic\\template_utils\\markup.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "# compile selector pattern\n", "func_signal": "def findall(elem, path):\n", "code": "try:\n    selector = _cache[path]\nexcept KeyError:\n    if len(_cache) > 100:\n        _cache.clear()\n    if path[:1] == \"/\":\n        raise SyntaxError(\"cannot use absolute path on element\")\n    stream = iter(xpath_tokenizer(path))\n    next = stream.next; token = next()\n    selector = []\n    while 1:\n        try:\n            selector.append(ops[token[0]](next, token))\n        except StopIteration:\n            raise SyntaxError(\"invalid path\")\n        try:\n            token = next()\n            if token[0] == \"/\":\n                token = next()\n        except StopIteration:\n            break\n    _cache[path] = selector\n# execute selector pattern\nresult = [elem]\ncontext = _SelectorContext(elem)\nfor select in selector:\n    result = select(context, result)\nreturn result", "path": "lib\\elementtree\\ElementPath.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nUpdate tags associated with an object.\n\"\"\"\n", "func_signal": "def update_tags(self, obj, tag_names):\n", "code": "ctype = ContentType.objects.get_for_model(obj)\ncurrent_tags = list(self.filter(items__content_type__pk=ctype.pk,\n                                items__object_id=obj.pk))\nupdated_tag_names = parse_tag_input(tag_names)\nif settings.FORCE_LOWERCASE_TAGS:\n    updated_tag_names = [t.lower() for t in updated_tag_names]\n\n# Remove tags which no longer apply\ntags_for_removal = [tag for tag in current_tags \\\n                    if tag.name not in updated_tag_names]\nif len(tags_for_removal):\n    TaggedItem._default_manager.filter(content_type__pk=ctype.pk,\n                                       object_id=obj.pk,\n                                       tag__in=tags_for_removal).delete()\n# Add new tags\ncurrent_tag_names = [tag.name for tag in current_tags]\nfor tag_name in updated_tag_names:\n    if tag_name not in current_tag_names:\n        tag, created = self.get_or_create(name=tag_name)\n        TaggedItem._default_manager.create(tag=tag, object=obj)", "path": "generic\\tagging\\models.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nCreate a ``QuerySet`` containing instances of the specified\nmodel associated with *all* of the given list of tags.\n\"\"\"\n", "func_signal": "def get_intersection_by_model(self, queryset_or_model, tags):\n", "code": "tags = get_tag_list(tags)\ntag_count = len(tags)\nqueryset, model = get_queryset_and_model(queryset_or_model)\n\nif not tag_count:\n    return model._default_manager.none()\n\nmodel_table = qn(model._meta.db_table)\n# This query selects the ids of all objects which have all the\n# given tags.\nquery = \"\"\"\nSELECT %(model_pk)s\nFROM %(model)s, %(tagged_item)s\nWHERE %(tagged_item)s.content_type_id = %(content_type_id)s\n  AND %(tagged_item)s.tag_id IN (%(tag_id_placeholders)s)\n  AND %(model_pk)s = %(tagged_item)s.object_id\nGROUP BY %(model_pk)s\nHAVING COUNT(%(model_pk)s) = %(tag_count)s\"\"\" % {\n    'model_pk': '%s.%s' % (model_table, qn(model._meta.pk.column)),\n    'model': model_table,\n    'tagged_item': qn(self.model._meta.db_table),\n    'content_type_id': ContentType.objects.get_for_model(model).pk,\n    'tag_id_placeholders': ','.join(['%s'] * tag_count),\n    'tag_count': tag_count,\n}\n\ncursor = connection.cursor()\ncursor.execute(query, [tag.pk for tag in tags])\nobject_ids = [row[0] for row in cursor.fetchall()]\nif len(object_ids) > 0:\n    return queryset.filter(pk__in=object_ids)\nelse:\n    return model._default_manager.none()", "path": "generic\\tagging\\models.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nObtain a list of tags associated with instances of a model\ncontained in the given queryset.\n\nIf ``counts`` is True, a ``count`` attribute will be added to\neach tag, indicating how many times it has been used against\nthe Model class in question.\n\nIf ``min_count`` is given, only tags which have a ``count``\ngreater than or equal to ``min_count`` will be returned.\nPassing a value for ``min_count`` implies ``counts=True``.\n\"\"\"\n", "func_signal": "def usage_for_queryset(self, queryset, counts=False, min_count=None):\n", "code": "if parse_lookup:\n    raise AttributeError(\"'TagManager.usage_for_queryset' is not compatible with pre-queryset-refactor versions of Django.\")\n\nextra_joins = ' '.join(queryset.query.get_from_clause()[0][1:])\nwhere, params = queryset.query.where.as_sql()\nif where:\n    extra_criteria = 'AND %s' % where\nelse:\n    extra_criteria = ''\nreturn self._get_usage(queryset.model, counts, min_count, extra_joins, extra_criteria, params)", "path": "generic\\tagging\\models.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nObtain a list of tags related to a given list of tags - that\nis, other tags used by items which have all the given tags.\n\nIf ``counts`` is True, a ``count`` attribute will be added to\neach tag, indicating the number of items which have it in\naddition to the given list of tags.\n\nIf ``min_count`` is given, only tags which have a ``count``\ngreater than or equal to ``min_count`` will be returned.\nPassing a value for ``min_count`` implies ``counts=True``.\n\"\"\"\n", "func_signal": "def related_for_model(self, tags, model, counts=False, min_count=None):\n", "code": "if min_count is not None: counts = True\ntags = get_tag_list(tags)\ntag_count = len(tags)\ntagged_item_table = qn(TaggedItem._meta.db_table)\nquery = \"\"\"\nSELECT %(tag)s.id, %(tag)s.name%(count_sql)s\nFROM %(tagged_item)s INNER JOIN %(tag)s ON %(tagged_item)s.tag_id = %(tag)s.id\nWHERE %(tagged_item)s.content_type_id = %(content_type_id)s\n  AND %(tagged_item)s.object_id IN\n  (\n      SELECT %(tagged_item)s.object_id\n      FROM %(tagged_item)s, %(tag)s\n      WHERE %(tagged_item)s.content_type_id = %(content_type_id)s\n        AND %(tag)s.id = %(tagged_item)s.tag_id\n        AND %(tag)s.id IN (%(tag_id_placeholders)s)\n      GROUP BY %(tagged_item)s.object_id\n      HAVING COUNT(%(tagged_item)s.object_id) = %(tag_count)s\n  )\n  AND %(tag)s.id NOT IN (%(tag_id_placeholders)s)\nGROUP BY %(tag)s.id, %(tag)s.name\n%(min_count_sql)s\nORDER BY %(tag)s.name ASC\"\"\" % {\n    'tag': qn(self.model._meta.db_table),\n    'count_sql': counts and ', COUNT(%s.object_id)' % tagged_item_table or '',\n    'tagged_item': tagged_item_table,\n    'content_type_id': ContentType.objects.get_for_model(model).pk,\n    'tag_id_placeholders': ','.join(['%s'] * tag_count),\n    'tag_count': tag_count,\n    'min_count_sql': min_count is not None and ('HAVING COUNT(%s.object_id) >= %%s' % tagged_item_table) or '',\n}\n\nparams = [tag.pk for tag in tags] * 2\nif min_count is not None:\n    params.append(min_count)\n\ncursor = connection.cursor()\ncursor.execute(query, params)\nrelated = []\nfor row in cursor.fetchall():\n    tag = self.model(*row[:2])\n    if counts is True:\n        tag.count = row[2]\n    related.append(tag)\nreturn related", "path": "generic\\tagging\\models.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nApplies Markdown conversion to a string, and returns the HTML.\n\n\"\"\"\n", "func_signal": "def markdown(text, **kwargs):\n", "code": "import markdown\nreturn markdown.markdown(text, **kwargs)", "path": "generic\\template_utils\\markup.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "# this one should probably be refactored...\n", "func_signal": "def prepare_predicate(next, token):\n", "code": "token = next()\nif token[0] == \"@\":\n    # attribute\n    token = next()\n    if token[0]:\n        raise SyntaxError(\"invalid attribute predicate\")\n    key = token[1]\n    token = next()\n    if token[0] == \"]\":\n        def select(context, result):\n            for elem in result:\n                if elem.get(key) is not None:\n                    yield elem\n    elif token[0] == \"=\":\n        value = next()[0]\n        if value[:1] == \"'\" or value[:1] == '\"':\n            value = value[1:-1]\n        else:\n            raise SyntaxError(\"invalid comparision target\")\n        token = next()\n        def select(context, result):\n            for elem in result:\n                if elem.get(key) == value:\n                    yield elem\n    if token[0] != \"]\":\n        raise SyntaxError(\"invalid attribute predicate\")\nelif not token[0]:\n    tag = token[1]\n    token = next()\n    if token[0] != \"]\":\n        raise SyntaxError(\"invalid node predicate\")\n    def select(context, result):\n        for elem in result:\n            if elem.find(tag) is not None:\n                yield elem\nelse:\n    raise SyntaxError(\"invalid predicate\")\nreturn select", "path": "lib\\elementtree\\ElementPath.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nApplies SmartyPants to a piece of text, applying typographic\nniceties.\n\nRequires the Python SmartyPants library to be installed; see\nhttp://web.chad.org/projects/smartypants.py/\n\n\"\"\"\n", "func_signal": "def smartypants(value):\n", "code": "try:\n    from smartypants import smartyPants\nexcept ImportError:\n    if settings.DEBUG:\n        raise template.TemplateSyntaxError(\"Error in smartypants filter: the Python smartypants module is not installed or could not be imported\")\n    return value\nelse:\n    return smartyPants(value)", "path": "generic\\template_utils\\templatetags\\generic_markup.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nObtain a list of tags associated with instances of the given\nModel class.\n\nIf ``counts`` is True, a ``count`` attribute will be added to\neach tag, indicating how many times it has been used against\nthe Model class in question.\n\nIf ``min_count`` is given, only tags which have a ``count``\ngreater than or equal to ``min_count`` will be returned.\nPassing a value for ``min_count`` implies ``counts=True``.\n\nTo limit the tags (and counts, if specified) returned to those\nused by a subset of the Model's instances, pass a dictionary\nof field lookups to be applied to the given Model as the\n``filters`` argument.\n\"\"\"\n", "func_signal": "def usage_for_model(self, model, counts=False, min_count=None, filters=None):\n", "code": "if filters is None: filters = {}\n\nif not parse_lookup:\n    # post-queryset-refactor (hand off to usage_for_queryset)\n    queryset = model._default_manager.filter()\n    for f in filters.items():\n        queryset.query.add_filter(f)\n    usage = self.usage_for_queryset(queryset, counts, min_count)\nelse:\n    # pre-queryset-refactor\n    extra_joins = ''\n    extra_criteria = ''\n    params = []\n    if len(filters) > 0:\n        joins, where, params = parse_lookup(filters.items(), model._meta)\n        extra_joins = ' '.join(['%s %s AS %s ON %s' % (join_type, table, alias, condition)\n                                for (alias, (table, join_type, condition)) in joins.items()])\n        extra_criteria = 'AND %s' % (' AND '.join(where))\n    usage = self._get_usage(model, counts, min_count, extra_joins, extra_criteria, params)\n\nreturn usage", "path": "generic\\tagging\\models.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nApplies text-to-HTML conversion.\n\nTakes an optional argument to specify the name of a filter to use.\n\n\"\"\"\n", "func_signal": "def apply_markup(value, arg=None):\n", "code": "if arg is not None:\n    return mark_safe(formatter(value, filter_name=arg))\nreturn formatter(value)", "path": "generic\\template_utils\\templatetags\\generic_markup.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nPerform the custom SQL query for ``usage_for_model`` and\n``usage_for_queryset``.\n\"\"\"\n", "func_signal": "def _get_usage(self, model, counts=False, min_count=None, extra_joins=None, extra_criteria=None, params=None):\n", "code": "if min_count is not None: counts = True\n\nmodel_table = qn(model._meta.db_table)\nmodel_pk = '%s.%s' % (model_table, qn(model._meta.pk.column))\nquery = \"\"\"\nSELECT DISTINCT %(tag)s.id, %(tag)s.name%(count_sql)s\nFROM\n    %(tag)s\n    INNER JOIN %(tagged_item)s\n        ON %(tag)s.id = %(tagged_item)s.tag_id\n    INNER JOIN %(model)s\n        ON %(tagged_item)s.object_id = %(model_pk)s\n    %%s\nWHERE %(tagged_item)s.content_type_id = %(content_type_id)s\n    %%s\nGROUP BY %(tag)s.id, %(tag)s.name\n%%s\nORDER BY %(tag)s.name ASC\"\"\" % {\n    'tag': qn(self.model._meta.db_table),\n    'count_sql': counts and (', COUNT(%s)' % model_pk) or '',\n    'tagged_item': qn(TaggedItem._meta.db_table),\n    'model': model_table,\n    'model_pk': model_pk,\n    'content_type_id': ContentType.objects.get_for_model(model).pk,\n}\n\nmin_count_sql = ''\nif min_count is not None:\n    min_count_sql = 'HAVING COUNT(%s) >= %%s' % model_pk\n    params.append(min_count)\n\ncursor = connection.cursor()\ncursor.execute(query % (extra_joins, extra_criteria, min_count_sql), params)\ntags = []\nfor row in cursor.fetchall():\n    t = self.model(*row[:2])\n    if counts:\n        t.count = row[2]\n    tags.append(t)\nreturn tags", "path": "generic\\tagging\\models.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nApplies Textile conversion to a string, and returns the HTML.\n\nThis is simply a pass-through to the ``textile`` template filter\nincluded in ``django.contrib.markup``, which works around issues\nPyTextile has with Unicode strings. If you're not using Django but\nwant to use Textile with ``MarkupFormatter``, you'll need to\nsupply your own Textile filter.\n\n\"\"\"\n", "func_signal": "def textile(text, **kwargs):\n", "code": "from django.contrib.markup.templatetags.markup import textile\nreturn textile(text)", "path": "generic\\template_utils\\markup.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"Completes the authorization with Flickr, and displays the resulting\n   data.\"\"\"\n", "func_signal": "def complete_authorization(request):\n", "code": "check_key(request.GET, 'frob')\ntoken_request = authentication.GetToken({\n    'frob': request.GET['frob'],\n})\nreturn HttpResponse(unicode(token_request.send().decoded))", "path": "photos\\flickr\\views.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nRetrieve a list of instances of the specified model which share\ntags with the model instance ``obj``, ordered by the number of\nshared tags in descending order.\n\nIf ``num`` is given, a maximum of ``num`` instances will be\nreturned.\n\"\"\"\n", "func_signal": "def get_related(self, obj, queryset_or_model, num=None):\n", "code": "queryset, model = get_queryset_and_model(queryset_or_model)\nmodel_table = qn(model._meta.db_table)\ncontent_type = ContentType.objects.get_for_model(obj)\nrelated_content_type = ContentType.objects.get_for_model(model)\nquery = \"\"\"\nSELECT %(model_pk)s, COUNT(related_tagged_item.object_id) AS %(count)s\nFROM %(model)s, %(tagged_item)s, %(tag)s, %(tagged_item)s related_tagged_item\nWHERE %(tagged_item)s.object_id = %%s\n  AND %(tagged_item)s.content_type_id = %(content_type_id)s\n  AND %(tag)s.id = %(tagged_item)s.tag_id\n  AND related_tagged_item.content_type_id = %(related_content_type_id)s\n  AND related_tagged_item.tag_id = %(tagged_item)s.tag_id\n  AND %(model_pk)s = related_tagged_item.object_id\"\"\"\nif content_type.pk == related_content_type.pk:\n    # Exclude the given instance itself if determining related\n    # instances for the same model.\n    query += \"\"\"\n  AND related_tagged_item.object_id != %(tagged_item)s.object_id\"\"\"\nquery += \"\"\"\nGROUP BY %(model_pk)s\nORDER BY %(count)s DESC\n%(limit_offset)s\"\"\"\nquery = query % {\n    'model_pk': '%s.%s' % (model_table, qn(model._meta.pk.column)),\n    'count': qn('count'),\n    'model': model_table,\n    'tagged_item': qn(self.model._meta.db_table),\n    'tag': qn(self.model._meta.get_field('tag').rel.to._meta.db_table),\n    'content_type_id': content_type.pk,\n    'related_content_type_id': related_content_type.pk,\n    'limit_offset': num is not None and connection.ops.limit_offset_sql(num) or '',\n}\n\ncursor = connection.cursor()\ncursor.execute(query, [obj.pk])\nobject_ids = [row[0] for row in cursor.fetchall()]\nif len(object_ids) > 0:\n    # Use in_bulk here instead of an id__in lookup, because id__in would\n    # clobber the ordering.\n    object_dict = queryset.in_bulk(object_ids)\n    return [object_dict[object_id] for object_id in object_ids \\\n            if object_id in object_dict]\nelse:\n    return []", "path": "generic\\tagging\\models.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nCreate a ``QuerySet`` containing instances of the specified\nmodel associated with *any* of the given list of tags.\n\"\"\"\n", "func_signal": "def get_union_by_model(self, queryset_or_model, tags):\n", "code": "tags = get_tag_list(tags)\ntag_count = len(tags)\nqueryset, model = get_queryset_and_model(queryset_or_model)\n\nif not tag_count:\n    return model._default_manager.none()\n\nmodel_table = qn(model._meta.db_table)\n# This query selects the ids of all objects which have any of\n# the given tags.\nquery = \"\"\"\nSELECT %(model_pk)s\nFROM %(model)s, %(tagged_item)s\nWHERE %(tagged_item)s.content_type_id = %(content_type_id)s\n  AND %(tagged_item)s.tag_id IN (%(tag_id_placeholders)s)\n  AND %(model_pk)s = %(tagged_item)s.object_id\nGROUP BY %(model_pk)s\"\"\" % {\n    'model_pk': '%s.%s' % (model_table, qn(model._meta.pk.column)),\n    'model': model_table,\n    'tagged_item': qn(self.model._meta.db_table),\n    'content_type_id': ContentType.objects.get_for_model(model).pk,\n    'tag_id_placeholders': ','.join(['%s'] * tag_count),\n}\n\ncursor = connection.cursor()\ncursor.execute(query, [tag.pk for tag in tags])\nobject_ids = [row[0] for row in cursor.fetchall()]\nif len(object_ids) > 0:\n    return queryset.filter(pk__in=object_ids)\nelse:\n    return model._default_manager.none()", "path": "generic\\tagging\\models.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nApplies reStructuredText conversion to a string, and returns the\nHTML.\n\n\"\"\"\n", "func_signal": "def restructuredtext(text, **kwargs):\n", "code": "from docutils import core\nparts = core.publish_parts(source=text,\n                           writer_name='html4css1',\n                           **kwargs)\nreturn parts['fragment']", "path": "generic\\template_utils\\markup.py", "repo_name": "obeattie/oliver-beattie--version-5", "stars": 3, "license": "None", "language": "python", "size": 2461}
{"docstring": "\"\"\"\nConverts `val` so that it's safe for use in UTF-8 HTML.\n\n    >>> websafe(\"<'&\\\\\">\")\n    '&lt;&#39;&amp;&quot;&gt;'\n    >>> websafe(None)\n    ''\n    >>> websafe(u'\\u203d')\n    '\\\\xe2\\\\x80\\\\xbd'\n\"\"\"\n", "func_signal": "def websafe(val):\n", "code": "if val is None:\n    return ''\nif isinstance(val, unicode):\n    val = val.encode('utf-8')\nval = str(val)\nreturn htmlquote(val)", "path": "web\\net.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"returns True if `port` is a valid IPv4 port\"\"\"\n", "func_signal": "def validipport(port):\n", "code": "try:\n    assert 0 <= int(port) <= 65535\nexcept (AssertionError, ValueError):\n    return False\nreturn True", "path": "web\\net.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "# there are no attrs; collection is nonzero if any element is\n", "func_signal": "def __nonzero__(self):\n", "code": "for element in self.items:\n    if element:\n        return True\nreturn False", "path": "feed\\xe.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"\nReturn True if value is type compatible for assigning to object o.\n\nvalue is compatible with object o when:\n    * both o and value have the exact same type\n    * o is set to None\n    * both o and value are string types\n\"\"\"\n", "func_signal": "def _assign_compatible(o, value):\n", "code": "t_o = type(o)\nt_val = type(value)\n\nreturn t_o is t_val or \\\n        t_o is types.NoneType or \\\n        t_o in types.StringTypes and t_val in types.StringTypes", "path": "feed\\xe.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "# An XMLDeclaration() instance is never empty, so always prints.\n\n", "func_signal": "def _s_tag(self, tfc):\n", "code": "lst_attrs = self.attrs.lst_attrs()\ns_attrs = \" \".join(lst_attrs)\n\ns = \"%s%s %s%s\" % (tfc.s_indent(), \"<?xml\", s_attrs, \"?>\")\n\nreturn s", "path": "feed\\xe.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"\nArguments:\n    root_element -- an ElementItem to hold all the data in the\n            XMLDoc.  Usually this will be a NestElement or\n            Element with lots of ElementItems inside.\n\"\"\"\n", "func_signal": "def __init__(self, root_element=None):\n", "code": "Nest.__init__(self)\n\nself._name = \"XMLDoc\"\n\nself.xml_decl = XMLDeclaration()\nself.top = Collection(DocItem)\n\nif root_element is None:\n    root_element = Comment(\"no root element yet\")\nself.root_element = root_element\n\nself.end = Collection(DocItem)", "path": "feed\\xe.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"\nReplace the current data with the copied data of another block\nnode.\n\"\"\"\n", "func_signal": "def replace(self, node):\n", "code": "assert node.__class__ is Block\nself.lineno = node.lineno\nself.filename = node.filename\nself.name = node.name\nself.body = copy(node.body)", "path": "jinja\\nodes.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"returns True if `address` is a valid IPv4 address\"\"\"\n", "func_signal": "def validipaddr(address):\n", "code": "try:\n    octets = address.split('.')\n    assert len(octets) == 4\n    for x in octets:\n        assert 0 <= int(x) <= 255\nexcept (AssertionError, ValueError):\n    return False\nreturn True", "path": "web\\net.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"\nHandle direct assignment.\n\nSupported types for direct assignment are in self._direct_types\n\"\"\"\n", "func_signal": "def direct(self, value):\n", "code": "assert self._direct_types == \\\n        [self.cust_type, types.NoneType] + list(types.StringTypes)\nassert type(value) in self._direct_types\n\nif value is None:\n    self.value = None\nelif type(value) in types.StringTypes:\n    self.value = self.value_from_s(value)\nelse:\n    self.value = self.check_value(value)", "path": "feed\\xe.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "# A collection exists only as a place to put real elements.\n# There are no start or end tags...\n# When tfc.verbose() is true, we do put an XML comment\n# identifying the collection, and we indent the elements under\n# that comment, to better show the structure.\n\n", "func_signal": "def _s_tag(self, tfc):\n", "code": "if not self.items and not tfc.show_all():\n    return \"\"\n\nlst = []\n\nif tfc.verbose():\n    s = \"%s%s%s%s\" % (tfc.s_indent(), \"<!-- \", self.s_coll(), \" -->\")\n    lst.append(s)\n    tfc = tfc.indent_by(1)\n\nfor element in self.items:\n    s = element._s_tag(tfc)\n    if s:\n        lst.append(s)\n\nreturn tfc.tag_join(lst)", "path": "feed\\xe.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"\nGet all nodes from nodetype in the tree excluding the\nnode passed if `exclude_root` is `True` (default).\n\"\"\"\n", "func_signal": "def get_nodes(nodetype, tree, exclude_root=True):\n", "code": "if exclude_root:\n    todo = tree.get_child_nodes()\nelse:\n    todo = [tree]\nwhile todo:\n    node = todo.pop()\n    if node.__class__ is nodetype:\n        yield node\n    todo.extend(node.get_child_nodes())", "path": "jinja\\nodes.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"\nParses an HTTP date into a datetime object.\n\n    >>> parsehttpdate('Thu, 01 Jan 1970 01:01:01 GMT')\n    datetime.datetime(1970, 1, 1, 1, 1, 1)\n\"\"\"\n", "func_signal": "def parsehttpdate(string_):\n", "code": "try:\n    t = time.strptime(string_, \"%a, %d %b %Y %H:%M:%S %Z\")\nexcept ValueError:\n    return None\nreturn datetime.datetime(*t[:6])", "path": "web\\net.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"\nQuotes a string for use in a URL.\n\n    >>> urlquote('://?f=1&j=1')\n    '%3A//%3Ff%3D1%26j%3D1'\n    >>> urlquote(None)\n    ''\n    >>> urlquote(u'\\u203d')\n    '%E2%80%BD'\n\"\"\"\n", "func_signal": "def urlquote(val):\n", "code": "if val is None: return ''\nif not isinstance(val, unicode): val = str(val)\nelse: val = val.encode('utf-8')\nreturn urllib.quote(val)", "path": "web\\net.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"\nSet the default string used to indent tags.\n\nArguments:\n    s -- string to use as the new tag indent string.\n\nThe default indent is a single tab character.\n\"\"\"\n", "func_signal": "def set_indent_str(s):\n", "code": "global s_indent\nglobal lst_indent\ns_indent = s\nlst_indent = [s_indent*i for i in range(25)]", "path": "feed\\xe.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"\nreturns either (ip_address, port) or \"/path/to/socket\" from string_\n\n    >>> validaddr('/path/to/socket')\n    '/path/to/socket'\n    >>> validaddr('8000')\n    ('0.0.0.0', 8000)\n    >>> validaddr('127.0.0.1')\n    ('127.0.0.1', 8080)\n    >>> validaddr('127.0.0.1:8000')\n    ('127.0.0.1', 8000)\n    >>> validaddr('fff')\n    Traceback (most recent call last):\n        ...\n    ValueError: fff is not a valid IP address/port\n\"\"\"\n", "func_signal": "def validaddr(string_):\n", "code": "if '/' in string_:\n    return string_\nelse:\n    return validip(string_)", "path": "web\\net.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"\nCompare two strings, line by line; return a report on any differences.\n\"\"\"\n", "func_signal": "def diff(s0, s1):\n", "code": "from difflib import ndiff\nlst0 = s0.split(\"\\n\")\nlst1 = s1.split(\"\\n\")\nreport = '\\n'.join(ndiff(lst0, lst1))\nreturn report", "path": "feed\\xe.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"\nReturn an integer describing what level this tag is.\n\nThe root tag of an XML document is level 0; document-level comments\nor other document-level declarations are also level 0.  Tags nested\ninside the root tag are level 1, tags nested inside those tags are\nlevel 2, and so on.\n\nThis is currently only used by the debug_tree() functions.  When\nprinting tags normally, the code that walks the tree keeps track of\nwhat level is current.\n\"\"\"\n", "func_signal": "def level(self):\n", "code": "level = 0\nwhile self._parent != None:\n    self = self._parent\n    if isinstance(self, ElementItem):\n        level += 1\nreturn level", "path": "feed\\xe.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"\nReturn True if XMLDoc is valid.\n\nCurrently doesn't test very much.\n\"\"\"\n# XMLDoc never has parent.  Never change this!\n", "func_signal": "def Validate(self):\n", "code": "assert self._parent == None\nreturn True", "path": "feed\\xe.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"\nReturn a minimal tag string without indentation.\n\nIf the item is empty, and it's not a top-level item (level is\nnot 0), an empty string (\"\") will be returned.  If it is a\ntop-level item, an empty compact tag string will be returned,\nlike this:  <tagname/>\n\"\"\"\n", "func_signal": "def s_tag_terse(self, level=0):\n", "code": "tfc = TFC(level, TFC.mode_terse)\nreturn self._s_tag(tfc)", "path": "feed\\xe.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"\nReturn a string describing the collection.\n\nThe string will be something like:\n\n\"collection of XMLItem with 2 elements.\"\n\"\"\"\n", "func_signal": "def s_coll(self):\n", "code": "name = self.contains.__name__\nn = len(self.items)\nif n == 1:\n    el = \"element\"\nelse:\n    el = \"elements\"\nreturn \"collection of %s with %d %s\" % (name, n, el)", "path": "feed\\xe.py", "repo_name": "codemac/blogit", "stars": 3, "license": "None", "language": "python", "size": 256}
{"docstring": "\"\"\"This takes a given filename; tries to find it in the\nenvironment path; then checks if it is executable.\n\"\"\"\n\n# Special case where filename already contains a path.\n", "func_signal": "def _which (filename):\n", "code": "if os.path.dirname(filename) != '':\n    if os.access (filename, os.X_OK):\n        return filename\n\nif not os.environ.has_key('PATH') or os.environ['PATH'] == '':\n    p = os.defpath\nelse:\n    p = os.environ['PATH']\n\n# Oddly enough this was the one line that made Pexpect\n# incompatible with Python 1.5.2.\n#pathlist = p.split (os.pathsep) \npathlist = string.split (p, os.pathsep)\n\nfor path in pathlist:\n    f = os.path.join(path, filename)\n    if os.access(f, os.X_OK):\n        return f\nreturn None", "path": "pacman\\smart\\util\\pexpect.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "# Include everything that doesn't change locked packages\n", "func_signal": "def includeAll(self, subset):\n", "code": "set = self._changeset.get()\nfor pkg in set.keys():\n    try:\n        self.include(subset, pkg)\n    except Error:\n        pass", "path": "pacman\\smart\\transaction.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "\"\"\"This sends the given signal to the child application.\nIn keeping with UNIX tradition it has a misleading name.\nIt does not necessarily kill the child unless\nyou send the right signal.\n\"\"\"\n# Same as os.kill, but the pid is given for you.\n", "func_signal": "def kill(self, sig):\n", "code": "if self.isalive():\n    os.kill(self.pid, sig)", "path": "pacman\\smart\\util\\pexpect.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "\"\"\"\npretty-print a trace line if it patches the current filter.\nIt accepts format arguments and evaluates them only if needed,\ninstead of having the caller always evaluate its % operator.\n\"\"\"\n", "func_signal": "def trace(self, verbosity, str, args=[], cs=None):\n", "code": "if verbosity <= traceVerbosity and self._depth <= traceDepth:\n    iface.debug(\"%s>     %s\" % (self._tracepath, str % args))\n    if traceVerbosity > 6 and cs is not None:\n        iface.debug(\"--> changeset:\\n%s\" % (cs))", "path": "pacman\\smart\\transaction.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "# Unbounded so we can express \"get me that version whatever it takes\".\n# The +/-0.5 is for up/downgrades with no priority difference.\n", "func_signal": "def _weightReplacement(self, deltapri):\n", "code": "assert(abs(deltapri)>=0.5)\nif deltapri>=0:\n    return -30 - 10*(deltapri-0.5)/priorityScale # (-infty,-30]\nelse:\n    return 1 - 10*(deltapri+0.5)/priorityScale # [1,infty)", "path": "pacman\\smart\\transaction.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "\"\"\"This tests if the child process is running or not.\nThis returns 1 if the child process appears to be running or 0 if not.\nThis also sets the exitstatus attribute.\nIt can take literally SECONDS for Solaris to return the right status.\nThis is the most wiggly part of Pexpect, but I think I've almost got\nit nailed down.\n\"\"\"\n# I can't use signals. Signals on UNIX suck and they\n# mess up Python pipes (setting SIGCHLD to SIGIGNORE).\n\n# If this class was created from an existing file descriptor then\n# I just check to see if the file descriptor is still valid.\n", "func_signal": "def isalive(self):\n", "code": "if self.pid == -1 and not self.__child_fd_owner: \n    try:\n        os.fstat(self.child_fd)\n        return 1\n    except:\n        return 0\n\ntry:\n    pid, status = os.waitpid(self.pid, os.WNOHANG)\nexcept OSError:\n    return 0\n\n# I have to do this twice for Solaris.\n# I can't even believe that I figured this out...\nif pid == 0 and status == 0:\n    try:\n        pid, status = os.waitpid(self.pid, os.WNOHANG)\n        #print 'Solaris sucks'\n    except OSError: # This is crufty. When does this happen?\n        return 0\n    # If pid and status is still 0 after two calls to waitpid() then\n    # the process really is alive. This seems to work on all platforms.\n    if pid == 0 and status == 0:\n        return 1\n\n# I do not OR this together because I want hooks for debugging.\nif os.WIFEXITED (status):\n    self.exitstatus = os.WEXITSTATUS(status)\n    return 0\nelif os.WIFSTOPPED (status):\n    return 0\nelif os.WIFSIGNALED (status):\n    return 0\nelse:\n    return 0 # Can I ever get here?", "path": "pacman\\smart\\util\\pexpect.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "\"\"\"This splits a command line into a list of arguments.\nIt splits arguments on spaces, but handles\nembedded quotes, doublequotes, and escaped characters.\nIt's impossible to do this with a regular expression, so\nI wrote a little state machine to parse the command line.\n\"\"\"\n", "func_signal": "def _split_command_line(command_line):\n", "code": "arg_list = []\narg = ''\nstate_quote = 0\nstate_doublequote = 0\nstate_esc = 0\nfor c in command_line:\n    if c == '\\\\': # Escape the next character\n        state_esc = 1\n    elif c == r\"'\": # Handle single quote\n        if state_esc:\n            state_esc = 0\n        elif not state_quote:\n            state_quote = 1\n        else:\n            state_quote = 0\n    elif c == r'\"': # Handle double quote\n        if state_esc:\n            state_esc = 0\n        elif not state_doublequote:\n            state_doublequote = 1\n        else:\n            state_doublequote = 0\n\n    # Add arg to arg_list unless in some other state.\n    elif c == ' 'and not state_quote and not state_doublequote and not state_esc:\n        arg_list.append(arg)\n        arg = ''\n    else:\n        arg = arg + c\n        if c != '\\\\'and state_esc: # escape mode lasts for one character.\n            state_esc = 0\n\n# Handle last argument.        \nif arg != '':\n    arg_list.append(arg)\nreturn arg_list", "path": "pacman\\smart\\util\\pexpect.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "# xmllib in 2.0 and later provides limited (and slightly broken)\n# support for XML namespaces.\n", "func_signal": "def fixname(name, split=string.split):\n", "code": "if \" \" not in name:\n    return name\nreturn \"{%s}%s\" % tuple(split(name, \" \", 1))", "path": "pacman\\smart\\util\\elementtree\\SimpleXMLTreeBuilder.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "\"\"\"\nThis reads at most size characters from the child application.\nIt includes a timeout. If the read does not complete within the\ntimeout period then a TIMEOUT exception is raised.\nIf the end of file is read then an EOF exception will be raised.\nIf a log file was set using setlog() then all data will\nalso be written to the log file.\n\nNotice that if this method is called with timeout=None \nthen it actually may block.\n\nThis is a non-blocking wrapper around os.read().\nIt uses select.select() to implement a timeout. \n\"\"\"\n\n", "func_signal": "def read_nonblocking (self, size = 1, timeout = None):\n", "code": "if self.child_fd == -1:\n    raise ValueError ('I/O operation on closed file')\n\n# Note that some systems like Solaris don't seem to ever give\n# an EOF when the child dies. In fact, you can still try to read\n# from the child_fd -- it will block forever or until TIMEOUT.\n# For this case, I test isalive() before doing any reading.\n# If isalive() is false, then I pretend that this is the same as EOF.\nif not self.isalive():\n    r, w, e = select.select([self.child_fd], [], [], 0)\n    if not r:\n        self.flag_eof = 1\n        raise EOF ('End Of File (EOF) in read(). Braindead platform.')\n\nr, w, e = select.select([self.child_fd], [], [], timeout)\nif not r:\n    raise TIMEOUT('Timeout exceeded in read().')", "path": "pacman\\smart\\util\\pexpect.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "\"\"\"This gives control of the child process to the interactive user\n(the human at the keyboard).\nKeystrokes are sent to the child process, and the stdout and stderr\noutput of the child process is printed.\nWhen the user types the escape_character this method will stop.\nThe default for escape_character is ^] (ASCII 29).\nThis simply echos the child stdout and child stderr to the real\nstdout and it echos the real stdin to the child stdin.\n\"\"\"\n# Flush the buffer.\n", "func_signal": "def interact(self, escape_character = chr(29)):\n", "code": "self.stdout.write (self.buffer)\nself.buffer = ''\nself.stdout.flush()\nmode = tty.tcgetattr(self.STDIN_FILENO)\ntty.setraw(self.STDIN_FILENO)\ntry:\n    self.__interact_copy(escape_character)\nfinally:\n    tty.tcsetattr(self.STDIN_FILENO, tty.TCSAFLUSH, mode)", "path": "pacman\\smart\\util\\pexpect.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "\"\"\"This is like send(), but it adds a line feed (os.linesep).\nThis returns the number of bytes written.\n\"\"\"\n", "func_signal": "def sendline(self, str=''):\n", "code": "n = self.send(str)\nn = n + self.send (os.linesep)\nreturn n", "path": "pacman\\smart\\util\\pexpect.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "\"\"\"This is used by the interact() method.\n\"\"\"\n", "func_signal": "def __interact_writen(self, fd, data):\n", "code": "while data != '' and self.isalive():\n    n = os.write(fd, data)\n    data = data[n:]", "path": "pacman\\smart\\util\\pexpect.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "\"\"\"This runs a command; waits for it to finish; then returns\n    all output as a string. This is a utility interface around\n    the spawn class.\n\"\"\"\n", "func_signal": "def run (command, args=[], timeout=30):\n", "code": "child = spawn(command, args, timeout)\nchild.expect (EOF)\nreturn child.before", "path": "pacman\\smart\\util\\pexpect.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "\"\"\"This seeks through the stream until a pattern is matched.\nThe pattern is overloaded and may take several types including a list.\nThe pattern can be a StringType, EOF, a compiled re, or\na list of those types. Strings will be compiled to re types.\nThis returns the index into the pattern list. If the pattern was\nnot a list this returns index 0 on a successful match.\nThis may raise exceptions for EOF or TIMEOUT.\nTo avoid the EOF or TIMEOUT exceptions add EOF or TIMEOUT to\nthe pattern list.\n\nAfter a match is found the instance attributes\n'before', 'after' and 'match' will be set.\nYou can see all the data read before the match in 'before'.\nYou can see the data that was matched in 'after'.\nThe re.MatchObject used in the re match will be in 'match'.\nIf an error occured then 'before' will be set to all the\ndata read so far and 'after' and 'match' will be None.\n\nIf timeout is -1 then timeout will be set to the self.timeout value.\n\nNote: A list entry may be EOF or TIMEOUT instead of a string.\nThis will catch these exceptions and return the index\nof the list entry instead of raising the exception.\nThe attribute 'after' will be set to the exception type.\nThe attribute 'match' will be None.\nThis allows you to write code like this:\n        index = p.expect (['good', 'bad', pexpect.EOF, pexpect.TIMEOUT])\n        if index == 0:\n            do_something()\n        elif index == 1:\n            do_something_else()\n        elif index == 2:\n            do_some_other_thing()\n        elif index == 3:\n            do_something_completely_different()\ninstead of code like this:\n        try:\n            index = p.expect (['good', 'bad'])\n            if index == 0:\n                do_something()\n            elif index == 1:\n                do_something_else()\n        except EOF:\n            do_some_other_thing()\n        except TIMEOUT:\n            do_something_completely_different()\nThese two forms are equivalent. It all depends on what you want.\nYou can also just expect the EOF if you are waiting for all output\nof a child to finish. For example:\n        p = pexpect.spawn('/bin/ls')\n        p.expect (pexpect.EOF)\n        print p.before\n\nIf you are trying to optimize for speed then see\nexpect_list() and expect_exact().\n\"\"\"\n", "func_signal": "def expect(self, pattern, timeout = -1):\n", "code": "compiled_pattern_list = self.compile_pattern_list(pattern)\nreturn self.expect_list(compiled_pattern_list, timeout)", "path": "pacman\\smart\\util\\pexpect.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "\"\"\"This is to support iterators over a file-like object.\n\"\"\"\n", "func_signal": "def next (self):\n", "code": "result = self.readline()\nif result == \"\":\n    raise StopIteration\nreturn result", "path": "pacman\\smart\\util\\pexpect.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "\"\"\"This sets the terminal echo mode on or off.\"\"\"\n", "func_signal": "def setecho (self, on):\n", "code": "new = termios.tcgetattr(self.child_fd)\nif on:\n    new[3] = new[3] | termios.ECHO # lflags\nelse:\n    new[3] = new[3] & ~termios.ECHO # lflags\ntermios.tcsetattr(self.child_fd, termios.TCSADRAIN, new)", "path": "pacman\\smart\\util\\pexpect.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "\"\"\"This is used by the interact() method.\n\"\"\"\n", "func_signal": "def __interact_copy(self, escape_character = None):\n", "code": "while self.isalive():\n    r, w, e = select.select([self.child_fd, self.STDIN_FILENO], [], [])\n    if self.child_fd in r:\n        data = self.__interact_read(self.child_fd)\n        os.write(self.STDOUT_FILENO, data)\n    if self.STDIN_FILENO in r:\n        data = self.__interact_read(self.STDIN_FILENO)\n        self.__interact_writen(self.child_fd, data)\n        if escape_character in data:\n            break", "path": "pacman\\smart\\util\\pexpect.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "\"\"\"\nReturn a set of packages which directly or indirectly conflict with pkg.\nWe first construct a set of \"red\" packages, which must be installed if pkg\nis installed. We then identify all \"blue\" packages, which conflict with red\npackages. Then we find the closure of the \"blue\" packages by considering\nunsatisfiable requirements, and return this closure. The result is cached.\n\"\"\"\n\n", "func_signal": "def getProhibits(self, pkg):\n", "code": "if pkg in self._prohibitspkgs:\n    return self._prohibitspkgs[pkg]\n\nreds = self.getNecessitates(pkg)\nreds[pkg] = True\nblues = {}\nbluequeue = []\n\n# Direct conflicts of red packages:\nfor redpkg in reds:\n    for namepkg in self._cache.getPackages(redpkg.name):\n        if (namepkg not in reds and\n            namepkg not in blues and\n            not redpkg.coexists(namepkg)):\n            blues[namepkg] = True\n            bluequeue.append(namepkg)\n    for cnf in redpkg.conflicts:\n        for prv in cnf.providedby:\n            for prvpkg in prv.packages:\n                if prvpkg not in blues and prvpkg not in reds:\n                    blues[prvpkg] = True\n                    bluequeue.append(prvpkg)\n    for prv in redpkg.provides:\n        for cnf in prv.conflictedby:\n            for cnfpkg in cnf.packages:\n                if cnfpkg not in blues and cnfpkg not in reds:\n                    blues[cnfpkg] = True\n                    bluequeue.append(cnfpkg)\n\n# Indirect conflict due to necessary requirements of blue packages:\nwhile bluequeue:\n    bluepkg = bluequeue.pop()\n    # What requires bluepkg?\n    for prv in bluepkg.provides:\n        for req in prv.requiredby:\n            # Does any non-blue package provide that?\n            for prv in req.providedby:\n               for prvpkg in prv.packages:\n                   if prvpkg not in blues:\n                       break # provided by non-blue package\n               else:\n                   continue\n               break\n            else: # all providing packages are blue\n                for reqpkg in req.packages:\n                    if reqpkg not in blues and reqpkg not in reds:\n                        blues[reqpkg] = True\n                        bluequeue.append(reqpkg)\n\nself._prohibitspkgs[pkg] = blues\nif traceVerbosity >= 7:\n    iface.debug(\"# getProhibits(%s) -> %s\" %\n                (pkg, sorted(blues.keys())))\nreturn blues", "path": "pacman\\smart\\transaction.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "# Give priority to local files.\n", "func_signal": "def __cmp__(self, other):\n", "code": "rc = -cmp(self.mirror.startswith(\"file://\"),\n          other.mirror.startswith(\"file://\"))\nif rc == 0:\n    # Otherwise, check penality.\n    pen = self._system._penality\n    rc = cmp(pen.get(self.mirror, 0), pen.get(other.mirror, 0))\nreturn rc", "path": "pacman\\smart\\mirror.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "# Exclude everything that doesn't change locked packages\n", "func_signal": "def excludeAll(self, subset):\n", "code": "set = self._changeset.get()\nfor pkg in set.keys():\n    try:\n        self.exclude(subset, pkg)\n    except Error:\n        pass", "path": "pacman\\smart\\transaction.py", "repo_name": "pierrejean-coudert/winlibrepacman", "stars": 2, "license": "None", "language": "python", "size": 694}
{"docstring": "# This is more complicated than svn's GenerateDiff because we must convert\n# the diff output to include an svn-style \"Index:\" line as well as record\n# the hashes of the base files, so we can upload them along with our diff.\n", "func_signal": "def GenerateDiff(self, extra_args):\n", "code": "if self.options.revision:\n  extra_args = [self.options.revision] + extra_args\ngitdiff = RunShell([\"git\", \"diff\", \"--full-index\"] + extra_args)\nsvndiff = []\nfilecount = 0\nfilename = None\nfor line in gitdiff.splitlines():\n  match = re.match(r\"diff --git a/(.*) b/.*$\", line)\n  if match:\n    filecount += 1\n    filename = match.group(1)\n    svndiff.append(\"Index: %s\\n\" % filename)\n  else:\n    # The \"index\" line in a git diff looks like this (long hashes elided):\n    #   index 82c0d44..b2cee3f 100755\n    # We want to save the left hash, as that identifies the base file.\n    match = re.match(r\"index (\\w+)\\.\\.\", line)\n    if match:\n      self.base_hashes[filename] = match.group(1)\n  svndiff.append(line + \"\\n\")\nif not filecount:\n  ErrorExit(\"No valid patches found in output from git diff\")\nreturn \"\".join(svndiff)", "path": "static\\upload.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"The number of 'chunks' in this patch.\n\nA chunk is a block of lines starting with '@@'.\n\nThe value is cached.\n\"\"\"\n", "func_signal": "def num_chunks(self):\n", "code": "if self._num_chunks is None:\n  num = 0\n  for line in self.lines:\n    if line.startswith('@@'):\n      num += 1\n  self._num_chunks = num\nreturn self._num_chunks", "path": "codereview\\models.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"Save the cookie jar after authentication.\"\"\"\n", "func_signal": "def _Authenticate(self):\n", "code": "super(HttpRpcServer, self)._Authenticate()\nif self.save_cookies:\n  StatusUpdate(\"Saving authentication cookies to %s\" % self.cookie_file)\n  self.cookie_jar.save()", "path": "static\\upload.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"Splits a patch into separate pieces for each file.\n\nArgs:\n  data: A string containing the output of svn diff.\n\nReturns:\n  A list of 2-tuple (filename, text) where text is the svn diff output\n    pertaining to filename.\n\"\"\"\n", "func_signal": "def SplitPatch(data):\n", "code": "patches = []\nfilename = None\ndiff = []\nfor line in data.splitlines(True):\n  new_filename = None\n  if line.startswith('Index:'):\n    unused, new_filename = line.split(':', 1)\n    new_filename = new_filename.strip()\n  elif line.startswith('Property changes on:'):\n    unused, temp_filename = line.split(':', 1)\n    # When a file is modified, paths use '/' between directories, however\n    # when a property is modified '\\' is used on Windows.  Make them the same\n    # otherwise the file shows up twice.\n    temp_filename = temp_filename.strip().replace('\\\\', '/')\n    if temp_filename != filename:\n      # File has property changes but no modifications, create a new diff.\n      new_filename = temp_filename\n  if new_filename:\n    if filename and diff:\n      patches.append((filename, ''.join(diff)))\n    filename = new_filename\n    diff = [line]\n    continue\n  if diff is not None:\n    diff.append(line)\nif filename and diff:\n  patches.append((filename, ''.join(diff)))\nreturn patches", "path": "static\\upload.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"The number of draft comments on this patch for the current user.\n\nThe value is expensive to compute, so it is cached.\n\"\"\"\n", "func_signal": "def num_drafts(self):\n", "code": "if self._num_drafts is None:\n  user = Account.current_user_account\n  if user is None:\n    self._num_drafts = 0\n  else:\n    query = gql(Comment,\n                'WHERE patch = :1 AND draft = TRUE AND author = :2',\n                self, account.user)\n    self._num_drafts = query.count()\nreturn self._num_drafts", "path": "codereview\\models.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"Return a list of files unknown to the VCS.\"\"\"\n", "func_signal": "def GetUnknownFiles(self):\n", "code": "raise NotImplementedError(\n    \"abstract method -- subclass %s must override\" % self.__class__)", "path": "static\\upload.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"Update the user's draft status for this issue.\n\nArgs:\n  issue: an Issue instance.\n  have_drafts: optional bool forcing the draft status.  By default,\n      issue.num_drafts is inspected (which may query the datastore).\n\nThe Account is written to the datastore if necessary.\n\"\"\"\n", "func_signal": "def update_drafts(self, issue, have_drafts=None):\n", "code": "dirty = False\nif self._drafts is None:\n  dirty = self._initialize_drafts()\nid = issue.key().id()\nif have_drafts is None:\n  have_drafts = bool(issue.num_drafts)  # Beware, this may do a query.\nif have_drafts:\n  if id not in self._drafts:\n    self._drafts.append(id)\n    dirty = True\nelse:\n  if id in self._drafts:\n    self._drafts.remove(id)\n    dirty = True\nif dirty:\n  self._save_drafts()", "path": "codereview\\models.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"The property changes split into lines.\n\nThe value is cached.\n\"\"\"\n", "func_signal": "def property_changes(self):\n", "code": "if self._property_changes != None:\n  return self._property_changes\nself._property_changes = []\nmatch = re.search('^Property changes on.*\\n'+'_'*67+'$', self.text,\n                  re.MULTILINE)\nif match:\n  self._property_changes = self.text[match.end():].splitlines()\nreturn self._property_changes", "path": "codereview\\models.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"Return True if the user picked the nickname.\n\nNormally this returns 'not self.fresh', but if that property is\nNone, we assume that if the created and modified timestamp are\nwithin 2 seconds, the account is fresh (i.e. the user hasn't\nselected a nickname yet).  We then also update self.fresh, so it\nis used as a cache and may even be written back if we're lucky.\n\"\"\"\n", "func_signal": "def user_has_selected_nickname(self):\n", "code": "if self.fresh is None:\n  delta = self.created - self.modified\n  # Simulate delta = abs(delta)\n  if delta.days < 0:\n    delta = -delta\n  self.fresh = (delta.days == 0 and delta.seconds < 2)\nreturn not self.fresh", "path": "codereview\\models.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"Get the list of Accounts that have this nickname.\"\"\"\n", "func_signal": "def get_accounts_for_nickname(cls, nickname):\n", "code": "assert nickname\nassert '@' not in nickname\nreturn list(gql(cls, 'WHERE nickname = :1', nickname))", "path": "codereview\\models.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"The text split into lines, retaining line endings.\"\"\"\n", "func_signal": "def lines(self):\n", "code": "if not self.text:\n  return []\nreturn self.text.splitlines(True)", "path": "codereview\\models.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"Get the Account for an email address, or return None.\"\"\"\n", "func_signal": "def get_account_for_email(cls, email):\n", "code": "assert email\nkey = '<%s>' % email\nreturn cls.get_by_key_name(key)", "path": "codereview\\models.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"The number of draft comments on this issue for the current user.\n\nThe value is expensive to compute, so it is cached.\n\"\"\"\n", "func_signal": "def num_drafts(self):\n", "code": "if self._num_drafts is None:\n  account = Account.current_user_account\n  if account is None:\n    self._num_drafts = 0\n  else:\n    query = gql(Comment,\n        'WHERE ANCESTOR IS :1 AND author = :2 AND draft = TRUE',\n        self, account.user)\n    self._num_drafts = query.count()\nreturn self._num_drafts", "path": "codereview\\models.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"Get self.patched_content, computing it if necessary.\n\nThis is the content of the file after applying this patch.\n\nReturns:\n  a Content instance.\n\nRaises:\n  engine.FetchError: If there was a problem fetching the old content.\n\"\"\"\n", "func_signal": "def get_patched_content(self):\n", "code": "try:\n  if self.patched_content is not None:\n    return self.patched_content\nexcept db.Error:\n  # This may happen when a Content entity was deleted behind our back.\n  self.patched_content = None\n\nold_lines = self.get_content().text.splitlines(True)\nlogging.info('Creating patched_content for %s', self.filename)\nchunks = patching.ParsePatchToChunks(self.lines, self.filename)\nnew_lines = []\nfor tag, old, new in patching.PatchChunks(old_lines, chunks):\n  new_lines.extend(new)\ntext = db.Text(''.join(new_lines))\npatched_content = Content(text=text, parent=self)\npatched_content.put()\nself.patched_content = patched_content\nself.put()\nreturn patched_content", "path": "codereview\\models.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"Get the Account for a user, creating a default one if needed.\"\"\"\n", "func_signal": "def get_account_for_user(cls, user):\n", "code": "email = user.email()\nassert email\nkey = '<%s>' % email\n# Since usually the account already exists, first try getting it\n# without the transaction implied by get_or_insert().\naccount = cls.get_by_key_name(key)\nif account is not None:\n  return account\nnickname = user.nickname()\nif '@' in nickname:\n  nickname = nickname.split('@', 1)[0]\nassert nickname\nreturn cls.get_or_insert(key, user=user, email=email, nickname=nickname,\n                         fresh=True)", "path": "codereview\\models.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"Get the content of the upstream version of a file.\n\nReturns:\n  A tuple (base_content, new_content, is_binary, status)\n    base_content: The contents of the base file.\n    new_content: For text files, this is empty.  For binary files, this is\n      the contents of the new file, since the diff output won't contain\n      information to reconstruct the current file.\n    is_binary: True iff the file is binary.\n    status: The status of the file.\n\"\"\"\n\n", "func_signal": "def GetBaseFile(self, filename):\n", "code": "raise NotImplementedError(\n    \"abstract method -- subclass %s must override\" % self.__class__)", "path": "static\\upload.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"Encode form fields for multipart/form-data.\n\nArgs:\n  fields: A sequence of (name, value) elements for regular form fields.\n  files: A sequence of (name, filename, value) elements for data to be\n         uploaded as files.\nReturns:\n  (content_type, body) ready for httplib.HTTP instance.\n\nSource:\n  http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/146306\n\"\"\"\n", "func_signal": "def EncodeMultipartFormData(fields, files):\n", "code": "BOUNDARY = '-M-A-G-I-C---B-O-U-N-D-A-R-Y-'\nCRLF = '\\r\\n'\nlines = []\nfor (key, value) in fields:\n  lines.append('--' + BOUNDARY)\n  lines.append('Content-Disposition: form-data; name=\"%s\"' % key)\n  lines.append('')\n  lines.append(value)\nfor (key, filename, value) in files:\n  lines.append('--' + BOUNDARY)\n  lines.append('Content-Disposition: form-data; name=\"%s\"; filename=\"%s\"' %\n           (key, filename))\n  lines.append('Content-Type: %s' % GetContentType(filename))\n  lines.append('')\n  lines.append(value)\nlines.append('--' + BOUNDARY + '--')\nlines.append('')\nbody = CRLF.join(lines)\ncontent_type = 'multipart/form-data; boundary=%s' % BOUNDARY\nreturn content_type, body", "path": "static\\upload.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"Returns the contents of a file.\"\"\"\n", "func_signal": "def ReadFile(self, filename):\n", "code": "file = open(filename, 'rb')\nresult = \"\"\ntry:\n  result = file.read()\nfinally:\n  file.close()\nreturn result", "path": "static\\upload.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"The patch split into lines, retaining line endings.\n\nThe value is cached.\n\"\"\"\n", "func_signal": "def lines(self):\n", "code": "if self._lines is not None:\n  return self._lines\nif not self.text:\n  lines = []\nelse:\n  lines = self.text.splitlines(True)\nself._lines = lines\nreturn lines", "path": "codereview\\models.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "\"\"\"Helper to compute the number of comments through a query.\"\"\"\n", "func_signal": "def _get_num_comments(self):\n", "code": "return gql(Comment,\n           'WHERE ANCESTOR IS :1 AND draft = FALSE',\n           self).count()", "path": "codereview\\models.py", "repo_name": "kaelog/rietveld", "stars": 2, "license": "apache-2.0", "language": "python", "size": 2952}
{"docstring": "#print \"End tag %s\" % name\n", "func_signal": "def unknown_endtag(self, name):\n", "code": "if self.quoteStack and self.quoteStack[-1] != name:\n    #This is not a real end tag.\n    #print \"</%s> is not real!\" % name\n    self.handle_data('</%s>' % name)\n    return\nself.endData()\nself._popToTag(name)\nif self.quoteStack and self.quoteStack[-1] == name:\n    self.quoteStack.pop()\n    self.literal = (len(self.quoteStack) > 0)", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Changes a MS smart quote character to an XML or HTML\nentity.\"\"\"\n", "func_signal": "def _subMSChar(self, orig):\n", "code": "sub = self.MS_CHARS.get(orig)\nif type(sub) == types.TupleType:\n    if self.smartQuotesTo == 'xml':\n        sub = '&#x%s;' % sub[1]\n    else:\n        sub = '&%s;' % sub[0]\nreturn sub", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"This method routes method call requests to either the SGMLParser\nsuperclass or the Tag superclass, depending on the method name.\"\"\"\n#print \"__getattr__ called on %s.%s\" % (self.__class__, methodName)\n\n", "func_signal": "def __getattr__(self, methodName):\n", "code": "if methodName.find('start_') == 0 or methodName.find('end_') == 0 \\\n       or methodName.find('do_') == 0:\n    return SGMLParser.__getattr__(self, methodName)\nelif methodName.find('__') != 0:\n    return Tag.__getattr__(self, methodName)\nelse:\n    raise AttributeError", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Returns true iff this tag has the same name, the same attributes,\nand the same contents (recursively) as the given tag.\n\nNOTE: right now this will return false if two tags have the\nsame attributes in a different order. Should this be fixed?\"\"\"\n", "func_signal": "def __eq__(self, other):\n", "code": "if not hasattr(other, 'name') or not hasattr(other, 'attrs') or not hasattr(other, 'contents') or self.name != other.name or self.attrs != other.attrs or len(self) != len(other):\n    return False\nfor i in range(0, len(self.contents)):\n    if self.contents[i] != other.contents[i]:\n        return False\nreturn True", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Recursively destroys the contents of this tree.\"\"\"\n", "func_signal": "def decompose(self):\n", "code": "contents = [i for i in self.contents]\nfor i in contents:\n    if isinstance(i, Tag):\n        i.decompose()\n    else:\n        i.extract()\nself.extract()", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Returns the closest parent of this Tag that matches the given\ncriteria.\"\"\"\n# NOTE: We can't use _findOne because findParents takes a different\n# set of arguments.\n", "func_signal": "def findParent(self, name=None, attrs={}, **kwargs):\n", "code": "r = None\nl = self.findParents(name, attrs, 1)\nif l:\n    r = l[0]\nreturn r", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Handle a processing instruction as a ProcessingInstruction\nobject, possibly one with a %SOUP-ENCODING% slot into which an\nencoding will be plugged later.\"\"\"\n", "func_signal": "def handle_pi(self, text):\n", "code": "if text[:3] == \"xml\":\n    text = u\"xml version='1.0' encoding='%SOUP-ENCODING%'\"\nself._toStringSubclass(text, ProcessingInstruction)", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Beautiful Soup can detect a charset included in a META tag,\ntry to convert the document to that charset, and re-parse the\ndocument from the beginning.\"\"\"\n", "func_signal": "def start_meta(self, attrs):\n", "code": "httpEquiv = None\ncontentType = None\ncontentTypeIndex = None\ntagNeedsEncodingSubstitution = False\n\nfor i in range(0, len(attrs)):\n    key, value = attrs[i]\n    key = key.lower()\n    if key == 'http-equiv':\n        httpEquiv = value\n    elif key == 'content':\n        contentType = value\n        contentTypeIndex = i\n\nif httpEquiv and contentType: # It's an interesting meta tag.\n    match = self.CHARSET_RE.search(contentType)\n    if match:\n        if (self.declaredHTMLEncoding is not None or\n            self.originalEncoding == self.fromEncoding):\n            # An HTML encoding was sniffed while converting\n            # the document to Unicode, or an HTML encoding was\n            # sniffed during a previous pass through the\n            # document, or an encoding was specified\n            # explicitly and it worked. Rewrite the meta tag.\n            def rewrite(match):\n                return match.group(1) + \"%SOUP-ENCODING%\"\n            newAttr = self.CHARSET_RE.sub(rewrite, contentType)\n            attrs[contentTypeIndex] = (attrs[contentTypeIndex][0],\n                                       newAttr)\n            tagNeedsEncodingSubstitution = True\n        else:\n            # This is our first pass through the document.\n            # Go through it again with the encoding information.\n            newCharset = match.group(3)\n            if newCharset and newCharset != self.originalEncoding:\n                self.declaredHTMLEncoding = newCharset\n                self._feed(self.declaredHTMLEncoding)\n                raise StopParsing\n            pass\ntag = self.unknown_starttag(\"meta\", attrs)\nif tag and tagNeedsEncodingSubstitution:\n    tag.containsSubstitutions = True", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Returns true iff the given string is the name of a\nself-closing tag according to this parser.\"\"\"\n", "func_signal": "def isSelfClosingTag(self, name):\n", "code": "return self.SELF_CLOSING_TAGS.has_key(name) \\\n       or self.instanceSelfClosingTags.has_key(name)", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Convenience method that works with all 2.x versions of Python\nto determine whether or not something is stringlike.\"\"\"\n", "func_signal": "def isString(s):\n", "code": "try:\n    return isinstance(s, unicode) or isinstance(s, basestring)\nexcept NameError:\n    return isinstance(s, str)", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Adds a certain piece of text to the tree as a NavigableString\nsubclass.\"\"\"\n", "func_signal": "def _toStringSubclass(self, text, subclass):\n", "code": "self.endData()\nself.handle_data(text)\nself.endData(subclass)", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Setting tag[key] sets the value of the 'key' attribute for the\ntag.\"\"\"\n", "func_signal": "def __setitem__(self, key, value):\n", "code": "self._getAttrMap()\nself.attrMap[key] = value\nfound = False\nfor i in range(0, len(self.attrs)):\n    if self.attrs[i][0] == key:\n        self.attrs[i] = (key, value)\n        found = True\nif not found:\n    self.attrs.append((key, value))\nself._getAttrMap()[key] = value", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "#print \"Push\", tag.name\n", "func_signal": "def pushTag(self, tag):\n", "code": "if self.currentTag:\n    self.currentTag.contents.append(tag)\nself.tagStack.append(tag)\nself.currentTag = self.tagStack[-1]", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Turns a list of maps, lists, or scalars into a single map.\nUsed to build the SELF_CLOSING_TAGS, NESTABLE_TAGS, and\nNESTING_RESET_TAGS maps out of lists and partial maps.\"\"\"\n", "func_signal": "def buildTagMap(default, *args):\n", "code": "built = {}\nfor portion in args:\n    if hasattr(portion, 'items'):\n        #It's a map. Merge it.\n        for k,v in portion.items():\n            built[k] = v\n    elif isList(portion):\n        #It's a list. Map each item to the default.\n        for k in portion:\n            built[k] = default\n    else:\n        #It's a scalar. Map it to the default.\n        built[portion] = default\nreturn built", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "# Convert the document to Unicode.\n", "func_signal": "def _feed(self, inDocumentEncoding=None, isHTML=False):\n", "code": "markup = self.markup\nif isinstance(markup, unicode):\n    if not hasattr(self, 'originalEncoding'):\n        self.originalEncoding = None\nelse:\n    dammit = UnicodeDammit\\\n             (markup, [self.fromEncoding, inDocumentEncoding],\n              smartQuotesTo=self.smartQuotesTo, isHTML=isHTML)\n    markup = dammit.unicode\n    self.originalEncoding = dammit.originalEncoding\n    self.declaredHTMLEncoding = dammit.declaredHTMLEncoding\nif markup:\n    if self.markupMassage:\n        if not isList(self.markupMassage):\n            self.markupMassage = self.MARKUP_MASSAGE\n        for fix, m in self.markupMassage:\n            markup = fix.sub(m, markup)\n        # TODO: We get rid of markupMassage so that the\n        # soup object can be deepcopied later on. Some\n        # Python installations can't copy regexes. If anyone\n        # was relying on the existence of markupMassage, this\n        # might cause problems.\n        del(self.markupMassage)\nself.reset()\n\nSGMLParser.feed(self, markup)\n# Close out any unfinished strings and close all the open tags.\nself.endData()\nwhile self.currentTag.name != self.ROOT_TAG_NAME:\n    self.popTag()", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Used in a call to re.sub to replace HTML, XML, and numeric\nentities with the appropriate Unicode characters. If HTML\nentities are being converted, any unrecognized entities are\nescaped.\"\"\"\n", "func_signal": "def _convertEntities(self, match):\n", "code": "x = match.group(1)\nif self.convertHTMLEntities and x in name2codepoint:\n    return unichr(name2codepoint[x])\nelif x in self.XML_ENTITIES_TO_SPECIAL_CHARS:\n    if self.convertXMLEntities:\n        return self.XML_ENTITIES_TO_SPECIAL_CHARS[x]\n    else:\n        return u'&%s;' % x\nelif len(x) > 0 and x[0] == '#':\n    # Handle numeric entities\n    if len(x) > 1 and x[1] == 'x':\n        return unichr(int(x[2:], 16))\n    else:\n        return unichr(int(x[1:]))\n\nelif self.escapeUnrecognizedEntities:\n    return u'&amp;%s;' % x\nelse:\n    return u'&%s;' % x", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"This method fixes a bug in Python's SGMLParser.\"\"\"\n", "func_signal": "def convert_charref(self, name):\n", "code": "try:\n    n = int(name)\nexcept ValueError:\n    return\nif not 0 <= n <= 127 : # ASCII ends at 127, not 255\n    return\nreturn self.convert_codepoint(n)", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Returns the closest sibling to this Tag that matches the\ngiven criteria and appears before this Tag in the document.\"\"\"\n", "func_signal": "def findPreviousSibling(self, name=None, attrs={}, text=None, **kwargs):\n", "code": "return self._findOne(self.findPreviousSiblings, name, attrs, text,\n                     **kwargs)", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Convenience method that works with all 2.x versions of Python\nto determine whether or not something is listlike.\"\"\"\n", "func_signal": "def isList(l):\n", "code": "return hasattr(l, '__iter__') \\\n       or (type(l) in (types.ListType, types.TupleType))", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Destructively rips this element out of the tree.\"\"\"\n", "func_signal": "def extract(self):\n", "code": "if self.parent:\n    try:\n        self.parent.contents.remove(self)\n    except ValueError:\n        pass\n\n#Find the two elements that would be next to each other if\n#this element (and any children) hadn't been parsed. Connect\n#the two.\nlastChild = self._lastRecursiveChild()\nnextElement = lastChild.next\n\nif self.previous:\n    self.previous.next = nextElement\nif nextElement:\n    nextElement.previous = self.previous\nself.previous = None\nlastChild.next = None\n\nself.parent = None\nif self.previousSibling:\n    self.previousSibling.nextSibling = self.nextSibling\nif self.nextSibling:\n    self.nextSibling.previousSibling = self.previousSibling\nself.previousSibling = self.nextSibling = None\nreturn self", "path": "recommend\\BeautifulSoup.py", "repo_name": "yaotti/collective-intelligence", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "'''\n   Writes a complete SimCoal2 template file.\n\n   This joins together get_demography_template and get_chr_template,\n   which are feed into generate_model\n   Please check the three functions for parameters (model from\n     get_demography_template, chrs from get_chr_template and\n     params from generate_model).\n'''\n", "func_signal": "def generate_simcoal_from_template(model, chrs, params, out_dir = '.', tp_dir=None):\n", "code": "stream = open(out_dir + sep + 'tmp.par', 'w')\nget_demography_template(stream, model, tp_dir)\nget_chr_template(stream, chrs)\nstream.close()\npar_stream = open(out_dir + sep + 'tmp.par', 'r')\ngenerate_model(par_stream, model, params, out_dir = out_dir)\npar_stream.close()", "path": "src\\PopGen\\SimCoal\\Template.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "\"\"\"\nTemporary function to print a marker in .geno (e.g. HGDP) format\ndelim = tab or space\n\"\"\"\n", "func_signal": "def to_geno_format(self, delim = ' '):\n", "code": "output = self.name + delim\nfor genotype in self.genotypes:\n    output += ''.join(genotype) + delim", "path": "src\\PopGen\\Gio\\Marker.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "'''Runs a program.\n\n   Real _run_program to be implemented by concrete classes.\n\n   parameters:\n   program String identifying program.\n   parameters List of String parameters.\n   input_files Hash of Input file descriptors.\n\n   returns:\n   Task Id.\n\n   The input_files hash key is the path that is passed\n   to the program. It should always be relative.\n   Value is a stream.\n'''\n", "func_signal": "def run_program(self, program, parameters, input_files):\n", "code": "if self.hooks.has_key(program):\n    self.access_ds.acquire()\n    self.id += 1\n    id = self.id\n    self.access_ds.release()\n    self._run_program(id, self.hooks[program], parameters, input_files)\n    return id", "path": "src\\PopGen\\Async\\__init__.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "\"\"\"feed(self, handle, consumer)\n\nFeed in a FStat unit record for scanning.  handle is a file-like\nobject that contains a FStat record.  consumer is a\nConsumer object that will receive events as the report is scanned.\n\n\"\"\"\n", "func_signal": "def feed(self, handle, consumer):\n", "code": "if isinstance(handle, File.UndoHandle):\n    uhandle = handle\nelse:\n    uhandle = File.UndoHandle(handle)\n\n\nconsumer.start_record()\n\nboot_line = uhandle.readline().rstrip()\npops, num_loci, marker_len, ploidy = map(\n        lambda x: int(x), boot_line.split(' '))\nconsumer.sub_pops(pops)\nconsumer.num_loci(num_loci)\nconsumer.marker_len(marker_len)\nconsumer.ploidy(ploidy)\n\nfor i in range(num_loci): \n    loci_name = uhandle.readline().rstrip()\n    consumer.loci_name(loci_name)\n\nline = uhandle.readline()\nwhile line != '':\n    line = line.rstrip()\n    toks = line.split(' ')\n    consumer.individual(toks[0], toks[1:])\n    line = uhandle.readline()\nconsumer.end_record()", "path": "src\\PopGen\\FStat\\__init__.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "'''Converts to GenePop format.\n'''\n", "func_signal": "def convert_to_genepop(self):\n", "code": "gp = GenePop.Record()\ngp.marker_len = len(str(self.marker_len))\ngp.comment_line = 'Converted from FStat format'\ngp.loci_list = deepcopy(self.loci_list)\ngp.populations = []\nfor mypop in self.populations:\n    indIdx = 1\n    pop = []\n    for indiv in mypop:\n        pop.append((str(indIdx), deepcopy(indiv)))\n        indIdx += 1\n    gp.populations.append(pop)\nreturn gp", "path": "src\\PopGen\\FStat\\__init__.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "\"\"\"Executes LDNe.\n\"\"\"\n", "func_signal": "def run_ldne(self, gen_file, out_file):\n", "code": "in_name = 'in.le'\ninf = open(in_name,'w')\ninf.write(gen_file + \"\\n\")\ninf.write(out_file + \"\\n\")\ninf.close()\nos.system(self.ldne_dir + os.sep + self.bin_name + \n  ' < ' + in_name + ' >/dev/null 2>&1')", "path": "src\\PopGen\\LDNe\\Controller.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "\"\"\"\ncheck if a genotype input is correct (a tuple with two elements)\n\n>>> m = Marker()\n>>> _check_genotype_input(['A', 'C'])\nTraceback (most recent call last):\n    ... \nInvalidGenotype: not a tuple of two elements\n>>> _check_genotype_input(('A'))\nTraceback (most recent call last):\n    ... \nInvalidGenotype: not a tuple of two elements\n>>> _check_genotype_input(('A', 'C'))\n\"\"\"\n", "func_signal": "def _check_genotype_input(genotype):\n", "code": "if not isinstance(genotype, tuple):\n    raise InvalidGenotype('not a tuple of two elements')\nelif len(genotype) != 2:\n    raise InvalidGenotype('not a tuple of two elements')", "path": "src\\PopGen\\Gio\\Marker.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "\"\"\"Removes a locus by name.\n\"\"\"\n", "func_signal": "def remove_locus_by_name(self, name):\n", "code": "for i in range(len(self.loci_list)):\n    if self.loci_list[i] == name:\n        self.remove_locus_by_position(i)\n        return\n#If here than locus not existent... Maybe raise exception?\n#   Although it should be Ok... Just a boolean return, maybe?", "path": "src\\PopGen\\AbstractPopRecord.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "\"\"\"Splits a GP record in a dictionary with 1 pop per entry.\n\n    Given a record with n pops and m loci returns a dictionary\n    of records (key pop_name) where each item is a record\n    with a single pop and m loci.\n\n    Parameters:\n    pop_names - Population names\n\"\"\"\n", "func_signal": "def split_in_pops(self, pop_names):\n", "code": "gp_pops = {}\nfor i in range(len(self.populations)):\n    gp_pop = GenePop.Record()                  # should import GenePop.Record??\n    gp_pop.marker_len = self.marker_len\n    gp_pop.comment_line = self.comment_line\n    gp_pop.loci_list = deepcopy(self.loci_list)\n    gp_pop.populations = [deepcopy(self.populations[i])]\n    gp_pops[pop_names[i]] = gp_pop\nreturn gp_pops", "path": "src\\PopGen\\AbstractPopRecord.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "\"\"\"Parses a handle containing a PED file.\n\"\"\"\n", "func_signal": "def parse(handle):\n", "code": "parser = RecordParser()\nreturn parser.parse(handle)", "path": "src\\PopGen\\Gio\\PedIO.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "\"\"\"Removes a locus by position.\n\"\"\"\n", "func_signal": "def remove_locus_by_position(self, pos):\n", "code": "del self.loci_list[pos]\nfor pop in self.populations:\n    for indiv in pop:\n        name, loci = indiv\n        del loci[pos]", "path": "src\\PopGen\\AbstractPopRecord.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "'''\n    Writes a Simcoal2 loci template part.\n\n    stream - Writable stream.\n    chr    - Chromosome list.\n\n    Current loci list:\n      [(chr_repeats,[(marker, (params))])]\n      chr_repeats --> Number of chromosome repeats\n      marker  --> 'SNP', 'DNA', 'RFLP', 'MICROSAT'\n      params  --> Simcoal2 parameters for markers (list of floats\n        or ints - if to be processed by generate_model)\n'''\n", "func_signal": "def get_chr_template(stream, chrs):\n", "code": "num_chrs = reduce(lambda x, y: x + y[0], chrs, 0)\nstream.write('//Number of independent (unlinked) chromosomes, and \"chromosome structure\" flag:  0 for identical structure across chromosomes, and  1 for different structures on different chromosomes.\\n')\nif len(chrs) > 1 or num_chrs == 1:\n    stream.write(str(num_chrs) + ' 1\\n')\nelse:\n    stream.write(str(num_chrs) + ' 0\\n')\nfor chr in chrs:\n    repeats = chr[0]\n    loci = chr[1]\n    if len(chrs) == 1:\n        _gen_loci(stream, loci)\n    else:\n        for i in range(repeats):\n            _gen_loci(stream, loci)", "path": "src\\PopGen\\SimCoal\\Template.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "\"\"\"\nRepresent the record\n\nexample:\n# put an example here\n\"\"\"\n", "func_signal": "def __str__(self):\n", "code": "rep  = [self.comment_line + '\\n']\nrep.append('\\n'.join(self.loci_list) + '\\n')\nfor pop in self.populations:\n    rep.append('Pop\\n')\n    for indiv in pop:\n        name, markers = indiv\n        rep.append(name)\n        rep.append(',')\n        for marker in markers:\n            rep.append(' ')\n            for al in marker:\n                if al == None:\n                    al = '0'\n                aStr = str(al)\n                while len(aStr) < self.marker_len:\n                    aStr = \"\".join(['0', aStr])\n                rep.append(aStr)\n        rep.append('\\n')\nreturn \"\".join(rep)", "path": "src\\PopGen\\AbstractPopRecord.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "\"\"\"test this module\"\"\"\n", "func_signal": "def _test():\n", "code": "import doctest\ndoctest.testmod()", "path": "src\\PopGen\\Gio\\PedIO.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "''' Returns the results for a certain Id, the info for that Id is\n    forgotten.\n\n    parameters:\n    id Id of the task.\n\n    returns:\n    (return_code, output_files) return code and file access\n    object.\n\n    The output_files hash key is a relative file name, and the value a\n    output stream.\n'''\n", "func_signal": "def get_result(self, id):\n", "code": "self.access_ds.acquire()\nif self.done.has_key(id):\n    returnCode, fileObject = done[id]\n    del done[id]\n    self.access_ds.release()\nelse:\n    self.access_ds.release()\n    return None", "path": "src\\PopGen\\Async\\__init__.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "\"\"\"\nuse this method when adding a genotype.\n\"\"\"\n# should check genotype format here\n", "func_signal": "def add_genotype(self, genotype):\n", "code": "if isinstance(genotype, basestring) and len(genotype) == 2:\n    # genotype is probably a string like 'AA'\n    self.genotypes.append((genotype[0], genotype[1]))", "path": "src\\PopGen\\Gio\\Marker.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "'''Async constructor.\n\n   Initializes the queues, among other things.\n   Of notice, is the access_ds lock for controlling exclusive\n       access to this object.\n'''\n", "func_signal": "def __init__(self):\n", "code": "self.running = {}\nself.waiting = []\nself.done = {}\nself.id = 0\nself.hooks = {}\nself.access_ds = thread.allocate_lock()", "path": "src\\PopGen\\Async\\__init__.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "\"\"\"\nPlease use this method when adding multiple genotypes (e.g. when parsing a file), \ninstead of overwriting Marker.genotypes\n\"\"\"\n", "func_signal": "def add_multiple_genotypes(self, genotypes):\n", "code": "for genotype in genotypes:\n    _check_genotype_input(genotype)\nself.genotypes = genotypes  # avoid calling self.genotype multiple times        \nself._recalculate_freqs()", "path": "src\\PopGen\\Gio\\Marker.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "# should add a check for parameters type (e.g. missing -> should be integer)\n", "func_signal": "def __init__(self, name = None, individuals = None):\n", "code": "if name is None:\n    name = 'Un-named Marker'\nself.name = name\nself.position = \"\"  # should be a 'position' object. For now, just a description (e.g. chromosome 11 pos 23131)\nself.genotypes = [] # list of genotypes object (e.g.: [('A', 'A'), ('G', 'A')] Should be an object\nself.populations = {}       # should define populations. which are the positions in self.genotypes which correspond to populations.\nself.individuals = individuals \nself.individual_count = 0        # Individuals for which the Marker is genotyped\nself.missing_data_count = 0      # Individuals for which data is not available\nself.reference_allele_freq = 0.0 # frequency of the reference allele (the first!)\nself.derived_allele_freq = 0.0   # frequency of the derived allele (the second!)\nself.original_strand = ''        # should be '+' or '-'\nself.references = ''             # gene name, associated diseases, etc..", "path": "src\\PopGen\\Gio\\Marker.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "\"\"\"Parses a handle containing a FStat file.\n\"\"\"\n", "func_signal": "def parse(handle):\n", "code": "parser = RecordParser()\nreturn parser.parse(handle)", "path": "src\\PopGen\\FStat\\__init__.py", "repo_name": "lu78/biopython---popgen", "stars": 2, "license": "None", "language": "python", "size": 316}
{"docstring": "\"\"\"\nReturns a dictionary of fieldname -> infodict for the given table,\nwhere each infodict is in the format:\n    {'primary_key': boolean representing whether it's the primary key,\n     'unique': boolean representing whether it's a unique index}\n\"\"\"\n", "func_signal": "def get_indexes(cursor, table_name):\n", "code": "indexes = {}\nfor info in _table_info(cursor, table_name):\n    indexes[info['name']] = {'primary_key': info['pk'] != 0,\n                             'unique': False}\ncursor.execute('PRAGMA index_list(%s)' % quote_name(table_name))\n# seq, name, unique\nfor index, unique in [(field[1], field[2]) for field in cursor.fetchall()]:\n    if not unique:\n        continue\n    cursor.execute('PRAGMA index_info(%s)' % quote_name(index))\n    info = cursor.fetchall()\n    # Skip indexes across multiple fields\n    if len(info) != 1:\n        continue\n    name = info[0][2] # seqno, cid, name\n    indexes[name]['unique'] = True\nreturn indexes", "path": "thirdparty\\google_appengine\\lib\\django\\django\\db\\backends\\sqlite3\\introspection.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"\nChecks to make sure that the SIN passes a luhn mod-10 checksum\nSee: http://en.wikipedia.org/wiki/Luhn_algorithm\n\"\"\"\n\n", "func_signal": "def luhn_checksum_is_valid(self, number):\n", "code": "sum = 0\nnum_digits = len(number)\noddeven = num_digits & 1\n\nfor count in range(0, num_digits):\n    digit = int(number[count])\n\n    if not (( count & 1 ) ^ oddeven ):\n        digit = digit * 2\n    if digit > 9:\n        digit = digit - 9\n\n    sum = sum + digit\n\nreturn ( (sum % 10) == 0 )", "path": "app\\django\\contrib\\localflavor\\ca\\forms.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"\nA version of shutil.copyfileobj that will not read more than 'size' bytes.\nThis makes it safe from clients sending more than CONTENT_LENGTH bytes of\ndata in the body.\n\"\"\"\n", "func_signal": "def safe_copyfileobj(fsrc, fdst, length=16*1024, size=0):\n", "code": "if not size:\n    return\nwhile size > 0:\n    buf = fsrc.read(min(length, size))\n    if not buf:\n        break\n    fdst.write(buf)\n    size -= len(buf)", "path": "thirdparty\\google_appengine\\lib\\django\\django\\core\\handlers\\wsgi.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"\nRetrieves the specified file from storage, using the optional mixin\nclass to customize what features are available on the File returned.\n\"\"\"\n", "func_signal": "def open(self, name, mode='rb', mixin=None):\n", "code": "file = self._open(name, mode)\nif mixin:\n    # Add the mixin as a parent class of the File returned from storage.\n    file.__class__ = type(mixin.__name__, (mixin, file.__class__), {})\nreturn file", "path": "app\\django\\core\\files\\storage.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "# Since this is called as part of error handling, we need to be very\n# robust against potentially malformed input.\n", "func_signal": "def __repr__(self):\n", "code": "try:\n    get = pformat(self.GET)\nexcept:\n    get = '<could not parse>'\ntry:\n    post = pformat(self.POST)\nexcept:\n    post = '<could not parse>'\ntry:\n    cookies = pformat(self.COOKIES)\nexcept:\n    cookies = '<could not parse>'\ntry:\n    meta = pformat(self.META)\nexcept:\n    meta = '<could not parse>'\nreturn '<WSGIRequest\\nGET:%s,\\nPOST:%s,\\nCOOKIES:%s,\\nMETA:%s>' % \\\n    (get, post, cookies, meta)", "path": "thirdparty\\google_appengine\\lib\\django\\django\\core\\handlers\\wsgi.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"\nA view decorator that adds the specified headers to the Vary header of the\nresponse. Usage:\n\n   @vary_on_headers('Cookie', 'Accept-language')\n   def index(request):\n       ...\n\nNote that the header names are not case-sensitive.\n\"\"\"\n", "func_signal": "def vary_on_headers(*headers):\n", "code": "def decorator(func):\n    def inner_func(*args, **kwargs):\n        response = func(*args, **kwargs)\n        patch_vary_headers(response, headers)\n        return response\n    return inner_func\nreturn decorator", "path": "thirdparty\\google_appengine\\lib\\django\\django\\views\\decorators\\vary.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"\nReturns a filename that's free on the target storage system, and\navailable for new content to be written to.\n\"\"\"\n# If the filename already exists, keep adding an underscore to the name\n# of the file until the filename doesn't exist.\n", "func_signal": "def get_available_name(self, name):\n", "code": "while self.exists(name):\n    try:\n        dot_index = name.rindex('.')\n    except ValueError: # filename has no dot\n        name += '_'\n    else:\n        name = name[:dot_index] + '_' + name[dot_index:]\nreturn name", "path": "app\\django\\core\\files\\storage.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"See base.View.list.\n\"\"\"\n\n", "func_signal": "def listDevelopers(self, request, access_type, page_name=None, params=None):\n", "code": "filter = {'is_developer': True}\n\nreturn self.list(request, access_type, page_name=page_name,\n                 params=params, filter=filter)", "path": "app\\soc\\views\\models\\user.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"\nReturn two independent iterators from a single iterable.\n\nBased on http://www.python.org/doc/2.3.5/lib/itertools-example.html\n\"\"\"\n# Note: Using a dictionary and a list as the default arguments here is\n# deliberate and safe in this instance.\n", "func_signal": "def compat_tee(iterable):\n", "code": "def gen(next, data={}, cnt=[0]):\n    dpop = data.pop\n    for i in itertools.count():\n        if i == cnt[0]:\n            item = data[i] = next()\n            cnt[0] += 1\n        else:\n            item = dpop(i)\n        yield item\nnext = iter(iterable).next\nreturn gen(next), gen(next)", "path": "app\\django\\utils\\itercompat.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"Determines the value of the 'User-agent' header to use for HTTP requests.\n\nReturns:\n  String containing the 'user-agent' header value, which includes the SDK\n  version, the platform information, and the version of Python;\n  e.g., \"remote_api/1.0.1 Darwin/9.2.0 Python/2.5.2\".\n\"\"\"\n", "func_signal": "def GetUserAgent():\n", "code": "product_tokens = []\n\nproduct_tokens.append(\"Google-remote_api/1.0\")\n\nproduct_tokens.append(appengine_rpc.GetPlatformToken())\n\npython_version = \".\".join(str(i) for i in sys.version_info)\nproduct_tokens.append(\"Python/%s\" % python_version)\n\nreturn \" \".join(product_tokens)", "path": "thirdparty\\google_appengine\\google\\appengine\\ext\\remote_api\\remote_api_stub.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"\nA view decorator that adds \"Cookie\" to the Vary header of a response. This\nindicates that a page's contents depends on cookies. Usage:\n\n    @vary_on_cookie\n    def index(request):\n        ...\n\"\"\"\n", "func_signal": "def vary_on_cookie(func):\n", "code": "def inner_func(*args, **kwargs):\n    response = func(*args, **kwargs)\n    patch_vary_headers(response, ('Cookie',))\n    return response\nreturn inner_func", "path": "thirdparty\\google_appengine\\lib\\django\\django\\views\\decorators\\vary.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"Defines the fields and methods required for the base View class\nto provide the user with list, public, create, edit and delete views.\n\nParams:\n  params: a dict with params for this View\n\"\"\"\n\n", "func_signal": "def __init__(self, params=None):\n", "code": "rights = access.Checker(params)\nrights['create'] = ['checkIsDeveloper']\nrights['edit'] = ['checkIsDeveloper']\nrights['delete'] = ['checkIsDeveloper']\nrights['show'] = ['allow']\nrights['list'] = ['checkIsDeveloper']\nrights['list_developers'] = ['checkIsDeveloper']\n\nnew_params = {}\nnew_params['logic'] = soc.logic.models.user.logic\nnew_params['rights'] = rights\n\nnew_params['name'] = \"User\"\n\nnew_params['edit_template'] = 'soc/user/edit.html'\nnew_params['pickable'] = True\nnew_params['cache_pick'] = True\n\nnew_params['sidebar_heading'] = 'Users'\n\nnew_params['extra_dynaexclude'] = ['former_accounts', 'agreed_to_tos',\n    'agreed_to_tos_on', 'status']\nnew_params['create_extra_dynaproperties'] = {\n    'clean_link_id': cleaning.clean_user_not_exist('link_id'),\n    'clean_account': cleaning.clean_user_account_not_in_use('account')}\n\n# recreate the choices for the edit form\nstatus_choices = []\nfor choice in user_logic.getModel().status.choices:\n  status_choices.append((choice, choice))\n\nnew_params['edit_extra_dynaproperties'] = {\n    'link_id': forms.CharField(widget=widgets.ReadOnlyInput(),\n        required=True),\n    'clean_link_id': cleaning.clean_link_id('link_id'),\n    'agreed_to_tos_on': forms.DateTimeField(\n        widget=widgets.ReadOnlyInput(attrs={'disabled':'true'}),\n        required=False),\n    'status': forms.ChoiceField(choices=status_choices),\n    'clean_account': cleaning.clean_user_account('account'),\n    'clean': cleaning.validate_user_edit('link_id', 'account'),\n}\n\npatterns = []\n\npatterns += [(r'^%(url_name)s/(?P<access_type>list_developers)$',\n              'soc.views.models.%(module_name)s.list_developers', \n              \"List Developers\")]\n\nnew_params['extra_django_patterns'] = patterns\n\nnew_params['sidebar_additional'] = [\n    ('/user/list_developers' % new_params,\n     'List Developers', 'list_developers'),]\n\nparams = dicts.merge(params, new_params)\n\nsuper(View, self).__init__(params=params)", "path": "app\\soc\\views\\models\\user.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"Constructs a new RemoteStub that communicates with the specified server.\n\nArgs:\n  server: An instance of a subclass of\n    google.appengine.tools.appengine_rpc.AbstractRpcServer.\n  path: The path to the handler this stub should send requests to.\n\"\"\"\n", "func_signal": "def __init__(self, server, path):\n", "code": "self._server = server\nself._path = path", "path": "thirdparty\\google_appengine\\google\\appengine\\ext\\remote_api\\remote_api_stub.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"Validate a phone number.\n\"\"\"\n", "func_signal": "def clean(self, value):\n", "code": "super(CAPhoneNumberField, self).clean(value)\nif value in EMPTY_VALUES:\n    return u''\nvalue = re.sub('(\\(|\\)|\\s+)', '', smart_unicode(value))\nm = phone_digits_re.search(value)\nif m:\n    return u'%s-%s-%s' % (m.group(1), m.group(2), m.group(3))\nraise ValidationError(self.error_messages['invalid'])", "path": "app\\django\\contrib\\localflavor\\ca\\forms.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"Returns example_text linking to site-wide ToS, or a warning message.\n\"\"\"\n", "func_signal": "def _getToSExampleText(self):\n", "code": "tos_link = redirects.getToSRedirect(site_logic.getSingleton())\n\nif not tos_link:\n  return ('<div class=\"notice\">&nbsp;<i>No site-wide</i> Terms of'\n          ' Service <i>are currently set!</i>&nbsp;</div>')\n\nreturn ('<i>current site-wide <b><a href=%s>Terms of Service</a></b></i>'\n        % tos_link)", "path": "app\\soc\\views\\models\\user.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"\nAll attributes of the spatial backend return False by default.\n\"\"\"\n", "func_signal": "def __getattr__(self, name):\n", "code": "try:\n    return self.__dict__[name]\nexcept KeyError:\n    return False", "path": "app\\django\\contrib\\gis\\db\\backend\\base.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"\nTaken from http://docs.python.org/lib/itertools-functions.html\n\"\"\"\n", "func_signal": "def groupby(iterable, keyfunc=None):\n", "code": "if keyfunc is None:\n    keyfunc = lambda x:x\niterable = iter(iterable)\nl = [iterable.next()]\nlastkey = keyfunc(l[0])\nfor item in iterable:\n    key = keyfunc(item)\n    if key != lastkey:\n        yield lastkey, l\n        lastkey = key\n        l = [item]\n    else:\n        l.append(item)\nyield lastkey, l", "path": "app\\django\\utils\\itercompat.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "# Populates self._post and self._files\n", "func_signal": "def _load_post_and_files(self):\n", "code": "if self.method == 'POST':\n    if self.environ.get('CONTENT_TYPE', '').startswith('multipart'):\n        header_dict = dict([(k, v) for k, v in self.environ.items() if k.startswith('HTTP_')])\n        header_dict['Content-Type'] = self.environ.get('CONTENT_TYPE', '')\n        self._post, self._files = http.parse_file_upload(header_dict, self.raw_post_data)\n    else:\n        self._post, self._files = http.QueryDict(self.raw_post_data), datastructures.MultiValueDict()\nelse:\n    self._post, self._files = http.QueryDict(''), datastructures.MultiValueDict()", "path": "thirdparty\\google_appengine\\lib\\django\\django\\core\\handlers\\wsgi.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"\nDisplays the template validator form, which finds and displays template\nsyntax errors.\n\"\"\"\n# get a dict of {site_id : settings_module} for the validator\n", "func_signal": "def template_validator(request):\n", "code": "settings_modules = {}\nfor mod in settings.ADMIN_FOR:\n    settings_module = __import__(mod, {}, {}, [''])\n    settings_modules[settings_module.SITE_ID] = settings_module\nsite_list = Site.objects.in_bulk(settings_modules.keys()).values()\nif request.POST:\n    form = TemplateValidatorForm(settings_modules, site_list,\n                                 data=request.POST)\n    if form.is_valid():\n        request.user.message_set.create(message='The template is valid.')\nelse:\n    form = TemplateValidatorForm(settings_modules, site_list)\nreturn render_to_response('admin/template_validator.html', {\n    'title': 'Template validator',\n    'form': form,\n}, context_instance=template.RequestContext(request))", "path": "app\\django\\contrib\\admin\\views\\template.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"\nSaves new content to the file specified by name. The content should be a\nproper File object, ready to be read from the beginning.\n\"\"\"\n# Get the proper name for the file, as it will actually be saved.\n", "func_signal": "def save(self, name, content):\n", "code": "if name is None:\n    name = content.name\n\nname = self.get_available_name(name)\nname = self._save(name, content)\n\n# Store filenames with forward slashes, even on Windows\nreturn force_unicode(name.replace('\\\\', '/'))", "path": "app\\django\\core\\files\\storage.py", "repo_name": "jaytoday/gsoc", "stars": 3, "license": "None", "language": "python", "size": 7972}
{"docstring": "\"\"\"NICKLEN capability semantics\"\"\"\n", "func_signal": "def testNicklen(self):\n", "code": "c = scap.ServerCapabilities()\n\n# Default value\nself.assertEquals(c.nicklen, 9)\n\n# Setting no value fails\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'nicklen', '')\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'nicklen', None)\n\n# Setting integer values is cool\nc.nicklen = 3\nself.assertEquals(c.nicklen, 3)\nc.nicklen = 32\nself.assertEquals(c.nicklen, 32)\n\n# Setting garbage values is not cool\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'nicklen', 'bleh')\n\n# Deletion resets default\ndel c.nicklen\nself.assertEquals(c.nicklen, 9)", "path": "pyirc\\server_capabilities_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"EXCEPTS capability semantics\"\"\"\n", "func_signal": "def testExcepts(self):\n", "code": "c = scap.ServerCapabilities()\n\n# No default value\nself.assertEquals(c.excepts, None)\n\n# Set using the default channel flag\nc.excepts = None\nself.assertEquals(c.excepts, 'e')\nc.excepts = ''\nself.assertEquals(c.excepts, 'e')\n\n# Set a custom flag\nc.excepts = 'f'\nself.assertEquals(c.excepts, 'f')\n\n# Set a wonky flag\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'excepts', 'bleh')\n\n# If chanmodes are set, the excepts flag must be an A type\n# chanmode.\nc.chanmodes = 'abf,,,'\nself.assertRaises(\n    scap.CapabilityLogicError, setattr, c, 'excepts', 'e')\nc.excepts = 'a'\nself.assertEquals(c.excepts, 'a')", "path": "pyirc\\server_capabilities_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"CASEMAPPING capability semantics\"\"\"\n", "func_signal": "def testCasemapping(self):\n", "code": "c = scap.ServerCapabilities()\n\n# Default value\nself.assertEquals(c.casemapping, 'ascii')\n\n# Explicitely setting 'ascii'\nc.casemapping = 'ascii'\nself.assertEquals(c.casemapping, 'ascii')\n\n# Setting other valid values. We don't support them, so check\n# that we do raise the appropriate exception.\nself.assertRaises(\n    NotImplementedError, setattr, c, 'casemapping', 'rfc1459')\nself.assertRaises(\n    NotImplementedError, setattr, c, 'casemapping', 'strict-rfc1459')\n\n# Setting invalid values raises a value error.\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'casemapping', 'bleh')\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'casemapping', '')\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'casemapping', None)\n\n# Deleting resets to the default.\ndel c.casemapping\nself.assertEquals(c.casemapping, 'ascii')", "path": "pyirc\\server_capabilities_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"Dispatcher message writing\"\"\"\n# Again with the confusing reverse expectations. Read the\n# expectation setup in reverse order.\n", "func_signal": "def testDispatcherWritesOutput(self):\n", "code": "self._sock_write('h', 1)\nself._sock_write('efgh', 3)\nself._sock_write('defgh', 1)\nself._sock_write('abcdefgh', 3)\nself.dispatcher.output('abcdefgh')\nself.dispatcher.handle_write()\nself.dispatcher.handle_write()\nself.dispatcher.handle_write()\nself.dispatcher.handle_write()", "path": "pyirc\\server_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "# The following are things that asyncore will call on our\n# socket. Since we're going to drive the socket manually\n# without asyncore's help, we just return dummy values to\n# please it.\n", "func_signal": "def setUp(self):\n", "code": "self.sock = Mock()\nself.sock.expects(once()).fileno().will(return_value(1))\nself.sock.expects(once()).setblocking(eq(0))\nself.sock.expects(once()).getpeername()\n\nself.handler = Mock()\nself.handler.expects(once())._handle_connect()\nself.dispatcher = server._ConnectionDispatcher(\n    '', 0, self.handler, ext_sock=self.sock)\n# Asyncore would call this handler on a real connect, but we\n# need to simulate it.\nself.dispatcher.handle_connect()", "path": "pyirc\\server_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"CHANELLEN capability semantics\"\"\"\n", "func_signal": "def testChannellen(self):\n", "code": "c = scap.ServerCapabilities()\n\n# Default value\nself.assertEquals(c.channellen, 200)\n\n# Explicitely setting a new value\nc.channellen = 40\nself.assertEquals(c.channellen, 40)\n\n# Explicitely setting no value\nc.channellen = None\nself.assertEquals(c.channellen, None)\n\n# Setting a non-int value fails\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'channellen', 'bleh')\n\n# Deleting resets to the default.\ndel c.channellen\nself.assertEquals(c.channellen, 200)", "path": "pyirc\\server_capabilities_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"INVEX capability semantics\"\"\"\n", "func_signal": "def testInvex(self):\n", "code": "c = scap.ServerCapabilities()\n\n# No default value\nself.assertEquals(c.invex, None)\n\n# Set using the default channel flag\nc.invex = None\nself.assertEquals(c.invex, 'I')\nc.invex = ''\nself.assertEquals(c.invex, 'I')\n\n# Set a custom flag\nc.invex = 'X'\nself.assertEquals(c.invex, 'X')\n\n# Set a wonky flag\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'invex', 'bleh')\n\n# If chanmodes are set, the invex flag must be an A type\n# chanmode.\nc.chanmodes = 'abX,,,'\nself.assertRaises(\n    scap.CapabilityLogicError, setattr, c, 'invex', 'k')\nc.excepts = 'a'\nself.assertEquals(c.excepts, 'a')", "path": "pyirc\\server_capabilities_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"CHANTYPES capability semantics\"\"\"\n", "func_signal": "def testChantypes(self):\n", "code": "c = scap.ServerCapabilities()\n\n# Default value\nself.assertEquals(c.chantypes, frozenset(['#', '&']))\n\n# Explicitely setting a new value\nc.chantypes = '#&!'\nself.assertEquals(c.chantypes, frozenset(['#', '&', '!']))\n\n# Explicitely setting no value\nc.chantypes = None\nself.assertEquals(c.chantypes, frozenset())\nc.chantypes = ''\nself.assertEquals(c.chantypes, frozenset())\n\n# Setting channel limits restricts what we can do to this\n# field.\nc.chantypes = '#'\nc.chanlimit = '#:5'\nself.assertRaises(scap.CapabilityLogicError, setattr, c, 'chantypes', '&')\n\n# Deleting resets to the default.\ndel c.chantypes\nself.assertEquals(c.chantypes, frozenset(['#', '&']))", "path": "pyirc\\server_capabilities_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"Capability setting helpers\"\"\"\n", "func_signal": "def testCapabilitySetting(self):\n", "code": "c = scap.ServerCapabilities()\n\nc.setCapability('TOPICLEN=42')\nself.assertEquals(c.topiclen, 42)\n\nc.setCapability('INVEX')\nself.assertEquals(c.invex, 'I')\n\nc.setCapability('TOPICLEN=')\nself.assertEquals(c.topiclen, None)\n\nc.setCapabilities('TOPICLEN=42 INVEX=U EXCEPTS')\nself.assertEquals(c.topiclen, 42)\nself.assertEquals(c.invex, 'U')\nself.assertEquals(c.excepts, 'e')\n\n# This one tests ordering: the latter fields depend on the\n# values configured by the former.\nc.setCapabilities('CHANTYPES=@%& CHANLIMIT=@%:42,&:5')\nself.assertEquals(c.chantypes, frozenset(['@', '%', '&']))\nself.assertEquals(c.chanlimit, {frozenset(['@','%']): 42,\n                                frozenset(['&']): 5})\n\nc = scap.ServerCapabilities()\nself.assertRaises(scap.CapabilityLogicError,\n                  c.setCapabilities,\n                  'CHANLIMIT=@%:42,&:5 CHANTYPES=@%&')", "path": "pyirc\\server_capabilities_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"NETWORK capability semantics\"\"\"\n", "func_signal": "def testNetwork(self):\n", "code": "c = scap.ServerCapabilities()\n\n# No default value\nself.assertEquals(c.network, None)\n\n# Setting no value fails\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'network', '')\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'network', None)\n\n# Setting values is cool\nc.network = 'bleh'\nself.assertEquals(c.network, 'bleh')\nc.network = 'freenode'\nself.assertEquals(c.network, 'freenode')\n\n# No deletion\nself.assertRaises(AttributeError, delattr, c, 'network')", "path": "pyirc\\server_capabilities_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"SAFELIST capability semantics\"\"\"\n", "func_signal": "def testSafelist(self):\n", "code": "c = scap.ServerCapabilities()\n\n# Default value\nself.assertEquals(c.safelist, False)\n\n# Assignment of None succeeds (the caller's way of saying\n# \"just the directive, no value\")\nc.safelist = None\nself.assertEquals(c.safelist, True)\n\n# Assignment of other values fails\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'safelist', '')\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'safelist', 'true')\n\n# Deletion reverts to the default\ndel c.safelist\nself.assertEquals(c.safelist, False)", "path": "pyirc\\server_capabilities_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"STATUSMSG capability semantics\"\"\"\n", "func_signal": "def testStatusmsg(self):\n", "code": "c = scap.ServerCapabilities()\n\n# Default value\nself.assertEquals(c.statusmsg, frozenset())\n\n# Assignment to values defined by the default PREFIX is okay\nc.statusmsg = '@+'\nself.assertEquals(c.statusmsg, frozenset(['@', '+']))\nc.statusmsg = '@'\nself.assertEquals(c.statusmsg, frozenset(['@']))\n\n# Assignment of values not defined in PREFIX fails\nself.assertRaises(\n    scap.CapabilityLogicError, setattr, c, 'statusmsg', '%')\n\n# Deletion reverts to the default\ndel c.statusmsg\nself.assertEquals(c.statusmsg, frozenset())\n\n# Altering PREFIX changes the restrictions for STATUSMSG\nc.prefix = '(ohv)$%^'\nc.statusmsg = '$'\nself.assertEquals(c.statusmsg, frozenset(['$']))\nself.assertRaises(\n    scap.CapabilityLogicError, setattr, c, 'statusmsg', '@')", "path": "pyirc\\server_capabilities_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"Set a single capability specified in ISUPPORT format.\n\nExample: TOPICLEN=5\n\"\"\"\n", "func_signal": "def setCapability(self, cap_str):\n", "code": "cap = cap_str.split('=', 1)\nif len(cap) == 1:\n    cap.append(None)\nsetattr(self, cap[0].lower(), cap[1])", "path": "pyirc\\server_capabilities.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"TARGMAX capability semantics\"\"\"\n", "func_signal": "def testTargmax(self):\n", "code": "c = scap.ServerCapabilities()\n\n# Default is no value\nself.assertEquals(c.targmax, {})\n\n# Setting simple values works\nc.targmax = 'PRIVMSG:42'\nself.assertEquals(c.targmax, {'PRIVMSG': 42})\n\nc.targmax = 'PRIVMSG:4,NOTICE:3,KICK:42'\nself.assertEquals(c.targmax,\n                  {'PRIVMSG': 4,\n                   'NOTICE': 3,\n                   'KICK': 42})\n\n# Setting more complex values also works\nc.targmax = 'PRIVMSG:3,NOTICE:,KICK:5'\nself.assertEquals(c.targmax,\n                  {'PRIVMSG': 3,\n                   'NOTICE': 1000,\n                   'KICK': 5})\n\n# Setting None resets to default\nc.targmax = ''\nself.assertEquals(c.targmax, {})\nc.targmax = None\nself.assertEquals(c.targmax, {})\n\n# Setting borked values fails\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'targmax', 'bleh')\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'targmax', 'PRIVMSG:4,bleh')\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'targmax', 'PRIVMSG:4,KICK')", "path": "pyirc\\server_capabilities_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"MAXLIST capability semantics\"\"\"\n", "func_signal": "def testMaxlist(self):\n", "code": "c = scap.ServerCapabilities()\n\n# No default value\nself.assertEquals(c.maxlist, None)\n\n# Set values\nc.maxlist = 'b:100,e:200,I:150'\nself.assertEquals(c.maxlist, {frozenset(['b']): 100,\n                              frozenset(['e']): 200,\n                              frozenset(['I']): 150})\nc.maxlist = 'beI: 42'\nself.assertEquals(c.maxlist, {frozenset(['b', 'e', 'I']): 42})\n\n# Set incorrect values\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'maxlist', None)\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'maxlist', '')\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'maxlist', 'b:bleh')\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'maxlist', '#$(@*@')\n\n# Setting chanmodes should restrict the possible values for\n# maxlist.\nc.chanmodes = 'beI,,,'\nself.assertRaises(\n    scap.CapabilityLogicError, setattr, c, 'maxlist', 'be:100')\nc.maxlist = 'b:100,eI:42'\nself.assertEquals(c.maxlist, {frozenset(['b']): 100,\n                              frozenset(['e', 'I']): 42})\n\n# No deletion possible.\nself.assertRaises(AttributeError, delattr, c, 'maxlist')", "path": "pyirc\\server_capabilities_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"Server connection sequence\"\"\"\n", "func_signal": "def testServerSequence(self):\n", "code": "self.w.expects(once()).encode(eq('NICK'), eq('nick')).will(\n    return_value(1))\nself.w.expects(once()).encode(\n    eq('USER'), eq('user'), eq('0'), eq('*'), eq('foo')).will(\n    return_value(2))\n\nself.d.expects(once()).output(eq(1))\nself.d.expects(once()).output(eq(2))\n\n# We simulate the server event from the dispatcher ourselves.\nself.conn._handle_connect()", "path": "pyirc\\server_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"TOPICLEN capability semantics\"\"\"\n", "func_signal": "def testTopiclen(self):\n", "code": "c = scap.ServerCapabilities()\n\nc = scap.ServerCapabilities()\n\n# No default value\nself.assertEquals(c.topiclen, None)\n\n# Setting no value is cool\nc.topiclen = None\nself.assertEquals(c.topiclen, None)\nc.topiclen = ''\nself.assertEquals(c.topiclen, None)\n\n# Setting integer values is cool\nc.topiclen = 42\nself.assertEquals(c.topiclen, 42)\nc.topiclen = 32\nself.assertEquals(c.topiclen, 32)\n\n# Setting garbage values is not cool\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'topiclen', 'bleh')\n\n# Deletion resets default\ndel c.topiclen\nself.assertEquals(c.topiclen, None)", "path": "pyirc\\server_capabilities_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"MODES capability semantics\"\"\"\n", "func_signal": "def testModes(self):\n", "code": "c = scap.ServerCapabilities()\n\n# Default value\nself.assertEquals(c.modes, 3)\n\n# Setting no value\nc.modes = None\nself.assertEquals(c.modes, None)\nc.modes = ''\nself.assertEquals(c.modes, None)\n\n# Setting an explicit value\nc.modes = '5'\nself.assertEquals(c.modes, 5)\n\n# Setting an invalid value\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'modes', 'bleh')\n\n# Deletion restores default\ndel c.modes\nself.assertEquals(c.modes, 3)", "path": "pyirc\\server_capabilities_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"Decorator function to register a property.\n\nThe contained function should return locals(), after having\ndefined doc, fget, fset and fdel.\n\"\"\"\n", "func_signal": "def _mkproperty(capname, withdel=False):\n", "code": "def dec(func):\n    d = func()\n    if not isinstance(d, dict):\n        raise RuntimeError('A decorated property is missing '\n                           'return locals() !')\n    private_var = '_%s' % capname.lower()\n    if 'fget' not in d:\n        def default_fget(self):\n            return getattr(self, private_var)\n        d['fget'] = default_fget\n    if withdel:\n        def default_fdel(self):\n            delattr(self, private_var)\n        d['fdel'] = default_fdel\n    return property(**d)\nreturn dec", "path": "pyirc\\server_capabilities.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"CHANMODES capability semantics\"\"\"\n", "func_signal": "def testChanmodes(self):\n", "code": "c = scap.ServerCapabilities()\n\n# No default\nself.assertEquals(c.chanmodes, None)\n\n# Setting modes works\nc.chanmodes = 'ab,cd,ef,gh'\nself.assertEquals(c.chanmodes,\n                  {scap.CHANMODE_LIST: frozenset(['a', 'b']),\n                   scap.CHANMODE_PARAM_ALWAYS: frozenset(['c', 'd']),\n                   scap.CHANMODE_PARAM_ADDONLY: frozenset(['e', 'f']),\n                   scap.CHANMODE_NO_PARAM: frozenset(['g', 'h'])})\n\n# Setting no flags for certain types is fine\nc.chanmodes = 'ab,,ef,gh'\nself.assertEquals(c.chanmodes,\n                  {scap.CHANMODE_LIST: frozenset(['a', 'b']),\n                   scap.CHANMODE_PARAM_ALWAYS: frozenset(),\n                   scap.CHANMODE_PARAM_ADDONLY: frozenset(['e', 'f']),\n                   scap.CHANMODE_NO_PARAM: frozenset(['g', 'h'])})\n\n# Setting no flags for all types is also fine\nc.chanmodes = ',,,'\nself.assertEquals(c.chanmodes,\n                  {scap.CHANMODE_LIST: frozenset(),\n                   scap.CHANMODE_PARAM_ALWAYS: frozenset(),\n                   scap.CHANMODE_PARAM_ADDONLY: frozenset(),\n                   scap.CHANMODE_NO_PARAM: frozenset()})\n\n# Setting more than 4 channel types is cool, we ignore what is\n# probably a future extension.\nc.chanmodes = 'ab,cd,ef,gh,i,j,klm'\nself.assertEquals(c.chanmodes,\n                  {scap.CHANMODE_LIST: frozenset(['a', 'b']),\n                   scap.CHANMODE_PARAM_ALWAYS: frozenset(['c', 'd']),\n                   scap.CHANMODE_PARAM_ADDONLY: frozenset(['e', 'f']),\n                   scap.CHANMODE_NO_PARAM: frozenset(['g', 'h'])})\n\n# Setting less than 4 is not cool.\nself.assertRaises(\n    scap.CapabilityValueError, setattr, c, 'chanmodes', 'ab,cd')\n\n# Cannot delete chanmodes\nself.assertRaises(AttributeError, delattr, c, 'chanmodes')\n\n# Check that all caps that depend on chanmodes values get\n# rechecked on change.\nc.excepts = 'a'\nself.assertRaises(\n    scap.CapabilityLogicError, setattr, c, 'chanmodes', ',,,')\nself.assertEquals(c.chanmodes,\n                  {scap.CHANMODE_LIST: frozenset(['a', 'b']),\n                   scap.CHANMODE_PARAM_ALWAYS: frozenset(['c', 'd']),\n                   scap.CHANMODE_PARAM_ADDONLY: frozenset(['e', 'f']),\n                   scap.CHANMODE_NO_PARAM: frozenset(['g', 'h'])})\ndel c.excepts\n\nc.invex = 'b'\nself.assertRaises(\n    scap.CapabilityLogicError, setattr, c, 'chanmodes', ',,,')\nself.assertEquals(c.chanmodes,\n                  {scap.CHANMODE_LIST: frozenset(['a', 'b']),\n                   scap.CHANMODE_PARAM_ALWAYS: frozenset(['c', 'd']),\n                   scap.CHANMODE_PARAM_ADDONLY: frozenset(['e', 'f']),\n                   scap.CHANMODE_NO_PARAM: frozenset(['g', 'h'])})\ndel c.invex\n\nc.maxlist = 'ab:100'\nself.assertRaises(\n    scap.CapabilityLogicError, setattr, c, 'chanmodes', ',,,')\n\nc = scap.ServerCapabilities()\nc.chanmodes = 'ab,cd,ef,gi'\nc.prefix = '(ohv)@%+'\nself.assertRaises(\n    scap.CapabilityLogicError, setattr, c, 'chanmodes', 'ab,cd,ef,gh')", "path": "pyirc\\server_capabilities_test.py", "repo_name": "Screwperman/pyirc", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"Implementation of ^ operator when left operand is not a ParserElement\"\"\"\n", "func_signal": "def __rxor__(self, other ):\n", "code": "if isinstance( other, basestring ):\n    other = Literal( other )\nif not isinstance( other, ParserElement ):\n    warnings.warn(\"Cannot combine element of type %s with ParserElement\" % type(other),\n            SyntaxWarning, stacklevel=2)\n    return None\nreturn other ^ self", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Define action to perform if parsing fails at this expression.\n   Fail acton fn is a callable function that takes the arguments\n   fn(s,loc,expr,err) where:\n    - s = string being parsed\n    - loc = location where expression match was attempted and failed\n    - expr = the parse expression that failed\n    - err = the exception thrown\n   The function returns no value.  It may throw ParseFatalException\n   if it is desired to stop parsing immediately.\"\"\"\n", "func_signal": "def setFailAction( self, fn ):\n", "code": "self.failAction = fn\nreturn self", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Overrides default behavior to expand <TAB>s to spaces before parsing the input string.\n   Must be called before parseString when the input grammar contains elements that\n   match <TAB> characters.\"\"\"\n", "func_signal": "def parseWithTabs( self ):\n", "code": "self.keepTabs = True\nreturn self", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"\n   Defined with the following parameters:\n    - quoteChar - string of one or more characters defining the quote delimiting string\n    - escChar - character to escape quotes, typically backslash (default=None)\n    - escQuote - special quote sequence to escape an embedded quote string (such as SQL's \"\" to escape an embedded \") (default=None)\n    - multiline - boolean indicating whether quotes can span multiple lines (default=False)\n    - unquoteResults - boolean indicating whether the matched text should be unquoted (default=True)\n    - endQuoteChar - string of one or more characters defining the end of the quote delimited string (default=None => same as quoteChar)\n\"\"\"\n", "func_signal": "def __init__( self, quoteChar, escChar=None, escQuote=None, multiline=False, unquoteResults=True, endQuoteChar=None):\n", "code": "super(QuotedString,self).__init__()\n\n# remove white space from quote chars - wont work anyway\nquoteChar = quoteChar.strip()\nif len(quoteChar) == 0:\n    warnings.warn(\"quoteChar cannot be the empty string\",SyntaxWarning,stacklevel=2)\n    raise SyntaxError()\n\nif endQuoteChar is None:\n    endQuoteChar = quoteChar\nelse:\n    endQuoteChar = endQuoteChar.strip()\n    if len(endQuoteChar) == 0:\n        warnings.warn(\"endQuoteChar cannot be the empty string\",SyntaxWarning,stacklevel=2)\n        raise SyntaxError()\n\nself.quoteChar = quoteChar\nself.quoteCharLen = len(quoteChar)\nself.firstQuoteChar = quoteChar[0]\nself.endQuoteChar = endQuoteChar\nself.endQuoteCharLen = len(endQuoteChar)\nself.escChar = escChar\nself.escQuote = escQuote\nself.unquoteResults = unquoteResults\n\nif multiline:\n    self.flags = re.MULTILINE | re.DOTALL\n    self.pattern = r'%s(?:[^%s%s]' % \\\n        ( re.escape(self.quoteChar),\n          _escapeRegexRangeChars(self.endQuoteChar[0]),\n          (escChar is not None and _escapeRegexRangeChars(escChar) or '') )\nelse:\n    self.flags = 0\n    self.pattern = r'%s(?:[^%s\\n\\r%s]' % \\\n        ( re.escape(self.quoteChar),\n          _escapeRegexRangeChars(self.endQuoteChar[0]),\n          (escChar is not None and _escapeRegexRangeChars(escChar) or '') )\nif len(self.endQuoteChar) > 1:\n    self.pattern += (\n        '|(?:' + ')|(?:'.join([\"%s[^%s]\" % (re.escape(self.endQuoteChar[:i]),\n                                       _escapeRegexRangeChars(self.endQuoteChar[i]))\n                            for i in range(len(self.endQuoteChar)-1,0,-1)]) + ')'\n        )\nif escQuote:\n    self.pattern += (r'|(?:%s)' % re.escape(escQuote))\nif escChar:\n    self.pattern += (r'|(?:%s.)' % re.escape(escChar))\n    self.escCharReplacePattern = re.escape(self.escChar)+\"(.)\"\nself.pattern += (r')*%s' % re.escape(self.endQuoteChar))\n\ntry:\n    self.re = re.compile(self.pattern, self.flags)\n    self.reString = self.pattern\nexcept sre_constants.error:\n    warnings.warn(\"invalid pattern (%s) passed to Regex\" % self.pattern,\n        SyntaxWarning, stacklevel=2)\n    raise\n\nself.name = _ustr(self)\nself.errmsg = \"Expected \" + self.name\n#self.myException.msg = self.errmsg\nself.mayIndexError = False\nself.mayReturnEmpty = True", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Reads (and optionally parses) a single line.\"\"\"\n", "func_signal": "def readline(self):\n", "code": "line = self.file.readline()\nif self.grammar and line:\n    try:\n        return self.grammar.parseString(line).asDict()\n    except ParseException:\n        return self.readline()\nelse:\n    return line", "path": "examples\\sparser.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"supported attributes by name are:\n    - lineno - returns the line number of the exception text\n    - col - returns the column number of the exception text\n    - line - returns the line containing the exception text\n\"\"\"\n", "func_signal": "def __getattr__( self, aname ):\n", "code": "if( aname == \"lineno\" ):\n    return lineno( self.loc, self.pstr )\nelif( aname in (\"col\", \"column\") ):\n    return col( self.loc, self.pstr )\nelif( aname == \"line\" ):\n    return line( self.loc, self.pstr )\nelse:\n    raise AttributeError(aname)", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Implementation of + operator - returns And\"\"\"\n", "func_signal": "def __add__(self, other ):\n", "code": "if isinstance( other, basestring ):\n    other = Literal( other )\nif not isinstance( other, ParserElement ):\n    warnings.warn(\"Cannot combine element of type %s with ParserElement\" % type(other),\n            SyntaxWarning, stacklevel=2)\n    return None\nreturn And( [ self, other ] )", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Helper to define a counted list of expressions.\n   This helper defines a pattern of the form::\n       integer expr expr expr...\n   where the leading integer tells how many expr expressions follow.\n   The matched tokens returns the array of expr tokens as a list - the leading count token is suppressed.\n\"\"\"\n", "func_signal": "def countedArray( expr ):\n", "code": "arrayExpr = Forward()\ndef countFieldParseAction(s,l,t):\n    n = int(t[0])\n    arrayExpr << (n and Group(And([expr]*n)) or Group(empty))\n    return []\nreturn ( Word(nums).setName(\"arrayLen\").setParseAction(countFieldParseAction, callDuringTry=True) + arrayExpr )", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Helper parse action to preserve original parsed text,\n   overriding any nested parse actions.\"\"\"\n", "func_signal": "def keepOriginalText(s,startLoc,t):\n", "code": "try:\n    endloc = getTokensEndLoc()\nexcept ParseException:\n    raise ParseFatalException(\"incorrect usage of keepOriginalText - may only be called as a parse action\")\ndel t[:]\nt += ParseResults(s[startLoc:endloc])\nreturn t", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Scan the input string for expression matches.  Each match will return the\n   matching tokens, start location, and end location.  May be called with optional\n   maxMatches argument, to clip scanning after 'n' matches are found.\n\n   Note that the start and end locations are reported relative to the string\n   being parsed.  See L{I{parseString}<parseString>} for more information on parsing\n   strings with embedded tabs.\"\"\"\n", "func_signal": "def scanString( self, instring, maxMatches=_MAX_INT ):\n", "code": "if not self.streamlined:\n    self.streamline()\nfor e in self.ignoreExprs:\n    e.streamline()\n\nif not self.keepTabs:\n    instring = _ustr(instring).expandtabs()\ninstrlen = len(instring)\nloc = 0\npreparseFn = self.preParse\nparseFn = self._parse\nParserElement.resetCache()\nmatches = 0\nwhile loc <= instrlen and matches < maxMatches:\n    try:\n        preloc = preparseFn( instring, loc )\n        nextLoc,tokens = parseFn( instring, preloc, callPreParse=False )\n    except ParseException:\n        loc = preloc+1\n    else:\n        matches += 1\n        yield tokens, preloc, nextLoc\n        loc = nextLoc", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Method to be called from within a parse action to determine the end\n   location of the parsed tokens.\"\"\"\n", "func_signal": "def getTokensEndLoc():\n", "code": "import inspect\nfstack = inspect.stack()\ntry:\n    # search up the stack (through intervening argument normalizers) for correct calling routine\n    for f in fstack[2:]:\n        if f[3] == \"_parseNoCache\":\n            endloc = f[0].f_locals[\"loc\"]\n            return endloc\n    else:\n        raise ParseFatalException(\"incorrect usage of getTokensEndLoc - may only be called from within a parse action\")\nfinally:\n    del fstack", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Define name for this expression, for use in debugging.\"\"\"\n", "func_signal": "def setName( self, name ):\n", "code": "self.name = name\nself.errmsg = \"Expected \" + self.name\nif hasattr(self,\"exception\"):\n    self.exception.msg = self.errmsg\nreturn self", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Send message to stdout.\"\"\"\n", "func_signal": "def msg(txt):\n", "code": "sys.stdout.write(txt)\nsys.stdout.flush()", "path": "examples\\sparser.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Execute the parse expression on the given file or filename.\n   If a filename is specified (instead of a file object),\n   the entire file is opened, read, and closed before parsing.\n\"\"\"\n", "func_signal": "def parseFile( self, file_or_filename ):\n", "code": "try:\n    file_contents = file_or_filename.read()\nexcept AttributeError:\n    f = open(file_or_filename, \"rb\")\n    file_contents = f.read()\n    f.close()\nreturn self.parseString(file_contents)", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Returns named result matching the given key, or if there is no\n   such name, then returns the given defaultValue or None if no\n   defaultValue is specified.\"\"\"\n", "func_signal": "def get(self, key, defaultValue=None):\n", "code": "if key in self:\n    return self[key]\nelse:\n    return defaultValue", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Helper method for defining nested lists enclosed in opening and closing\n   delimiters (\"(\" and \")\" are the default).\n\n   Parameters:\n    - opener - opening character for a nested list (default=\"(\"); can also be a pyparsing expression\n    - closer - closing character for a nested list (default=\")\"); can also be a pyparsing expression\n    - content - expression for items within the nested lists (default=None)\n    - ignoreExpr - expression for ignoring opening and closing delimiters (default=quotedString)\n\n   If an expression is not provided for the content argument, the nested\n   expression will capture all whitespace-delimited content between delimiters\n   as a list of separate values.\n\n   Use the ignoreExpr argument to define expressions that may contain\n   opening or closing characters that should not be treated as opening\n   or closing characters for nesting, such as quotedString or a comment\n   expression.  Specify multiple expressions using an Or or MatchFirst.\n   The default is quotedString, but if no expressions are to be ignored,\n   then pass None for this argument.\n\"\"\"\n", "func_signal": "def nestedExpr(opener=\"(\", closer=\")\", content=None, ignoreExpr=quotedString):\n", "code": "if opener == closer:\n    raise ValueError(\"opening and closing strings cannot be the same\")\nif content is None:\n    if isinstance(opener,basestring) and isinstance(closer,basestring):\n        if ignoreExpr is not None:\n            content = (Combine(OneOrMore(~ignoreExpr +\n                            CharsNotIn(opener+closer+ParserElement.DEFAULT_WHITE_CHARS,exact=1))\n                        ).setParseAction(lambda t:t[0].strip()))\n        else:\n            content = (empty+CharsNotIn(opener+closer+ParserElement.DEFAULT_WHITE_CHARS).setParseAction(lambda t:t[0].strip()))\n    else:\n        raise ValueError(\"opening and closing arguments must be strings if no content expression is given\")\nret = Forward()\nif ignoreExpr is not None:\n    ret << Group( Suppress(opener) + ZeroOrMore( ignoreExpr | ret | content ) + Suppress(closer) )\nelse:\n    ret << Group( Suppress(opener) + ZeroOrMore( ret | content )  + Suppress(closer) )\nreturn ret", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Returns a new copy of a ParseResults object.\"\"\"\n", "func_signal": "def copy( self ):\n", "code": "ret = ParseResults( self.__toklist )\nret.__tokdict = self.__tokdict.copy()\nret.__parent = self.__parent\nret.__accumNames.update( self.__accumNames )\nret.__name = self.__name\nreturn ret", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Define action to perform when successfully matching parse element definition.\n   Parse action fn is a callable method with 0-3 arguments, called as fn(s,loc,toks),\n   fn(loc,toks), fn(toks), or just fn(), where:\n    - s   = the original string being parsed (see note below)\n    - loc = the location of the matching substring\n    - toks = a list of the matched tokens, packaged as a ParseResults object\n   If the functions in fns modify the tokens, they can return them as the return\n   value from fn, and the modified list of tokens will replace the original.\n   Otherwise, fn does not need to return any value.\n\n   Note: the default parsing behavior is to expand tabs in the input string\n   before starting the parsing process.  See L{I{parseString}<parseString>} for more information\n   on parsing strings containing <TAB>s, and suggested methods to maintain a\n   consistent view of the parsed string, the parse location, and line and column\n   positions within the parsed string.\n   \"\"\"\n", "func_signal": "def setParseAction( self, *fns, **kwargs ):\n", "code": "self.parseAction = list(map(self._normalizeParseActionArgs, list(fns)))\nself.callDuringTry = (\"callDuringTry\" in kwargs and kwargs[\"callDuringTry\"])\nreturn self", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Internal helper to construct opening and closing tag expressions, given a tag name\"\"\"\n", "func_signal": "def _makeTags(tagStr, xml):\n", "code": "if isinstance(tagStr,basestring):\n    resname = tagStr\n    tagStr = Keyword(tagStr, caseless=not xml)\nelse:\n    resname = tagStr.name\n\ntagAttrName = Word(alphas,alphanums+\"_-:\")\nif (xml):\n    tagAttrValue = dblQuotedString.copy().setParseAction( removeQuotes )\n    openTag = Suppress(\"<\") + tagStr + \\\n            Dict(ZeroOrMore(Group( tagAttrName + Suppress(\"=\") + tagAttrValue ))) + \\\n            Optional(\"/\",default=[False]).setResultsName(\"empty\").setParseAction(lambda s,l,t:t[0]=='/') + Suppress(\">\")\nelse:\n    printablesLessRAbrack = \"\".join( [ c for c in printables if c not in \">\" ] )\n    tagAttrValue = quotedString.copy().setParseAction( removeQuotes ) | Word(printablesLessRAbrack)\n    openTag = Suppress(\"<\") + tagStr + \\\n            Dict(ZeroOrMore(Group( tagAttrName.setParseAction(downcaseTokens) + \\\n            Optional( Suppress(\"=\") + tagAttrValue ) ))) + \\\n            Optional(\"/\",default=[False]).setResultsName(\"empty\").setParseAction(lambda s,l,t:t[0]=='/') + Suppress(\">\")\ncloseTag = Combine(_L(\"</\") + tagStr + \">\")\n\nopenTag = openTag.setResultsName(\"start\"+\"\".join(resname.replace(\":\",\" \").title().split())).setName(\"<%s>\" % tagStr)\ncloseTag = closeTag.setResultsName(\"end\"+\"\".join(resname.replace(\":\",\" \").title().split())).setName(\"</%s>\" % tagStr)\n\nreturn openTag, closeTag", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Helper to define an expression that is indirectly defined from\n   the tokens matched in a previous expression, that is, it looks\n   for a 'repeat' of a previous expression.  For example::\n       first = Word(nums)\n       second = matchPreviousExpr(first)\n       matchExpr = first + \":\" + second\n   will match \"1:1\", but not \"1:2\".  Because this matches by\n   expressions, will *not* match the leading \"1:1\" in \"1:10\";\n   the expressions are evaluated first, and then compared, so\n   \"1\" is compared with \"10\".\n   Do *not* use with packrat parsing enabled.\n\"\"\"\n", "func_signal": "def matchPreviousExpr(expr):\n", "code": "rep = Forward()\ne2 = expr.copy()\nrep << e2\ndef copyTokenToRepeater(s,l,t):\n    matchTokens = _flatten(t.asList())\n    def mustMatchTheseTokens(s,l,t):\n        theseTokens = _flatten(t.asList())\n        if  theseTokens != matchTokens:\n            raise ParseException(\"\",0,\"\")\n    rep.setParseAction( mustMatchTheseTokens, callDuringTry=True )\nexpr.addParseAction(copyTokenToRepeater, callDuringTry=True)\nreturn rep", "path": "pyparsing.py", "repo_name": "chrisdew/pyparsing-autocomplete", "stars": 3, "license": "mit", "language": "python", "size": 812}
{"docstring": "\"\"\"Choose font size for poll answers.\n\nchoice -- integer to choose an answer.\n\nreturns font size as integer.\n\"\"\"\n", "func_signal": "def _size_answer_text(self, choice):\n", "code": "text =  self._poll.options[choice]\nif len(text) <= 16:\n    text_size = 12\nelif len(text) <= 18:\n    text_size = 11\nelif len(text) <= 20:\n    text_size = 10\nelif len(text) <= 22:\n    text_size = 9\nelif len(text) <= 25:\n    text_size = 8\nelif len(text) <= 29:\n    text_size = 7\nelif len(text) <= 33:\n    text_size = 6\nelse:\n    text_size = 5\nreturn text_size", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Register a vote\n\nTake the selected option from self.current_vote\nand increment the poll_data.\n\"\"\"\n", "func_signal": "def _button_vote_cb(self, button):\n", "code": "if self.current_vote is not None:\n    if self._poll.vote_count >= self._poll.maxvoters:\n        self._logger.debug(\n            'Hit the max voters, ignoring this vote.')\n        return\n    self._logger.debug('Voted '+str(self.current_vote))\n    self._has_voted = True\n    try:\n        self._poll.register_vote(self.current_vote, self.nick_sha1)\n    except OverflowError:\n        self._logger.debug('Local vote failed: '\n            'maximum votes already registered.')\n    except ValueError:\n        self._logger.debug('Local vote failed: '\n            'poll closed.')\n    self._logger.debug('Results: '+str(self._poll.data))\n    self.draw_poll_details_box()", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Implement reading from journal\n\nThis is called within sugar.activity.Activity code\nwhich provides file_path.\n\"\"\"\n", "func_signal": "def read_file(self, file_path):\n", "code": "self._logger.debug('Reading file from datastore via Journal: %s' %\n                   file_path)\nself._polls = set()\nf = open(file_path, 'r')\nnum_polls = cPickle.load(f)\nfor p in range(num_polls):\n    title = cPickle.load(f)\n    author = cPickle.load(f)\n    active = cPickle.load(f)\n    createdate_i = cPickle.load(f)\n    maxvoters = cPickle.load(f)\n    question = cPickle.load(f)\n    number_of_options = cPickle.load(f)\n    options = cPickle.load(f)\n    data = cPickle.load(f)\n    votes = cPickle.load(f)\n    poll = Poll(self, title, author, active, \n                date.fromordinal(int(createdate_i)),\n                maxvoters, question, number_of_options, options,\n                data, votes)\n    self._polls.add(poll)\nf.close()", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Callback for when we have a Tube.\"\"\"\n", "func_signal": "def _new_tube_cb(self, id, initiator, type, service, params, state):\n", "code": "self._logger.debug('New tube: ID=%d initator=%d type=%d service=%s '\n             'params=%r state=%d', id, initiator, type, service,\n             params, state)\n\nif (type == telepathy.TUBE_TYPE_DBUS and\n    service == SERVICE):\n    if state == telepathy.TUBE_STATE_LOCAL_PENDING:\n        self.tubes_chan[telepathy.CHANNEL_TYPE_TUBES].AcceptDBusTube(id)\n\n    tube_conn = TubeConnection(self.conn,\n        self.tubes_chan[telepathy.CHANNEL_TYPE_TUBES],\n        id, group_iface=self.text_chan[telepathy.CHANNEL_INTERFACE_GROUP])\n    self.poll_session = PollSession(tube_conn, self.initiating, self._get_buddy, self)", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Show Choose a Poll canvas\"\"\"\n", "func_signal": "def button_select_clicked(self, button):\n", "code": "self._canvas.set_root(self._select_canvas())\nself.show_all()", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Render topbox.\n\nlesson_return is the view we want to return to from\nlesson plan if the lesson plan button is clicked.\n\"\"\"\n", "func_signal": "def _canvas_topbox(self, lesson_return=None):\n", "code": "topbox = hippo.CanvasBox(\n    background_color=style.Color(LIGHT_GREEN).get_int(),\n    orientation=hippo.ORIENTATION_HORIZONTAL)\ntopbox.append(hippo.CanvasWidget(widget=self._logo()))\nlanguageselectbox = self._canvas_language_select_box()\ntopbox.append(languageselectbox, hippo.PACK_EXPAND)\nlessonplanbox = self._canvas_lessonplanbox(lesson_return)\ntopbox.append(lessonplanbox, hippo.PACK_EXPAND)\nreturn topbox", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Show the select canvas where children choose an existing poll.\"\"\"\n", "func_signal": "def _select_canvas(self):\n", "code": "self._current_view = 'select'\ncanvasbox = self._canvas_root()\n\n# pollbuilderbox is centered within canvasbox\npollbuilderbox = self._canvas_pollbuilder_box()\ncanvasbox.append(pollbuilderbox)\n\npollbuilderbox.append(self._canvas_topbox())\n\nmainbox = self._canvas_mainbox()\npollbuilderbox.append(mainbox)\n\nmainbox.append(self._text_mainbox(_('Choose a Poll')))\n\npoll_details_box = hippo.CanvasBox(spacing=8,\n    background_color=style.COLOR_WHITE.get_int(),\n    border=4,\n    box_height=500,\n    border_color=style.Color(PINK).get_int(),  # XXXX\n    padding=20,\n    xalign=hippo.ALIGNMENT_START,\n    orientation=hippo.ORIENTATION_VERTICAL)\nmainbox.append(poll_details_box)\n\n# add scroll window\nscrolledwindow = hippo.CanvasScrollbars()\nscrolledwindow.set_policy(\n    hippo.ORIENTATION_HORIZONTAL, hippo.SCROLLBAR_NEVER)\n\npoll_selector_box = hippo.CanvasBox(\n    orientation=hippo.ORIENTATION_VERTICAL)\nscrolledwindow.set_root(poll_selector_box)\npoll_details_box.append(scrolledwindow,\n                        hippo.PACK_EXPAND)\n\nrow_number = 0\nfor poll in self._polls:\n    sha = poll.sha\n    if row_number % 2:\n        row_bgcolor=style.COLOR_WHITE.get_int()\n    else:\n        row_bgcolor=style.COLOR_SELECTION_GREY.get_int()\n    row_number += 1\n    poll_row = hippo.CanvasBox(\n        padding_top=4, padding_bottom=4,\n        background_color=row_bgcolor,\n        orientation=hippo.ORIENTATION_HORIZONTAL)\n    poll_selector_box.append(poll_row)\n\n    sized_box = hippo.CanvasBox(\n        box_width=600,\n        orientation=hippo.ORIENTATION_HORIZONTAL)\n    poll_row.append(sized_box)\n    title = hippo.CanvasText(\n        text=poll.title+' ('+poll.author+')',\n        xalign=hippo.ALIGNMENT_START,\n        color=style.Color(DARK_GREEN).get_int(),\n        font_desc = pango.FontDescription('Sans 10'))\n    sized_box.append(title)\n\n    sized_box = hippo.CanvasBox(\n        box_width=180,\n        orientation=hippo.ORIENTATION_HORIZONTAL)\n    poll_row.append(sized_box)\n    if poll.active:\n        button = gtk.Button(_('VOTE'))\n    else:\n        button = gtk.Button(_('SEE RESULTS'))\n    button.connect('clicked', self._select_poll_button_cb, sha)\n    sized_box.append(hippo.CanvasWidget(widget=theme_button(button)))\n\n    sized_box = hippo.CanvasBox(\n        box_width=150,\n        orientation=hippo.ORIENTATION_HORIZONTAL)\n    poll_row.append(sized_box)\n    if poll.author == self._pservice.get_owner().props.nick:\n        button = gtk.Button(_('DELETE'))\n        button.connect('clicked', self._delete_poll_button_cb, sha)\n        sized_box.append(hippo.CanvasWidget(widget=theme_button(button)))\n    poll_row.append(hippo.CanvasText(\n        text=poll.createdate.strftime('%d/%m/%y'),\n        color=style.Color(DARK_GREEN).get_int()))\n\nbutton_box = self._canvas_buttonbox(button_to_highlight=2)\nmainbox.append(button_box, hippo.PACK_END)\n\nreturn canvasbox", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Create a Notebook widget for displaying lesson plans in tabs.\n\nbasepath -- string, path of directory containing lesson plans.\n\"\"\"\n", "func_signal": "def __init__ (self, basepath):\n", "code": "super(LessonPlanWidget, self).__init__()\nlessons = filter(lambda x: os.path.isdir(os.path.join(basepath,\n                                                      'lessons', x)),\n                 os.listdir(os.path.join(basepath, 'lessons')))\nlessons.sort()\nfor lesson in lessons:\n    self._load_lesson(os.path.join(basepath, 'lessons', lesson),\n                      _(lesson))", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Initialize the poll state.\"\"\"\n", "func_signal": "def _make_blank_poll(self):\n", "code": "self._poll = Poll(activity=self)\nself.current_vote = None", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"CanvasBox definition for lang select box.\n\nCalled from _poll_canvas, _select_canvas, _build_canvas\n\"\"\"\n", "func_signal": "def _canvas_language_select_box(self):\n", "code": "languageselectbox = hippo.CanvasBox(\n    background_color=style.Color(LIGHT_GREEN).get_int(),\n    border_top=4, border_left=4,\n    border_color=style.Color(YELLOW).get_int(),\n    padding_top=12, padding_bottom=12,\n    padding_left=100, padding_right=100,\n    orientation=hippo.ORIENTATION_VERTICAL)\nbutton = LanguageComboBox()\nbutton.install()\nlanguageselectbox.append(hippo.CanvasWidget(widget=theme_button(button)))\nreturn languageselectbox", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Return the total votes cast.\"\"\"\n", "func_signal": "def vote_count(self):\n", "code": "total = 0\nfor choice in self.options.keys():\n    total += self.data[choice]\nreturn total", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Preview button clicked.\"\"\"\n# Validate data\n", "func_signal": "def _button_preview_cb(self, button, data=None):\n", "code": "failed_items = self._validate()\nif failed_items:\n    self._canvas.set_root(self._build_canvas(highlight=failed_items))\n    self.show_all()\n    return\n# Data OK\nself._poll.active = True  # Show radio buttons\nself._previewing = True\nself._canvas.set_root(self._poll_canvas())\nself.show_all()", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Delete a poll, either by passing sha or the actual poll object.\n\nsha -- string, sha property of the poll\npoll -- Poll\n\"\"\"\n", "func_signal": "def delete_poll(self, sha=None, poll=None):\n", "code": "if poll:\n    if self._poll == poll:\n        self._make_blank_poll\n    self._polls.remove(poll)\nif sha:\n    if self._poll.sha == sha:\n        self._logger.debug('delete_poll: removing current poll')\n        self._make_blank_poll()\n    for poll in self._polls.copy():\n        if poll.sha == sha:\n            self._polls.remove(poll)", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Get a Buddy from a channel specific handle.\"\"\"\n", "func_signal": "def _get_buddy(self, cs_handle):\n", "code": "self._logger.debug('Trying to find owner of handle %u...', cs_handle)\ngroup = self.text_chan[telepathy.CHANNEL_INTERFACE_GROUP]\nmy_csh = group.GetSelfHandle()\nself._logger.debug('My handle in that group is %u', my_csh)\nif my_csh == cs_handle:\n    handle = self.conn.GetSelfHandle()\n    self._logger.debug('CS handle %u belongs to me, %u', cs_handle, handle)\nelif group.GetGroupFlags() & telepathy.CHANNEL_GROUP_FLAG_CHANNEL_SPECIFIC_HANDLES:\n    handle = group.GetHandleOwners([cs_handle])[0]\n    self._logger.debug('CS handle %u belongs to %u', cs_handle, handle)\nelse:\n    handle = cs_handle\n    self._logger.debug('non-CS handle %u belongs to itself', handle)\n    assert handle != 0\nreturn self.pservice.get_buddy_by_telepathy_handle(\n    self.conn.service_name, self.conn.object_path, handle)", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Show Build a Poll canvas.\n\"\"\"\n# Reset vote data to 0\n", "func_signal": "def button_new_clicked(self, button):\n", "code": "self._make_blank_poll()\nowner = self._pservice.get_owner()\nself._poll.author = owner.props.nick\nself._poll.active = False\nself._canvas.set_root(self._build_canvas())\nself.show_all()", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Lesson Plan button clicked.\"\"\"\n", "func_signal": "def _button_lessonplan_cb(self, button):\n", "code": "self._logger.debug('%s -> Lesson Plan' % self._current_view)\nself._canvas.set_root(self._lessonplan_canvas())\nself.show_all()", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Go back from preview to edit\"\"\"\n", "func_signal": "def button_edit_clicked(self, button):\n", "code": "self._canvas.set_root(self._build_canvas())\nself.show_all()", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"A VOTE or SEE RESULTS button was clicked.\"\"\"\n", "func_signal": "def _select_poll_button_cb(self, button, sha=None):\n", "code": "if not sha:\n    self._logger.debug('Strange, which button was clicked?')\n    return\nself._switch_to_poll(sha)\nself._has_voted = False\nself._canvas.set_root(self._poll_canvas())\nself.show_all()", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Lesson Plan button clicked in Lesson Plan view.\n\nGo back to the view we had previously.\n\"\"\"\n", "func_signal": "def _button_closelessonplan_cb(self, button, lesson_return):\n", "code": "self._logger.debug('Lesson plans -> %s' % lesson_return)\nif lesson_return == 'poll':\n    self._canvas.set_root(self._poll_canvas())\nelif lesson_return == 'select':\n    self._canvas.set_root(self._select_canvas())\nelif lesson_return == 'build':\n    self._canvas.set_root(self._build_canvas())\nself.show_all()", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Apply colors to gtk Buttons\n\nbtn is the button\nw and h are optional width and height for resizing the button\nhighlight is a boolean to override the theme and apply a\n    different color to show \"you are here\".\n\nreturns the modified button.\n\"\"\"\n", "func_signal": "def theme_button(btn, w=-1, h=-1, highlight=False):\n", "code": "for state, color in COLOR_BG_BUTTONS:\n    if highlight:\n        btn.modify_bg(state, gtk.gdk.color_parse(\"#CCFF99\"))\n    else:\n        btn.modify_bg(state, gtk.gdk.color_parse(color))\nc = btn.get_child()\nif c is not None:\n    for state, color in COLOR_FG_BUTTONS:\n        if highlight:\n            c.modify_fg(state, gtk.gdk.color_parse(DARK_GREEN))\n        else:\n            c.modify_fg(state, gtk.gdk.color_parse(color))\nelse:\n    for state, color in COLOR_FG_BUTTONS:\n        btn.modify_fg(state, gtk.gdk.color_parse(color))\nif w>0 or h>0:\n    btn.set_size_request(w, h)\nreturn btn", "path": "poll.py", "repo_name": "morgs/poll-builder", "stars": 2, "license": "gpl-2.0", "language": "python", "size": 152}
{"docstring": "\"\"\"Read terminal status line: Ring Indicator\"\"\"\n", "func_signal": "def getRI(self):\n", "code": "if self.fd is None: raise portNotOpenError\ns = fcntl.ioctl(self.fd, TIOCMGET, TIOCM_zero_str)\nreturn struct.unpack('I',s)[0] & TIOCM_RI != 0", "path": "serial\\serialposix.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"select bit\"\"\"\n", "func_signal": "def setSelect(self, level):\n", "code": "if level:\n    self.ctrlReg = self.ctrlReg & ~0x08\nelse:\n    self.ctrlReg = self.ctrlReg |  0x08\n_pyparallel.outp(self.ctrlRegAdr, self.ctrlReg)", "path": "parallel\\parallelwin32.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Set break: Controls TXD. When active, to transmitting is possible.\"\"\"\n", "func_signal": "def setBreak(self, level=1):\n", "code": "if not self.hComPort: raise portNotOpenError\nif level:\n    win32file.SetCommBreak(self.hComPort)\nelse:\n    win32file.ClearCommBreak(self.hComPort)", "path": "serial\\serialwin32.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Output the given string over the serial port.\"\"\"\n", "func_signal": "def write(self, data):\n", "code": "if not self.hComPort: raise portNotOpenError\nif not isinstance(data, str):\n    raise TypeError('expected str, got %s' % type(data))\n#print repr(s),\nif data:\n    #~ win32event.ResetEvent(self._overlappedWrite.hEvent)\n    err, n = win32file.WriteFile(self.hComPort, data, self._overlappedWrite)\n    if err: #will be ERROR_IO_PENDING:\n        # Wait for the write to complete.\n        #~ win32event.WaitForSingleObject(self._overlappedWrite.hEvent, win32event.INFINITE)\n        n = win32file.GetOverlappedResult(self.hComPort, self._overlappedWrite, 1)\n        if n != len(data):\n            raise writeTimeoutError", "path": "serial\\serialwin32.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Close port\"\"\"\n", "func_signal": "def close(self):\n", "code": "if self._isOpen:\n    if self.hComPort:\n        try:\n            # Restore original timeout values:\n            win32file.SetCommTimeouts(self.hComPort, self._orgTimeouts)\n        except win32file.error:\n            # ignore errors. can happen for unplugged USB serial devices\n            pass\n        # Close COM-Port:\n        win32file.CloseHandle(self.hComPort)\n        win32file.CloseHandle(self._overlappedRead.hEvent)\n        win32file.CloseHandle(self._overlappedWrite.hEvent)\n        self.hComPort = None\n    self._isOpen = False", "path": "serial\\serialwin32.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Read terminal status line: Data Set Ready\"\"\"\n", "func_signal": "def getDSR(self):\n", "code": "if self.fd is None: raise portNotOpenError\ns = fcntl.ioctl(self.fd, TIOCMGET, TIOCM_zero_str)\nreturn struct.unpack('I',s)[0] & TIOCM_DSR != 0", "path": "serial\\serialposix.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Read size bytes from the serial port. If a timeout is set it may\n   return less characters as requested. With no timeout it will block\n   until the requested number of bytes is read.\"\"\"\n", "func_signal": "def read(self, size=1):\n", "code": "if self.fd is None: raise portNotOpenError\nread = ''\ninp = None\nif size > 0:\n    while len(read) < size:\n        #print \"\\tread(): size\",size, \"have\", len(read)    #debug\n        ready,_,_ = select.select([self.fd],[],[], self._timeout)\n        if not ready:\n            break   #timeout\n        buf = os.read(self.fd, size-len(read))\n        read = read + buf\n        if (self._timeout >= 0 or self._interCharTimeout > 0) and not buf:\n            break  #early abort on timeout\nreturn read", "path": "serial\\serialposix.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Clear input buffer, discarding all that is in the buffer.\"\"\"\n", "func_signal": "def flushInput(self):\n", "code": "if not self.hComPort: raise portNotOpenError\nwin32file.PurgeComm(self.hComPort, win32file.PURGE_RXCLEAR | win32file.PURGE_RXABORT)", "path": "serial\\serialwin32.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Set terminal status line: Data Terminal Ready\"\"\"\n", "func_signal": "def setDTR(self, level=1):\n", "code": "if not self.hComPort: raise portNotOpenError\nif level:\n    self._dtrState = win32file.DTR_CONTROL_ENABLE\n    win32file.EscapeCommFunction(self.hComPort, win32file.SETDTR)\nelse:\n    self._dtrState = win32file.DTR_CONTROL_DISABLE\n    win32file.EscapeCommFunction(self.hComPort, win32file.CLRDTR)", "path": "serial\\serialwin32.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Read terminal status line: Carrier Detect\"\"\"\n", "func_signal": "def getCD(self):\n", "code": "if not self.hComPort: raise portNotOpenError\nreturn MS_RLSD_ON & win32file.GetCommModemStatus(self.hComPort) != 0", "path": "serial\\serialwin32.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Read size bytes from the serial port. If a timeout is set it may\n   return less characters as requested. With no timeout it will block\n   until the requested number of bytes is read.\"\"\"\n", "func_signal": "def read(self, size=1):\n", "code": "if not self.hComPort: raise portNotOpenError\nif size > 0:\n    win32event.ResetEvent(self._overlappedRead.hEvent)\n    flags, comstat = win32file.ClearCommError(self.hComPort)\n    if self.timeout == 0:\n        n = min(comstat.cbInQue, size)\n        if n > 0:\n            rc, buf = win32file.ReadFile(self.hComPort, win32file.AllocateReadBuffer(n), self._overlappedRead)\n            win32event.WaitForSingleObject(self._overlappedRead.hEvent, win32event.INFINITE)\n            read = str(buf)\n        else:\n            read = ''\n    else:\n        rc, buf = win32file.ReadFile(self.hComPort, win32file.AllocateReadBuffer(size), self._overlappedRead)\n        n = win32file.GetOverlappedResult(self.hComPort, self._overlappedRead, 1)\n        read = str(buf[:n])\nelse:\n    read = ''\nreturn read", "path": "serial\\serialwin32.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Read terminal status line: Ring Indicator\"\"\"\n", "func_signal": "def getRI(self):\n", "code": "if not self.hComPort: raise portNotOpenError\nreturn MS_RING_ON & win32file.GetCommModemStatus(self.hComPort) != 0", "path": "serial\\serialwin32.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Read terminal status line: Clear To Send\"\"\"\n", "func_signal": "def getCTS(self):\n", "code": "if self.fd is None: raise portNotOpenError\ns = fcntl.ioctl(self.fd, TIOCMGET, TIOCM_zero_str)\nreturn struct.unpack('I',s)[0] & TIOCM_CTS != 0", "path": "serial\\serialposix.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Return the number of characters currently in the input buffer.\"\"\"\n#~ s = fcntl.ioctl(self.fd, TERMIOS.FIONREAD, TIOCM_zero_str)\n", "func_signal": "def inWaiting(self):\n", "code": "s = fcntl.ioctl(self.fd, TIOCINQ, TIOCM_zero_str)\nreturn struct.unpack('I',s)[0]", "path": "serial\\serialposix.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Read terminal status line: Data Set Ready\"\"\"\n", "func_signal": "def getDSR(self):\n", "code": "if not self.hComPort: raise portNotOpenError\nreturn MS_DSR_ON & win32file.GetCommModemStatus(self.hComPort) != 0", "path": "serial\\serialwin32.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Read terminal status line: Clear To Send\"\"\"\n", "func_signal": "def getCTS(self):\n", "code": "if not self.hComPort: raise portNotOpenError\nreturn MS_CTS_ON & win32file.GetCommModemStatus(self.hComPort) != 0", "path": "serial\\serialwin32.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Set break: Controls TXD. When active, to transmitting is possible.\"\"\"\n", "func_signal": "def setBreak(self, level=1):\n", "code": "if self.fd is None: raise portNotOpenError\nif level:\n    fcntl.ioctl(self.fd, TIOCSBRK)\nelse:\n    fcntl.ioctl(self.fd, TIOCCBRK)", "path": "serial\\serialposix.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Send break condition. Timed, returns to idle state after given duration.\"\"\"\n", "func_signal": "def sendBreak(self, duration=0.25):\n", "code": "if not self.hComPort: raise portNotOpenError\nimport time\nwin32file.SetCommBreak(self.hComPort)\ntime.sleep(duration)\nwin32file.ClearCommBreak(self.hComPort)", "path": "serial\\serialwin32.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Clear output buffer, aborting the current output and\ndiscarding all that is in the buffer.\"\"\"\n", "func_signal": "def flushOutput(self):\n", "code": "if not self.hComPort: raise portNotOpenError\nwin32file.PurgeComm(self.hComPort, win32file.PURGE_TXCLEAR | win32file.PURGE_TXABORT)", "path": "serial\\serialwin32.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"Platform specific - set flow state.\"\"\"\n", "func_signal": "def setXON(self, level=True):\n", "code": "if not self.hComPort: raise portNotOpenError\nif level:\n    win32file.EscapeCommFunction(self.hComPort, win32file.SETXON)\nelse:\n    win32file.EscapeCommFunction(self.hComPort, win32file.SETXOFF)", "path": "serial\\serialwin32.py", "repo_name": "andreisavu/ev-z3-webui", "stars": 3, "license": "None", "language": "python", "size": 7138}
{"docstring": "\"\"\"\nCreate a queryset matching all tags associated with the given\nobject.\n\"\"\"\n", "func_signal": "def get_for_object(self, obj):\n", "code": "ctype = ContentType.objects.get_for_model(obj)\nreturn self.filter(items__content_type__pk=ctype.pk,\n                   items__object_id=obj.pk)", "path": "tagging\\managers.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nSet the wordpress API key for all transactions.\n\nIf you don't specify an explicit API ``key`` and ``blog_url`` it will\nattempt to load them from a file called ``apikey.txt`` in the current\ndirectory.\n\nThis method is *usually* called automatically when you create a new\n``Akismet`` instance.\n\"\"\"\n", "func_signal": "def setAPIKey(self, key=None, blog_url=None):\n", "code": "if key is None and isfile('apikey.txt'):\n    the_file = [l.strip() for l in open('apikey.txt').readlines()\n        if l.strip() and not l.strip().startswith('#')]\n    try:\n        self.key = the_file[0]\n        self.blog_url = the_file[1]\n    except IndexError:\n        raise APIKeyError(\"Your 'apikey.txt' is invalid.\")\nelse:\n    self.key = key\n    self.blog_url = blog_url", "path": "comments\\akismet.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nGiven a ``QuerySet`` or a ``Model``, returns a two-tuple of\n(queryset, model).\n\nIf a ``Model`` is given, the ``QuerySet`` returned will be created\nusing its default manager.\n\"\"\"\n", "func_signal": "def get_queryset_and_model(queryset_or_model):\n", "code": "try:\n    return queryset_or_model, queryset_or_model.model\nexcept AttributeError:\n    return queryset_or_model._default_manager.all(), queryset_or_model", "path": "tagging\\utils.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nUpdate tags associated with an object.\n\"\"\"\n", "func_signal": "def update_tags(self, obj, tag_names):\n", "code": "from models import TaggedItem\nctype = ContentType.objects.get_for_model(obj)\ncurrent_tags = list(self.filter(items__content_type__pk=ctype.pk,\n                                items__object_id=obj.pk))\nupdated_tag_names = parse_tag_input(tag_names)\n\n# Remove tags which no longer apply\ntags_for_removal = [tag for tag in current_tags \\\n                    if tag.name not in updated_tag_names]\nif len(tags_for_removal):\n    TaggedItem._default_manager.filter(content_type__pk=ctype.pk,\n                                       object_id=obj.pk,\n                                       tag__in=tags_for_removal).delete()\n# Add new tags\ncurrent_tag_names = [tag.name for tag in current_tags]\nfor tag_name in updated_tag_names:\n    if tag_name not in current_tag_names:\n        tag, created = self.get_or_create(tag_name)\n        TaggedItem._default_manager.create(tag=tag, content_object=obj)", "path": "tagging\\managers.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nLogarithmic tag weight calculation is based on code from the\n`Tag Cloud`_ plugin for Mephisto, by Sven Fuchs.\n\n.. _`Tag Cloud`: http://www.artweb-design.de/projects/mephisto-plugin-tag-cloud\n\"\"\"\n", "func_signal": "def _calculate_tag_weight(weight, max_weight, distribution):\n", "code": "if distribution == LINEAR or max_weight == 1:\n    return weight\nelif distribution == LOGARITHMIC:\n    return math.log(weight) * max_weight / math.log(max_weight)\nraise ValueError(_('Invalid distribution algorithm specified: %s.') % distribution)", "path": "tagging\\utils.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nPost a comment.\n\nHTTP POST is required. If ``POST['submit'] == \"preview\"`` or if there are\nerrors a preview template, ``comment/preview.html``, will be rendered.\n\"\"\"\n# Fill out some initial data fields from an authenticated user, if present\n", "func_signal": "def post_comment(request, next = None):\n", "code": "data = request.POST.copy()\nif request.user.is_authenticated():\n    if not data.get('name', ''):\n        try:\n            data['name'] = request.user.get_profile().nickname\n        except:\n            data['name'] = request.user.get_full_name() or request.user.username\n    if not data.get('email', ''):\n        data[\"email\"] = request.user.email\n    if not data.get('url', ''):\n        try:\n            data['url'] = request.user.get_profile().website\n        except:\n            data['url'] = ''\n\n# Look up the object we're trying to comment about\nctype = data.get(\"content_type\")\nobject_pk = data.get(\"object_pk\")\nif ctype is None or object_pk is None:\n    return CommentPostBadRequest(\"Missing content_type or object_pk field.\")\ntry:\n    model = models.get_model(*ctype.split(\".\", 1))\n    target = model._default_manager.get(pk=object_pk)\nexcept TypeError:\n    return CommentPostBadRequest(\n        \"Invalid content_type value: %r\" % escape(ctype))\nexcept AttributeError:\n    return CommentPostBadRequest(\n        \"The given content-type %r does not resolve to a valid model.\" % \\\n            escape(ctype))\nexcept ObjectDoesNotExist:\n    return CommentPostBadRequest(\n        \"No object matching content-type %r and object PK %r exists.\" % \\\n            (escape(ctype), escape(object_pk)))\n\n# Construct the comment form\nform = CommentForm(target, data=data)\n\n# Check security information\nif form.security_errors():\n    return CommentPostBadRequest(\n        \"The comment form failed security verification: %s\" % \\\n            escape(str(form.security_errors())))\n\n# If there are errors\nif form.errors:\n    message = None\n    for field in ['author', 'email', 'content', 'url']:\n        if field in form.errors:                                              \n            if form.errors[field][0]:                                         \n                message = '[%s] %s' % (field.title(), form.errors[field][0].capitalize())\n                break\n\n    return render_to_response('post/error.html', {'message': message})\n\n# Otherwise create the comment\ncomment = form.get_comment_object()\ncomment.parent_id = data['parent_id']\ncomment.ip_address = request.META.get(\"REMOTE_ADDR\", None)\nif request.user.is_authenticated():\n    comment.user = request.user\n\n# Signal that the comment is about to be saved\nresponses = signals.comment_will_be_posted.send(\n    sender  = comment.__class__,\n    comment = comment,\n    request = request\n)\n\nfor (receiver, response) in responses:\n    if response == False:\n        return CommentPostBadRequest(\n            \"comment_will_be_posted receiver %r killed the comment\" % receiver.__name__)\n\n# Save the comment and signal that it was saved\ncomment.save()\nsignals.comment_was_posted.send(\n    sender  = comment.__class__,\n    comment = comment,\n    request = request\n)\n\nresponse = HttpResponseRedirect('%s#comment-%d' % (target.get_absolute_url(), comment.id))\n\ntry:\n    response.set_cookie('ip', comment.ip_address, max_age = 31536000)\n    response.set_cookie('email', comment.user_email, max_age = 31536000)\n    response.set_cookie('url', comment.user_url, max_age = 31536000)\n    response.set_cookie('name', comment.user_name, max_age = 31536000)\nexcept:\n    pass\n\nreturn response", "path": "comments\\views.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nRetrieve a list of instances of the specified model which share\ntags with the model instance ``obj``, ordered by the number of\nshared tags in descending order.\n\nIf ``num`` is given, a maximum of ``num`` instances will be\nreturned.\n\"\"\"\n", "func_signal": "def get_related(self, obj, queryset_or_model, num=None):\n", "code": "queryset, model = get_queryset_and_model(queryset_or_model)\nmodel_table = qn(model._meta.db_table)\ncontent_type = ContentType.objects.get_for_model(obj)\nrelated_content_type = ContentType.objects.get_for_model(model)\nquery = \"\"\"\nSELECT %(model_pk)s, COUNT(related_tagged_item.object_id) AS %(count)s\nFROM %(model)s, %(tagged_item)s, %(tag)s, %(tagged_item)s related_tagged_item\nWHERE %(tagged_item)s.object_id = %%s\n  AND %(tagged_item)s.content_type_id = %(content_type_id)s\n  AND %(tag)s.id = %(tagged_item)s.tag_id\n  AND related_tagged_item.content_type_id = %(related_content_type_id)s\n  AND related_tagged_item.tag_id = %(tagged_item)s.tag_id\n  AND %(model_pk)s = related_tagged_item.object_id\"\"\"\nif content_type.pk == related_content_type.pk:\n    # Exclude the given instance itself if determining related\n    # instances for the same model.\n    query += \"\"\"\n  AND related_tagged_item.object_id != %(tagged_item)s.object_id\"\"\"\nquery += \"\"\"\nGROUP BY %(model_pk)s\nORDER BY %(count)s DESC\n%(limit_offset)s\"\"\"\nquery = query % {\n    'model_pk': '%s.%s' % (model_table, qn(model._meta.pk.column)),\n    'count': qn('count'),\n    'model': model_table,\n    'tagged_item': qn(self.model._meta.db_table),\n    'tag': qn(self.model._meta.get_field('tag').rel.to._meta.db_table),\n    'content_type_id': content_type.pk,\n    'related_content_type_id': related_content_type.pk,\n    # Hardcoding this for now just to get tests working again - this\n    # should now be handled by the query object.\n    'limit_offset': num is not None and 'LIMIT %s' or '',\n}\n\ncursor = connection.cursor()\nparams = [obj.pk]\nif num is not None:\n    params.append(num)\ncursor.execute(query, params)\nobject_ids = [row[0] for row in cursor.fetchall()]\nif len(object_ids) > 0:\n    # Use in_bulk here instead of an id__in lookup, because id__in would\n    # clobber the ordering.\n    object_dict = queryset.in_bulk(object_ids)\n    return [object_dict[object_id] for object_id in object_ids \\\n            if object_id in object_dict]\nelse:\n    return []", "path": "tagging\\managers.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "'''\nChanges, e.g., \"Petty theft\" to \"petty_theft\".\nThis function is the Python equivalent of the javascript function\nof the same name in django/contrib/admin/media/js/urlify.js.\nIt can get invoked for any field that has a prepopulate_from\nattribute defined, although it only really makes sense for\nSlugFields.\n\nNOTE: this implementation corresponds to the Python implementation\n      of the same algorithm in django/contrib/admin/media/js/urlify.js\n'''\n# remove all these words from the string before urlifying\n", "func_signal": "def URLify(s, num_chars = None):\n", "code": "removelist = [\"a\", \"an\", \"as\", \"at\", \"before\", \"but\", \"by\", \"for\",\n              \"from\", \"is\", \"in\", \"into\", \"like\", \"of\", \"off\", \"on\",\n              \"onto\", \"per\", \"since\", \"than\", \"the\", \"this\", \"that\",\n              \"to\", \"up\", \"via\", \"with\"]\nignore_words = '|'.join([r for r in removelist])\nignore_words_pat = re.compile(r'\\b(%s)\\b' % ignore_words, re.I)\nignore_chars_pat = re.compile(r'[^-a-z0-9\\s]')\ninside_space_pat = re.compile(r'[-\\s]+')\n\ns = s.lower()                    # convert to lowercase\ns = ignore_words_pat.sub('', s)  # remove unimportant words\ns = ignore_chars_pat.sub('', s)  # remove unneeded chars\ns = s.strip()                    # trim leading/trailing spaces\ns = inside_space_pat.sub('-', s) # convert remaining spaces to hyphens\nif num_chars is not None:\n    s = s[:num_chars]            # trim to first num_chars chars\nreturn s", "path": "tagging\\utils.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nThis function is used to tell akismet that a comment it marked as spam,\nis really ham.\n\nIt takes all the same arguments as ``comment_check``, except for\n*DEBUG*.\n\"\"\"\n", "func_signal": "def submit_ham(self, comment, data=None, build_data=True):\n", "code": "if self.key is None:\n    raise APIKeyError(\"Your have not set an API key.\")\nif data is None:\n    data = {}\nif build_data:\n    self._build_data(comment, data)\nurl = '%ssubmit-ham' % self._getURL()\n# we *don't* trap the error here\n# so if akismet is down it will raise an HTTPError or URLError\nheaders = {'User-Agent' : self.user_agent}\nself._safeRequest(url, urlencode(data), headers)", "path": "comments\\akismet.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nParses tag input, with multiple word input being activated and\ndelineated by commas and double quotes. Quotes take precedence, so\nthey may contain commas.\n\nReturns a sorted list of unique tag names.\n\"\"\"\n", "func_signal": "def parse_tag_input(input):\n", "code": "if not input:\n    return []\n\ninput = force_unicode(input)\n\n# Special case - if there are no commas or double quotes in the\n# input, we don't *do* a recall... I mean, we know we only need to\n# split on spaces.", "path": "tagging\\utils.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nUtility function for accepting single tag input in a flexible\nmanner.\n\nIf a ``Tag`` object is given it will be returned as-is; if a\nstring or integer are given, they will be used to lookup the\nappropriate ``Tag``.\n\nIf no matching tag can be found, ``None`` will be returned.\n\"\"\"\n", "func_signal": "def get_tag(tag):\n", "code": "from tagging.models import Tag\nif isinstance(tag, Tag):\n    return tag\n\ntry:\n    if isinstance(tag, types.StringTypes):\n        return Tag.objects.get(name=tag)\n    elif isinstance(tag, (types.IntType, types.LongType)):\n        return Tag.objects.get(id=tag)\nexcept Tag.DoesNotExist:\n    pass\n\nreturn None", "path": "tagging\\utils.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nThis equates to the ``verify-key`` call against the akismet API.\n\nIt returns ``True`` if the key is valid.\n\nThe docs state that you *ought* to call this at the start of the\ntransaction.\n\nIt raises ``APIKeyError`` if you have not yet set an API key.\n\nIf the connection to akismet fails, it allows the normal ``HTTPError``\nor ``URLError`` to be raised.\n(*akismet.py* uses `urllib2 <http://docs.python.org/lib/module-urllib2.html>`_)\n\"\"\"\n", "func_signal": "def verify_key(self):\n", "code": "if self.key is None:\n    raise APIKeyError(\"Your have not set an API key.\")\ndata = { 'key': self.key, 'blog': self.blog_url }\n# this function *doesn't* use the key as part of the URL\nurl = 'http://%sverify-key' % self.baseurl\n# we *don't* trap the error here\n# so if akismet is down it will raise an HTTPError or URLError\nheaders = {'User-Agent' : self.user_agent}\nresp = self._safeRequest(url, urlencode(data), headers)\nif resp.lower() == 'valid':\n    return True\nelse:\n    return False", "path": "comments\\akismet.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nCreate a ``QuerySet`` containing instances of the specified\nmodel associated with a given tag or list of tags.\n\"\"\"\n", "func_signal": "def get_by_model(self, queryset_or_model, tags):\n", "code": "tags = get_tag_list(tags)\ntag_count = len(tags)\nif tag_count == 0:\n    # No existing tags were given\n    queryset, model = get_queryset_and_model(queryset_or_model)\n    return model._default_manager.none()\nelif tag_count == 1:\n    # Optimisation for single tag - fall through to the simpler\n    # query below.\n    tag = tags[0]\nelse:\n    return self.get_intersection_by_model(queryset_or_model, tags)\n\nqueryset, model = get_queryset_and_model(queryset_or_model)\ncontent_type = ContentType.objects.get_for_model(model)\nopts = self.model._meta\ntagged_item_table = qn(opts.db_table)\nreturn queryset.extra(\n    tables=[opts.db_table],\n    where=[\n        '%s.content_type_id = %%s' % tagged_item_table,\n        '%s.tag_id = %%s' % tagged_item_table,\n        '%s.%s = %s.object_id' % (qn(model._meta.db_table),\n                                  qn(model._meta.pk.column),\n                                  tagged_item_table)\n    ],\n    params=[content_type.pk, tag.pk],\n)", "path": "tagging\\managers.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nThis is the function that checks comments.\n\nIt returns ``True`` for spam and ``False`` for ham.\n\nIf you set ``DEBUG=True`` then it will return the text of the response,\ninstead of the ``True`` or ``False`` object.\n\nIt raises ``APIKeyError`` if you have not yet set an API key.\n\nIf the connection to Akismet fails then the ``HTTPError`` or\n``URLError`` will be propogated.\n\nAs a minimum it requires the body of the comment. This is the\n``comment`` argument.\n\nAkismet requires some other arguments, and allows some optional ones.\nThe more information you give it, the more likely it is to be able to\nmake an accurate diagnosise.\n\nYou supply these values using a mapping object (dictionary) as the\n``data`` argument.\n\nIf ``build_data`` is ``True`` (the default), then *akismet.py* will\nattempt to fill in as much information as possible, using default\nvalues where necessary. This is particularly useful for programs\nrunning in a {acro;CGI} environment. A lot of useful information\ncan be supplied from evironment variables (``os.environ``). See below.\n\nYou *only* need supply values for which you don't want defaults filled\nin for. All values must be strings.\n\nThere are a few required values. If they are not supplied, and\ndefaults can't be worked out, then an ``AkismetError`` is raised.\n\nIf you set ``build_data=False`` and a required value is missing an\n``AkismetError`` will also be raised.\n\nThe normal values (and defaults) are as follows : ::\n\n    'user_ip':          os.environ['REMOTE_ADDR']       (*)\n    'user_agent':       os.environ['HTTP_USER_AGENT']   (*)\n    'referrer':         os.environ.get('HTTP_REFERER', 'unknown') [#]_\n    'permalink':        ''\n    'comment_type':     'comment' [#]_\n    'comment_author':   ''\n    'comment_author_email': ''\n    'comment_author_url': ''\n    'SERVER_ADDR':      os.environ.get('SERVER_ADDR', '')\n    'SERVER_ADMIN':     os.environ.get('SERVER_ADMIN', '')\n    'SERVER_NAME':      os.environ.get('SERVER_NAME', '')\n    'SERVER_PORT':      os.environ.get('SERVER_PORT', '')\n    'SERVER_SIGNATURE': os.environ.get('SERVER_SIGNATURE', '')\n    'SERVER_SOFTWARE':  os.environ.get('SERVER_SOFTWARE', '')\n    'HTTP_ACCEPT':      os.environ.get('HTTP_ACCEPT', '')\n\n(*) Required values\n\nYou may supply as many additional 'HTTP_*' type values as you wish.\nThese should correspond to the http headers sent with the request.\n\n.. [#] Note the spelling \"referrer\". This is a required value by the\n    akismet api - however, referrer information is not always\n    supplied by the browser or server. In fact the HTTP protocol\n    forbids relying on referrer information for functionality in \n    programs.\n.. [#] The `API docs <http://akismet.com/development/api/>`_ state that this value\n    can be \" *blank, comment, trackback, pingback, or a made up value*\n    *like 'registration'* \".\n\"\"\"\n", "func_signal": "def comment_check(self, comment, data=None, build_data=True, DEBUG=False):\n", "code": "if self.key is None:\n    raise APIKeyError(\"Your have not set an API key.\")\nif data is None:\n    data = {}\nif build_data:\n    self._build_data(comment, data)\nurl = '%scomment-check' % self._getURL()\n# we *don't* trap the error here\n# so if akismet is down it will raise an HTTPError or URLError\nheaders = {'User-Agent' : self.user_agent}\nresp = self._safeRequest(url, urlencode(data), headers)\nif DEBUG:\n    return resp\nresp = resp.lower()\nif resp == 'true':\n    return True\nelif resp == 'false':\n    return False\nelse:\n    # NOTE: Happens when you get a 'howdy wilbur' response !\n    raise AkismetError('missing required argument.')", "path": "comments\\akismet.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nPerform the custom SQL query for ``usage_for_model`` and\n``usage_for_queryset``.\n\"\"\"\n", "func_signal": "def _get_usage(self, model, counts=False, min_count=None, extra_joins=None, extra_criteria=None, params=None):\n", "code": "from models import TaggedItem\nif min_count is not None: counts = True\n\nmodel_table = qn(model._meta.db_table)\nmodel_pk = '%s.%s' % (model_table, qn(model._meta.pk.column))\nquery = \"\"\"\nSELECT DISTINCT %(tag)s.id, %(tag)s.name%(count_sql)s\nFROM\n    %(tag)s\n    INNER JOIN %(tagged_item)s\n        ON %(tag)s.id = %(tagged_item)s.tag_id\n    INNER JOIN %(model)s\n        ON %(tagged_item)s.object_id = %(model_pk)s\n    %%s\nWHERE %(tagged_item)s.content_type_id = %(content_type_id)s\n    %%s\nGROUP BY %(tag)s.id, %(tag)s.name\n%%s\nORDER BY %(tag)s.name ASC\"\"\" % {\n    'tag': qn(self.model._meta.db_table),\n    'count_sql': counts and (', COUNT(%s)' % model_pk) or '',\n    'tagged_item': qn(TaggedItem._meta.db_table),\n    'model': model_table,\n    'model_pk': model_pk,\n    'content_type_id': ContentType.objects.get_for_model(model).pk,\n}\n\nmin_count_sql = ''\nif min_count is not None:\n    min_count_sql = 'HAVING COUNT(%s) >= %%s' % model_pk\n    params.append(min_count)\n\ncursor = connection.cursor()\ncursor.execute(query % (extra_joins, extra_criteria, min_count_sql), params)\ntags = []\nfor row in cursor.fetchall():\n    t = self.model(*row[:2])\n    if counts:\n        t.count = row[2]\n    tags.append(t)\nreturn tags", "path": "tagging\\managers.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nObtain a list of tags associated with instances of the given\nModel class.\n\nIf ``counts`` is True, a ``count`` attribute will be added to\neach tag, indicating how many times it has been used against\nthe Model class in question.\n\nIf ``min_count`` is given, only tags which have a ``count``\ngreater than or equal to ``min_count`` will be returned.\nPassing a value for ``min_count`` implies ``counts=True``.\n\nTo limit the tags (and counts, if specified) returned to those\nused by a subset of the Model's instances, pass a dictionary\nof field lookups to be applied to the given Model as the\n``filters`` argument.\n\"\"\"\n", "func_signal": "def usage_for_model(self, model, counts=False, min_count=None, filters=None):\n", "code": "if filters is None: filters = {}\n\nqueryset = model._default_manager.filter()\nfor f in filters.items():\n    queryset.query.add_filter(f)\nusage = self.usage_for_queryset(queryset, counts, min_count)\n\nreturn usage", "path": "tagging\\managers.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nGiven list of ``Tag`` instances, creates a string representation of\nthe list suitable for editing by the user, such that submitting the\ngiven string representation back without changing it will give the\nsame list of tags.\n\nTag names which contain commas will be double quoted.\n\nIf any tag name which isn't being quoted contains whitespace, the\nresulting string of tag names will be comma-delimited, otherwise\nit will be space-delimited.\n\"\"\"\n", "func_signal": "def edit_string_for_tags(tags):\n", "code": "names = []\nuse_commas = True\nfor tag in tags:\n    name = tag.name\n    if u',' in name:\n        names.append('\"%s\"' % name)\n        continue\n    elif u' ' in name:\n        if not use_commas:\n            use_commas = True\n    names.append(name)\nif use_commas:\n    glue = u', '\nelse:\n    glue = u' '\nreturn glue.join(names)", "path": "tagging\\utils.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nThis function builds the data structure required by ``comment_check``,\n``submit_spam``, and ``submit_ham``.\n\nIt modifies the ``data`` dictionary you give it in place. (and so\ndoesn't return anything)\n\nIt raises an ``AkismetError`` if the user IP or user-agent can't be\nworked out.\n\"\"\"\n", "func_signal": "def _build_data(self, comment, data):\n", "code": "data['comment_content'] = comment\nif not 'user_ip' in data:\n    try:\n        val = os.environ['REMOTE_ADDR']\n    except KeyError:\n        raise AkismetError(\"No 'user_ip' supplied\")\n    data['user_ip'] = val\nif not 'user_agent' in data:\n    try:\n        val = os.environ['HTTP_USER_AGENT']\n    except KeyError:\n        raise AkismetError(\"No 'user_agent' supplied\")\n    data['user_agent'] = val\n#\ndata.setdefault('referrer', os.environ.get('HTTP_REFERER', 'unknown'))\ndata.setdefault('permalink', '')\ndata.setdefault('comment_type', 'comment')\ndata.setdefault('comment_author', '')\ndata.setdefault('comment_author_email', '')\ndata.setdefault('comment_author_url', '')\ndata.setdefault('SERVER_ADDR', os.environ.get('SERVER_ADDR', ''))\ndata.setdefault('SERVER_ADMIN', os.environ.get('SERVER_ADMIN', ''))\ndata.setdefault('SERVER_NAME', os.environ.get('SERVER_NAME', ''))\ndata.setdefault('SERVER_PORT', os.environ.get('SERVER_PORT', ''))\ndata.setdefault('SERVER_SIGNATURE', os.environ.get('SERVER_SIGNATURE',\n    ''))\ndata.setdefault('SERVER_SOFTWARE', os.environ.get('SERVER_SOFTWARE',\n    ''))\ndata.setdefault('HTTP_ACCEPT', os.environ.get('HTTP_ACCEPT', ''))\ndata.setdefault('blog', self.blog_url)", "path": "comments\\akismet.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nUtility function for accepting tag input in a flexible manner.\n\nIf a ``Tag`` object is given, it will be returned in a list as\nits single occupant.\n\nIf given, the tag names in the following will be used to create a\n``Tag`` ``QuerySet``:\n\n   * A string, which may contain multiple tag names.\n   * A list or tuple of strings corresponding to tag names.\n   * A list or tuple of integers corresponding to tag ids.\n\nIf given, the following will be returned as-is:\n\n   * A list or tuple of ``Tag`` objects.\n   * A ``Tag`` ``QuerySet``.\n\n\"\"\"\n", "func_signal": "def get_tag_list(tags):\n", "code": "from models import Tag\nif isinstance(tags, Tag):\n    return [tags]\nelif isinstance(tags, QuerySet) and tags.model is Tag:\n    return tags\nelif isinstance(tags, types.StringTypes):\n    return Tag.objects.filter(name__in=parse_tag_input(tags))\nelif isinstance(tags, (types.ListType, types.TupleType)):\n    if len(tags) == 0:\n        return tags\n    contents = set()\n    for item in tags:\n        if isinstance(item, types.StringTypes):\n            contents.add('string')\n        elif isinstance(item, Tag):\n            contents.add('tag')\n        elif isinstance(item, (types.IntType, types.LongType)):\n            contents.add('int')\n    if len(contents) == 1:\n        if 'string' in contents:\n            return Tag.objects.filter(name__in=[force_unicode(tag) \\\n                                                for tag in tags])\n        elif 'tag' in contents:\n            return tags\n        elif 'int' in contents:\n            return Tag.objects.filter(id__in=tags)\n    else:\n        raise ValueError(_('If a list or tuple of tags is provided, they must all be tag names, Tag objects or Tag ids.'))\nelse:\n    raise ValueError(_('The tag input given was invalid.'))", "path": "tagging\\utils.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\nCreate a ``QuerySet`` containing instances of the specified\nmodel associated with *all* of the given list of tags.\n\"\"\"\n", "func_signal": "def get_intersection_by_model(self, queryset_or_model, tags):\n", "code": "tags = get_tag_list(tags)\ntag_count = len(tags)\nqueryset, model = get_queryset_and_model(queryset_or_model)\n\nif not tag_count:\n    return model._default_manager.none()\n\nmodel_table = qn(model._meta.db_table)\n# This query selects the ids of all objects which have all the\n# given tags.\nquery = \"\"\"\nSELECT %(model_pk)s\nFROM %(model)s, %(tagged_item)s\nWHERE %(tagged_item)s.content_type_id = %(content_type_id)s\n  AND %(tagged_item)s.tag_id IN (%(tag_id_placeholders)s)\n  AND %(model_pk)s = %(tagged_item)s.object_id\nGROUP BY %(model_pk)s\nHAVING COUNT(%(model_pk)s) = %(tag_count)s\"\"\" % {\n    'model_pk': '%s.%s' % (model_table, qn(model._meta.pk.column)),\n    'model': model_table,\n    'tagged_item': qn(self.model._meta.db_table),\n    'content_type_id': ContentType.objects.get_for_model(model).pk,\n    'tag_id_placeholders': ','.join(['%s'] * tag_count),\n    'tag_count': tag_count,\n}\n\ncursor = connection.cursor()\ncursor.execute(query, [tag.pk for tag in tags])\nobject_ids = [row[0] for row in cursor.fetchall()]\nif len(object_ids) > 0:\n    return queryset.filter(pk__in=object_ids)\nelse:\n    return model._default_manager.none()", "path": "tagging\\managers.py", "repo_name": "tualatrix/django", "stars": 2, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"Deactivate plugin.\"\"\"\n\n", "func_signal": "def deactivate(self, window):\n", "code": "widgets = [window]\nwidgets.extend(window.get_views())\nwidgets.extend(window.get_documents())\nname = self.__class__.__name__\nfor widget in widgets:\n    for handler_id in widget.get_data(name):\n        widget.disconnect(handler_id)\n    widget.set_data(name, None)\nself._terminate_completion()\nself._completion_windows.pop(window)\nfor doc in window.get_documents():\n    self._all_words.pop(doc, None)\n    self._favorite_words.pop(doc, None)", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Manage actions for completions and the completion window.\"\"\"\n\n# Check what do when key press\n# CTRL\n", "func_signal": "def _on_view_key_press_event(self, view, event, window):\n", "code": "if event.state & gtk.gdk.CONTROL_MASK:\n    return self._terminate_completion()\n# ALT\nif event.state & gtk.gdk.MOD1_MASK:\n    return self._terminate_completion()\n# TAB\nif (event.keyval == gtk.keysyms.Tab) and self._remains:\n    return not self._complete_current()\n# RETURN\nif (event.keyval == gtk.keysyms.Return) and self._remains:\n    return not self._complete_current()\ncompletion_window = self._completion_windows[window]\n# UP Arrow\nif (event.keyval == gtk.keysyms.Up) and self._remains:\n    return not completion_window.select_previous()\n# DOWN Arrow\nif (event.keyval == gtk.keysyms.Down) and self._remains:\n    return not completion_window.select_next()\nstring = unicode(event.string)\nif len(string) != 1:\n    # Do not suggest completions after pasting text.\n    return self._terminate_completion()\nif self._re_alpha.match(string) is None:\n    return self._terminate_completion()\ndoc = view.get_buffer()\ninsert = doc.get_iter_at_mark(doc.get_insert())\nif self._re_alpha.match(unicode(insert.get_char())):\n    # Do not suggest completions in the middle of a word.\n    return self._terminate_completion()\nreturn self._display_completions(view, event)", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Find completions and display them in the completion window.\"\"\"\n\n", "func_signal": "def _display_completions(self, view, event):\n", "code": "doc = view.get_buffer()\ninsert = doc.get_iter_at_mark(doc.get_insert())\nstart = insert.copy()\nwhile start.backward_char():\n    char = unicode(start.get_char())\n    if not self._re_alpha.match(char):\n        start.forward_char()\n        break\nincomplete = unicode(doc.get_text(start, insert))\nincomplete += unicode(event.string)\nif incomplete.isdigit():\n    # Usually completing numbers is not a good idea.\n    return self._terminate_completion()\nself._find_completions(doc, incomplete)\nif not self._completions:\n    return self._terminate_completion()\nself._show_completion_window(view, insert)", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Scan all the words in the active document in window.\"\"\"\n\n# Return False to not scan again.\n", "func_signal": "def _scan_active_document(self, window):\n", "code": "if window is None: return False\ndoc = window.get_active_document()\nif doc is not None:\n    self._scan_document(doc)\nreturn True", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Hide the completion window and cancel completions.\"\"\"\n\n", "func_signal": "def _terminate_completion(self):\n", "code": "window = gedit.app_get_default().get_active_window()\nself._completion_windows[window].hide()\nself._completions = []\nself._remains = []", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Connect to document's 'loaded' signal.\"\"\"\n\n", "func_signal": "def _connect_document(self, doc):\n", "code": "callback = lambda doc, x, self: self._scan_document(doc)\nhandler_id = doc.connect(\"loaded\", callback, self)\ndoc.set_data(self.__class__.__name__, (handler_id,))", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "# Create a new window ==================================================\n", "func_signal": "def create_configure_dialog(self):\n", "code": "window = CompletionPHPConfigWindow()\n\n# Return window\nreturn window", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Initialize the frame and the scrolled window.\"\"\"\n\n", "func_signal": "def _init_containers(self):\n", "code": "scroller = gtk.ScrolledWindow()\nscroller.set_policy(*((gtk.POLICY_NEVER,) * 2))\nscroller.add(self._view)\nframe = gtk.Frame()\nframe.set_shadow_type(gtk.SHADOW_OUT)\nframe.add(scroller)\nself.add(frame)", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Activate plugin.\"\"\"\n\n", "func_signal": "def activate(self, window):\n", "code": "callback = self._on_window_tab_added\nid_1 = window.connect(\"tab-added\", callback)\ncallback = self._on_window_tab_removed\nid_2 = window.connect(\"tab-removed\", callback)\nwindow.set_data(self.__class__.__name__, (id_1, id_2))\nfor doc in window.get_documents():\n    self._connect_document(doc)\n    self._scan_document(doc)\nviews = window.get_views()\nfor view in views:\n    self._connect_view(view, window)\nif views: self._update_fonts(views[0])\nself._completion_windows[window] = CompletionPHPWindow(window)\n# Scan the active document in window if it has input focus\n# for new words at constant intervals.\ndef scan(self, window):\n    if not window.is_active(): return True\n    return self._scan_active_document(window)", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Connect to view's editing signals.\"\"\"\n\n", "func_signal": "def _connect_view(self, view, window):\n", "code": "callback = lambda x, y, self: self._terminate_completion()\nid_1 = view.connect(\"focus-out-event\", callback, self)\ncallback = self._on_view_key_press_event\nid_2 = view.connect(\"key-press-event\", callback, window)\nview.set_data(self.__class__.__name__, (id_1, id_2))", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Return the index of the selected row.\"\"\"\n\n", "func_signal": "def get_selected(self):\n", "code": "selection = self._view.get_selection()\nreturn selection.get_selected_rows()[1][0][0]", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Remove closed document's word and favorite sets.\"\"\"\n\n", "func_signal": "def _on_window_tab_removed(self, window, tab):\n", "code": "doc = tab.get_document()\nself._all_words.pop(doc, None)", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Select the previous complete word.\"\"\"\n\n", "func_signal": "def select_previous(self):\n", "code": "row = max(self.get_selected() - 1, 0)\nselection = self._view.get_selection()\nselection.unselect_all()\nselection.select_path(row)\nself._view.scroll_to_cell(row)", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Complete the current word.\"\"\"\n\n# Load current window\n", "func_signal": "def _complete_current(self):\n", "code": "window = gedit.app_get_default().get_active_window()\n# Load current document\ndoc = window.get_active_document()\n# Index of completion windows\nindex = self._completion_windows[window].get_selected()\n# Insert into documente (at cursor position), selected text\ndoc.insert_at_cursor(self._remains[index])\n# terminate completion\nself._terminate_completion()", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Find completions for incomplete word and save them.\"\"\"\n\n", "func_signal": "def _find_completions(self, doc, incomplete):\n", "code": "if len(incomplete) < self._min_word_length: return True\n# Empty element array storage\nself._completions = []\nself._remains = []\n# Create empty array for words\n_all_words = set(())\n# Cycle every word into aviable words\nfor words in self._all_words.itervalues():\n    # Add this eleemnt into temp array\n    _all_words.update(words)\n# Find limit of element to display\nlimit = self._max_completions_to_show\n# Find words into 'all words', limit by 'limit'\nfor word in _all_words:\n    # check if not start with 'incomplete' text\n    if not word.startswith(incomplete): continue\n    # Check if 'incomplete' is fulltext\n    if word == incomplete: continue\n    # check if term is already aviable into '_completions'\n    if word in self._completions: continue\n    # add term into '_completions'\n    self._completions.append(word)\n    # add remaning term\n    self._remains.append(word[len(incomplete):])\n    if len(self._remains) >= limit: break", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Scan and save all words in document.\"\"\"\n\n# Load text from file\n", "func_signal": "def _scan_document(self, doc):\n", "code": "in_file = open(self._function_definition_file,\"r\")\ntext = in_file.read()\nin_file.close()\n\n# Add aviable function into hash\nself._all_words[doc] = frozenset(text.splitlines())", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Initialize the tree view listing the complete words.\"\"\"\n\n", "func_signal": "def _init_view(self):\n", "code": "self._store = gtk.ListStore(gobject.TYPE_STRING)\nself._view = gtk.TreeView(self._store)\nrenderer = gtk.CellRendererText()\nrenderer.xpad = renderer.ypad = 6\ncolumn = gtk.TreeViewColumn(\"\", renderer, text=0)\nself._view.append_column(column)\nself._view.set_enable_search(False)\nself._view.set_headers_visible(False)\nself._view.set_rules_hint(True)\nselection = self._view.get_selection()\nselection.set_mode(gtk.SELECTION_SINGLE)", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Show the completion window below the caret.\"\"\"\n\n", "func_signal": "def _show_completion_window(self, view, itr):\n", "code": "text_window = gtk.TEXT_WINDOW_WIDGET\nrect = view.get_iter_location(itr)\nx, y = view.buffer_to_window_coords(text_window, rect.x, rect.y)\nwindow = gedit.app_get_default().get_active_window()\nx, y = view.translate_coordinates(window, x, y)\nx += window.get_position()[0] + self._font_ascent\n# Use 24 pixels as an estimate height for window title bar.\n# TODO: There must be a better way than a hardcoded pixel value.\ny += window.get_position()[1] + 24 + (2 * self._font_ascent)\ncompletion_window = self._completion_windows[window]\ncompletion_window.set_completions(self._completions)\ncompletion_window.move(int(x), int(y))\ncompletion_window.show_all()", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Select the next complete word.\"\"\"\n\n", "func_signal": "def select_next(self):\n", "code": "row = min(self.get_selected() + 1, len(self._store) - 1)\nselection = self._view.get_selection()\nselection.unselect_all()\nselection.select_path(row)\nself._view.scroll_to_cell(row)", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Connect to signals of the document and view in tab.\"\"\"\n\n", "func_signal": "def _on_window_tab_added(self, window, tab):\n", "code": "self._update_fonts(tab.get_view())\nname = self.__class__.__name__\ndoc = tab.get_document()\nhandler_id = doc.get_data(name)\nif handler_id is None:\n    self._connect_document(doc)\nview = tab.get_view()\nhandler_id = view.get_data(name)\nif handler_id is None:\n    self._connect_view(view, window)", "path": "completion_php.py", "repo_name": "mavimo/gedit-completation_php", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "# escape something so it'll fit on a \"FOO: bar\" line\n", "func_signal": "def mtesc(s):\n", "code": "s = s.strip()\npos = len(s)\nfor x in \"\\r\\n\":\n\tp = s.find(x)\n\tif p != -1 and pos > p:\n\t\tpos = p\ns = s[:pos]\nreturn s", "path": "src\\comments\\export_mt.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "\"\"\"Converts the Julian date to the Gregorian date.\"\"\"\n", "func_signal": "def julianToGreg(self):\n", "code": "julian_first=self.julianFirst()\njulian_day=self.julian_date+julian_first\njulian_day=julian_day-1\na=julian_day+32044\nb=(4*a+3)/146097\nc=a-((146097*b)/4)\nd=(4*c+3)/1461\ne=c-((1461*d)/4)\nm=(5*e+2)/153\nday=e-((153*m+2)/5)+1\nmonth=m+3-12*(m/10)\nyear=100*b+d-4800+(m/10)\nreturn (year,month,day)", "path": "src\\strptime.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "\"\"\"Returns a tuple in the format used by time.gmtime().\nAll instances of None in the information are replaced with 0.\"\"\"\n", "func_signal": "def return_time(self):\n", "code": "temp_time=[self.year, self.month, self.day, self.hour, self.minute, self.second,\n           self.day_week, self.julian_date, self.daylight]\nreturn tuple([t or 0 for t in temp_time])  ###Python 2.2 -- change to:\n    ###struct_time(tuple(...)\n    ###Make sure to uncomment importation of struct_time at the top \n    ###of the file.", "path": "src\\strptime.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "\"\"\"\nURI, filename, or string --> stream\n\nThis function lets you define parsers that take any input source\n(URL, pathname to local or network file, or actual data as a string)\nand deal with it in a uniform manner.  Returned object is guaranteed\nto have all the basic stdio read methods (read, readline, readlines).\nJust .close() the object when you're done with it.\n\nIf the etag argument is supplied, it will be used as the value of an\nIf-None-Match request header.\n\nIf the modified argument is supplied, it must be a tuple of 9 integers\nas returned by gmtime() in the standard Python time module. This MUST\nbe in GMT (Greenwich Mean Time). The formatted date/time will be used\nas the value of an If-Modified-Since request header.\n\nIf the agent argument is supplied, it will be used as the value of a\nUser-Agent request header.\n\nIf the referrer argument is supplied, it will be used as the value of a\nReferer[sic] request header.\n\"\"\"\n\n", "func_signal": "def open_resource(source, etag=None, modified=None, agent=None, referrer=None):\n", "code": "if hasattr(source, \"read\"):\n    return source\n\nif source == \"-\":\n    return sys.stdin\n\nif not agent:\n    agent = USER_AGENT\n    \n# try to open with urllib2 (to use optional headers)\nrequest = urllib2.Request(source)\nif etag:\n    request.add_header(\"If-None-Match\", etag)\nif modified:\n    request.add_header(\"If-Modified-Since\", format_http_date(modified))\nrequest.add_header(\"User-Agent\", agent)\nif referrer:\n    request.add_header(\"Referer\", referrer)\n    request.add_header(\"Accept-encoding\", \"gzip\")\nopener = urllib2.build_opener(FeedURLHandler())\nopener.addheaders = [] # RMK - must clear so we only send our custom User-Agent\ntry:\n    return opener.open(request)\nexcept:\n    # source is not a valid URL, but it might be a valid filename\n    pass\n\n# try to open with native open function (if source is a filename)\ntry:\n    return open(source)\nexcept:\n    pass\n\n# treat source as string\nreturn StringIO.StringIO(str(source))", "path": "src\\rss\\feedparser.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "\"\"\"\nIf we are not running under a POSIX system, just simulate\nthe daemon mode by doing redirections and directory changeing\n\"\"\"\n\n", "func_signal": "def become_daemon(ourHomeDir='.',outLog=None,errLog=None):\n", "code": "os.chdir(ourHomeDir)\nos.umask(0)\nsys.stdin.close()\nsys.stdout.close()\nsys.stderr.close()", "path": "src\\daemonize.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "# convert string encoding\n", "func_signal": "def convertEncoding(text, src_enc, dst_enc):\n", "code": "if src_enc:\n\ttry:\n\t\ttext = text.decode(src_enc).encode(dst_enc)\n\texcept UnicodeError:\n\t\ttext = escape_8bit(text)\nelse:\n\t# unkown encoding\n\ttry:\n\t\ttext = text.decode('ascii').encode('ascii')\n\texcept UnicodeError:\n\t\ttry:\n\t\t\ttext = text.decode('utf-8').encode(dst_enc)\n\t\texcept UnicodeError:\n\t\t\ttry:\n\t\t\t\ttext = text.decode('iso-8859-1').encode(dst_enc)\n\t\t\texcept UnicodeError:\n\t\t\t\ttext = escape_8bit(text)\nreturn text", "path": "src\\modules\\system\\trackback.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "# called for each entity reference, e.g. for \"&copy;\", ref will be \"copy\"\n# Reconstruct the original entity reference.\n", "func_signal": "def handle_entityref(self, ref):\n", "code": "if not self.elementstack: return\ntext = \"&%s;\" % ref\nif self.incontent and self.contentmode == 'xml':\n    text = cgi.escape(text)\nself.elementstack[-1][2].append(text)", "path": "src\\rss\\feedparser.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "\"\"\"Figures out the day of the week using self.year, self.month, and self.day.\nMonday is 0.\n\n\"\"\"\n", "func_signal": "def dayWeek(self):\n", "code": "a=(14-self.month)/12\ny=self.year-a\nm=self.month+12*a-2\nday_week=(self.day+y+(y/4)-(y/100)+(y/400)+((31*m)/12))%7\nif day_week==0:\n    day_week=6\nelse:\n    day_week=day_week-1\nreturn day_week", "path": "src\\strptime.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "# We are now going to receive data that we want to ignore.\n# to ignore the file data we're not interested in.\n", "func_signal": "def handle_unauthorized (self, request):\n", "code": "self.fail_count.increment()\nrequest.channel.set_terminator (None)\nrequest['Connection'] = 'close'\nrequest['WWW-Authenticate'] = 'Basic realm=\"%s\"' % self.realm\nrequest.error (401)", "path": "src\\pycs_auth_handler.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "\"\"\"\nGet the ETag associated with a response returned from a call to \nopen_resource().\n\nIf the resource was not returned from an HTTP server or the server did\nnot specify an ETag for the resource, this will return None.\n\"\"\"\n\n", "func_signal": "def get_etag(resource):\n", "code": "if hasattr(resource, \"info\"):\n    return resource.info().getheader(\"ETag\")\nreturn None", "path": "src\\rss\\feedparser.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "# called for each block of plain text, i.e. outside of any tag and\n# not containing any character or entity references\n", "func_signal": "def handle_data(self, text):\n", "code": "if not self.elementstack: return\nif self.incontent and self.contentmode == 'xml':\n    text = cgi.escape(text)\nself.elementstack[-1][2].append(text)", "path": "src\\rss\\feedparser.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "# override internal declaration handler to handle CDATA blocks\n", "func_signal": "def parse_declaration(self, i):\n", "code": "if self.rawdata[i:i+9] == '<![CDATA[':\n    k = self.rawdata.find(']]>', i)\n    if k == -1: k = len(self.rawdata)\n    self.handle_data(cgi.escape(self.rawdata[i+9:k]))\n    return k+3\nreturn sgmllib.SGMLParser.parse_declaration(self, i)", "path": "src\\rss\\feedparser.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "\"\"\"\nParses any of the three HTTP date formats into a tuple of 9 integers as\nreturned by time.gmtime(). This should not use time.strptime() since\nthat function is not available on all platforms and could also be\naffected by the current locale.\n\"\"\"\n\n", "func_signal": "def parse_http_date(date):\n", "code": "date = str(date)\nyear = 0\nweekdays = short_weekdays\n\nm = rfc1123_match(date)\nif not m:\n    m = rfc850_match(date)\n    if m:\n        year = 1900\n        weekdays = long_weekdays\n    else:\n        m = asctime_match(date)\n        if not m:\n            return None\n\ntry:\n    year = year + int(m.group(\"year\"))\n    month = months.index(m.group(\"month\")) + 1\n    day = int(m.group(\"day\"))\n    hour = int(m.group(\"hour\"))\n    minute = int(m.group(\"minute\"))\n    second = int(m.group(\"second\"))\n    weekday = weekdays.index(m.group(\"weekday\"))\n    a = int((14 - month) / 12)\n    julian_day = (day - 32045 + int(((153 * (month + (12 * a) - 3)) + 2) / 5) + int((146097 * (year + 4800 - a)) / 400)) - (int((146097 * (year + 4799)) / 400) - 31738) + 1\n    daylight_savings_flag = 0\n    return (year, month, day, hour, minute, second, weekday, julian_day, daylight_savings_flag)\nexcept:\n    # the month or weekday lookup probably failed indicating an invalid timestamp\n    return None", "path": "src\\rss\\feedparser.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "\"\"\"Converts the Gregorian date to the Julian date.\nUses self.year, self.month, and self.day along with julianFirst().\n\n\t\"\"\"\n", "func_signal": "def gregToJulian(self):\n", "code": "a=(14-self.month)/12\ny=self.year+4800-a\nm=self.month+12*a-3\njulian_day=self.day+((153*m+2)/5)+365*y+y/4-y/100+y/400-32045\n\njulian_first=self.julianFirst()\n\njulian_date=julian_day-julian_first\njulian_date=julian_date+1 # to make result be same as what strftime would give.\nreturn julian_date", "path": "src\\strptime.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "# called for each character reference, e.g. for \"&#160;\", ref will be \"160\"\n# Reconstruct the original character reference.\n", "func_signal": "def handle_charref(self, ref):\n", "code": "if not self.elementstack: return\ntext = \"&#%s;\" % ref\nif self.incontent and self.contentmode == 'xml':\n    text = cgi.escape(text)\nself.elementstack[-1][2].append(text)", "path": "src\\rss\\feedparser.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "\"\"\"Calculates the julian date for the first day of year self.year.\"\"\"\n", "func_signal": "def julianFirst(self):\n", "code": "a=(14-1)/12  # for symmetry with gregToJulian's formula\ny=(self.year+4800)-a\nm=1+12*a-3\njulian_first=1+((153*m+2)/5)+365*y+y/4-y/100+y/400-32045\nreturn julian_first", "path": "src\\strptime.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "\"\"\"Creates locale tuple for use by strptime.\nTakes in DirectiveDict (locale-specific regexes for extracting info from\ntime string), MonthDict (locale full and abbreviated month names), DayDict\n(locale full and abbreviated weekday names), and am_pmDict (locale's valid\nrepresentation of AM and PM).\n\nDirectiveDict, MonthDict, and DayDict are dictionaries, while am_pmTuple is a\ntuple.  Look at how the ENGLISH dictionary is created for an example of how\nthe passed-in values should be constructed.  Also, make sure that every\nvalue in your language dictionary has a corresponding version to one in the\nENGLISH dictionary; leaving any out could cause problems.\n\nAlso note: if there are any values in the BasicDict that you would like to\noverride, just put the overrides in the DirectiveDict dictionary argument.\n\n\"\"\"\n###Python 2.2 -- Remove the %Z value since it has been deprecated.\n", "func_signal": "def LocaleAssembly(DirectiveDict, MonthDict, DayDict, am_pmTuple):\n", "code": "BasicDict={'%d':r'(?P<d>[0-3]\\d)', # Day of the month [01,31].\n    '%H':r'(?P<H>[0-2]\\d)', # Hour (24-h) [00,23].\n    '%I':r'(?P<I>[01]\\d)', # Hour (12-h) [01,12].\n    '%j':r'(?P<j>[0-3]\\d\\d)', # Day of the year [001,366].\n    '%m':r'(?P<m>[01]\\d)', # Month [01,12].\n    '%M':r'(?P<M>[0-5]\\d)', # Minute [00,59].\n    '%S':r'(?P<S>[0-6]\\d)', # Second [00,61].\n    '%U':r'(?P<U>[0-5]\\d)', # Week number of the year, Sunday first [00,53]\n    '%w':r'(?P<w>[0-6])', # Weekday [0(Sunday),6].\n    '%W':r'(?P<W>[0-5]\\d)', # Week number of the year, Monday first [00,53]\n    '%y':r'(?P<y>\\d\\d)', # Year without century [00,99].\n    '%Y':r'(?P<Y>\\d\\d\\d\\d)', # Year with century.\n    '%Z':r'(?P<Z>(\\D+ Time)|([\\S\\D]{3,3}))', # Time zone name (or empty)\n    '%%':r'(?P<percent>%)' # Literal \"%\" (ignored, in the end)\n    }\nBasicDict.update(DirectiveDict)\nreturn BasicDict, MonthDict, DayDict, am_pmTuple", "path": "src\\strptime.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "# Thanks to mwm@contessa.phone.net (Mike Meyer)\n", "func_signal": "def status (self):\n", "code": "r = [\n\t\tproducers.simple_producer (\n\t\t\t\t'<li>Authorization Extension : '\n\t\t\t\t'<b>Unauthorized requests:</b> %s<ul>' % self.fail_count\n\t\t\t\t)\n\t\t]\nif hasattr (self.handler, 'status'):\n\tr.append (self.handler.status())\nr.append (\n\t\tproducers.simple_producer ('</ul>')\n\t\t)\nreturn producers.composite_producer (\n\t\thttp_server.fifo (r)\n\t\t)", "path": "src\\pycs_auth_handler.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "\"\"\"\nGet the Last-Modified timestamp for a response returned from a call to\nopen_resource().\n\nIf the resource was not returned from an HTTP server or the server did\nnot specify a Last-Modified timestamp, this function will return None.\nOtherwise, it returns a tuple of 9 integers as returned by gmtime() in\nthe standard Python time module().\n\"\"\"\n\n", "func_signal": "def get_modified(resource):\n", "code": "if hasattr(resource, \"info\"):\n    last_modified = resource.info().getheader(\"Last-Modified\")\n    if last_modified:\n        return parse_http_date(last_modified)\nreturn None", "path": "src\\rss\\feedparser.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "\"\"\"Based on the current time information, it figures out what other info can be filled in.\"\"\"\n", "func_signal": "def FillInInfo(self):\n", "code": "if self.julian_date==None and self.year and self.month and self.day:\n    julian_date=self.gregToJulian()\n    self.julian_date=julian_date\nif (self.month==None or self.day==None) and self.year and self.julian_date:\n    gregorian=self.julianToGreg()\n    self.month=gregorian[1] # Year tossed out since must be already ok\n    self.day=gregorian[2]\nif self.day_week==None and self.year and self.month and self.day:\n    self.day_week=self.dayWeek()", "path": "src\\strptime.py", "repo_name": "myelin/pycs", "stars": 2, "license": "None", "language": "python", "size": 524}
{"docstring": "# Case 1: Presence of OAuth token (in case of 3-legged OAuth)\n", "func_signal": "def testSecureAuthSubGetAuthHeader(self):\n", "code": "url = 'http://dummy.com/?q=notebook&s=true'\ntoken = gdata.auth.SecureAuthSubToken(RSA_KEY, token_string='foo')\nauth_header = token.GetAuthHeader('GET', url)\nself.assert_('Authorization' in auth_header)\nheader_value = auth_header['Authorization']\nself.assert_(header_value.startswith(r'AuthSub token=\"foo\"'))\nself.assert_(-1 < header_value.find(r'sigalg=\"rsa-sha1\"'))\nself.assert_(-1 < header_value.find(r'data=\"'))\nself.assert_(-1 < header_value.find(r'sig=\"'))\nm = re.search(r'data=\"(.*?)\"', header_value)\nself.assert_(m is not None)\ndata = m.group(1)\nself.assert_(data.startswith('GET'))\nself.assert_(-1 < data.find(url))", "path": "gdata-1.3.1\\tests\\gdata_tests\\auth_test.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\" Adds a reminder to a calendar event. \n\n    This function sets the reminder attribute of the CalendarEventEntry.\n    The script sets it to 2 days by default, and this value is not \n    settable by the user. However, it can easily be changed to take this\n    option.\n\n    Args:\n      event: CalendarEventEntry\n      minutes: int\n \n    Returns:\n      the updated event: CalendarEventEntry\n\"\"\"\n\n", "func_signal": "def _AddReminder(self, event, minutes):\n", "code": "for a_when in event.when:\n  if len(a_when.reminder) > 0:\n    a_when.reminder[0].minutes = minutes\n  else:\n    a_when.reminder.append(gdata.calendar.Reminder(minutes=minutes))\n\nreturn self.c_client.UpdateEvent(event.GetEditLink().href, event)", "path": "gdata-1.3.1\\samples\\mashups\\birthdaySample.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\" Initializes spreadsheet and calendar clients.\n    \n    Creates SpreadsheetsService and CalendarService objects and \n    authenticates to each with ClientLogin. For more information\n    about ClientLogin authentication: \n    http://code.google.com/apis/accounts/AuthForInstalledApps.html\n\n    Args:\n      email: string\n      password: string\n\"\"\"\n\n", "func_signal": "def __init__(self, email, password):\n", "code": "self.s_client = gdata.spreadsheet.service.SpreadsheetsService()\nself.s_client.email = email\nself.s_client.password = password\nself.s_client.source = 'exampleCo-birthdaySample-1'\nself.s_client.ProgrammaticLogin()\n\nself.c_client = gdata.calendar.service.CalendarService()\nself.c_client.email = email\nself.c_client.password = password\nself.c_client.source = 'exampleCo-birthdaySample-1'\nself.c_client.ProgrammaticLogin()", "path": "gdata-1.3.1\\samples\\mashups\\birthdaySample.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Creates a new AuthSubToken using information in the URL.\n\nUses auth_sub_string_from_url.\n\nArgs:\n  str_or_uri: The current page's URL (as a str or atom.http_core.Uri)\n              which should contain a token query parameter since the\n              Google auth server redirected the user's browser to this\n              URL.\n\"\"\"\n", "func_signal": "def from_url(str_or_uri):\n", "code": "token_and_scopes = auth_sub_string_from_url(str_or_uri)\nreturn AuthSubToken(token_and_scopes[0], token_and_scopes[1])", "path": "gdata-1.3.1\\src\\gdata\\gauth.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Upgrades a single use AuthSub token to a session token.\n\nArgs:\n  token: A gdata.auth.AuthSubToken or gdata.auth.SecureAuthSubToken\n         (optional) which is good for a single use but can be upgraded\n         to a session token. If no token is passed in, the token\n         is found by looking in the token_store by looking for a token\n         for the current scope.\n\nRaises:\n  NonAuthSubToken if the user's auth token is not an AuthSub token\n  TokenUpgradeFailed if the server responded to the request with an \n  error.\n\"\"\"\n", "func_signal": "def UpgradeToSessionToken(self, token=None):\n", "code": "if token is None:\n  scopes = lookup_scopes(self.service)\n  if scopes:\n    token = self.token_store.find_token(scopes[0])\n  else:\n    token = self.token_store.find_token(atom.token_store.SCOPE_ALL)\nif not isinstance(token, gdata.auth.AuthSubToken):\n  raise NonAuthSubToken\n\nself.SetAuthSubToken(self.upgrade_to_session_token(token))", "path": "gdata-1.3.1\\src\\gdata\\service.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Sets the token sent in requests to an AuthSub token.\n\nSets the current_token and attempts to add the token to the token_store.\n\nOnly use this method if you have received a token from the AuthSub\nservice. The auth token is set automatically when UpgradeToSessionToken()\nis used. See documentation for Google AuthSub here:\nhttp://code.google.com/apis/accounts/AuthForWebApps.html \n\nArgs:\n token: gdata.auth.AuthSubToken or gdata.auth.SecureAuthSubToken or string\n        The token returned by the AuthSub service. If the token is an\n        AuthSubToken or SecureAuthSubToken, the scope information stored in\n        the token is used. If the token is a string, the scopes parameter is\n        used to determine the valid scopes.\n scopes: list of URLs for which the token is valid. This is only used\n         if the token parameter is a string.\n rsa_key: string (optional) Private key required for RSA_SHA1 signature\n          method.  This parameter is necessary if the token is a string\n          representing a secure token.\n\"\"\"\n", "func_signal": "def SetAuthSubToken(self, token, scopes=None, rsa_key=None):\n", "code": "if not isinstance(token, gdata.auth.AuthSubToken):\n  token_string = token\n  if rsa_key:\n    token = gdata.auth.SecureAuthSubToken(rsa_key)\n  else:\n    token = gdata.auth.AuthSubToken()\n\n  token.set_token_string(token_string)\n    \n# If no scopes were set for the token, use the scopes passed in, or\n# try to determine the scopes based on the current service name. If\n# all else fails, set the token to match all requests.\nif not token.scopes:\n  if scopes is None:\n    scopes = lookup_scopes(self.service)\n    if scopes is None:\n      scopes = [atom.token_store.SCOPE_ALL]\n  token.scopes = scopes\nif self.auto_set_current_token:\n  self.current_token = token\nif self.auto_store_tokens:\n  self.token_store.add_token(token)", "path": "gdata-1.3.1\\src\\gdata\\service.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "# Case 1: no token.\n", "func_signal": "def testSecureAuthSubToAndFromString(self):\n", "code": "token = gdata.auth.SecureAuthSubToken(RSA_KEY)\ntoken.set_token_string('foo')\nself.assertEquals(token.get_token_string(), 'foo')\ntoken.set_token_string(token.get_token_string())\nself.assertEquals(token.get_token_string(), 'foo')\nself.assertEquals(str(token), 'foo')\n# Case 2: token is a string\ntoken = gdata.auth.SecureAuthSubToken(RSA_KEY, token_string='foo')\nself.assertEquals(token.get_token_string(), 'foo')\ntoken.set_token_string(token.get_token_string())\nself.assertEquals(token.get_token_string(), 'foo')\nself.assertEquals(str(token), 'foo')", "path": "gdata-1.3.1\\tests\\gdata_tests\\auth_test.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\" Insert event into the authenticated user's calendar. \n\n    Args:\n      event: CalendarEventEntry\n\n    Returns:\n       the newly created CalendarEventEntry \n\"\"\"\n\n", "func_signal": "def _InsertBirthdayWebContentEvent(self, event):\n", "code": "edit_uri = '/calendar/feeds/default/private/full'\nreturn self.c_client.InsertEvent(event, edit_uri)", "path": "gdata-1.3.1\\samples\\mashups\\birthdaySample.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Extracts the AuthSub token from an HTTP body string.\n\nUsed to find the new session token after making a request to upgrade a\nsingle use AuthSub token.\n\nArgs:\n  http_body: str The repsonse from the server which contains the AuthSub\n      key. For example, this function would find the new session token\n      from the server's response to an upgrade token request.\n\nReturns:\n  The raw token value string to use in an AuthSubToken object.\n\"\"\"\n", "func_signal": "def auth_sub_string_from_body(http_body):\n", "code": "for response_line in http_body.splitlines():\n  if response_line.startswith('Token='):\n    # Strip off Token= and return the token value string.\n    return response_line[6:]\nreturn None", "path": "gdata-1.3.1\\src\\gdata\\gauth.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Returns the token string for the current token or a token matching the \nservice scope.\n\nIf the current_token is a ClientLoginToken, the token string for \nthe current token is returned. If the current_token is not set, this method\nsearches for a token in the token_store which is valid for the service \nobject's current scope.\n\nThe current scope is determined by the service name string member.\nThe token string is the end of the Authorization header, it doesn not\ninclude the ClientLogin label.\n\"\"\"\n", "func_signal": "def GetClientLoginToken(self):\n", "code": "if isinstance(self.current_token, gdata.auth.ClientLoginToken):\n  return self.current_token.get_token_string()\ncurrent_scopes = lookup_scopes(self.service)\nif current_scopes:\n  token = self.token_store.find_token(current_scopes[0])\n  if isinstance(token, gdata.auth.ClientLoginToken):\n    return token.get_token_string()\nelse:\n  token = self.token_store.find_token(atom.token_store.SCOPE_ALL)\n  if isinstance(token, gdata.auth.ClientLoginToken):\n    return token.get_token_string()\n  return None", "path": "gdata-1.3.1\\src\\gdata\\service.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Returns the AuthSub token as a string.\n \nIf the token is an gdta.auth.AuthSubToken, the Authorization Label\n(\"AuthSub token\") is removed.\n\nThis method examines the current_token to see if it is an AuthSubToken\nor SecureAuthSubToken. If not, it searches the token_store for a token\nwhich matches the current scope.\n\nThe current scope is determined by the service name string member.\n\nReturns:\n  If the current_token is set to an AuthSubToken/SecureAuthSubToken,\n  return the token string. If there is no current_token, a token string\n  for a token which matches the service object's default scope is returned.\n  If there are no tokens valid for the scope, returns None.\n\"\"\"\n", "func_signal": "def GetAuthSubToken(self):\n", "code": "if isinstance(self.current_token, gdata.auth.AuthSubToken):\n  return self.current_token.get_token_string()\ncurrent_scopes = lookup_scopes(self.service)\nif current_scopes:\n  token = self.token_store.find_token(current_scopes[0])\n  if isinstance(token, gdata.auth.AuthSubToken):\n    return token.get_token_string()\nelse:\n  token = self.token_store.find_token(atom.token_store.SCOPE_ALL)\n  if isinstance(token, gdata.auth.ClientLoginToken):\n    return token.get_token_string()\n  return None", "path": "gdata-1.3.1\\src\\gdata\\service.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Returns the token value for a ClientLoginToken.\n\nReads the token from the server's response to a Client Login request and\ncreates the token value string to use in requests.\n\nArgs:\n  http_body: str The body of the server's HTTP response to a Client Login\n      request\n \nReturns:\n  The token value string for a ClientLoginToken.\n\"\"\"\n", "func_signal": "def get_client_login_token_string(http_body):\n", "code": "for response_line in http_body.splitlines():\n  if response_line.startswith('Auth='):\n    # Strip off the leading Auth= and return the Authorization value.\n    return response_line[5:]\nreturn None", "path": "gdata-1.3.1\\src\\gdata\\gauth.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\" Prompts user to select desired worksheet.\n\n    Gets and displays titles of all worksheets for user to\n    select. Generic function taken from spreadsheetsExample.py.\n\n    Args:\n      key: string\n\n    Returns:\n       the worksheet ID that the user selected: string\n\"\"\"\n\n", "func_signal": "def _PromptForWorksheet(self, key):\n", "code": "feed = self.s_client.GetWorksheetsFeed(key)\nself._PrintFeed(feed)\ninput = raw_input('\\nSelection: ')\n\n# extract and return the worksheet ID\nreturn feed.entry[string.atoi(input)].id.text.rsplit('/', 1)[1]", "path": "gdata-1.3.1\\samples\\mashups\\birthdaySample.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Finds the token string (and scopes) after the browser is redirected.\n\nAfter the Google Accounts AuthSub pages redirect the user's broswer back to\nthe web application (using the 'next' URL from the request) the web app must\nextract the token from the current page's URL. The token is provided as a\nURL parameter named 'token' and if generate_auth_sub_url was used to create\nthe request, the token's valid scopes are included in a URL parameter whose\nname is specified in scopes_param_prefix.\n\nArgs:\n  url: atom.url.Url or str representing the current URL. The token value\n       and valid scopes should be included as URL parameters.\n  scopes_param_prefix: str (optional) The URL parameter key which maps to\n                       the list of valid scopes for the token.\n\nReturns:\n  A tuple containing the token value as a string, and a tuple of scopes \n  (as atom.http_core.Uri objects) which are URL prefixes under which this\n  token grants permission to read and write user data.\n  (token_string, (scope_uri, scope_uri, scope_uri, ...))\n  If no scopes were included in the URL, the second value in the tuple is\n  None. If there was no token param in the url, the tuple returned is \n  (None, None)\n\"\"\"\n", "func_signal": "def auth_sub_string_from_url(url, scopes_param_prefix='auth_sub_scopes'):\n", "code": "if isinstance(url, (str, unicode)):\n  url = atom.http_core.Uri.parse_uri(url)\nif 'token' not in url.query:\n  return (None, None)\ntoken = url.query['token']\n# TODO: decide whether no scopes should be None or ().\nscopes = None # Default to None for no scopes.\nif scopes_param_prefix in url.query:\n  scopes = tuple(url.query[scopes_param_prefix].split(' '))\nreturn (token, scopes)", "path": "gdata-1.3.1\\src\\gdata\\gauth.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "# Case 1: Presence of OAuth token (in case of 3-legged OAuth)\n", "func_signal": "def testOAuthGetAuthHeader(self):\n", "code": "oauth_input_params = gdata.auth.OAuthInputParams(\n    gdata.auth.OAuthSignatureMethod.RSA_SHA1, CONSUMER_KEY,\n    rsa_key=RSA_KEY)    \ntoken = gdata.auth.OAuthToken(key='ABCDDSFFDSG',\n                              oauth_input_params=oauth_input_params)\nauth_header = token.GetAuthHeader('GET',\n                                  'http://dummy.com/?q=notebook&s=true',\n                                  realm='http://dummy.com')\nself.assert_('Authorization' in auth_header)\nheader_value = auth_header['Authorization']\nself.assert_(-1 < header_value.find(r'OAuth realm=\"http://dummy.com\"'))\nself.assert_(-1 < header_value.find(r'oauth_version=\"1.0\"'))\nself.assert_(-1 < header_value.find(r'oauth_token=\"ABCDDSFFDSG\"'))\nself.assert_(-1 < header_value.find(r'oauth_nonce=\"'))\nself.assert_(-1 < header_value.find(r'oauth_timestamp=\"'))\nself.assert_(-1 < header_value.find(r'oauth_signature=\"'))\nself.assert_(-1 < header_value.find(\n    r'oauth_consumer_key=\"%s\"' % CONSUMER_KEY))\nself.assert_(-1 < header_value.find(r'oauth_signature_method=\"RSA-SHA1\"'))\n# Case 2: Absence of OAuth token (in case of 2-legged OAuth)\noauth_input_params = gdata.auth.OAuthInputParams(\n    gdata.auth.OAuthSignatureMethod.HMAC_SHA1, CONSUMER_KEY,\n    consumer_secret=CONSUMER_SECRET)\ntoken = gdata.auth.OAuthToken(oauth_input_params=oauth_input_params)     \nauth_header = token.GetAuthHeader(\n    'GET', 'http://dummy.com/?xoauth_requestor_id=user@gmail.com&q=book')\nself.assert_('Authorization' in auth_header)\nheader_value = auth_header['Authorization']\nself.assert_(-1 < header_value.find(r'OAuth realm=\"\"'))\nself.assert_(-1 < header_value.find(r'oauth_version=\"1.0\"'))\nself.assertEquals(-1, header_value.find(r'oauth_token='))\nself.assert_(-1 < header_value.find(r'oauth_nonce=\"'))\nself.assert_(-1 < header_value.find(r'oauth_timestamp=\"'))\nself.assert_(-1 < header_value.find(r'oauth_signature=\"'))\nself.assert_(-1 < header_value.find(\n    r'oauth_consumer_key=\"%s\"' % CONSUMER_KEY))\nself.assert_(-1 < header_value.find(r'oauth_signature_method=\"HMAC-SHA1\"'))", "path": "gdata-1.3.1\\tests\\gdata_tests\\auth_test.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "# Add parameters to a URI\n", "func_signal": "def testBuildUriWithParams(self):\n", "code": "x = atom.service.BuildUri('/base/feeds/snippets', url_params={'foo': 'bar', \n                                                 'bq': 'digital camera'})\nself.assert_(x == '/base/feeds/snippets?foo=bar&bq=digital+camera')\nself.assert_(x.startswith('/base/feeds/snippets'))\nself.assert_(x.count('?') == 1)\nself.assert_(x.count('&') == 1)\nself.assert_(x.index('?') < x.index('&'))\nself.assert_(x.index('bq=digital+camera') != -1)\n\n# Add parameters to a URI that already has parameters\nx = atom.service.BuildUri('/base/feeds/snippets?bq=digital+camera', \n                         url_params={'foo': 'bar', 'max-results': '250'})\nself.assert_(x.startswith('/base/feeds/snippets?bq=digital+camera'))\nself.assert_(x.count('?') == 1)\nself.assert_(x.count('&') == 2)\nself.assert_(x.index('?') < x.index('&'))\nself.assert_(x.index('max-results=250') != -1)\nself.assert_(x.index('foo=bar') != -1)", "path": "gdata-1.3.1\\tests\\atom_tests\\service_test.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Finds the scope URLs for the desired service.\n\nIn some cases, an unknown service may be used, and in those cases this\nfunction will return None.\n\"\"\"\n", "func_signal": "def lookup_scopes(service_name):\n", "code": "if service_name in CLIENT_LOGIN_SCOPES:\n  return CLIENT_LOGIN_SCOPES[service_name]\nreturn None", "path": "gdata-1.3.1\\src\\gdata\\service.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\" Prompts user to select spreadsheet.\n \n    Gets and displays titles of all spreadsheets for user to \n    select. Generic function taken from spreadsheetsExample.py.\n\n    Args:\n      none\n\n    Returns:\n       spreadsheet ID that the user selected: string\n\"\"\"\n\n", "func_signal": "def _PromptForSpreadsheet(self):\n", "code": "feed = self.s_client.GetSpreadsheetsFeed()\nself._PrintFeed(feed)\ninput = raw_input('\\nSelection: ')\n\n# extract and return the spreadsheet ID\nreturn feed.entry[string.atoi(input)].id.text.rsplit('/', 1)[1]", "path": "gdata-1.3.1\\samples\\mashups\\birthdaySample.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Revokes an existing AuthSub token.\n\nRaises:\n  NonAuthSubToken if the user's auth token is not an AuthSub token\n\"\"\"\n", "func_signal": "def RevokeAuthSubToken(self):\n", "code": "scopes = lookup_scopes(self.service)\ntoken = self.token_store.find_token(scopes[0])\nif not isinstance(token, gdata.auth.AuthSubToken):\n  raise NonAuthSubToken\n\nresponse = token.perform_request(self.http_client, 'GET', \n    AUTH_SERVER_HOST + '/accounts/AuthSubRevokeToken', \n    headers={'Content-Type':'application/x-www-form-urlencoded'})\nif response.status == 200:\n  self.token_store.remove_token(token)", "path": "gdata-1.3.1\\src\\gdata\\service.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Attempts to set the current token and add it to the token store.\n\nThe oauth_token can be any OAuth token i.e. unauthorized request token,\nauthorized request token or access token.\nThis method also attempts to add the token to the token store.\nUse this method any time you want the current token to point to the\noauth_token passed. For e.g. call this method with the request token\nyou receive from FetchOAuthRequestToken.\n\nArgs:\n  request_token: gdata.auth.OAuthToken OAuth request token.\n\"\"\"\n", "func_signal": "def SetOAuthToken(self, oauth_token):\n", "code": "if self.auto_set_current_token:\n  self.current_token = oauth_token\nif self.auto_store_tokens:\n  self.token_store.add_token(oauth_token)", "path": "gdata-1.3.1\\src\\gdata\\service.py", "repo_name": "spookyvision/vcfimport", "stars": 2, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Returns true iff this tag has the same name, the same attributes,\nand the same contents (recursively) as the given tag.\n\nNOTE: right now this will return false if two tags have the\nsame attributes in a different order. Should this be fixed?\"\"\"\n", "func_signal": "def __eq__(self, other):\n", "code": "if not hasattr(other, 'name') or not hasattr(other, 'attrs') or not hasattr(other, 'contents') or self.name != other.name or self.attrs != other.attrs or len(self) != len(other):\n    return False\nfor i in range(0, len(self.contents)):\n    if self.contents[i] != other.contents[i]:\n        return False\nreturn True", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"Beautiful Soup can detect a charset included in a META tag,\ntry to convert the document to that charset, and re-parse the\ndocument from the beginning.\"\"\"\n", "func_signal": "def start_meta(self, attrs):\n", "code": "httpEquiv = None\ncontentType = None\ncontentTypeIndex = None\ntagNeedsEncodingSubstitution = False\n\nfor i in range(0, len(attrs)):\n    key, value = attrs[i]\n    key = key.lower()\n    if key == 'http-equiv':\n        httpEquiv = value\n    elif key == 'content':\n        contentType = value\n        contentTypeIndex = i\n\nif httpEquiv and contentType: # It's an interesting meta tag.\n    match = self.CHARSET_RE.search(contentType)\n    if match:\n        if (self.declaredHTMLEncoding is not None or\n            self.originalEncoding == self.fromEncoding):\n            # An HTML encoding was sniffed while converting\n            # the document to Unicode, or an HTML encoding was\n            # sniffed during a previous pass through the\n            # document, or an encoding was specified\n            # explicitly and it worked. Rewrite the meta tag.\n            def rewrite(match):\n                return match.group(1) + \"%SOUP-ENCODING%\"\n            newAttr = self.CHARSET_RE.sub(rewrite, contentType)\n            attrs[contentTypeIndex] = (attrs[contentTypeIndex][0],\n                                       newAttr)\n            tagNeedsEncodingSubstitution = True\n        else:\n            # This is our first pass through the document.\n            # Go through it again with the encoding information.\n            newCharset = match.group(3)\n            if newCharset and newCharset != self.originalEncoding:\n                self.declaredHTMLEncoding = newCharset\n                self._feed(self.declaredHTMLEncoding)\n                raise StopParsing\n            pass\ntag = self.unknown_starttag(\"meta\", attrs)\nif tag and tagNeedsEncodingSubstitution:\n    tag.containsSubstitutions = True", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"Changes a MS smart quote character to an XML or HTML\nentity.\"\"\"\n", "func_signal": "def _subMSChar(self, orig):\n", "code": "sub = self.MS_CHARS.get(orig)\nif type(sub) == types.TupleType:\n    if self.smartQuotesTo == 'xml':\n        sub = '&#x%s;' % sub[1]\n    else:\n        sub = '&%s;' % sub[0]\nreturn sub", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"Encodes an object to a string in some encoding, or to Unicode.\n.\"\"\"\n", "func_signal": "def toEncoding(self, s, encoding=None):\n", "code": "if isinstance(s, unicode):\n    if encoding:\n        s = s.encode(encoding)\nelif isinstance(s, str):\n    if encoding:\n        s = s.encode(encoding)\n    else:\n        s = unicode(s)\nelse:\n    if encoding:\n        s  = self.toEncoding(str(s), encoding)\n    else:\n        s = unicode(s)\nreturn s", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"Returns the closest sibling to this Tag that matches the\ngiven criteria and appears after this Tag in the document.\"\"\"\n", "func_signal": "def findNextSibling(self, name=None, attrs={}, text=None, **kwargs):\n", "code": "return self._findOne(self.findNextSiblings, name, attrs, text,\n                     **kwargs)", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "#print \"End tag %s\" % name\n", "func_signal": "def unknown_endtag(self, name):\n", "code": "if self.quoteStack and self.quoteStack[-1] != name:\n    #This is not a real end tag.\n    #print \"</%s> is not real!\" % name\n    self.handle_data('</%s>' % name)\n    return\nself.endData()\nself._popToTag(name)\nif self.quoteStack and self.quoteStack[-1] == name:\n    self.quoteStack.pop()\n    self.literal = (len(self.quoteStack) > 0)", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"Returns the closest parent of this Tag that matches the given\ncriteria.\"\"\"\n# NOTE: We can't use _findOne because findParents takes a different\n# set of arguments.\n", "func_signal": "def findParent(self, name=None, attrs={}, **kwargs):\n", "code": "r = None\nl = self.findParents(name, attrs, 1)\nif l:\n    r = l[0]\nreturn r", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"This method fixes a bug in Python's SGMLParser.\"\"\"\n", "func_signal": "def convert_charref(self, name):\n", "code": "try:\n    n = int(name)\nexcept ValueError:\n    return\nif not 0 <= n <= 127 : # ASCII ends at 127, not 255\n    return\nreturn self.convert_codepoint(n)", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"This method routes method call requests to either the SGMLParser\nsuperclass or the Tag superclass, depending on the method name.\"\"\"\n#print \"__getattr__ called on %s.%s\" % (self.__class__, methodName)\n\n", "func_signal": "def __getattr__(self, methodName):\n", "code": "if methodName.find('start_') == 0 or methodName.find('end_') == 0 \\\n       or methodName.find('do_') == 0:\n    return SGMLParser.__getattr__(self, methodName)\nelif methodName.find('__') != 0:\n    return Tag.__getattr__(self, methodName)\nelse:\n    raise AttributeError", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"Used in a call to re.sub to replace HTML, XML, and numeric\nentities with the appropriate Unicode characters. If HTML\nentities are being converted, any unrecognized entities are\nescaped.\"\"\"\n", "func_signal": "def _convertEntities(self, match):\n", "code": "x = match.group(1)\nif self.convertHTMLEntities and x in name2codepoint:\n    return unichr(name2codepoint[x])\nelif x in self.XML_ENTITIES_TO_SPECIAL_CHARS:\n    if self.convertXMLEntities:\n        return self.XML_ENTITIES_TO_SPECIAL_CHARS[x]\n    else:\n        return u'&%s;' % x\nelif len(x) > 0 and x[0] == '#':\n    # Handle numeric entities\n    if len(x) > 1 and x[1] == 'x':\n        return unichr(int(x[2:], 16))\n    else:\n        return unichr(int(x[1:]))\n\nelif self.escapeUnrecognizedEntities:\n    return u'&amp;%s;' % x\nelse:\n    return u'&%s;' % x", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"Initializes a map representation of this tag's attributes,\nif not already initialized.\"\"\"\n", "func_signal": "def _getAttrMap(self):\n", "code": "if not getattr(self, 'attrMap'):\n    self.attrMap = {}\n    for (key, value) in self.attrs:\n        self.attrMap[key] = value\nreturn self.attrMap", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"Returns true iff the given string is the name of a\nself-closing tag according to this parser.\"\"\"\n", "func_signal": "def isSelfClosingTag(self, name):\n", "code": "return self.SELF_CLOSING_TAGS.has_key(name) \\\n       or self.instanceSelfClosingTags.has_key(name)", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"Given a document, tries to detect its XML encoding.\"\"\"\n", "func_signal": "def _detectEncoding(self, xml_data, isHTML=False):\n", "code": "xml_encoding = sniffed_xml_encoding = None\ntry:\n    if xml_data[:4] == '\\x4c\\x6f\\xa7\\x94':\n        # EBCDIC\n        xml_data = self._ebcdic_to_ascii(xml_data)\n    elif xml_data[:4] == '\\x00\\x3c\\x00\\x3f':\n        # UTF-16BE\n        sniffed_xml_encoding = 'utf-16be'\n        xml_data = unicode(xml_data, 'utf-16be').encode('utf-8')\n    elif (len(xml_data) >= 4) and (xml_data[:2] == '\\xfe\\xff') \\\n             and (xml_data[2:4] != '\\x00\\x00'):\n        # UTF-16BE with BOM\n        sniffed_xml_encoding = 'utf-16be'\n        xml_data = unicode(xml_data[2:], 'utf-16be').encode('utf-8')\n    elif xml_data[:4] == '\\x3c\\x00\\x3f\\x00':\n        # UTF-16LE\n        sniffed_xml_encoding = 'utf-16le'\n        xml_data = unicode(xml_data, 'utf-16le').encode('utf-8')\n    elif (len(xml_data) >= 4) and (xml_data[:2] == '\\xff\\xfe') and \\\n             (xml_data[2:4] != '\\x00\\x00'):\n        # UTF-16LE with BOM\n        sniffed_xml_encoding = 'utf-16le'\n        xml_data = unicode(xml_data[2:], 'utf-16le').encode('utf-8')\n    elif xml_data[:4] == '\\x00\\x00\\x00\\x3c':\n        # UTF-32BE\n        sniffed_xml_encoding = 'utf-32be'\n        xml_data = unicode(xml_data, 'utf-32be').encode('utf-8')\n    elif xml_data[:4] == '\\x3c\\x00\\x00\\x00':\n        # UTF-32LE\n        sniffed_xml_encoding = 'utf-32le'\n        xml_data = unicode(xml_data, 'utf-32le').encode('utf-8')\n    elif xml_data[:4] == '\\x00\\x00\\xfe\\xff':\n        # UTF-32BE with BOM\n        sniffed_xml_encoding = 'utf-32be'\n        xml_data = unicode(xml_data[4:], 'utf-32be').encode('utf-8')\n    elif xml_data[:4] == '\\xff\\xfe\\x00\\x00':\n        # UTF-32LE with BOM\n        sniffed_xml_encoding = 'utf-32le'\n        xml_data = unicode(xml_data[4:], 'utf-32le').encode('utf-8')\n    elif xml_data[:3] == '\\xef\\xbb\\xbf':\n        # UTF-8 with BOM\n        sniffed_xml_encoding = 'utf-8'\n        xml_data = unicode(xml_data[3:], 'utf-8').encode('utf-8')\n    else:\n        sniffed_xml_encoding = 'ascii'\n        pass\nexcept:\n    xml_encoding_match = None\nxml_encoding_match = re.compile(\n    '^<\\?.*encoding=[\\'\"](.*?)[\\'\"].*\\?>').match(xml_data)\nif not xml_encoding_match and isHTML:\n    regexp = re.compile('<\\s*meta[^>]+charset=([^>]*?)[;\\'\">]', re.I)\n    xml_encoding_match = regexp.search(xml_data)\nif xml_encoding_match is not None:\n    xml_encoding = xml_encoding_match.groups()[0].lower()\n    if isHTML:\n        self.declaredHTMLEncoding = xml_encoding\n    if sniffed_xml_encoding and \\\n       (xml_encoding in ('iso-10646-ucs-2', 'ucs-2', 'csunicode',\n                         'iso-10646-ucs-4', 'ucs-4', 'csucs4',\n                         'utf-16', 'utf-32', 'utf_16', 'utf_32',\n                         'utf16', 'u16')):\n        xml_encoding = sniffed_xml_encoding\nreturn xml_data, xml_encoding, sniffed_xml_encoding", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"Sets up the initial relations between this element and\nother elements.\"\"\"\n", "func_signal": "def setup(self, parent=None, previous=None):\n", "code": "self.parent = parent\nself.previous = previous\nself.next = None\nself.previousSibling = None\nself.nextSibling = None\nif self.parent and self.parent.contents:\n    self.previousSibling = self.parent.contents[-1]\n    self.previousSibling.nextSibling = self", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"Returns the closest sibling to this Tag that matches the\ngiven criteria and appears before this Tag in the document.\"\"\"\n", "func_signal": "def findPreviousSibling(self, name=None, attrs={}, text=None, **kwargs):\n", "code": "return self._findOne(self.findPreviousSiblings, name, attrs, text,\n                     **kwargs)", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "#print \"Push\", tag.name\n", "func_signal": "def pushTag(self, tag):\n", "code": "if self.currentTag:\n    self.currentTag.contents.append(tag)\nself.tagStack.append(tag)\nself.currentTag = self.tagStack[-1]", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"Destructively rips this element out of the tree.\"\"\"\n", "func_signal": "def extract(self):\n", "code": "if self.parent:\n    try:\n        self.parent.contents.remove(self)\n    except ValueError:\n        pass\n\n#Find the two elements that would be next to each other if\n#this element (and any children) hadn't been parsed. Connect\n#the two.\nlastChild = self._lastRecursiveChild()\nnextElement = lastChild.next\n\nif self.previous:\n    self.previous.next = nextElement\nif nextElement:\n    nextElement.previous = self.previous\nself.previous = None\nlastChild.next = None\n\nself.parent = None\nif self.previousSibling:\n    self.previousSibling.nextSibling = self.nextSibling\nif self.nextSibling:\n    self.nextSibling.previousSibling = self.previousSibling\nself.previousSibling = self.nextSibling = None\nreturn self", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "'''Given a string and its encoding, decodes the string into Unicode.\n%encoding is a string recognized by encodings.aliases'''\n\n# strip Byte Order Mark (if present)\n", "func_signal": "def _toUnicode(self, data, encoding):\n", "code": "if (len(data) >= 4) and (data[:2] == '\\xfe\\xff') \\\n       and (data[2:4] != '\\x00\\x00'):\n    encoding = 'utf-16be'\n    data = data[2:]\nelif (len(data) >= 4) and (data[:2] == '\\xff\\xfe') \\\n         and (data[2:4] != '\\x00\\x00'):\n    encoding = 'utf-16le'\n    data = data[2:]\nelif data[:3] == '\\xef\\xbb\\xbf':\n    encoding = 'utf-8'\n    data = data[3:]\nelif data[:4] == '\\x00\\x00\\xfe\\xff':\n    encoding = 'utf-32be'\n    data = data[4:]\nelif data[:4] == '\\xff\\xfe\\x00\\x00':\n    encoding = 'utf-32le'\n    data = data[4:]\nnewdata = unicode(data, encoding)\nreturn newdata", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "# Convert the document to Unicode.\n", "func_signal": "def _feed(self, inDocumentEncoding=None, isHTML=False):\n", "code": "markup = self.markup\nif isinstance(markup, unicode):\n    if not hasattr(self, 'originalEncoding'):\n        self.originalEncoding = None\nelse:\n    dammit = UnicodeDammit\\\n             (markup, [self.fromEncoding, inDocumentEncoding],\n              smartQuotesTo=self.smartQuotesTo, isHTML=isHTML)\n    markup = dammit.unicode\n    self.originalEncoding = dammit.originalEncoding\n    self.declaredHTMLEncoding = dammit.declaredHTMLEncoding\nif markup:\n    if self.markupMassage:\n        if not isList(self.markupMassage):\n            self.markupMassage = self.MARKUP_MASSAGE\n        for fix, m in self.markupMassage:\n            markup = fix.sub(m, markup)\n        # TODO: We get rid of markupMassage so that the\n        # soup object can be deepcopied later on. Some\n        # Python installations can't copy regexes. If anyone\n        # was relying on the existence of markupMassage, this\n        # might cause problems.\n        del(self.markupMassage)\nself.reset()\n\nSGMLParser.feed(self, markup)\n# Close out any unfinished strings and close all the open tags.\nself.endData()\nwhile self.currentTag.name != self.ROOT_TAG_NAME:\n    self.popTag()", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"Treat a bogus SGML declaration as raw data. Treat a CDATA\ndeclaration as a CData object.\"\"\"\n", "func_signal": "def parse_declaration(self, i):\n", "code": "j = None\nif self.rawdata[i:i+9] == '<![CDATA[':\n     k = self.rawdata.find(']]>', i)\n     if k == -1:\n         k = len(self.rawdata)\n     data = self.rawdata[i+9:k]\n     j = k+3\n     self._toStringSubclass(data, CData)\nelse:\n    try:\n        j = SGMLParser.parse_declaration(self, i)\n    except SGMLParseError:\n        toHandle = self.rawdata[i:]\n        self.handle_data(toHandle)\n        j = i + len(toHandle)\nreturn j", "path": "src\\sync\\lib\\BeautifulSoup.py", "repo_name": "nrolland/google-reader-iphone-sync", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 4147}
{"docstring": "\"\"\"\nCalculate the scale required for our printout to match what appears on screen,\nand the bounds that will be effective at that scale and margins\n\"\"\"\n# This code comes from Robin Dunn's \"wxPython In Action.\"\n# Without that, I would never have figured this out.\n", "func_signal": "def SetScaleAndBounds(self, dc):\n", "code": "ppiPrinterX, ppiPrinterY = self.GetPPIPrinter()\nppiScreenX, ppiScreenY = self.GetPPIScreen()\nlogicalScale = float(ppiPrinterX) / float(ppiScreenX)\npw, ph = self.GetPageSizePixels()\ndw, dh = dc.GetSize()\nscale = logicalScale * float(dw)/float(pw)\ndc.SetUserScale(scale, scale)\n\n# Now calculate our boundries\nlogicalUnitsMM = float(ppiPrinterX) / (logicalScale*25.4)\ntopLeft, bottomRight = self.margins\nleft = round(topLeft.x * logicalUnitsMM)\ntop = round(topLeft.y * logicalUnitsMM)\nright = round(dc.DeviceToLogicalYRel(dw) - bottomRight.x * logicalUnitsMM)\nbottom = round(dc.DeviceToLogicalYRel(dh) - bottomRight.y * logicalUnitsMM)\nself.bounds = (left, top, right-left, bottom-top)", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nCreate a watermark decoration, replacing any existing watermark\n\"\"\"\n", "func_signal": "def _CreateReplaceWatermarkDecoration(self):\n", "code": "pageFmt = self.GetNamedFormat(\"Page\")\npageFmt.decorations = [x for x in pageFmt.decorations if not isinstance(x, WatermarkDecoration)]\n\nwatermarkFmt = self.GetNamedFormat(\"Watermark\")\npageFmt.Add(WatermarkDecoration(self.watermark, font=watermarkFmt.Font,\n                                color=watermarkFmt.TextColor, angle=watermarkFmt.Angle,\n                                over=watermarkFmt.Over))", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nReturn a collection of Buckets that hold all the values of the\nsubclass-overridable collections above\n\"\"\"\n", "func_signal": "def GetCombinedLists(self):\n", "code": "buckets = [Bucket(cellWidth=x, text=\"\", align=None, image=None) for x in self.GetCellWidths()]\nfor (i, x) in enumerate(self.GetSubstitutedTexts()):\n    buckets[i].text = x\nfor (i, x) in enumerate(self.GetAlignments()):\n    buckets[i].align = x\n\nif self.IncludeImages():\n    for (i, x) in enumerate(self.GetImages()):\n        buckets[i].image = x\n\n# Calculate where the cell contents should be drawn\ncellPadding = self.GetFormat().CalculateCellPadding()\nfor x in buckets:\n    x.innerCellWidth = max(0, x.cellWidth - (cellPadding[0] + cellPadding[2]))\n\nreturn buckets", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nReturn the model objects that contain our text in one of the columns to consider\n\"\"\"\n", "func_signal": "def __call__(self, modelObjects):\n", "code": "if not self.text:\n    return modelObjects\n\n# In non-report views, we can only search the primary column\nif self.objectListView.InReportView():\n    cols = self.columns or self.objectListView.columns\nelse:\n    cols = [self.objectListView.columns[0]]\n\ntextToFind = self.text.lower()\n\ndef _containsText(modelObject):\n    for col in cols:\n        if textToFind in col.GetStringValue(modelObject).lower():\n            return True\n    return False\n\nreturn [x for x in modelObjects if _containsText(x)]", "path": "ObjectListView\\Filter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nReturn Colour that should be used to draw text in this block\n\"\"\"\n", "func_signal": "def GetTextColor(self):\n", "code": "color = None\nif self.engine.reportFormat.UseListCtrlTextFormat and self.GetListCtrl():\n    # Figure out what text colour is being used for this row in the list.\n    # Unfortunately, there is no one way to find this information: virtual mode lists\n    # have to be treated in a different manner from non-virtual lists.\n    listCtrl = self.GetListCtrl()\n    if listCtrl.IsVirtual():\n        attr = listCtrl.OnGetItemAttr(self.rowIndex)\n        if attr and attr.HasTextColour():\n            color = attr.GetTextColour()\n    else:\n        color = listCtrl.GetItemTextColour(self.rowIndex)\n\nif color and color.IsOk():\n    return color\nelse:\n    return self.GetFormat().GetTextColor()", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nPrint this Block.\n\nReturn True if the Block has finished printing\n\"\"\"\n", "func_signal": "def Print(self, dc):\n", "code": "if not self.ShouldPrint():\n    return True\n\nbounds = self.CalculateBounds(dc)\nif not self.CanFit(RectUtils.Height(bounds)):\n    return False\n\nif self.engine.shouldDrawBlocks:\n    self.PreDraw(dc, bounds)\n    self.Draw(dc, bounds)\n    self.PostDraw(dc, bounds)\n\nself.ChangeWorkBoundsBy(RectUtils.Height(bounds))\nreturn True", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nReturn a list indicating how the text within each cell is aligned.\n\"\"\"\n", "func_signal": "def GetAlignments(self):\n", "code": "if self.GetFormat().AlwaysCenter:\n    return [wx.ALIGN_CENTRE for i in range(self.left, self.right+1)]\nelse:\n    return self.GetColumnAlignments(self.lv, self.left, self.right)", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nReturn a reasonable default format for a report\n\"\"\"\n", "func_signal": "def TooMuch(headerFontName=\"Chiller\", rowFontName=\"Gill Sans\"):\n", "code": "fmt = ReportFormat()\nfmt.IsShrinkToFit = False\n\nfmt.PageHeader.Font = wx.FFont(12, wx.FONTFAMILY_DECORATIVE, wx.FONTFLAG_BOLD, face=headerFontName)\nfmt.PageHeader.TextColor = wx.WHITE\nfmt.PageHeader.Background(wx.GREEN, wx.RED, space=(16, 4, 0, 4))\nfmt.PageHeader.Padding = (0, 0, 0, 12)\n\nfmt.ListHeader.Font = wx.FFont(24, wx.FONTFAMILY_DECORATIVE, face=headerFontName)\nfmt.ListHeader.TextColor = wx.WHITE\nfmt.ListHeader.Padding = (0, 12, 0, 12)\nfmt.ListHeader.TextAlignment = wx.ALIGN_CENTER\nfmt.ListHeader.Background(wx.RED, wx.GREEN, space=(16, 4, 0, 4))\n\nfmt.GroupTitle.Font = wx.FFont(14, wx.FONTFAMILY_DECORATIVE, wx.FONTFLAG_BOLD, face=headerFontName)\nfmt.GroupTitle.TextColor = wx.BLUE\nfmt.GroupTitle.Padding = (0, 12, 0, 12)\nfmt.GroupTitle.Line(wx.BOTTOM, wx.GREEN, 4, toColor=wx.WHITE, space=5)\n\nfmt.PageFooter.Font = wx.FFont(10, wx.FONTFAMILY_DECORATIVE, face=headerFontName)\nfmt.PageFooter.Line(wx.TOP, wx.GREEN, 2, toColor=wx.RED, space=3)\nfmt.PageFooter.Padding = (0, 16, 0, 0)\n\nfmt.ColumnHeader.Font = wx.FFont(14, wx.FONTFAMILY_SWISS, wx.FONTFLAG_BOLD, face=headerFontName)\nfmt.ColumnHeader.Background(wx.Colour(255, 215, 0))\nfmt.ColumnHeader.CellPadding = 5\nfmt.ColumnHeader.GridPen = wx.Pen(wx.Colour(192, 192, 192), 1)\n\nfmt.Row.Font = wx.FFont(12, wx.FONTFAMILY_SWISS, face=rowFontName)\nfmt.Row.CellPadding = 5\nfmt.Row.GridPen = wx.Pen(wx.BLUE, 1, wx.DOT)\nfmt.Row.CanWrap = True\n\nfmt.Watermark.TextColor = wx.Colour(233, 150, 122)\n\nreturn fmt", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nShould this block be printed?\n\"\"\"\n# If the block has no text, it should not be printed\n", "func_signal": "def ShouldPrint(self):\n", "code": "if self.GetText():\n    return Block.ShouldPrint(self)\nelse:\n    return False", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nSet the texts that will be shown in various cells of the page footer.\n\nleftText can be a string or a 3-tuple of strings.\n\"\"\"\n", "func_signal": "def SetPageFooter(self, leftText=\"\", centerText=\"\", rightText=\"\"):\n", "code": "if isinstance(leftText, (tuple, list)):\n    self.engine.pageFooter = leftText\nelse:\n    self.engine.pageFooter = (leftText, centerText, rightText)", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nReturn a minimal format for a report\n\"\"\"\n", "func_signal": "def Minimal(headerFontName=\"Arial\", rowFontName=\"Times New Roman\"):\n", "code": "fmt = ReportFormat()\nfmt.IsShrinkToFit = False\n\nfmt.PageHeader.Font = wx.FFont(12, wx.FONTFAMILY_DEFAULT, face=headerFontName)\nfmt.PageHeader.Line(wx.BOTTOM, wx.BLACK, 1, space=5)\nfmt.PageHeader.Padding = (0, 0, 0, 12)\n\nfmt.ListHeader.Font = wx.FFont(18, wx.FONTFAMILY_DEFAULT, face=headerFontName)\nfmt.ListHeader.Padding = (0, 12, 0, 12)\nfmt.ListHeader.Line(wx.BOTTOM, wx.BLACK, 1, space=5)\n\nfmt.GroupTitle.Font = wx.FFont(12, wx.FONTFAMILY_DEFAULT, face=headerFontName)\nfmt.GroupTitle.Padding = (0, 12, 0, 12)\nfmt.GroupTitle.Line(wx.BOTTOM, wx.BLACK, 1, space=5)\n\nfmt.PageFooter.Font = wx.FFont(10, wx.FONTFAMILY_DEFAULT, face=headerFontName)\nfmt.PageFooter.Line(wx.TOP, wx.BLACK, 1, space=3)\nfmt.PageFooter.Padding = (0, 16, 0, 0)\n\nfmt.ColumnHeader.Font = wx.FFont(14, wx.FONTFAMILY_DEFAULT, wx.FONTFLAG_BOLD, face=headerFontName)\nfmt.ColumnHeader.Padding = (0, 12, 0, 12)\nfmt.ColumnHeader.CellPadding = 5\nfmt.ColumnHeader.Line(wx.BOTTOM, wx.Colour(192, 192, 192), 1, space=3)\nfmt.ColumnHeader.AlwaysCenter = True\n\nfmt.Row.Font = wx.FFont(10, wx.FONTFAMILY_DEFAULT, face=rowFontName)\nfmt.Row.CellPadding = 5\nfmt.Row.Line(wx.BOTTOM, wx.Colour(192, 192, 192), 1, space=3)\nfmt.Row.CanWrap = True\n\nreturn fmt", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nApply our scale before performing any drawing\n\"\"\"\n", "func_signal": "def PreDraw(self, dc, bounds):\n", "code": "self.oldScale = dc.GetUserScale()\ndc.SetUserScale(self.scale * self.oldScale[0], self.scale * self.oldScale[1])", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nReturn the height of the given txt in pixels\n\"\"\"\n", "func_signal": "def CalculateTextHeight(self, dc, txt, bounds=None, font=None):\n", "code": "bounds = bounds or self.GetReducedBlockBounds(dc)\nfont = font or self.GetFont()\ndc.SetFont(font)\nif self.GetFormat().CanWrap:\n    return WordWrapRenderer.CalculateHeight(dc, txt, RectUtils.Width(bounds))\nelse:\n    # Calculate the height of one line. The 1000 pixel width\n    # ensures that 'Wy' doesn't wrap, which might happen if bounds is narrow\n    return WordWrapRenderer.CalculateHeight(dc, \"Wy\", 1000)", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nDo the actual work of rendering this block.\n\"\"\"\n", "func_signal": "def DrawSelf(self, dc, bounds):\n", "code": "fmt = self.GetFormat()\nself.DrawText(dc, self.GetSubstitutedText(), bounds, canWrap=fmt.CanWrap, alignment=fmt.TextAlignment)", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nCalculate the rectangle that this decoration is going to paint\n\"\"\"\n", "func_signal": "def _CalculateRect(self, bounds):\n", "code": "if self.side is None:\n    return bounds\nif self.side == wx.LEFT:\n    return (RectUtils.Left(bounds), RectUtils.Top(bounds), self.width, RectUtils.Height(bounds))\nif self.side == wx.RIGHT:\n    return (RectUtils.Right(bounds) - self.width, RectUtils.Top(bounds), self.width, RectUtils.Height(bounds))\nif self.side == wx.TOP:\n    return (RectUtils.Left(bounds), RectUtils.Top(bounds), RectUtils.Width(bounds), self.width)\nif self.side == wx.BOTTOM:\n    return (RectUtils.Left(bounds), RectUtils.Bottom(bounds) - self.width, RectUtils.Width(bounds), self.width)\n\nreturn bounds", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nDraw the decoration\n\"\"\"\n", "func_signal": "def DrawDecoration(self, dc, bounds, block):\n", "code": "if not self.bitmap:\n    return\n\nif self.horizontalAlign == wx.LEFT:\n    x = RectUtils.Left(bounds)\nelif self.horizontalAlign == wx.RIGHT:\n    x = RectUtils.Right(bounds) - self.bitmap.Width\nelse:\n    x = RectUtils.CenterX(bounds) - self.bitmap.Width/2\n\nif self.verticalAlign == wx.TOP:\n    y = RectUtils.Top(bounds)\nelif self.verticalAlign == wx.BOTTOM:\n    y = RectUtils.Bottom(bounds) - self.bitmap.Height\nelse:\n    y = RectUtils.CenterY(bounds) - self.bitmap.Height/2\n\ndc.DrawBitmap(self.bitmap, x, y, True)", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nDraw this decoration\n\"\"\"\n", "func_signal": "def DrawDecoration(self, dc, bounds, block):\n", "code": "if self.pen == None:\n    return\n\nif self.side == wx.LEFT:\n    pt1 = RectUtils.TopLeft(bounds)\n    pt2 = RectUtils.BottomLeft(bounds)\nelif self.side == wx.RIGHT:\n    pt1 = RectUtils.TopRight(bounds)\n    pt2 = RectUtils.BottomRight(bounds)\nelif self.side == wx.TOP:\n    pt1 = RectUtils.TopLeft(bounds)\n    pt2 = RectUtils.TopRight(bounds)\nelif self.side == wx.BOTTOM:\n    pt1 = RectUtils.BottomLeft(bounds)\n    pt2 = RectUtils.BottomRight(bounds)\n\ndc.SetPen(self.pen)\ndc.DrawLine(pt1[0], pt1[1], pt2[0], pt2[1])", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nAdd a line to our decorations.\nIf a pen is given, we use a straight Line decoration, otherwise we use a\ncoloured rectangle\n\"\"\"\n", "func_signal": "def Line(self, side=wx.BOTTOM, color=wx.BLACK, width=1, toColor=None, space=0, pen=None):\n", "code": "if pen:\n    self.Add(LineDecoration(side, pen, space))\nelse:\n    self.Add(RectangleDecoration(side, None, color, toColor, width, space))", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nReturn Font that should be used to draw text in this block\n\"\"\"\n", "func_signal": "def GetFont(self):\n", "code": "font = None\nif self.engine.reportFormat.UseListCtrlTextFormat and self.GetListCtrl():\n    # Figure out what font is being used for this row in the list.\n    # Unfortunately, there is no one way to find this information: virtual mode lists\n    # have to be treated in a different manner from non-virtual lists.\n    listCtrl = self.GetListCtrl()\n    if listCtrl.IsVirtual():\n        attr = listCtrl.OnGetItemAttr(self.rowIndex)\n        if attr and attr.HasFont():\n            font = attr.GetFont()\n    else:\n        font = listCtrl.GetItemFont(self.rowIndex)\n\nif font and font.IsOk():\n    return font\nelse:\n    return self.GetFormat().GetFont()", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"\nReturn a list of the widths of the cells in this block\n\"\"\"\n# We divide the available space between the non-empty cells\n", "func_signal": "def GetCellWidths(self):\n", "code": "numNonEmptyTexts = sum(1 for x in self.GetTexts() if x)\nif not numNonEmptyTexts:\n    return (0, 0, 0)\n\nwidths = list()\nwidth = round(RectUtils.Width(self.GetWorkBounds()) / numNonEmptyTexts)\nfor x in self.GetTexts():\n    if x:\n        widths.append(width)\n    else:\n        widths.append(0)\nreturn widths", "path": "ObjectListView\\ListCtrlPrinter.py", "repo_name": "batok/objectlistview-mirror", "stars": 2, "license": "other", "language": "python", "size": 2416}
{"docstring": "\"\"\"_handle_long_word(chunks : [string],\n                     cur_line : [string],\n                     cur_len : int, width : int)\n\nHandle a chunk of text (most likely a word, not whitespace) that\nis too long to fit in any line.\n\"\"\"\n", "func_signal": "def _handle_long_word(self, chunks, cur_line, cur_len, width):\n", "code": "space_left = max(width - cur_len, 1)\n\n# If we're allowed to break long words, then do so: put as much\n# of the next chunk onto the current line as will fit.\nif self.break_long_words:\n    cur_line.append(chunks[0][0:space_left])\n    chunks[0] = chunks[0][space_left:]\n\n# Otherwise, we have to preserve the long word intact.  Only add\n# it to the current line if there's nothing already there --\n# that minimizes how much we violate the width constraint.\nelif not cur_line:\n    cur_line.append(chunks.pop(0))\n\n# If we're not allowed to break long words, and there's already\n# text on the current line, do nothing.  Next time through the\n# main loop of _wrap_chunks(), we'll wind up here again, but\n# cur_len will be zero, so the next line will be entirely\n# devoted to the long word that we can't handle right now.", "path": "koan\\text_wrap.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"Wait for child process to terminate.  Returns returncode\nattribute.\"\"\"\n", "func_signal": "def wait(self):\n", "code": "if self.returncode == None:\n    pid, sts = os.waitpid(self.pid, 0)\n    self._handle_exitstatus(sts)\nreturn self.returncode", "path": "koan\\sub_process.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"Construct and return tupel with IO objects:\np2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite\n\"\"\"\n", "func_signal": "def _get_handles(self, stdin, stdout, stderr):\n", "code": "p2cread, p2cwrite = None, None\nc2pread, c2pwrite = None, None\nerrread, errwrite = None, None\n\nif stdin == None:\n    pass\nelif stdin == PIPE:\n    p2cread, p2cwrite = os.pipe()\nelif type(stdin) == types.IntType:\n    p2cread = stdin\nelse:\n    # Assuming file-like object\n    p2cread = stdin.fileno()\n\nif stdout == None:\n    pass\nelif stdout == PIPE:\n    c2pread, c2pwrite = os.pipe()\nelif type(stdout) == types.IntType:\n    c2pwrite = stdout\nelse:\n    # Assuming file-like object\n    c2pwrite = stdout.fileno()\n\nif stderr == None:\n    pass\nelif stderr == PIPE:\n    errread, errwrite = os.pipe()\nelif stderr == STDOUT:\n    errwrite = c2pwrite\nelif type(stderr) == types.IntType:\n    errwrite = stderr\nelse:\n    # Assuming file-like object\n    errwrite = stderr.fileno()\n\nreturn (p2cread, p2cwrite,\n        c2pread, c2pwrite,\n        errread, errwrite)", "path": "koan\\sub_process.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"Return a duplicate of handle, which is inheritable\"\"\"\n", "func_signal": "def _make_inheritable(self, handle):\n", "code": "return DuplicateHandle(GetCurrentProcess(), handle,\n                       GetCurrentProcess(), 0, 1,\n                       DUPLICATE_SAME_ACCESS)", "path": "koan\\sub_process.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"_munge_whitespace(text : string) -> string\n\nMunge whitespace in text: expand tabs and convert all other\nwhitespace characters to spaces.  Eg. \" foo\\tbar\\n\\nbaz\"\nbecomes \" foo    bar  baz\".\n\"\"\"\n", "func_signal": "def _munge_whitespace(self, text):\n", "code": "if self.expand_tabs:\n    text = text.expandtabs()\nif self.replace_whitespace:\n    if isinstance(text, str):\n        text = text.translate(self.whitespace_trans)\n    elif isinstance(text, unicode):\n        text = text.translate(self.unicode_whitespace_trans)\nreturn text", "path": "koan\\text_wrap.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"Find and return absolut path to w9xpopen.exe\"\"\"\n", "func_signal": "def _find_w9xpopen(self):\n", "code": "w9xpopen = os.path.join(os.path.dirname(GetModuleFileName(0)),\n                        \"w9xpopen.exe\")\nif not os.path.exists(w9xpopen):\n    # Eeek - file-not-found - possibly an embedding\n    # situation - see if we can locate it in sys.exec_prefix\n    w9xpopen = os.path.join(os.path.dirname(sys.exec_prefix),\n                            \"w9xpopen.exe\")\n    if not os.path.exists(w9xpopen):\n        raise RuntimeError(\"Cannot locate w9xpopen.exe, which is \"\n                           \"needed for Popen to work with your \"\n                           \"shell or platform.\")\nreturn w9xpopen", "path": "koan\\sub_process.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"_wrap_chunks(chunks : [string]) -> [string]\n\nWrap a sequence of text chunks and return a list of lines of\nlength 'self.width' or less.  (If 'break_long_words' is false,\nsome lines may be longer than this.)  Chunks correspond roughly\nto words and the whitespace between them: each chunk is\nindivisible (modulo 'break_long_words'), but a line break can\ncome between any two chunks.  Chunks should not have internal\nwhitespace; ie. a chunk is either all whitespace or a \"word\".\nWhitespace chunks will be removed from the beginning and end of\nlines, but apart from that whitespace is preserved.\n\"\"\"\n", "func_signal": "def _wrap_chunks(self, chunks):\n", "code": "lines = []\nif self.width <= 0:\n    raise ValueError(\"invalid width %r (must be > 0)\" % self.width)\n\nwhile chunks:\n\n    # Start the list of chunks that will make up the current line.\n    # cur_len is just the length of all the chunks in cur_line.\n    cur_line = []\n    cur_len = 0\n\n    # Figure out which static string will prefix this line.\n    if lines:\n        indent = self.subsequent_indent\n    else:\n        indent = self.initial_indent\n\n    # Maximum width for this line.\n    width = self.width - len(indent)\n\n    # First chunk on line is whitespace -- drop it, unless this\n    # is the very beginning of the text (ie. no lines started yet).\n    if chunks[0].strip() == '' and lines:\n        del chunks[0]\n\n    while chunks:\n        l = len(chunks[0])\n\n        # Can at least squeeze this chunk onto the current line.\n        if cur_len + l <= width:\n            cur_line.append(chunks.pop(0))\n            cur_len += l\n\n        # Nope, this line is full.\n        else:\n            break\n\n    # The current line is full, and the next chunk is too big to\n    # fit on *any* line (not just this one).\n    if chunks and len(chunks[0]) > width:\n        self._handle_long_word(chunks, cur_line, cur_len, width)\n\n    # If the last chunk on this line is all whitespace, drop it.\n    if cur_line and cur_line[-1].strip() == '':\n        del cur_line[-1]\n\n    # Convert current line back to a string and store it in list\n    # of all lines (return value).\n    if cur_line:\n        lines.append(indent + ''.join(cur_line))\n\nreturn lines", "path": "koan\\text_wrap.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"\nTranslate a sequence of arguments into a command line\nstring, using the same rules as the MS C runtime:\n\n1) Arguments are delimited by white space, which is either a\n   space or a tab.\n\n2) A string surrounded by double quotation marks is\n   interpreted as a single argument, regardless of white space\n   contained within.  A quoted string can be embedded in an\n   argument.\n\n3) A double quotation mark preceded by a backslash is\n   interpreted as a literal double quotation mark.\n\n4) Backslashes are interpreted literally, unless they\n   immediately precede a double quotation mark.\n\n5) If backslashes immediately precede a double quotation mark,\n   every pair of backslashes is interpreted as a literal\n   backslash.  If the number of backslashes is odd, the last\n   backslash escapes the next double quotation mark as\n   described in rule 3.\n\"\"\"\n\n# See\n# http://msdn.microsoft.com/library/en-us/vccelng/htm/progs_12.asp\n", "func_signal": "def list2cmdline(seq):\n", "code": "result = []\nneedquote = False\nfor arg in seq:\n    bs_buf = []\n\n    # Add a space to separate this argument from the others\n    if result:\n        result.append(' ')\n\n    needquote = (\" \" in arg) or (\"\\t\" in arg)\n    if needquote:\n        result.append('\"')\n\n    for c in arg:\n        if c == '\\\\':\n            # Don't know if we need to double yet.\n            bs_buf.append(c)\n        elif c == '\"':\n            # Double backspaces.\n            result.append('\\\\' * len(bs_buf)*2)\n            bs_buf = []\n            result.append('\\\\\"')\n        else:\n            # Normal char\n            if bs_buf:\n                result.extend(bs_buf)\n                bs_buf = []\n            result.append(c)\n\n    # Add remaining backspaces, if any.\n    if bs_buf:\n        result.extend(bs_buf)\n\n    if needquote:\n        result.extend(bs_buf)\n        result.append('\"')\n\nreturn ''.join(result)", "path": "koan\\sub_process.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"_fix_sentence_endings(chunks : [string])\n\nCorrect for sentence endings buried in 'chunks'.  Eg. when the\noriginal text contains \"... foo.\\nBar ...\", munge_whitespace()\nand split() will convert that to [..., \"foo.\", \" \", \"Bar\", ...]\nwhich has one too few spaces; this method simply changes the one\nspace to two.\n\"\"\"\n", "func_signal": "def _fix_sentence_endings(self, chunks):\n", "code": "i = 0\npat = self.sentence_end_re\nwhile i < len(chunks)-1:\n    if chunks[i+1] == \" \" and pat.search(chunks[i]):\n        chunks[i+1] = \"  \"\n        i += 2\n    else:\n        i += 1", "path": "koan\\text_wrap.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"Wrap a single paragraph of text, returning a list of wrapped lines.\n\nReformat the single paragraph in 'text' so it fits in lines of no\nmore than 'width' columns, and return a list of wrapped lines.  By\ndefault, tabs in 'text' are expanded with string.expandtabs(), and\nall other whitespace characters (including newline) are converted to\nspace.  See TextWrapper class for available keyword args to customize\nwrapping behaviour.\n\"\"\"\n", "func_signal": "def wrap(text, width=70, **kwargs):\n", "code": "w = TextWrapper(width=width, **kwargs)\nreturn w.wrap(text)", "path": "koan\\text_wrap.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"Construct and return tupel with IO objects:\np2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite\n\"\"\"\n", "func_signal": "def _get_handles(self, stdin, stdout, stderr):\n", "code": "if stdin == None and stdout == None and stderr == None:\n    return (None, None, None, None, None, None)\n\np2cread, p2cwrite = None, None\nc2pread, c2pwrite = None, None\nerrread, errwrite = None, None\n\nif stdin == None:\n    p2cread = GetStdHandle(STD_INPUT_HANDLE)\nelif stdin == PIPE:\n    p2cread, p2cwrite = CreatePipe(None, 0)\n    # Detach and turn into fd\n    p2cwrite = p2cwrite.Detach()\n    p2cwrite = msvcrt.open_osfhandle(p2cwrite, 0)\nelif type(stdin) == types.IntType:\n    p2cread = msvcrt.get_osfhandle(stdin)\nelse:\n    # Assuming file-like object\n    p2cread = msvcrt.get_osfhandle(stdin.fileno())\np2cread = self._make_inheritable(p2cread)\n\nif stdout == None:\n    c2pwrite = GetStdHandle(STD_OUTPUT_HANDLE)\nelif stdout == PIPE:\n    c2pread, c2pwrite = CreatePipe(None, 0)\n    # Detach and turn into fd\n    c2pread = c2pread.Detach()\n    c2pread = msvcrt.open_osfhandle(c2pread, 0)\nelif type(stdout) == types.IntType:\n    c2pwrite = msvcrt.get_osfhandle(stdout)\nelse:\n    # Assuming file-like object\n    c2pwrite = msvcrt.get_osfhandle(stdout.fileno())\nc2pwrite = self._make_inheritable(c2pwrite)\n\nif stderr == None:\n    errwrite = GetStdHandle(STD_ERROR_HANDLE)\nelif stderr == PIPE:\n    errread, errwrite = CreatePipe(None, 0)\n    # Detach and turn into fd\n    errread = errread.Detach()\n    errread = msvcrt.open_osfhandle(errread, 0)\nelif stderr == STDOUT:\n    errwrite = c2pwrite\nelif type(stderr) == types.IntType:\n    errwrite = msvcrt.get_osfhandle(stderr)\nelse:\n    # Assuming file-like object\n    errwrite = msvcrt.get_osfhandle(stderr.fileno())\nerrwrite = self._make_inheritable(errwrite)\n\nreturn (p2cread, p2cwrite,\n        c2pread, c2pwrite,\n        errread, errwrite)", "path": "koan\\sub_process.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"dedent(text : string) -> string\n\nRemove any whitespace than can be uniformly removed from the left\nof every line in `text`.\n\nThis can be used e.g. to make triple-quoted strings line up with\nthe left edge of screen/whatever, while still presenting it in the\nsource code in indented form.\n\nFor example:\n\n    def test():\n        # end first line with \\ to avoid the empty line!\n        s = '''\\\n        hello\n          world\n        '''\n        print repr(s)          # prints '    hello\\n      world\\n    '\n        print repr(dedent(s))  # prints 'hello\\n  world\\n'\n\"\"\"\n", "func_signal": "def dedent(text):\n", "code": "lines = text.expandtabs().split('\\n')\nmargin = None\nfor line in lines:\n    content = line.lstrip()\n    if not content:\n        continue\n    indent = len(line) - len(content)\n    if margin is None:\n        margin = indent\n    else:\n        margin = min(margin, indent)\n\nif margin is not None and margin > 0:\n    for i in range(len(lines)):\n        lines[i] = lines[i][margin:]\n\nreturn '\\n'.join(lines)", "path": "koan\\text_wrap.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"Fill a single paragraph of text, returning a new string.\n\nReformat the single paragraph in 'text' to fit in lines of no more\nthan 'width' columns, and return a new string containing the entire\nwrapped paragraph.  As with wrap(), tabs are expanded and other\nwhitespace characters converted to space.  See TextWrapper class for\navailable keyword args to customize wrapping behaviour.\n\"\"\"\n", "func_signal": "def fill(text, width=70, **kwargs):\n", "code": "w = TextWrapper(width=width, **kwargs)\nreturn w.fill(text)", "path": "koan\\text_wrap.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"Interact with process: Send data to stdin.  Read data from\nstdout and stderr, until end-of-file is reached.  Wait for\nprocess to terminate.  The optional input argument should be a\nstring to be sent to the child process, or None, if no data\nshould be sent to the child.\n\ncommunicate() returns a tuple (stdout, stderr).\"\"\"\n", "func_signal": "def communicate(self, input=None):\n", "code": "read_set = []\nwrite_set = []\nstdout = None # Return\nstderr = None # Return\n\nif self.stdin:\n    # Flush stdio buffer.  This might block, if the user has\n    # been writing to .stdin in an uncontrolled fashion.\n    self.stdin.flush()\n    if input:\n        write_set.append(self.stdin)\n    else:\n        self.stdin.close()\nif self.stdout:\n    read_set.append(self.stdout)\n    stdout = []\nif self.stderr:\n    read_set.append(self.stderr)\n    stderr = []\n\nwhile read_set or write_set:\n    rlist, wlist, xlist = select.select(read_set, write_set, [])\n\n    if self.stdin in wlist:\n        # When select has indicated that the file is writable,\n        # we can write up to PIPE_BUF bytes without risk\n        # blocking.  POSIX defines PIPE_BUF >= 512\n        bytes_written = os.write(self.stdin.fileno(), input[:512])\n        input = input[bytes_written:]\n        if not input:\n            self.stdin.close()\n            write_set.remove(self.stdin)\n\n    if self.stdout in rlist:\n        data = os.read(self.stdout.fileno(), 1024)\n        if data == \"\":\n            self.stdout.close()\n            read_set.remove(self.stdout)\n        stdout.append(data)\n\n    if self.stderr in rlist:\n        data = os.read(self.stderr.fileno(), 1024)\n        if data == \"\":\n            self.stderr.close()\n            read_set.remove(self.stderr)\n        stderr.append(data)\n\n# All data exchanged.  Translate lists into strings.\nif stdout != None:\n    stdout = ''.join(stdout)\nif stderr != None:\n    stderr = ''.join(stderr)\n\n# Translate newlines, if requested.  We cannot let the file\n# object do the translation: It is based on stdio, which is\n# impossible to combine with select (unless forcing no\n# buffering).\nif self.universal_newlines and hasattr(open, 'newlines'):\n    if stdout:\n        stdout = self._translate_newlines(stdout)\n    if stderr:\n        stderr = self._translate_newlines(stderr)\n\nself.wait()\nreturn (stdout, stderr)", "path": "koan\\sub_process.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"wrap(text : string) -> [string]\n\nReformat the single paragraph in 'text' so it fits in lines of\nno more than 'self.width' columns, and return a list of wrapped\nlines.  Tabs in 'text' are expanded with string.expandtabs(),\nand all other whitespace characters (including newline) are\nconverted to space.\n\"\"\"\n", "func_signal": "def wrap(self, text):\n", "code": "text = self._munge_whitespace(text)\nindent = self.initial_indent\nchunks = self._split(text)\nif self.fix_sentence_endings:\n    self._fix_sentence_endings(chunks)\nreturn self._wrap_chunks(chunks)", "path": "koan\\text_wrap.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"Interact with process: Send data to stdin.  Read data from\nstdout and stderr, until end-of-file is reached.  Wait for\nprocess to terminate.  The optional input argument should be a\nstring to be sent to the child process, or None, if no data\nshould be sent to the child.\n\ncommunicate() returns a tuple (stdout, stderr).\"\"\"\n", "func_signal": "def communicate(self, input=None):\n", "code": "stdout = None # Return\nstderr = None # Return\n\nif self.stdout:\n    stdout = []\n    stdout_thread = threading.Thread(target=self._readerthread,\n                                     args=(self.stdout, stdout))\n    stdout_thread.setDaemon(True)\n    stdout_thread.start()\nif self.stderr:\n    stderr = []\n    stderr_thread = threading.Thread(target=self._readerthread,\n                                     args=(self.stderr, stderr))\n    stderr_thread.setDaemon(True)\n    stderr_thread.start()\n\nif self.stdin:\n    if input != None:\n        self.stdin.write(input)\n    self.stdin.close()\n\nif self.stdout:\n    stdout_thread.join()\nif self.stderr:\n    stderr_thread.join()\n\n# All data exchanged.  Translate lists into strings.\nif stdout != None:\n    stdout = stdout[0]\nif stderr != None:\n    stderr = stderr[0]\n\n# Translate newlines, if requested.  We cannot let the file\n# object do the translation: It is based on stdio, which is\n# impossible to combine with select (unless forcing no\n# buffering).\nif self.universal_newlines and hasattr(open, 'newlines'):\n    if stdout:\n        stdout = self._translate_newlines(stdout)\n    if stderr:\n        stderr = self._translate_newlines(stderr)\n\nself.wait()\nreturn (stdout, stderr)", "path": "koan\\sub_process.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"Check if child process has terminated.  Returns returncode\nattribute.\"\"\"\n", "func_signal": "def poll(self):\n", "code": "if self.returncode == None:\n    if WaitForSingleObject(self._handle, 0) == WAIT_OBJECT_0:\n        self.returncode = GetExitCodeProcess(self._handle)\n        _active.remove(self)\nreturn self.returncode", "path": "koan\\sub_process.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"Wait for child process to terminate.  Returns returncode\nattribute.\"\"\"\n", "func_signal": "def wait(self):\n", "code": "if self.returncode == None:\n    obj = WaitForSingleObject(self._handle, INFINITE)\n    self.returncode = GetExitCodeProcess(self._handle)\n    _active.remove(self)\nreturn self.returncode", "path": "koan\\sub_process.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"_split(text : string) -> [string]\n\nSplit the text to wrap into indivisible chunks.  Chunks are\nnot quite the same as words; see wrap_chunks() for full\ndetails.  As an example, the text\n  Look, goof-ball -- use the -b option!\nbreaks into the following chunks:\n  'Look,', ' ', 'goof-', 'ball', ' ', '--', ' ',\n  'use', ' ', 'the', ' ', '-b', ' ', 'option!'\n\"\"\"\n", "func_signal": "def _split(self, text):\n", "code": "chunks = self.wordsep_re.split(text)\nchunks = filter(None, chunks)\nreturn chunks", "path": "koan\\text_wrap.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"Check if child process has terminated.  Returns returncode\nattribute.\"\"\"\n", "func_signal": "def poll(self):\n", "code": "if self.returncode == None:\n    try:\n        pid, sts = os.waitpid(self.pid, os.WNOHANG)\n        if pid == self.pid:\n            self._handle_exitstatus(sts)\n    except os.error:\n        pass\nreturn self.returncode", "path": "koan\\sub_process.py", "repo_name": "charles-dyfis-net/koan", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 460}
{"docstring": "\"\"\"\nparabolic_flow_coeffs(f(x), t, x)\n\"\"\"\n# get parabolic IDM, checks parabolic-ness\n", "func_signal": "def parabolic_flow_coeffs(expr, t, x, x0=0, n=5):\n", "code": "idm = parabolic_IDM(expr, x, x0, n)\n\n# use Jabotinsky's formula (requires IDM)\nret = [sum([(-1)**(m-k-1)*idm[k][m]*\n    binomial(t, k)*binomial(t-k-1, m-k-1)\n    for k in xrange(m)]) for m in xrange(n)]\nreturn ret", "path": "iteration\\parabolic.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\na_poly(x) -- Arbitrary polynomial, with coeffs C1, C2, ...\na_poly(x, n) -- Degree n polynomial, with coeffs C1, C2, ...\na_poly(x, n, [a, b]) -- A polynomial starting with a + b*x + ...\n\"\"\"\n", "func_signal": "def a_poly(x, n=5, coeff=[]):\n", "code": "if len(coeff) > n: n = len(coeff)\nhead = [coeff[i]*x**i \n        for i in xrange(len(coeff))]\ntail = [var('C' + str(i))*x**i \n        for i in xrange(len(coeff), n + 1)]\nreturn sum(head + tail)", "path": "polynomial.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nhyperbolic_flow(f(x), t, x)\n\nThe power series (flow) for a hyperbolic function.\nCurrently only implemented for a fixed point of 0.\n\"\"\"\n# checks hyperbolic-ness\n", "func_signal": "def hyperbolic_flow(expr, t, x, x0=0, n=5):\n", "code": "coeffs = hyperbolic_flow_coeffs(expr, t, x, x0, n)\nreturn sum([coeffs[k]*(x - x0)**k for k in xrange(n + 1)])", "path": "iteration\\hyperbolic.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nInitialization by finite sequence of coefficients:\nExamples:\nsage: from powerseries import PowerSeriesI\nsage: PowerSeriesI([1,2,3])\n[1, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\nsage: PowerSeriesI()\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n\nInitialization by coefficient function:\nExample:\nsage: PowerSeriesI(lambda n: 1/factorial(n))\n[1, 1, 1/2, 1/6, 1/24, 1/120, 1/720, 1/5040, 1/40320, 1/362880, 1/3628800, ...]\n\nInitialization by expresion:\nExamples:\nsage: PowerSeriesI(1+2*x+3*x^2,x)\n[1, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\nsage: PowerSeriesI(exp(x),x)\n[1, 1, 1/2, 1/6, 1/24, 1/120, 1/720, 1/5040, 1/40320, 1/362880, 1/3628800, ...]\nsage: PowerSeriesI(ln(x),x,1)\n[0, 1, -1/2, 1/3, -1/4, 1/5, -1/6, 1/7, -1/8, 1/9, -1/10, 1/11, -1/12, ...]\n\nNote: This is much slower than directly providing the coefficient function. \n\n\"\"\"\n", "func_signal": "def __init__(self,p=[],var='_undef',at=0):\n", "code": "self._memo = {}\nself._powMemo = {}\nself._itMemo = {}\nif isinstance(p,list):\n    def f(n):\n        if n<len(p):\n            return p[n]\n        else:\n            return 0\n    self.f = f\n    return\nif isinstance(p,SymbolicExpression):\n    assert not var == '_undef'\n    expr=p\n    assert isinstance(var,SymbolicVariable)\n    def f(n):\n        return diff(expr,var,n).substitute({var:at})/factorial(n)\n    self.f = f\n    return\nif type(p) is type(lambda n: 0):\n    self.f = p", "path": "powerseries.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nAn implementation of the regular super log which uses a\nsuitable regular Schroeder function.\n\nb can be an expression that is evaluated with type of x .\nIt has to satisfy -e < ln(b) < 1/e.\nThe precision of the outcome is determined by the precision of x.\nFor example:\n\nrslog2(log(2))(RealField(100)(0.5))\n\"\"\"\n", "func_signal": "def rslog2(b):\n", "code": "f=lambda x: x.parent()(b)**x\ns=reg_schroeder(f)\ndef r(x,iprec='_default'):\n    prec = x.prec()\n    if iprec == '_default':\n        iprec = prec + 4\n    R=type(x.parent())(iprec)\n\n    [a,y]=s(R(x),1,out=1)\n    return x.parent()(log(y,log(a)))\nreturn r", "path": "regit.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nLambertW(x) -- base-e product logarithm\n\"\"\"\n# FIXME: this needs work\n#w = var('w')\n#return series_inverse(w*e^w, x, w)\n", "func_signal": "def LambertW(x, k=0):\n", "code": "if x == 0: return 0\nreturn LambertW_by_iteration(x, guess=LambertW_by_desy(x))\n#return KnoebelH(exp(-x), k)*x", "path": "special\\function.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nSubtraction:\n\"\"\"\n", "func_signal": "def __sub__(a,b):\n", "code": "def ret(n):\n    return a[n]-b[n]\nreturn PowerSeriesI(ret)", "path": "powerseries.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nAn implementation of the regular super log which uses the\nprincipial Schroeder function.\n\nb can be an expression that is evaluated with type of x.\nThe precision of the outcome is determined by the precision of x.\nFor example:\n\nrslog1(log(2))(RealField(100)(0.5))\n\"\"\"\n", "func_signal": "def rslog1(b):\n", "code": "f=lambda x: x.parent()(b)**x\ns=princ_schroeder(f)\ns1cache = {}\ndef r(x,iprec='_default'):\n    prec = x.prec()\n    if iprec == '_default':\n        iprec = prec+4\n    R=type(x.parent())(iprec)\n    \n    if not s1cache.has_key(prec):\n        s1cache[prec]=s(R(1))\n    s1=s1cache[prec]\n\n    [a,c,y]=s(R(x),out=1)\n    return log(y/s1,c)\nreturn r", "path": "regit.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nKnoebelH(x) -- infinitely iterated exponential\n\nThe Knoebel H function, also known as the infinite tetrate, or\nthe infinitely iterated exponential, is defined as (x^^oo),\nbut we use a different algorithm, obviously.\n\"\"\"\n# FIXME: this needs work\n", "func_signal": "def KnoebelH(x, k=0):\n", "code": "if x == 1:\n    return 1\nelif x < 1/e:\n    raise NotImplemented\nelse:\n    return KnoebelH_by_iteration(x)\n#return -LambertW(-log(x), k)/log(x)", "path": "special\\function.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nhyper_HD_simple(base, height, rank)\n\nThis function is only defined for ranks between 2, 3.\nFor many bases, this will make a smooth curve between\nmultiplication (rank=2) and exponentiation (rank=3).\n\"\"\"\n", "func_signal": "def hyper_HD_simple(b, h, rank=3):\n", "code": "if rank == 2:\n    return b*h\nelif rank == 3:\n    return b**h\nelse:\n    return (b*h)*cos(rank*pi/2)**2 + (b**h)*sin(rank*pi/2)**2", "path": "hyper.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nis_hyperbolic(f(x), x, x0) -- is x0 a hyperbolic fixed point of f?\n\"\"\"\n", "func_signal": "def is_hyperbolic(expr, x, x0):\n", "code": "if expr.subs(x=x0) != x0:\n    return False\nif diff(expr, x).subs(x=x0) == 1:\n    return False\nreturn True", "path": "iteration\\hyperbolic.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nnatural_Schroeder_function(f(x), x)\n\nReturns a function, so to use this, write:\n    s = natural_Schroeder_function(f(x), x)\nthen you can do things like s(0), s(x), etc...\n\"\"\"\n", "func_signal": "def natural_Schroeder_function(expr, x, x0=0, n=5, fp=None, ring=None):\n", "code": "abel = natural_Abel_function(expr, x, x0, n)\nif not fp == None:\n    fp = diff(expr, x).subs(x=x0)\ndef ret(xf):\n    return fp**abel(xf)\nreturn ret", "path": "iteration\\natural.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nTakes a function f with f(0)==0 and 0<|f'(0)|<1 and an initial value x0!=a.\nComputes the regular Schroeder function s that is determined by s(x0)=1\n\"\"\"\n\n", "func_signal": "def reg_schroeder_at(f,x0,a=0):\n", "code": "def r(x,iprec='_default'):\n    prec = x.prec()\n    if iprec == '_default':\n        iprec = 3*prec #heuristic\n    R=type(x.parent())(iprec)\n\n    _check_funcprec(f,x,R)\n\n    itf=R(x)\n    itf0=R(x0)\n    yp = (a-x)/(a-x0)\n    if yp == 1:\n        return 1\n    if yp > 1:\n        signum = 1\n    else:\n        signum = -1\n\n    while True:\n        itf=f(itf)\n        itf0=f(itf0)\n        y=(a-itf)/(a-itf0)\n        \n        #print y.prec(),itf.prec(),itf,itf0,y\n        d = yp - y\n        if d*signum < 0:\n            raise ZeroDivisionError\n        if d*signum < 2**(-prec):\n            break\n        yp=y\n    return x.parent()(y)\n    \nreturn r", "path": "regit.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nMultiplication:\nIf b is a powerseries then powerseries multiplication\nif b is a scalar then just multiply each coefficient by that scalar\nin that case: a*b=a*PowerSeriesI([b])\n\"\"\"\n", "func_signal": "def __mul__(a,b):\n", "code": "scalar = True\ntry:\n    c=a[0]*b\nexcept TypeError:\n    scalar = False\n\n#multiplication by scalar\nif scalar: return PowerSeriesI(lambda n: a[n]*b)\n\n#multiplication of two powerseries\n#maybe necessary to avoid evaluation of a(n) or b(n)\nif a[0] == 0 and b[0] == 0:\n    def ret(n):\n        return sum(a[k]*b[n-k] for k in range(1,n))\nelse:\n    def ret(n):\n        return sum(a[k]*b[n-k] for k in range(n+1))\nreturn PowerSeriesI(ret)", "path": "powerseries.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nparabolic_flow_matrix(f(x), t, x)\n\nThe flow matrix for a parabolic function,\nbasically the coefficients of x and t.\n\nThis takes the flow coefficients (1-D list)\nand 'creates' a dimension (2-D matrix).\n\"\"\"\n# this also checks parabolic-ness\n", "func_signal": "def parabolic_flow_matrix(expr, t, x, x0=0, n=5):\n", "code": "coeffs = parabolic_flow_coeffs(expr, t, x, x0, n)\nret = []\n\n# # extract coeffs from series\n# coeffs = ser.coeffs(x)\n# coeffs2 = [0 for k in xrange(n + 1)]\n# for cof in coeffs:\n#     try:\n#         coeffs2[cof[1]] = cof[0]\n#     except:\n#         pass\n\nfor i in xrange(n):\n    if (i < 2):\n        ret.append([coeffs[i]])\n    else:\n        ser = coeffs[i]\n        # cof = coeffs[i].expand().coeffs(t)\n        # extract coeffs from series\n        cof = get_coeff_list(ser, t, 0, i-1)\n        ret.append(cof)\nreturn ret", "path": "iteration\\parabolic.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "# extract coeffs from series\n", "func_signal": "def get_coeff_list(ser, x, x0=0, n=5):\n", "code": "coeffs_alist = ser.coeffs(x)\ncoeffs = [0 for k in xrange(n + 1)]\nfor c in coeffs_alist:\n    try:\n        coeffs[int(c[1])] = c[0]\n    except e:\n        pass\n\n# make sure there are exactly (n+1) coeffs\ncoeffs.extend([0 for i in xrange(n + 1 - len(coeffs))])\ncoeffs = coeffs[0 : n + 1]\nreturn coeffs", "path": "polynomial.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nAddition:\n\"\"\"\n", "func_signal": "def __add__(a,b):\n", "code": "def ret(n):\n    return a[n]+b[n]\nreturn PowerSeriesI(ret)", "path": "powerseries.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\niterational_matrix(f(x), x) -- matrix of coefficients C[j,k]\n    where f<t>(x) = SUM[j=0..n, k=0..n] C[j,k]*t^j*x^k\n\"\"\"\n# assume x0 is fixed point, check later\n# is the function parabolic or hyperbolic?\n", "func_signal": "def iterational_matrix(expr, x, x0=0, n=5):\n", "code": "if diff(expr, x).subs(x=x0) == 1:\n    f = parabolic_flow(expr, t, x, x0, n)\nelse:\n    f = hyperbolic_flow(expr, t, x, x0, n)\nreturn NotImplemented", "path": "iteration\\regular.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nparabolic_flow(f(x), t, x)\n\nThe power series (flow) for a parabolic function,\nwhich is a power series in x and t.\n\nThis takes the flow coefficients (1-D list) and\n'removes' a dimension (0-D value).\n\"\"\"\n# this also checks parabolic-ness\n", "func_signal": "def parabolic_flow(expr, t, x, x0=0, n=5):\n", "code": "coeffs = parabolic_flow_coeffs(expr, t, x, x0, n)\nreturn sum([coeffs[k]*(x - x0)**k for k in xrange(n)])", "path": "iteration\\parabolic.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nKnoebelH_by_iteration(x)\n\nInputs:   Flt:    A RealField of arbitrary precision\nOutputs:  a complex number with the same precision as Flt\nDescription:\n    Finds the upper primary fixed point of exponentiation for base e\n\"\"\"\n# Notes:\n# 1) The code will loop until precision is within 8 bits of the full\n#    precision of the input field. However, the maxout variable is\n#    used to prevent an infinite loop, just in case.\n# 2) The perturb value is used to prevent a situation where the a0\n#    variable is so accurate that the axial variable can't be\n#    determined accurately. The number of bits of accyracy should\n#    roughly double with each iteration, so any inaccuracy introduced\n#    by perturb should easily be removed by another iteration.\n# Jay Fox's code (slightly modified for Sage 3.0 by AR):\n", "func_signal": "def KnoebelH_by_iteration(x, guess=1):\n", "code": "try:\n    prec = x.prec()\nexcept:\n    prec = 53\nR = RealField(prec)\nC = ComplexField(prec)    \ndelta = R(2**(8-prec))\nperturb = C(2**(-3*prec/4), 0)\na0 = C(0.3, 1.3)\nmag = 1\nmaxout = 0\nwhile (mag > delta) and (maxout < 50):\n    a0 = a0 + perturb\n    a1 = C(log(a0)/log(x))\n    #a1 = C(log(a0, x))\n    diff = a1-a0\n    axial = diff/(a0-1)\n    mag = abs(diff)\n    maxout = maxout + 1\n    a0 = a1 + axial\nreturn a0", "path": "special\\function.py", "repo_name": "andydude/hyperops", "stars": 3, "license": "None", "language": "python", "size": 96}
{"docstring": "# it's silly that we need connection just for escaping strings\n", "func_signal": "def dbEscape(txt):\n", "code": "global g_conn\nreturn g_conn.escape_string(txt)", "path": "ipedia\\Server\\iPediaParseLogs.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# database names are in 2 styles:\n# old english db: ipedia_$date (e.g. ipedia_20040829)\n# new multi-lang db: ipedia_$lang_$data (e.g. ipedia_fr_20040829)\n", "func_signal": "def getLangFromDbName(dbName):\n", "code": "parts = dbName.split(\"_\")\nif 2==len(parts):\n    # old style\n    lang = \"en\"\nelse:\n    assert 3 == len(parts)\n    lang = parts[1]\n\nreturn lang", "path": "ipedia\\Server\\iPediaServer.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# this is what client sends when it sends Verify-Register-Code\n# as the first request ever\n", "func_signal": "def test_VerifyRegCodeAsFirstRequest(self):\n", "code": "self.req = Request()\nself.req.addField(iPediaFields.getArticleCount, None)\nself.req.addField(iPediaFields.getDatabaseTime, None)\nself.req.addField(iPediaFields.verifyRegCode, testValidRegCode)\nself.req.addField(iPediaFields.getCookie, g_exampleDeviceInfo)\nself.getResponse([iPediaFields.cookie,iPediaFields.transactionId,iPediaFields.regCodeValid])\nself.assertFieldEqual(self.rsp,iPediaFields.regCodeValid,1)", "path": "ipedia\\Server\\UnitTestsServer.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "\"\"\"Return True if a given database name is a name of the database with Wikipedia\narticles\"\"\"\n", "func_signal": "def fIpediaDb(dbName):\n", "code": "global g_supportedLangs\n\nif 0 != dbName.find(\"ipedia_\"):\n    return False\nparts = dbName.split(\"_\")\n\nif 2 == len(parts):\n    lang = \"en\"\n    dbDate = parts[1]\nelif 3 == len(parts):\n    lang = parts[1]\n    dbDate = parts[2]\nelse:\n    return False\n\nif lang not in g_supportedLangs:\n    return False\n\nif not fDbDate(dbDate):\n    return False\n\nreturn True", "path": "ipedia\\Server\\iPediaServer.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# all values returned by server are strings. If value to compare with\n# is int, change it to string. This makes it easier to e.g. compare\n# server errors\n", "func_signal": "def assertFieldEqual(self,response,field,value):\n", "code": "if isinstance(value,int):\n    value = \"%d\" % value\nself.assertEqual(response.getField(field),value)", "path": "ipedia\\Server\\UnitTestsServer.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# this is the simplest valid requests - only sends transaction id\n# in response server sends the same transaction id\n", "func_signal": "def test_Ping(self):\n", "code": "self.req = getRequestHandleCookie()\nself.getResponse([iPediaFields.cookie,iPediaFields.transactionId])", "path": "ipedia\\Server\\UnitTestsServer.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# sometimes we have errors before we can establish userId\n", "func_signal": "def logRequest(self, error):\n", "code": "if None == self.userId:\n    return\n\nif self.fHasField(iPediaFields.getArticle):\n    self.logSearchRequest(self.userId,self.getFieldValue(iPediaFields.getArticle),self.searchResult,error)\nelif self.fHasField(iPediaFields.getArticleU):\n    self.logSearchRequest(self.userId,self.getFieldValue(iPediaFields.getArticleU),self.searchResult,error)\nelif self.fHasField(iPediaFields.search):\n    self.logExtendedSearchRequest(self.userId,self.getFieldValue(iPediaFields.search),error)\nelif self.fHasField(iPediaFields.getRandom):\n    self.logRandomSearchRequest(self.userId,self.searchResult,error)", "path": "ipedia\\Server\\iPediaServer.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# testing if I got __eq__ and __ne__ right\n", "func_signal": "def test_WikipediaLinkEq(self):\n", "code": "wl1 = WikipediaLink(None,None)\nwl2 = WikipediaLink(None,None)\nself.assertEqual( wl1==wl2, True )\nself.assertEqual( wl1!=wl2, False )\nself.assertEqual( wl1, wl2)\nwl3 = WikipediaLink(\"me\", None)\nself.assertEqual( wl1==wl3, False)\nself.assertEqual( wl2!=wl3, True)", "path": "ipedia\\Server\\UnitTests.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# it's silly that we need connection just for escaping strings\n", "func_signal": "def dbEscape(txt):\n", "code": "global g_connIpedia\nreturn g_connIpedia.escape_string(txt)", "path": "ipedia\\Server\\wikiToDbConvert.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# TODO: should I check if the file exists? Or maybe just append?\n", "func_signal": "def saveNewCodesToSQL(newCodes):\n", "code": "fo = open(getSQLFileName(), \"wb\")\nfor code in newCodes.keys():\n    purpose = newCodes[code][0]\n    fo.write(\"INSERT INTO VALUES('%s','%s')\\n\" % (code, purpose))\nfo.close()", "path": "ipedia\\scripts\\ipedia_gen_reg_codes.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# check for (hopefuly frequent) case: this a valid, direct redirect\n", "func_signal": "def resolveRedirect(title,cur_redirect, allRedirects, allArticles):\n", "code": "if allArticles.has_key(cur_redirect):\n    return cur_redirect\nvisited = [title]\nvisited.append(cur_redirect)\nwhile True:\n    if allArticles.has_key(cur_redirect):\n        # this points to a valid article, so we resolved the redirect\n        return cur_redirect\n    if allRedirects.has_key(cur_redirect):\n        # there is some other redirects for this -> keep looking\n        cur_redirect = allRedirects[cur_redirect]\n        if cur_redirect in visited:\n            #print \"found circular redirect: %s\" % cur_redirect\n            break\n        visited.append(cur_redirect)\n    else:\n        # no more redirects -> we couldn't resolve the redirect\n        break\ndumpUnresolvedRedirect(visited)\nreturn None", "path": "ipedia\\Server\\wikiToDbConvert.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# print \"telnet: '%s'\" % request\n", "func_signal": "def lineReceived(self, request):\n", "code": "if iPediaTelnetProtocol.listRe.match(request):\n    self.listDatabases()\n    return\n\nmatch = iPediaTelnetProtocol.useDbRe.match(request)\nif match:\n    self.useDatabase(match.group(1))\n    return\n\nself.transport.loseConnection()", "path": "ipedia\\Server\\iPediaServer.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "#print \"started processing telnet connection\"\n", "func_signal": "def processTelnetConnection(clientSocketAddress, plugClass):\n", "code": "plug = plugClass()\nplug.transport = _Transport(clientSocketAddress, plug)\nplug.processConnection()\nif not plug.transport.closed:\n    plug.transport.loseConnection()\n#print \"finished processing telnet connection\"", "path": "ipedia\\Server\\ThreadedServer.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# case a)\n", "func_signal": "def computeUserId(self):\n", "code": "        if self.fHasField(iPediaFields.regCode):\n            return self.handleRegistrationCodeRequest()\n# case b)\n        if self.fHasField(iPediaFields.cookie):\n            return self.handleCookieRequest()\n# case c)\n        if self.fHasField(iPediaFields.getCookie):\n            return self.handleGetCookieRequest()", "path": "ipedia\\Server\\iPediaServer.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# create document\n", "func_signal": "def indexOneArticle(indexer, title, txt):\n", "code": "d = document.Document()\n# add a file field containing the path to this file\nf = document.Keyword('title',title)\nd.add(f)\n# I happen to know that the title is separated\n# from the story by '\\n\\n\\n', so I can easily get the title\n# which we store in the title field\n#fp = open(fname,'rb')\n#s = fp.read().decode(\"latin-1\")\n#title = s.split('\\n\\n\\n')[0]\n#f = document.Text('title',title)\n#d.add(f)\n# Here I pass False as the 3rd arg to ensure that\n# the actual text of s is not stored in the index\n# the following lines using TextWithReader are\n# more typical.   \nf = document.Text('body', txt, False)\nd.add(f)\n# Add text of an open file (fp)\n# This is typically how you add a file to an index\n# f = field.Text('text', fp)\n# d.add(f)    \n#fp.close()\n# add doc to index\n\n#if g_fVerbose:\n#    sys.stdout.write('indexing %s' % title)\nindexer.addDocument(d)", "path": "ipedia\\scripts\\testLupy.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# ifninite cycles shouldn't happen, but just in case we're limiting number of re-directs\n", "func_signal": "def findArticle(db, cursor, title):\n", "code": "redirectsLeft = 10\nretVal = None\nwhile redirectsLeft>0:\n    titleEscaped = db.escape_string(title)\n    query = \"\"\"SELECT id, title, body FROM articles WHERE title='%s';\"\"\" % titleEscaped\n    cursor.execute(query)\n    row = cursor.fetchone()\n    if row:\n        retVal = (row[0], row[1], row[2])\n        break\n    query = \"\"\"SELECT redirect FROM redirects WHERE title='%s';\"\"\" % titleEscaped\n    cursor.execute(query)\n    row = cursor.fetchone()\n    if not row:\n        break\n    title=row[0]\n    redirectsLeft -= 1\nreturn retVal", "path": "ipedia\\Server\\iPediaServer.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# Ok, so I can't really guarantee that a article with this title doesn't exist\n# but this is a really good guess\n", "func_signal": "def test_NotFound(self):\n", "code": "self.req = getRequestHandleCookie(iPediaFields.getArticle, \"asdfasdflkj324;l1kjasd13214aasdf341l324\")\nself.getResponse([iPediaFields.transactionId,iPediaFields.cookie,iPediaFields.notFound])", "path": "ipedia\\Server\\UnitTestsServer.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# this is guaranteed to be an invalid cookie\n", "func_signal": "def test_InvalidCookie(self):\n", "code": "self.req = Request()\nself.req.addField(iPediaFields.cookie,\"baraba\")\nself.getResponse([iPediaFields.error,iPediaFields.transactionId])\nself.assertError(ServerErrors.invalidCookie)", "path": "ipedia\\Server\\UnitTestsServer.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# those macros are actually removed during conversion phase, so this\n# code is disabled. I'll leave it for now if we decide to revive it\n", "func_signal": "def preprocessArticleBody(self, body):\n", "code": "return body\n# perf: we could improve this by marking articles that need this conversion\n# in the database and only do this if it's marked as such. but maybe\n# the overhead of storing/retrieving this info will be bigger than code\n\n# perf: maybe we should ignore {{NUMBEROFARTICLES}} or replace it during conversion\nbody=body.replace(\"{{NUMBEROFARTICLES}}\", str(self.dbInfo.articlesCount))\n# speed up trick: don't do the conversion if there can't possibly anything to convert\nif -1 == body.find(\"{{CURRENT\"):\n    return body\nbody=body.replace(\"{{CURRENTMONTH}}\",       str(int(time.strftime('%m'))));\nbody=body.replace(\"{{CURRENTMONTHNAME}}\",   time.strftime('%B'))\nbody=body.replace(\"{{CURRENTMONTHNAMEGEN}}\",time.strftime(\"%B\"))\nbody=body.replace(\"{{CURRENTDAY}}\",         str(int(time.strftime(\"%d\"))))\nbody=body.replace(\"{{CURRENTDAYNAME}}\",     time.strftime(\"%A\"))\nbody=body.replace(\"{{CURRENTYEAR}}\",        time.strftime(\"%Y\"))\nbody=body.replace(\"{{CURRENTTIME}}\",        time.strftime(\"%X\"))\nreturn body", "path": "ipedia\\Server\\iPediaServer.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "# it's silly that we need connection just for escaping strings\n", "func_signal": "def dbEscape(txt):\n", "code": "global g_conn\nreturn g_conn.escape_string(txt)", "path": "ipedia\\scripts\\import_reg_codes.py", "repo_name": "kjk/ipedia-palm", "stars": 2, "license": "None", "language": "python", "size": 1308}
{"docstring": "\"\"\"\nReturn a static text analysation function that\nreturns float values.\n\"\"\"\n", "func_signal": "def make_analysator(f):\n", "code": "def text_analyse(text):\n    rv = f(text)\n    if not rv:\n        return 0.0\n    return min(1.0, max(0.0, float(rv)))\ntext_analyse.__doc__ = f.__doc__\nreturn staticmethod(text_analyse)", "path": "pygments\\util.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"\nReturn CSS style definitions for the classes produced by the current\nhighlighting style. ``arg`` can be a string or list of selectors to\ninsert before the token type classes.\n\"\"\"\n", "func_signal": "def get_style_defs(self, arg=None):\n", "code": "if arg is None:\n    arg = ('cssclass' in self.options and '.'+self.cssclass or '')\nif isinstance(arg, basestring):\n    args = [arg]\nelse:\n    args = list(arg)\n\ndef prefix(cls):\n    if cls:\n        cls = '.' + cls\n    tmp = []\n    for arg in args:\n        tmp.append((arg and arg + ' ' or '') + cls)\n    return ', '.join(tmp)\n\nstyles = [(level, ttype, cls, style)\n          for cls, (style, ttype, level) in self.class2style.iteritems()\n          if cls and style]\nstyles.sort()\nlines = ['%s { %s } /* %s */' % (prefix(cls), style, repr(ttype)[6:])\n         for (level, ttype, cls, style) in styles]\nif arg and not self.nobackground and \\\n   self.style.background_color is not None:\n    text_style = ''\n    if Text in self.ttype2class:\n        text_style = ' ' + self.class2style[self.ttype2class[Text]][0]\n    lines.insert(0, '%s { background: %s;%s }' %\n                 (prefix(''), self.style.background_color, text_style))\nreturn '\\n'.join(lines)", "path": "pygments\\formatters\\html.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"Escape &, <, > as well as single and double quotes for HTML.\"\"\"\n", "func_signal": "def escape_html(text):\n", "code": "return text.replace('&', '&amp;').  \\\n            replace('<', '&lt;').   \\\n            replace('>', '&gt;').   \\\n            replace('\"', '&quot;'). \\\n            replace(\"'\", '&#39;')", "path": "pygments\\formatters\\html.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "# XXX outencoding\n", "func_signal": "def __init__(self, **options):\n", "code": "Formatter.__init__(self, **options)\nself.nowrap = get_bool_opt(options, 'nowrap', False)\nself.fontfamily = options.get('fontfamily', 'monospace')\nself.fontsize = options.get('fontsize', '14px')\nself.xoffset = get_int_opt(options, 'xoffset', 0)\nfs = self.fontsize.strip()\nif fs.endswith('px'): fs = fs[:-2].strip()\ntry:\n    int_fs = int(fs)\nexcept:\n    int_fs = 20\nself.yoffset = get_int_opt(options, 'yoffset', int_fs)\nself.ystep = get_int_opt(options, 'ystep', int_fs + 5)\nself.spacehack = get_bool_opt(options, 'spacehack', True)\nself._stylecache = {}", "path": "pygments\\formatters\\svg.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"\nReturn the \\\\newcommand sequences needed to define the commands\nused to format text in the verbatim environment. ``arg`` is ignored.\n\"\"\"\n", "func_signal": "def get_style_defs(self, arg=''):\n", "code": "nc = '\\\\newcommand'\nreturn '%s\\\\at{@}\\n%s\\\\lb{[}\\n%s\\\\rb{]}\\n' % (nc, nc, nc) + \\\n       '\\n'.join(['\\\\newcommand\\\\%s[1]{%s}' % (alias, cmndef)\n                  for alias, cmndef in self.cmd2def.iteritems()\n                  if cmndef != '#1'])", "path": "pygments\\formatters\\latex.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"\nJust format the tokens, without any wrapping tags.\nYield individual lines.\n\"\"\"\n", "func_signal": "def _format_lines(self, tokensource):\n", "code": "nocls = self.noclasses\nenc = self.encoding\nlsep = self.lineseparator\n# for <span style=\"\"> lookup only\ngetcls = self.ttype2class.get\nc2s = self.class2style\n\nlspan = ''\nline = ''\nfor ttype, value in tokensource:\n    if nocls:\n        cclass = getcls(ttype)\n        while cclass is None:\n            ttype = ttype.parent\n            cclass = getcls(ttype)\n        cspan = cclass and '<span style=\"%s\">' % c2s[cclass][0] or ''\n    else:\n        cls = self._get_css_class(ttype)\n        cspan = cls and '<span class=\"%s\">' % cls or ''\n\n    if enc:\n        value = value.encode(enc)\n\n    parts = escape_html(value).split('\\n')\n\n    # for all but the last line\n    for part in parts[:-1]:\n        if line:\n            if lspan != cspan:\n                line += (lspan and '</span>') + cspan + part + \\\n                        (cspan and '</span>') + lsep\n            else: # both are the same\n                line += part + (lspan and '</span>') + lsep\n            yield 1, line\n            line = ''\n        elif part:\n            yield 1, cspan + part + (cspan and '</span>') + lsep\n        else:\n            yield 1, lsep\n    # for the last line\n    if line and parts[-1]:\n        if lspan != cspan:\n            line += (lspan and '</span>') + cspan + parts[-1]\n            lspan = cspan\n        else:\n            line += parts[-1]\n    elif parts[-1]:\n        line = cspan + parts[-1]\n        lspan = cspan\n    # else we neither have to open a new span nor set lspan\n\nif line:\n    yield 1, line + (lspan and '</span>') + lsep", "path": "pygments\\formatters\\html.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"\nCheck if a doctype exists or if we have some tags.\n\"\"\"\n", "func_signal": "def looks_like_xml(text):\n", "code": "m = doctype_lookup_re.match(text)\nif m is not None:\n    return True\nreturn tag_re.search(text) is not None", "path": "pygments\\util.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"Return an generator for all styles by name,\nboth builtin and plugin.\"\"\"\n", "func_signal": "def get_all_styles():\n", "code": "for name in STYLE_MAP:\n    yield name\nfor name, _ in find_plugin_styles():\n    yield name", "path": "pygments\\styles\\__init__.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"Escape &, <, > as well as single and double quotes for HTML.\"\"\"\n", "func_signal": "def escape_html(text):\n", "code": "return text.replace('&', '&amp;').  \\\n            replace('<', '&lt;').   \\\n            replace('>', '&gt;').   \\\n            replace('\"', '&quot;'). \\\n            replace(\"'\", '&#39;')", "path": "pygments\\formatters\\svg.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"\nConvert a string into a token type::\n\n    >>> string_to_token('String.Double')\n    Token.Literal.String.Double\n    >>> string_to_token('Token.Literal.Number')\n    Token.Literal.Number\n    >>> string_to_token('')\n    Token\n\nTokens that are already tokens are returned unchanged:\n\n    >>> string_to_token(String)\n    Token.Literal.String\n\"\"\"\n", "func_signal": "def string_to_tokentype(s):\n", "code": "if isinstance(s, _TokenType):\n    return s\nif not s:\n    return Token\nnode = Token\nfor item in s.split('.'):\n    node = getattr(node, item)\nreturn node", "path": "pygments\\token.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"Helper to render a response, passing standard stuff to the response.\n\nArgs:\n  request: The request object.\n  user: The User object representing the current user; or None if nobody\n    is logged in.\n  template: The template name; '.html' is appended automatically.\n  params: A dict giving the template parameters; modified in-place.\n\nReturns:\n  Whatever render_to_response(template, params) returns.\n\nRaises:\n  Whatever render_to_response(template, params) raises.\n\"\"\"\n", "func_signal": "def respond(request, user, template, params=None):\n", "code": "if params is None:\n  params = {}\nif user:\n  params['user'] = user\n  params['sign_out'] = users.CreateLogoutURL('/')\n  params['is_admin'] = (users.IsCurrentUserAdmin() and\n                        'Dev' in os.getenv('SERVER_SOFTWARE'))\nelse:\n  params['sign_in'] = users.CreateLoginURL(request.path)\nif not template.endswith('.html'):\n  template += '.html'\nreturn shortcuts.render_to_response(template, params)", "path": "views\\__init__.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"Return the css class of this token type prefixed with\nthe classprefix option.\"\"\"\n", "func_signal": "def _get_css_class(self, ttype):\n", "code": "if ttype in self._class_cache:\n    return self._class_cache[ttype]\nreturn self.classprefix + _get_ttype_class(ttype)", "path": "pygments\\formatters\\html.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"Return a random id for javascript fields.\"\"\"\n", "func_signal": "def get_random_id():\n", "code": "from random import random\nfrom time import time\ntry:\n    from hashlib import sha1 as sha\nexcept ImportError:\n    import sha\n    sha = sha.new\nreturn sha('%s|%s' % (random(), time())).hexdigest()", "path": "pygments\\formatters\\html.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"\nThe formatting process uses several nested generators; which of\nthem are used is determined by the user's options.\n\nEach generator should take at least one argument, ``inner``,\nand wrap the pieces of text generated by this.\n\nAlways yield 2-tuples: (code, text). If \"code\" is 1, the text\nis part of the original tokensource being highlighted, if it's\n0, the text is some piece of wrapping. This makes it possible to\nuse several different wrappers that process the original source\nlinewise, e.g. line number generators.\n\"\"\"\n", "func_signal": "def format(self, tokensource, outfile):\n", "code": "source = self._format_lines(tokensource)\nif not self.nowrap:\n    if self.linenos == 2:\n        source = self._wrap_inlinelinenos(source)\n    if self.lineanchors:\n        source = self._wrap_lineanchors(source)\n    source = self.wrap(source, outfile)\n    if self.linenos == 1:\n        source = self._wrap_tablelinenos(source)\n    if self.full:\n        source = self._wrap_full(source, outfile)\n\nfor t, piece in source:\n    outfile.write(piece)", "path": "pygments\\formatters\\html.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"\nCheck if the doctype matches a regular expression (if present).\nNote that this method only checks the first part of a DOCTYPE.\neg: 'html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"'\n\"\"\"\n", "func_signal": "def doctype_matches(text, regex):\n", "code": "m = doctype_lookup_re.match(text)\nif m is None:\n    return False\ndoctype = m.group(2)\nreturn re.compile(regex).match(doctype.strip()) is not None", "path": "pygments\\util.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "# need a list of lines since we need the width of a single number :(\n", "func_signal": "def _wrap_inlinelinenos(self, inner):\n", "code": "lines = list(inner)\nsp = self.linenospecial\nst = self.linenostep\nnum = self.linenostart\nmw = len(str(len(lines) + num - 1))\n\nif sp:\n    for t, line in lines:\n        yield 1, '<span class=\"lineno%s\">%*s</span> ' % (\n            num%sp == 0 and ' special' or '', mw, (num%st and ' ' or num)) + line\n        num += 1\nelse:\n    for t, line in lines:\n        yield 1, '<span class=\"lineno\">%*s</span> ' % (\n            mw, (num%st and ' ' or num)) + line\n        num += 1", "path": "pygments\\formatters\\html.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"\nFormat ``tokensource``, an iterable of ``(tokentype, tokenstring)``\ntuples and write it into ``outfile``.\n\nFor our implementation we put all lines in their own 'line group'.\n\"\"\"\n", "func_signal": "def format(self, tokensource, outfile):\n", "code": "x = self.xoffset\ny = self.yoffset\nenc = self.encoding\nif not self.nowrap:\n    if enc:\n        outfile.write('<?xml version=\"1.0\" encoding=\"%s\"?>\\n' % self.encoding)\n    else:\n        outfile.write('<?xml version=\"1.0\"?>\\n')\n    outfile.write('<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.0//EN\" '\n                  '\"http://www.w3.org/TR/2001/REC-SVG-20010904/DTD/'\n                  'svg10.dtd\">\\n')\n    outfile.write('<svg xmlns=\"http://www.w3.org/2000/svg\">\\n')\n    outfile.write('<g font-family=\"%s\" font-size=\"%s\">\\n' % (self.fontfamily,\n                                                             self.fontsize))\noutfile.write('<text x=\"%s\" y=\"%s\" xml:space=\"preserve\">' % (x, y))\nfor ttype, value in tokensource:\n    if enc:\n        value = value.encode(enc)\n    style = self._get_style(ttype)\n    tspan = style and '<tspan' + style + '>' or ''\n    tspanend = tspan and '</tspan>' or ''\n    value = escape_html(value)\n    if self.spacehack:\n        value = value.expandtabs().replace(' ', '&#160;')\n    parts = value.split('\\n')\n    for part in parts[:-1]:\n        outfile.write(tspan + part + tspanend)\n        y += self.ystep\n        outfile.write('</text>\\n<text x=\"%s\" y=\"%s\" '\n                      'xml:space=\"preserve\">' % (x, y))\n    outfile.write(tspan + parts[-1] + tspanend)\noutfile.write('</text>')\n\nif not self.nowrap:\n    outfile.write('</g></svg>\\n')", "path": "pygments\\formatters\\svg.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "# colors 0..15: 16 basic colors\n\n", "func_signal": "def _build_color_table(self):\n", "code": "self.xterm_colors.append((0x00, 0x00, 0x00)) # 0\nself.xterm_colors.append((0xcd, 0x00, 0x00)) # 1\nself.xterm_colors.append((0x00, 0xcd, 0x00)) # 2\nself.xterm_colors.append((0xcd, 0xcd, 0x00)) # 3\nself.xterm_colors.append((0x00, 0x00, 0xee)) # 4\nself.xterm_colors.append((0xcd, 0x00, 0xcd)) # 5\nself.xterm_colors.append((0x00, 0xcd, 0xcd)) # 6\nself.xterm_colors.append((0xe5, 0xe5, 0xe5)) # 7\nself.xterm_colors.append((0x7f, 0x7f, 0x7f)) # 8\nself.xterm_colors.append((0xff, 0x00, 0x00)) # 9\nself.xterm_colors.append((0x00, 0xff, 0x00)) # 10\nself.xterm_colors.append((0xff, 0xff, 0x00)) # 11\nself.xterm_colors.append((0x5c, 0x5c, 0xff)) # 12\nself.xterm_colors.append((0xff, 0x00, 0xff)) # 13\nself.xterm_colors.append((0x00, 0xff, 0xff)) # 14\nself.xterm_colors.append((0xff, 0xff, 0xff)) # 15\n\n# colors 16..232: the 6x6x6 color cube\n\nvaluerange = (0x00, 0x5f, 0x87, 0xaf, 0xd7, 0xff)\n\nfor i in range(217):\n    r = valuerange[(i / 36) % 6]\n    g = valuerange[(i / 6) % 6]\n    b = valuerange[i % 6]\n    self.xterm_colors.append((r, g, b))\n\n# colors 233..253: grayscale\n\nfor i in range(1, 22):\n    v = 8 + i * 10\n    self.xterm_colors.append((v, v, v))", "path": "pygments\\formatters\\terminal256.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "# TODO: add support for background colors\n", "func_signal": "def format(self, tokensource, outfile):\n", "code": "enc = self.encoding\n\nif self.full:\n    realoutfile = outfile\n    outfile = StringIO.StringIO()\n\noutfile.write(r'\\begin{Verbatim}[commandchars=@\\[\\]')\nif self.linenos:\n    start, step = self.linenostart, self.linenostep\n    outfile.write(',numbers=left' +\n                  (start and ',firstnumber=%d' % start or '') +\n                  (step and ',stepnumber=%d' % step or ''))\nif self.verboptions:\n    outfile.write(',' + self.verboptions)\noutfile.write(']\\n')\n\nfor ttype, value in tokensource:\n    if enc:\n        value = value.encode(enc)\n    value = escape_tex(value)\n    cmd = self.ttype2cmd.get(ttype)\n    while cmd is None:\n        ttype = ttype.parent\n        cmd = self.ttype2cmd.get(ttype)\n    if cmd:\n        spl = value.split('\\n')\n        for line in spl[:-1]:\n            if line:\n                outfile.write(\"@%s[%s]\" % (cmd, line))\n            outfile.write('\\n')\n        if spl[-1]:\n            outfile.write(\"@%s[%s]\" % (cmd, spl[-1]))\n    else:\n        outfile.write(value)\n\noutfile.write('\\\\end{Verbatim}\\n')\n\nif self.full:\n    realoutfile.write(DOC_TEMPLATE %\n        dict(docclass  = self.docclass,\n             preamble  = self.preamble,\n             title     = self.title,\n             encoding  = self.encoding or 'latin1',\n             styledefs = self.get_style_defs(),\n             code      = outfile.getvalue()))", "path": "pygments\\formatters\\latex.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"Return a generator for all formatters.\"\"\"\n", "func_signal": "def get_all_formatters():\n", "code": "for formatter in FORMATTERS:\n    yield formatter\nfor _, formatter in find_plugin_formatters():\n    yield formatter", "path": "pygments\\formatters\\__init__.py", "repo_name": "markchadwick/syntaxing", "stars": 3, "license": "None", "language": "python", "size": 736}
{"docstring": "\"\"\"Convert an IP address string (e.g. '192.168.0.1') to an IP\nnumber as an integer given in ASCII representation\n(e.g. '3232235521').\"\"\"\n", "func_signal": "def ip_quad_to_numstr(quad):\n", "code": "p = map(long, quad.split(\".\"))\ns = str((p[0] << 24) | (p[1] << 16) | (p[2] << 8) | p[3])\nif s[-1] == \"L\":\n    s = s[:-1]\nreturn s", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Connect to a DCC peer.\n\nArguments:\n\n    address -- IP address of the peer.\n\n    port -- Port to connect to.\n\nReturns a DCCConnection instance.\n\"\"\"\n", "func_signal": "def dcc_connect(self, address, port, dcctype=\"chat\"):\n", "code": "dcc = self.ircobj.dcc(dcctype)\nself.dcc_connections.append(dcc)\ndcc.connect(address, port)\nreturn dcc", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Close the connection.\n\nThis method closes the connection permanently; after it has\nbeen called, the object is unusable.\n\"\"\"\n\n", "func_signal": "def close(self):\n", "code": "self.disconnect(\"Closing object\")\nself.irclibobj._remove_connection(self)", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Adds a global handler function for a specific event type.\n\nArguments:\n\n    event -- Event type (a string).  Check the values of the\n    numeric_events dictionary in irclib.py for possible event\n    types.\n\n    handler -- Callback function.\n\n    priority -- A number (the lower number, the higher priority).\n\nThe handler function is called whenever the specified event is\ntriggered in any of the connections.  See documentation for\nthe Event class.\n\nThe handler functions are called in priority order (lowest\nnumber is highest priority).  If a handler function returns\n\\\"NO MORE\\\", no more handlers will be called.\n\"\"\"\n\n", "func_signal": "def add_global_handler(self, event, handler, priority=0):\n", "code": "if not event in self.handlers:\n    self.handlers[event] = []\nbisect.insort(self.handlers[event], ((priority, handler)))", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Process data from connections once.\n\nArguments:\n\n    timeout -- How long the select() call should wait if no\n               data is available.\n\nThis method should be called periodically to check and process\nincoming data, if there are any.  If that seems boring, look\nat the process_forever method.\n\"\"\"\n", "func_signal": "def process_once(self, timeout=0):\n", "code": "sockets = map(lambda x: x._get_socket(), self.connections)\nsockets = filter(lambda x: x != None, sockets)\nif sockets:\n    (i, o, e) = select.select(sockets, [], [], timeout)\n    self.process_data(i)\nelse:\n    time.sleep(timeout)\nself.process_timeout()", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Listen for connections from a DCC peer.\n\nReturns a DCCConnection instance.\n\"\"\"\n", "func_signal": "def dcc_listen(self, dcctype=\"chat\"):\n", "code": "dcc = self.ircobj.dcc(dcctype)\nself.dcc_connections.append(dcc)\ndcc.listen()\nreturn dcc", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Send a WHOWAS command.\"\"\"\n", "func_signal": "def whowas(self, nick, max=\"\", server=\"\"):\n", "code": "self.send_raw(\"WHOWAS %s%s%s\" % (nick,\n                                 max and (\" \" + max),\n                                 server and (\" \" + server)))", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Send a LINKS command.\"\"\"\n", "func_signal": "def links(self, remote_server=\"\", server_mask=\"\"):\n", "code": "command = \"LINKS\"\nif remote_server:\n    command = command + \" \" + remote_server\nif server_mask:\n    command = command + \" \" + server_mask\nself.send_raw(command)", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Get the user part of a nickmask.\n\n(The source of an Event is a nickmask.)\n\"\"\"\n", "func_signal": "def nm_to_u(s):\n", "code": "s = s.split(\"!\")[1]\nreturn s.split(\"@\")[0]", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Check if a nick matches a mask.\n\nReturns true if the nick matches, otherwise false.\n\"\"\"\n", "func_signal": "def mask_matches(nick, mask):\n", "code": "nick = irc_lower(nick)\nmask = irc_lower(mask)\nmask = mask.replace(\"\\\\\", \"\\\\\\\\\")\nfor ch in \".$|[](){}+\":\n    mask = mask.replace(ch, \"\\\\\" + ch)\nmask = mask.replace(\"?\", \".\")\nmask = mask.replace(\"*\", \".*\")\nr = re.compile(mask, re.IGNORECASE)\nreturn r.match(nick)", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Get the (real) server name.\n\nThis method returns the (real) server name, or, more\nspecifically, what the server calls itself.\n\"\"\"\n\n", "func_signal": "def get_server_name(self):\n", "code": "if self.real_server_name:\n    return self.real_server_name\nelse:\n    return \"\"", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Convert an IP number as an integer given in ASCII\nrepresentation (e.g. '3232235521') to an IP address string\n(e.g. '192.168.0.1').\"\"\"\n", "func_signal": "def ip_numstr_to_quad(num):\n", "code": "n = long(num)\np = map(str, map(int, [n >> 24 & 0xFF, n >> 16 & 0xFF,\n                       n >> 8 & 0xFF, n & 0xFF]))\nreturn \".\".join(p)", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Send an SCONNECT command.\"\"\"\n", "func_signal": "def sconnect(self, target, port=\"\", server=\"\"):\n", "code": "self.send_raw(\"CONNECT %s%s%s\" % (target,\n                                  port and (\" \" + port),\n                                  server and (\" \" + server)))", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Send a TOPIC command.\"\"\"\n", "func_signal": "def topic(self, channel, new_topic=None):\n", "code": "if new_topic is None:\n    self.send_raw(\"TOPIC \" + channel)\nelse:\n    self.send_raw(\"TOPIC %s :%s\" % (channel, new_topic))", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"[Internal]\"\"\"\n", "func_signal": "def _remove_connection(self, connection):\n", "code": "self.connections.remove(connection)\nif self.fn_to_remove_socket:\n    self.fn_to_remove_socket(connection._get_socket())", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Removes a global handler function.\n\nArguments:\n\n    event -- Event type (a string).\n\n    handler -- Callback function.\n\nReturns 1 on success, otherwise 0.\n\"\"\"\n", "func_signal": "def remove_global_handler(self, event, handler):\n", "code": "if not event in self.handlers:\n    return 0\nfor h in self.handlers[event]:\n    if handler == h[1]:\n        self.handlers[event].remove(h)\nreturn 1", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"[Internal]\"\"\"\n", "func_signal": "def _dispatcher(self, c, e):\n", "code": "m = \"on_\" + e.eventtype()\nif hasattr(self, m):\n    getattr(self, m)(c, e)", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Constructor of Event objects.\n\nArguments:\n\n    eventtype -- A string describing the event.\n\n    source -- The originator of the event (a nick mask or a server).\n\n    target -- The target of the event (a nick or a channel).\n\n    arguments -- Any event specific arguments.\n\"\"\"\n", "func_signal": "def __init__(self, eventtype, source, target, arguments=None):\n", "code": "self._eventtype = eventtype\nself._source = source\nself._target = target\nif arguments:\n    self._arguments = arguments\nelse:\n    self._arguments = []", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Send a PART command.\"\"\"\n", "func_signal": "def part(self, channels, message=\"\"):\n", "code": "if type(channels) == types.StringType:\n    self.send_raw(\"PART \" + channels + (message and (\" \" + message)))\nelse:\n    self.send_raw(\"PART \" + \",\".join(channels) + (message and (\" \" + message)))", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\"Called when there is more data to read on connection sockets.\n\nArguments:\n\n    sockets -- A list of socket objects.\n\nSee documentation for IRC.__init__.\n\"\"\"\n", "func_signal": "def process_data(self, sockets):\n", "code": "for s in sockets:\n    for c in self.connections:\n        if s == c._get_socket():\n            c.process_data()", "path": "birclib.py", "repo_name": "william-ml-leslie/bfirc", "stars": 2, "license": "None", "language": "python", "size": 240}
{"docstring": "\"\"\" Transform every WikiWord in a text into links.\n    WikiWord must match this regular expression:\n    '(?:[A-Z]+[a-z]+){2,}'\n\"\"\"\n# @@@ TODO: absolute links\n", "func_signal": "def wikiwords(s):\n", "code": "s = wikiwordfier.sub(r'<a href=\"../\\1/\">\\1</a>', s)\nreturn force_unicode(s)", "path": "apps\\external_apps\\wiki\\templatetags\\wiki.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Create and return a new empty document tree (root node).\"\"\"\n", "func_signal": "def new_document(self):\n", "code": "document = utils.new_document(self.source.source_path, self.settings)\nreturn document", "path": "libs\\external_libs\\docutils-0.4\\docutils\\readers\\__init__.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"\nInitialize the Reader instance.\n\nSeveral instance attributes are defined with dummy initial values.\nSubclasses may use these attributes as they wish.\n\"\"\"\n\n", "func_signal": "def __init__(self, parser=None, parser_name=None):\n", "code": "self.parser = parser\n\"\"\"A `parsers.Parser` instance shared by all doctrees.  May be left\nunspecified if the document source determines the parser.\"\"\"\n\nif parser is None and parser_name:\n    self.set_parser(parser_name)\n\nself.source = None\n\"\"\"`docutils.io` IO object, source of input data.\"\"\"\n\nself.input = None\n\"\"\"Raw text input; either a single string or, for more complex cases,\na collection of strings.\"\"\"", "path": "libs\\external_libs\\docutils-0.4\\docutils\\readers\\__init__.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Tests the existence of <atom:updated> in\nEmailListRecipientEntry and verifies the value\"\"\"\n\n", "func_signal": "def testUpdated(self):\n", "code": "self.assert_(\n  isinstance(self.rcpt_entry.updated, atom.Updated),\n  \"EmailListRecipient entry <atom:updated> element must be an instance \" +\n  \"of atom.Updated: %s\" % self.rcpt_entry.updated)\n\nself.assertEquals(self.rcpt_entry.updated.text,\n                  '1970-01-01T00:00:00.000Z')", "path": "libs\\external_libs\\gdata.py-1.0.13\\tests\\gdata_tests\\apps_test.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Constructor for the DocsSample object.\n\nTakes an email and password corresponding to a gmail account to\ndemonstrate the functionality of the Document List feed.\n\nArgs:\n  email: [string] The e-mail address of the account to use for the sample.\n  password: [string] The password corresponding to the account specified by\n      the email parameter.\n\nReturns:\n  A DocsSample object used to run the sample demonstrating the\n  functionality of the Document List feed.\n\"\"\"\n", "func_signal": "def __init__(self, email, password):\n", "code": "self.gd_client = gdata.docs.service.DocsService()\nself.gd_client.email = email\nself.gd_client.password = password\nself.gd_client.source = 'Document List Python Sample'\nself.gd_client.ProgrammaticLogin()", "path": "libs\\external_libs\\gdata.py-1.0.13\\samples\\docs\\docs_example.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Tests the existence of <atom:title> in NicknameEntry and\nverifies the value\"\"\"\n\n", "func_signal": "def testTitle(self):\n", "code": "self.assert_(isinstance(self.nick_entry.title, atom.Title),\n    \"Nickname entry <atom:title> element must be an instance \" +\n    \"of atom.Title: %s\" % self.nick_entry.title)\n\nself.assertEquals(self.nick_entry.title.text, \"Foo\")", "path": "libs\\external_libs\\gdata.py-1.0.13\\tests\\gdata_tests\\apps_test.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Tests the existence of <apps:name> in UserEntry and verifies\nthe value\"\"\"\n\n", "func_signal": "def testName(self):\n", "code": "self.assert_(isinstance(self.user_entry.name, gdata.apps.Name),\n    \"User entry <apps:name> element must be an instance of apps.Name: %s\"\n    % self.user_entry.name)\nself.assertEquals(self.user_entry.name.family_name, 'Test')\nself.assertEquals(self.user_entry.name.given_name, 'User')", "path": "libs\\external_libs\\gdata.py-1.0.13\\tests\\gdata_tests\\apps_test.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Tests the existence of <apps:nickname> in NicknameEntry and\nverifies the value\"\"\"\n\n", "func_signal": "def testNickname(self):\n", "code": "self.assert_(isinstance(self.nick_entry.nickname, gdata.apps.Nickname),\n    \"Nickname entry <apps:nickname> element must be an instance \" +\n    \"of apps.Nickname: %s\" % self.nick_entry.nickname)\nself.assertEquals(self.nick_entry.nickname.name, \"Foo\")", "path": "libs\\external_libs\\gdata.py-1.0.13\\tests\\gdata_tests\\apps_test.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Tests the existence of <atom:entry> in EmailListFeed and simply\nverifies the value\"\"\"\n\n", "func_signal": "def testUserEntries(self):\n", "code": "for a_entry in self.list_feed.entry:\n  self.assert_(isinstance(a_entry, gdata.apps.EmailListEntry),\n      \"EmailList Feed <atom:entry> must be an instance of \" +\n      \"apps.EmailListEntry: %s\" % a_entry)\n\nself.assertEquals(self.list_feed.entry[0].email_list.name, \"us-sales\")\nself.assertEquals(self.list_feed.entry[1].email_list.name, \"us-eng\")", "path": "libs\\external_libs\\gdata.py-1.0.13\\tests\\gdata_tests\\apps_test.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Tests the return value of GetXXXLink() methods\"\"\"\n\n", "func_signal": "def testLinkFinderFindsHtmlLink(self):\n", "code": "self.assert_(self.list_entry.GetSelfLink() is not None)\nself.assert_(self.list_entry.GetEditLink() is not None)\nself.assert_(self.list_entry.GetHtmlLink() is None)", "path": "libs\\external_libs\\gdata.py-1.0.13\\tests\\gdata_tests\\apps_test.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Tests the existence of <atom:title> in UserEntry and verifies\nthe value\"\"\"\n\n", "func_signal": "def testTitle(self):\n", "code": "self.assert_(\n  isinstance(self.user_entry.title, atom.Title),\n  \"User entry <atom:title> element must be an instance of atom.Title: %s\" %\n  self.user_entry.title)\n  \nself.assertEquals(self.user_entry.title.text, 'TestUser')", "path": "libs\\external_libs\\gdata.py-1.0.13\\tests\\gdata_tests\\apps_test.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Tests for modifing attributes of UserEntry\"\"\"\n\n", "func_signal": "def testUpdate(self):\n", "code": "self.user_entry.name.family_name = 'ModifiedFamilyName'\nself.user_entry.name.given_name = 'ModifiedGivenName'\nself.user_entry.quota.limit = '2048'\nself.user_entry.login.password = 'ModifiedPassword'\nself.user_entry.login.suspended = 'true'\nmodified = gdata.apps.UserEntryFromString(self.user_entry.ToString())\n\nself.assertEquals(modified.name.family_name, 'ModifiedFamilyName')\nself.assertEquals(modified.name.given_name, 'ModifiedGivenName')\nself.assertEquals(modified.quota.limit, '2048')\nself.assertEquals(modified.login.password, 'ModifiedPassword')\nself.assertEquals(modified.login.suspended, 'true')", "path": "libs\\external_libs\\gdata.py-1.0.13\\tests\\gdata_tests\\apps_test.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Tests the return value of GetXXXLink() methods\"\"\"\n\n", "func_signal": "def testLinkFinderFindsHtmlLink(self):\n", "code": "self.assert_(self.rcpt_entry.GetSelfLink() is not None)\nself.assert_(self.rcpt_entry.GetEditLink() is not None)\nself.assert_(self.rcpt_entry.GetHtmlLink() is None)", "path": "libs\\external_libs\\gdata.py-1.0.13\\tests\\gdata_tests\\apps_test.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Tests the existence of <atom:id> in EmailListRecipientEntry and\nverifies the value\"\"\"\n\n", "func_signal": "def testId(self):\n", "code": "self.assert_(\n  isinstance(self.rcpt_entry.id, atom.Id),\n  \"EmailListRecipient entry <atom:id> element must be an instance of \" +\n  \"atom.Id: %s\" %\n  self.rcpt_entry.id)\n\nself.assertEquals(\n  self.rcpt_entry.id.text,\n  'https://www.google.com/a/feeds/example.com/emailList/2.0/us-sales/' +\n  'recipient/TestUser%40example.com')", "path": "libs\\external_libs\\gdata.py-1.0.13\\tests\\gdata_tests\\apps_test.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Parse `self.input` into a document tree.\"\"\"\n", "func_signal": "def parse(self):\n", "code": "self.document = document = self.new_document()\nself.parser.parse(self.input, document)\ndocument.current_source = document.current_line = None", "path": "libs\\external_libs\\docutils-0.4\\docutils\\readers\\__init__.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Retrieves a list of a user's WP documents and displays them.\"\"\"\n", "func_signal": "def _ListAllWPDocuments(self):\n", "code": "query = gdata.docs.service.DocumentQuery(categories=['document'])\nfeed = self.gd_client.Query(query.ToUri())\nself._PrintFeed(feed)", "path": "libs\\external_libs\\gdata.py-1.0.13\\samples\\docs\\docs_example.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Retrieves a list of a user's presentations and displays them.\"\"\"\n", "func_signal": "def _ListAllPresentations(self):\n", "code": "query = gdata.docs.service.DocumentQuery(categories=['presentation'])\nfeed = self.gd_client.Query(query.ToUri())\nself._PrintFeed(feed)", "path": "libs\\external_libs\\gdata.py-1.0.13\\samples\\docs\\docs_example.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Tests the return value of GetXXXLink() methods\"\"\"\n\n", "func_signal": "def testLinkFinderFindsHtmlLink(self):\n", "code": "self.assert_(self.user_entry.GetSelfLink() is not None)\nself.assert_(self.user_entry.GetEditLink() is not None)\nself.assert_(self.user_entry.GetHtmlLink() is None)", "path": "libs\\external_libs\\gdata.py-1.0.13\\tests\\gdata_tests\\apps_test.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Tests the existence of <atom:updated> in UserEntry and verifies\nthe value\"\"\"\n\n", "func_signal": "def testUpdated(self):\n", "code": "self.assert_(\n  isinstance(self.user_entry.updated, atom.Updated),\n  \"User entry <atom:updated> element must be an instance of \" +\n  \"atom.Updated: %s\" % self.user_entry.updated)\n\nself.assertEquals(self.user_entry.updated.text,\n                  '1970-01-01T00:00:00.000Z')", "path": "libs\\external_libs\\gdata.py-1.0.13\\tests\\gdata_tests\\apps_test.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\"Tests the existence of <openSearch:startIndex> in NicknameFeed\nand verifies the value\"\"\"\n\n", "func_signal": "def testStartItem(self):\n", "code": "self.assert_(isinstance(self.nick_feed.start_index, gdata.StartIndex),\n    \"Nickname feed <openSearch:startIndex> element must be an instance \" +\n    \"of gdata.OpenSearch: %s\" % self.nick_feed.start_index)\nself.assertEquals(self.nick_feed.start_index.text, \"1\")", "path": "libs\\external_libs\\gdata.py-1.0.13\\tests\\gdata_tests\\apps_test.py", "repo_name": "indro/t2c", "stars": 3, "license": "mit", "language": "python", "size": 6820}
{"docstring": "\"\"\" \uac01 resource\ub9c8\ub2e4 \ud544\uc694\ud55c \ud6c4\ucc98\ub9ac\ub97c \ud560 \uc218 \uc788\ub2e4 \"\"\"\n# set direct accessor\n", "func_signal": "def process_resource(self, resource_dict):\n", "code": "[setattr(self, key, value) for key, value in resource_dict.iteritems()]\n# unicode\nfor key, value in resource_dict.iteritems():\n    if isinstance(value, str):\n        setattr(self, key, eval('u\"\"\"%s\"\"\"' % value))\n# alias id\nif \"identifier\" in resource_dict:\n    setattr(self, \"id\", resource_dict[\"identifier\"])", "path": "springnote.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\" /pages/:page_id.json\uc5d0 \uc811\uadfc\ud558\uc5ec page\ub97c \uac00\uc838\uc635\ub2c8\ub2e4. \"\"\"\n", "func_signal": "def page(self, note, id, params={}):\n", "code": "params['domain'] = note\npath  = \"/pages/%d.json\" % id\npath += \"?%s\" % urllib.urlencode(params) if params else ''\nmethod = \"GET\"\n\nnew_page = Page(self.access_token)\nnew_page.request(path, method, params)\nreturn new_page", "path": "springnote.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "# verify that the nonce is uniqueish\n", "func_signal": "def _check_nonce(self, consumer, token, nonce):\n", "code": "nonce = self.data_store.lookup_nonce(consumer, token, nonce)\nif nonce:\n    raise OAuthError('Nonce already used: %s' % str(nonce))", "path": "lib\\oauth.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "# -> consumer and token\n", "func_signal": "def verify_request(self, oauth_request):\n", "code": "version = self._get_version(oauth_request)\nconsumer = self._get_consumer(oauth_request)\n# get the access token\ntoken = self._get_token(oauth_request, 'access')\nself._check_signature(oauth_request, consumer, token)\nparameters = oauth_request.get_nonoauth_parameters()\nreturn consumer, token, parameters", "path": "lib\\oauth.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\" Consumer\uc758 \uc790\uaca9\uc73c\ub85c Service Provider\ub85c\ubd80\ud130 access token\uc744 \ubc1b\uc544\uc628\ub2e4  \"\"\"\n", "func_signal": "def fetch_access_token(self, token):\n", "code": "conn = self.springnote_request('POST', self.ACCESS_TOKEN_URL, sign_token=token)\n\nresponse = conn.getresponse()\nself.access_token = oauth.OAuthToken.from_string(response.read())\n\nreturn self.access_token", "path": "springnote.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Scan the string s for a JSON string. End is the index of the\ncharacter in s after the quote that started the JSON string.\nUnescapes all valid JSON string escape sequences and raises ValueError\non attempt to decode an invalid string. If strict is False then literal\ncontrol characters are allowed in the string.\n\nReturns a tuple of the decoded string and the index of the character in s\nafter the end quote.\"\"\"\n", "func_signal": "def py_scanstring(s, end, encoding=None, strict=True, _b=BACKSLASH, _m=STRINGCHUNK.match):\n", "code": "if encoding is None:\n    encoding = DEFAULT_ENCODING\nchunks = []\n_append = chunks.append\nbegin = end - 1\nwhile 1:\n    chunk = _m(s, end)\n    if chunk is None:\n        raise ValueError(\n            errmsg(\"Unterminated string starting at\", s, begin))\n    end = chunk.end()\n    content, terminator = chunk.groups()\n    # Content is contains zero or more unescaped string characters\n    if content:\n        if not isinstance(content, unicode):\n            content = unicode(content, encoding)\n        _append(content)\n    # Terminator is the end of string, a literal control character,\n    # or a backslash denoting that an escape sequence follows\n    if terminator == '\"':\n        break\n    elif terminator != '\\\\':\n        if strict:\n            msg = \"Invalid control character %r at\" % (terminator,)\n            #msg = \"Invalid control character {0!r} at\".format(terminator)\n            raise ValueError(errmsg(msg, s, end))\n        else:\n            _append(terminator)\n            continue\n    try:\n        esc = s[end]\n    except IndexError:\n        raise ValueError(\n            errmsg(\"Unterminated string starting at\", s, begin))\n    # If not a unicode escape sequence, must be in the lookup table\n    if esc != 'u':\n        try:\n            char = _b[esc]\n        except KeyError:\n            msg = \"Invalid \\\\escape: \" + repr(esc)\n            raise ValueError(errmsg(msg, s, end))\n        end += 1\n    else:\n        # Unicode escape sequence\n        esc = s[end + 1:end + 5]\n        next_end = end + 5\n        if len(esc) != 4:\n            msg = \"Invalid \\\\uXXXX escape\"\n            raise ValueError(errmsg(msg, s, end))\n        uni = int(esc, 16)\n        # Check for surrogate pair on UCS-4 systems\n        if 0xd800 <= uni <= 0xdbff and sys.maxunicode > 65535:\n            msg = \"Invalid \\\\uXXXX\\\\uXXXX surrogate pair\"\n            if not s[end + 5:end + 7] == '\\\\u':\n                raise ValueError(errmsg(msg, s, end))\n            esc2 = s[end + 7:end + 11]\n            if len(esc2) != 4:\n                raise ValueError(errmsg(msg, s, end))\n            uni2 = int(esc2, 16)\n            uni = 0x10000 + (((uni - 0xd800) << 10) | (uni2 - 0xdc00))\n            next_end += 6\n        char = unichr(uni)\n        end = next_end\n    # Append the unescaped character\n    _append(char)\nreturn u''.join(chunks), end", "path": "lib\\simplejson\\decoder.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "# build the base signature string\n", "func_signal": "def build_signature(self, oauth_request, consumer, token):\n", "code": "key, raw = self.build_signature_base_string(oauth_request, consumer, token)\n\n# hmac object\ntry:\n    import hashlib # 2.5\n    hashed = hmac.new(key, raw, hashlib.sha1)\nexcept:\n    import sha # deprecated\n    hashed = hmac.new(key, raw, sha)\n\n# calculate the digest base 64\nreturn base64.b64encode(hashed.digest())", "path": "lib\\oauth.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\" tags\ub97c \ubc30\uc5f4\ub85c \ubcc0\ud658\ud55c\ub2e4 \"\"\"\n", "func_signal": "def process_resource(self, resource_dict):\n", "code": "SpringnoteResource.process_resource(self, resource_dict)\nif \"tags\" in resource_dict:\n    self.tags = filter(None, self.tags.split(','))", "path": "springnote.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "# verify that timestamp is recentish\n", "func_signal": "def _check_timestamp(self, timestamp):\n", "code": "timestamp = int(timestamp)\nnow = int(time.time())\nlapsed = now - timestamp\nif lapsed > self.timestamp_threshold:\n    raise OAuthError('Expired timestamp: given %d and now %s has a greater difference than threshold %d' % (timestamp, now, self.timestamp_threshold))", "path": "lib\\oauth.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\" /pages/:page_id.json\uc5d0 \uc811\uadfc\ud558\uc5ec page\ub97c \uc218\uc815\ud569\ub2c8\ub2e4. \"\"\"\n", "func_signal": "def save(self):\n", "code": "path = \"/pages/%d.json\" % self.id\nmethod = \"PUT\"\n\nself.request(path, method, data=self._writable_resources())\nreturn self", "path": "springnote.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "# combine multiple parameter sources\n", "func_signal": "def from_request(http_method, http_url, headers=None, parameters=None, query_string=None):\n", "code": "if parameters is None:\n    parameters = {}\n\n# headers\nif headers and 'Authorization' in headers:\n    auth_header = headers['Authorization']\n    # check that the authorization header is OAuth\n    if auth_header.index('OAuth') > -1:\n        try:\n            # get the parameters from the header\n            header_params = OAuthRequest._split_header(auth_header)\n            parameters.update(header_params)\n        except:\n            raise OAuthError('Unable to parse OAuth parameters from Authorization header.')\n\n# GET or POST query string\nif query_string:\n    query_params = OAuthRequest._split_url_string(query_string)\n    parameters.update(query_params)\n\n# URL parameters\nparam_str = urlparse.urlparse(http_url)[4] # query\nurl_params = OAuthRequest._split_url_string(param_str)\nparameters.update(url_params)\n\nif parameters:\n    return OAuthRequest(http_method, http_url, parameters)\n\nreturn None", "path": "lib\\oauth.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\" Consumer\uc758 \uc790\uaca9\uc73c\ub85c Service Provider\ub85c\ubd80\ud130 request token\uc744 \ubc1b\uc544\uc628\ub2e4 \"\"\"\n", "func_signal": "def fetch_request_token(self):\n", "code": "conn = self.springnote_request('POST', self.REQUEST_TOKEN_URL)\n\nresponse = conn.getresponse()\nif response.status == 401:\n    springnote_error = SpringnoteError.find_error(response)\n    raise springnote_error\nreturn oauth.OAuthToken.from_string(response.read())", "path": "springnote.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\" Consumer\uc758 \uc790\uaca9\uc73c\ub85c User\uc5d0\uac8c request token\uc744 \uc2b9\uc778\ubc1b\uc744 url \"\"\"\n", "func_signal": "def authorize_url(self, token, callback=None):\n", "code": "ret = \"%s?oauth_token=%s\" % (self.AUTHORIZATION_URL, token.key)\nif callback:\n    ret += \"&oauth_callback=%s\" % escape(callback)\nreturn ret", "path": "springnote.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\" finds files that end with '_test.py', recursively \"\"\"\n#test_file_pattern = re.compile('^t(est)?_.*\\.py$')\n", "func_signal": "def find_all_test_files(filename_arg='*'):\n", "code": "test_file_pattern = re.compile('.*_test\\.py$')\nis_test = lambda filename: test_file_pattern.match(filename)\ndrop_dot_py = lambda filename: filename[:-3]\njoin_module = lambda *names: '.'.join(names) if len(filter(None, names)) > 1 else names[-1]\n#return [drop_dot_py(module) for module in filter(is_test, os.listdir(os.curdir))]\ncheck_filename = True if os.path.isfile(filename_arg) else False\nmodules = []\nfor root, dirs, files in os.walk(os.curdir):\n    root_name = os.path.split(root)[-1].lstrip('.')\n    if check_filename:\n        files = filter(lambda x: x == filename_arg, files)\n    for test_file in filter(is_test, files):\n        modules.append(join_module(root_name, drop_dot_py(test_file)))\n    #modules += ['.'.join([root_name, drop_dot_py(test_file)]) for test_file in filter(is_test, files)]\nreturn modules", "path": "alltests.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\"Return the Python representation of ``s`` (a ``str`` or ``unicode``\ninstance containing a JSON document)\n\n\"\"\"\n", "func_signal": "def decode(self, s, _w=WHITESPACE.match):\n", "code": "obj, end = self.raw_decode(s, idx=_w(s, 0).end())\nend = _w(s, end).end()\nif end != len(s):\n    raise ValueError(errmsg(\"Extra data\", s, end, len(s)))\nreturn obj", "path": "lib\\simplejson\\decoder.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "# list of objects\n", "func_signal": "def parse_dictionary(params, recursive=True):\n", "code": "if isinstance(params, list):\n    return [OpenStruct.parse_dictionary(d) for d in params]\n# single object\nelif isinstance(params, dict):\n    def nestable(value):\n        return isinstance(value, dict) and recursive\n    d = {}\n    for key, value in params.iteritems():\n        # nest if value is dictionary\n        if nestable(value):\n            value = OpenStruct.parse(value, recursive)\n        # check if value is list with dictionary inside\n        elif isinstance(value, list):\n            value = [\n                OpenStruct.parse(v, recursive)  \\\n                if nestable(v) else v           \\\n                for v in value[:]               \\\n            ]\n        # type conversion\n        if key == \"pubDate\":\n            value = datetime.strptime(value[:-5], ME2DAY_DATETIME_FORMAT)\n        d[key] = value\n    return d\nelse:\n    return params", "path": "me2day.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "# set the signature method\n", "func_signal": "def sign_request(self, signature_method, consumer, token):\n", "code": "self.set_parameter('oauth_signature_method', signature_method.get_name())\n# set the signature\nself.set_parameter('oauth_signature', self.build_signature(signature_method, consumer, token))", "path": "lib\\oauth.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\" springnote\uc5d0 request\ub97c \ubcf4\ub0c5\ub2c8\ub2e4. \n    SpringnoteResource\ub97c \uc0c1\uc18d \ubc1b\ub294 \ubaa8\ub4e0 \ud558\uc704\ud074\ub798\uc2a4\uc5d0\uc11c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \"\"\"\n\n", "func_signal": "def request(self, path, method=\"GET\", params={}, data=None):\n", "code": "url = \"http://%s/%s\" % (Springnote.BASEURL, path.lstrip('/'))\nheaders = {'Content-Type': 'application/json'}\nif data: # set body if any\n    data = {self.__class__.__name__.lower(): data}\n    data = json.dumps(data, ensure_ascii=False)\n    data = data.encode('utf-8')\n\nconn = Springnote.springnote_request(method, url, params, headers, data, sign_token=self.access_token, secure=False)\n\n# get response\nresponse = conn.getresponse()\nif response.status != httplib.OK:\n    raise SpringnoteError.find_error(response)\n\nself.build_from_response(response.read())", "path": "springnote.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "# Note that this function is called from _speedups\n", "func_signal": "def errmsg(msg, doc, pos, end=None):\n", "code": "lineno, colno = linecol(doc, pos)\nif end is None:\n    #fmt = '{0}: line {1} column {2} (char {3})'\n    #return fmt.format(msg, lineno, colno, pos)\n    fmt = '%s: line %d column %d (char %d)'\n    return fmt % (msg, lineno, colno, pos)\nendlineno, endcolno = linecol(doc, end)\n#fmt = '{0}: line {1} column {2} - line {3} column {4} (char {5} - {6})'\n#return fmt.format(msg, lineno, colno, endlineno, endcolno, pos, end)\nfmt = '%s: line %d column %d - line %d column %d (char %d - %d)'\nreturn fmt % (msg, lineno, colno, endlineno, endcolno, pos, end)", "path": "lib\\simplejson\\decoder.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "# already have an access token\n", "func_signal": "def __init__(self, access_token=None):\n", "code": "if access_token:\n    self.access_token = oauth.OAuthToken(*access_token)", "path": "springnote.py", "repo_name": "jangxyz/me2chatnote", "stars": 2, "license": "None", "language": "python", "size": 144}
{"docstring": "\"\"\" Saves the exception file as a repr(dict) \"\"\"\n", "func_signal": "def _save_exception_file( self, ex_path, exceptions ):\n", "code": "try:\n    if ( not os.path.isdir( os.path.split( ex_path )[ 0 ] ) ):\n        os.makedirs( os.path.split( ex_path )[ 0 ] )\n    ex_file = open( ex_path, \"w\" )\n    ex_file.write( repr( exceptions ) )\n    ex_file.close()\nexcept: pass", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\scrapers\\lyricwikiapi\\lyricsScraper.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" *required: Returns song lyrics or a list of choices from artist & song \"\"\"\n# format artist and song, check for exceptions\n", "func_signal": "def get_lyrics( self, artist, song ):\n", "code": "artist = self._format_param( artist )\nsong = self._format_param( song, False )\n# fetch lyrics\nlyrics = self._fetch_lyrics( artist, song )\n# if no lyrics found try just artist for a list of songs\nif ( not lyrics ):\n    # fetch song list\n    song_list = self._get_song_list( artist )\n    return song_list\nelse: return lyrics", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\scrapers\\lyricwikiapi\\lyricsScraper.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" setup default values if none obtained \"\"\"\n", "func_signal": "def _use_defaults( self, current_settings=None, save=True ):\n", "code": "LOG( LOG_NOTICE, \"%s (ver: %s) used default settings\", __scriptname__, __version__ )\nsettings = {}\ndefaults = {  \n    \"scraper\": \"lyricwiki\",\n    \"save_lyrics\": True,\n    \"lyrics_path\": os.path.join( BASE_DATA_PATH, \"lyrics\" ),\n    \"smooth_scrolling\": False,\n    \"show_viz\": True,\n    \"use_filename\": False,\n    \"filename_format\": 0,\n    \"music_path\": \"\",\n    \"shuffle\": True,\n    \"compatible\": False,\n    \"use_extension\": True,\n    }\nfor key, value in defaults.items():\n    # add default values for missing settings\n    settings[ key ] = current_settings.get( key, defaults[ key ] )\nsettings[ \"version\" ] = __version__\nif ( save ):\n    ok = self.save_settings( settings )\nreturn settings", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\lib\\utilities.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" Fetch lyrics if available \"\"\"\n", "func_signal": "def _fetch_lyrics( self, url ):\n", "code": "try:\n    # Open url or local file (if debug)\n    if ( not debug ):\n        usock = urllib.urlopen( url )\n    else:\n        usock = open( os.path.join( os.getcwd(), \"lyrics_source.txt\" ), \"r\" )\n    htmlSource = usock.read()\n    usock.close()\n    # Save htmlSource to a file for testing scraper (if debugWrite)\n    if ( debugWrite ):\n        file_object = open( os.path.join( os.getcwd(), \"lyrics_source.txt\" ), \"w\" )\n        file_object.write( htmlSource )\n        file_object.close()\n    # Parse htmlSource for lyrics\n    parser = _LyricsParser()\n    parser.feed( htmlSource )\n    parser.close()\n    return parser.lyrics\nexcept:\n    return None", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\scrapers\\lyricwiki\\lyricsScraper.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" shows a numeric dialog and returns a value\n    - 0 : ShowAndGetNumber\t\t(default format: #)\n    - 1 : ShowAndGetDate\t\t\t(default format: DD/MM/YYYY)\n    - 2 : ShowAndGetTime\t\t\t(default format: HH:MM)\n    - 3 : ShowAndGetIPAddress\t(default format: #.#.#.#)\n\"\"\"\n", "func_signal": "def get_numeric_dialog( default=\"\", heading=\"\", dlg_type=3 ):\n", "code": "dialog = xbmcgui.Dialog()\nvalue = dialog.numeric( type, heading, default )\nreturn value", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\lib\\utilities.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" If no lyrics found, fetch a list of choices \"\"\"\n", "func_signal": "def _get_song_list( self, artist ):\n", "code": "try:\n    url = self.base_url + \"/%s\"\n    # Open url or local file (if debug)\n    if ( not debug ):\n        usock = urllib.urlopen( url % ( artist, ) )\n    else:\n        usock = open( os.path.join( os.getcwd(), \"songs_source.txt\" ), \"r\" )\n    htmlSource = usock.read()\n    usock.close()\n    # Save htmlSource to a file for testing scraper (if debugWrite)\n    if ( debugWrite ):\n        file_object = open( os.path.join( os.getcwd(), \"songs_source.txt\" ), \"w\" )\n        file_object.write( htmlSource )\n        file_object.close()\n    # Parse htmlSource for song links\n    parser = _SongListParser()\n    parser.feed( htmlSource )\n    parser.close()\n    # Create sorted return list\n    song_list = self._remove_dupes( parser.song_list )\n    return song_list\nexcept:\n    return None", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\scrapers\\lyricwiki\\lyricsScraper.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" Sets exceptions for formatting artist \"\"\"\n", "func_signal": "def _set_exceptions( self, exception=None ):\n", "code": "try:\n    if ( __name__ == \"__main__\" ):\n        ex_path = os.path.join( os.getcwd(), \"exceptions.txt\" )\n    else:\n        name = __name__.replace( \"resources.scrapers.\", \"\" ).replace( \".lyricsScraper\", \"\" )\n        ex_path = os.path.join( xbmc.translatePath( \"P:\\\\script_data\" ), os.getcwd(), \"scrapers\", name, \"exceptions.txt\" )\n    ex_file = open( ex_path, \"r\" )\n    self.exceptions = eval( ex_file.read() )\n    ex_file.close()\nexcept:\n    self.exceptions = {}\nif ( exception is not None ):\n    self.exceptions[ exception[ 0 ] ] = exception[ 1 ]\n    self._save_exception_file( ex_path, self.exceptions )", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\scrapers\\lyricwikiapi\\lyricsScraper.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" Returns a sorted list with duplicates removed \"\"\"\n# this is apparently the fastest method\n", "func_signal": "def _remove_dupes( self, song_list ):\n", "code": "dupes = {}\nfor x in song_list:\n    dupes[ x ] = x\nnew_song_list = dupes.values()\nnew_song_list.sort()\nreturn new_song_list", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\scrapers\\lyricwiki\\lyricsScraper.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" shows a browse dialog and returns a value\n    - 0 : ShowAndGetDirectory\n    - 1 : ShowAndGetFile\n    - 2 : ShowAndGetImage\n    - 3 : ShowAndGetWriteableDirectory\n\"\"\"\n", "func_signal": "def get_browse_dialog( default=\"\", heading=\"\", dlg_type=1, shares=\"files\", mask=\"\", use_thumbs=False, treat_as_folder=False ):\n", "code": "dialog = xbmcgui.Dialog()\nvalue = dialog.browse( dlg_type, heading, shares, mask, use_thumbs, treat_as_folder, default )\nreturn value", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\lib\\utilities.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" Converts param to the form expected by www.lyricwiki.org \"\"\"\n", "func_signal": "def _format_param( self, param, exception=True ):\n", "code": "caps = True\nresult = \"\"\n# enumerate thru string to properly capitalize words (why doesn't title() do this properly?)\nfor letter in param.upper().strip():\n    if ( letter == \" \" ):\n        letter = \"_\"\n        caps = True\n    elif ( letter in \"(_-.\" ):\n        caps = True\n    elif ( unicode( letter.isalpha() ) and caps ):\n        caps = False\n    else:\n        letter = letter.lower()\n        caps = False\n    result += letter\nresult = result.replace( \"/\", \"_\" )\n# properly quote string for url\nresult = urllib.quote( result )\n# replace any exceptions\nif ( exception and result in self.exceptions ):\n    result = self.exceptions[ result ]\nreturn result", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\scrapers\\lyricwiki\\lyricsScraper.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" save settings \"\"\"\n", "func_signal": "def save_settings( self, settings ):\n", "code": "try:\n    settings_file = open( BASE_SETTINGS_PATH, \"w\" )\n    settings_file.write( repr( settings ) )\n    settings_file.close()\n    return True\nexcept:\n    LOG( LOG_ERROR, \"%s (rev: %s) %s::%s (%d) [%s]\", __scriptname__, __svn_revision__, self.__class__.__name__, sys.exc_info()[ 2 ].tb_frame.f_code.co_name, sys.exc_info()[ 2 ].tb_lineno, sys.exc_info()[ 1 ], )\n    return False", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\lib\\utilities.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" read settings \"\"\"\n", "func_signal": "def get_settings( self, defaults=False ):\n", "code": "try:\n    settings = {}\n    if ( defaults ): raise\n    settings_file = open( BASE_SETTINGS_PATH, \"r\" )\n    settings = eval( settings_file.read() )\n    settings_file.close()\n    if ( settings[ \"version\" ] not in SETTINGS_VERSIONS ):\n        raise\nexcept:\n    settings = self._use_defaults( settings, save=( defaults == False ) )\nreturn settings", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\lib\\utilities.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" Sets exceptions for formatting artist \"\"\"\n", "func_signal": "def _set_exceptions( self, exception=None ):\n", "code": "try:\n    if ( __name__ == \"__main__\" ):\n        ex_path = os.path.join( os.getcwd(), \"exceptions.txt\" )\n    else:\n        name = __name__.replace( \"resources.scrapers.\", \"\" ).replace( \".lyricsScraper\", \"\" )\n        ex_path = xbmc.translatePath( os.path.join( \"P:\\\\script_data\", os.getcwd(), \"scrapers\", name, \"exceptions.txt\" ) )\n    ex_file = open( ex_path, \"r\" )\n    self.exceptions = eval( ex_file.read() )\n    ex_file.close()\nexcept:\n    self.exceptions = {}\nif ( exception is not None ):\n    self.exceptions[ exception[ 0 ] ] = exception[ 1 ]\n    self._save_exception_file( ex_path, self.exceptions )", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\scrapers\\lyricwiki\\lyricsScraper.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" shows a credit window \"\"\"\n", "func_signal": "def show_credits():\n", "code": "import resources.lib.credits as credits\nc = credits.GUI( \"script-%s-credits.xml\" % ( __scriptname__.replace( \" \", \"_\" ), ), os.getcwd(), \"Default\" )\nc.doModal()\ndel c", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\lib\\utilities.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" Convert line terminators and html entities \"\"\"\n", "func_signal": "def _clean_text( self, text ):\n", "code": "try:\n    text = text.replace( \"\\t\", \"\" )\n    text = text.replace( \"<br> \", \"\\n\" )\n    text = text.replace( \"<br>\", \"\\n\" )\n    text = text.replace( \"<br /> \", \"\\n\" )\n    text = text.replace( \"<br />\", \"\\n\" )\n    text = text.replace( \"<div>\", \"\\n\" )\n    text = text.replace( \"> \", \"\\n\" )\n    text = text.replace( \">\", \"\\n\" )\n    text = text.replace( \"&amp;\", \"&\" )\n    text = text.replace( \"&gt;\", \">\" )\n    text = text.replace( \"&lt;\", \"<\" )\n    text = text.replace( \"&quot;\", '\"' )\nexcept: \n    pass\nreturn text", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\scrapers\\lyricwiki\\lyricsScraper.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" creates the base folders \"\"\"\n", "func_signal": "def _create_base_paths():\n", "code": "if ( not os.path.isdir( BASE_DATA_PATH ) ):\n    os.makedirs( BASE_DATA_PATH )", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\lib\\utilities.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" Saves the exception file as a repr(dict) \"\"\"\n", "func_signal": "def _save_exception_file( self, ex_path, exceptions ):\n", "code": "try:\n    if ( not os.path.isdir( os.path.split( ex_path )[ 0 ] ) ):\n        os.makedirs( os.path.split( ex_path )[ 0 ] )\n    ex_file = open( ex_path, \"w\" )\n    ex_file.write( repr( exceptions ) )\n    ex_file.close()\nexcept: pass", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\scrapers\\lyricwiki\\lyricsScraper.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" *required: Returns song lyrics from user selection - item[1]\"\"\"\n", "func_signal": "def get_lyrics_from_list( self, item ):\n", "code": "lyrics = self._fetch_lyrics( self.base_url + item[ 1 ] )\nreturn self._clean_text( lyrics )", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\scrapers\\lyricwiki\\lyricsScraper.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" *required: Returns song lyrics or a list of choices from artist & song \"\"\"\n", "func_signal": "def get_lyrics( self, artist, song ):\n", "code": "url = self.base_url + \"/%s:%s\"\nartist = self._format_param( artist )\nsong = self._format_param( song, False )\nlyrics = self._fetch_lyrics( url % ( artist, song, ) )\n# if no lyrics found try just artist for a list of songs\nif ( not lyrics ):\n    song_list = self._get_song_list( artist )\n    return song_list\nelse: return self._clean_text( lyrics )", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\scrapers\\lyricwiki\\lyricsScraper.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "\"\"\" shows a keyboard and returns a value \"\"\"\n", "func_signal": "def get_keyboard( default=\"\", heading=\"\", hidden=False ):\n", "code": "keyboard = xbmc.Keyboard( default, heading, hidden )\nkeyboard.doModal()\nif ( keyboard.isConfirmed() ):\n    return keyboard.getText()\nreturn default", "path": "MediaStream\\extras\\XBMC Lyrics\\resources\\lib\\utilities.py", "repo_name": "neuros/neuroslink-xbmc-mediastream", "stars": 3, "license": "None", "language": "python", "size": 38206}
{"docstring": "'''Destroys the status specified by the required ID parameter.\n\nThe twitter.Api instance must be authenticated and thee\nauthenticating user must be the author of the specified status.\n\nArgs:\n  id: The numerical ID of the status you're trying to destroy.\n\nReturns:\n  A twitter.Status instance representing the destroyed status message\n'''\n", "func_signal": "def DestroyStatus(self, id):\n", "code": "try:\n  if id:\n    int(id)\nexcept:\n  raise TwitterError(\"id must be an integer\")\nurl = 'http://twitter.com/statuses/destroy/%s.json' % id\njson = self._FetchUrl(url, post_data={})\ndata = simplejson.loads(json)\nreturn Status.NewFromJsonDict(data)", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "'''A dict representation of this twitter.User instance.\n\nThe return value uses the same key names as the JSON representation.\n\nReturn:\n  A dict representing this twitter.User instance\n'''\n", "func_signal": "def AsDict(self):\n", "code": "data = {}\nif self.id:\n  data['id'] = self.id\nif self.name:\n  data['name'] = self.name\nif self.screen_name:\n  data['screen_name'] = self.screen_name\nif self.location:\n  data['location'] = self.location\nif self.description:\n  data['description'] = self.description\nif self.profile_image_url:\n  data['profile_image_url'] = self.profile_image_url\nif self.url:\n  data['url'] = self.url\nif self.status:\n  data['status'] = self.status.AsDict()\nreturn data", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"Return a JSON string representation of a Python data structure.\n\n>>> JSONEncoder().encode({\"foo\": [\"bar\", \"baz\"]})\n'{\"foo\": [\"bar\", \"baz\"]}'\n\n\"\"\"\n# This is for extremely simple cases and benchmarks.\n", "func_signal": "def encode(self, o):\n", "code": "if isinstance(o, basestring):\n    if isinstance(o, str):\n        _encoding = self.encoding\n        if (_encoding is not None\n                and not (_encoding == 'utf-8')):\n            o = o.decode(_encoding)\n    if self.ensure_ascii:\n        return encode_basestring_ascii(o)\n    else:\n        return encode_basestring(o)\n# This doesn't pass the iterator directly to ''.join() because the\n# exceptions aren't as detailed.  The list call should be roughly\n# equivalent to the PySequence_Fast that ''.join() would do.\nchunks = self.iterencode(o, _one_shot=True)\nif not isinstance(chunks, (list, tuple)):\n    chunks = list(chunks)\nreturn ''.join(chunks)", "path": "simplejson\\encoder.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "'''Attempt to find the username in a cross-platform fashion.'''\n", "func_signal": "def _GetUsername(self):\n", "code": "return os.getenv('USER') or \\\n    os.getenv('LOGNAME') or \\\n    os.getenv('USERNAME') or \\\n    os.getlogin() or \\\n    'nobody'", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"Scan the string s for a JSON string. End is the index of the\ncharacter in s after the quote that started the JSON string.\nUnescapes all valid JSON string escape sequences and raises ValueError\non attempt to decode an invalid string. If strict is False then literal\ncontrol characters are allowed in the string.\n\nReturns a tuple of the decoded string and the index of the character in s\nafter the end quote.\"\"\"\n", "func_signal": "def py_scanstring(s, end, encoding=None, strict=True, _b=BACKSLASH, _m=STRINGCHUNK.match):\n", "code": "if encoding is None:\n    encoding = DEFAULT_ENCODING\nchunks = []\n_append = chunks.append\nbegin = end - 1\nwhile 1:\n    chunk = _m(s, end)\n    if chunk is None:\n        raise ValueError(\n            errmsg(\"Unterminated string starting at\", s, begin))\n    end = chunk.end()\n    content, terminator = chunk.groups()\n    # Content is contains zero or more unescaped string characters\n    if content:\n        if not isinstance(content, unicode):\n            content = unicode(content, encoding)\n        _append(content)\n    # Terminator is the end of string, a literal control character,\n    # or a backslash denoting that an escape sequence follows\n    if terminator == '\"':\n        break\n    elif terminator != '\\\\':\n        if strict:\n            msg = \"Invalid control character %r at\" % (terminator,)\n            #msg = \"Invalid control character {0!r} at\".format(terminator)\n            raise ValueError(errmsg(msg, s, end))\n        else:\n            _append(terminator)\n            continue\n    try:\n        esc = s[end]\n    except IndexError:\n        raise ValueError(\n            errmsg(\"Unterminated string starting at\", s, begin))\n    # If not a unicode escape sequence, must be in the lookup table\n    if esc != 'u':\n        try:\n            char = _b[esc]\n        except KeyError:\n            msg = \"Invalid \\\\escape: \" + repr(esc)\n            raise ValueError(errmsg(msg, s, end))\n        end += 1\n    else:\n        # Unicode escape sequence\n        esc = s[end + 1:end + 5]\n        next_end = end + 5\n        if len(esc) != 4:\n            msg = \"Invalid \\\\uXXXX escape\"\n            raise ValueError(errmsg(msg, s, end))\n        uni = int(esc, 16)\n        # Check for surrogate pair on UCS-4 systems\n        if 0xd800 <= uni <= 0xdbff and sys.maxunicode > 65535:\n            msg = \"Invalid \\\\uXXXX\\\\uXXXX surrogate pair\"\n            if not s[end + 5:end + 7] == '\\\\u':\n                raise ValueError(errmsg(msg, s, end))\n            esc2 = s[end + 7:end + 11]\n            if len(esc2) != 4:\n                raise ValueError(errmsg(msg, s, end))\n            uni2 = int(esc2, 16)\n            uni = 0x10000 + (((uni - 0xd800) << 10) | (uni2 - 0xdc00))\n            next_end += 6\n        char = unichr(uni)\n        end = next_end\n    # Append the unescaped character\n    _append(char)\nreturn u''.join(chunks), end", "path": "simplejson\\decoder.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "'''Returns a single status message.\n\nThe twitter.Api instance must be authenticated if the status message is private.\n\nArgs:\n  id: The numerical ID of the status you're trying to retrieve.\n\nReturns:\n  A twitter.Status instance representing that status message\n'''\n", "func_signal": "def GetStatus(self, id):\n", "code": "try:\n  if id:\n    int(id)\nexcept:\n  raise TwitterError(\"id must be an integer\")\nurl = 'http://twitter.com/statuses/show/%s.json' % id\njson = self._FetchUrl(url)\ndata = simplejson.loads(json)\nreturn Status.NewFromJsonDict(data)", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "'''Post a twitter status message from the authenticated user.\n\nThe twitter.Api instance must be authenticated.\n\nArgs:\n  text: The message text to be posted.  Must be less than 140 characters.\n\nReturns:\n  A twitter.Status instance representing the message posted\n'''\n", "func_signal": "def PostUpdate(self, text):\n", "code": "if not self._username:\n  raise TwitterError(\"The twitter.Api instance must be authenticated.\")\nif len(text) > 140:\n  raise TwitterError(\"Text must be less than or equal to 140 characters.\")\nurl = 'http://twitter.com/statuses/update.json'\ndata = {'status': text}\njson = self._FetchUrl(url, post_data=data)\ndata = simplejson.loads(json)\nreturn Status.NewFromJsonDict(data)", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "'''Set the username and password for this instance\n\nArgs:\n  username: The twitter username.\n  password: The twitter password.\n'''\n", "func_signal": "def SetCredentials(self, username, password):\n", "code": "self._username = username\nself._password = password", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "# Break url into consituent parts\n", "func_signal": "def _BuildUrl(self, url, path_elements=None, extra_params=None):\n", "code": "(scheme, netloc, path, params, query, fragment) = urlparse.urlparse(url)\n\n# Add any additional path elements to the path\nif path_elements:\n  # Filter out the path elements that have a value of None\n  p = [i for i in path_elements if i]\n  if not path.endswith('/'):\n    path += '/'\n  path += '/'.join(p)\n\n# Add any additional query parameters to the query string\nif extra_params and len(extra_params) > 0:\n  extra_query = self._EncodeParameters(extra_params)\n  # Add it to the existing query\n  if query:\n    query += '&' + extra_query\n  else:\n    query = extra_query\n\n# Return the rebuilt URL\nreturn urlparse.urlunparse((scheme, netloc, path, params, query, fragment))", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "'''Destroys the direct message specified in the required ID parameter.\n\nThe twitter.Api instance must be authenticated, and the\nauthenticating user must be the recipient of the specified direct\nmessage.\n\nArgs:\n  id: The id of the direct message to be destroyed\n\nReturns:\n  A twitter.DirectMessage instance representing the message destroyed\n'''\n", "func_signal": "def DestroyDirectMessage(self, id):\n", "code": "url = 'http://twitter.com/direct_messages/destroy/%s.json' % id\njson = self._FetchUrl(url, post_data={})\ndata = simplejson.loads(json)\nreturn DirectMessage.NewFromJsonDict(data)", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "'''Create a new instance based on a JSON dict.\n\nArgs:\n  data: A JSON dict, as converted from the JSON in the twitter API\nReturns:\n  A twitter.User instance\n'''\n", "func_signal": "def NewFromJsonDict(data):\n", "code": "if 'status' in data:\n  status = Status.NewFromJsonDict(data['status'])\nelse:\n  status = None\nreturn User(id=data.get('id', None),\n            name=data.get('name', None),\n            screen_name=data.get('screen_name', None),\n            location=data.get('location', None),\n            description=data.get('description', None),\n            profile_image_url=data.get('profile_image_url', None),\n            url=data.get('url', None),\n            status=status)", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "'''Fetch the sequence of public twitter.Status messages for a single user.\n\nThe twitter.Api instance must be authenticated if the user is private.\n\nArgs:\n  user:\n    either the username (short_name) or id of the user to retrieve.  If\n    not specified, then the current authenticated user is used. [optional]\n  count: the number of status messages to retrieve [optional]\n  since:\n    Narrows the returned results to just those statuses created\n    after the specified HTTP-formatted date. [optional]\n\nReturns:\n  A sequence of twitter.Status instances, one for each message up to count\n'''\n", "func_signal": "def GetUserTimeline(self, user=None, count=None, since=None):\n", "code": "try:\n  if count:\n    int(count)\nexcept:\n  raise TwitterError(\"Count must be an integer\")\nparameters = {}\nif count:\n  parameters['count'] = count\nif since:\n  parameters['since'] = since\nif user:\n  url = 'http://twitter.com/statuses/user_timeline/%s.json' % user\nelif not user and not self._username:\n  raise TwitterError(\"User must be specified if API is not authenticated.\")\nelse:\n  url = 'http://twitter.com/statuses/user_timeline.json'\njson = self._FetchUrl(url, parameters=parameters)\ndata = simplejson.loads(json)\nreturn [Status.NewFromJsonDict(x) for x in data]", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "'''Discontinues friendship with the user specified in the user parameter.\n\nThe twitter.Api instance must be authenticated.\n\nArgs:\n  The ID or screen name of the user  with whom to discontinue friendship.\nReturns:\n  A twitter.User instance representing the discontinued friend.\n'''\n", "func_signal": "def DestroyFriendship(self, user):\n", "code": "url = 'http://twitter.com/friendships/destroy/%s.json' % user\njson = self._FetchUrl(url, post_data={})\ndata = simplejson.loads(json)\nreturn User.NewFromJsonDict(data)", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "'''Fetch the sequence of twitter.User instances, one for each friend.\n\nArgs:\n  user: the username or id of the user whose friends you are fetching.  If\n  not specified, defaults to the authenticated user. [optional]\n\nThe twitter.Api instance must be authenticated.\n\nReturns:\n  A sequence of twitter.User instances, one for each friend\n'''\n", "func_signal": "def GetFriends(self, user=None):\n", "code": "if not self._username:\n  raise TwitterError(\"twitter.Api instance must be authenticated\")\nif user:\n  url = 'http://twitter.com/statuses/friends/%s.json' % user\nelse:\n  url = 'http://twitter.com/statuses/friends.json'\njson = self._FetchUrl(url)\ndata = simplejson.loads(json)\nreturn [User.NewFromJsonDict(x) for x in data]", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "'''Set the X-Twitter HTTP headers that will be sent to the server.\n\nArgs:\n  client:\n     The client name as a string.  Will be sent to the server as\n     the 'X-Twitter-Client' header.\n  url:\n     The URL of the meta.xml as a string.  Will be sent to the server\n     as the 'X-Twitter-Client-URL' header.\n  version:\n     The client version as a string.  Will be sent to the server\n     as the 'X-Twitter-Client-Version' header.\n'''\n", "func_signal": "def SetXTwitterHeaders(self, client, url, version):\n", "code": "self._request_headers['X-Twitter-Client'] = client\nself._request_headers['X-Twitter-Client-URL'] = url\nself._request_headers['X-Twitter-Client-Version'] = version", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "'''Post a twitter direct message from the authenticated user\n\nThe twitter.Api instance must be authenticated.\n\nArgs:\n  user: The ID or screen name of the recipient user.\n  text: The message text to be posted.  Must be less than 140 characters.\n\nReturns:\n  A twitter.DirectMessage instance representing the message posted\n'''\n", "func_signal": "def PostDirectMessage(self, user, text):\n", "code": "if not self._username:\n  raise TwitterError(\"The twitter.Api instance must be authenticated.\")\nurl = 'http://twitter.com/direct_messages/new.json'\ndata = {'text': text, 'user': user}\njson = self._FetchUrl(url, post_data=data)\ndata = simplejson.loads(json)\nreturn DirectMessage.NewFromJsonDict(data)", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "'''Fetch the sequence of twitter.User instances, one for each follower\n\nThe twitter.Api instance must be authenticated.\n\nReturns:\n  A sequence of twitter.User instances, one for each follower\n'''\n", "func_signal": "def GetFollowers(self):\n", "code": "if not self._username:\n  raise TwitterError(\"twitter.Api instance must be authenticated\")\nurl = 'http://twitter.com/statuses/followers.json'\njson = self._FetchUrl(url)\ndata = simplejson.loads(json)\nreturn [User.NewFromJsonDict(x) for x in data]", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "'''Create a new instance based on a JSON dict.\n\nArgs:\n  data: A JSON dict, as converted from the JSON in the twitter API\nReturns:\n  A twitter.Status instance\n'''\n", "func_signal": "def NewFromJsonDict(data):\n", "code": "if 'user' in data:\n  user = User.NewFromJsonDict(data['user'])\nelse:\n  user = None\nreturn Status(created_at=data.get('created_at', None),\n              id=data.get('id', None),\n              text=data.get('text', None),\n              user=user)", "path": "twitter.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"Return a JSON representation of a Python string\n\n\"\"\"\n", "func_signal": "def encode_basestring(s):\n", "code": "def replace(match):\n    return ESCAPE_DCT[match.group(0)]\nreturn '\"' + ESCAPE.sub(replace, s) + '\"'", "path": "simplejson\\encoder.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"Encode the given object and yield each string\nrepresentation as available.\n\nFor example::\n\n    for chunk in JSONEncoder().iterencode(bigobject):\n        mysocket.write(chunk)\n\n\"\"\"\n", "func_signal": "def iterencode(self, o, _one_shot=False):\n", "code": "if self.check_circular:\n    markers = {}\nelse:\n    markers = None\nif self.ensure_ascii:\n    _encoder = encode_basestring_ascii\nelse:\n    _encoder = encode_basestring\nif self.encoding != 'utf-8':\n    def _encoder(o, _orig_encoder=_encoder, _encoding=self.encoding):\n        if isinstance(o, str):\n            o = o.decode(_encoding)\n        return _orig_encoder(o)\n\ndef floatstr(o, allow_nan=self.allow_nan, _repr=FLOAT_REPR, _inf=INFINITY, _neginf=-INFINITY):\n    # Check for specials.  Note that this type of test is processor- and/or\n    # platform-specific, so do tests which don't depend on the internals.\n\n    if o != o:\n        text = 'NaN'\n    elif o == _inf:\n        text = 'Infinity'\n    elif o == _neginf:\n        text = '-Infinity'\n    else:\n        return _repr(o)\n\n    if not allow_nan:\n        raise ValueError(\n            \"Out of range float values are not JSON compliant: \" +\n            repr(o))\n\n    return text\n\n\nif _one_shot and c_make_encoder is not None and not self.indent and not self.sort_keys:\n    _iterencode = c_make_encoder(\n        markers, self.default, _encoder, self.indent,\n        self.key_separator, self.item_separator, self.sort_keys,\n        self.skipkeys, self.allow_nan)\nelse:\n    _iterencode = _make_iterencode(\n        markers, self.default, _encoder, self.indent, floatstr,\n        self.key_separator, self.item_separator, self.sort_keys,\n        self.skipkeys, _one_shot)\nreturn _iterencode(o, 0)", "path": "simplejson\\encoder.py", "repo_name": "robspychala/twitter-follow.py", "stars": 2, "license": "None", "language": "python", "size": 108}
{"docstring": "\"\"\"\nRenames the column of 'table_name' from 'old' to 'new'.\nWARNING - This isn't transactional on MSSQL!\n\"\"\"\n", "func_signal": "def rename_column(self, table_name, old, new):\n", "code": "if old == new:\n    # No Operation\n    return\n# Examples on the MS site show the table name not being quoted...\nqn = connection.ops.quote_name\nparams = (table_name,qn(old), qn(new))\nself.execute(\"EXEC sp_rename '%s.%s', %s, 'COLUMN'\" % params)", "path": "south\\db\\sql_server\\pyodbc.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "# Detect the model for the given table name\n", "func_signal": "def _alter_sqlite_table(self, table_name, field_renames={}):\n", "code": "        model = None\n        for omodel in self.current_orm:\n            if omodel._meta.db_table == table_name:\n                model = omodel\n        if model is None:\n            raise ValueError(\"Cannot find ORM model for '%s'.\" % table_name)\n\n        temp_name = table_name + \"_temporary_for_schema_change\"\n        self.rename_table(table_name, temp_name)\n        fields = [(fld.name, fld) for fld in model._meta.fields]\n        self.create_table(table_name, fields)\n\n        columns = [fld.column for name, fld in fields]\n        self.copy_data(temp_name, table_name, columns, field_renames)\n        self.delete_table(temp_name, cascade=False)", "path": "south\\db\\sqlite3.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nGiven the name of something that needs orm. stuck on the front and\na python eval-able string, possibly add orm. to it.\n\"\"\"\n", "func_signal": "def poss_ormise(default_app, rel_to, arg):\n", "code": "orig_arg = arg\n# If it's not a relative field, short-circuit out\nif not rel_to:\n    return arg\n# Get the name of the other model\nrel_name = rel_to._meta.object_name\n# Is it in a different app? If so, use proper addressing.\nif rel_to._meta.app_label != default_app:\n    real_name = \"orm['%s.%s']\" % (rel_to._meta.app_label, rel_name)\nelse:\n    real_name = \"orm.%s\" % rel_name\n# If it's surrounded by quotes, get rid of those\nfor quote_type in QUOTES:\n    l = len(quote_type)\n    if arg[:l] == quote_type and arg[-l:] == quote_type:\n        arg = arg[l:-l]\n        break\n# Now see if we can replace it.\nif arg.lower() == rel_name.lower():\n    return real_name\n# Or perhaps it's app.model?\nif arg.lower() == rel_to._meta.app_label.lower() + \".\" + rel_name.lower():\n    return real_name\n# Or perhaps it's 'self'?\nif arg == RECURSIVE_RELATIONSHIP_CONSTANT:\n    return real_name\nreturn orig_arg", "path": "south\\management\\commands\\startmigration.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nUndoes the effect of set_installed_apps.\n\"\"\"\n", "func_signal": "def reset_installed_apps(self):\n", "code": "models.get_apps = models.get_apps_old\nsettings.INSTALLED_APPS = settings.OLD_INSTALLED_APPS\nself._redo_app_cache()", "path": "south\\hacks\\django_1_0.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "# If we have a set of models to use, use them.\n", "func_signal": "def prep_for_freeze(model, last_models=None):\n", "code": "if last_models:\n    fields = last_models[model_key(model)]\nelse:\n    fields = modelsinspector.get_model_fields(model, m2m=True)\n# Remove _stub if it stuck in\nif \"_stub\" in fields:\n    del fields[\"_stub\"]\n# Remove useless attributes (like 'choices')\nfor name, field in fields.items():\n    if name == \"Meta\":\n        continue\n    real_field = model._meta.get_field_by_name(name)[0]\n    fields[name] = ormise_triple(real_field, remove_useless_attributes(field))\n# See if there's a Meta\nif last_models:\n    meta = last_models[model_key(model)].get(\"Meta\", {})\nelse:\n    meta = modelsinspector.get_model_meta(model)\nif meta:\n    fields['Meta'] = remove_useless_meta(meta)\nreturn fields", "path": "south\\management\\commands\\startmigration.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nBackwards-compat comparison that ignores orm. on the RHS and not the left\nand which knows django.db.models.fields.CharField = models.CharField.\nHas a whole load of tests in tests/autodetectoion.py.\n\"\"\"\n\n# If they're not triples, just do normal comparison\n", "func_signal": "def different_attributes(old, new):\n", "code": "if not is_triple(old) or not is_triple(new):\n    return old != new\n\n# Expand them out into parts\nold_field, old_pos, old_kwd = old\nnew_field, new_pos, new_kwd = new\n\n# Copy the positional and keyword arguments so we can compare them and pop off things\nold_pos, new_pos = old_pos[:], new_pos[:]\nold_kwd = dict(old_kwd.items())\nnew_kwd = dict(new_kwd.items())\n\n# Remove comparison of the existence of 'unique', that's done elsewhere.\n# TODO: Make this work for custom fields where unique= means something else?\nif \"unique\" in old_kwd:\n    del old_kwd['unique']\nif \"unique\" in new_kwd:\n    del new_kwd['unique']\n\n# If the first bit is different, check it's not by dj.db.models...\nif old_field != new_field:\n    if old_field.startswith(\"models.\") and (new_field.startswith(\"django.db.models\") \\\n     or new_field.startswith(\"django.contrib.gis\")):\n        if old_field.split(\".\")[-1] != new_field.split(\".\")[-1]:\n            return True\n        else:\n            # Remove those fields from the final comparison\n            old_field = new_field = \"\"\n\n# If there's a positional argument in the first, and a 'to' in the second,\n# see if they're actually comparable.\nif (old_pos and \"to\" in new_kwd) and (\"orm\" in new_kwd['to'] and \"orm\" not in old_pos[0]):\n    # Do special comparison to fix #153\n    try:\n        if old_pos[0] != new_kwd['to'].split(\"'\")[1].split(\".\")[1]:\n            return True\n    except IndexError:\n        pass # Fall back to next comparison\n    # Remove those attrs from the final comparison\n    old_pos = old_pos[1:]\n    del new_kwd['to']\n\nreturn old_field != new_field or old_pos != new_pos or old_kwd != new_kwd", "path": "south\\management\\commands\\startmigration.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nCreates a Fake Django ORM.\nThis is actually a memoised constructor; the real class is _FakeORM.\n\"\"\"\n", "func_signal": "def FakeORM(*args):\n", "code": "if not args in _orm_cache:\n    _orm_cache[args] = _FakeORM(*args)  \nreturn _orm_cache[args]", "path": "south\\orm.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nUsed to repopulate AppCache after fiddling with INSTALLED_APPS.\n\"\"\"\n", "func_signal": "def _redo_app_cache(self):\n", "code": "a = AppCache()\na.loaded = False\na._populate()", "path": "south\\hacks\\django_1_0.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nDiffs the two provided Meta definitions (dicts).\n\"\"\"\n\n# First, diff unique_together\n", "func_signal": "def meta_diff(old, new):\n", "code": "old_unique_together = eval(old.get('unique_together', \"[]\"))\nnew_unique_together = eval(new.get('unique_together', \"[]\"))\n\nadded_uniques = set()\nremoved_uniques = set()\n\nfor entry in old_unique_together:\n    if entry not in new_unique_together:\n        removed_uniques.add(tuple(entry))\n\nfor entry in new_unique_together:\n    if entry not in old_unique_together:\n        added_uniques.add(tuple(entry))\n\nreturn added_uniques, removed_uniques", "path": "south\\management\\commands\\startmigration.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nGiven the defualt app, the field class,\nand the defn triple (or string), make the definition string.\n\"\"\"\n# It might be None; return a placeholder\n", "func_signal": "def make_field_constructor(default_app, field, triple):\n", "code": "if triple is None:\n    return FIELD_NEEDS_DEF_SNIPPET\n# It might be a defn string already...\nif isinstance(triple, (str, unicode)):\n    return triple\n# OK, do it the hard way\nif hasattr(field, \"rel\") and hasattr(field.rel, \"to\") and field.rel.to:\n    rel_to = field.rel.to\nelse:\n    rel_to = None\nargs = [poss_ormise(default_app, rel_to, arg) for arg in triple[1]]\nkwds = [\"%s=%s\" % (k, poss_ormise(default_app, rel_to, v)) for k,v in triple[2].items()]\nreturn \"%s(%s)\" % (triple[0], \", \".join(args+kwds))", "path": "south\\management\\commands\\startmigration.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nSets Django's INSTALLED_APPS setting to be effectively the list passed in.\n\"\"\"\n\n# Make sure it's a list.\n", "func_signal": "def set_installed_apps(self, apps):\n", "code": "apps = list(apps)\n\n# This function will be monkeypatched into place.\ndef new_get_apps():\n    return apps\n\n# Monkeypatch in!\nmodels.get_apps_old, models.get_apps = models.get_apps, new_get_apps\nsettings.INSTALLED_APPS, settings.OLD_INSTALLED_APPS = (\n    apps,\n    settings.INSTALLED_APPS,\n)\nself._redo_app_cache()", "path": "south\\hacks\\django_1_0.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "# Tweak stuff as needed\n", "func_signal": "def create_table(self, table_name, fields):\n", "code": "for name,f in fields:\n    self._fix_field_definition(f)\n\n# Run\ngeneric.DatabaseOperations.create_table(self, table_name, fields)", "path": "south\\db\\sql_server\\pyodbc.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nReturns a set of models this one depends on to be defined; things like\nOneToOneFields as ID, ForeignKeys everywhere, etc.\n\"\"\"\n", "func_signal": "def model_dependencies(model, last_models=None, checked_models=None):\n", "code": "depends = {}\nchecked_models = checked_models or set()\n# Get deps for each field\nfor field in model._meta.fields + model._meta.many_to_many:\n    depends.update(field_dependencies(field, last_models))\n# Now recurse\nnew_to_check = set(depends.keys()) - checked_models\nwhile new_to_check:\n    checked_model = new_to_check.pop()\n    if checked_model == model or checked_model in checked_models:\n        continue\n    checked_models.add(checked_model)\n    deps = model_dependencies(checked_model, last_models, checked_models)\n    # Loop through dependencies...\n    for dep, value in deps.items():\n        # If the new dep is not already checked, add to the queue\n        if (dep not in depends) and (dep not in new_to_check) and (dep not in checked_models):\n            new_to_check.add(dep)\n        depends[dep] = value\nreturn depends", "path": "south\\management\\commands\\startmigration.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nClears the contents of AppCache to a blank state, so new models\nfrom the ORM can be added.\n\"\"\"\n", "func_signal": "def clear_app_cache(self):\n", "code": "self.old_app_models = cache.app_models\ncache.app_models = {}", "path": "south\\hacks\\django_1_0.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nRenames the table 'old_table_name' to 'table_name'.\nWARNING - This isn't transactional on MSSQL!\n\"\"\"\n", "func_signal": "def rename_table(self, old_table_name, table_name):\n", "code": "if old_table_name == table_name:\n    # No Operation\n    return\nqn = connection.ops.quote_name\nparams = (qn(old_table_name), qn(table_name))\nself.execute('EXEC sp_rename %s, %s' % params)", "path": "south\\db\\sql_server\\pyodbc.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "# Run ALTER TABLE with no unique column\n", "func_signal": "def add_column(self, table_name, name, field, *args, **kwds):\n", "code": "unique, field._unique, field.db_index = field.unique, False, False\n# If it's not nullable, and has no default, raise an error (SQLite is picky)\nif (not field.null and \n    (not field.has_default() or field.get_default() is None) and\n    not field.empty_strings_allowed):\n    raise ValueError(\"You cannot add a null=False column without a default value.\")\n# Don't try and drop the default, it'll fail\nkwds['keep_default'] = True\ngeneric.DatabaseOperations.add_column(self, table_name, name, field, *args, **kwds)\n# If it _was_ unique, make an index on it.\nif unique:\n    self.create_index(table_name, [field.column], unique=True)", "path": "south\\db\\sqlite3.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "# Model 'Spam'\n", "func_signal": "def forwards(self):\n", "code": "        db.create_table(\"southtest_spam\", (\n            ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)),\n            ('weight', models.FloatField()),\n            ('expires', models.DateTimeField()),\n            ('name', models.CharField(max_length=255))\n        ))", "path": "south\\tests\\fakeapp\\migrations\\0001_spam.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nReturns the difference between the old and new sets of models as a 5-tuple:\nadded_models, deleted_models, added_fields, deleted_fields, changed_fields\n\"\"\"\n\n", "func_signal": "def models_diff(old, new):\n", "code": "added_models = set()\ndeleted_models = set()\nignored_models = set() # Stubs for backwards\ncontinued_models = set() # Models that existed before and after\nadded_fields = set()\ndeleted_fields = set()\nchanged_fields = []\nadded_uniques = set()\ndeleted_uniques = set()\n\n# See if anything's vanished\nfor key in old:\n    if key not in new:\n        if \"_stub\" not in old[key]:\n            deleted_models.add(key)\n        else:\n            ignored_models.add(key)\n\n# Or appeared\nfor key in new:\n    if key not in old:\n        added_models.add(key)\n\n# Now, for every model that's stayed the same, check its fields.\nfor key in old:\n    if key not in deleted_models and key not in ignored_models:\n        continued_models.add(key)\n        still_there = set()\n        # Find fields that have vanished.\n        for fieldname in old[key]:\n            if fieldname != \"Meta\" and fieldname not in new[key]:\n                deleted_fields.add((key, fieldname))\n            else:\n                still_there.add(fieldname)\n        # And ones that have appeared\n        for fieldname in new[key]:\n            if fieldname != \"Meta\" and fieldname not in old[key]:\n                added_fields.add((key, fieldname))\n        # For the ones that exist in both models, see if they were changed\n        for fieldname in still_there:\n            if fieldname != \"Meta\":\n                if different_attributes(\n                 remove_useless_attributes(old[key][fieldname], True),\n                 remove_useless_attributes(new[key][fieldname], True)):\n                    changed_fields.append((key, fieldname, old[key][fieldname], new[key][fieldname]))\n                # See if their uniques have changed\n                old_triple = old[key][fieldname]\n                new_triple = new[key][fieldname]\n                if is_triple(old_triple) and is_triple(new_triple):\n                    if old_triple[2].get(\"unique\", \"False\") != new_triple[2].get(\"unique\", \"False\"):\n                        # Make sure we look at the one explicitly given to see what happened\n                        if \"unique\" in old_triple[2]:\n                            if old_triple[2]['unique'] == \"False\":\n                                added_uniques.add((key, (fieldname,)))\n                            else:\n                                deleted_uniques.add((key, (fieldname,)))\n                        else:\n                            if new_triple[2]['unique'] == \"False\":\n                                deleted_uniques.add((key, (fieldname,)))\n                            else:\n                                added_uniques.add((key, (fieldname,)))\n\nreturn added_models, deleted_models, continued_models, added_fields, deleted_fields, changed_fields, added_uniques, deleted_uniques", "path": "south\\management\\commands\\startmigration.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "\"\"\"\nrebuilds the table using the new definitions.  only one change \ncan be made per call and it must be either a rename, alter or\ndelete\n\"\"\"\n", "func_signal": "def _rebuild_table(self, table_name, new_fields):\n", "code": "self._populate_current_structure(table_name)\n\ncurrent_fields = self._fields[table_name]\ntemp_table_name = '%s_temp' % table_name\noperation = None\nchanged_field = None\n\nif len(current_fields) != len(new_fields):\n    if len(current_fields) - len(new_fields) != 1:\n        raise ValueError('only one field can be deleted at a time, found %s missing fields' % str(len(current_fields) - len(new_fields)))\n    operation = 'delete'\n    current_field_names = [f[0] for f in current_fields]\n    new_field_names = [f[0] for f in new_fields]\n    # find the deleted field\n    for f in current_field_names:\n        if not f in new_field_names:\n            changed_field = f\n            break\nelse:\n    found = False\n    for current, new in zip(current_fields, new_fields):\n        if current[0] != new[0]:\n            if found:\n                raise ValueError('can only handle one change per call, found more than one')\n            operation = 'rename'\n            changed_field = (current[0], new[0])\n            found = True\n        elif current[1] != new[1]:\n            if found:\n                raise ValueError('can only handle one change per call, found more than one')\n            operation = 'alter'\n            changed_field = current[0]\n            found = True\n    if not found:\n        raise ValueError('no changed found')\n# create new table as temp\ncreate = 'CREATE TABLE \"%s\" ( %s )'\nfields_sql = ','.join(['\"%s\" %s' % (f[0], f[1]) for f in new_fields])\nsql = create % (temp_table_name, fields_sql)\n\ncursor = connection.cursor()\ncursor.execute(sql)\n\n# copy over data\n# rename, redef or delete?\nif operation in ['rename', 'alter']:\n    sql = 'insert into %s select * from %s' % (temp_table_name, table_name)\nelif operation == 'delete':\n    new_field_names = ','.join(['\"%s\"' % f[0] for f in new_fields])\n    sql = 'insert into %s select %s from %s' % (temp_table_name, new_field_names, table_name)\ncursor.execute(sql)\n                        \n# remove existing table\nself.delete_table(table_name)\n\n# rename new table\nself.rename_table(temp_table_name, table_name)\n\n# repopulate field info\nself._populate_current_structure(table_name, force=True)", "path": "south\\db\\sqlite3.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "# get if we don't have it already or are being forced to refresh it\n", "func_signal": "def _populate_current_structure(self, table_name, force=False):\n", "code": "if force or not table_name in self._fields.keys():\n    cursor = connection.cursor()\n    cursor.execute(GET_TABLE_DEF_SQL % table_name)\n    create_table = cursor.fetchall()[0][0]\n    first = create_table.find('(')\n    last = create_table.rfind(')')\n    # rip out the CREATE TABLE xxx ( ) and only get the field definitions plus\n    # add the trailing comma to make the next part easier\n    fields_part = create_table[first+1: last] + ','\n    # pull out the field name and definition for each field\n    self._fields[table_name] = re.findall(r'\"(\\S+?)\"(.*?),', fields_part, re.DOTALL)", "path": "south\\db\\sqlite3.py", "repo_name": "simonw/south", "stars": 2, "license": "None", "language": "python", "size": 96}
{"docstring": "# packet larger than the fifo\n", "func_signal": "def randpacket(delay, bpfid, ram, data, minsize, maxsize):\n", "code": "l = random.randint(minsize, maxsize)\ns = \"\"\nfor i in range(l):\n    s += struct.pack(\"B\", random.randint(0, 255))\n\nl += 4  # add on the CRC\ns = packageData(s)\nbpfid.write((l+3)/4 + 1)\nram.write(s)\ndata.write(delay, (l+1)/2 + 1 , s)\nreturn l", "path": "sim\\rxoutput\\rxoutput.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "'''Return the current CRC value as a string of bytes.  The length of\nthis string is specified in the digest_size attribute.\n'''\n", "func_signal": "def digest(self):\n", "code": "n = self.digest_size\ncrc = self.crcValue\nlst = []\nwhile n > 0:\n    lst.append(chr(crc & 0xFF))\n    crc = crc >> 8\n    n -= 1\nlst.reverse()\nreturn ''.join(lst)", "path": "code\\crcmod-1.2\\crcmod.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "# we wait n ticks to put the data on the wire\n#\n", "func_signal": "def wait(self, nticks):\n", "code": "for i in range(nticks):\n    self.dinfile.write(\"0 0000\\n\")", "path": "sim\\network\\network.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "'''Return the current CRC value as a string of hex digits.  The length\nof this string is twice the digest_size attribute.\n'''\n", "func_signal": "def hexdigest(self):\n", "code": "n = self.digest_size\ncrc = self.crcValue\nlst = []\nwhile n > 0:\n    lst.append('%02X' % (crc & 0xFF))\n    crc = crc >> 8\n    n -= 1\nlst.reverse()\nreturn ''.join(lst)", "path": "code\\crcmod-1.2\\crcmod.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "\"\"\"\ndlen == words to wait for\n\"\"\"\n", "func_signal": "def write(self, noplen, dlen, data):\n", "code": "self.fid.write(\"%d %d \" % (noplen, dlen))\n\nself.fid.write(\"%04X \" % (len(data), ))\n\nfor i in range(len(data)/2):\n    vals = struct.unpack(\"BB\", data[i*2:(i+1)*2])\n    self.fid.write(\"%02X%02X \" % (vals[0], vals[1]))\nif len(data) % 2 == 1:\n    vals = struct.unpack(\"B\", data[-1])\n    self.fid.write(\"%02X00\" % (vals[0],))\n\nself.fid.write('\\n')", "path": "sim\\rxoutput\\rxoutput.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "# returns a string containing the wire-representation of the\n# frame\n\n", "func_signal": "def getWire(self, preamble=7, SFD=True):\n", "code": "length = 6 + 6 + 2 + len(self.data) + 4\n\n\nframe = self.destmac + self.srcmac + \\\n        struct.pack(\"BB\", self.ethertype / 256, self.ethertype % 256)+\\\n        self.data\n\nfcscrc = crcmod.Crc(0x104C11DB7)\nfcscrc.update(frame)\n\ni = struct.unpack('i', fcscrc.digest())[0]\ninvcrc = struct.pack('I', ~i)\noutdata = frame + invcrc[3] + invcrc[2] + invcrc[1] + invcrc[0]\n\nif SFD:\n    outdata = '\\xd5' + outdata\n\nfor i in range(preamble):\n    outdata = '\\x55' + outdata; \n\n\nreturn outdata", "path": "code\\frame.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "\"\"\" Takes in data and\n\n\"\"\"\n", "func_signal": "def packageData(data):\n", "code": "fcscrc = crcmod.Crc(0x104C11DB7)\nfcscrc.update(data)\n\ni = struct.unpack('i', fcscrc.digest())[0]\ninvcrc = struct.pack('I', ~i)\noutdata = data + invcrc[3] + invcrc[2] + invcrc[1] + invcrc[0]\nreturn outdata", "path": "sim\\rxoutput\\rxoutput.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "# simple code to write tiny packets and see if we process them correctly.\n# sure, we'll never encounter these in the real world, but it doesn't\n# hurt to be correct everywhere.\n\n# first, len = 1\n", "func_signal": "def simplepackets(bpfid, ram, data):\n", "code": "bpfid.write(3)\nd = packageData(\"A\")\nram.write(d)\ndata.write(0, 4, d)\n\n# len = 2\nbpfid.write(3)\nd = packageData(\"AB\")\nram.write(d)\ndata.write(0, 4, d)\n\n# len = 3\nbpfid.write(3)\nd = packageData(\"ABC\")\nram.write(d)\ndata.write(0, 5, d)\n\n# len = 4\nbpfid.write(3)\nd = packageData(\"WXYZ\")\nram.write(d)\ndata.write(0, 5, d)\n\n# len = 5\nbpfid.write(4)\nd = packageData(\"\\x00\\x01\\x02\\x03\\x04\")\nram.write(d)\ndata.write(0, 6, d)\n\n# len = 6\nbpfid.write(4)\nd = packageData(\"\\x00\\x01\\x02\\x03\\x04\\x05\")\nram.write(d)\ndata.write(0, 6, d)\n\n# len = 7\nbpfid.write(4)\nd = packageData(\"\\x00\\x01\\x02\\x03\\x04\\x05\\x06\")\nram.write(d)\ndata.write(0, 7, d)\n\n# len = 8\nbpfid.write(4)\nd = packageData(\"\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\07\")\nram.write(d)\ndata.write(0, 7, d)", "path": "sim\\rxoutput\\rxoutput.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "# for encoding\n", "func_signal": "def __init__(self, destmac, srcmac, ethertype, data):\n", "code": "if isinstance(destmac, str):\n    self.destmac = macdecode(destmac)\nelse:\n    self.destmac = struct.pack(\"BBBBBB\", destmac[0], destmac[1],\n                               destmac[2], destmac[3], destmac[4],\n                               destmac[5])\n\nif isinstance(srcmac, str):\n    self.srcmac = macdecode(srcmac)\nelse:\n    self.srcmac = struct.pack(\"BBBBBB\", srcmac[0], srcmac[1],\n                              srcmac[2], srcmac[3], srcmac[4],\n                              srcmac[5])\n\n    \nself.ethertype = ethertype\nself.data = data", "path": "code\\frame.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "'''Return the current CRC value as a string of hex digits.  The length\nof this string is twice the digest_size attribute.\n'''\n", "func_signal": "def hexdigest(self):\n", "code": "n = self.digest_size\ncrc = self.crcValue\nlst = []\nwhile n > 0:\n    lst.append('%02X' % (crc & 0xFF))\n    crc = crc >> 8\n    n -= 1\nlst.reverse()\nreturn ''.join(lst)", "path": "code\\crcmod.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "\"\"\" Takes in data and appends the crc\n\n\"\"\"\n# create the string:\n", "func_signal": "def generateCRC(data):\n", "code": "d = \"\"\nfor i in data:\n    d += chr(i)\n    \nfcs = frame.generateFCS(d)\n\nreturn [ord(fcs[0]),  ord(fcs[1]), ord(fcs[2]), ord(fcs[3])]", "path": "sim\\txoutput\\txoutput.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "'''Create a new instance of the Crc class initialized to the same\nvalues as the original instance.  The current CRC is set to the current\nvalue.  This allows multiple CRC calculations using a common initial\nstring.\n'''\n", "func_signal": "def copy(self):\n", "code": "c = self.new()\nc.crcValue = self.crcValue\nreturn c", "path": "code\\crcmod.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "'''Create a new instance of the Crc class initialized to the same\nvalues as the original instance.  The current CRC is set to the initial\nvalue.  If a string is provided in the optional arg parameter, it is\npassed to the update method.\n'''\n", "func_signal": "def new(self, arg=None):\n", "code": "n = Crc(poly=None, initialize=False)\nn._crc = self._crc\nn.digest_size = self.digest_size\nn.initCrc = self.initCrc\nn.table = self.table\nn.crcValue = self.initCrc\nn.reverse = self.reverse\nn.poly = self.poly\nif arg is not None:\n    n.update(arg)\nreturn n", "path": "code\\crcmod.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "'''Generate a C/C++ function.\n\nfunctionName -- String specifying the name of the function.\n\nout -- An open file-like object with a write method.  This specifies\nwhere the generated code is written.\n\ndataType -- An optional parameter specifying the data type of the input\ndata to the function.  Defaults to UINT8.\n\ncrcType -- An optional parameter specifying the data type of the CRC\nvalue.  Defaults to one of UINT8, UINT16, UINT32, or UINT64 depending\non the size of the CRC value.\n'''\n", "func_signal": "def generateCode(self, functionName, out, dataType=None, crcType=None):\n", "code": "if dataType is None:\n    dataType = 'UINT8'\n\nif crcType is None:\n    crcType = 'UINT%d' % (8*self.digest_size)\n\nif self.digest_size == 1:\n    # Both 8-bit CRC algorithms are the same\n    crcAlgor = 'table[*data ^ (%s)crc]'\nelif self.reverse:\n    # The bit reverse algorithms are all the same except for the data\n    # type of the crc variable which is specified elsewhere.\n    crcAlgor = 'table[*data ^ (%s)crc] ^ (crc >> 8)'\nelse:\n    # The forward CRC algorithms larger than 8 bits have an extra shift\n    # operation to get the high byte.\n    shift = 8*(self.digest_size - 1)\n    crcAlgor = 'table[*data ^ (%%s)(crc >> %d)] ^ (crc << 8)' % shift\n\nfmt = '0x%%0%dX' % (2*self.digest_size)\nif self.digest_size <= 4:\n    fmt = fmt + 'U,'\nelse:\n    # Need the long long type identifier to keep gcc from complaining.\n    fmt = fmt + 'ULL,'\n\n# Select the number of entries per row in the output code.\nn = {1:8, 2:8, 4:4, 8:2}[self.digest_size]\n\nlst = []\nfor i, val in enumerate(self.table):\n    if (i % n) == 0:\n        lst.append('\\n    ')\n    lst.append(fmt % val)\n\npoly = 'polynomial: 0x%X' % self.poly\nif self.reverse:\n    poly = poly + ', bit reverse algorithm'\n\nparms = {\n    'dataType' : dataType,\n    'crcType' : crcType,\n    'name' : functionName,\n    'crcAlgor' : crcAlgor % dataType,\n    'crcTable' : ''.join(lst),\n    'poly' : poly,\n}\nout.write(_codeTemplate % parms)", "path": "code\\crcmod-1.2\\crcmod.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "'''Create a new instance of the Crc class initialized to the same\nvalues as the original instance.  The current CRC is set to the initial\nvalue.  If a string is provided in the optional arg parameter, it is\npassed to the update method.\n'''\n", "func_signal": "def new(self, arg=None):\n", "code": "n = Crc(poly=None, initialize=False)\nn._crc = self._crc\nn.digest_size = self.digest_size\nn.initCrc = self.initCrc\nn.table = self.table\nn.crcValue = self.initCrc\nn.reverse = self.reverse\nn.poly = self.poly\nif arg is not None:\n    n.update(arg)\nreturn n", "path": "code\\crcmod-1.2\\crcmod.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "'''Return the current CRC value as a string of bytes.  The length of\nthis string is specified in the digest_size attribute.\n'''\n", "func_signal": "def digest(self):\n", "code": "n = self.digest_size\ncrc = self.crcValue\nlst = []\nwhile n > 0:\n    lst.append(chr(crc & 0xFF))\n    crc = crc >> 8\n    n -= 1\nlst.reverse()\nreturn ''.join(lst)", "path": "code\\crcmod.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "# dframe is just a long string of data, that we normally\n# get from the getWire section of a frame object\n#\n# nvalid is a list of tuples, each showing where we want non-valid\n# frames\n\n", "func_signal": "def addFrame(self, dframe, space=10, abortn = -1):\n", "code": "pos = 0\nfor s in dframe:\n    val = struct.unpack(\"B\", s)\n\n    if pos == abortn:\n        self.fid.write(\"%d %d %02X\\n\" % (0, 0, val[0]))\n    else:\n        self.fid.write(\"%d %d %02X\\n\" % (0, 1, val[0]))\n\n    pos += 1\n    \nfor s in range(space):\n    self.fid.write(\"0 0 00\\n\")", "path": "sim\\rxinput\\rxinput.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "'''Generate a C/C++ function.\n\nfunctionName -- String specifying the name of the function.\n\nout -- An open file-like object with a write method.  This specifies\nwhere the generated code is written.\n\ndataType -- An optional parameter specifying the data type of the input\ndata to the function.  Defaults to UINT8.\n\ncrcType -- An optional parameter specifying the data type of the CRC\nvalue.  Defaults to one of UINT8, UINT16, UINT32, or UINT64 depending\non the size of the CRC value.\n'''\n", "func_signal": "def generateCode(self, functionName, out, dataType=None, crcType=None):\n", "code": "if dataType is None:\n    dataType = 'UINT8'\n\nif crcType is None:\n    crcType = 'UINT%d' % (8*self.digest_size)\n\nif self.digest_size == 1:\n    # Both 8-bit CRC algorithms are the same\n    crcAlgor = 'table[*data ^ (%s)crc]'\nelif self.reverse:\n    # The bit reverse algorithms are all the same except for the data\n    # type of the crc variable which is specified elsewhere.\n    crcAlgor = 'table[*data ^ (%s)crc] ^ (crc >> 8)'\nelse:\n    # The forward CRC algorithms larger than 8 bits have an extra shift\n    # operation to get the high byte.\n    shift = 8*(self.digest_size - 1)\n    crcAlgor = 'table[*data ^ (%%s)(crc >> %d)] ^ (crc << 8)' % shift\n\nfmt = '0x%%0%dX' % (2*self.digest_size)\nif self.digest_size <= 4:\n    fmt = fmt + 'U,'\nelse:\n    # Need the long long type identifier to keep gcc from complaining.\n    fmt = fmt + 'ULL,'\n\n# Select the number of entries per row in the output code.\nn = {1:8, 2:8, 4:4, 8:2}[self.digest_size]\n\nlst = []\nfor i, val in enumerate(self.table):\n    if (i % n) == 0:\n        lst.append('\\n    ')\n    lst.append(fmt % val)\n\npoly = 'polynomial: 0x%X' % self.poly\nif self.reverse:\n    poly = poly + ', bit reverse algorithm'\n\nparms = {\n    'dataType' : dataType,\n    'crcType' : crcType,\n    'name' : functionName,\n    'crcAlgor' : crcAlgor % dataType,\n    'crcTable' : ''.join(lst),\n    'poly' : poly,\n}\nout.write(_codeTemplate % parms)", "path": "code\\crcmod.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "'''Create a new instance of the Crc class initialized to the same\nvalues as the original instance.  The current CRC is set to the current\nvalue.  This allows multiple CRC calculations using a common initial\nstring.\n'''\n", "func_signal": "def copy(self):\n", "code": "c = self.new()\nc.crcValue = self.crcValue\nreturn c", "path": "code\\crcmod-1.2\\crcmod.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "# we take in the frame data as well as a 4-byte CRC\n# which is written to ram if the len(data) is not\n# an exact multiple of 4\n\n", "func_signal": "def addFrame(self, data, crc):\n", "code": "tdata = data + crc # total data\nl = len(tdata)\n\nwlen = math.floor(l/4)\nif (l % 4 != 0):\n    wlen += 1\n\nself.fid.write(\"%d \" % (wlen + 1,))\nself.fid.write(\"%08X \" % (l,))\nfor i in range(l / 4):\n    val = struct.unpack(\"BBBB\", tdata[(i*4):((i+1)*4)])\n    self.fid.write(\"%02X%02X%02X%02X \" % (val[2], val[3], val[0], val[1]))\n\ncrcval = struct.unpack(\"BBBB\", crc)\nif l % 4 == 0:\n    self.fid.write(\"\\n\")\nelif l % 4 == 1:\n    val = struct.unpack(\"B\", tdata[-1])\n     \n    self.fid.write(\"%02X%02X%02X%02X\\n\" % (crcval[1], crcval[2],\n                                      val[0], crcval[0]))\nelif l % 4 == 2:\n    val = struct.unpack(\"BB\", tdata[-2:])\n     \n    self.fid.write(\"%02X%02X%02X%02X\\n\" % ( crcval[0],\n                                      crcval[1], val[0], val[1]))\nelif l % 4 == 3:\n    val = struct.unpack(\"BBB\", tdata[-3:])\n     \n    self.fid.write(\"%02X%02X%02X%02X\\n\" % (val[2], crcval[0], \n                                           val[0], val[1]))", "path": "sim\\rxinput\\rxinput.py", "repo_name": "somaproject/network", "stars": 3, "license": "None", "language": "python", "size": 61812}
{"docstring": "# utility method to be called by descendants\n", "func_signal": "def normalize_attrs(self, attrs):\n", "code": "attrs = [(k.lower(), v) for k, v in attrs]\nattrs = [(k, k in ('rel', 'type') and v.lower() or v) for k, v in attrs]\nreturn attrs", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "# called for each end tag, e.g. for </pre>, tag will be 'pre'\n# Reconstruct the original end tag.\n", "func_signal": "def unknown_endtag(self, tag):\n", "code": "if tag not in self.elements_no_end_tag:\n    self.pieces.append(\"</%(tag)s>\" % locals())", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "# called for each start tag\n# attrs is a list of (attr, value) tuples\n# e.g. for <pre class='screen'>, tag='pre', attrs=[('class', 'screen')]\n", "func_signal": "def unknown_starttag(self, tag, attrs):\n", "code": "if _debug: sys.stderr.write('_BaseHTMLProcessor, unknown_starttag, tag=%s\\n' % tag)\nuattrs = []\n# thanks to Kevin Marks for this breathtaking hack to deal with (valid) high-bit attribute values in UTF-8 feeds\nfor key, value in attrs:\n    if type(value) != type(u''):\n        value = unicode(value, self.encoding)\n    uattrs.append((unicode(key, self.encoding), value))\nstrattrs = u''.join([u' %s=\"%s\"' % (key, value) for key, value in uattrs]).encode(self.encoding)\nif tag in self.elements_no_end_tag:\n    self.pieces.append('<%(tag)s%(strattrs)s />' % locals())\nelse:\n    self.pieces.append('<%(tag)s%(strattrs)s>' % locals())", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "# Check if\n# - server requires digest auth, AND\n# - we tried (unsuccessfully) with basic auth, AND\n# - we're using Python 2.3.3 or later (digest auth is irreparably broken in earlier versions)\n# If all conditions hold, parse authentication information\n# out of the Authorization header we sent the first time\n# (for the username and password) and the WWW-Authenticate\n# header the server sent back (for the realm) and retry\n# the request with the appropriate digest auth headers instead.\n# This evil genius hack has been brought to you by Aaron Swartz.\n", "func_signal": "def http_error_401(self, req, fp, code, msg, headers):\n", "code": "host = urlparse.urlparse(req.get_full_url())[1]\ntry:\n    assert sys.version.split()[0] >= '2.3.3'\n    assert base64 != None\n    user, passw = base64.decodestring(req.headers['Authorization'].split(' ')[1]).split(':')\n    realm = re.findall('realm=\"([^\"]*)\"', headers['WWW-Authenticate'])[0]\n    self.add_password(realm, host, user, passw)\n    retry = self.http_error_auth_reqed('www-authenticate', host, req, headers)\n    self.reset_retry_count()\n    return retry\nexcept:\n    return self.http_error_default(req, fp, code, msg, headers)", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "'''Parse a string according to the OnBlog 8-bit date format'''\n", "func_signal": "def _parse_date_onblog(dateString):\n", "code": "m = _korean_onblog_date_re.match(dateString)\nif not m: return\nw3dtfdate = '%(year)s-%(month)s-%(day)sT%(hour)s:%(minute)s:%(second)s%(zonediff)s' % \\\n            {'year': m.group(1), 'month': m.group(2), 'day': m.group(3),\\\n             'hour': m.group(4), 'minute': m.group(5), 'second': m.group(6),\\\n             'zonediff': '+09:00'}\nif _debug: sys.stderr.write('OnBlog date parsed as: %s\\n' % w3dtfdate)\nreturn _parse_date_w3dtf(w3dtfdate)", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "'''Parse a string according to the Nate 8-bit date format'''\n", "func_signal": "def _parse_date_nate(dateString):\n", "code": "m = _korean_nate_date_re.match(dateString)\nif not m: return\nhour = int(m.group(5))\nampm = m.group(4)\nif (ampm == _korean_pm):\n    hour += 12\nhour = str(hour)\nif len(hour) == 1:\n    hour = '0' + hour\nw3dtfdate = '%(year)s-%(month)s-%(day)sT%(hour)s:%(minute)s:%(second)s%(zonediff)s' % \\\n            {'year': m.group(1), 'month': m.group(2), 'day': m.group(3),\\\n             'hour': hour, 'minute': m.group(6), 'second': m.group(7),\\\n             'zonediff': '+09:00'}\nif _debug: sys.stderr.write('Nate date parsed as: %s\\n' % w3dtfdate)\nreturn _parse_date_w3dtf(w3dtfdate)", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "'''Changes an XML data stream on the fly to specify a new encoding\n\ndata is a raw sequence of bytes (not Unicode) that is presumed to be in %encoding already\nencoding is a string recognized by encodings.aliases\n'''\n", "func_signal": "def _toUTF8(data, encoding):\n", "code": "if _debug: sys.stderr.write('entering _toUTF8, trying encoding %s\\n' % encoding)\n# strip Byte Order Mark (if present)\nif (len(data) >= 4) and (data[:2] == '\\xfe\\xff') and (data[2:4] != '\\x00\\x00'):\n    if _debug:\n        sys.stderr.write('stripping BOM\\n')\n        if encoding != 'utf-16be':\n            sys.stderr.write('trying utf-16be instead\\n')\n    encoding = 'utf-16be'\n    data = data[2:]\nelif (len(data) >= 4) and (data[:2] == '\\xff\\xfe') and (data[2:4] != '\\x00\\x00'):\n    if _debug:\n        sys.stderr.write('stripping BOM\\n')\n        if encoding != 'utf-16le':\n            sys.stderr.write('trying utf-16le instead\\n')\n    encoding = 'utf-16le'\n    data = data[2:]\nelif data[:3] == '\\xef\\xbb\\xbf':\n    if _debug:\n        sys.stderr.write('stripping BOM\\n')\n        if encoding != 'utf-8':\n            sys.stderr.write('trying utf-8 instead\\n')\n    encoding = 'utf-8'\n    data = data[3:]\nelif data[:4] == '\\x00\\x00\\xfe\\xff':\n    if _debug:\n        sys.stderr.write('stripping BOM\\n')\n        if encoding != 'utf-32be':\n            sys.stderr.write('trying utf-32be instead\\n')\n    encoding = 'utf-32be'\n    data = data[4:]\nelif data[:4] == '\\xff\\xfe\\x00\\x00':\n    if _debug:\n        sys.stderr.write('stripping BOM\\n')\n        if encoding != 'utf-32le':\n            sys.stderr.write('trying utf-32le instead\\n')\n    encoding = 'utf-32le'\n    data = data[4:]\nnewdata = unicode(data, encoding)\nif _debug: sys.stderr.write('successfully converted %s data to unicode\\n' % encoding)\ndeclmatch = re.compile('^<\\?xml[^>]*?>')\nnewdecl = '''<?xml version='1.0' encoding='utf-8'?>'''\nif declmatch.search(newdata):\n    newdata = declmatch.sub(newdecl, newdata)\nelse:\n    newdata = newdecl + u'\\n' + newdata\nreturn newdata.encode('utf-8')", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "# TODO: filter and sort posts\n", "func_signal": "def archive(request):\n", "code": "posts = BlogPost.objects.all()\nfeeds = __getAllFeeds()\ntitle = u'Archive'\nreturn render_to_response('archive.html', locals())", "path": "blog\\views.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "# called for each character reference, e.g. for '&#160;', ref will be '160'\n", "func_signal": "def handle_charref(self, ref):\n", "code": "if not self.elementstack: return\nref = ref.lower()\nif ref in ('34', '38', '39', '60', '62', 'x22', 'x26', 'x27', 'x3c', 'x3e'):\n    text = '&#%s;' % ref\nelse:\n    if ref[0] == 'x':\n        c = int(ref[1:], 16)\n    else:\n        c = int(ref)\n    text = unichr(c).encode('utf-8')\nself.elementstack[-1][2].append(text)", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "'''Parse a variety of ISO-8601-compatible formats like 20040105'''\n", "func_signal": "def _parse_date_iso8601(dateString):\n", "code": "m = None\nfor _iso8601_match in _iso8601_matches:\n    m = _iso8601_match(dateString)\n    if m: break\nif not m: return\nif m.span() == (0, 0): return\nparams = m.groupdict()\nordinal = params.get('ordinal', 0)\nif ordinal:\n    ordinal = int(ordinal)\nelse:\n    ordinal = 0\nyear = params.get('year', '--')\nif not year or year == '--':\n    year = time.gmtime()[0]\nelif len(year) == 2:\n    # ISO 8601 assumes current century, i.e. 93 -> 2093, NOT 1993\n    year = 100 * int(time.gmtime()[0] / 100) + int(year)\nelse:\n    year = int(year)\nmonth = params.get('month', '-')\nif not month or month == '-':\n    # ordinals are NOT normalized by mktime, we simulate them\n    # by setting month=1, day=ordinal\n    if ordinal:\n        month = 1\n    else:\n        month = time.gmtime()[1]\nmonth = int(month)\nday = params.get('day', 0)\nif not day:\n    # see above\n    if ordinal:\n        day = ordinal\n    elif params.get('century', 0) or \\\n             params.get('year', 0) or params.get('month', 0):\n        day = 1\n    else:\n        day = time.gmtime()[2]\nelse:\n    day = int(day)\n# special case of the century - is the first year of the 21st century\n# 2000 or 2001 ? The debate goes on...\nif 'century' in params.keys():\n    year = (int(params['century']) - 1) * 100 + 1\n# in ISO 8601 most fields are optional\nfor field in ['hour', 'minute', 'second', 'tzhour', 'tzmin']:\n    if not params.get(field, None):\n        params[field] = 0\nhour = int(params.get('hour', 0))\nminute = int(params.get('minute', 0))\nsecond = int(params.get('second', 0))\n# weekday is normalized by mktime(), we can ignore it\nweekday = 0\n# daylight savings is complex, but not needed for feedparser's purposes\n# as time zones, if specified, include mention of whether it is active\n# (e.g. PST vs. PDT, CET). Using -1 is implementation-dependent and\n# and most implementations have DST bugs\ndaylight_savings_flag = 0\ntm = [year, month, day, hour, minute, second, weekday,\n      ordinal, daylight_savings_flag]\n# ISO 8601 time zone adjustments\ntz = params.get('tz')\nif tz and tz != 'Z':\n    if tz[0] == '-':\n        tm[3] += int(params.get('tzhour', 0))\n        tm[4] += int(params.get('tzmin', 0))\n    elif tz[0] == '+':\n        tm[3] -= int(params.get('tzhour', 0))\n        tm[4] -= int(params.get('tzmin', 0))\n    else:\n        return None\n# Python's time.mktime() is a wrapper around the ANSI C mktime(3c)\n# which is guaranteed to normalize d/m/y/h/m/s.\n# Many implementations have bugs, but we'll pretend they don't.\nreturn time.localtime(time.mktime(tm))", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "\"\"\"URL, filename, or string --> stream\n\nThis function lets you define parsers that take any input source\n(URL, pathname to local or network file, or actual data as a string)\nand deal with it in a uniform manner.  Returned object is guaranteed\nto have all the basic stdio read methods (read, readline, readlines).\nJust .close() the object when you're done with it.\n\nIf the etag argument is supplied, it will be used as the value of an\nIf-None-Match request header.\n\nIf the modified argument is supplied, it must be a tuple of 9 integers\nas returned by gmtime() in the standard Python time module. This MUST\nbe in GMT (Greenwich Mean Time). The formatted date/time will be used\nas the value of an If-Modified-Since request header.\n\nIf the agent argument is supplied, it will be used as the value of a\nUser-Agent request header.\n\nIf the referrer argument is supplied, it will be used as the value of a\nReferer[sic] request header.\n\nIf handlers is supplied, it is a list of handlers used to build a\nurllib2 opener.\n\"\"\"\n\n", "func_signal": "def _open_resource(url_file_stream_or_string, etag, modified, agent, referrer, handlers):\n", "code": "if hasattr(url_file_stream_or_string, 'read'):\n    return url_file_stream_or_string\n\nif url_file_stream_or_string == '-':\n    return sys.stdin\n\nif urlparse.urlparse(url_file_stream_or_string)[0] in ('http', 'https', 'ftp'):\n    if not agent:\n        agent = USER_AGENT\n    # test for inline user:password for basic auth\n    auth = None\n    if base64:\n        urltype, rest = urllib.splittype(url_file_stream_or_string)\n        realhost, rest = urllib.splithost(rest)\n        if realhost:\n            user_passwd, realhost = urllib.splituser(realhost)\n            if user_passwd:\n                url_file_stream_or_string = '%s://%s%s' % (urltype, realhost, rest)\n                auth = base64.encodestring(user_passwd).strip()\n    # try to open with urllib2 (to use optional headers)\n    request = urllib2.Request(url_file_stream_or_string)\n    request.add_header('User-Agent', agent)\n    if etag:\n        request.add_header('If-None-Match', etag)\n    if modified:\n        # format into an RFC 1123-compliant timestamp. We can't use\n        # time.strftime() since the %a and %b directives can be affected\n        # by the current locale, but RFC 2616 states that dates must be\n        # in English.\n        short_weekdays = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n        months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n        request.add_header('If-Modified-Since', '%s, %02d %s %04d %02d:%02d:%02d GMT' % (short_weekdays[modified[6]], modified[2], months[modified[1] - 1], modified[0], modified[3], modified[4], modified[5]))\n    if referrer:\n        request.add_header('Referer', referrer)\n    if gzip and zlib:\n        request.add_header('Accept-encoding', 'gzip, deflate')\n    elif gzip:\n        request.add_header('Accept-encoding', 'gzip')\n    elif zlib:\n        request.add_header('Accept-encoding', 'deflate')\n    else:\n        request.add_header('Accept-encoding', '')\n    if auth:\n        request.add_header('Authorization', 'Basic %s' % auth)\n    if ACCEPT_HEADER:\n        request.add_header('Accept', ACCEPT_HEADER)\n    request.add_header('A-IM', 'feed') # RFC 3229 support\n    opener = apply(urllib2.build_opener, tuple([_FeedURLHandler()] + handlers))\n    opener.addheaders = [] # RMK - must clear so we only send our custom User-Agent\n    try:\n        return opener.open(request)\n    finally:\n        opener.close() # JohnD\n\n# try to open with native open function (if url_file_stream_or_string is a filename)\ntry:\n    return open(url_file_stream_or_string)\nexcept:\n    pass\n\n# treat url_file_stream_or_string as string\nreturn _StringIO(str(url_file_stream_or_string))", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "'''Randomizes cache expiry time to help prevent all objects expiring at once'''\n", "func_signal": "def __randomizeCacheMinutes(minutes):\n", "code": "seconds = minutes * 60\nreturn random.randint(seconds, seconds * 2)", "path": "blog\\views.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "'''Takes a list of lists describing feed information, and\nreturns a dictionary of feedparser feeds. Uses Django caching.\nFormat: ((name, uri, limit, cacheMinutes), ...)'''\n\n", "func_signal": "def __getFeeds(feedinfo):\n", "code": "feeds = {}\n\nfor (name, uri, limit, cacheMinutes) in feedinfo:\n\n\t# try cache\n\tcacheKey = 'feed-' + name\n\tfeeds[name] = cache.get(cacheKey)\n\n\t# check for cache miss\n\tif not feeds[name]:\n\n\t\t# grab and parse feed\n\t\tfeed = feedparser.parse(uri)\n\n\t\t# reduce entries to specified limit\n\t\tif len(feed.entries) > limit:\n\t\t\tfeed.entries = feed.entries[0:limit]\n\n\t\t# add to feeds, cache for later\n\t\tfeeds[name] = feed\n\t\tcache.set(cacheKey, feed, __randomizeCacheMinutes(cacheMinutes))\n\nreturn feeds", "path": "blog\\views.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "'''Get the character encoding of the XML document\n\nhttp_headers is a dictionary\nxml_data is a raw string (not Unicode)\n\nThis is so much trickier than it sounds, it's not even funny.\nAccording to RFC 3023 ('XML Media Types'), if the HTTP Content-Type\nis application/xml, application/*+xml,\napplication/xml-external-parsed-entity, or application/xml-dtd,\nthe encoding given in the charset parameter of the HTTP Content-Type\ntakes precedence over the encoding given in the XML prefix within the\ndocument, and defaults to 'utf-8' if neither are specified.  But, if\nthe HTTP Content-Type is text/xml, text/*+xml, or\ntext/xml-external-parsed-entity, the encoding given in the XML prefix\nwithin the document is ALWAYS IGNORED and only the encoding given in\nthe charset parameter of the HTTP Content-Type header should be\nrespected, and it defaults to 'us-ascii' if not specified.\n\nFurthermore, discussion on the atom-syntax mailing list with the\nauthor of RFC 3023 leads me to the conclusion that any document\nserved with a Content-Type of text/* and no charset parameter\nmust be treated as us-ascii.  (We now do this.)  And also that it\nmust always be flagged as non-well-formed.  (We now do this too.)\n\nIf Content-Type is unspecified (input was local file or non-HTTP source)\nor unrecognized (server just got it totally wrong), then go by the\nencoding given in the XML prefix of the document and default to\n'iso-8859-1' as per the HTTP specification (RFC 2616).\n\nThen, assuming we didn't find a character encoding in the HTTP headers\n(and the HTTP Content-type allowed us to look in the body), we need\nto sniff the first few bytes of the XML data and try to determine\nwhether the encoding is ASCII-compatible.  Section F of the XML\nspecification shows the way here:\nhttp://www.w3.org/TR/REC-xml/#sec-guessing-no-ext-info\n\nIf the sniffed encoding is not ASCII-compatible, we need to make it\nASCII compatible so that we can sniff further into the XML declaration\nto find the encoding attribute, which will tell us the true encoding.\n\nOf course, none of this guarantees that we will be able to parse the\nfeed in the declared character encoding (assuming it was declared\ncorrectly, which many are not).  CJKCodecs and iconv_codec help a lot;\nyou should definitely install them if you can.\nhttp://cjkpython.i18n.org/\n'''\n\n", "func_signal": "def _getCharacterEncoding(http_headers, xml_data):\n", "code": "def _parseHTTPContentType(content_type):\n    '''takes HTTP Content-Type header and returns (content type, charset)\n\n    If no charset is specified, returns (content type, '')\n    If no content type is specified, returns ('', '')\n    Both return parameters are guaranteed to be lowercase strings\n    '''\n    content_type = content_type or ''\n    content_type, params = cgi.parse_header(content_type)\n    return content_type, params.get('charset', '').replace(\"'\", '')\n\nsniffed_xml_encoding = ''\nxml_encoding = ''\ntrue_encoding = ''\nhttp_content_type, http_encoding = _parseHTTPContentType(http_headers.get('content-type'))\n# Must sniff for non-ASCII-compatible character encodings before\n# searching for XML declaration.  This heuristic is defined in\n# section F of the XML specification:\n# http://www.w3.org/TR/REC-xml/#sec-guessing-no-ext-info\ntry:\n    if xml_data[:4] == '\\x4c\\x6f\\xa7\\x94':\n        # EBCDIC\n        xml_data = _ebcdic_to_ascii(xml_data)\n    elif xml_data[:4] == '\\x00\\x3c\\x00\\x3f':\n        # UTF-16BE\n        sniffed_xml_encoding = 'utf-16be'\n        xml_data = unicode(xml_data, 'utf-16be').encode('utf-8')\n    elif (len(xml_data) >= 4) and (xml_data[:2] == '\\xfe\\xff') and (xml_data[2:4] != '\\x00\\x00'):\n        # UTF-16BE with BOM\n        sniffed_xml_encoding = 'utf-16be'\n        xml_data = unicode(xml_data[2:], 'utf-16be').encode('utf-8')\n    elif xml_data[:4] == '\\x3c\\x00\\x3f\\x00':\n        # UTF-16LE\n        sniffed_xml_encoding = 'utf-16le'\n        xml_data = unicode(xml_data, 'utf-16le').encode('utf-8')\n    elif (len(xml_data) >= 4) and (xml_data[:2] == '\\xff\\xfe') and (xml_data[2:4] != '\\x00\\x00'):\n        # UTF-16LE with BOM\n        sniffed_xml_encoding = 'utf-16le'\n        xml_data = unicode(xml_data[2:], 'utf-16le').encode('utf-8')\n    elif xml_data[:4] == '\\x00\\x00\\x00\\x3c':\n        # UTF-32BE\n        sniffed_xml_encoding = 'utf-32be'\n        xml_data = unicode(xml_data, 'utf-32be').encode('utf-8')\n    elif xml_data[:4] == '\\x3c\\x00\\x00\\x00':\n        # UTF-32LE\n        sniffed_xml_encoding = 'utf-32le'\n        xml_data = unicode(xml_data, 'utf-32le').encode('utf-8')\n    elif xml_data[:4] == '\\x00\\x00\\xfe\\xff':\n        # UTF-32BE with BOM\n        sniffed_xml_encoding = 'utf-32be'\n        xml_data = unicode(xml_data[4:], 'utf-32be').encode('utf-8')\n    elif xml_data[:4] == '\\xff\\xfe\\x00\\x00':\n        # UTF-32LE with BOM\n        sniffed_xml_encoding = 'utf-32le'\n        xml_data = unicode(xml_data[4:], 'utf-32le').encode('utf-8')\n    elif xml_data[:3] == '\\xef\\xbb\\xbf':\n        # UTF-8 with BOM\n        sniffed_xml_encoding = 'utf-8'\n        xml_data = unicode(xml_data[3:], 'utf-8').encode('utf-8')\n    else:\n        # ASCII-compatible\n        pass\n    xml_encoding_match = re.compile('^<\\?.*encoding=[\\'\"](.*?)[\\'\"].*\\?>').match(xml_data)\nexcept:\n    xml_encoding_match = None\nif xml_encoding_match:\n    xml_encoding = xml_encoding_match.groups()[0].lower()\n    if sniffed_xml_encoding and (xml_encoding in ('iso-10646-ucs-2', 'ucs-2', 'csunicode', 'iso-10646-ucs-4', 'ucs-4', 'csucs4', 'utf-16', 'utf-32', 'utf_16', 'utf_32', 'utf16', 'u16')):\n        xml_encoding = sniffed_xml_encoding\nacceptable_content_type = 0\napplication_content_types = ('application/xml', 'application/xml-dtd', 'application/xml-external-parsed-entity')\ntext_content_types = ('text/xml', 'text/xml-external-parsed-entity')\nif (http_content_type in application_content_types) or \\\n   (http_content_type.startswith('application/') and http_content_type.endswith('+xml')):\n    acceptable_content_type = 1\n    true_encoding = http_encoding or xml_encoding or 'utf-8'\nelif (http_content_type in text_content_types) or \\\n     (http_content_type.startswith('text/')) and http_content_type.endswith('+xml'):\n    acceptable_content_type = 1\n    true_encoding = http_encoding or 'us-ascii'\nelif http_content_type.startswith('text/'):\n    true_encoding = http_encoding or 'us-ascii'\nelif http_headers and (not http_headers.has_key('content-type')):\n    true_encoding = xml_encoding or 'iso-8859-1'\nelse:\n    true_encoding = xml_encoding or 'utf-8'\nreturn true_encoding, http_encoding, xml_encoding, sniffed_xml_encoding, acceptable_content_type", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "# called for each entity reference, e.g. for '&copy;', ref will be 'copy'\n", "func_signal": "def handle_entityref(self, ref):\n", "code": "if not self.elementstack: return\nif _debug: sys.stderr.write('entering handle_entityref with %s\\n' % ref)\nif ref in ('lt', 'gt', 'quot', 'amp', 'apos'):\n    text = '&%s;' % ref\nelse:\n    # entity resolution graciously donated by Aaron Swartz\n    def name2cp(k):\n        import htmlentitydefs\n        if hasattr(htmlentitydefs, 'name2codepoint'): # requires Python 2.3\n            return htmlentitydefs.name2codepoint[k]\n        k = htmlentitydefs.entitydefs[k]\n        if k.startswith('&#') and k.endswith(';'):\n            return int(k[2:-1]) # not in latin-1\n        return ord(k)\n    try: name2cp(ref)\n    except KeyError: text = '&%s;' % ref\n    else: text = unichr(name2cp(ref)).encode('utf-8')\nself.elementstack[-1][2].append(text)", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "'''Parse a string according to a Greek 8-bit date format.'''\n", "func_signal": "def _parse_date_greek(dateString):\n", "code": "m = _greek_date_format_re.match(dateString)\nif not m: return\ntry:\n    wday = _greek_wdays[m.group(1)]\n    month = _greek_months[m.group(3)]\nexcept:\n    return\nrfc822date = '%(wday)s, %(day)s %(month)s %(year)s %(hour)s:%(minute)s:%(second)s %(zonediff)s' % \\\n             {'wday': wday, 'day': m.group(2), 'month': month, 'year': m.group(4),\\\n              'hour': m.group(5), 'minute': m.group(6), 'second': m.group(7),\\\n              'zonediff': m.group(8)}\nif _debug: sys.stderr.write('Greek date parsed as: %s\\n' % rfc822date)\nreturn _parse_date_rfc822(rfc822date)", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "# called for each block of plain text, i.e. outside of any tag and\n# not containing any character or entity references\n", "func_signal": "def handle_data(self, text, escape=1):\n", "code": "if not self.elementstack: return\nif escape and self.contentparams.get('type') == 'application/xhtml+xml':\n    text = _xmlescape(text)\nself.elementstack[-1][2].append(text)", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "# called for each block of plain text, i.e. outside of any tag and\n# not containing any character or entity references\n# Store the original text verbatim.\n", "func_signal": "def handle_data(self, text):\n", "code": "if _debug: sys.stderr.write('_BaseHTMLProcessor, handle_text, text=%s\\n' % text)\nself.pieces.append(text)", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "'''Parse a string according to a Hungarian 8-bit date format.'''\n", "func_signal": "def _parse_date_hungarian(dateString):\n", "code": "m = _hungarian_date_format_re.match(dateString)\nif not m: return\ntry:\n    month = _hungarian_months[m.group(2)]\n    day = m.group(3)\n    if len(day) == 1:\n        day = '0' + day\n    hour = m.group(4)\n    if len(hour) == 1:\n        hour = '0' + hour\nexcept:\n    return\nw3dtfdate = '%(year)s-%(month)s-%(day)sT%(hour)s:%(minute)s%(zonediff)s' % \\\n            {'year': m.group(1), 'month': month, 'day': day,\\\n             'hour': hour, 'minute': m.group(5),\\\n             'zonediff': m.group(6)}\nif _debug: sys.stderr.write('Hungarian date parsed as: %s\\n' % w3dtfdate)\nreturn _parse_date_w3dtf(w3dtfdate)", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "'''Return the Time Zone Designator as an offset in seconds from UTC.'''\n", "func_signal": "def __extract_tzd(m):\n", "code": "if not m:\n    return 0\ntzd = m.group('tzd')\nif not tzd:\n    return 0\nif tzd == 'Z':\n    return 0\nhours = int(m.group('tzdhours'))\nminutes = m.group('tzdminutes')\nif minutes:\n    minutes = int(minutes)\nelse:\n    minutes = 0\noffset = (hours*60 + minutes) * 60\nif tzd[0] == '+':\n    return -offset\nreturn offset", "path": "lib\\feedparser.py", "repo_name": "pda/pacc-django", "stars": 2, "license": "None", "language": "python", "size": 732}
{"docstring": "\"\"\"Advance to the next result set.\n\nReturns None if there are no more result sets.\n\nNote that MySQL does not support multiple result sets at this\ntime.\n\n\"\"\"\n", "func_signal": "def nextset(self):\n", "code": "del self.messages[:]\nif self._executed:\n    self.fetchall()\nreturn None", "path": "tags\\MySQLdb-1.0.0c2\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Return the last inserted ID on an AUTO_INCREMENT columns.\nDEPRECATED: use lastrowid attribute\"\"\"\n", "func_signal": "def insert_id(self):\n", "code": "self._check_executed()\nreturn self.lastrowid", "path": "tags\\MySQLdb-1.0.0c2\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Does nothing, required by DB API.\"\"\"\n\n", "func_signal": "def setoutputsizes(self, *args):\n", "code": "\nif not self.connection:\n    self.errorhandler(self, ProgrammingError, \"cursor closed\")\nreturn self.connection", "path": "tags\\MySQLdb-1.1.9\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"This is not a standard part of Python DB API.\"\"\"\n", "func_signal": "def create(self, dbname):\n", "code": "self.__conn.query(\"CREATE DATABASE %s\" % dbname)\nself.__conn.store_result()\nreturn None", "path": "tags\\MySQLdb-0.9.2b1\\MySQLdb\\CompatMysqldb.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Fetches a single row from the cursor.\"\"\"\n", "func_signal": "def fetchone(self):\n", "code": "self._check_executed()\nr = self._fetch_row(1)\nif not r: return None\nself.rownumber = self.rownumber + 1\nreturn r[0]", "path": "tags\\MySQLdb-1.0.0c2\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Convert a MySQL TIMESTAMP to a Timestamp object.\"\"\"\n# MySQL>4.1 returns TIMESTAMP in the same format as DATETIME\n", "func_signal": "def mysql_timestamp_converter(s):\n", "code": "if s[4] == '-': return DateTime_or_None(s)\ns = s + \"0\"*(14-len(s)) # padding\nparts = map(int, filter(None, (s[:4],s[4:6],s[6:8],\n                               s[8:10],s[10:12],s[12:14])))\ntry: return Timestamp(*parts)\nexcept: return None", "path": "tags\\MySQLdb-1.1.10\\MySQLdb\\MySQLdb\\times.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Return the current position in the result set analogously to\nfile.tell(). This is a non-standard extension. DEPRECATED:\nuse rownumber attribute\"\"\"\n", "func_signal": "def tell(self):\n", "code": "self._check_executed()\nreturn self.rownumber", "path": "tags\\MySQLdb-1.0.0c2\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Fetchs all available rows from the cursor.\"\"\"\n", "func_signal": "def fetchall(self):\n", "code": "self._check_executed()\nr = self._fetch_row(0)\nself.rownumber = self.rownumber + len(r)\nreturn r", "path": "tags\\MySQLdb-1.1.9\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Fetch up to size rows from the cursor. Result set may be smaller\nthan size. If size is not defined, cursor.arraysize is used.\"\"\"\n", "func_signal": "def fetchmany(self, size=None):\n", "code": "self._check_executed()\nr = self._fetch_row(size or self.arraysize)\nself.rownumber = self.rownumber + len(r)\nreturn r", "path": "tags\\MySQLdb-1.0.0c2\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Fetches a single row from the cursor.\"\"\"\n", "func_signal": "def fetchone(self):\n", "code": "self._check_executed()\nr = self._fetch_row(1)\nif not r: return None\nself.rownumber = self.rownumber + 1\nreturn r[0]", "path": "tags\\MySQLdb-1.1.9\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"This is not a standard part of Python DB API.\"\"\"\n", "func_signal": "def reload(self):\n", "code": "self.__conn.query(\"RELOAD TABLES\")\nself.__conn.store_result()\nreturn None", "path": "tags\\MySQLdb-0.9.2b1\\MySQLdb\\CompatMysqldb.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Fetches a single row from the cursor. None indicates that\nno more rows are available.\"\"\"\n", "func_signal": "def fetchone(self):\n", "code": "self._check_executed()\nif self.rownumber >= len(self._rows): return None\nresult = self._rows[self.rownumber]\nself.rownumber = self.rownumber+1\nreturn result", "path": "tags\\MySQLdb-1.1.9\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Does nothing, required by DB API.\"\"\"\n\n", "func_signal": "def setoutputsizes(self, *args):\n", "code": "\nif not self.connection:\n    self.errorhandler(self, ProgrammingError, \"cursor closed\")\nreturn self.connection", "path": "tags\\MySQLdb-1.0.0c2\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Commit the current transaction.\"\"\"\n", "func_signal": "def commit(self):\n", "code": "if self.__transactional:\n\t self.__conn.query(\"COMMIT\")", "path": "tags\\MySQLdb-0.9.2b1\\MySQLdb\\CompatMysqldb.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"seek to a given row of the result set analogously to file.seek().\nThis is non-standard extension. DEPRECATED: Use scroll method\"\"\"\n", "func_signal": "def seek(self, row, whence=0):\n", "code": "self._check_executed()\nif whence == 0:\n    self.rownumber = row\nelif whence == 1:\n    self.rownumber = self.rownumber + row\nelif whence == 2:\n    self.rownumber = len(self._rows) + row", "path": "tags\\MySQLdb-1.0.0c2\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Close the cursor. No further queries can be executed.\"\"\"\n", "func_signal": "def close(self):\n", "code": "del self.messages[:]\nself.nextset()\nself._result = None\nBaseCursor.close(self)", "path": "tags\\MySQLdb-1.0.0c2\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Fetch up to size rows from the cursor. Result set may be smaller\nthan size. If size is not defined, cursor.arraysize is used.\"\"\"\n", "func_signal": "def fetchmany(self, size=None):\n", "code": "self._check_executed()\nend = self.rownumber + (size or self.arraysize)\nresult = self._rows[self.rownumber:end]\nself.rownumber = min(end, len(self._rows))\nreturn result", "path": "tags\\MySQLdb-1.0.0c2\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Fetchs all available rows from the cursor.\"\"\"\n", "func_signal": "def fetchall(self):\n", "code": "self._check_executed()\nresult = self.rownumber and self._rows[self.rownumber:] or self._rows\nself.rownumber = len(self._rows)\nreturn result", "path": "tags\\MySQLdb-1.1.9\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Close the cursor. No further queries will be possible.\"\"\"\n", "func_signal": "def close(self):\n", "code": "if not self.connection: return\nwhile self.nextset(): pass\nself.connection = None", "path": "tags\\MySQLdb-1.1.9\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\"Fetchs all available rows from the cursor.\"\"\"\n", "func_signal": "def fetchall(self):\n", "code": "self._check_executed()\nr = self._fetch_row(0)\nself.rownumber = self.rownumber + len(r)\nreturn r", "path": "tags\\MySQLdb-1.0.0c2\\MySQLdb\\MySQLdb\\cursors.py", "repo_name": "twleung/mac-mysql-python", "stars": 2, "license": "None", "language": "python", "size": 912}
{"docstring": "\"\"\" Realiza um rollback e termina quaisquer transa\u00e7\u00f5es abertas. \"\"\"\n", "func_signal": "def rollback(self):\n", "code": "self.bd.rollback()\nself.in_transaction = 0", "path": "querys.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\"item \u00e9 a descri\u00e7\u00e3o do item alugado ou comprado\n    valor o pre\u00e7o do item\"\"\"\n", "func_signal": "def __init__(self,item, valor):\n", "code": "self.item = item\nself.valor = currency(valor)", "path": "receber.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\" Roda uma consulta (select) no banco de dados. \"\"\"\n", "func_signal": "def runQuery(self, query, params = None):\n", "code": "self.modelo.cursor.execute(query, params)\nrows = self.modelo.cursor.fetchall()\nreturn rows", "path": "querys.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\"Adiciona um label ao notify\"\"\"\n", "func_signal": "def add_msg(self):\n", "code": "self.msg = gtk.Label()\nself.msg_area.pack_start (self.msg, False, True, 0)\nreturn self.msg", "path": "notify.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\"Envia o sinal para o controle que o recebimento foi realizado com sucesso\"\"\"\n", "func_signal": "def recebido(self, widget):\n", "code": "self.controle.set_receber_status(True)   \nself.w_receber.destroy()", "path": "receber.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\"Prepara para carregar a interface\"\"\"\n", "func_signal": "def start(self):\n", "code": "self.open =Open()\n#instancias das classes que fazem referencias a tabelas no modelo\n#locadora\nself.categorias_dvd = Categorias_dvd(self.modelo, self.modelo.categorias_dvd)\nself.generos = Generos(self.modelo, self.modelo.generos)\nself.clientes = Clientes(self.modelo, self.modelo.clientes)\nself.filmes = Filmes(self.modelo, self.modelo.filmes)\nself.dvds = Dvds(self.modelo, self.modelo.dvds)\n#loja\nself.categorias = Categorias(self.modelo, self.modelo.categorias)\nself.contas = Contas(self.modelo, self.modelo.contas)\nself.produtos = Contas(self.modelo, self.modelo.produtos)\n\nself.interface.show()", "path": "controle.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\" Igual ao select, mas retorna uma lista de dicion\u00e1rios. \"\"\"\n", "func_signal": "def select_records(self, campos, chaves = {}):\n", "code": "records = [] #Dicion\u00e1rios\nvalues = self.select(campos, chaves)\nfor row in values:\n    record = {}\n    for i in range(len(campos)):\n        record[campos[i]] = row[i]\n    records.append(record)\nreturn records", "path": "querys.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\" Seleciona os campos especificados em campos dos registros especificados em chaves. \"\"\"\n", "func_signal": "def select(self, campos, chaves = {}):\n", "code": "values = []\nsql1 = 'SELECT '\nfor campo in campos:\n    sql1 += campo + ', '\nsql1 = sql1[:-2] + ' FROM ' + self.nome_tabela\n\nif chaves:\n    sql1 += ' WHERE '\n    for chave in chaves:\n        sql1 += chave + '=%s and '\n        values.append(chaves[chave])\n\nreturn self.runQuery(sql1, values)", "path": "querys.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "#----Janela       \n", "func_signal": "def __init__(self, controle):\n", "code": "       self.w_clientes = gtk.Dialog()\n       self.w_clientes.set_position(gtk.WIN_POS_CENTER)\n       self.w_clientes.connect(\"destroy\", self.close)\n       self.w_clientes.set_title(\"CEF SHOP - Cadastrar Categorias de Dvds \")\n       self.w_clientes.set_size_request(800,600)\n       self.w_clientes.set_border_width(8)\n       self.controle = controle", "path": "clientes.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\"Aplica um style no objeto para que ele tenha borda com a cor do tooltip\"\"\"\n", "func_signal": "def paint(self, w, event):\n", "code": "gtk.Style.paint_flat_box(w.style,\n                         w.window,\n                         gtk.STATE_NORMAL,\n                         gtk.SHADOW_OUT,\n                         None,\n                         w,\n                         \"tooltip\",\n                         w.allocation.x + 1,\n                         w.allocation.y + 1,\n                         w.allocation.width - 2,\n                         w.allocation.height - 2)\nreturn False", "path": "notify.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\" Roda um comando execute (insert, update, delete) no banco de dados. \"\"\"\n", "func_signal": "def runSql(self, query, params = None):\n", "code": "self.modelo.cursor.execute(query, params)\nif self.modelo.in_transaction == 0:\n    #Nenhuma transa\u00e7\u00e3o aberta: realiza auto-commit\n    self.modelo.bd.commit()\nreturn self.modelo.last_insert_id()", "path": "querys.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\"Implementa um hack necessario para usar as cores de fundo do tooltip\"\"\"\n", "func_signal": "def on_style_set(self, w, style):\n", "code": "if self.changing_style:\n    return\nwindow = gtk.Window(gtk.WINDOW_POPUP);\nwindow.set_name(\"gtk-tooltip\")\nwindow.ensure_style()\nstyle = window.get_style()\n\nself.changing_style = True\nself.set_style(style)\nself.changing_style = False\n\nwindow.destroy()\nself.queue_draw()", "path": "notify.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\"Adiciona bot\u00e3o de fechar ao notify\"\"\"\n", "func_signal": "def add_button(self):\n", "code": "close_button = gtk.Button()\nclose = gtk.image_new_from_stock(gtk.STOCK_CLOSE, gtk.ICON_SIZE_MENU)\nclose_button.add(close)\nclose_button.set_relief(gtk.RELIEF_NONE)\nself.action_area.pack_start (close_button, False, True, 0)\nreturn close_button", "path": "notify.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\" Retorna o estoque de um produto (se for especificado, em um armaz\u00e9m). Retorna a quantidade em estoque,\n    0 caso n\u00e3o haja nenhum item no estoque ou None caso haja registro do produto no estoque. \"\"\"\n", "func_signal": "def get_estoque(self, cod_produto, localiz):\n", "code": "sql1 = \"SELECT sum(quantidade) FROM estoque WHERE cod_produto=%s\"\nparams = [cod_produto]\nif localiz:\n    sql1 += \" AND localiz=%s\"\n    params.append(localiz)\n\nrset = self.runQuery(sql1, params)\nif rset:\n    return rset[0][0] #Primeiro registro, primeiro campo\nelse:\n    return None", "path": "querys.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\" Verifica se um campo est\u00e1 preenchido e, se n\u00e3o, exibe o notify com a mensagem de erro (caso especificada). \"\"\"\n", "func_signal": "def obrigatorio(self, valor, mensagem = ''):\n", "code": "if not valor:\n    if self.notify and mensagem:\n        self.notify.show_notify('erro', mensagem)\n    return False\nelse:\n    return True", "path": "controle.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\" Inclui um novo pedido em branco \"\"\"\n", "func_signal": "def novo_pedido(self, cod_cliente):\n", "code": "runSql('INSERT INTO pedido (cod_cliente, datahora, status_pedido) VALUES (%s, NOW(), %s)', (cod_cliente, '0'))\nreturn self.modelo.last_insert_id()", "path": "querys.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\"Adiciona um icone ao notify\"\"\"\n", "func_signal": "def add_icon(self, icon):\n", "code": "self.remove_icon()\nif icon == 'erro':\n    self.erro = gtk.image_new_from_stock(gtk.STOCK_DIALOG_ERROR, gtk.ICON_SIZE_MENU)\n    self.icons.append(self.erro)\n    self.icon_area.pack_start (self.erro, False, True, 2)\nelif icon == 'apply':\n    self.apply = gtk.image_new_from_stock(gtk.STOCK_APPLY, gtk.ICON_SIZE_MENU)\n    self.icons.append(self.apply)\n    self.icon_area.pack_start (self.apply, False, True, 2)\nelif icon == 'info':\n    self.info = gtk.image_new_from_stock(gtk.STOCK_DIALOG_INFO, gtk.ICON_SIZE_MENU)\n    self.icons.append(self.info)\n    self.icon_area.pack_start (self.info, False, True, 2)\nelif icon == 'warning':\n    self.warning = gtk.image_new_from_stock(gtk.STOCK_DIALOG_WARNING, gtk.ICON_SIZE_MENU)\n    self.icons.append(self.warning)\n    self.icon_area.pack_start (self.warning, False, True, 2)", "path": "notify.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\" Atualiza o registro identificado por chaves usando os valores de campos na tabela atual (nome_tabela). \"\"\"\n", "func_signal": "def update(self, campos, chaves={}):\n", "code": "sql1 = 'UPDATE ' + self.nome_tabela + ' SET '\nvalues = []\nfor campo in campos:\n    sql1 += campo + '=%s, '\n    values.append(campos[campo])\nsql1 = sql1[:-2] #tira o ', '\n\nif chaves:\n    sql1 += ' WHERE '\n    for chave in chaves:\n        sql1 += chave + \"=%s and \"\n        values.append(chaves[chave])\n    sql1 = sql1[:-5] #tira o ' and '\n\nreturn self.runSql(sql1, values)", "path": "querys.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\"window \u00e9 a janela que est\u00e1 chamando o recebimento\n    itens a lista de itens adquiridos com descri\u00e7\u00e3o e pre\u00e7o\"\"\"\n", "func_signal": "def __init__(self, controle, window, itens):\n", "code": "self.w_receber = gtk.Dialog(\"CEF SHOP - Recebimento\", window, gtk.DIALOG_MODAL)\nself.w_receber.set_position(gtk.WIN_POS_CENTER)\nself.w_receber.set_size_request(550,450)\nself.w_receber.connect(\"destroy\", self.close)\nself.controle = controle", "path": "receber.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\" Obt\u00e9m o n\u00famero do pr\u00f3ximo item no pedido (1 se o pedido n\u00e3o tiver itens) \"\"\"\n", "func_signal": "def next_item(self, cod_pedido):\n", "code": "rows = self.runQuery(\"select max(item) from itempedido where cod_pedido=%s\", (cod_pedido))\nif rows[0][0]:\n    nitem = rows[0][0] + 1\nelse:\n    nitem = 1\nreturn nitem", "path": "querys.py", "repo_name": "venilton/cefsite", "stars": 3, "license": "None", "language": "python", "size": 222}
{"docstring": "\"\"\"This takes two version strings and returns an integer to tell you whether\nthe versions are the same, val1>val2 or val2>val1.\n\n>>> vercmp('1', '2')\n-1.0\n>>> vercmp('2', '1')\n1.0\n>>> vercmp('1', '1.0')\n0\n>>> vercmp('1', '1.1')\n-1.0\n>>> vercmp('1.1', '1_p2')\n1.0\n\"\"\"\n\n# quick short-circuit\n", "func_signal": "def vercmp(val1,val2):\n", "code": "if val1 == val2:\n    return 0\nvalkey = val1+\" \"+val2\n\n# cache lookup\ntry:\n    return __vercmp_cache__[valkey]\n    try:\n        return - __vercmp_cache__[val2+\" \"+val1]\n    except KeyError:\n        pass\nexcept KeyError:\n    pass\n\n# consider 1_p2 vc 1.1\n# after expansion will become (1_p2,0) vc (1,1)\n# then 1_p2 is compared with 1 before 0 is compared with 1\n# to solve the bug we need to convert it to (1,0_p2)\n# by splitting _prepart part and adding it back _after_expansion\n\nval1_prepart = val2_prepart = ''\nif val1.count('_'):\n    val1, val1_prepart = val1.split('_', 1)\nif val2.count('_'):\n    val2, val2_prepart = val2.split('_', 1)\n\n# replace '-' by '.'\n# FIXME: Is it needed? can val1/2 contain '-'?\n\nval1 = string.split(val1,'-')\nif len(val1) == 2:\n    val1[0] = val1[0] +\".\"+ val1[1]\nval2 = string.split(val2,'-')\nif len(val2) == 2:\n    val2[0] = val2[0] +\".\"+ val2[1]\n\nval1 = string.split(val1[0],'.')\nval2 = string.split(val2[0],'.')\n\n# add back decimal point so that .03 does not become \"3\" !\nfor x in range(1,len(val1)):\n    if val1[x][0] == '0' :\n        val1[x] = '.' + val1[x]\nfor x in range(1,len(val2)):\n    if val2[x][0] == '0' :\n        val2[x] = '.' + val2[x]\n\n# extend varion numbers\nif len(val2) < len(val1):\n    val2.extend([\"0\"]*(len(val1)-len(val2)))\nelif len(val1) < len(val2):\n    val1.extend([\"0\"]*(len(val2)-len(val1)))\n\n# add back _prepart tails\nif val1_prepart:\n    val1[-1] += '_' + val1_prepart\nif val2_prepart:\n    val2[-1] += '_' + val2_prepart\n# The above code will extend version numbers out so they\n# have the same number of digits.\nfor x in range(0,len(val1)):\n    cmp1 = relparse(val1[x])\n    cmp2 = relparse(val2[x])\n    for y in range(0,3):\n        myret = cmp1[y] - cmp2[y]\n        if myret != 0:\n            __vercmp_cache__[valkey] = myret\n            return myret\n__vercmp_cache__[valkey] = 0\nreturn 0", "path": "bitbake\\lib\\bb\\__init__.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "\"\"\"Removes tokens based on whether conditional definitions exist or not.\nRecognizes !\n\n>>> evaluate(['sys-apps/linux-headers', 'nls?', ['sys-devel/gettext']], {})\n['sys-apps/linux-headers']\n\nNegate the flag:\n\n>>> evaluate(['sys-apps/linux-headers', '!nls?', ['sys-devel/gettext']], {})\n['sys-apps/linux-headers', ['sys-devel/gettext']]\n\nDefine 'nls':\n\n>>> evaluate(['sys-apps/linux-headers', 'nls?', ['sys-devel/gettext']], {\"nls\":1})\n['sys-apps/linux-headers', ['sys-devel/gettext']]\n\nTurn allon on:\n\n>>> evaluate(['sys-apps/linux-headers', 'nls?', ['sys-devel/gettext']], {}, True)\n['sys-apps/linux-headers', ['sys-devel/gettext']]\n\"\"\"\n\n", "func_signal": "def evaluate(tokens,mydefines,allon=0):\n", "code": "if tokens == None:\n    return None\nmytokens = tokens + []        # this copies the list\npos = 0\nwhile pos < len(mytokens):\n    if type(mytokens[pos]) == types.ListType:\n        evaluate(mytokens[pos], mydefines)\n        if not len(mytokens[pos]):\n            del mytokens[pos]\n            continue\n    elif mytokens[pos][-1] == \"?\":\n        cur = mytokens[pos][:-1]\n        del mytokens[pos]\n        if allon:\n            if cur[0] == \"!\":\n                del mytokens[pos]\n        else:\n            if cur[0] == \"!\":\n                if (cur[1:] in mydefines) and (pos < len(mytokens)):\n                    del mytokens[pos]\n                    continue\n            elif (cur not in mydefines) and (pos < len(mytokens)):\n                del mytokens[pos]\n                continue\n    pos = pos + 1\nreturn mytokens", "path": "bitbake\\lib\\bb\\__init__.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "\"\"\"Returns true if we have a handler for this file, false otherwise\"\"\"\n", "func_signal": "def supports(fn, data):\n", "code": "for h in handlers:\n    if h['supports'](fn, data):\n        return 1\nreturn 0", "path": "bitbake\\lib\\bb\\parse\\__init__.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "# Rip apart the cvsroot style location to build a cvs:// url for\n# bitbake's usage in the cvsmodule handler.\n# root=\":pserver:anoncvs@cvs.freedesktop.org:/cvs/fontconfig\"\n", "func_signal": "def cvsroot(self, element, parent):\n", "code": "print(\"cvsroot(%s, %s)\" % (element, parent))\n\nroot = element.attrib.get('root')\nrootmatch = re.match(Handlers.cvsrootpat, root)\nname = element.attrib.get('name')\nuser = rootmatch.group('user') or ''\nif user != '':\n    pw = element.attrib.get('password') or ''\n    if pw != '':\n        pw = ':' + pw + '@'\n    else:\n        user = user + '@'\nprint('user: %s' % user)\nprint('pw: %s' % pw)\n\nhost = rootmatch.group('host')\nprint('host: %s' % host)\npath = rootmatch.group('path') or '/'\nprint('path: %s' % path)\n\nroot = \"cvs://%s%s%s%s\" % (user, pw, host, path)\nprint('root: %s' % root)\nself.cvsroots[name] = root", "path": "scripts\\jhbuild\\jhbuild2oe.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "\"\"\"Call the handler that is appropriate for this file\"\"\"\n", "func_signal": "def handle(fn, data, include = 0):\n", "code": "for h in handlers:\n    if h['supports'](fn, data):\n        return h['handle'](fn, data, include)\nraise ParseError(\"%s is not a BitBake file\" % fn)", "path": "bitbake\\lib\\bb\\parse\\__init__.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "\"\"\" Compares two packages, which should have been split via\npkgsplit(). if the return value val is less than zero, then pkg2 is\nnewer than pkg1, zero if equal and positive if older.\n\n>>> pkgcmp(['glibc', '2.2.5', 'r7'], ['glibc', '2.2.5', 'r7'])\n0\n>>> pkgcmp(['glibc', '2.2.5', 'r4'], ['glibc', '2.2.5', 'r7'])\n-1\n>>> pkgcmp(['glibc', '2.2.5', 'r7'], ['glibc', '2.2.5', 'r2'])\n1\n\"\"\"\n\n", "func_signal": "def pkgcmp(pkg1,pkg2):\n", "code": "mycmp = vercmp(pkg1[1],pkg2[1])\nif mycmp > 0:\n    return 1\nif mycmp < 0:\n    return -1\nr1=string.atoi(pkg1[2][1:])\nr2=string.atoi(pkg2[2][1:])\nif r1 > r2:\n    return 1\nif r2 > r1:\n    return -1\nreturn 0", "path": "bitbake\\lib\\bb\\__init__.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "# return a relative path to the bitbake .bb which will be written\n", "func_signal": "def filefunc(package):\n", "code": "src_uri = bb.data.getVar('SRC_URI', package, 1)\nfilename = bb.data.getVar('PN', package, 1) + '.bb'\nif not src_uri:\n    return filename\nelse:\n    substr = src_uri[src_uri.find('xorg/'):]\n    subdirlist = substr.split('/')[:2]\n    subdir = '-'.join(subdirlist)\n    return os.path.join(subdir, filename)", "path": "scripts\\jhbuild\\jhbuild2oe.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "# TODO:\n# Convert the URL in the href attribute, if necessary, to the format\n# which bitbake expects to see in SRC_URI.\n", "func_signal": "def repository(self, element, parent):\n", "code": "name = element.attrib.get('name')\nself.repositories[name] = element.attrib.get('href')", "path": "scripts\\jhbuild\\jhbuild2oe.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "\"\"\"Decodes an URL into the tokens (scheme, network location, path,\nuser, password, parameters).\n\n>>> decodeurl(\"http://www.google.com/index.html\")\n('http', 'www.google.com', '/index.html', '', '', {})\n\nCVS url with username, host and cvsroot. The cvs module to check out is in the\nparameters:\n\n>>> decodeurl(\"cvs://anoncvs@cvs.handhelds.org/cvs;module=familiar/dist/ipkg\")\n('cvs', 'cvs.handhelds.org', '/cvs', 'anoncvs', '', {'module': 'familiar/dist/ipkg'})\n\nDito, but this time the username has a password part. And we also request a special tag\nto check out.\n\n>>> decodeurl(\"cvs://anoncvs:anonymous@cvs.handhelds.org/cvs;module=familiar/dist/ipkg;tag=V0-99-81\")\n('cvs', 'cvs.handhelds.org', '/cvs', 'anoncvs', 'anonymous', {'tag': 'V0-99-81', 'module': 'familiar/dist/ipkg'})\n\"\"\"\n\n", "func_signal": "def decodeurl(url):\n", "code": "m = re.compile('(?P<type>[^:]*)://((?P<user>.+)@)?(?P<location>[^;]+)(;(?P<parm>.*))?').match(url)\nif not m:\n    raise MalformedUrl(url)\n\ntype = m.group('type')\nlocation = m.group('location')\nif not location:\n    raise MalformedUrl(url)\nuser = m.group('user')\nparm = m.group('parm')\n\nlocidx = location.find('/')\nif locidx != -1:\n    host = location[:locidx]\n    path = location[locidx:]\nelse:\n    host = \"\"\n    path = location\nif user:\n    m = re.compile('(?P<user>[^:]+)(:?(?P<pswd>.*))').match(user)\n    if m:\n        user = m.group('user')\n        pswd = m.group('pswd')\nelse:\n    user = ''\n    pswd = ''\n\np = {}\nif parm:\n    for s in parm.split(';'):\n        s1,s2 = s.split('=')\n        p[s1] = s2\n\nreturn (type, host, path, user, pswd, p)", "path": "bitbake\\lib\\bb\\__init__.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "\"\"\"Converts nested arrays into a flat arrays:\n\n>>> flatten([1,[2,3]])\n[1, 2, 3]\n>>> flatten(['sys-apps/linux-headers', ['sys-devel/gettext']])\n['sys-apps/linux-headers', 'sys-devel/gettext']\n\"\"\"\n\n", "func_signal": "def flatten(mytokens):\n", "code": "newlist=[]\nfor x in mytokens:\n    if type(x)==types.ListType:\n        newlist.extend(flatten(x))\n    else:\n        newlist.append(x)\nreturn newlist", "path": "bitbake\\lib\\bb\\__init__.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "\"\"\"\nBuild up an hg commandline based on ud\ncommand is \"fetch\", \"update\", \"info\"\n\"\"\"\n\n", "func_signal": "def _buildhgcommand(self, ud, d, command):\n", "code": "basecmd = data.expand('${FETCHCMD_hg}', d)\n\nproto = \"http\"\nif \"proto\" in ud.parm:\n    proto = ud.parm[\"proto\"]\n\nhost = ud.host\nif proto == \"file\":\n    host = \"/\"\n    ud.host = \"localhost\"\n\nif not ud.user:\n    hgroot = host + ud.path\nelse:\n    hgroot = ud.user + \"@\" + host + ud.path\n\nif command is \"info\":\n    return \"%s identify -i %s://%s/%s\" % (basecmd, proto, hgroot, ud.module)\n\noptions = [];\nif ud.revision:\n    options.append(\"-r %s\" % ud.revision)\n\nif command is \"fetch\":\n    cmd = \"%s clone %s %s://%s/%s %s\" % (basecmd, \" \".join(options), proto, hgroot, ud.module, ud.module)\nelif command is \"pull\":\n    # do not pass options list; limiting pull to rev causes the local\n    # repo not to contain it and immediately following \"update\" command\n    # will crash\n    cmd = \"%s pull\" % (basecmd)\nelif command is \"update\":\n    cmd = \"%s update -C %s\" % (basecmd, \" \".join(options))\nelse:\n    raise FetchError(\"Invalid hg command %s\" % command)\n\nreturn cmd", "path": "bitbake-dev\\lib\\bb\\fetch\\hg.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "\"\"\"Fetch url\"\"\"\n\n# try to use the tarball stash\n", "func_signal": "def go(self, loc, ud, d):\n", "code": "if Fetch.try_mirror(d, ud.localfile):\n    bb.msg.debug(1, bb.msg.domain.Fetcher, \"%s already exists or was mirrored, skipping hg checkout.\" % ud.localpath)\n    return\n\nbb.msg.debug(2, bb.msg.domain.Fetcher, \"Fetch: checking for module directory '\" + ud.moddir + \"'\")\n\nif os.access(os.path.join(ud.moddir, '.hg'), os.R_OK):\n    updatecmd = self._buildhgcommand(ud, d, \"pull\")\n    bb.msg.note(1, bb.msg.domain.Fetcher, \"Update \" + loc)\n    # update sources there\n    os.chdir(ud.moddir)\n    bb.msg.debug(1, bb.msg.domain.Fetcher, \"Running %s\" % updatecmd)\n    runfetchcmd(updatecmd, d)\n\nelse:\n    fetchcmd = self._buildhgcommand(ud, d, \"fetch\")\n    bb.msg.note(1, bb.msg.domain.Fetcher, \"Fetch \" + loc)\n    # check out sources there\n    bb.mkdirhier(ud.pkgdir)\n    os.chdir(ud.pkgdir)\n    bb.msg.debug(1, bb.msg.domain.Fetcher, \"Running %s\" % fetchcmd)\n    runfetchcmd(fetchcmd, d)", "path": "bitbake-dev\\lib\\bb\\fetch\\hg.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "\"\"\"returns [cat, pkgname, version, rev ]\n\n>>> catpkgsplit('sys-libs/glibc-1.2-r7')\n['sys-libs', 'glibc', '1.2', 'r7']\n>>> catpkgsplit('glibc-1.2-r7')\n[None, 'glibc', '1.2', 'r7']\n\"\"\"\n\n", "func_signal": "def catpkgsplit(mydata,silent=1):\n", "code": "try:\n    return __catpkgsplit_cache__[mydata]\nexcept KeyError:\n    pass\n\ncat = os.path.basename(os.path.dirname(mydata))\nmydata = os.path.join(cat, os.path.basename(mydata))\nif mydata[-3:] == '.bb':\n    mydata = mydata[:-3]\n\nmysplit = mydata.split(\"/\")\np_split = None\nsplitlen = len(mysplit)\nif splitlen == 1:\n    retval = [None]\n    p_split = pkgsplit(mydata,silent)\nelse:\n    retval = [mysplit[splitlen - 2]]\n    p_split = pkgsplit(mysplit[splitlen - 1],silent)\nif not p_split:\n    __catpkgsplit_cache__[mydata] = None\n    return None\nretval.extend(p_split)\n__catpkgsplit_cache__[mydata] = retval\nreturn retval", "path": "bitbake\\lib\\bb\\__init__.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "# grab the deps\n", "func_signal": "def metamodule(self, element, parent):\n", "code": "deps = None\nfor child in element:\n    if child.tag == 'dependencies':\n        deps = [self.packagename(dep.attrib.get('package')) for dep in child if dep.tag == \"dep\"]\n\n# create the package\nd = bb.data.init()\npn = self.packagename(element.attrib.get('id'))\nbb.data.setVar('PN', pn, d)\nbb.data.setVar('DEPENDS', ' '.join(deps), d)\nbb.data.setVar('_handler', 'metamodule', d)\nself.packages.append(d)", "path": "scripts\\jhbuild\\jhbuild2oe.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "\"\"\"Encodes a URL from tokens (scheme, network location, path,\nuser, password, parameters).\n\n>>> encodeurl(['http', 'www.google.com', '/index.html', '', '', {}])\n'http://www.google.com/index.html'\n\nCVS with username, host and cvsroot. The cvs module to check out is in the\nparameters:\n\n>>> encodeurl(['cvs', 'cvs.handhelds.org', '/cvs', 'anoncvs', '', {'module': 'familiar/dist/ipkg'}])\n'cvs://anoncvs@cvs.handhelds.org/cvs;module=familiar/dist/ipkg'\n\nDito, but this time the username has a password part. And we also request a special tag\nto check out.\n\n>>> encodeurl(['cvs', 'cvs.handhelds.org', '/cvs', 'anoncvs', 'anonymous', {'tag': 'V0-99-81', 'module': 'familiar/dist/ipkg'}])\n'cvs://anoncvs:anonymous@cvs.handhelds.org/cvs;tag=V0-99-81;module=familiar/dist/ipkg'\n\"\"\"\n\n", "func_signal": "def encodeurl(decoded):\n", "code": "(type, host, path, user, pswd, p) = decoded\n\nif not type or not path:\n    fatal(\"invalid or missing parameters for url encoding\")\nurl = '%s://' % type\nif user:\n    url += \"%s\" % user\n    if pswd:\n        url += \":%s\" % pswd\n    url += \"@\"\nif host:\n    url += \"%s\" % host\nurl += \"%s\" % path\nif p:\n    for parm in p.keys():\n        url += \";%s=%s\" % (parm, p[parm])\n\nreturn url", "path": "bitbake\\lib\\bb\\__init__.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "\"\"\"Accepts a list of strings, and converts '(' and ')' surrounded items to sub-lists:\n\n>>> dep_parenreduce([''])\n['']\n>>> dep_parenreduce(['1', '2', '3'])\n['1', '2', '3']\n>>> dep_parenreduce(['1', '(', '2', '3', ')', '4'])\n['1', ['2', '3'], '4']\n\"\"\"\n\n", "func_signal": "def dep_parenreduce(mysplit, mypos=0):\n", "code": "while mypos < len(mysplit):\n    if mysplit[mypos] == \"(\":\n        firstpos = mypos\n        mypos = mypos + 1\n        while mypos < len(mysplit):\n            if mysplit[mypos] == \")\":\n                mysplit[firstpos:mypos+1] = [mysplit[firstpos+1:mypos]]\n                mypos = firstpos\n                break\n            elif mysplit[mypos] == \"(\":\n                # recurse\n                mysplit = dep_parenreduce(mysplit,mypos)\n            mypos = mypos + 1\n    mypos = mypos + 1\nreturn mysplit", "path": "bitbake\\lib\\bb\\__init__.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "# 1) Assemble new file contents in ram, either new from bitbake\n#    metadata, or a combination of the template and that metadata.\n# 2) Open the path returned by the filefunc + the basedir for writing.\n# 3) Write the new bitbake data file.\n", "func_signal": "def write(self, package, template = None):\n", "code": "fdata = ''\nif template:\n    f = file(template, 'r')\n    fdata = f.read()\n    f.close()\n\n    for key in bb.data.keys(package):\n        fdata = fdata.replace('@@'+key+'@@', bb.data.getVar(key, package))\nelse:\n    for key in bb.data.keys(package):\n        if key == '_handler':\n            continue\n        elif key == 'INHERITS':\n            fdata += 'inherit %s\\n' % bb.data.getVar('INHERITS', package)\n        else:\n            oper = bb.data.getVarFlag(key, 'operator', package) or '='\n            fdata += '%s %s \"%s\"\\n' % (key, oper, bb.data.getVar(key, package))\n\nif not os.path.exists(os.path.join(self.basedir, os.path.dirname(self.filefunc(package)))):\n    os.makedirs(os.path.join(self.basedir, os.path.dirname(self.filefunc(package))))\n\nout = file(os.path.join(self.basedir, self.filefunc(package)), 'w')\nout.write(fdata)\nout.close()", "path": "scripts\\jhbuild\\jhbuild2oe.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "\"\"\"Parses the last elements of a version number into a triplet, that can\nlater be compared:\n\n>>> relparse('1.2_pre3')\n[1.2, -2, 3.0]\n>>> relparse('1.2b')\n[1.2, 98, 0]\n>>> relparse('1.2')\n[1.2, 0, 0]\n\"\"\"\n\n", "func_signal": "def relparse(myver):\n", "code": "number   = 0\np1       = 0\np2       = 0\nmynewver = myver.split('_')\nif len(mynewver)==2:\n    # an _package_weights_\n    number = float(mynewver[0])\n    match = 0\n    for x in _package_ends_:\n        elen = len(x)\n        if mynewver[1][:elen] == x:\n            match = 1\n            p1 = _package_weights_[x]\n            try:\n                p2 = float(mynewver[1][elen:])\n            except:\n                p2 = 0\n            break\n    if not match:\n        # normal number or number with letter at end\n        divider = len(myver)-1\n        if myver[divider:] not in \"1234567890\":\n            # letter at end\n            p1 = ord(myver[divider:])\n            number = float(myver[0:divider])\n        else:\n            number = float(myver)\nelse:\n    # normal number or number with letter at end\n    divider = len(myver)-1\n    if myver[divider:] not in \"1234567890\":\n        #letter at end\n        p1     = ord(myver[divider:])\n        number = float(myver[0:divider])\n    else:\n        number = float(myver)\nreturn [number,p1,p2]", "path": "bitbake\\lib\\bb\\__init__.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "\"\"\"\nLocate a file in a PATH\n\"\"\"\n\n", "func_signal": "def which(path, item, direction = 0):\n", "code": "paths = (path or \"\").split(':')\nif direction != 0:\n    paths.reverse()\n\nfor p in (path or \"\").split(':'):\n    next = os.path.join(p, item)\n    if os.path.exists(next):\n        return next\n\nreturn \"\"", "path": "bitbake\\lib\\bb\\__init__.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "\"\"\"Returns 1 if given a valid version string, els 0. Valid versions are in the format\n\n<v1>.<v2>...<vx>[a-z,_{_package_weights_}[vy]]\n\n>>> ververify('2.4.20')\n1\n>>> ververify('2.4..20')        # two dots\n0\n>>> ververify('2.x.20')            # 'x' is not numeric\n0\n>>> ververify('2.4.20a')\n1\n>>> ververify('2.4.20cvs')        # only one trailing letter\n0\n>>> ververify('1a')\n1\n>>> ververify('test_a')            # no version at all\n0\n>>> ververify('2.4.20_beta1')\n1\n>>> ververify('2.4.20_beta')\n1\n>>> ververify('2.4.20_wrongext')    # _wrongext is no valid trailer\n0\n\"\"\"\n\n# Lookup the cache first\n", "func_signal": "def ververify(myorigval,silent=1):\n", "code": "try:\n    return __ververify_cache__[myorigval]\nexcept KeyError:\n    pass\n\nif len(myorigval) == 0:\n    if not silent:\n        error(\"package version is empty\")\n    __ververify_cache__[myorigval] = 0\n    return 0\nmyval = myorigval.split('.')\nif len(myval)==0:\n    if not silent:\n        error(\"package name has empty version string\")\n    __ververify_cache__[myorigval] = 0\n    return 0\n# all but the last version must be a numeric\nfor x in myval[:-1]:\n    if not len(x):\n        if not silent:\n            error(\"package version has two points in a row\")\n        __ververify_cache__[myorigval] = 0\n        return 0\n    try:\n        foo = int(x)\n    except:\n        if not silent:\n            error(\"package version contains non-numeric '\"+x+\"'\")\n        __ververify_cache__[myorigval] = 0\n        return 0\nif not len(myval[-1]):\n        if not silent:\n            error(\"package version has trailing dot\")\n        __ververify_cache__[myorigval] = 0\n        return 0\ntry:\n    foo = int(myval[-1])\n    __ververify_cache__[myorigval] = 1\n    return 1\nexcept:\n    pass\n\n# ok, our last component is not a plain number or blank, let's continue\nif myval[-1][-1] in lowercase:\n    try:\n        foo = int(myval[-1][:-1])\n        return 1\n        __ververify_cache__[myorigval] = 1\n        # 1a, 2.0b, etc.\n    except:\n        pass\n# ok, maybe we have a 1_alpha or 1_beta2; let's see\nep=string.split(myval[-1],\"_\")\nif len(ep)!= 2:\n    if not silent:\n        error(\"package version has more than one letter at then end\")\n    __ververify_cache__[myorigval] = 0\n    return 0\ntry:\n    foo = string.atoi(ep[0])\nexcept:\n    # this needs to be numeric, i.e. the \"1\" in \"1_alpha\"\n    if not silent:\n        error(\"package version must have numeric part before the '_'\")\n    __ververify_cache__[myorigval] = 0\n    return 0\n\nfor mye in _package_ends_:\n    if ep[1][0:len(mye)] == mye:\n        if len(mye) == len(ep[1]):\n            # no trailing numeric is ok\n            __ververify_cache__[myorigval] = 1\n            return 1\n        else:\n            try:\n                foo = string.atoi(ep[1][len(mye):])\n                __ververify_cache__[myorigval] = 1\n                return 1\n            except:\n                # if no _package_weights_ work, *then* we return 0\n                pass\nif not silent:\n    error(\"package version extension after '_' is invalid\")\n__ververify_cache__[myorigval] = 0\nreturn 0", "path": "bitbake\\lib\\bb\\__init__.py", "repo_name": "webiapoky/webiapoky", "stars": 2, "license": "other", "language": "python", "size": 33580}
{"docstring": "# Convert the document to Unicode.\n", "func_signal": "def _feed(self, inDocumentEncoding=None, isHTML=False):\n", "code": "markup = self.markup\nif isinstance(markup, unicode):\n    if not hasattr(self, 'originalEncoding'):\n        self.originalEncoding = None\nelse:\n    dammit = UnicodeDammit\\\n             (markup, [self.fromEncoding, inDocumentEncoding],\n              smartQuotesTo=self.smartQuotesTo, isHTML=isHTML)\n    markup = dammit.unicode\n    self.originalEncoding = dammit.originalEncoding\n    self.declaredHTMLEncoding = dammit.declaredHTMLEncoding\nif markup:\n    if self.markupMassage:\n        if not isList(self.markupMassage):\n            self.markupMassage = self.MARKUP_MASSAGE\n        for fix, m in self.markupMassage:\n            markup = fix.sub(m, markup)\n        # TODO: We get rid of markupMassage so that the\n        # soup object can be deepcopied later on. Some\n        # Python installations can't copy regexes. If anyone\n        # was relying on the existence of markupMassage, this\n        # might cause problems.\n        del(self.markupMassage)\nself.reset()\n\nSGMLParser.feed(self, markup)\n# Close out any unfinished strings and close all the open tags.\nself.endData()\nwhile self.currentTag.name != self.ROOT_TAG_NAME:\n    self.popTag()", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "#self.universe.rotatePlanets( -60*event.fraction() )\n", "func_signal": "def OnTimerFraction( self, event ):\n", "code": "self.iter = self.iter + 1\n#print \"awesome! %d\" % self.iter\nif(self.iter > 200):  \n\tself.updateFromSQL()\n\tself.iter = 0", "path": "app.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "#print \"Push\", tag.name\n", "func_signal": "def pushTag(self, tag):\n", "code": "if self.currentTag:\n    self.currentTag.contents.append(tag)\nself.tagStack.append(tag)\nself.currentTag = self.tagStack[-1]", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Returns the closest parent of this Tag that matches the given\ncriteria.\"\"\"\n# NOTE: We can't use _findOne because findParents takes a different\n# set of arguments.\n", "func_signal": "def findParent(self, name=None, attrs={}, **kwargs):\n", "code": "r = None\nl = self.findParents(name, attrs, 1)\nif l:\n    r = l[0]\nreturn r", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"This method fixes a bug in Python's SGMLParser.\"\"\"\n", "func_signal": "def convert_charref(self, name):\n", "code": "try:\n    n = int(name)\nexcept ValueError:\n    return\nif not 0 <= n <= 127 : # ASCII ends at 127, not 255\n    return\nreturn self.convert_codepoint(n)", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Handle a processing instruction as a ProcessingInstruction\nobject, possibly one with a %SOUP-ENCODING% slot into which an\nencoding will be plugged later.\"\"\"\n", "func_signal": "def handle_pi(self, text):\n", "code": "if text[:3] == \"xml\":\n    text = u\"xml version='1.0' encoding='%SOUP-ENCODING%'\"\nself._toStringSubclass(text, ProcessingInstruction)", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Returns true iff this tag has the same name, the same attributes,\nand the same contents (recursively) as the given tag.\n\nNOTE: right now this will return false if two tags have the\nsame attributes in a different order. Should this be fixed?\"\"\"\n", "func_signal": "def __eq__(self, other):\n", "code": "if not hasattr(other, 'name') or not hasattr(other, 'attrs') or not hasattr(other, 'contents') or self.name != other.name or self.attrs != other.attrs or len(self) != len(other):\n    return False\nfor i in range(0, len(self.contents)):\n    if self.contents[i] != other.contents[i]:\n        return False\nreturn True", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Returns true iff the given string is the name of a\nself-closing tag according to this parser.\"\"\"\n", "func_signal": "def isSelfClosingTag(self, name):\n", "code": "return self.SELF_CLOSING_TAGS.has_key(name) \\\n       or self.instanceSelfClosingTags.has_key(name)", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Treat a bogus SGML declaration as raw data. Treat a CDATA\ndeclaration as a CData object.\"\"\"\n", "func_signal": "def parse_declaration(self, i):\n", "code": "j = None\nif self.rawdata[i:i+9] == '<![CDATA[':\n     k = self.rawdata.find(']]>', i)\n     if k == -1:\n         k = len(self.rawdata)\n     data = self.rawdata[i+9:k]\n     j = k+3\n     self._toStringSubclass(data, CData)\nelse:\n    try:\n        j = SGMLParser.parse_declaration(self, i)\n    except SGMLParseError:\n        toHandle = self.rawdata[i:]\n        self.handle_data(toHandle)\n        j = i + len(toHandle)\nreturn j", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Encodes an object to a string in some encoding, or to Unicode.\n.\"\"\"\n", "func_signal": "def toEncoding(self, s, encoding=None):\n", "code": "if isinstance(s, unicode):\n    if encoding:\n        s = s.encode(encoding)\nelif isinstance(s, str):\n    if encoding:\n        s = s.encode(encoding)\n    else:\n        s = unicode(s)\nelse:\n    if encoding:\n        s  = self.toEncoding(str(s), encoding)\n    else:\n        s = unicode(s)\nreturn s", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Setting tag[key] sets the value of the 'key' attribute for the\ntag.\"\"\"\n", "func_signal": "def __setitem__(self, key, value):\n", "code": "self._getAttrMap()\nself.attrMap[key] = value\nfound = False\nfor i in range(0, len(self.attrs)):\n    if self.attrs[i][0] == key:\n        self.attrs[i] = (key, value)\n        found = True\nif not found:\n    self.attrs.append((key, value))\nself._getAttrMap()[key] = value", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Initializes a map representation of this tag's attributes,\nif not already initialized.\"\"\"\n", "func_signal": "def _getAttrMap(self):\n", "code": "if not getattr(self, 'attrMap'):\n    self.attrMap = {}\n    for (key, value) in self.attrs:\n        self.attrMap[key] = value\nreturn self.attrMap", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Sets up the initial relations between this element and\nother elements.\"\"\"\n", "func_signal": "def setup(self, parent=None, previous=None):\n", "code": "self.parent = parent\nself.previous = previous\nself.next = None\nself.previousSibling = None\nself.nextSibling = None\nif self.parent and self.parent.contents:\n    self.previousSibling = self.parent.contents[-1]\n    self.previousSibling.nextSibling = self", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Used in a call to re.sub to replace HTML, XML, and numeric\nentities with the appropriate Unicode characters. If HTML\nentities are being converted, any unrecognized entities are\nescaped.\"\"\"\n", "func_signal": "def _convertEntities(self, match):\n", "code": "x = match.group(1)\nif self.convertHTMLEntities and x in name2codepoint:\n    return unichr(name2codepoint[x])\nelif x in self.XML_ENTITIES_TO_SPECIAL_CHARS:\n    if self.convertXMLEntities:\n        return self.XML_ENTITIES_TO_SPECIAL_CHARS[x]\n    else:\n        return u'&%s;' % x\nelif len(x) > 0 and x[0] == '#':\n    # Handle numeric entities\n    if len(x) > 1 and x[1] == 'x':\n        return unichr(int(x[2:], 16))\n    else:\n        return unichr(int(x[1:]))\n\nelif self.escapeUnrecognizedEntities:\n    return u'&amp;%s;' % x\nelse:\n    return u'&%s;' % x", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"This method routes method call requests to either the SGMLParser\nsuperclass or the Tag superclass, depending on the method name.\"\"\"\n#print \"__getattr__ called on %s.%s\" % (self.__class__, methodName)\n\n", "func_signal": "def __getattr__(self, methodName):\n", "code": "if methodName.find('start_') == 0 or methodName.find('end_') == 0 \\\n       or methodName.find('do_') == 0:\n    return SGMLParser.__getattr__(self, methodName)\nelif methodName.find('__') != 0:\n    return Tag.__getattr__(self, methodName)\nelse:\n    raise AttributeError", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Adds a certain piece of text to the tree as a NavigableString\nsubclass.\"\"\"\n", "func_signal": "def _toStringSubclass(self, text, subclass):\n", "code": "self.endData()\nself.handle_data(text)\nself.endData(subclass)", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Create a new NavigableString.\n\nWhen unpickling a NavigableString, this method is called with\nthe string in DEFAULT_OUTPUT_ENCODING. That encoding needs to be\npassed in to the superclass's __new__ or the superclass won't know\nhow to handle non-ASCII characters.\n\"\"\"\n", "func_signal": "def __new__(cls, value):\n", "code": "if isinstance(value, unicode):\n    return unicode.__new__(cls, value)\nreturn unicode.__new__(cls, value, DEFAULT_OUTPUT_ENCODING)", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Convenience method that works with all 2.x versions of Python\nto determine whether or not something is listlike.\"\"\"\n", "func_signal": "def isList(l):\n", "code": "return hasattr(l, '__iter__') \\\n       or (type(l) in (types.ListType, types.TupleType))", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Returns the parents of this Tag that match the given\ncriteria.\"\"\"\n\n", "func_signal": "def findParents(self, name=None, attrs={}, limit=None, **kwargs):\n", "code": "return self._findAll(name, attrs, None, limit, self.parentGenerator,\n                     **kwargs)", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Given a document, tries to detect its XML encoding.\"\"\"\n", "func_signal": "def _detectEncoding(self, xml_data, isHTML=False):\n", "code": "xml_encoding = sniffed_xml_encoding = None\ntry:\n    if xml_data[:4] == '\\x4c\\x6f\\xa7\\x94':\n        # EBCDIC\n        xml_data = self._ebcdic_to_ascii(xml_data)\n    elif xml_data[:4] == '\\x00\\x3c\\x00\\x3f':\n        # UTF-16BE\n        sniffed_xml_encoding = 'utf-16be'\n        xml_data = unicode(xml_data, 'utf-16be').encode('utf-8')\n    elif (len(xml_data) >= 4) and (xml_data[:2] == '\\xfe\\xff') \\\n             and (xml_data[2:4] != '\\x00\\x00'):\n        # UTF-16BE with BOM\n        sniffed_xml_encoding = 'utf-16be'\n        xml_data = unicode(xml_data[2:], 'utf-16be').encode('utf-8')\n    elif xml_data[:4] == '\\x3c\\x00\\x3f\\x00':\n        # UTF-16LE\n        sniffed_xml_encoding = 'utf-16le'\n        xml_data = unicode(xml_data, 'utf-16le').encode('utf-8')\n    elif (len(xml_data) >= 4) and (xml_data[:2] == '\\xff\\xfe') and \\\n             (xml_data[2:4] != '\\x00\\x00'):\n        # UTF-16LE with BOM\n        sniffed_xml_encoding = 'utf-16le'\n        xml_data = unicode(xml_data[2:], 'utf-16le').encode('utf-8')\n    elif xml_data[:4] == '\\x00\\x00\\x00\\x3c':\n        # UTF-32BE\n        sniffed_xml_encoding = 'utf-32be'\n        xml_data = unicode(xml_data, 'utf-32be').encode('utf-8')\n    elif xml_data[:4] == '\\x3c\\x00\\x00\\x00':\n        # UTF-32LE\n        sniffed_xml_encoding = 'utf-32le'\n        xml_data = unicode(xml_data, 'utf-32le').encode('utf-8')\n    elif xml_data[:4] == '\\x00\\x00\\xfe\\xff':\n        # UTF-32BE with BOM\n        sniffed_xml_encoding = 'utf-32be'\n        xml_data = unicode(xml_data[4:], 'utf-32be').encode('utf-8')\n    elif xml_data[:4] == '\\xff\\xfe\\x00\\x00':\n        # UTF-32LE with BOM\n        sniffed_xml_encoding = 'utf-32le'\n        xml_data = unicode(xml_data[4:], 'utf-32le').encode('utf-8')\n    elif xml_data[:3] == '\\xef\\xbb\\xbf':\n        # UTF-8 with BOM\n        sniffed_xml_encoding = 'utf-8'\n        xml_data = unicode(xml_data[3:], 'utf-8').encode('utf-8')\n    else:\n        sniffed_xml_encoding = 'ascii'\n        pass\nexcept:\n    xml_encoding_match = None\nxml_encoding_match = re.compile(\n    '^<\\?.*encoding=[\\'\"](.*?)[\\'\"].*\\?>').match(xml_data)\nif not xml_encoding_match and isHTML:\n    regexp = re.compile('<\\s*meta[^>]+charset=([^>]*?)[;\\'\">]', re.I)\n    xml_encoding_match = regexp.search(xml_data)\nif xml_encoding_match is not None:\n    xml_encoding = xml_encoding_match.groups()[0].lower()\n    if isHTML:\n        self.declaredHTMLEncoding = xml_encoding\n    if sniffed_xml_encoding and \\\n       (xml_encoding in ('iso-10646-ucs-2', 'ucs-2', 'csunicode',\n                         'iso-10646-ucs-4', 'ucs-4', 'csucs4',\n                         'utf-16', 'utf-32', 'utf_16', 'utf_32',\n                         'utf16', 'u16')):\n        xml_encoding = sniffed_xml_encoding\nreturn xml_data, xml_encoding, sniffed_xml_encoding", "path": "BeautifulSoup.py", "repo_name": "candersonmiller/glart-final", "stars": 3, "license": "None", "language": "python", "size": 128}
{"docstring": "\"\"\"Used as decorator to check username and password.\"\"\"\n", "func_signal": "def _check_userpass(func):\n", "code": "def new_def(*args, **kwds):\n    self = args[0]\n    if not self.username:\n        raise ValueError(\"Username cannot be empty.\")\n    if not self.password:\n        raise ValueError(\"Password cannot be empty.\")\n\n    return func(*args, **kwds)\n\nreturn new_def", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Check error responses to raise Exception.\"\"\"\n", "func_signal": "def _check_response(self, response):\n", "code": "if \"BADAUTH\" in response:\n    raise AuthenticationError(\"Invalid username or password\")\nelif \"BANNED\" in response:\n    raise AuthenticationError(\"You have been banned from this server\")\nelif \"BADTIME\" in response:\n    pass # ignore bad time error (will not use audioscrobbler)\nelif \"FAILED\" in response:\n    raise AuthenticationError(\"Authentication failed. Reason: \" + response[0])\nelif \"BADSESSION\" in response:\n    self._logged = False\n    raise AuthenticationError(\"Bad session error\")", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Function that is called everytime that the Player's Controller\nupdates it's length.\n\"\"\"\n", "func_signal": "def duration_updated(self, duration):\n", "code": "self._length = duration\n\nif duration < 30:\n    return\nelif duration > self.time_cons:\n    time = self.time_cons\nelse:\n    time = duration / 2\n\nself.create_timer(time, self._submit)", "path": "canola-jamendo\\audio_scrobbler.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Return url content in text.\n\n@parm url: url address.\n@parm params: dict of url parameters.\n\"\"\"\n", "func_signal": "def _request(self, _url, **params):\n", "code": "if params:\n    _url = _url + \"?\" + urlencode(params)\n\nlog.debug(\"requesting url: %s\" % str(_url))\nreturn urlopen(_url).read()", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Ban a last.fm track.\n\n@parm artist_name: artist name.\n@parm track_title: track title.\n@return: True if success and False otherwise.\n\"\"\"\n", "func_signal": "def ban_track(self, artist_name, track_title):\n", "code": "r = self._execute_rpc_method(self.proxy.banTrack,\n                             artist_name, track_title)\nreturn (r == \"OK\")", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Used as decorator to validate login.\"\"\"\n", "func_signal": "def check_login(func):\n", "code": "def new_def(*args, **kwds):\n    self = args[0]\n    if not self.logged:\n        self.login()\n    return func(*args, **kwds)\nreturn new_def", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Set a last.fm track as loved.\n\n@parm artist_name: artist name.\n@parm track_title: track title.\n@return: True if success and False otherwise.\n\"\"\"\n", "func_signal": "def love_track(self, artist_name, track_title):\n", "code": "r = self._execute_rpc_method(self.proxy.loveTrack,\n                             artist_name, track_title)\nreturn (r == \"OK\")", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Return url content in text lines.\n\n@parm url: url address.\n@parm params: dict of url parameters.\n\"\"\"\n", "func_signal": "def _request_lines(self, _url, **params):\n", "code": "if params:\n    _url = _url + \"?\" + urlencode(params)\n\nlog.debug(\"requesting url: %s\" % str(_url))\nlines = urlopen(_url).readlines()\nreturn [c.strip() for c in lines]", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Function that is called everytime that the Player's Controller\nchanges it's state to 'PLAYING'.\n\"\"\"\n", "func_signal": "def playing(self):\n", "code": "if self._timer_paused:\n    self.resume_timer()\n\nif self.start_time is None:\n    self.start_time = int(mktime(localtime()))\n    self._now_playing()", "path": "canola-jamendo\\audio_scrobbler.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Function that is called everytime that the Player's Controller\nchanges the model.\n\"\"\"\n", "func_signal": "def media_changed(self, model):\n", "code": "if self._timer is not None:\n    self._timer.delete()\n    self._timer_paused = False\n\nlog.warning(\"media changed to %s\" % model.title)\n\nself._model = model\nself._length = 0\nself.start_time = None", "path": "canola-jamendo\\audio_scrobbler.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Retrieve friends of a Jamendo user.\n\n@parm username: Jamendo username\n\"\"\"\n", "func_signal": "def get_friends(self, username):\n", "code": "url = \"%s/%s/friends.xml\" % (self.url_userfeed, username)\nxml = self._request(url)\n\nlst = []\ntree = ElementTree.fromstring(xml)\nfor child in tree.getchildren():\n    friend = Friend(to_utf8(child.get(\"username\")))\n    friend.url = child.find(\"url\").text\n    friend.image = child.find(\"image\").text\n    lst.append(friend)\n\nreturn lst", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "# try to login if user/pass are not empty\n", "func_signal": "def refresh():\n", "code": "if lastfm_manager.get_username() and lastfm_manager.get_password():\n    lastfm_manager.login()\nreturn lastfm_manager.is_logged()", "path": "canola-jamendo\\model.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Second last.fm handshake. Necessary if you want\nto get xspf tracks.\"\"\"\n", "func_signal": "def second_handshake(self):\n", "code": "token, timestamp = self.get_token_timestamp()\n\nret = self._request_lines(self.url_post_handshake,\n                          hs=\"true\", a=token, t=timestamp,\n                          u=self.username, p=self.protocol_version,\n                          c=self.client_name, v=self.client_version)\n\nif \"OK\" in ret:\n    self.post_session_id = ret[1]\n    self.now_url = ret[2]\n    self.post_url = ret[3]\nelse:\n    self.post_session_id = None\n    self._check_response(ret)", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Retrieve xspf tracks from last.fm.\"\"\"\n", "func_signal": "def get_xspf_tracks(self):\n", "code": "xml = self._request(self.url_radio_xspf,\n                    sk=self.session_id,\n                    desktop=0.1, discovery=0)\n\nlst = []\ntree = ElementTree.fromstring(xml)\ntracklist = tree.find(\"trackList\")\nfor child in tracklist.findall(\"track\"):\n    track = Track(to_utf8(child.find(\"title\").text),\n                  child.find(\"id\").text)\n\n    track.album = Album(to_utf8(child.find(\"album\").text or \"\"))\n    track.artist = Artist(to_utf8(child.find(\"creator\").text or \"\"))\n\n    track.url = child.find(\"location\").text\n    track.duration = int(child.find(\"duration\").text)\n    track.image = child.find(\"image\").text\n\n    lst.append(track)\n\nreturn lst", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Execute xml rpc method from last.fm server.\n\n@parm method: proxy method.\n@parm args: method arguments.\n\"\"\"\n", "func_signal": "def _execute_rpc_method(self, method, *args):\n", "code": "token, timestamp = self.get_token_timestamp()\nreturn method(self.username, str(timestamp), token, *args)", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Tune the stream_url to play the specified last.fm url.\n\nList of lastfm urls:\n    lastfm://user/$username/personal\n    lastfm://user/$username/playlist\n    lastfm://artist/$artistname\n    lastfm://artist/$artistname/similarartists\n    lastfm://globaltags/$tag\n    lastfm://group/$groupname\n    lastfm://user/$username/neighbours\n    lastfm://user/$username/recommended/100\n    lastfm://play/tracks/$trackid,$trackid,$trackid\n\"\"\"\n", "func_signal": "def tune(self, lastfm_url):\n", "code": "lines = self._request_lines(self.url_radio_adjust,\n                            url=lastfm_url, lang=\"en\",\n                            debug=0, session=self.session_id)\n\nparams = self.make_dict(lines)\nresponse = params.get('response', None)\n\nif response == 'OK':\n    self.user_url = params['url']\n    self.station_name = params['stationname']\n    self.discovery = params.get('discovery', 0)\nelif response:\n    raise TuningError(response)\nelse:\n    raise TuningError(\"Unknown error\")", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"First last.fm handshake.\"\"\"\n", "func_signal": "def handshake(self):\n", "code": "ret = self._request_lines(self.url_radio_handshake,\n                          platform=\"linux\",\n                          version=self.client_version,\n                          username=self.username,\n                          passwordmd5=md5(self.password).hexdigest())\n\nparams = self.make_dict(ret)\nif params['session'] == 'FAILED':\n    raise HandshakeError(params['msg'])\nelse:\n    self.session_id = params['session']\n    self.stream_url = params['stream_url']\n    self.base_url = params['base_url']\n    self.base_path = params['base_path']", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Return actual (token, timestamp).\"\"\"\n", "func_signal": "def get_token_timestamp(self):\n", "code": "passwordmd5 = md5(self.password).hexdigest()\ntimestamp = int(time.mktime(time.localtime()))\ntoken  = md5(\"%s%d\" % (passwordmd5, timestamp)).hexdigest()\nreturn (token, timestamp)", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Retrieve neighbours of a last.fm user.\n\n@parm username: last.fm username\n\"\"\"\n", "func_signal": "def get_neighbours(self, username):\n", "code": "url = \"%s/%s/neighbours.xml\" % (self.url_userfeed, username)\nxml = self._request(url)\n\nlst = []\ntree = ElementTree.fromstring(xml)\nfor child in tree.getchildren():\n    neighbour = Neighbour(to_utf8(child.get(\"username\")))\n    neighbour.url = child.find(\"url\").text\n    neighbour.image = child.find(\"image\").text\n    lst.append(neighbour)\n\nreturn lst", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"Complete login to last.fm.\nDo first and second handshake.\"\"\"\n", "func_signal": "def login(self):\n", "code": "try:\n    self.handshake()\n    self._logged = True\nexcept:\n    self._logged = False\n    raise", "path": "canola-jamendo\\client.py", "repo_name": "vincent/canola-jamendo", "stars": 2, "license": "other", "language": "python", "size": 148}
{"docstring": "\"\"\"\nGet guide data for the channel and date specified.\n\"\"\"\n# !TODO Error checking on channel id and date values.\n", "func_signal": "def getGuideData(self, chan_id, date):\n", "code": "guide = []\nsql = \"\"\"SELECT * FROM `program` WHERE (`chanid` = \"\"\" + chan_id + \"\"\") AND  ('\"\"\" + date + \"\"\" ' = DATE(`starttime`)) ORDER BY `starttime` ASC\"\"\"\n\nc = self.db.cursor()\nc.execute(sql)\nrow = c.fetchone()\nwhile row is not None:\n        guide.append(Guide(row))\n        row = c.fetchone()\nc.close()\nreturn guide", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nReturns a Program object for the current recorders recording.\n\"\"\"\n", "func_signal": "def getCurrentRecording(self, recorder):\n", "code": "res = self.backendCommand('QUERY_RECORDER %s[]:[]GET_CURRENT_RECORDING' % recorder)\nreturn Program(res.split(BACKEND_SEP))", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nReturns the system uptime in seconds. On error returns\nCould not determine uptime.\n\"\"\"\n", "func_signal": "def queryUptime(self):\n", "code": "mythtv = MythTV()\n# Time is returned in seconds or \"Could not determine uptime.\"\n# if not available.\nres = self.backendCommand('QUERY_UPTIME').split(BACKEND_SEP)\n\nreturn res", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nLoad the list of data into the object.\n\"\"\"\n", "func_signal": "def __init__(self, data):\n", "code": "self.cardid = data[0]\nself.cardtype = data[1]\nself.videodevice = data[2]\nself.hostname = data[3]", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nLoad data into the object.\n\"\"\"\n", "func_signal": "def __init__(self, data):\n", "code": "self.chanid = data[0]\nself.channum = data[1]\nself.freqid = data[2]\nself.sourceid = data[3]\nself.callsign = data[4]\nself.name = data[5]\nself.icon = data[6]\nself.finetune = data[7]\nself.videofilters = data[8]\nself.xmltvid = data[9]\nself.recpriority = data[10]\nself.contrast = data[11]\nself.brightness = data[12]\nself.colour = data[13]\nself.hue = data[14]\nself.tvformat = data[15]\nself.commfree = data[16]\nself.visible = data[17]\nself.outputfilters = data[18]\nself.useonairguide = data[19]\nself.mplexid = data[20]\nself.serviceid = data[21]\nself.atscsrcid = data[22]\nself.tmoffset = data[23]\nself.atsc_major_chan = data[24]\nself.atsc_minor_chan = data[25]\nself.last_record = data[26]\nself.default_authority = data[27]\nself.commethod = data[28]", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"Returns a list of recordings as program objects.\n   Passing   arg 'Delete' returns the items in \n   descending order based on start time.\n   Passing arg 'Recording' returns programs currently\n   being recorded\n   Passing arg 'Play' (or anything else): Returns all items.\n   Note the list includes live TV.\n\"\"\"\n", "func_signal": "def getRecordingList(self, arg):\n", "code": "mythtv = MythTV()\nprograms = []\nres = self.backendCommand('QUERY_RECORDINGS ' + arg).split(BACKEND_SEP)\nnum_progs = int(res.pop(0))\nlog.Msg(DEBUG, '%s recordings', num_progs)\nfor i in range(num_progs):\n        programs.append(Program(res[i * PROGRAM_FIELDS:(i * PROGRAM_FIELDS)\n                + PROGRAM_FIELDS]))\nreturn programs", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nReturns a list of channels defined in the database.\n\"\"\"\n", "func_signal": "def getChannels(self):\n", "code": "channels = []\nc = self.db.cursor()\nc.execute(\"\"\"SELECT * FROM channel\"\"\")\nrow = c.fetchone()\nwhile row is not None:\n        channels.append(Channel(row))\n        row = c.fetchone()\nc.close()\n\n\n\n#while row is not None:\n#       channels = Channel(row)\n#       row = c.fetchone()\n#c.close()\nreturn channels", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nSends a formatted command via a socket to the mythbackend.\n\nReturns the result from the backend.\n\"\"\"\n", "func_signal": "def backendCommand(self, data):\n", "code": "def recv():\n        \"\"\"\n        Reads the data returned from the backend.\n        \"\"\"\n        # The first 8 bytes of the response gives us the length\n        data = self.socket.recv(8)\n        try:\n                length = int(data)\n        except:\n                return ''\n        data = []\n        while length > 0:\n                chunk = self.socket.recv(length)\n                length = length - len(chunk)\n                data.append(chunk)\n        return ''.join(data)\n\ncommand = '%-8d%s' % (len(data), data)\nlog.Msg(DEBUG, 'Sending command: %s', command)\nself.socket.send(command)\nreturn recv()", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nLoad the list of data into the object.\n\"\"\"\n", "func_signal": "def __init__(self, data):\n", "code": "self.title = data[0]\nself.subtitle = data[1]\nself.description = data[2]\nself.category = data[3]\ntry:\n        self.chanid = int(data[4])\nexcept ValueError:\n        self.chanid = None\nself.channum = data[5] #chanstr\nself.callsign = data[6] #chansign\nself.channame = data[7]\nself.filename = data[8] #pathname\nself.fs_high = data[9]\nself.fs_low = data[10]\nself.starttime = datetime.fromtimestamp(int(data[11])) # startts\nself.endtime = datetime.fromtimestamp(int(data[12])) #endts\nself.duplicate = int(data[13])\nself.shareable = int(data[14])\nself.findid = int(data[15])\nself.hostname = data[16]\nself.sourceid = int(data[17])\nself.cardid = int(data[18])\nself.inputid = int(data[19])\nself.recpriority = int(data[20])\nself.recstatus = int(data[21])\nself.recordid = int(data[22])\nself.rectype = data[23]\nself.dupin = data[24]\nself.dupmethod = data[25]\nself.recstartts = datetime.fromtimestamp(int(data[26]))\nself.recendts = datetime.fromtimestamp(int(data[27]))\nself.repeat = int(data[28])\nself.programflags = data[29]\nself.recgroup = data[30]\nself.commfree = int(data[31])\nself.outputfilters = data[32]\nself.seriesid = data[33]\nself.programid = data[34]\nself.lastmodified = data[35]\nself.stars = float(data[36])\nself.airdate = data[37]\nself.hasairdate = int(data[38])\nself.playgroup = data[39]\nself.recpriority2 = int(data[40])\nself.parentid = data[41]\nself.storagegroup = data[42]\nself.audio_props = data[43]\nself.video_props = data[44]\nself.subtitle_type = data[45]", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nReturns the last date for which guide data is available.\nIf successful the date is returned in the form 2007-02-03 22:00.\nOn error 0000-00-00 00:00 is returned.\n\"\"\"\n", "func_signal": "def getGuideDataThrough(self):\n", "code": "mythtv = MythTV()\nres = self.backendCommand('QUERY_GUIDEDATATHROUGH').split(BACKEND_SEP)\n\nreturn res", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nReturns a list of free recorders, or an empty list if none.\n\"\"\"\n", "func_signal": "def getFreeRecorderList(self):\n", "code": "res = self.backendCommand('GET_FREE_RECORDER_LIST').split(BACKEND_SEP)\nrecorders = [int(d) for d in res]\nreturn recorders", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nReturns a list of all scheduled recordings as program objects.\n\"\"\"\n", "func_signal": "def getAllScheduledRecordings(self):\n", "code": "mythtv = MythTV()\nprograms = []\nres = self.backendCommand('QUERY_GETALLSCHEDULED').split(BACKEND_SEP)\nnum_progs = int(res.pop(0))\nlog.Msg(DEBUG, '%s recordings', num_progs)\nfor i in range(num_progs):\n        programs.append(Program(res[i * PROGRAM_FIELDS:(i * PROGRAM_FIELDS)\n                + PROGRAM_FIELDS]))\nreturn programs", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nLoad data into the object.\n\"\"\"\n", "func_signal": "def __init__(self, data):\n", "code": "self.chanid = data[0]\nself.starttime  = data[1]\nself.endtime  = data[2]\nself.title  = data[3]\nself.subtitle  = data[4]\nself.description  = data[5]\nself.category  = data[6]\nself.category_type  = data[7]\nself.airdate  = data[8]\nself.stars  = data[9]\nself.previouslyshown  = data[10]\nself.title_pronounce  = data[11]\nself.stereo  = data[12]\nself.subtitled  = data[13]\nself.hdtv  = data[14]\nself.closecaptioned  = data[15]\nself.partnumber  = data[16]\nself.parttotal  = data[17]\nself.seriesid  = data[18]\nself.originalairdate  = data[19]\nself.showtype  = data[20]\nself.colorcode  = data[21]\nself.syndicatedepisodenumber  = data[22]\nself.programid = data[23]\nself.manualid  = data[24]\nself.generic  = data[25]\nself.listingsource  = data[26]\nself.first  = data[27]\nself.last  = data[28]\nself.audioprop  = data[29]\nself.subtitletypes  = data[30]\nself.videoprop  = data[31]", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nReturns a list of Program objects which are scheduled to be recorded.\n\nSorts the list by recording start time and only returns those with\nrecord status of WillRecord.\n\"\"\"\n", "func_signal": "def getUpcomingRecordings(self):\n", "code": "def sort_programs_by_starttime(x, y):\n        if x.starttime > y.starttime:\n                return 1\n        elif x.starttime == y.starttime:\n                return 0\n        else:\n                return -1\nprograms = []\nres = self.getPendingRecordings()\nfor p in res:\n        if p.recstatus == RECSTATUS['WillRecord']:\n                programs.append(p)\nprograms.sort(sort_programs_by_starttime)\nreturn programs", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nReturns a Recorder object with details of the recorder.\n\"\"\"\n", "func_signal": "def getRecorderDetails(self, recorder_id):\n", "code": "c = self.db.cursor()\nc.execute(\"\"\"SELECT cardid, cardtype, videodevice, hostname\n                FROM capturecard WHERE cardid = %s\"\"\", recorder_id)\nrow = c.fetchone()\nif row:\n        recorder = Recorder(row)\n        return recorder\nelse:\n        return None", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nQueries the remote host for a specific setting. \nThe backend will look in the MySQL database table \n'settings', and attempt to return the value for the \ngiven setting. It seems only settings with the \nhostname set can be retrieved by this call.\n\nOn error returns -1.\n\"\"\"\n", "func_signal": "def getSetting(self, hostname, setting):\n", "code": "mythtv = MythTV()\nres = self.backendCommand('QUERY_SETTING ' + hostname + ' ' + setting).split(BACKEND_SEP)\n\nreturn res", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nReturns a list of Program objects which are scheduled to be recorded.\n\"\"\"\n", "func_signal": "def getPendingRecordings(self):\n", "code": "programs = []\nres = self.backendCommand('QUERY_GETALLPENDING').split(BACKEND_SEP)\nhas_conflict = int(res.pop(0))\nnum_progs = int(res.pop(0))\nlog.Msg(DEBUG, '%s pending recordings', num_progs)\nfor i in range(num_progs):\n        programs.append(Program(res[i * PROGRAM_FIELDS:(i * PROGRAM_FIELDS)\n                + PROGRAM_FIELDS]))\nreturn programs", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nReturns a boolean as to whether the given recorder is recording.\n\"\"\"\n", "func_signal": "def isRecording(self, recorder):\n", "code": "res = self.backendCommand('QUERY_RECORDER %s[]:[]IS_RECORDING' % recorder)\nif res == '1':\n        return True\nelse:\n        return False", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nReturns a list of Program objects which are scheduled to be recorded.\n\"\"\"\n", "func_signal": "def getScheduledRecordings(self):\n", "code": "programs = []\nres = self.backendCommand('QUERY_GETALLSCHEDULED').split(BACKEND_SEP)\nnum_progs = int(res.pop(0))\nlog.Msg(DEBUG, '%s scheduled recordings', num_progs)\nfor i in range(num_progs):\n        programs.append(Program(res[i * PROGRAM_FIELDS:(i * PROGRAM_FIELDS)\n                + PROGRAM_FIELDS]))\nreturn programs", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"\nReturns a list of recorders, or an empty list if none.\n\"\"\"\n", "func_signal": "def getRecorderList(self):\n", "code": "recorders = []\nc = self.db.cursor()\nc.execute('SELECT cardid FROM capturecard')\nrow = c.fetchone()\nwhile row is not None:\n        recorders.append(int(row[0]))\n        row = c.fetchone()\nc.close()\nreturn recorders", "path": "bindings\\build\\lib\\MythTV\\MythTV.py", "repo_name": "geekinthesticks/mythtv_conky_status", "stars": 3, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"Used in a call to re.sub to replace HTML, XML, and numeric\nentities with the appropriate Unicode characters. If HTML\nentities are being converted, any unrecognized entities are\nescaped.\"\"\"\n", "func_signal": "def _convertEntities(self, match):\n", "code": "x = match.group(1)\nif self.convertHTMLEntities and x in name2codepoint:\n    return unichr(name2codepoint[x])\nelif x in self.XML_ENTITIES_TO_SPECIAL_CHARS:\n    if self.convertXMLEntities:\n        return self.XML_ENTITIES_TO_SPECIAL_CHARS[x]\n    else:\n        return u'&%s;' % x\nelif len(x) > 0 and x[0] == '#':\n    # Handle numeric entities\n    if len(x) > 1 and x[1] == 'x':\n        return unichr(int(x[2:], 16))\n    else:\n        return unichr(int(x[1:]))\n\nelif self.escapeUnrecognizedEntities:\n    return u'&amp;%s;' % x\nelse:\n    return u'&%s;' % x", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Setting tag[key] sets the value of the 'key' attribute for the\ntag.\"\"\"\n", "func_signal": "def __setitem__(self, key, value):\n", "code": "self._getAttrMap()\nself.attrMap[key] = value\nfound = False\nfor i in range(0, len(self.attrs)):\n    if self.attrs[i][0] == key:\n        self.attrs[i] = (key, value)\n        found = True\nif not found:\n    self.attrs.append((key, value))\nself._getAttrMap()[key] = value", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Returns either the given Unicode string or its encoding.\"\"\"\n", "func_signal": "def sob(unicode, encoding):\n", "code": "if encoding is None:\n    return unicode\nelse:\n    return unicode.encode(encoding)", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Pops the tag stack up to and including the most recent\ninstance of the given tag. If inclusivePop is false, pops the tag\nstack up to but *not* including the most recent instqance of\nthe given tag.\"\"\"\n#print \"Popping to %s\" % name\n", "func_signal": "def _popToTag(self, name, inclusivePop=True):\n", "code": "if name == self.ROOT_TAG_NAME:\n    return\n\nnumPops = 0\nmostRecentTag = None\nfor i in range(len(self.tagStack)-1, 0, -1):\n    if name == self.tagStack[i].name:\n        numPops = len(self.tagStack)-i\n        break\nif not inclusivePop:\n    numPops = numPops - 1\n\nfor i in range(0, numPops):\n    mostRecentTag = self.popTag()\nreturn mostRecentTag", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "# Convert the document to Unicode.\n", "func_signal": "def _feed(self, inDocumentEncoding=None, isHTML=False):\n", "code": "markup = self.markup\nif isinstance(markup, unicode):\n    if not hasattr(self, 'originalEncoding'):\n        self.originalEncoding = None\nelse:\n    dammit = UnicodeDammit\\\n             (markup, [self.fromEncoding, inDocumentEncoding],\n              smartQuotesTo=self.smartQuotesTo, isHTML=isHTML)\n    markup = dammit.unicode\n    self.originalEncoding = dammit.originalEncoding\n    self.declaredHTMLEncoding = dammit.declaredHTMLEncoding\nif markup:\n    if self.markupMassage:\n        if not isList(self.markupMassage):\n            self.markupMassage = self.MARKUP_MASSAGE\n        for fix, m in self.markupMassage:\n            markup = fix.sub(m, markup)\n        # TODO: We get rid of markupMassage so that the\n        # soup object can be deepcopied later on. Some\n        # Python installations can't copy regexes. If anyone\n        # was relying on the existence of markupMassage, this\n        # might cause problems.\n        del(self.markupMassage)\nself.builder.reset()\n\nself.builder.feed(markup)\n# Close out any unfinished strings and close all the open tags.\nself.endData()\nwhile self.currentTag.name != self.ROOT_TAG_NAME:\n    self.popTag()", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Handle entity references as data, possibly converting known\nHTML and/or XML entity references to the corresponding Unicode\ncharacters.\"\"\"\n", "func_signal": "def handle_entityref(self, ref):\n", "code": "data = None\nif self.soup.convertHTMLEntities:\n    try:\n        data = unichr(name2codepoint[ref])\n    except KeyError:\n        pass\n\nif not data and self.soup.convertXMLEntities:\n        data = self.soup.XML_ENTITIES_TO_SPECIAL_CHARS.get(ref)\n\nif not data and self.soup.convertHTMLEntities and \\\n    not self.soup.XML_ENTITIES_TO_SPECIAL_CHARS.get(ref):\n        # TODO: We've got a problem here. We're told this is\n        # an entity reference, but it's not an XML entity\n        # reference or an HTML entity reference. Nonetheless,\n        # the logical thing to do is to pass it through as an\n        # unrecognized entity reference.\n        #\n        # Except: when the input is \"&carol;\" this function\n        # will be called with input \"carol\". When the input is\n        # \"AT&T\", this function will be called with input\n        # \"T\". We have no way of knowing whether a semicolon\n        # was present originally, so we don't know whether\n        # this is an unknown entity or just a misplaced\n        # ampersand.\n        #\n        # The more common case is a misplaced ampersand, so I\n        # escape the ampersand and omit the trailing semicolon.\n        data = \"&amp;%s\" % ref\nif not data:\n    # This case is different from the one above, because we\n    # haven't already gone through a supposedly comprehensive\n    # mapping of entities to Unicode characters. We might not\n    # have gone through any mapping at all. So the chances are\n    # very high that this is a real entity, and not a\n    # misplaced ampersand.\n    data = \"&%s;\" % ref\nself.handle_data(data)", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Convenience method that works with all 2.x versions of Python\nto determine whether or not something is stringlike.\"\"\"\n", "func_signal": "def isString(s):\n", "code": "try:\n    return isinstance(s, unicode) or isinstance(s, basestring)\nexcept NameError:\n    return isinstance(s, str)", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Handle a processing instruction as a ProcessingInstruction\nobject, possibly one with a %SOUP-ENCODING% slot into which an\nencoding will be plugged later.\"\"\"\n", "func_signal": "def handle_pi(self, text):\n", "code": "if text[:3] == \"xml\":\n    text = u\"xml version='1.0' encoding='%SOUP-ENCODING%'\"\nself._toStringSubclass(text, ProcessingInstruction)", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Returns the closest parent of this Tag that matches the given\ncriteria.\"\"\"\n# NOTE: We can't use _findOne because findParents takes a different\n# set of arguments.\n", "func_signal": "def findParent(self, name=None, attrs={}, **kwargs):\n", "code": "r = None\nl = self.findParents(name, attrs, 1)\nif l:\n    r = l[0]\nreturn r", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Given a document, tries to detect its XML encoding.\"\"\"\n", "func_signal": "def _detectEncoding(self, xml_data, isHTML=False):\n", "code": "xml_encoding = sniffed_xml_encoding = None\ntry:\n    if xml_data[:4] == '\\x4c\\x6f\\xa7\\x94':\n        # EBCDIC\n        xml_data = self._ebcdic_to_ascii(xml_data)\n    elif xml_data[:4] == '\\x00\\x3c\\x00\\x3f':\n        # UTF-16BE\n        sniffed_xml_encoding = 'utf-16be'\n        xml_data = unicode(xml_data, 'utf-16be').encode('utf-8')\n    elif (len(xml_data) >= 4) and (xml_data[:2] == '\\xfe\\xff') \\\n             and (xml_data[2:4] != '\\x00\\x00'):\n        # UTF-16BE with BOM\n        sniffed_xml_encoding = 'utf-16be'\n        xml_data = unicode(xml_data[2:], 'utf-16be').encode('utf-8')\n    elif xml_data[:4] == '\\x3c\\x00\\x3f\\x00':\n        # UTF-16LE\n        sniffed_xml_encoding = 'utf-16le'\n        xml_data = unicode(xml_data, 'utf-16le').encode('utf-8')\n    elif (len(xml_data) >= 4) and (xml_data[:2] == '\\xff\\xfe') and \\\n             (xml_data[2:4] != '\\x00\\x00'):\n        # UTF-16LE with BOM\n        sniffed_xml_encoding = 'utf-16le'\n        xml_data = unicode(xml_data[2:], 'utf-16le').encode('utf-8')\n    elif xml_data[:4] == '\\x00\\x00\\x00\\x3c':\n        # UTF-32BE\n        sniffed_xml_encoding = 'utf-32be'\n        xml_data = unicode(xml_data, 'utf-32be').encode('utf-8')\n    elif xml_data[:4] == '\\x3c\\x00\\x00\\x00':\n        # UTF-32LE\n        sniffed_xml_encoding = 'utf-32le'\n        xml_data = unicode(xml_data, 'utf-32le').encode('utf-8')\n    elif xml_data[:4] == '\\x00\\x00\\xfe\\xff':\n        # UTF-32BE with BOM\n        sniffed_xml_encoding = 'utf-32be'\n        xml_data = unicode(xml_data[4:], 'utf-32be').encode('utf-8')\n    elif xml_data[:4] == '\\xff\\xfe\\x00\\x00':\n        # UTF-32LE with BOM\n        sniffed_xml_encoding = 'utf-32le'\n        xml_data = unicode(xml_data[4:], 'utf-32le').encode('utf-8')\n    elif xml_data[:3] == '\\xef\\xbb\\xbf':\n        # UTF-8 with BOM\n        sniffed_xml_encoding = 'utf-8'\n        xml_data = unicode(xml_data[3:], 'utf-8').encode('utf-8')\n    else:\n        sniffed_xml_encoding = 'ascii'\n        pass\nexcept:\n    xml_encoding_match = None\nxml_encoding_re = '^<\\?.*encoding=[\\'\"](.*?)[\\'\"].*\\?>'.encode()\nxml_encoding_match = re.compile(xml_encoding_re).match(xml_data)\nif not xml_encoding_match and isHTML:\n    meta_re = '<\\s*meta[^>]+charset=([^>]*?)[;\\'\">]'.encode()\n    regexp = re.compile(meta_re, re.I)\n    xml_encoding_match = regexp.search(xml_data)\nif xml_encoding_match is not None:\n    xml_encoding = xml_encoding_match.groups()[0].decode(\n        'ascii').lower()\n    if isHTML:\n        self.declaredHTMLEncoding = xml_encoding\n    if sniffed_xml_encoding and \\\n       (xml_encoding in ('iso-10646-ucs-2', 'ucs-2', 'csunicode',\n                         'iso-10646-ucs-4', 'ucs-4', 'csucs4',\n                         'utf-16', 'utf-32', 'utf_16', 'utf_32',\n                         'utf16', 'u16')):\n        xml_encoding = sniffed_xml_encoding\nreturn xml_data, xml_encoding, sniffed_xml_encoding", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Changes a MS smart quote character to an XML or HTML\nentity.\"\"\"\n", "func_signal": "def _subMSChar(self, match):\n", "code": "orig = match.group(1)\nsub = self.MS_CHARS.get(orig)\nif type(sub) == types.TupleType:\n    if self.smartQuotesTo == 'xml':\n        sub = '&#x'.encode() + sub[1].encode() + ';'.encode()\n    else:\n        sub = '&'.encode() + sub[0].encode() + ';'.encode()\nelse:\n    sub = sub.encode()\nreturn sub", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Sets up the initial relations between this element and\nother elements.\"\"\"\n", "func_signal": "def setup(self, parent=None, previous=None):\n", "code": "self.parent = parent\nself.previous = previous\nself.next = None\nself.previousSibling = None\nself.nextSibling = None\nif self.parent and self.parent.contents:\n    self.previousSibling = self.parent.contents[-1]\n    self.previousSibling.nextSibling = self", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Beautiful Soup can detect a charset included in a META tag,\ntry to convert the document to that charset, and re-parse the\ndocument from the beginning.\"\"\"\n", "func_signal": "def extractCharsetFromMeta(self, attrs):\n", "code": "httpEquiv = None\ncontentType = None\ncontentTypeIndex = None\ntagNeedsEncodingSubstitution = False\n\nfor i in range(0, len(attrs)):\n    key, value = attrs[i]\n    key = key.lower()\n    if key == 'http-equiv':\n        httpEquiv = value\n    elif key == 'content':\n        contentType = value\n        contentTypeIndex = i\n\nif httpEquiv and contentType: # It's an interesting meta tag.\n    match = self.CHARSET_RE.search(contentType)\n    if match:\n        if (self.declaredHTMLEncoding is not None or\n            self.originalEncoding == self.fromEncoding):\n            # An HTML encoding was sniffed while converting\n            # the document to Unicode, or an HTML encoding was\n            # sniffed during a previous pass through the\n            # document, or an encoding was specified\n            # explicitly and it worked. Rewrite the meta tag.\n            def rewrite(match):\n                return match.group(1) + \"%SOUP-ENCODING%\"\n            newAttr = self.CHARSET_RE.sub(rewrite, contentType)\n            attrs[contentTypeIndex] = (attrs[contentTypeIndex][0],\n                                       newAttr)\n            tagNeedsEncodingSubstitution = True\n        else:\n            # This is our first pass through the document.\n            # Go through it again with the encoding information.\n            newCharset = match.group(3)\n            if newCharset and newCharset != self.originalEncoding:\n                self.declaredHTMLEncoding = newCharset\n                self._feed(self.declaredHTMLEncoding)\n                raise StopParsing\n            pass\ntag = self.unknown_starttag(\"meta\", attrs)\nif tag and tagNeedsEncodingSubstitution:\n    tag.containsSubstitutions = True", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Convenience method that works with all 2.x versions of Python\nto determine whether or not something is listlike.\"\"\"\n", "func_signal": "def isList(l):\n", "code": "return ((hasattr(l, '__iter__') and not isString(l))\n        or (type(l) in (types.ListType, types.TupleType)))", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "#print \"Matching %s against %s\" % (markup, matchAgainst)\n", "func_signal": "def _matches(self, markup, matchAgainst):\n", "code": "result = False\nif matchAgainst == True and type(matchAgainst) == types.BooleanType:\n    result = markup != None\nelif callable(matchAgainst):\n    result = matchAgainst(markup)\nelse:\n    #Custom match methods take the tag as an argument, but all\n    #other ways of matching match the tag name as a string.\n    if isinstance(markup, Tag):\n        markup = markup.name\n    if markup is not None and not isString(markup):\n        markup = unicode(markup)\n    #Now we know that chunk is either a string, or None.\n    if hasattr(matchAgainst, 'match'):\n        # It's a regexp object.\n        result = markup and matchAgainst.search(markup)\n    elif (isList(matchAgainst)\n          and (markup is not None or not isString(matchAgainst))):\n        result = markup in matchAgainst\n    elif hasattr(matchAgainst, 'items'):\n        result = markup.has_key(matchAgainst)\n    elif matchAgainst and isString(markup):\n        if isinstance(markup, unicode):\n            matchAgainst = unicode(matchAgainst)\n        else:\n            matchAgainst = str(matchAgainst)\n\n    if not result:\n        result = matchAgainst == markup\nreturn result", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Create a new NavigableString.\n\nWhen unpickling a NavigableString, this method is called with\nthe string in DEFAULT_OUTPUT_ENCODING. That encoding needs to be\npassed in to the superclass's __new__ or the superclass won't know\nhow to handle non-ASCII characters.\n\"\"\"\n", "func_signal": "def __new__(cls, value):\n", "code": "if isinstance(value, unicode):\n    return unicode.__new__(cls, value)\nreturn unicode.__new__(cls, value, DEFAULT_OUTPUT_ENCODING)", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "#print \"End tag %s\" % name\n", "func_signal": "def unknown_endtag(self, name):\n", "code": "if self.quoteStack and self.quoteStack[-1] != name:\n    #This is not a real end tag.\n    #print \"</%s> is not real!\" % name\n    self.handle_data('</%s>' % name)\n    return\nself.endData()\nself._popToTag(name)\nif self.quoteStack and self.quoteStack[-1] == name:\n    self.quoteStack.pop()\n    self.literal = (len(self.quoteStack) > 0)", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "#print \"Push\", tag.name\n", "func_signal": "def pushTag(self, tag):\n", "code": "if self.currentTag:\n    self.currentTag.contents.append(tag)\nself.tagStack.append(tag)\nself.currentTag = self.tagStack[-1]", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Returns the closest sibling to this Tag that matches the\ngiven criteria and appears after this Tag in the document.\"\"\"\n", "func_signal": "def findNextSibling(self, name=None, attrs={}, text=None, **kwargs):\n", "code": "return self._findOne(self.findNextSiblings, name, attrs, text,\n                     **kwargs)", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Recursively destroys the contents of this tree.\"\"\"\n", "func_signal": "def decompose(self):\n", "code": "contents = [i for i in self.contents]\nfor i in contents:\n    if isinstance(i, Tag):\n        i.decompose()\n    else:\n        i.extract()\nself.extract()", "path": "BeautifulSoup.py", "repo_name": "skyisle/gmp4ever", "stars": 2, "license": "None", "language": "python", "size": 112}
{"docstring": "\"\"\"Run command with arguments.  Wait for command to complete.  If\nthe exit code was zero then return, otherwise raise\nCalledProcessError.  The CalledProcessError object will have the\nreturn code in the returncode attribute.\n\nThe arguments are the same as for the Popen constructor.  Example:\n\ncheck_call([\"ls\", \"-l\"])\n\"\"\"\n", "func_signal": "def check_call(*popenargs, **kwargs):\n", "code": "retcode = call(*popenargs, **kwargs)\ncmd = kwargs.get(\"args\")\nif cmd is None:\n    cmd = popenargs[0]\nif retcode:\n    raise CalledProcessError(retcode, cmd)\nreturn retcode", "path": "certmaster\\sub_process.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"\"\ngets us our cert back from the certmaster.wait_for_cert() method\ntakes csr_file as path location and master_uri\nreturns Bool, str(cert), str(ca_cert)\n\"\"\"\n\n", "func_signal": "def submit_csr_to_master(csr_file, master_uri):\n", "code": "fo = open(csr_file)\ncsr = fo.read()\ns = xmlrpclib.ServerProxy(master_uri)\n\n# print \"DEBUG: waiting for cert\"\nreturn s.wait_for_cert(csr)", "path": "certmaster\\utils.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "# FIXME: I believe we can remove this function\n", "func_signal": "def nice_exception(etype, evalue, etb):\n", "code": "etype = str(etype)\nlefti = etype.index(\"'\") + 1\nrighti = etype.rindex(\"'\")\nnicetype = etype[lefti:righti]\nnicestack = string.join(traceback.format_list(traceback.extract_tb(etb)))\nreturn [ REMOTE_ERROR, nicetype, str(evalue), nicestack ]", "path": "certmaster\\utils.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"\nIdentify common network errors that mean we cannot connect to the server\n\"\"\"\n\n# This is a bit complicated by the fact that different versions of\n# M2Crypto & OpenSSL seem to return different error codes for the\n# same type of error\n", "func_signal": "def canIgnoreSSLError(e):\n", "code": "s = \"%s\" % e\nif e[0] == 104:     # Connection refused\n    return True\nelif e[0] == 111:   # Connection reset by peer\n    return True\nelif e[0] == 61:    # Connection refused\n    return True\nelif e[0] == 54:    # Connection reset by peer\n    return True\nelif s == \"no certificate returned\":\n    return True\nelif s == \"wrong version number\":\n    return True\nelif s == \"unexpected eof\":\n    return True\n\nreturn False", "path": "certmaster\\CommonErrors.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"Construct and return tupel with IO objects:\np2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite\n\"\"\"\n", "func_signal": "def _get_handles(self, stdin, stdout, stderr):\n", "code": "p2cread, p2cwrite = None, None\nc2pread, c2pwrite = None, None\nerrread, errwrite = None, None\n\nif stdin is None:\n    pass\nelif stdin == PIPE:\n    p2cread, p2cwrite = os.pipe()\nelif isinstance(stdin, int):\n    p2cread = stdin\nelse:\n    # Assuming file-like object\n    p2cread = stdin.fileno()\n\nif stdout is None:\n    pass\nelif stdout == PIPE:\n    c2pread, c2pwrite = os.pipe()\nelif isinstance(stdout, int):\n    c2pwrite = stdout\nelse:\n    # Assuming file-like object\n    c2pwrite = stdout.fileno()\n\nif stderr is None:\n    pass\nelif stderr == PIPE:\n    errread, errwrite = os.pipe()\nelif stderr == STDOUT:\n    errwrite = c2pwrite\nelif isinstance(stderr, int):\n    errwrite = stderr\nelse:\n    # Assuming file-like object\n    errwrite = stderr.fileno()\n\nreturn (p2cread, p2cwrite,\n        c2pread, c2pwrite,\n        errread, errwrite)", "path": "certmaster\\sub_process.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"\nThis is the other part of the shutdown() workaround.\nSince servers create new sockets, we have to infect\nthem with our magic. :)\n\"\"\"\n", "func_signal": "def accept(self):\n", "code": "c, a = self.__dict__[\"conn\"].accept()\nreturn (SSLConnection(c), a)", "path": "certmaster\\SSLConnection.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"Find and return absolut path to w9xpopen.exe\"\"\"\n", "func_signal": "def _find_w9xpopen(self):\n", "code": "w9xpopen = os.path.join(os.path.dirname(GetModuleFileName(0)),\n                        \"w9xpopen.exe\")\nif not os.path.exists(w9xpopen):\n    # Eeek - file-not-found - possibly an embedding\n    # situation - see if we can locate it in sys.exec_prefix\n    w9xpopen = os.path.join(os.path.dirname(sys.exec_prefix),\n                            \"w9xpopen.exe\")\n    if not os.path.exists(w9xpopen):\n        raise RuntimeError(\"Cannot locate w9xpopen.exe, which is \"\n                           \"needed for Popen to work with your \"\n                           \"shell or platform.\")\nreturn w9xpopen", "path": "certmaster\\sub_process.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "# FIXME: I believe we can remove this function\n", "func_signal": "def is_error(result):\n", "code": "if type(result) != list:\n    return False\nif len(result) == 0:\n    return False\nif result[0] == REMOTE_ERROR:\n    return True\nreturn False", "path": "certmaster\\utils.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"\nIdentify common network errors that mean we cannot connect to the server\n\"\"\"\n\n", "func_signal": "def canIgnoreSocketError(e):\n", "code": "try:\n    if e[0] == 111:     # Connection refused\n        return True\n    elif e[0] == 104:   # Connection reset by peer\n        return True\n    elif e[0] == 61:    # Connection refused\n        return True\nexcept IndexError:\n    return True\n\nreturn False", "path": "certmaster\\CommonErrors.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"Wait for child process to terminate.  Returns returncode\nattribute.\"\"\"\n", "func_signal": "def wait(self):\n", "code": "if self.returncode is None:\n    obj = WaitForSingleObject(self._handle, INFINITE)\n    self.returncode = GetExitCodeProcess(self._handle)\nreturn self.returncode", "path": "certmaster\\sub_process.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"\nWe need to use socket._fileobject Because SSL.Connection\ndoesn't have a 'dup'. Not exactly sure WHY this is, but\nthis is backed up by comments in socket.py and SSL/connection.c\n\nSince httplib.HTTPSResponse/HTTPConnection depend on the\nsocket being duplicated when they close it, we refcount the\nsocket object and don't actually close until its count is 0.\n\"\"\"\n", "func_signal": "def makefile(self, mode, bufsize):\n", "code": "self.__dict__[\"close_refcount\"] = self.__dict__[\"close_refcount\"] + 1\nreturn PlgFileObject(self, mode, bufsize)", "path": "certmaster\\SSLConnection.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"\nTranslate a sequence of arguments into a command line\nstring, using the same rules as the MS C runtime:\n\n1) Arguments are delimited by white space, which is either a\n   space or a tab.\n\n2) A string surrounded by double quotation marks is\n   interpreted as a single argument, regardless of white space\n   contained within.  A quoted string can be embedded in an\n   argument.\n\n3) A double quotation mark preceded by a backslash is\n   interpreted as a literal double quotation mark.\n\n4) Backslashes are interpreted literally, unless they\n   immediately precede a double quotation mark.\n\n5) If backslashes immediately precede a double quotation mark,\n   every pair of backslashes is interpreted as a literal\n   backslash.  If the number of backslashes is odd, the last\n   backslash escapes the next double quotation mark as\n   described in rule 3.\n\"\"\"\n\n# See\n# http://msdn.microsoft.com/library/en-us/vccelng/htm/progs_12.asp\n", "func_signal": "def list2cmdline(seq):\n", "code": "result = []\nneedquote = False\nfor arg in seq:\n    bs_buf = []\n\n    # Add a space to separate this argument from the others\n    if result:\n        result.append(' ')\n\n    needquote = (\" \" in arg) or (\"\\t\" in arg)\n    if needquote:\n        result.append('\"')\n\n    for c in arg:\n        if c == '\\\\':\n            # Don't know if we need to double yet.\n            bs_buf.append(c)\n        elif c == '\"':\n            # Double backspaces.\n            result.append('\\\\' * len(bs_buf)*2)\n            bs_buf = []\n            result.append('\\\\\"')\n        else:\n            # Normal char\n            if bs_buf:\n                result.extend(bs_buf)\n                bs_buf = []\n            result.append(c)\n\n    # Add remaining backspaces, if any.\n    if bs_buf:\n        result.extend(bs_buf)\n\n    if needquote:\n        result.extend(bs_buf)\n        result.append('\"')\n\nreturn ''.join(result)", "path": "certmaster\\sub_process.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"\nsocket._fileobject doesn't actually _close_ the socket,\nwhich we want it to do, so we have to override.\n\"\"\"\n", "func_signal": "def close(self):\n", "code": "try:\n    if self._sock:\n        self.flush()\n        self._sock.close()\nfinally:\n    self._sock = None", "path": "certmaster\\SSLConnection.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"Interact with process: Send data to stdin.  Read data from\nstdout and stderr, until end-of-file is reached.  Wait for\nprocess to terminate.  The optional input argument should be a\nstring to be sent to the child process, or None, if no data\nshould be sent to the child.\n\ncommunicate() returns a tuple (stdout, stderr).\"\"\"\n\n# Optimization: If we are only using one pipe, or no pipe at\n# all, using select() or threads is unnecessary.\n", "func_signal": "def communicate(self, input=None):\n", "code": "if [self.stdin, self.stdout, self.stderr].count(None) >= 2:\n    stdout = None\n    stderr = None\n    if self.stdin:\n        if input:\n            self.stdin.write(input)\n        self.stdin.close()\n    elif self.stdout:\n        stdout = self.stdout.read()\n    elif self.stderr:\n        stderr = self.stderr.read()\n    self.wait()\n    return (stdout, stderr)\n\nreturn self._communicate(input)", "path": "certmaster\\sub_process.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"Construct and return tupel with IO objects:\np2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite\n\"\"\"\n", "func_signal": "def _get_handles(self, stdin, stdout, stderr):\n", "code": "if stdin is None and stdout is None and stderr is None:\n    return (None, None, None, None, None, None)\n\np2cread, p2cwrite = None, None\nc2pread, c2pwrite = None, None\nerrread, errwrite = None, None\n\nif stdin is None:\n    p2cread = GetStdHandle(STD_INPUT_HANDLE)\nelif stdin == PIPE:\n    p2cread, p2cwrite = CreatePipe(None, 0)\n    # Detach and turn into fd\n    p2cwrite = p2cwrite.Detach()\n    p2cwrite = msvcrt.open_osfhandle(p2cwrite, 0)\nelif isinstance(stdin, int):\n    p2cread = msvcrt.get_osfhandle(stdin)\nelse:\n    # Assuming file-like object\n    p2cread = msvcrt.get_osfhandle(stdin.fileno())\np2cread = self._make_inheritable(p2cread)\n\nif stdout is None:\n    c2pwrite = GetStdHandle(STD_OUTPUT_HANDLE)\nelif stdout == PIPE:\n    c2pread, c2pwrite = CreatePipe(None, 0)\n    # Detach and turn into fd\n    c2pread = c2pread.Detach()\n    c2pread = msvcrt.open_osfhandle(c2pread, 0)\nelif isinstance(stdout, int):\n    c2pwrite = msvcrt.get_osfhandle(stdout)\nelse:\n    # Assuming file-like object\n    c2pwrite = msvcrt.get_osfhandle(stdout.fileno())\nc2pwrite = self._make_inheritable(c2pwrite)\n\nif stderr is None:\n    errwrite = GetStdHandle(STD_ERROR_HANDLE)\nelif stderr == PIPE:\n    errread, errwrite = CreatePipe(None, 0)\n    # Detach and turn into fd\n    errread = errread.Detach()\n    errread = msvcrt.open_osfhandle(errread, 0)\nelif stderr == STDOUT:\n    errwrite = c2pwrite\nelif isinstance(stderr, int):\n    errwrite = msvcrt.get_osfhandle(stderr)\nelse:\n    # Assuming file-like object\n    errwrite = msvcrt.get_osfhandle(stderr.fileno())\nerrwrite = self._make_inheritable(errwrite)\n\nreturn (p2cread, p2cwrite,\n        c2pread, c2pwrite,\n        errread, errwrite)", "path": "certmaster\\sub_process.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"Wait for child process to terminate.  Returns returncode\nattribute.\"\"\"\n", "func_signal": "def wait(self):\n", "code": "if self.returncode is None:\n    pid, sts = os.waitpid(self.pid, 0)\n    self._handle_exitstatus(sts)\nreturn self.returncode", "path": "certmaster\\sub_process.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"Check if child process has terminated.  Returns returncode\nattribute.\"\"\"\n", "func_signal": "def poll(self, _deadstate=None):\n", "code": "if self.returncode is None:\n    try:\n        pid, sts = os.waitpid(self.pid, os.WNOHANG)\n        if pid == self.pid:\n            self._handle_exitstatus(sts)\n    except os.error:\n        if _deadstate is not None:\n            self.returncode = _deadstate\nreturn self.returncode", "path": "certmaster\\sub_process.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"Check if child process has terminated.  Returns returncode\nattribute.\"\"\"\n", "func_signal": "def poll(self, _deadstate=None):\n", "code": "if self.returncode is None:\n    if WaitForSingleObject(self._handle, 0) == WAIT_OBJECT_0:\n        self.returncode = GetExitCodeProcess(self._handle)\nreturn self.returncode", "path": "certmaster\\sub_process.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"\nConnection is not yet a new-style class,\nso I'm making a proxy instead of subclassing.\n\"\"\"\n", "func_signal": "def __init__(self, conn):\n", "code": "self.__dict__[\"conn\"] = conn\nself.__dict__[\"close_refcount\"] = 0\nself.__dict__[\"closed\"] = False\nself.__dict__[\"timeout\"] = self.DEFAULT_TIMEOUT", "path": "certmaster\\SSLConnection.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"Return a duplicate of handle, which is inheritable\"\"\"\n", "func_signal": "def _make_inheritable(self, handle):\n", "code": "return DuplicateHandle(GetCurrentProcess(), handle,\n                       GetCurrentProcess(), 0, 1,\n                       DUPLICATE_SAME_ACCESS)", "path": "certmaster\\sub_process.py", "repo_name": "nabeken/certmaster", "stars": 3, "license": "gpl-2.0", "language": "python", "size": 884}
{"docstring": "\"\"\"Generate HTML files for website.\n\"\"\"\n", "func_signal": "def webhtml():\n", "code": "set_templates(options.website.templates)\nrun_sphinx('website')\nreturn", "path": "pavement.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Create a source distribution.\n\"\"\"\n# Copy the output file to the desktop\n", "func_signal": "def sdist():\n", "code": "dist_files = path('dist').glob('*.tar.gz')\ndest_dir = path(options.sdist.outdir).expanduser()\nfor f in dist_files:\n    f.move(dest_dir)\nreturn", "path": "pavement.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Generate the PDF book.\n\"\"\"\n", "func_signal": "def pdf():\n", "code": "set_templates(options.pdf.templates)\nrun_sphinx('pdf')\nlatex_dir = path(options.pdf.builddir) / 'latex'\nsh('cd %s; make' % latex_dir)\nreturn", "path": "pavement.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Kill the thread, returning when it has been shut down.\"\"\"\n", "func_signal": "def kill (self):\n", "code": "self.ready.acquire()\nself._kill=1\nself.ready.release()\nself.join()", "path": "examples\\gpython.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Build HTML documentation using Sphinx. This uses the following\noptions in a \"sphinx\" section of the options.\n\ndocroot\n  the root under which Sphinx will be working.\n  default: docs\nbuilddir\n  directory under the docroot where the resulting files are put.\n  default: build\nsourcedir\n  directory under the docroot for the source files\n  default: (empty string)\ndoctrees\n  the location of the cached doctrees\n  default: $builddir/doctrees\nconfdir\n  the location of the sphinx conf.py\n  default: $sourcedir\noutdir\n  the location of the generated output files\n  default: $builddir/$builder\nbuilder\n  the name of the sphinx builder to use\n  default: html\n\"\"\"\n", "func_signal": "def html():\n", "code": "set_templates(options.html.templates)\nrun_sphinx('html')\nreturn", "path": "pavement.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Execute waiting code.  Called every timeout period.\"\"\"\n", "func_signal": "def code_exec (self):\n", "code": "self.ready.acquire ()\nif self._kill: gtk.main_quit ()\nif self.new_cmd != None:  \n    self.ready.notify ()  \n    self.cmd = self.cmd + self.new_cmd\n    self.new_cmd = None\n    try:\n        code = codeop.compile_command (self.cmd[:-1]) \n        if code: \n            self.cmd = ''\n            exec (code, self.globs, self.locs)\n            self.completer.update (self.locs)\n    except Exception:\n        traceback.print_exc ()\n        self.cmd = ''  \n                            \nself.ready.release()\nreturn 1", "path": "examples\\gpython.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Remove sphinx output directories before building the HTML.\n\"\"\"\n", "func_signal": "def html_clean():\n", "code": "remake_directories(options.sphinx.doctrees, options.html.outdir)\ncall_task('html')\nreturn", "path": "pavement.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "# Create a new window\n", "func_signal": "def __init__(self):\n", "code": "self.window = gtk.Window(gtk.WINDOW_TOPLEVEL)\n\n# \u65b0\u7684\u51fd\u6578\u3002\u7528\u4f86\u8a2d\u5b9awindows \u7684title\n# \nself.window.set_title(\"Hello Buttons!\")\n\n# Here we just set a handler for delete_event that immediately\n# exits GTK.\nself.window.connect(\"delete_event\", self.delete_event)\n\n# Sets the border width of the window.\nself.window.set_border_width(10)\n\n# \u65b0\u5efa\u4e86\u4e00\u500bbox\u7528\u4f86\u7576\u6210\u5176\u4ed6widget\u7684\u5bb9\u5668\u3002\n# \u5728 \"packing section\"\u9084\u6703\u518d\u8a73\u8ff0\u3002\n# HBox\u57fa\u672c\u4e0a\u662f\u770b\u4e0d\u5230\u7684\uff0c\u5927\u591a\u662f\u7528\u4f86\u6392\u5217widget\nself.box1 = gtk.HBox(False, 0)\n\n# Put the box into the main window.\nself.window.add(self.box1)\n\n# Creates a new button with the label \"Button 1\".\nself.button1 = gtk.Button(\"Button 1\")\n\n# button1\u88ab\u6309\u4e0b\u7684\u6642\u5019\uff0c\u7a0b\u5f0f\u6703\u547c\u53ebcallback()\n# \u4e26\u50b3\u51fa \"button 1\"\nself.button1.connect(\"clicked\", self.callback, \"button 1\")\n\n# \u4e0a\u6b21\u7528add()\uff0c\u9019\u6b21\u6539\u7528pack_start()\n# \nself.box1.pack_start(self.button1, True, True, 0)\n\n# \u8a18\u5f97\u9019\u500b\u6b65\u9a5f\uff0c\u79c0\u51fa button1\n#\nself.button1.show()\n\n# Do these same steps again to create a second button\nself.button2 = gtk.Button(\"Button 2\")\n\n# Call the same callback method with a different argument,\n# passing a pointer to \"button 2\" instead.\nself.button2.connect(\"clicked\", self.callback, \"button 2\")\n\nself.box1.pack_start(self.button2, True, True, 0)\n\n# \u5728\u9019\u500b\u4f8b\u5b50\u4e2d\uff0cbutton\u7684\u9806\u5e8f\u4e0d\u91cd\u8981\uff0c\u6240\u4ee5\u96a8\u4fbf\n# \u4f46 box1,windows\u9084\u662f\u6700\u5f8c\u79c0\uff0c\u9019\u6a23\u6240\u6709widgets\u53ef\u4ee5\u4e00\u8d77\u986f\u793a \nself.button2.show()\nself.box1.show()\nself.window.show()", "path": "examples\\helloworld2.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "# Clean up the HTML\n", "func_signal": "def clean_blog_html(body):\n", "code": "import re\nimport sys\nfrom BeautifulSoup import BeautifulSoup\nfrom cStringIO import StringIO\n\n# The post body is passed to stdin.\nsoup = BeautifulSoup(body)\n\n# Remove the permalinks to each header since the blog does not have\n# the styles to hide them.\nlinks = soup.findAll('a', attrs={'class':\"headerlink\"})\n[l.extract() for l in links]\n\n# Get BeautifulSoup's version of the string\ns = soup.__str__(prettyPrint=False)\n\n# Remove extra newlines.  This depends on the fact that\n# code blocks are passed through pygments, which wraps each part of the line\n# in a span tag.\npattern = re.compile(r'([^s][^p][^a][^n]>)\\n$', re.DOTALL|re.IGNORECASE)\ns = ''.join(pattern.sub(r'\\1', l) for l in StringIO(s))\n\nreturn s", "path": "pavement.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "# Create a new window\n", "func_signal": "def __init__(self):\n", "code": "self.window = gtk.Window(gtk.WINDOW_TOPLEVEL)\n\n# Set the window title\nself.window.set_title(\"Table\")\n\n# Set a handler for delete_event that immediately\n# exits GTK.\nself.window.connect(\"delete_event\", self.delete_event)\n\n# Sets the border width of the window.\nself.window.set_border_width(20)\n\n# Create a 2x2 table\ntable = gtk.Table(2, 2, True)\n\n# Put the table in the main window\nself.window.add(table)\n\n# Create first button\nbutton = gtk.Button(\"button 1\")\n\n# When the button is clicked, we call the \"callback\" method\n# with a pointer to \"button 1\" as its argument\nbutton.connect(\"clicked\", self.callback, \"button 1\")\n\n\n# Insert button 1 into the upper left quadrant of the table\ntable.attach(button, 0, 1, 0, 1)\n\nbutton.show()\n\n# Create second button\n\nbutton = gtk.Button(\"button 2\")\n\n# When the button is clicked, we call the \"callback\" method\n# with a pointer to \"button 2\" as its argument\nbutton.connect(\"clicked\", self.callback, \"button 2\")\n# Insert button 2 into the upper right quadrant of the table\ntable.attach(button, 1, 2, 0, 1)\n\nbutton.show()\n\n# Create \"Quit\" button\nbutton = gtk.Button(\"Quit\")\n\n# When the button is clicked, we call the main_quit function\n# and the program exits\nbutton.connect(\"clicked\", lambda w: gtk.main_quit())\n\n# Insert the quit button into the both lower quadrants of the table\ntable.attach(button, 0, 2, 1, 2)\n\nbutton.show()\n\ntable.show()\nself.window.show()", "path": "examples\\table.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Rebuild and copy website files to the remote server.\n\"\"\"\n# Clean up\n", "func_signal": "def installwebsite():\n", "code": "remake_directories(options.pdf.builddir, options.website.builddir)\n# Rebuild\ncall_task('website')\n# Copy to the server\nos.environ['RSYNC_RSH'] = '/usr/bin/ssh'\nsrc_path = path(options.website.builddir) / 'html'\nsh('cd %s; rsync --archive --delete --verbose . %s:%s' % \n    (src_path, options.website.server, options.website.server_path))\nreturn", "path": "pavement.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"look up the options that determine where all of the files are.\"\"\"\n", "func_signal": "def _get_paths():\n", "code": "opts = options\n\ndocroot = path(opts.get('docroot', 'docs'))\nif not docroot.exists():\n    raise BuildFailure(\"Sphinx documentation root (%s) does not exist.\"\n                       % docroot)\n\nbuilddir = docroot / opts.get(\"builddir\", \".build\")\nbuilddir.mkdir()\n\nsrcdir = docroot / opts.get(\"sourcedir\", \"\")\nif not srcdir.exists():\n    raise BuildFailure(\"Sphinx source file dir (%s) does not exist\" \n                        % srcdir)\n\n# Where is the sphinx conf.py file?\nconfdir = path(opts.get('confdir', srcdir))\n\n# Where should output files be generated?\noutdir = opts.get('outdir', '')\nif outdir:\n    outdir = path(outdir)\nelse:\n    outdir = builddir / opts.get('builder', 'html')\noutdir.mkdir()\n\n# Where are doctrees cached?\ndoctrees = opts.get('doctrees', '')\nif not doctrees:\n    doctrees = builddir / \"doctrees\"\nelse:\n    doctrees = path(doctrees)\ndoctrees.mkdir()\n\nreturn Bunch(locals())", "path": "pavement.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Remove the directories and recreate them.\n\"\"\"\n", "func_signal": "def remake_directories(*dirnames):\n", "code": "for d in dirnames:\n    d = path(d)\n    if d.exists():\n        d.rmtree()\n    d.mkdir()\nreturn", "path": "pavement.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Generate the blog post body.\n\"\"\"\n# Add link to project home page at the end\n", "func_signal": "def gen_blog_post(index_file, blog_file):\n", "code": "body = index_file.text().strip()\noutput_body = clean_blog_html(body) + '''<p><a class=\"reference external\" href=\"http://www.doughellmann.com/PyMOTW/\">PyMOTW Home</a></p>'''\n\nblog_file.write_text(output_body)\nreturn", "path": "pavement.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Create local copy of website files.\n\"\"\"\n# Copy the PDF to the files to be copied to the directory to install\n", "func_signal": "def website():\n", "code": "pdf_file = path(options.pdf.builddir) / 'latex' / (PROJECT + '-' + VERSION + '.pdf')\npdf_file.copy(path(options.website.builddir) / 'html')\nreturn", "path": "pavement.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "# Create a new window\n", "func_signal": "def __init__(self):\n", "code": "self.window = gtk.Window(gtk.WINDOW_TOPLEVEL)\n\n# Set the window title\nself.window.set_title(\"Check Button\")\n\n# Set a handler for delete_event that immediately\n# exits GTK.\nself.window.connect(\"delete_event\", self.delete_event)\n\n# Sets the border width of the window.\nself.window.set_border_width(20)\n\n# Create a vertical box\nvbox = gtk.VBox(True, 2)\n\n# Put the vbox in the main window\nself.window.add(vbox)\n\n# Create first button\nbutton = gtk.CheckButton(\"check button 1\")\n\n# When the button is toggled, we call the \"callback\" method\n# with a pointer to \"button\" as its argument\nbutton.connect(\"toggled\", self.callback, \"check button 1\")\n\n\n# Insert button 1\nvbox.pack_start(button, True, True, 2)\n\nbutton.show()\n\n# Create second button\n\nbutton = gtk.CheckButton(\"check button 2\")\n\n# When the button is toggled, we call the \"callback\" method\n# with a pointer to \"button 2\" as its argument\nbutton.connect(\"toggled\", self.callback, \"check button 2\")\n# Insert button 2\nvbox.pack_start(button, True, True, 2)\n\nbutton.show()\n\n# Create \"Quit\" button\nbutton = gtk.Button(\"Quit\")\n\n# When the button is clicked, we call the mainquit function\n# and the program exits\nbutton.connect(\"clicked\", lambda wid: gtk.main_quit())\n\n# Insert the quit button\nvbox.pack_start(button, True, True, 2)\n\nbutton.show()\nvbox.show()\nself.window.show()", "path": "examples\\checkbutton.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Generate the blog post version of the HTML for the current module.\n\"\"\"\n# Clean and recreate output directory\n", "func_signal": "def blog():\n", "code": "remake_directories(options.blog.outdir)\noutdir = path(options.blog.outdir)\n\n# Generate html from sphinx\nrun_sphinx('blog')\n\nindex_file = outdir / 'index.html'\nblog_file = outdir / 'blog.html'\ndry(\"Write blog post body to %s\" % blog_file, \n    gen_blog_post, index_file=index_file, blog_file=blog_file)\n\nif 'EDITOR' in os.environ:\n    sh('$EDITOR %s' % blog_file)\nreturn", "path": "pavement.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Helper function to run sphinx with common options.\n\nPass the names of namespaces to be used in the search path\nfor options.\n\"\"\"\n", "func_signal": "def run_sphinx(*option_sets):\n", "code": "if 'sphinx' not in option_sets:\n    option_sets += ('sphinx',)\nkwds = dict(add_rest=False)\noptions.order(*option_sets, **kwds)\npaths = _get_paths()\nsphinxopts = ['', \n              '-b', options.get('builder', 'html'), \n              '-d', paths.doctrees, \n              '-c', paths.confdir,\n              paths.srcdir, paths.outdir]\ndry(\"sphinx-build %s\" % (\" \".join(sphinxopts),), sphinx.main, sphinxopts)\nreturn", "path": "pavement.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Import the latest version of the web page template from the source.\n\"\"\"\n", "func_signal": "def webtemplatebase():\n", "code": "dest = path(options.website.template_dest).expanduser()\nsrc = path(options.website.template_source).expanduser()\nif not dest.exists() or (src.mtime > dest.mtime):\n    src.copy(dest)\nreturn", "path": "pavement.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"Run a script in the context of the input_file's directory, \nreturn the text output formatted to be included as an rst\nliteral text block.\n\"\"\"\n", "func_signal": "def run_script(input_file, script_name, interpreter='python', include_prefix=True):\n", "code": "from paver.runtime import sh\nfrom paver.path import path\nrundir = path(input_file).dirname()\noutput_text = sh('cd %(rundir)s; %(interpreter)s %(script_name)s 2>&1' % vars(),\n                capture=True)\nif include_prefix:\n    response = '\\n::\\n\\n'\nelse:\n    response = ''\nresponse += '\\t$ %(interpreter)s %(script_name)s\\n\\t' % vars()\nresponse += '\\n\\t'.join(output_text.splitlines())\nwhile not response.endswith('\\n\\n'):\n    response += '\\n'\nreturn response", "path": "pavement.py", "repo_name": "MagicSword/pygtktutnote", "stars": 3, "license": "None", "language": "python", "size": 936}
{"docstring": "\"\"\"\nCheck that a file exists at the given location.\n\"\"\"\n", "func_signal": "def assert_file_exists (file_path):\n", "code": "assert (type (file_path) == type ('')), \\\n\t\"file path is type %s\" % type (file_path)\nassert (os.path.isfile (file_path)), \\\n\t\"file '%s' doesn't exist\" % file_path", "path": "relais\\dev\\rcheck.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nTest to see if a variable is in a list of allowed values.\n\nThis functions as a stricter version of `assert_val_equal`, in that it\ntests for 'is' instead of 'equal', and thus will avoid (say) any conversion\nproblems between ints andfloats.\n\nFor example::\n\n\t>>> val = 5\n\t>>> assert_val_is (val, [5])\n\t>>> assert_val_is (val, ['a', 4, 5])\n\t>>> assert_val_is (val, [5.0])\n\tTraceback (most recent call last):\n\t...\n\tAssertionError: found '5', expected one of '[5.0]'\n\n\n\"\"\"\n", "func_signal": "def assert_val_is (var, allowed_vals):\n", "code": "assert ([x for x in make_sequence (allowed_vals) if (x is var)]), \\\n\t\"found '%s', expected one of '%s'\" % (var, allowed_vals)", "path": "relais\\dev\\rcheck.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nTest to see if a variable falls within a pair of inclusive bounds.\n\nFor example::\n\n\t>>> val = 5\n\t>>> assert_in_bounds (val, 0, 10)\n\t>>> assert_in_bounds (val, 5, 10)\n\t>>> assert_in_bounds (val, 0, 5)\n\t>>> assert_in_bounds (val, 5, 5)\n\t>>> assert_in_bounds (val, 6, 10)\n\tTraceback (most recent call last):\n\t...\n\tAssertionError: '5' is less than lower bound '6'\n\t>>> assert_in_bounds (val, 0, 4)\n\tTraceback (most recent call last):\n\t...\n\tAssertionError: '5' is greater than upper bound '4'\n\n\"\"\"\n", "func_signal": "def assert_in_bounds (var, lower, upper):\n", "code": "assert (lower <= var), \"'%s' is less than lower bound '%s'\" % (var, lower)\nassert (var <= upper), \"'%s' is greater than upper bound '%s'\" % (var, upper)", "path": "relais\\dev\\rcheck.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nIf not a writable file-like object, open as a file path for writing.\n\"\"\"\n", "func_signal": "def make_writable_handle (dest, mode='w'):\n", "code": "if (not hasattr (dest, 'write')):\n\tassert_file_exists (dest)\n\tdest = open (dest, mode)\nreturn dest", "path": "relais\\dev\\io\\utils.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nWrite the buffer to the given file.\n\nThis is a convenience method, simply for brevity.\n\n:Params:\n\tbuf\n\t\tThe buffer or string to be written.\n\tpath\n\t\tThe path to the file.\n\tmode\n\t\tThe mode to use when opening and writing the file.\n\n\"\"\"\n## Preconditions:\n", "func_signal": "def string_to_file (buf, path, mode='w'):\n", "code": "assert ('r' not in mode)\n## Main:\nfhndl = open (path, mode)\nfhndl.write (buf)\nfhndl.close()", "path": "relais\\dev\\fileutils.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nDelete the contents of a directory, while leaving the directory itself.\n\nThis duplicates ``recursive_remove`` except that a directory - not a file -\nmust be supplied and the directory itself is left intact.\n\"\"\"\n## Preconditions:\n", "func_signal": "def recursive_clear (path):\n", "code": "assert (os.path.exists (path) and os.path.isdir (path))\n## Main:\ncontents = os.listdir (path)\nfor item in contents:\n\tnew_path = os.path.join (path, item)\n\trecursive_remove (new_path)", "path": "relais\\dev\\scratchfile.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nWrite data to a temporary file of the given name and return the path.\n\nAs several functions in ReportLab, BioPython and other modules require\nactual filepaths for initialisation and we are dealing with file objects or\ndata in memory, it becomes necessary to write the data down to disk\ntemporarily so it can be read back up.\n\nNote that if an exact filename is given, it will be created in a temporary\ndirectory for safety. See `make_tmp_dir`.\n\n:Parameters:\n\tdata_hndl\n\t\tAn open file or file-like object (with 'read()').\n\tfile_name\n\t\tThe name of the temporary file to be created. If not provided, one\n\t\twill be generated.\n\tfile_suffix\n\t\tIf no file name is provided, teh one generated will have this suffix.\n\n:Returns:\n\tThe path to the newly created file.\n\n\"\"\"\n# TODO: need file mode?\n## Preconditions:\n# can't have file name and suffix\n\n## Main:\n", "func_signal": "def write_handle_to_tmpfile (data_hndl, file_name=None, file_suffix=None):\n", "code": "if (file_name):\n\tfile_path = make_scratch_file (file_name)\nelif (file_suffix):\n\tfile_path = tempfile.mktemp (file_suffix)\nout_file = open (file_path, 'wb')\nout_file.write (data_hndl.read())\nout_file.close()\n## Postconditions & return:\nreturn file_path", "path": "relais\\dev\\scratchfile.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nExtract all the files in a given directory and return then in a dict.\n\n:Params:\n\tpath\n\t\tPath to the target directory.\n\tfilenames\n\t\tA list of files in the directory to extract. If none are provided,\n\t\tall files will be extracted.\n\tmode\n\t\tThe mode to read files with.\n\n:Returns:\n\tA dictionary of (file-name, file-contents)\n\n\"\"\"\n# TODO: allow filenames to be a selector func?\n## Preconditions:\n", "func_signal": "def hoover_dir (path, filenames=None, mode='rU'):\n", "code": "assert (os.path.exists (path))\nassert (os.path.isdir (path))\n## Main:\nif (filenames is None):\n\tfilenames = os.listdir (path)\nresults = {}\nfor f in filenames:\n\tfpath = os.path.join (path, f)\n\tassert (os.path.exists (fpath))\n\tif (os.path.isfile (fpath)):\n\t\tresults[f] = file_to_string (fpath, mode)\n## Return:\nreturn results", "path": "relais\\dev\\fileutils.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nReturn the extension of this file name or path.\n\n:Parameters:\n\tfpath\n\t\tFile name or path\n\tlower\n\t\tNormalise the extension to lower case.\n\t\t\n:Returns:\n\tThe file extension, without the seperator / do character.\n\t\n\"\"\"\n", "func_signal": "def ext_from_filepath (fpath, lower=True):\n", "code": "basename, ext = os.path.splitext (fpath)\nif ext.startswith (os.extsep):\n\text = ext[len (os.extsep):]\nif (lower):\n\text = ext.lower()\nreturn ext", "path": "relais\\dev\\fileutils.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nReturn the extension of a filename.\n\n:Parameters:\n\tfname\n\t\tA file name or path.\n\tlower\n\t\tShould the derived extension be given as lowercase?\n\n\"\"\"\n", "func_signal": "def get_format (self, fmt, lower=True):\n", "code": "if (fmt is not None):\n\tif (lower):\n\t\tfmt = fmt.lower()\n\treturn fmt\nelse:\n\t# TODO: place with utilities?\n\tfname = getattr (self.hndl, 'name', None)\n\tif (fname is None):\n\t\treturn None\n\treturn fileutils.ext_from_filepath (fname, lower)", "path": "relais\\dev\\io\\baseio.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nNote this may generate an error if the object is disposed of unnaturally.\n\"\"\"\n", "func_signal": "def __del__ (self):\n", "code": "try:\n\tif (self.hndl_opened):\n\t\tself.hndl.close()\nexcept:\n\tpass", "path": "relais\\dev\\io\\baseio.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nCreate a temporary directory and return it's path.\n\nThis is intended for when you are using the temporary directory to create\ncreate files with fixed names, and you want to avoid the possibility of\ncolliding with other files or processes. The solution is to create a\ntemporary directory and do all your work in there.\n\n\"\"\"\n# TODO: a 'temporary workspace' class that cleans up after itself?\n# See TemporaryFile in tempfile\n# TODO: allow the designation of a scratch area?\n## Main:\n", "func_signal": "def make_scratch_dir ():\n", "code": "tmp_path = tempfile.mktemp()\nos.mkdir (tmp_path)\n## Postconditions & return:\nassert (os.path.exists (tmp_path)), \"can't create temporary directory\"\nreturn tmp_path", "path": "relais\\dev\\scratchfile.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nTest to see if a variable is of a set of allowed types.\n\nFor example::\n\n\t>>> val = 5\n\t>>> from types import IntType, StringType, FloatType\n\t>>> assert_type (val, [IntType])\n\t>>> assert_type (val, [StringType, IntType, FloatType])\n\t>>> assert_type (val, [StringType, FloatType])\n\tTraceback (most recent call last):\n\t...\n\tAssertionError: found '5' of type '<type 'int'>', expected one of [<type 'str'>, <type 'float'>]\n\n\"\"\"\n", "func_signal": "def assert_type (var, allowed_types):\n", "code": "assert (type (var) in make_sequence (allowed_types)), \\\n\t\"found '%s' of type '%s', expected one of %s\" % (var, type (var),\n\tallowed_types)", "path": "relais\\dev\\rcheck.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nIssue a warning that the calling code is deprecated.\n\"\"\"\n", "func_signal": "def warn_deprecated (msg='deprecated'):\n", "code": "called_from = debug.get_call_locn_str (-3)\nwarnings.warn (\"%s %s\" % (called_from, msg), DeprecationWarning)", "path": "relais\\dev\\rcheck.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nIssue a warning that the calling code is deprecated.\n\"\"\"\n", "func_signal": "def runtime_warning (msg):\n", "code": "called_from = debug.get_call_locn_str (-3)\nwarnings.warn (\"%s %s\" % (called_from, msg), RuntimeWarning)", "path": "relais\\dev\\rcheck.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nGiven a path, delete that file or folder and any contents.\n\nUse with care. This essentially duplicates ``rm -r``, deleting a non-empty\ndirectory. It largely duplicates certain standard library functions\n(except for being able to acccept a file) and is here for completeness\n(match with ``recursive_clear``) and because of historical reasons.\n\n:Parameters:\n\tpath\n\t\tPath to the file or directory to be removed.\n\n\"\"\"\n# TODO: there *must* be a standard function for this. os.removedirs()?\n## Preconditions:\n", "func_signal": "def recursive_remove (path):\n", "code": "assert (os.path.exists (path))\n## Main:\nif os.path.isfile (path):\n\tos.remove (path)\nelif os.path.isdir (path):\n\tshutil.rmtree (path)", "path": "relais\\dev\\scratchfile.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nClass c'tor.\n\n:Parameters:\n\thndl\n\t\tThe output (or input) for the object, being a file path or an open\n\t\tand writable (or readable) file-like object.\n\tmode\n\t\tWhat mode to open any file path as, if necessary. If an open\n\t\tfile-like is supplied, obviously this won't be used. By default,\n\t\tit is set to 'rb', the least destructive option. Derived classes\n\t\tshould obviously override this.\n\tfmt : string\n\t\tThe file format. This is case-insensitive and if not given is\n\t\tderived from the handles ``name`` attribute. Obviously, it's\n\t\tan error if the handle has no name.\n\tdialect : dict or Options\n\t\tA set of properties for IO behaviour.\n\nNote that if an open handle is passed to the reader it will not close\nit, but if it has to open a handle, it will close it.\n\n\"\"\"\n## Preconditions & preparations:\n#\u00a0if file is a filename\n", "func_signal": "def __init__ (self, hndl, mode='rb', fmt=None, dialect=None):\n", "code": "if (isinstance (hndl, basestring)):\n\thndl = open (hndl, mode)\n\thndl_opened = True\nelse:\n\thndl_opened = False\nself.hndl = hndl\nself.hndl_opened = hndl_opened\n# determine & normalise format if need be\nself.fmt = self.get_format (fmt)\n# set dialect\nif (self.dialect is None):\n\tself.dialect = options.Options()\nif (dialect):\n\tself.dialect.update (dialect)", "path": "relais\\dev\\io\\baseio.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nIf this object is not a sequence, make it one.\n\nThis is used for functions that can accept a single instance or sequence of\nobject, converting instances to a list of one. It's called 'make_sequence'\nrather than 'make_list' because tuples pass through unchanged.\n\n\"\"\"\n# NOTE: we make a list by enclosing it in square braces. If you were to\n# use the function `list()`, it would convert a string into a list of \n# characters, e.g. ['f', 'o', 'o']\n", "func_signal": "def make_sequence (obj):\n", "code": "if (is_sequence (obj)):\n\treturn obj\nelse:\n\treturn [obj]", "path": "relais\\dev\\rcheck.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nRaises an assertion when you get somewhere you shouldn't have.\n\nOften, it is useful to bug-proof a section of code with an automatic\nassertion failure. This occurs most commonly when selecting from a series\nof limited choices and checking for impossible choices::\n\n\tonetothree = ...\n\tif (onetothree == 1):\n\t\tdo_one()\n\telif (onetothree == 2):\n\t\tdo_two()\n\telif (onetothree == 3):\n\t\tdo_two()\n\telse:\n\t\tfailure (\"must be from one to three not %s\" % onetothree)\n\t\t\nThus ``failure`` just provides a simple and readable shorthand for throwing\nan assert.\n\t\n\"\"\"\n", "func_signal": "def failure (msg=None):\n", "code": "final_msg = \"shouldn't get here\"\nif (msg):\n\tfinal_msg += ': ' + msg\nassert (False), final_msg", "path": "relais\\dev\\rcheck.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "\"\"\"\nTest to see if a variable (or variables) is in a set of allowed values.\n\n\"\"\"\n", "func_signal": "def assert_vals_in (var, allowed_vals):\n", "code": "var = make_sequence (var)\nallowed_vals = make_sequence (allowed_vals)\nfor v in var:\n\tassert (v in allowed_vals), \"'%s' not in '%s'\" % (v, allowed_vals)", "path": "relais\\dev\\rcheck.py", "repo_name": "agapow/relais.dev", "stars": 2, "license": "None", "language": "python", "size": 136}
{"docstring": "'''Returns a human-readable string from word\nReturns a human-readable string from word, by replacing\nunderscores with a space, and by upper-casing the initial\ncharacter by default.\nIf you need to uppercase all the words you just have to\npass 'all' as a second parameter.'''\n\n", "func_signal": "def humanize(self, word, uppercase = '') :\n", "code": "if(uppercase == 'first'):\n    return re.sub('_id$', '', word).replace('_',' ').capitalize()\nelse :\n    return re.sub('_id$', '', word).replace('_',' ').title()", "path": "graphstore\\inflector\\Rules\\Base.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "# these only test id's being set in idfromname (called in set())\n", "func_signal": "def testIdCache(self):\n", "code": "g = Graph(':memory:')\ng.set('apple','color','red')\ndel g.cursor # because it shouldn't need to query the db\nself.assertEquals(g.id_cache,{'apple':1,'color':2,'red':3})\nself.assertEquals(g.idfromname('Apple'),1)", "path": "graphstore\\tests.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "'''Singularizes Spanish nouns.'''\n\n", "func_signal": "def singularize (self, word) :\n", "code": "rules = [\n    ['(?i)^([bcdfghjklmnpqrstvwxyz]*)([aeiou])([ns])es$', '\\\\1\\\\2\\\\3'],\n    ['(?i)([aeiou])([ns])es$',  '~1\\\\2'],\n    ['(?i)oides$',  'oide'], # androides->androide\n    ['(?i)(ces)$/i', 'z'],\n    ['(?i)(sis|tis|xis)+$',  '\\\\1'], # crisis, apendicitis, praxis\n    ['(?i)()s$',  '\\\\1'], # bebs->beb\n    ['(?i)([^e])s$',  '\\\\1'], # casas->casa\n    ['(?i)([bcdfghjklmnprstvwxyz]{2,}e)s$', '\\\\1'], # cofres->cofre\n    ['(?i)([ghpv]e)s$', '\\\\1'], # 24-01 llaves->llave\n    ['(?i)es$', ''] # ELSE remove _es_  monitores->monitor\n];\n    \nuncountable_words = ['paraguas','tijeras', 'gafas', 'vacaciones', 'vveres','lunes','martes','mircoles','jueves','viernes','cumpleaos','virus','atlas','sms']\n\nirregular_words = {\n    'jersey':'jersis',\n    'espcimen':'especmenes',\n    'carcter':'caracteres',\n    'rgimen':'regmenes',\n    'men':'mens',\n    'rgimen':'regmenes',\n    'curriculum' : 'currculos',\n    'ultimtum' : 'ultimatos',\n    'memorndum' : 'memorandos',\n    'referndum' : 'referendos',\n    'sndwich' : 'sndwiches'\n}\n    \nlower_cased_word = word.lower();\n    \nfor uncountable_word in uncountable_words:\n    if lower_cased_word[-1*len(uncountable_word):] == uncountable_word :\n        return word\n    \nfor irregular in irregular_words.keys():\n    match = re.search('('+irregular+')$',word, re.IGNORECASE)\n    if match:\n        return re.sub('(?i)'+irregular+'$', match.expand('\\\\1')[0]+irregular_words[irregular][1:], word)\n    \nfor rule in range(len(rules)):\n    match = re.search(rules[rule][0], word, re.IGNORECASE)\n    if match :\n        groups = match.groups()\n        replacement = rules[rule][1]\n        if re.match('~', replacement) :\n            for k in range(1, len(groups)) :\n                replacement = replacement.replace('~'+str(k), self.string_replace(groups[k-1], 'AEIOUaeiou', ''))\n        \n        result = re.sub(rules[rule][0], replacement, word)\n        # Esta es una posible solucin para el problema de dobles acentos. Un poco guarrillo pero funciona\n        match = re.search('(?i)([]).*([])',result)\n        \n        if match and len(match.groups()) > 1 and not re.search('(?i)[]', word) :\n            result = self.string_replace(result, '', 'AEIOUaeiou')\n        \n        return result\n\nreturn word", "path": "graphstore\\inflector\\Rules\\Spanish.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "'''Converts number to its ordinal English form.\nThis method converts 13 to 13th, 2 to 2nd ...'''\n", "func_signal": "def ordinalize(self, number) :\n", "code": "tail = 'th'\nif number % 100 == 11 or number % 100 == 12 or number % 100 == 13:\n    tail = 'th'\nelif number % 10 == 1 :\n    tail = 'st'\nelif number % 10 == 2 :\n    tail = 'nd'\nelif number % 10 == 3 :\n    tail = 'rd'\n\nreturn str(number)+tail", "path": "graphstore\\inflector\\Rules\\Base.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "# TODO: multiple attrs, asc/desc\n", "func_signal": "def select(self, criteria=None, sections=['metadata'], orderby=None):\n", "code": "data = []\nfor page in self.list(criteria):\n  pagedata = {'name': page}\n  if 'metadata' in sections: pagedata['metadata'] = self.get(page)\n  if 'description' in sections: pagedata['description'] = self.describe(page)\n  if 'backlinks' in sections: pagedata['backlinks'] = self.backlinks(page)\n  data.append(pagedata)\nif orderby is not None:\n  return sorted(data,key=lambda a: a['metadata'][orderby])\nelse:\n  return data", "path": "graphstore\\graph.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "'''Singularizes English nouns.'''\n\n", "func_signal": "def singularize (self, word) :\n", "code": "rules = [\n    ['(?i)(quiz)zes$' , '\\\\1'],\n    ['(?i)(matr)ices$' , '\\\\1ix'],\n    ['(?i)(vert|ind)ices$' , '\\\\1ex'],\n    ['(?i)^(ox)en' , '\\\\1'],\n    ['(?i)(alias|status)es$' , '\\\\1'],\n    ['(?i)([octop|vir])i$' , '\\\\1us'],\n    ['(?i)(cris|ax|test)es$' , '\\\\1is'],\n    ['(?i)(shoe)s$' , '\\\\1'],\n    ['(?i)(o)es$' , '\\\\1'],\n    ['(?i)(bus)es$' , '\\\\1'],\n    ['(?i)([m|l])ice$' , '\\\\1ouse'],\n    ['(?i)(x|ch|ss|sh)es$' , '\\\\1'],\n    ['(?i)(m)ovies$' , '\\\\1ovie'],\n    ['(?i)(s)eries$' , '\\\\1eries'],\n    ['(?i)([^aeiouy]|qu)ies$' , '\\\\1y'],\n    ['(?i)([lr])ves$' , '\\\\1f'],\n    ['(?i)(tive)s$' , '\\\\1'],\n    ['(?i)(hive)s$' , '\\\\1'],\n    ['(?i)([^f])ves$' , '\\\\1fe'],\n    ['(?i)(^analy)ses$' , '\\\\1sis'],\n    ['(?i)((a)naly|(b)a|(d)iagno|(p)arenthe|(p)rogno|(s)ynop|(t)he)ses$' , '\\\\1\\\\2sis'],\n    ['(?i)([ti])a$' , '\\\\1um'],\n    ['(?i)(n)ews$' , '\\\\1ews'],\n    ['(?i)s$' , ''],\n];\n    \nuncountable_words = ['equipment', 'information', 'rice', 'money', 'species', 'series', 'fish', 'sheep','sms'];\n    \nirregular_words = {\n    'people' : 'person',\n    'men' : 'man',\n    'children' : 'child',\n    'sexes' : 'sex',\n    'moves' : 'move'\n}\n    \nlower_cased_word = word.lower();\n    \nfor uncountable_word in uncountable_words:\n    if lower_cased_word[-1*len(uncountable_word):] == uncountable_word :\n        return word\n    \nfor irregular in irregular_words.keys():\n    match = re.search('('+irregular+')$',word, re.IGNORECASE)\n    if match:\n        return re.sub('(?i)'+irregular+'$', match.expand('\\\\1')[0]+irregular_words[irregular][1:], word)\n    \n\nfor rule in range(len(rules)):\n    match = re.search(rules[rule][0], word, re.IGNORECASE)\n    if match :\n        groups = match.groups()\n        for k in range(0,len(groups)) :\n            if groups[k] == None :\n                rules[rule][1] = rules[rule][1].replace('\\\\'+str(k+1), '')\n                \n        return re.sub(rules[rule][0], rules[rule][1], word)\n\nreturn word", "path": "graphstore\\inflector\\Rules\\English.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "'''Same as camelize but first char is lowercased\nConverts a word like \"send_email\" to \"sendEmail\". It\nwill remove non alphanumeric character from the word, so\n\"who's online\" will be converted to \"whoSOnline\"'''\n", "func_signal": "def variablize(self, word) :\n", "code": "word = self.camelize(word)\nreturn word[0].lower()+word[1:]", "path": "graphstore\\inflector\\Rules\\Base.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "\"\"\"main api.\"\"\"\n", "func_signal": "def index(self, criteria=None, sections='metadata|description', format='html'):\n", "code": "graph = cherrypy.thread_data.graph\ntry:\n  sections = sections.split('|')\n  pages = graph.select(criteria,sections=sections)\n  for page in pages: page['url'] = helpers.pageurl(page['name'])\nexcept NonexistentPageError:\n  pages = []\nexcept NoMatchingComparisonOperatorError:\n  pages = []\nreturn render('index',format,pages=pages,criteria=criteria)", "path": "controller.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "\"\"\"redirect the browser to url\"\"\"\n", "func_signal": "def redirect(url):\n", "code": "cherrypy.response.status = 302\ncherrypy.response.headers['Location'] = cherrypy.url(url)", "path": "framework.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "\"\"\"capitalized properly\"\"\"\n", "func_signal": "def normalize_name(self, name):\n", "code": "result = self.query('SELECT name FROM pages WHERE name LIKE ?',(name,)).fetchone()\nif result is not None:\n  return result[0]\nelse:\n  raise NonexistentPageError(name)", "path": "graphstore\\graph.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "'''Pluralizes Spanish nouns.'''\n", "func_signal": "def pluralize(self, word) :\n", "code": "rules = [\n    ['(?i)([aeiou])x$', '\\\\1x'], # This could fail if the word is oxytone.\n    ['(?i)([])([ns])$', '|1\\\\2es'],\n    ['(?i)(^[bcdfghjklmnpqrstvwxyz]*)an$', '\\\\1anes'], # clan->clanes\n    ['(?i)([])s$', '|1ses'],\n    ['(?i)(^[bcdfghjklmnpqrstvwxyz]*)([aeiou])([ns])$', '\\\\1\\\\2\\\\3es'], # tren->trenes\n    ['(?i)([aeiou])$', '\\\\1s'], # casa->casas, padre->padres, pap->paps\n    ['(?i)([aeiou])s$', '\\\\1s'], # atlas->atlas, virus->virus, etc.\n    ['(?i)([])(s)$', '|1\\\\2es'], # ingls->ingleses\n    ['(?i)z$', 'ces'],  # luz->luces\n    ['(?i)([])$', '\\\\1es'], # ceut->ceutes, tab->tabes\n    ['(?i)(ng|[wckgtp])$', '\\\\1s'], # Anglicismos como puenting, frac, crack, show (En que casos podra fallar esto?)\n    ['(?i)$', 'es']\t# ELSE +es (v.g. rbol->rboles)\n]\n\nuncountable_words = ['tijeras','gafas', 'vacaciones','vveres','dficit']\n''' In fact these words have no singular form: you cannot say neither\n\"una gafa\" nor \"un vvere\". So we should change the variable name to\nonlyplural or something alike.'''\n\nirregular_words = {\n    'pas' : 'pases',\n    'champ' : 'champs',\n    'jersey' : 'jersis',\n    'carcter' : 'caracteres',\n    'espcimen' : 'especmenes',\n    'men' : 'mens',\n    'rgimen' : 'regmenes',\n    'curriculum'  :  'currculos',\n    'ultimtum'  :  'ultimatos',\n    'memorndum'  :  'memorandos',\n    'referndum'  :  'referendos'\n}\n\nlower_cased_word = word.lower();\n\nfor uncountable_word in uncountable_words:\n    if lower_cased_word[-1*len(uncountable_word):] == uncountable_word :\n        return word\n\nfor irregular in irregular_words.keys():\n    match = re.search('(?i)('+irregular+')$',word, re.IGNORECASE)\n    if match:\n        return re.sub('(?i)'+irregular+'$', match.expand('\\\\1')[0]+irregular_words[irregular][1:], word)\n\n\nfor rule in range(len(rules)):\n    match = re.search(rules[rule][0], word, re.IGNORECASE)\n    \n    if match :\n        groups = match.groups()\n        replacement = rules[rule][1]\n        if re.match('\\|', replacement) :\n            for k in range(1, len(groups)) :\n                replacement = replacement.replace('|'+str(k), self.string_replace(groups[k-1], '', 'AEIOUaeiou'))\n        \n        result = re.sub(rules[rule][0], replacement, word)\n        # Esto acentua los sustantivos que al pluralizarse se convierten en esdrjulos como esmquines, jvenes...\n        match = re.search('(?i)([aeiou]).{1,3}([aeiou])nes$',result)\n        \n        if match and len(match.groups()) > 1 and not re.search('(?i)[]', word) :\n            result = result.replace(match.group(0), self.string_replace(match.group(1), 'AEIOUaeiou', '') + match.group(0)[1:])\n            \n        return result\n\nreturn word", "path": "graphstore\\inflector\\Rules\\Spanish.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "''' Converts a word \"into_it_s_underscored_version\"\nConvert any \"CamelCased\" or \"ordinary Word\" into an\n\"underscored_word\".\nThis can be really useful for creating friendly URLs.'''\n\n", "func_signal": "def underscore(self, word) :\n", "code": "return  re.sub('[^A-Z^a-z^0-9^\\/]+','_', \\\n        re.sub('([a-z\\d])([A-Z])','\\\\1_\\\\2', \\\n        re.sub('([A-Z]+)([A-Z][a-z])','\\\\1_\\\\2', re.sub('::', '/',word)))).lower()", "path": "graphstore\\inflector\\Rules\\Base.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "# string\n", "func_signal": "def testSet(self):\n", "code": "g = Graph(':memory:')\ng.set('apple','color','red')\nself.assertEquals(g.query('SELECT * FROM pages').fetchall(),[\n (1,u'apple',''),\n (2,u'color',''),\n (3,u'red','')\n])\nself.assertEquals(g.query('SELECT * FROM triples').fetchall(),[(1,1,2,3)])\ndel g\n# list\ng = Graph(':memory:')\ng.set('grocery list','items',['milk','cookies'])\nself.assertEquals(g.query('SELECT * FROM pages').fetchall(),[\n  (1,u'grocery list',''),\n  (2,u'item',''),\n  (3,u'milk',''),\n  (4,u'cookies','')\n])\nself.assertEquals(g.query('SELECT * FROM triples').fetchall(),[\n  (1,1,2,3),\n  (2,1,2,4)\n])\ndel g\n# dict\ng = Graph(':memory:')\ng.set('apple',{'color':'red','tastiness':'high'})\nself.assertEquals(g.query('SELECT * FROM pages').fetchall(),[\n  (1,u'apple',''),\n  (2,u'color',''),\n  (3,u'red',''),\n  (4,u'tastiness',''),\n  (5,u'high','')\n])\nself.assertEquals(g.query('SELECT * FROM triples').fetchall(),[\n  (1,1,2,3),\n  (2,1,4,5)\n])\ndel g", "path": "graphstore\\tests.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "'''Returns the plural form of a word if first parameter is greater than 1'''\n\n", "func_signal": "def conditionalPlural(self, numer_of_records, word) :\n", "code": "if numer_of_records > 1 :\n    return self.pluralize(word)\nelse :\n    return word", "path": "graphstore\\inflector\\Rules\\Base.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "'''Pluralizes English nouns.'''\n\n", "func_signal": "def pluralize(self, word) :\n", "code": "rules = [\n    ['(?i)(quiz)$' , '\\\\1zes'],\n    ['^(?i)(ox)$' , '\\\\1en'],\n    ['(?i)([m|l])ouse$' , '\\\\1ice'],\n    ['(?i)(matr|vert|ind)ix|ex$' , '\\\\1ices'],\n    ['(?i)(x|ch|ss|sh)$' , '\\\\1es'],\n    ['(?i)([^aeiouy]|qu)ies$' , '\\\\1y'],\n    ['(?i)([^aeiouy]|qu)y$' , '\\\\1ies'],\n    ['(?i)(hive)$' , '\\\\1s'],\n    ['(?i)(?:([^f])fe|([lr])f)$' , '\\\\1\\\\2ves'],\n    ['(?i)sis$' , 'ses'],\n    ['(?i)([ti])um$' , '\\\\1a'],\n    ['(?i)(buffal|tomat)o$' , '\\\\1oes'],\n    ['(?i)(bu)s$' , '\\\\1ses'],\n    ['(?i)(alias|status)' , '\\\\1es'],\n    ['(?i)(octop|vir)us$' , '\\\\1i'],\n    ['(?i)(ax|test)is$' , '\\\\1es'],\n    ['(?i)s$' , 's'],\n    ['(?i)$' , 's']\n]\n\nuncountable_words = ['equipment', 'information', 'rice', 'money', 'species', 'series', 'fish', 'sheep']\n\nirregular_words = {\n    'person' : 'people',\n    'man' : 'men',\n    'child' : 'children',\n    'sex' : 'sexes',\n    'move' : 'moves'\n}\n\nlower_cased_word = word.lower();\n\nfor uncountable_word in uncountable_words:\n    if lower_cased_word[-1*len(uncountable_word):] == uncountable_word :\n        return word\n\nfor irregular in irregular_words.keys():\n    match = re.search('('+irregular+')$',word, re.IGNORECASE)\n    if match:\n        return re.sub('(?i)'+irregular+'$', match.expand('\\\\1')[0]+irregular_words[irregular][1:], word)\n\nfor rule in range(len(rules)):\n    match = re.search(rules[rule][0], word, re.IGNORECASE)\n    if match :\n        groups = match.groups()\n        for k in range(0,len(groups)) :\n            if groups[k] == None :\n                rules[rule][1] = rules[rule][1].replace('\\\\'+str(k+1), '')\n                \n        return re.sub(rules[rule][0], rules[rule][1], word)\n\nreturn word", "path": "graphstore\\inflector\\Rules\\English.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "'''Transforms a string to its unaccented version. \nThis might be useful for generating \"friendly\" URLs'''\n", "func_signal": "def unaccent(self, text) :\n", "code": "find = u'\\u00C0\\u00C1\\u00C2\\u00C3\\u00C4\\u00C5\\u00C6\\u00C7\\u00C8\\u00C9\\u00CA\\u00CB\\u00CC\\u00CD\\u00CE\\u00CF\\u00D0\\u00D1\\u00D2\\u00D3\\u00D4\\u00D5\\u00D6\\u00D8\\u00D9\\u00DA\\u00DB\\u00DC\\u00DD\\u00DE\\u00DF\\u00E0\\u00E1\\u00E2\\u00E3\\u00E4\\u00E5\\u00E6\\u00E7\\u00E8\\u00E9\\u00EA\\u00EB\\u00EC\\u00ED\\u00EE\\u00EF\\u00F0\\u00F1\\u00F2\\u00F3\\u00F4\\u00F5\\u00F6\\u00F8\\u00F9\\u00FA\\u00FB\\u00FC\\u00FD\\u00FE\\u00FF'\nreplace = u'AAAAAAACEEEEIIIIDNOOOOOOUUUUYTsaaaaaaaceeeeiiiienoooooouuuuyty'\nreturn self.string_replace(text, find, replace)", "path": "graphstore\\inflector\\Rules\\Base.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "\"\"\"for index's ajax interface: returns a simple <ul>\"\"\"\n", "func_signal": "def list(self, criteria=None, **params):\n", "code": "try:\n  pages = cherrypy.thread_data.graph.list(criteria)\nexcept NonexistentPageError:\n  pages = []\nexcept NoMatchingComparisonOperatorError:\n  pages = []\nreturn render('list',pages=pages,criteria=criteria)", "path": "controller.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "\"\"\"render templates/[format]/[template].jinja and return result\"\"\"\n", "func_signal": "def render(template, format='html', **context):\n", "code": "content_type(mimetypes.guess_type('.'+format)[0])\ntemplate = environments[format].get_template('%s.jinja' % template)\n\nadd_to_context(context,helpers)\n\nreturn template.render(**context)", "path": "framework.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "'''This function returns a copy of word, translating\nall occurrences of each character in find to the\ncorresponding character in replace'''\n", "func_signal": "def string_replace (self, word, find, replace) :\n", "code": "for k in range(0,len(find)) :\n    word = re.sub(find[k], replace[k], word)\n    \nreturn word", "path": "graphstore\\inflector\\Rules\\Base.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "'''Converts an underscored or CamelCase word into a English sentence.\n    The titleize function converts text like \"WelcomePage\",\n    \"welcome_page\" or  \"welcome page\" to this \"Welcome Page\".\n    If second parameter is set to 'first' it will only\n    capitalize the first character of the title.'''\n    \n", "func_signal": "def titleize(self, word, uppercase = '') :\n", "code": "if(uppercase == 'first'):\n    return self.humanize(self.underscore(word)).capitalize()\nelse :\n    return self.humanize(self.underscore(word)).title()", "path": "graphstore\\inflector\\Rules\\Base.py", "repo_name": "vilterp/braindump", "stars": 3, "license": "None", "language": "python", "size": 928}
{"docstring": "# Every mask is 7 days longer to handle cross-year weekly periods.\n", "func_signal": "def rebuild(self, year, month):\n", "code": "rr = self.rrule\nif year != self.lastyear:\n    self.yearlen = 365+calendar.isleap(year)\n    self.nextyearlen = 365+calendar.isleap(year+1)\n    firstyday = datetime.date(year, 1, 1)\n    self.yearordinal = firstyday.toordinal()\n    self.yearweekday = firstyday.weekday()\n\n    wday = datetime.date(year, 1, 1).weekday()\n    if self.yearlen == 365:\n        self.mmask = M365MASK\n        self.mdaymask = MDAY365MASK\n        self.nmdaymask = NMDAY365MASK\n        self.wdaymask = WDAYMASK[wday:]\n        self.mrange = M365RANGE\n    else:\n        self.mmask = M366MASK\n        self.mdaymask = MDAY366MASK\n        self.nmdaymask = NMDAY366MASK\n        self.wdaymask = WDAYMASK[wday:]\n        self.mrange = M366RANGE\n\n    if not rr._byweekno:\n        self.wnomask = None\n    else:\n        self.wnomask = [0]*(self.yearlen+7)\n        #no1wkst = firstwkst = self.wdaymask.index(rr._wkst)\n        no1wkst = firstwkst = (7-self.yearweekday+rr._wkst)%7\n        if no1wkst >= 4:\n            no1wkst = 0\n            # Number of days in the year, plus the days we got\n            # from last year.\n            wyearlen = self.yearlen+(self.yearweekday-rr._wkst)%7\n        else:\n            # Number of days in the year, minus the days we\n            # left in last year.\n            wyearlen = self.yearlen-no1wkst\n        div, mod = divmod(wyearlen, 7)\n        numweeks = div+mod//4\n        for n in rr._byweekno:\n            if n < 0:\n                n += numweeks+1\n            if not (0 < n <= numweeks):\n                continue\n            if n > 1:\n                i = no1wkst+(n-1)*7\n                if no1wkst != firstwkst:\n                    i -= 7-firstwkst\n            else:\n                i = no1wkst\n            for j in range(7):\n                self.wnomask[i] = 1\n                i += 1\n                if self.wdaymask[i] == rr._wkst:\n                    break\n        if 1 in rr._byweekno:\n            # Check week number 1 of next year as well\n            # TODO: Check -numweeks for next year.\n            i = no1wkst+numweeks*7\n            if no1wkst != firstwkst:\n                i -= 7-firstwkst\n            if i < self.yearlen:\n                # If week starts in next year, we\n                # don't care about it.\n                for j in range(7):\n                    self.wnomask[i] = 1\n                    i += 1\n                    if self.wdaymask[i] == rr._wkst:\n                        break\n        if no1wkst:\n            # Check last week number of last year as\n            # well. If no1wkst is 0, either the year\n            # started on week start, or week number 1\n            # got days from last year, so there are no\n            # days from last year's last week number in\n            # this year.\n            if -1 not in rr._byweekno:\n                lyearweekday = datetime.date(year-1,1,1).weekday()\n                lno1wkst = (7-lyearweekday+rr._wkst)%7\n                lyearlen = 365+calendar.isleap(year-1)\n                if lno1wkst >= 4:\n                    lno1wkst = 0\n                    lnumweeks = 52+(lyearlen+\n                                   (lyearweekday-rr._wkst)%7)%7//4\n                else:\n                    lnumweeks = 52+(self.yearlen-no1wkst)%7//4\n            else:\n                lnumweeks = -1\n            if lnumweeks in rr._byweekno:\n                for i in range(no1wkst):\n                    self.wnomask[i] = 1\n\nif (rr._bynweekday and\n    (month != self.lastmonth or year != self.lastyear)):\n    ranges = []\n    if rr._freq == YEARLY:\n        if rr._bymonth:\n            for month in rr._bymonth:\n                ranges.append(self.mrange[month-1:month+1])\n        else:\n            ranges = [(0, self.yearlen)]\n    elif rr._freq == MONTHLY:\n        ranges = [self.mrange[month-1:month+1]]\n    if ranges:\n        # Weekly frequency won't get here, so we may not\n        # care about cross-year weekly periods.\n        self.nwdaymask = [0]*self.yearlen\n        for first, last in ranges:\n            last -= 1\n            for wday, n in rr._bynweekday:\n                if n < 0:\n                    i = last+(n+1)*7\n                    i -= (self.wdaymask[i]-wday)%7\n                else:\n                    i = first+(n-1)*7\n                    i += (7-self.wdaymask[i]+wday)%7\n                if first <= i <= last:\n                    self.nwdaymask[i] = 1\n\nif rr._byeaster:\n    self.eastermask = [0]*(self.yearlen+7)\n    eyday = easter.easter(year).toordinal()-self.yearordinal\n    for offset in rr._byeaster:\n        self.eastermask[eyday+offset] = 1\n\nself.lastyear = year\nself.lastmonth = month", "path": "external\\dateutil\\rrule.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "# test in/out equivalence and parsing\n", "func_signal": "def test_parse(self):\n", "code": "res = S.loads(JSON)\nout = S.dumps(res)\nself.assertEquals(res, S.loads(out))", "path": "external\\simplejson\\tests\\test_pass3.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "\"\"\"\nTurn obj.value into a list of dates, datetimes, or\n(datetime, timedelta) tuples.\n\n\"\"\"\n", "func_signal": "def transformToNative(obj):\n", "code": "if obj.isNative:\n    return obj\nobj.isNative = True\nif obj.value == '':\n    obj.value = []\n    return obj\ntzinfo = getTzid(getattr(obj, 'tzid_param', None))\nvalueParam = getattr(obj, 'value_param', \"DATE-TIME\").upper()\nvalTexts = obj.value.split(\",\")\nif valueParam == \"DATE\":\n    obj.value = [stringToDate(x) for x in valTexts]\nelif valueParam == \"DATE-TIME\":\n    obj.value = [stringToDateTime(x, tzinfo) for x in valTexts]\nelif valueParam == \"PERIOD\":\n    obj.value = [stringToPeriod(x, tzinfo) for x in valTexts]\nreturn obj", "path": "external\\vobject\\icalendar.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "\"\"\"Generate a UID if one does not exist.\n\nThis is just a dummy implementation, for now.\n\n\"\"\"\n", "func_signal": "def generateImplicitParameters(obj):\n", "code": "if not hasattr(obj, 'uid'):\n    rand = str(int(random.random() * 100000))\n    now = datetime.datetime.now(utc)\n    now = dateTimeToString(now)\n    host = socket.gethostname()\n    obj.add(ContentLine('UID', [], now + '-' + rand + '@' + host))", "path": "external\\vobject\\icalendar.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "# test in/out equivalence and parsing\n", "func_signal": "def test_parse(self):\n", "code": "res = S.loads(JSON)\nout = S.dumps(res)\nself.assertEquals(res, S.loads(out))\ntry:\n    S.dumps(res, allow_nan=False)\nexcept ValueError:\n    pass\nelse:\n    self.fail(\"23456789012E666 should be out of range\")", "path": "external\\simplejson\\tests\\test_pass1.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "\"\"\"Replace the datetime.timedelta in obj.value with an RFC2445 string.\n\"\"\"\n", "func_signal": "def transformFromNative(obj):\n", "code": "if not obj.isNative: return obj\nobj.isNative = False\nobj.value = timedeltaToString(obj.value)\nreturn obj", "path": "external\\vobject\\icalendar.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "\"\"\"Backslash escape line.value.\"\"\"\n", "func_signal": "def encode(cls, line):\n", "code": "if not line.encoded:\n    line.value = cls.listSeparator.join(backslashEscape(val) for val in line.value)\n    line.encoded=True", "path": "external\\vobject\\icalendar.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "\"\"\"Take a string or unicode, turn it into unicode, decoding as utf-8\"\"\"\n", "func_signal": "def toUnicode(s):\n", "code": "if isinstance(s, str):\n    s = s.decode('utf-8')\nreturn s", "path": "external\\vobject\\icalendar.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "# workaround for dateutil failing to parse some experimental properties\n", "func_signal": "def gettzinfo(self):\n", "code": "good_lines = ('rdate', 'rrule', 'dtstart', 'tzname', 'tzoffsetfrom',\n              'tzoffsetto', 'tzid')\n# serialize encodes as utf-8, cStringIO will leave utf-8 alone\nbuffer = cStringIO.StringIO()\n# allow empty VTIMEZONEs\nif len(self.contents) == 0:\n    return None\ndef customSerialize(obj):\n    if isinstance(obj, Component):\n        foldOneLine(buffer, u\"BEGIN:\" + obj.name)\n        for child in obj.lines():\n            if child.name.lower() in good_lines:\n                child.serialize(buffer, 75, validate=False)\n        for comp in obj.components():\n            customSerialize(comp)\n        foldOneLine(buffer, u\"END:\" + obj.name)\ncustomSerialize(self)\nbuffer.seek(0) # tzical wants to read a stream\nreturn dateutil.tz.tzical(buffer).get()", "path": "external\\vobject\\icalendar.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "\"\"\"\nSerialize iCalendar to HTML using the hCalendar microformat (http://microformats.org/wiki/hcalendar)\n\"\"\"\n\n", "func_signal": "def serialize(cls, obj, buf=None, lineLength=None, validate=True):\n", "code": "outbuf = buf or StringIO.StringIO()\nlevel = 0 # holds current indentation level        \ntabwidth = 3\n\ndef indent():\n    return ' ' * level * tabwidth\n\ndef out(s):\n    outbuf.write(indent())\n    outbuf.write(s)\n\n# not serializing optional vcalendar wrapper\n\nvevents = obj.vevent_list\n\nfor event in vevents:\n    out('<span class=\"vevent\">' + CRLF)\n    level += 1\n    \n    # URL\n    url = event.getChildValue(\"url\")\n    if url:\n        out('<a class=\"url\" href=\"' + url + '\">' + CRLF)\n        level += 1\n    # SUMMARY\n    summary = event.getChildValue(\"summary\")\n    if summary:\n        out('<span class=\"summary\">' + summary + '</span>:' + CRLF)\n    \n    # DTSTART\n    dtstart = event.getChildValue(\"dtstart\")\n    if dtstart:\n        if type(dtstart) == date:\n            timeformat = \"%A, %B %e\"\n            machine    = \"%Y%m%d\"\n        elif type(dtstart) == datetime:\n            timeformat = \"%A, %B %e, %H:%M\"\n            machine    = \"%Y%m%dT%H%M%S%z\"\n\n        #TODO: Handle non-datetime formats?\n        #TODO: Spec says we should handle when dtstart isn't included\n        \n        out('<abbr class=\"dtstart\", title=\"%s\">%s</abbr>\\r\\n' % \n             (dtstart.strftime(machine), dtstart.strftime(timeformat)))\n        \n        # DTEND\n        dtend = event.getChildValue(\"dtend\")\n        if not dtend:\n            duration = event.getChildValue(\"duration\")\n            if duration:\n                dtend = duration + dtstart\n           # TODO: If lacking dtend & duration?\n       \n        if dtend:\n            human = dtend\n            # TODO: Human readable part could be smarter, excluding repeated data\n            if type(dtend) == date:\n                human = dtend - timedelta(days=1)\n                \n            out('- <abbr class=\"dtend\", title=\"%s\">%s</abbr>\\r\\n' % \n             (dtend.strftime(machine), human.strftime(timeformat)))    \n\n    # LOCATION    \n    location = event.getChildValue(\"location\")\n    if location:\n        out('at <span class=\"location\">' + location + '</span>' + CRLF)\n\n    description = event.getChildValue(\"description\")\n    if description:\n        out('<div class=\"description\">' + description + '</div>' + CRLF)\n    \n    if url:\n        level -= 1\n        out('</a>' + CRLF)\n    \n    level -= 1                \n    out('</span>' + CRLF) # close vevent\n\nreturn buf or outbuf.getvalue()", "path": "external\\vobject\\hcalendar.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "\"\"\"Returns datetime.datetime object.\"\"\"\n", "func_signal": "def stringToDateTime(s, tzinfo=None):\n", "code": "try:\n    year   = int( s[0:4] )\n    month  = int( s[4:6] )\n    day    = int( s[6:8] )\n    hour   = int( s[9:11] )\n    minute = int( s[11:13] )\n    second = int( s[13:15] )\n    if len(s) > 15:\n        if s[15] == 'Z':\n            tzinfo = utc\nexcept:\n    raise ParseError(\"'%s' is not a valid DATE-TIME\" % s)\nreturn datetime.datetime(year, month, day, hour, minute, second, 0, tzinfo)", "path": "external\\vobject\\icalendar.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "\"\"\"Turn obj.value into a timedelta or datetime.\"\"\"\n", "func_signal": "def transformToNative(obj):\n", "code": "if obj.isNative: return obj\nvalue = getattr(obj, 'value_param', 'DURATION').upper()\nif hasattr(obj, 'value_param'):\n    del obj.value_param\nif obj.value == '':\n    obj.isNative = True\n    return obj\nelif value  == 'DURATION':\n    try:\n        return Duration.transformToNative(obj)\n    except ParseError:\n        logger.warn(\"TRIGGER not recognized as DURATION, trying \"\n                     \"DATE-TIME, because iCal sometimes exports \"\n                     \"DATE-TIMEs without setting VALUE=DATE-TIME\")\n        try:\n            obj.isNative = False\n            dt = DateTimeBehavior.transformToNative(obj)\n            return dt\n        except:\n            msg = \"TRIGGER with no VALUE not recognized as DURATION \" \\\n                  \"or as DATE-TIME\"\n            raise ParseError(msg)\nelif value == 'DATE-TIME':\n    #TRIGGERs with DATE-TIME values must be in UTC, we could validate\n    #that fact, for now we take it on faith.\n    return DateTimeBehavior.transformToNative(obj)\nelse:\n    raise ParseError(\"VALUE must be DURATION or DATE-TIME\")", "path": "external\\vobject\\icalendar.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "# We need to handle cross-year weeks here.\n", "func_signal": "def wdayset(self, year, month, day):\n", "code": "set = [None]*(self.yearlen+7)\ni = datetime.date(year, month, day).toordinal()-self.yearordinal\nstart = i\nfor j in range(7):\n    set[i] = i\n    i += 1\n    #if (not (0 <= i < self.yearlen) or\n    #    self.wdaymask[i] == self.rrule._wkst):\n    # This will cross the year boundary, if necessary.\n    if self.wdaymask[i] == self.rrule._wkst:\n        break\nreturn set, start, i", "path": "external\\dateutil\\rrule.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "\"\"\"Create PRODID, VERSION, and VTIMEZONEs if needed.\n\nVTIMEZONEs will need to exist whenever TZID parameters exist or when\ndatetimes with tzinfo exist.\n\n\"\"\"\n", "func_signal": "def generateImplicitParameters(cls, obj):\n", "code": "for comp in obj.components():\n    if comp.behavior is not None:\n        comp.behavior.generateImplicitParameters(comp)\nif not hasattr(obj, 'prodid'):\n    obj.add(ContentLine('PRODID', [], PRODID))\nif not hasattr(obj, 'version'):\n    obj.add(ContentLine('VERSION', [], cls.versionString))\ntzidsUsed = {}\n\ndef findTzids(obj, table):\n    if isinstance(obj, ContentLine) and (obj.behavior is None or\n                                         not obj.behavior.forceUTC):\n        if getattr(obj, 'tzid_param', None):\n            table[obj.tzid_param] = 1\n        else:\n            if type(obj.value) == list:\n                for item in obj.value:\n                    tzinfo = getattr(obj.value, 'tzinfo', None)\n                    tzid = TimezoneComponent.registerTzinfo(tzinfo)\n                    if tzid:\n                        table[tzid] = 1\n            else:\n                tzinfo = getattr(obj.value, 'tzinfo', None)\n                tzid = TimezoneComponent.registerTzinfo(tzinfo)\n                if tzid:\n                    table[tzid] = 1\n    for child in obj.getChildren():\n        if obj.name != 'VTIMEZONE':\n            findTzids(child, table)\n\nfindTzids(obj, tzidsUsed)\noldtzids = [toUnicode(x.tzid.value) for x in getattr(obj, 'vtimezone_list', [])]\nfor tzid in tzidsUsed.keys():\n    tzid = toUnicode(tzid)\n    if tzid != u'UTC' and tzid not in oldtzids:\n        obj.add(TimezoneComponent(tzinfo=getTzid(tzid)))", "path": "external\\vobject\\icalendar.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "\"\"\"Ignore tzinfo unless convertToUTC.  Output string.\"\"\"\n", "func_signal": "def dateTimeToString(dateTime, convertToUTC=False):\n", "code": "if dateTime.tzinfo and convertToUTC:\n    dateTime = dateTime.astimezone(utc)\nif tzinfo_eq(dateTime.tzinfo, utc): utcString = \"Z\"\nelse: utcString = \"\"\n\nyear  = numToDigits( dateTime.year,  4 )\nmonth = numToDigits( dateTime.month, 2 )\nday   = numToDigits( dateTime.day,   2 )\nhour  = numToDigits( dateTime.hour,  2 )\nmins  = numToDigits( dateTime.minute,  2 )\nsecs  = numToDigits( dateTime.second,  2 )\n\nreturn year + month + day + \"T\" + hour + mins + secs + utcString", "path": "external\\vobject\\icalendar.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "# move to info\n", "func_signal": "def validate(self, res):\n", "code": "if res.year is not None:\n    res.year = self.convertyear(res.year)\nif res.tzoffset == 0 and not res.tzname or res.tzname == 'Z':\n    res.tzname = \"UTC\"\n    res.tzoffset = 0\nelif res.tzoffset != 0 and res.tzname and self.utczone(res.tzname):\n    res.tzoffset = 0\nreturn True", "path": "external\\dateutil\\parser.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "\"\"\"dayofweek == 0 means Sunday, whichweek 5 means last instance\"\"\"\n", "func_signal": "def picknthweekday(year, month, dayofweek, hour, minute, whichweek):\n", "code": "first = datetime.datetime(year, month, 1, hour, minute)\nweekdayone = first.replace(day=((dayofweek-first.isoweekday())%7+1))\nfor n in xrange(whichweek):\n    dt = weekdayone+(whichweek-n)*ONEWEEK\n    if dt.month == month:\n        return dt", "path": "external\\dateutil\\tzwin.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "\"\"\"Turn a recurring Component into a RecurringComponent.\"\"\"\n", "func_signal": "def transformToNative(obj):\n", "code": "if not obj.isNative:\n    object.__setattr__(obj, '__class__', RecurringComponent)\n    obj.isNative = True\nreturn obj", "path": "external\\vobject\\icalendar.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "\"\"\"Turn obj.value into a date or datetime.\"\"\"\n", "func_signal": "def transformToNative(obj):\n", "code": "if obj.isNative: return obj\nobj.isNative = True\nif obj.value == '': return obj\nobj.value=str(obj.value)\nobj.value=parseDtstart(obj, allowSignatureMismatch=True)\nif getattr(obj, 'value_param', 'DATE-TIME').upper() == 'DATE-TIME':\n    if hasattr(obj, 'tzid_param'):\n        # Keep a copy of the original TZID around\n        obj.params['X-VOBJ-ORIGINAL-TZID'] = [obj.tzid_param]\n        del obj.tzid_param\nreturn obj", "path": "external\\vobject\\icalendar.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "\"\"\"How many weeks from the end of the month dt is, starting from 1.\"\"\"\n", "func_signal": "def fromLastWeek(dt):\n", "code": "weekDelta = datetime.timedelta(weeks=1)\nn = 1\ncurrent = dt + weekDelta\nwhile current.month == dt.month:\n    n += 1\n    current += weekDelta\nreturn n", "path": "external\\vobject\\icalendar.py", "repo_name": "arsfeld/meeting-scheduler", "stars": 3, "license": "None", "language": "python", "size": 472}
{"docstring": "\"\"\"Creates default set with values stringified\n\nPut together our list of defaults, stringify non-None values\nand add in our action/id default if they use it and didn't\nspecify it.\n\ndefaultkeys is a list of the currently assumed default keys\nroutekeys is a list of the keys found in the route path\nreserved_keys is a list of keys that are not\n\n\"\"\"\n", "func_signal": "def _defaults(self, routekeys, reserved_keys, kargs):\n", "code": "defaults = {}\n# Add in a controller/action default if they don't exist\nif 'controller' not in routekeys and 'controller' not in kargs \\\n   and not self.explicit:\n    kargs['controller'] = 'content'\nif 'action' not in routekeys and 'action' not in kargs \\\n   and not self.explicit:\n    kargs['action'] = 'index'\ndefaultkeys = frozenset([key for key in kargs.keys() \\\n                         if key not in reserved_keys])\nfor key in defaultkeys:\n    if kargs[key] is not None:\n        defaults[key] = self.make_unicode(kargs[key])\n    else:\n        defaults[key] = None\nif 'action' in routekeys and not defaults.has_key('action') \\\n   and not self.explicit:\n    defaults['action'] = 'index'\nif 'id' in routekeys and not defaults.has_key('id') \\\n   and not self.explicit:\n    defaults['id'] = None\nnewdefaultkeys = frozenset([key for key in defaults.keys() \\\n                            if key not in reserved_keys])\n\nreturn (defaults, newdefaultkeys)", "path": "enginelight\\framework\\routes\\route.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Recursively build our regexp given a path, and a controller\nlist.\n\nReturns the regular expression string, and two booleans that\ncan be ignored as they're only used internally by buildnextreg.\n\n\"\"\"\n", "func_signal": "def buildnextreg(self, path, clist):\n", "code": "if path:\n    part = path[0]\nelse:\n    part = ''\nreg = ''\n\n# noreqs will remember whether the remainder has either a string \n# match, or a non-defaulted regexp match on a key, allblank remembers\n# if the rest could possible be completely empty\n(rest, noreqs, allblank) = ('', True, True)\nif len(path[1:]) > 0:\n    self.prior = part\n    (rest, noreqs, allblank) = self.buildnextreg(path[1:], clist)\n\nif isinstance(part, dict) and part['type'] == ':':\n    var = part['name']\n    partreg = ''\n    \n    # First we plug in the proper part matcher\n    if self.reqs.has_key(var):\n        partreg = '(?P<' + var + '>' + self.reqs[var] + ')'\n    elif var == 'controller':\n        partreg = '(?P<' + var + '>' + '|'.join(map(re.escape, clist))\n        partreg += ')'\n    elif self.prior in ['/', '#']:\n        partreg = '(?P<' + var + '>[^' + self.prior + ']+?)'\n    else:\n        if not rest:\n            partreg = '(?P<' + var + '>[^%s]+?)' % '/'\n        else:\n            end = ''.join(self.done_chars)\n            rem = rest\n            if rem[0] == '\\\\' and len(rem) > 1:\n                rem = rem[1]\n            elif rem.startswith('(\\\\') and len(rem) > 2:\n                rem = rem[2]\n            else:\n                rem = end\n            rem = frozenset(rem) | frozenset(['/'])\n            partreg = '(?P<' + var + '>[^%s]+?)' % ''.join(rem)\n    \n    if self.reqs.has_key(var):\n        noreqs = False\n    if not self.defaults.has_key(var): \n        allblank = False\n        noreqs = False\n    \n    # Now we determine if its optional, or required. This changes \n    # depending on what is in the rest of the match. If noreqs is \n    # true, then its possible the entire thing is optional as there's\n    # no reqs or string matches.\n    if noreqs:\n        # The rest is optional, but now we have an optional with a \n        # regexp. Wrap to ensure that if we match anything, we match\n        # our regexp first. It's still possible we could be completely\n        # blank as we have a default\n        if self.reqs.has_key(var) and self.defaults.has_key(var):\n            reg = '(' + partreg + rest + ')?'\n        \n        # Or we have a regexp match with no default, so now being \n        # completely blank form here on out isn't possible\n        elif self.reqs.has_key(var):\n            allblank = False\n            reg = partreg + rest\n        \n        # If the character before this is a special char, it has to be\n        # followed by this\n        elif self.defaults.has_key(var) and \\\n             self.prior in (',', ';', '.'):\n            reg = partreg + rest\n        \n        # Or we have a default with no regexp, don't touch the allblank\n        elif self.defaults.has_key(var):\n            reg = partreg + '?' + rest\n        \n        # Or we have a key with no default, and no reqs. Not possible\n        # to be all blank from here\n        else:\n            allblank = False\n            reg = partreg + rest\n    # In this case, we have something dangling that might need to be\n    # matched\n    else:\n        # If they can all be blank, and we have a default here, we know\n        # its safe to make everything from here optional. Since \n        # something else in the chain does have req's though, we have\n        # to make the partreg here required to continue matching\n        if allblank and self.defaults.has_key(var):\n            reg = '(' + partreg + rest + ')?'\n            \n        # Same as before, but they can't all be blank, so we have to \n        # require it all to ensure our matches line up right\n        else:\n            reg = partreg + rest\nelif isinstance(part, dict) and part['type'] == '*':\n    var = part['name']\n    if noreqs:\n        if self.defaults.has_key(var):\n            reg = '(?P<' + var + '>.*)' + rest\n        else:\n            reg = '(?P<' + var + '>.*)' + rest\n            allblank = False\n            noreqs = False\n    else:\n        if allblank and self.defaults.has_key(var):\n            reg = '(?P<' + var + '>.*)' + rest\n        elif self.defaults.has_key(var):\n            reg = '(?P<' + var + '>.*)' + rest\n        else:\n            allblank = False\n            noreqs = False\n            reg = '(?P<' + var + '>.*)' + rest\nelif part and part[-1] in self.done_chars:\n    if allblank:\n        reg = re.escape(part[:-1]) + '(' + re.escape(part[-1]) + rest\n        reg += ')?'\n    else:\n        allblank = False\n        reg = re.escape(part) + rest\n\n# We have a normal string here, this is a req, and it prevents us from \n# being all blank\nelse:\n    noreqs = False\n    allblank = False\n    reg = re.escape(part) + rest\n\nreturn (reg, noreqs, allblank)", "path": "enginelight\\framework\\routes\\route.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Create a regular expression for matching purposes\n\nNote: This MUST be called before match can function properly.\n\nclist should be a list of valid controller strings that can be \nmatched, for this reason makeregexp should be called by the web\nframework after it knows all available controllers that can be\nutilized.\n\n\"\"\"\n", "func_signal": "def makeregexp(self, clist):\n", "code": "if self.minimization:\n    reg = self.buildnextreg(self.routelist, clist)[0]\n    if not reg:\n        reg = '/'\n    reg = reg + '(/)?' + '$'\n\n    if not reg.startswith('/'):\n        reg = '/' + reg\nelse:\n    reg = self.buildfullreg(clist)\n\nreg = '^' + reg\n\nself.regexp = reg\nself.regmatch = re.compile(reg)", "path": "enginelight\\framework\\routes\\route.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Initialize a route, with a given routepath for\nmatching/generation\n\nThe set of keyword args will be used as defaults.\n\nUsage::\n\n    >>> from routes.base import Route\n    >>> newroute = Route(':controller/:action/:id')\n    >>> newroute.defaults\n    {'action': 'index', 'id': None}\n    >>> newroute = Route('date/:year/:month/:day',  \n    ...     controller=\"blog\", action=\"view\")\n    >>> newroute = Route('archives/:page', controller=\"blog\", \n    ...     action=\"by_page\", requirements = { 'page':'\\d{1,2}' })\n    >>> newroute.reqs\n    {'page': '\\\\\\d{1,2}'}\n\n.. Note:: \n    Route is generally not called directly, a Mapper instance\n    connect method should be used to add routes.\n\n\"\"\"\n", "func_signal": "def __init__(self, routepath, **kargs):\n", "code": "self.routepath = routepath\nself.sub_domains = False\nself.prior = None\nself.minimization = kargs.pop('_minimize', True)\nself.encoding = kargs.pop('_encoding', 'utf-8')\nself.reqs = kargs.get('requirements', {})\nself.decode_errors = 'replace'\n\n# Don't bother forming stuff we don't need if its a static route\nself.static = kargs.get('_static', False)\nself.filter = kargs.pop('_filter', None)\nself.absolute = kargs.pop('_absolute', False)\n\n# Pull out the member/collection name if present, this applies only to\n# map.resource\nself.member_name = kargs.pop('_member_name', None)\nself.collection_name = kargs.pop('_collection_name', None)\nself.parent_resource = kargs.pop('_parent_resource', None)\n\n# Pull out route conditions\nself.conditions = kargs.pop('conditions', None)\n\n# Determine if explicit behavior should be used\nself.explicit = kargs.pop('_explicit', False)\n\n# reserved keys that don't count\nreserved_keys = ['requirements']\n\n# special chars to indicate a natural split in the URL\nself.done_chars = ('/', ',', ';', '.', '#')\n\n# Strip preceding '/' if present, and not minimizing\nif routepath.startswith('/') and self.minimization:\n    routepath = routepath[1:]\n\n# Build our routelist, and the keys used in the route\nself.routelist = routelist = self._pathkeys(routepath)\nroutekeys = frozenset([key['name'] for key in routelist \\\n                       if isinstance(key, dict)])\n\nif not self.minimization:\n    self.make_full_route()\n\n# Build a req list with all the regexp requirements for our args\nself.req_regs = {}\nfor key, val in self.reqs.iteritems():\n    self.req_regs[key] = re.compile('^' + val + '$')\n# Update our defaults and set new default keys if needed. defaults\n# needs to be saved\n(self.defaults, defaultkeys) = self._defaults(routekeys, \n                                              reserved_keys, kargs)\n# Save the maximum keys we could utilize\nself.maxkeys = defaultkeys | routekeys\n\n# Populate our minimum keys, and save a copy of our backward keys for\n# quicker generation later\n(self.minkeys, self.routebackwards) = self._minkeys(routelist[:])\n\n# Populate our hardcoded keys, these are ones that are set and don't \n# exist in the route\nself.hardcoded = frozenset([key for key in self.maxkeys \\\n    if key not in routekeys and self.defaults[key] is not None])", "path": "enginelight\\framework\\routes\\route.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Generate a non-minimal version of the URL\"\"\"\n# Iterate through the keys that are defaults, and NOT in the route\n# path. If its not in kargs, or doesn't match, or is None, this\n# route won't work\n", "func_signal": "def generate_non_minimized(self, kargs):\n", "code": "for k in self.maxkeys - self.minkeys:\n    if k not in kargs:\n        return False\n    elif self.make_unicode(kargs[k]) != \\\n        self.make_unicode(self.defaults[k]):\n        return False\n\n# Ensure that all the args in the route path are present and not None\nfor arg in self.minkeys:\n    if arg not in kargs or kargs[arg] is None:\n        return False\nreturn self.regpath % kargs", "path": "enginelight\\framework\\routes\\route.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Generate a minimized version of the URL\"\"\"\n", "func_signal": "def generate_minimized(self, kargs):\n", "code": "routelist = self.routebackwards\nurllist = []\ngaps = False\nfor part in routelist:\n    if isinstance(part, dict) and part['type'] == ':':\n        arg = part['name']\n        \n        # For efficiency, check these just once\n        has_arg = kargs.has_key(arg)\n        has_default = self.defaults.has_key(arg)\n        \n        # Determine if we can leave this part off\n        # First check if the default exists and wasn't provided in the \n        # call (also no gaps)\n        if has_default and not has_arg and not gaps:\n            continue\n            \n        # Now check to see if there's a default and it matches the \n        # incoming call arg\n        if (has_default and has_arg) and self.make_unicode(kargs[arg]) == \\\n            self.make_unicode(self.defaults[arg]) and not gaps: \n            continue\n        \n        # We need to pull the value to append, if the arg is None and \n        # we have a default, use that\n        if has_arg and kargs[arg] is None and has_default and not gaps:\n            continue\n        \n        # Otherwise if we do have an arg, use that\n        elif has_arg:\n            val = kargs[arg]\n        \n        elif has_default and self.defaults[arg] is not None:\n            val = self.defaults[arg]\n        \n        # No arg at all? This won't work\n        else:\n            return False\n        \n        urllist.append(url_quote(val, self.encoding))\n        if has_arg:\n            del kargs[arg]\n        gaps = True\n    elif isinstance(part, dict) and part['type'] == '*':\n        arg = part['name']\n        kar = kargs.get(arg)\n        if kar is not None:\n            urllist.append(url_quote(kar, self.encoding))\n            gaps = True\n    elif part and part[-1] in self.done_chars:\n        if not gaps and part in self.done_chars:\n            continue\n        elif not gaps:\n            urllist.append(part[:-1])\n            gaps = True\n        else:\n            gaps = True\n            urllist.append(part)\n    else:\n        gaps = True\n        urllist.append(part)\nurllist.reverse()\nurl = ''.join(urllist)\nreturn url", "path": "enginelight\\framework\\routes\\route.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Generate a URL from ourself given a set of keyword arguments\n\nToss an exception if this\nset of keywords would cause a gap in the url.\n\n\"\"\"\n# Verify that our args pass any regexp requirements\n", "func_signal": "def generate(self, _ignore_req_list=False, _append_slash=False, **kargs):\n", "code": "if not _ignore_req_list:\n    for key in self.reqs.keys():\n        val = kargs.get(key)\n        if val and not self.req_regs[key].match(self.make_unicode(val)):\n            return False\n\n# Verify that if we have a method arg, its in the method accept list. \n# Also, method will be changed to _method for route generation\nmeth = kargs.get('method')\nif meth:\n    if self.conditions and 'method' in self.conditions \\\n        and meth.upper() not in self.conditions['method']:\n        return False\n    kargs.pop('method')\n\nif self.minimization:\n    url = self.generate_minimized(kargs)\nelse:\n    url = self.generate_non_minimized(kargs)\n\nif url is False:\n    return url\n\nif not url.startswith('/'):\n    url = '/' + url\nextras = frozenset(kargs.keys()) - self.maxkeys\nif extras:\n    if _append_slash and not url.endswith('/'):\n        url += '/'\n    url += '?'\n    fragments = []\n    # don't assume the 'extras' set preserves order: iterate\n    # through the ordered kargs instead\n    for key in kargs:\n        if key not in extras:\n            continue\n        if key == 'action' or key == 'controller':\n            continue\n        val = kargs[key]\n        if isinstance(val, (tuple, list)):\n            for value in val:\n                fragments.append((key, value))\n        else:\n            fragments.append((key, val))\n        \n    url += urllib.urlencode(fragments)\nelif _append_slash and not url.endswith('/'):\n    url += '/'\nreturn url", "path": "enginelight\\framework\\routes\\route.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Issues a redirect based on the arguments. \n\nRedirect's *should* occur as a \"302 Moved\" header, however the web \nframework may utilize a different method.\n\nAll arguments are passed to url_for to retrieve the appropriate URL, then\nthe resulting URL it sent to the redirect function as the URL.\n\"\"\"\n", "func_signal": "def redirect_to(*args, **kargs):\n", "code": "target = url_for(*args, **kargs)\nconfig = request_config()\nreturn config.redirect(target)", "path": "enginelight\\templates\\application\\framework\\routes\\util.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Transform the given argument into a unicode string.\"\"\"\n", "func_signal": "def make_unicode(self, s):\n", "code": "if isinstance(s, unicode):\n    return s\nelif isinstance(s, str):\n    return s.decode(self.encoding)\nelif callable(s):\n    return s\nelse:\n    return unicode(s)", "path": "enginelight\\framework\\routes\\route.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Utility function to walk the route, and pull out the valid\ndynamic/wildcard keys.\"\"\"\n", "func_signal": "def _pathkeys(self, routepath):\n", "code": "collecting = False\ncurrent = ''\ndone_on = ''\nvar_type = ''\njust_started = False\nroutelist = []\nfor char in routepath:\n    if char in [':', '*', '{'] and not collecting:\n        just_started = True\n        collecting = True\n        var_type = char\n        if char == '{':\n            done_on = '}'\n            just_started = False\n        if len(current) > 0:\n            routelist.append(current)\n            current = ''\n    elif collecting and just_started:\n        just_started = False\n        if char == '(':\n            done_on = ')'\n        else:\n            current = char\n            done_on = self.done_chars + ('-',)\n    elif collecting and char not in done_on:\n        current += char\n    elif collecting:\n        collecting = False\n        if var_type == '{':\n            opts = current.split(':')\n            if len(opts) > 1:\n                current = opts[0]\n                self.reqs[current] = opts[1]\n            var_type = ':'\n        routelist.append(dict(type=var_type, name=current))\n        if char in self.done_chars:\n            routelist.append(char)\n        done_on = var_type = current = ''\n    else:\n        current += char\nif collecting:\n    routelist.append(dict(type=var_type, name=current))\nelif current:\n    routelist.append(current)\nreturn routelist", "path": "enginelight\\framework\\routes\\route.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Build the regexp by iterating through the routelist and\nreplacing dicts with the appropriate regexp match\"\"\"\n", "func_signal": "def buildfullreg(self, clist):\n", "code": "regparts = []\nfor part in self.routelist:\n    if isinstance(part, dict):\n        var = part['name']\n        if var == 'controller':\n            partmatch = '|'.join(map(re.escape, clist))\n        elif part['type'] == ':':\n            partmatch = self.reqs.get(var) or '[^/]+?'\n        else:\n            partmatch = self.reqs.get(var) or '.+?'\n        regparts.append('(?P<%s>%s)' % (var, partmatch))\n    else:\n        regparts.append(re.escape(part))\nregexp = ''.join(regparts) + '$'\nreturn regexp", "path": "enginelight\\framework\\routes\\route.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"A Unicode handling version of urllib.quote.\"\"\"\n", "func_signal": "def _url_quote(string, encoding):\n", "code": "if encoding:\n    if isinstance(string, unicode):\n        s = string.encode(encoding)\n    elif isinstance(string, str):\n        # assume the encoding is already correct\n        s = string\n    else:\n        s = unicode(string).encode(encoding)\nelse:\n    s = str(string)\nreturn urllib.quote(s, '/')", "path": "enginelight\\templates\\application\\framework\\routes\\util.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Scan a directory for python files and use them as controllers\"\"\"\n", "func_signal": "def controller_scan(directory=None):\n", "code": "if directory is None:\n    return []\n\ndef find_controllers(dirname, prefix=''):\n    \"\"\"Locate controllers in a directory\"\"\"\n    controllers = []\n    for fname in os.listdir(dirname):\n        filename = os.path.join(dirname, fname)\n        if os.path.isfile(filename) and \\\n            re.match('^[^_]{1,1}.*\\.py$', fname):\n            controllers.append(prefix + fname[:-3])\n        elif os.path.isdir(filename):\n            controllers.extend(find_controllers(filename, \n                                                prefix=prefix+fname+'/'))\n    return controllers\ndef longest_first(fst, lst):\n    \"\"\"Compare the length of one string to another, shortest goes first\"\"\"\n    return cmp(len(lst), len(fst))\ncontrollers = find_controllers(directory)\ncontrollers.sort(longest_first)\nreturn controllers", "path": "enginelight\\templates\\application\\framework\\routes\\util.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Resolves the URL in PATH_INFO, and uses wsgi.routing_args\nto pass on URL resolver results.\"\"\"\n", "func_signal": "def __call__(self, environ, start_response):\n", "code": "config = request_config()\nconfig.mapper = self.mapper\n\nold_method = None\nif self.use_method_override:\n    req = WSGIRequest(environ)\n    req.errors = 'ignore'\n    if '_method' in environ.get('QUERY_STRING', '') and \\\n        '_method' in req.GET:\n        old_method = environ['REQUEST_METHOD']\n        environ['REQUEST_METHOD'] = req.GET['_method'].upper()\n        log.debug(\"_method found in QUERY_STRING, altering request\"\n                  \" method to %s\", environ['REQUEST_METHOD'])\n    elif is_form_post(environ) and '_method' in req.POST:\n        old_method = environ['REQUEST_METHOD']\n        environ['REQUEST_METHOD'] = req.POST['_method'].upper()\n        log.debug(\"_method found in POST data, altering request \"\n                  \"method to %s\", environ['REQUEST_METHOD'])\n\n# Run the actual route matching\n# -- Assignment of environ to config triggers route matching\nconfig.environ = environ\n\nmatch = config.mapper_dict\nroute = config.route\n\nif old_method:\n    environ['REQUEST_METHOD'] = old_method\n\nurlinfo = \"%s %s\" % (environ['REQUEST_METHOD'], environ['PATH_INFO'])\nif not match:\n    match = {}\n    log.debug(\"No route matched for %s\", urlinfo)\nelse:\n    log.debug(\"Matched %s\", urlinfo)\n    log.debug(\"Route path: '%s', defaults: %s\", route.routepath, \n              route.defaults)\n    log.debug(\"Match dict: %s\", match)\n        \nenviron['wsgiorg.routing_args'] = ((), match)\nenviron['routes.route'] = route\n\n# If the route included a path_info attribute and it should be used to\n# alter the environ, we'll pull it out\nif self.path_info and match.get('path_info'):\n    oldpath = environ['PATH_INFO']\n    newpath = match.get('path_info') or ''\n    environ['PATH_INFO'] = newpath\n    if not environ['PATH_INFO'].startswith('/'):\n        environ['PATH_INFO'] = '/' + environ['PATH_INFO']\n    environ['SCRIPT_NAME'] += re.sub(r'^(.*?)/' + newpath + '$', \n                                     r'\\1', oldpath)\n    if environ['SCRIPT_NAME'].endswith('/'):\n        environ['SCRIPT_NAME'] = environ['SCRIPT_NAME'][:-1]\n\nresponse = self.app(environ, start_response)\ndel config.environ\ndel self.mapper.environ\nreturn response", "path": "enginelight\\templates\\application\\framework\\routes\\middleware.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Generates a URL \n\nAll keys given to url_for are sent to the Routes Mapper instance for \ngeneration except for::\n    \n    anchor          specified the anchor name to be appened to the path\n    host            overrides the default (current) host if provided\n    protocol        overrides the default (current) protocol if provided\n    qualified       creates the URL with the host/port information as \n                    needed\n    \nThe URL is generated based on the rest of the keys. When generating a new \nURL, values will be used from the current request's parameters (if \npresent). The following rules are used to determine when and how to keep \nthe current requests parameters:\n\n* If the controller is present and begins with '/', no defaults are used\n* If the controller is changed, action is set to 'index' unless otherwise \n  specified\n\nFor example, if the current request yielded a dict of\n{'controller': 'blog', 'action': 'view', 'id': 2}, with the standard \n':controller/:action/:id' route, you'd get the following results::\n\n    url_for(id=4)                    =>  '/blog/view/4',\n    url_for(controller='/admin')     =>  '/admin',\n    url_for(controller='admin')      =>  '/admin/view/2'\n    url_for(action='edit')           =>  '/blog/edit/2',\n    url_for(action='list', id=None)  =>  '/blog/list'\n\n**Static and Named Routes**\n\nIf there is a string present as the first argument, a lookup is done \nagainst the named routes table to see if there's any matching routes. The\nkeyword defaults used with static routes will be sent in as GET query \narg's if a route matches.\n\nIf no route by that name is found, the string is assumed to be a raw URL. \nShould the raw URL begin with ``/`` then appropriate SCRIPT_NAME data will\nbe added if present, otherwise the string will be used as the url with \nkeyword args becoming GET query args.\n\"\"\"\n", "func_signal": "def url_for(*args, **kargs):\n", "code": "anchor = kargs.get('anchor')\nhost = kargs.get('host')\nprotocol = kargs.get('protocol')\nqualified = kargs.pop('qualified', None)\n\n# Remove special words from kargs, convert placeholders\nfor key in ['anchor', 'host', 'protocol']:\n    if kargs.get(key):\n        del kargs[key]\n    if kargs.has_key(key+'_'):\n        kargs[key] = kargs.pop(key+'_')\nconfig = request_config()\nroute = None\nstatic = False\nencoding = config.mapper.encoding\nurl = ''\nif len(args) > 0:\n    route = config.mapper._routenames.get(args[0])\n    \n    if route and route.defaults.has_key('_static'):\n        static = True\n        url = route.routepath\n    \n    # No named route found, assume the argument is a relative path\n    if not route:\n        static = True\n        url = args[0]\n    \n    if url.startswith('/') and hasattr(config, 'environ') \\\n            and config.environ.get('SCRIPT_NAME'):\n        url = config.environ.get('SCRIPT_NAME') + url\n    \n    if static:\n        if kargs:\n            url += '?'\n            query_args = []\n            for key, val in kargs.iteritems():\n                if isinstance(val, (list, tuple)):\n                    for value in val:\n                        query_args.append(\"%s=%s\" % (\n                            urllib.quote(unicode(key).encode(encoding)),\n                            urllib.quote(unicode(value).encode(encoding))))\n                else:\n                    query_args.append(\"%s=%s\" % (\n                        urllib.quote(unicode(key).encode(encoding)),\n                        urllib.quote(unicode(val).encode(encoding))))\n            url += '&'.join(query_args)\nif not static:\n    route_args = []\n    if route:\n        if config.mapper.hardcode_names:\n            route_args.append(route)\n        newargs = route.defaults.copy()\n        newargs.update(kargs)\n        \n        # If this route has a filter, apply it\n        if route.filter:\n            newargs = route.filter(newargs)\n        \n        # Handle sub-domains\n        newargs = _subdomain_check(config, newargs)\n    else:\n        newargs = _screenargs(kargs)\n    anchor = newargs.pop('_anchor', None) or anchor\n    host = newargs.pop('_host', None) or host\n    protocol = newargs.pop('_protocol', None) or protocol\n    url = config.mapper.generate(*route_args, **newargs)\nif anchor:\n    url += '#' + _url_quote(anchor, encoding)\nif host or protocol or qualified:\n    if not host and not qualified:\n        # Ensure we don't use a specific port, as changing the protocol\n        # means that we most likely need a new port\n        host = config.host.split(':')[0]\n    elif not host:\n        host = config.host\n    if not protocol:\n        protocol = config.protocol\n    if url is not None:\n        url = protocol + '://' + host + url\n\nif not isinstance(url, str) and url is not None:\n    raise RouteException(\"url_for can only return a string, got \"\n                    \"unicode instead: %s\" % url)\nif url is None:\n    raise RouteException(\n        \"url_for could not generate URL. Called with args: %s %s\" % \\\n        (args, kargs))\nreturn url", "path": "enginelight\\templates\\application\\framework\\routes\\util.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Screen the kargs for a subdomain and alter it appropriately depending\non the current subdomain or lack therof.\"\"\"\n", "func_signal": "def _subdomain_check(config, kargs):\n", "code": "if config.mapper.sub_domains:\n    subdomain = kargs.pop('sub_domain', None)\n    if isinstance(subdomain, unicode):\n        subdomain = str(subdomain)\n    \n    # We use a try/except here, cause the only time there should be no\n    # environ is when we're unit testing, in which case we shouldn't be\n    # changing kargs and such. The exception catching also won't hurt as\n    # badly here vs doing a hasattr on every url check\n    try:\n        fullhost = config.environ.get('HTTP_HOST') or \\\n            config.environ.get('SERVER_NAME')\n    except AttributeError:\n        return kargs\n    \n    hostmatch = fullhost.split(':')\n    host = hostmatch[0]\n    port = ''\n    if len(hostmatch) > 1:\n        port += ':' + hostmatch[1]\n    sub_match = re.compile('^.+?\\.(%s)$' % config.mapper.domain_match)\n    domain = re.sub(sub_match, r'\\1', host)\n    if subdomain and not host.startswith(subdomain) and \\\n        subdomain not in config.mapper.sub_domains_ignore:\n        kargs['_host'] = subdomain + '.' + domain + port\n    elif (subdomain in config.mapper.sub_domains_ignore or \\\n        subdomain is None) and domain != host:\n        kargs['_host'] = domain + port\n    return kargs\nelse:\n    return kargs", "path": "enginelight\\templates\\application\\framework\\routes\\util.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Determine whether the request is a POSTed html form\"\"\"\n", "func_signal": "def is_form_post(environ):\n", "code": "if environ['REQUEST_METHOD'] != 'POST':\n    return False\ncontent_type = environ.get('CONTENT_TYPE', '').lower()\nif ';' in content_type:\n    content_type = content_type.split(';', 1)[0]\nreturn content_type in ('application/x-www-form-urlencoded',\n                        'multipart/form-data')", "path": "enginelight\\templates\\application\\framework\\routes\\middleware.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Make a full routelist string for use with non-minimized\ngeneration\"\"\"\n", "func_signal": "def make_full_route(self):\n", "code": "regpath = ''\nfor part in self.routelist:\n    if isinstance(part, dict):\n        regpath += '%(' + part['name'] + ')s'\n    else:\n        regpath += part\nself.regpath = regpath", "path": "enginelight\\framework\\routes\\route.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Resolves the URL in PATH_INFO, and uses wsgi.routing_args\nto pass on URL resolver results.\"\"\"\n", "func_signal": "def __call__(self, environ, start_response):\n", "code": "config = request_config()\nconfig.mapper = self.mapper\n\nold_method = None\nif self.use_method_override:\n    req = WSGIRequest(environ)\n    req.errors = 'ignore'\n    if '_method' in environ.get('QUERY_STRING', '') and \\\n        '_method' in req.GET:\n        old_method = environ['REQUEST_METHOD']\n        environ['REQUEST_METHOD'] = req.GET['_method'].upper()\n        log.debug(\"_method found in QUERY_STRING, altering request\"\n                  \" method to %s\", environ['REQUEST_METHOD'])\n    elif is_form_post(environ) and '_method' in req.POST:\n        old_method = environ['REQUEST_METHOD']\n        environ['REQUEST_METHOD'] = req.POST['_method'].upper()\n        log.debug(\"_method found in POST data, altering request \"\n                  \"method to %s\", environ['REQUEST_METHOD'])\n\n# Run the actual route matching\n# -- Assignment of environ to config triggers route matching\nconfig.environ = environ\n\nmatch = config.mapper_dict\nroute = config.route\n\nif old_method:\n    environ['REQUEST_METHOD'] = old_method\n\nurlinfo = \"%s %s\" % (environ['REQUEST_METHOD'], environ['PATH_INFO'])\nif not match:\n    match = {}\n    log.debug(\"No route matched for %s\", urlinfo)\nelse:\n    log.debug(\"Matched %s\", urlinfo)\n    log.debug(\"Route path: '%s', defaults: %s\", route.routepath, \n              route.defaults)\n    log.debug(\"Match dict: %s\", match)\n        \nenviron['wsgiorg.routing_args'] = ((), match)\nenviron['routes.route'] = route\n\n# If the route included a path_info attribute and it should be used to\n# alter the environ, we'll pull it out\nif self.path_info and match.get('path_info'):\n    oldpath = environ['PATH_INFO']\n    newpath = match.get('path_info') or ''\n    environ['PATH_INFO'] = newpath\n    if not environ['PATH_INFO'].startswith('/'):\n        environ['PATH_INFO'] = '/' + environ['PATH_INFO']\n    environ['SCRIPT_NAME'] += re.sub(r'^(.*?)/' + newpath + '$', \n                                     r'\\1', oldpath)\n    if environ['SCRIPT_NAME'].endswith('/'):\n        environ['SCRIPT_NAME'] = environ['SCRIPT_NAME'][:-1]\n\nresponse = self.app(environ, start_response)\ndel config.environ\ndel self.mapper.environ\nreturn response", "path": "enginelight\\framework\\routes\\middleware.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"Determine whether the request is a POSTed html form\"\"\"\n", "func_signal": "def is_form_post(environ):\n", "code": "if environ['REQUEST_METHOD'] != 'POST':\n    return False\ncontent_type = environ.get('CONTENT_TYPE', '').lower()\nif ';' in content_type:\n    content_type = content_type.split(';', 1)[0]\nreturn content_type in ('application/x-www-form-urlencoded',\n                        'multipart/form-data')", "path": "enginelight\\framework\\routes\\middleware.py", "repo_name": "giorgil/engine-light", "stars": 2, "license": "None", "language": "python", "size": 268}
{"docstring": "\"\"\"The handler for discovery events\"\"\"\n", "func_signal": "def _DiscoHandler(self,conn,request,type):\n", "code": "if request.getFrom().getStripped() in config.admins:\n    return xmpp.commands.Command_Handler_Prototype._DiscoHandler(self,conn,request,type)\nelse:\n    return None", "path": "xep0133.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "# override the send method to use our queued version \n", "func_signal": "def register_msmsg_handlers(self, con):\n", "code": "con.send = functools.partial(self.myspacequeue, con.fromjid)\n\ncon.handlers['online']= self.ms_online\ncon.handlers['offline']= self.ms_offline\ncon.handlers['chatonline']= self.ms_chatonline\ncon.handlers['chatoffline']= self.ms_chatoffline\ncon.handlers['login'] = self.ms_login\ncon.handlers['loginfail'] = self.ms_loginfail\ncon.handlers['subscribe'] = self.ms_subscribe\ncon.handlers['message'] = self.ms_message\ncon.handlers['messagefail'] = self.ms_messagefail\ncon.handlers['chatmessage'] = self.ms_chatmessage\ncon.handlers['notify'] = self.ms_notify\ncon.handlers['mailalert'] = self.ms_mailalert\ncon.handlers['closed'] = self.ms_closed\ncon.handlers['avatar'] = self.ms_avatar\n#chatroom handlers\ncon.handlers['reqroom'] = self.ms_chat_login\ncon.handlers['roominfo'] = self.ms_chat_roominfo\ncon.handlers['chatjoin'] = self.ms_chat_join\ncon.handlers['chatleave'] = self.ms_chat_leave\ncon.handlers['roommessage'] = self.ms_roommessage\n#con.handlers['roommessagefail'] = self.ms_roommessagefail", "path": "myspace.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"Apply and save the config\"\"\"\n", "func_signal": "def cmdSecondStage(self,conn,request):\n", "code": "form = DataForm(node=request.getTag(name='command').getTag(name='x',namespace=NS_DATA))\nsession = request.getTagAttr('command','sessionid')\nif self.sessions.has_key(session):\n    if self.sessions[session]['jid'] == request.getFrom():\n        self.transport.offlinemsg = '\\n'.join(form.getField('announcement').getValues())\n        self.transport.online = 0\n        reply = request.buildReply('result')\n        reply.addChild(name='command',namespace=NS_COMMANDS,attrs={'node':request.getTagAttr('command','node'),'sessionid':session,'status':'completed'})\n        self._owner.send(reply)\n    else:\n        self._owner.send(Error(request,ERR_BAD_REQUEST))\nelse:\n    self._owner.send(Error(request,ERR_BAD_REQUEST))   \nraise NodeProcessed", "path": "xep0133.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"Set the session ID, and return the form containing the restart reason\"\"\"\n", "func_signal": "def cmdFirstStage(self,conn,request):\n", "code": "if request.getFrom().getStripped() in config.admins:\n   # Setup session ready for form reply\n   session = self.getSessionID()\n   self.sessions[session] = {'jid':request.getFrom(),'actions':{'cancel':self.cmdCancel,'next':self.cmdSecondStage,'execute':self.cmdSecondStage}}\n   # Setup form with existing data in\n   reply = request.buildReply('result')\n   form = DataForm(title='Restarting the Service',data=['Fill out this form to restart the service', DataField(typ='hidden',name='FORM_TYPE',value=NS_ADMIN),DataField(desc='Announcement', typ='text-multi', name='announcement')])\n   replypayload = [Node('actions',attrs={'execute':'next'},payload=[Node('next')]),form]\n   reply.addChild(name='command',namespace=NS_COMMANDS,attrs={'node':request.getTagAttr('command','node'),'sessionid':session,'status':'executing'},payload=replypayload)\n   self._owner.send(reply)\nelse:\n   self._owner.send(Error(request,ERR_FORBIDDEN))\nraise NodeProcessed", "path": "xep0133.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"Build the reply to complete the request\"\"\"\n", "func_signal": "def cmdFirstStage(self,conn,request):\n", "code": "if request.getFrom().getStripped() in config.admins:\n    for each in self.userfile.keys():\n        conn.send(Presence(to=each, frm = config.jid, typ = 'probe'))\n        if self.userfile[each].has_key('servers'):\n            for server in self.userfile[each]['servers']:\n                conn.send(Presence(to=each, frm = '%s@%s'%(server,config.jid), typ = 'probe'))\n    reply = request.buildReply('result')\n    form = DataForm(typ='result',data=[DataField(value='Command completed.',typ='fixed')])\n    reply.addChild(name='command',namespace=NS_COMMANDS,attrs={'node':request.getTagAttr('command','node'),'sessionid':self.getSessionID(),'status':'completed'},payload=[form])\n    self._owner.send(reply)\nelse:\n    self._owner.send(Error(request,ERR_FORBIDDEN))\nraise NodeProcessed", "path": "adhoc.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "#This is service online not person online\n", "func_signal": "def ms_chatonline(self,msobj, msid):\n", "code": "for each in msobj.xresources.keys():\n    mjid = JID(msobj.fromjid)\n    mjid.setResource(each)\n    b = Presence(to = mjid, frm = '%s@%s/chat' %(msid,config.jid), priority = 5)\n    self.jabberqueue(b)", "path": "myspace.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"Initialise the command object\"\"\"\n", "func_signal": "def __init__(self,transport,jid=''):\n", "code": "xmpp.commands.Command_Handler_Prototype.__init__(self,jid)\nself.initial = {'execute':self.cmdFirstStage }\nself.transport = transport", "path": "xep0133.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"Initialise the command object\"\"\"\n", "func_signal": "def __init__(self,userfile):\n", "code": "xmpp.commands.Command_Handler_Prototype.__init__(self,config.jid)\nself.initial = { 'execute':self.cmdFirstStage }\nself.userfile = userfile", "path": "adhoc.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"The handler for discovery events\"\"\"\n", "func_signal": "def _DiscoHandler(self,conn,request,type):\n", "code": "if request.getFrom().getStripped() in config.admins:\n    return xmpp.commands.Command_Handler_Prototype._DiscoHandler(self,conn,request,type)\nelse:\n    return None", "path": "xep0133.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"Set the session ID, and return the form containing the current administrators\"\"\"\n", "func_signal": "def cmdFirstStage(self,conn,request):\n", "code": "if request.getFrom().getStripped() in config.admins:\n   # Setup session ready for form reply\n   session = self.getSessionID()\n   self.sessions[session] = {'jid':request.getFrom(),'actions':{'cancel':self.cmdCancel,'next':self.cmdSecondStage,'execute':self.cmdSecondStage}}\n   # Setup form with existing data in\n   reply = request.buildReply('result')\n   form = DataForm(title='Editing the Admin List',data=['Fill out this form to edit the list of entities who have administrative privileges', DataField(typ='hidden',name='FORM_TYPE',value=NS_ADMIN),DataField(desc='The Admin List', typ='jid-multi', name='adminjids',value=config.admins)])\n   replypayload = [Node('actions',attrs={'execute':'next'},payload=[Node('next')]),form]\n   reply.addChild(name='command',namespace=NS_COMMANDS,attrs={'node':request.getTagAttr('command','node'),'sessionid':session,'status':'executing'},payload=replypayload)\n   self._owner.send(reply)\nelse:\n   self._owner.send(Error(request,ERR_FORBIDDEN))\nraise NodeProcessed", "path": "xep0133.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"Build the reply to complete the request\"\"\"\n", "func_signal": "def cmdFirstStage(self,conn,request):\n", "code": "if request.getFrom().getStripped() in config.admins:\n    reply = request.buildReply('result')\n    form = DataForm(typ='result',data=[DataField(typ='hidden',name='FORM_TYPE',value=NS_ADMIN),DataField(desc='The list of active users',name='activeuserjids',value=self.users.keys(),typ='jid-multi')])\n    reply.addChild(name='command',namespace=NS_COMMANDS,attrs={'node':request.getTagAttr('command','node'),'sessionid':self.getSessionID(),'status':'completed'},payload=[form])\n    self._owner.send(reply)\nelse:\n    self._owner.send(Error(request,ERR_FORBIDDEN))\nraise NodeProcessed", "path": "xep0133.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"Initialise the command object\"\"\"\n", "func_signal": "def __init__(self,userfile,jid=''):\n", "code": "xmpp.commands.Command_Handler_Prototype.__init__(self,jid)\nself.initial = { 'execute':self.cmdFirstStage }\nself.userfile = userfile", "path": "xep0133.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"Initialise the command object\"\"\"\n", "func_signal": "def __init__(self,transport,jid=''):\n", "code": "xmpp.commands.Command_Handler_Prototype.__init__(self,jid)\nself.initial = {'execute':self.cmdFirstStage }\nself.transport = transport", "path": "adhoc.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"Initialise the command object\"\"\"\n", "func_signal": "def __init__(self,users,jid=''):\n", "code": "xmpp.commands.Command_Handler_Prototype.__init__(self,jid)\nself.initial = { 'execute':self.cmdFirstStage }\nself.users = users", "path": "xep0133.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "#This is service offline not person offline\n", "func_signal": "def ms_chatoffline(self,msobj,msid):\n", "code": "for each in msobj.xresources.keys():\n    mjid = JID(msobj.fromjid)\n    mjid.setResource(each)\n    self.jabberqueue(Presence(to =mjid, frm = '%s@%s/chat'%(msid, config.jid),typ='unavailable'))", "path": "myspace.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"The handler for discovery events\"\"\"\n", "func_signal": "def _DiscoHandler(self,conn,request,type):\n", "code": "if request.getFrom().getStripped() in config.admins:\n    return xmpp.commands.Command_Handler_Prototype._DiscoHandler(self,conn,request,type)\nelse:\n    return None", "path": "xep0133.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "# send authentication challenge responce\n", "func_signal": "def msmsg_challenge(self,msg):\n", "code": "stage = msg.get_int('lc')\nif stage == 1:\n    ip_list = [x[4][0] for x in socket.getaddrinfo(socket.gethostname(), None, socket.AF_INET, socket.SOCK_STREAM)]\n    response = myspace_auth.process_auth(self.username,self.password,msg.get_bin('nc'),ip_list)\n    self.send(msmsg_mkmsg(\n        ('int',MS_loginresponse,196610),\n        ('str','username',self.username),\n        ('bin','response',response),\n        ('int','clientver',self.version),\n        ('int','reconn',0),\n        ('int','status',100),\n        ('int','id',1)))\nelif stage == 2:\n    self.session = msg.get_int('sesskey')\n    self.uid = msg.get_int('userid')\n    self.msmsg_send_persist_req('list_contacts')\n    for data in self.sendqueue:\n        self.send_msg(*data)\n    self.sendqueue = None\nelse:\n    raise Exception('unexpected login challenge stage: %s' % stage)", "path": "mslib.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"Apply and save the config\"\"\"\n", "func_signal": "def cmdSecondStage(self,conn,request):\n", "code": "form = DataForm(node=request.getTag(name='command').getTag(name='x',namespace=NS_DATA))\nsession = request.getTagAttr('command','sessionid')\nif self.sessions.has_key(session):\n    if self.sessions[session]['jid'] == request.getFrom():\n        self.transport.offlinemsg = '\\n'.join(form.getField('announcement').getValues())\n        self.transport.restart = 1\n        self.transport.online = 0\n        reply = request.buildReply('result')\n        reply.addChild(name='command',namespace=NS_COMMANDS,attrs={'node':request.getTagAttr('command','node'),'sessionid':session,'status':'completed'})\n        self._owner.send(reply)\n    else:\n        self._owner.send(Error(request,ERR_BAD_REQUEST))\nelse:\n    self._owner.send(Error(request,ERR_BAD_REQUEST))   \nraise NodeProcessed", "path": "xep0133.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"Build the reply to complete the request\"\"\"\n", "func_signal": "def cmdFirstStage(self,conn,request):\n", "code": "if request.getFrom().getStripped() in config.admins:\n    reply = request.buildReply('result')\n    form = DataForm(typ='result',data=[DataField(typ='hidden',name='FORM_TYPE',value=NS_ADMIN),DataField(desc='The list of registered users',name='registereduserjids',value=self.userfile.keys(),typ='jid-multi')])\n    reply.addChild(name='command',namespace=NS_COMMANDS,attrs={'node':request.getTagAttr('command','node'),'sessionid':self.getSessionID(),'status':'completed'},payload=[form])\n    self._owner.send(reply)\nelse:\n    self._owner.send(Error(request,ERR_FORBIDDEN))\nraise NodeProcessed", "path": "xep0133.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\"The handler for discovery events\"\"\"\n", "func_signal": "def _DiscoHandler(self,conn,request,type):\n", "code": "if request.getFrom().getStripped() in config.admins:\n    return xmpp.commands.Command_Handler_Prototype._DiscoHandler(self,conn,request,type)\nelse:\n    return None", "path": "xep0133.py", "repo_name": "xmpppy/myspace-transport", "stars": 2, "license": "None", "language": "python", "size": 104}
{"docstring": "\"\"\" Provide the xml string \"\"\"\n\n", "func_signal": "def __init__(self, xml_str):\n", "code": "self.albums = []\nself.current_album = {}\nself.xml_str = xml_str", "path": "xmlparser.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" configuration files are read in \"\"\"\n#TODO: check for path's existance\n", "func_signal": "def __init__(self, config):\n", "code": "self.libpath   = config.libpath\nself.thumbpath = config.thumbpath", "path": "utilities.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" Retrieves the requested photo and saves it in a cache \"\"\"\n", "func_signal": "def getThumb(self, server, uri):\n", "code": "url = 'http://' + server + ':8407/thumb' + quote(uri)\nfilename = \"./tmp/\" + hashlib.sha1(url).hexdigest() + \".jpg\"\nif not os.path.exists(filename):\n\turlretrieve(url, filename)\nreturn filename", "path": "client.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" parser helper \"\"\"\n", "func_signal": "def handleEndElement(self, name):\n", "code": "if name == 'album':\n\tself.current_album['count'] = len(self.current_album['photos'])\n\tself.albums.append(self.current_album)", "path": "xmlparser.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" parse the xml string to generate the array of album dictionaries \"\"\"\n", "func_signal": "def parse(self):\n", "code": "parser = xml.parsers.expat.ParserCreate()\n\nparser.CharacterDataHandler = self.handleCharData\nparser.StartElementHandler = self.handleStartElement\nparser.EndElementHandler = self.handleEndElement\n\nparser.Parse(self.xml_str)", "path": "xmlparser.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" parser helper \"\"\"\n", "func_signal": "def handleStartElement(self, name, attrs):\n", "code": "if name == 'album':\n\tself.current_album = {}\n\tself.current_album['name'] = attrs['name']\n\tself.current_album['photos'] = []\n\nif name == 'photo':\n\tself.current_album['photos'].append({'path': attrs['path'], 'thumb': attrs['thumb']})", "path": "xmlparser.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" Constructor, opnes the specified configuration file. Default = \"dpss_client.conf\" \"\"\"\n#TODO: error checking\n", "func_signal": "def __init__(self, cfile = None):\n", "code": "self.cfile = cfile or \"dpss_client.conf\"\nconfig = ConfigParser.ConfigParser()\nconfig.read(self.cfile)\nself.buddylist = filter(self.filterIP, [ip.strip() for ip in config.get(\"client\", \"buddylist\").split(\",\")]);", "path": "utilities.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "#first load the config file\n", "func_signal": "def main():\n", "code": "c = utilities.Config()\n\n#get the xml\nxml = utilities.XMLGenerator(c).generate()\nf = open(\"albums.xml\", \"w\");\nf.write(xml);\nf.close();\n\n#serve the xml and the files\nservername = socket.gethostname()\n\nreactor.listenTCP(8407, PXMLFactory())\nreactor.run()", "path": "server.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" Constructor, opnes the specified configuration file. Default = \"dpss_server.conf\" \"\"\"\n", "func_signal": "def __init__(self, cfile = None):\n", "code": "self.cfile = cfile or \"dpss_server.conf\"\nconfig = ConfigParser.ConfigParser()\nconfig.read(self.cfile)\nself.libpath = os.path.expanduser(config.get(\"server\", \"libpath\"))\nself.thumbpath = os.path.expanduser(config.get(\"server\", \"thumbpath\"))\nself.listtype = config.get(\"server\", \"listtype\")\nself.ips = filter(self.filterIP, [ip.strip() for ip in config.get(\"server\", \"iplist\").split(\",\")]);", "path": "utilities.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" Connect to a user specified server and update the GUI \"\"\"\n\n", "func_signal": "def OnConnect(self, event):\n", "code": "self.statusbar.SetStatusText('Connecting...')\ndialog = wx.TextEntryDialog(self, 'Please Enter an IP to connect to:', 'Connect to IP')\ndialog.SetValue(\"127.0.0.1\")\n#if dialog.ShowModal == wx.ID_OK:\n\t#self.client.connect(dialog.GetValue())\ndialog.Destroy()", "path": "dpss.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" Parses the client requests and write out approperiate response \"\"\"\n", "func_signal": "def lineReceived(self, line):\n", "code": "if line == \"getxml\":\n\tself.sendXML(self.factory.xml)\nelif line.startswith(\"getphoto \"):\n\tself.sendPicture(line[9:])\nelif line == \"quit\":\n\tself.transport.write(\"good bye\\r\\n\")\n\tself.transport.loseConnection()\nelif line == \"help\":\n\tself.transport.write(\"getxml              : get the xml file with album/photo data\\r\\n\")\n\tself.transport.write(\"getphoto [filename] : get the photo of your choice \\r\\n\")\n\tself.transport.write(\"help                : see this message\\r\\n\")\n\tself.transport.write(\"quit                : disconnect\\r\\n\")\nelse:\n\tself.transport.write(\"DPSP 400 Bad Request\\r\\n\")", "path": "server.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" Validates IP address \"\"\"\n", "func_signal": "def isValidIP(self, ip):\n", "code": "if self.listtype == \"black\":\n\tif self.ips.count(ip):\n\t\treturn False\n\telse:\n\t\treturn True\nelse:\n\tif self.ips.count(ip):\n\t\treturn True\n\telse:\n\t\treturn False", "path": "utilities.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" Retrieves the requested photo and saves it in a cache \"\"\"\n", "func_signal": "def getOriginal(self, server, uri):\n", "code": "url = 'http://' + server + ':8407/original' + quote(uri)\nfilename = \"./tmp/\" + hashlib.sha1(url).hexdigest() + \".jpg\"\nif not os.path.exists(filename):\n\turlretrieve(url, filename)\nreturn filename", "path": "client.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" Validates IP address \"\"\"\n", "func_signal": "def isValidIP(self, ip):\n", "code": "if self.listtype == \"black\":\n\tif self.ips.count(ip):\n\t\treturn False\n\telse:\n\t\treturn True\nelse:\n\tif self.ips.count(ip):\n\t\treturn True\n\telse:\n\t\treturn False", "path": "utilities.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" Event handler for finishing up the connection. Strips the HTTP header and save only the data \"\"\"\n", "func_signal": "def handle_close(self):\n", "code": "self.data = ''.join(self.data_buffer)\na,b,self.data = self.data.partition(\"\\r\\n\\r\\n\")\nself.close()", "path": "http_client.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\"\n\tConstructor\n\t\n\tPopulates the left tree pane.\n\"\"\"\n", "func_signal": "def __init__(self, parent, id, title, client):\n", "code": "wx.Frame.__init__(self, parent, id, title, size=(800,500))\n\nself.client = client\n\n\n#create the main pain", "path": "dpss.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" Filters out the bad IPs \"\"\"\n", "func_signal": "def filterIP(self, ip):\n", "code": "for n in ip.split(\".\"):\n\tunit = int(n)\n\tif unit < 0 or unit > 255:\n\t\treturn None\nreturn ip", "path": "utilities.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" Event handler for tree item selections \"\"\"\n", "func_signal": "def OnTreeSelection(self, event):\n", "code": "item = event.GetItem()\nphoto = self.tree.GetPyData(item)\nif photo:\n\tp = self.client.getThumb(photo[\"server\"], photo[\"thumb\"])\n\tself.picture.SetBitmap(wx.Bitmap(p))\n\tself.Refresh()", "path": "dpss.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" Scans the directory specified the configuration and generates the xml file \"\"\"\n\n", "func_signal": "def generate(self):\n", "code": "albums = []\n\n#parse through the director to make the album list\nfor root, dirs, files in os.walk(self.libpath):\n\tfor f in files[:]:\n\t\tif not (f.endswith(\".jpg\") or f.endswith(\".jpeg\") or f.endswith(\".JPG\") or f.endswith(\".JPEG\")): files.remove(f)\n\tif len(files) > 0:\n\t\talbums.append({\"name\": os.path.basename(root), \"path\": root, \"thumbpath\": root.replace(self.libpath, self.thumbpath, 1), \"pictures\": files, })\n\n#return xml string\nxml = []\nxml.append('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\nxml.append('<albums count=\"' + str(len(albums)) + '\">\\n')\nfor album in albums:\n\txml.append('\\t<album name=\"' + album['name'] + '\" count=\"' + str(len(album['pictures'])) + '\">\\n')\n\tfor pic in album['pictures']:\n\t\txml.append('\\t\\t<photo path=\"' + album['path'].replace(self.libpath, '', 1) + \"/\" + pic + '\" thumb=\"' + album['thumbpath'].replace(self.thumbpath, '', 1) + \"/\" + pic + '\" />\\n')\n\txml.append('\\t</album>\\n')\nxml.append('</albums>\\n')\n\nreturn ''.join(xml)", "path": "utilities.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
{"docstring": "\"\"\" Filters out the bad IPs \"\"\"\n", "func_signal": "def filterIP(self, ip):\n", "code": "for n in ip.split(\".\"):\n\tunit = int(n)\n\tif unit < 0 or unit > 255:\n\t\treturn None\nreturn ip", "path": "utilities.py", "repo_name": "timothykim/dpss", "stars": 3, "license": "None", "language": "python", "size": 124}
